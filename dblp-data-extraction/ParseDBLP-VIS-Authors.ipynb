{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4fd8455b-c4eb-4809-a0c6-2baaa651d7c2",
   "metadata": {},
   "source": [
    "# DBLP VIS Paper Parser\n",
    "\n",
    "This code extracts papers and their deduped authors from DBLP.\n",
    "To run this code first do the following:\n",
    "\n",
    "- Go to the DBLP website https://dblp.org/xml/\n",
    "- Download the latest .xml and .dtd and put them into the **data** subfolder folder of the dblp-data-extraction folder in this repository.\n",
    "\n",
    "\n",
    "\n",
    "This code is inspired by and copies from: https://github.com/26hzhang/DBLPParser/blob/master/src/dblp_parser.py\n",
    "\n",
    "A DBLP parser by ZHANG HAO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a6231de-b782-4f42-bd50-ea7f994d37e8",
   "metadata": {},
   "source": [
    "## 1) Import what we need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3dba897e-9b28-4c8d-9d22-738e0050b131",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml import etree\n",
    "import re\n",
    "import csv\n",
    "import codecs\n",
    "from tqdm import tqdm\n",
    "from time import sleep\n",
    "\n",
    "# all of the element types in dblp\n",
    "all_elements = {\"article\", \"inproceedings\", \"proceedings\", \"book\", \"incollection\", \"phdthesis\", \"mastersthesis\", \"www\"}\n",
    "# all of the feature types in dblp\n",
    "all_features = {\"address\", \"author\", \"booktitle\", \"cdrom\", \"chapter\", \"cite\", \"crossref\", \"editor\", \"ee\", \"isbn\",\n",
    "                \"journal\", \"month\", \"note\", \"number\", \"pages\", \"publisher\", \"school\", \"series\", \"title\", \"url\",\n",
    "                \"volume\", \"year\"}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a84c5d-5fd9-4d8e-a89b-5fb8ab13c54b",
   "metadata": {},
   "source": [
    "## 2) Helper methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9eb3addd-6d4b-4a9d-9908-153e6dbc6681",
   "metadata": {},
   "outputs": [],
   "source": [
    "def context_iter(dblp_path):\n",
    "    \"\"\"Create a dblp data iterator of (event, element) pairs for processing\"\"\"\n",
    "    return etree.iterparse(source=dblp_path, dtd_validation=True, load_dtd=True)  # requires the dtd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "065e685c-2113-4ede-ad9a-07bdc35ddd3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_element(element):\n",
    "    \"\"\"Free up memory for temporary element tree after processing the element\"\"\"\n",
    "    element.clear()\n",
    "    while element.getprevious() is not None:\n",
    "        del element.getparent()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "85e68594-acfb-4304-8507-8b082238f337",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_feature(elem, features, include_key=False):\n",
    "    \"\"\"Extract the value of each feature\"\"\"\n",
    "    if include_key:\n",
    "        attribs = {'key': [elem.attrib['key']]}\n",
    "    else:\n",
    "        attribs = {}\n",
    "    for feature in features:\n",
    "        attribs[feature] = []\n",
    "    for sub in elem:\n",
    "        if sub.tag not in features:\n",
    "            continue\n",
    "        if sub.tag == 'title':\n",
    "            text = re.sub(\"<.*?>\", \"\", etree.tostring(sub).decode('utf-8')) if sub.text is None else sub.text\n",
    "        else:\n",
    "            text = sub.text\n",
    "        if text is not None and len(text) > 0:\n",
    "            attribs[sub.tag] = attribs.get(sub.tag) + [text]\n",
    "    return attribs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5637c48-4683-43cf-9127-438d22923117",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7a7d64f0-5e73-4557-a5f4-774e5d3edbff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_vis_publication(key, publications_to_search):\n",
    "\n",
    "    key = key.lower()  # Convert text to lowercase to ensure case-insensitive search\n",
    "    for publication in publications_to_search:\n",
    "        if publication in key:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4a4067b5-8d8e-480a-b7ce-6095647444dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_entity(dblp_path, save_path, type_name, features=None, save_to_csv=False, include_key=False):\n",
    "    \"\"\"Parse specific elements according to the given type name and features\"\"\"\n",
    "    print(\"PROCESS: Start parsing for {}...\".format(str(type_name)))\n",
    "    assert features is not None, \"features must be assigned before parsing the dblp dataset\"\n",
    "    results = []\n",
    "    attrib_count, full_entity, part_entity = {}, 0, 0\n",
    "    pbar = tqdm(position=0, leave=True)\n",
    "    \n",
    "    \n",
    "    for _, elem in context_iter(dblp_path):\n",
    "        if elem.tag in type_name:\n",
    "            attrib_values = extract_feature(elem, features, include_key)  # extract required features\n",
    "            #visconferences = ['infovis','visualization','ieeevast','tvcg','scivis','apvis','cgf','vissym']\n",
    "            visconferences = ['infovis','visualization','ieeevast','tvcg','scivis','journals/cga']\n",
    "            \n",
    "            key = attrib_values['key'][0]\n",
    "            isVisPaper = is_vis_publication(key, visconferences)\n",
    "            \n",
    "            if isVisPaper:\n",
    "                \n",
    "                results.append(attrib_values)  # add record to results array\n",
    "                for key, value in attrib_values.items():\n",
    "                    attrib_count[key] = attrib_count.get(key, 0) + len(value)\n",
    "                cnt = sum([1 if len(x) > 0 else 0 for x in list(attrib_values.values())])\n",
    "                if cnt == len(features):\n",
    "                    full_entity += 1\n",
    "                else:\n",
    "                    part_entity += 1\n",
    "        elif elem.tag not in all_elements:\n",
    "            continue\n",
    "        clear_element(elem)\n",
    "        sleep(0.1)\n",
    "        pbar.update(10)\n",
    "        \n",
    "    if save_to_csv:\n",
    "        f = open(save_path, 'w', newline='', encoding='utf8')\n",
    "        writer = csv.writer(f, delimiter=',')\n",
    "        writer.writerow(features)  # write title\n",
    "        for record in results:\n",
    "            # some features contain multiple values (e.g.: author), concatenate with `::`\n",
    "            row = ['::'.join(v) for v in list(record.values())]\n",
    "            writer.writerow(row)\n",
    "        f.close()\n",
    "    else:  # default save to json file\n",
    "        with codecs.open(save_path, mode='w', encoding='utf8', errors='ignore') as f:\n",
    "            ujson.dump(results, f)\n",
    "    return full_entity, part_entity, attrib_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fc51de99-c29a-43de-8b5b-840617db1dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_article(dblp_path, save_path, save_to_csv=False, include_key=True):\n",
    "    type_name = ['article','inproceedings']\n",
    "    features = ['title', 'author', 'year', 'ee'] #ee is the doi\n",
    "    info = parse_entity(dblp_path, save_path, type_name, features, save_to_csv=save_to_csv, include_key=include_key)\n",
    "    print('Total articles found: {}, articles contain all features: {}, articles contain part of features: {}'\n",
    "            .format(info[0] + info[1], info[0], info[1]))\n",
    "    print(\"Features information: {}\".format(str(info[2])))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb922ceb-8197-4a67-979c-3cf59a48bd4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOG: Successfully loaded \"data/dblp.xml\".\n",
      "PROCESS: Start parsing for ['article', 'inproceedings']...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "830it [00:09, 92.00it/s]"
     ]
    }
   ],
   "source": [
    "\n",
    "dblp_path = 'data/dblp.xml'\n",
    "save_path = 'data/VIS-author-articles.csv'\n",
    "try:\n",
    "    context_iter(dblp_path)\n",
    "    print(\"LOG: Successfully loaded \\\"{}\\\".\".format(dblp_path))\n",
    "except IOError:\n",
    "    print(\"ERROR: Failed to load file \\\"{}\\\". Please check your XML and DTD files.\".format(dblp_path))\n",
    "    \n",
    "parse_article(dblp_path, save_path, save_to_csv=True)\n",
    "print(\"DONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b541135-9d21-488b-a91b-04f611587bd6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
