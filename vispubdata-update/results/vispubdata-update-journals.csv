Journal,Year,Title,DOI,Link,FirstPage,LastPage,PaperType,Abstract,AuthorNames-Deduped,AuthorNames,AuthorAffiliation,InternalReferences,AuthorKeywords,AminerCitationCount,CitationCount_CrossRef,PubsCited_CrossRef,Downloads_Xplore,Award,GraphicsReplicabilityStamp
TVCG,2014,GraphDiaries: Animated Transitions andTemporal Navigation for Dynamic Networks,10.1109/tvcg.2013.254,http://dx.doi.org/10.1109/TVCG.2013.254,740,754,J,"Identifying, tracking and understanding changes in dynamic networks are complex and cognitively demanding tasks. We present GraphDiaries, a visual interface designed to improve support for these tasks in any node-link based graph visualization system. GraphDiaries relies on animated transitions that highlight changes in the network between time steps, thus helping users identify and understand those changes. To better understand the tasks related to the exploration of dynamic networks, we first introduce a task taxonomy, that informs the design of GraphDiaries, presented afterwards. We then report on a user study, based on representative tasks identified through the taxonomy, and that compares GraphDiaries to existing techniques for temporal navigation in dynamic networks, showing that it outperforms them in terms of both task time and errors for several of these tasks.",Benjamin Bach;Emmanuel Pietriga;Jean-Daniel Fekete,Benjamin Bach;Emmanuel Pietriga;Jean-Daniel Fekete,"INRIA, Saclay, France;INRIA, Saclay, France and INRIA Chile-CIRIC, Santiago, Chile;INRIA, Saclay, France",0.1109/infvis.1999.801854;10.1109/tvcg.2007.70539;10.1109/vast.2006.261450;10.1109/tvcg.2008.153;10.1109/tvcg.2008.125,"Dynamic networks,graph visualization,,,,,,,,,,,temporal navigation,,,,,,,,,,,user experiment",,132,48,1647,,
TVCG,2011,Hierarchical Line Integration,10.1109/tvcg.2010.227,http://dx.doi.org/10.1109/TVCG.2010.227,1148,1163,J,"This paper presents an acceleration scheme for the numerical computation of sets of trajectories in vector fields or iterated solutions in maps, possibly with simultaneous evaluation of quantities along the curves such as integrals or extrema. It addresses cases with a dense evaluation on the domain, where straightforward approaches are subject to redundant calculations. These are avoided by first calculating short solutions for the whole domain. From these, longer solutions are then constructed in a hierarchical manner until the designated length is achieved. While the computational complexity of the straightforward approach depends linearly on the length of the solutions, the computational cost with the proposed scheme grows only logarithmically with increasing length. Due to independence of subtasks and memory locality, our algorithm is suitable for parallel execution on many-core architectures like GPUs. The trade-offs of the method—lower accuracy and increased memory consumption—are analyzed, including error order as well as numerical error for discrete computation grids. The usefulness and flexibility of the scheme are demonstrated with two example applications: line integral convolution and the computation of the finite-time Lyapunov exponent. Finally, results and performance measurements of our GPU implementation are presented for both synthetic and simulated vector fields from computational fluid dynamics.",Marcel Hlawatsch;Filip Sadlo;Daniel Weiskopf,Marcel Hlawatsch;Filip Sadlo;Daniel Weiskopf,"Visualisierungsinstitut der Universität Stuttgart, Stuttgart, Germany;Visualisierungsinstitut der Universität Stuttgart, Stuttgart, Germany;Visualisierungsinstitut der Universität Stuttgart, Stuttgart, Germany",0.1109/visual.1993.398875;10.1109/visual.2003.1250361;10.1109/visual.2000.885688;10.1109/visual.2000.885689;10.1109/tvcg.2007.70551;10.1109/tvcg.2007.70554,"Flow visualization,integral curves,,,,,,,,,,,hierarchical computation,,,,,,,,,,,FTLE,,,,LIC,GPU.",,48,37,614,,
CG&A,2015,Visualizing Personal Progress in Participatory Sports Cycling Events,10.1109/mcg.2015.71,http://dx.doi.org/10.1109/MCG.2015.71,73,81,MAG,"This article explores the potential for creating personal visualization of participation in sports cycling as a design study. Examples show riders' personal narratives and performances relative to other participants in long-distance cycling events. Minimalist cartographic design is applied during the automatic generation of profile maps, which allows personal textual narratives to be attached to visualizations of 3D variations in terrain. Changes in relative position and time-in-hand data during mass participation events are shown as position charts, and animations of rider density over time are used to visualize the progress of larger groups of riders in an event. The designs focus on representing the aspects of participation that evoke an emotional response in an effort to engage users.",Jo Wood,Jo Wood,"City University, London",0.1109/tvcg.2014.2329308,"computer graphics,personal visualization,,,,,,,,,,,affective computing,,,,,,,,,,,sports data,,,,graphics design study",,13,5,1134,,
TVCG,2011,Stable Feature Flow Fields,10.1109/tvcg.2010.93,http://dx.doi.org/10.1109/TVCG.2010.93,770,780,J,"Feature Flow Fields are a well-accepted approach for extracting and tracking features. In particular, they are often used to track critical points in time-dependent vector fields and to extract and track vortex core lines. The general idea is to extract the feature or its temporal evolution using a stream line integration in a derived vector field—the so-called Feature Flow Field (FFF). Hence, the desired feature line is a stream line of the FFF. As we will carefully analyze in this paper, the stream lines around this feature line may diverge from it. This creates an unstable situation: if the integration moves slightly off the feature line due to numerical errors, then it will be captured by the diverging neighborhood and carried away from the real feature line. The goal of this paper is to define a new FFF with the guarantee that the neighborhood of a feature line has always converging behavior. This way, we have an automatic correction of numerical errors: if the integration moves slightly off the feature line, it automatically moves back to it during the ongoing integration. This yields results which are an order of magnitude more accurate than the results from previous schemes. We present new stable FFF formulations for the main applications of tracking critical points and solving the Parallel Vectors operator. We apply our method to a number of data sets.",Tino Weinkauf;Holger Theisel;Allen Van Gelder;Alex T. Pang,Tino Weinkauf;Holger Theisel;Allen Van Gelder;Alex Pang,"Learning and Graphics Group, Courant Institute of Mathematical Sciences, New York University, New York, NY, USA;AG Visual Computing, Fakultät für Informatik, Otto-von-Guericke-Universität Magdeburg, Germany;University of California Santa Cruz, Santa Cruz, CA, US;Baskin School of Engineering, Santa Cruz, CA, USA",0.1109/visual.2004.107;10.1109/visual.1991.175773;10.1109/visual.1999.809896;10.1109/tvcg.2008.148;10.1109/tvcg.2007.70545;10.1109/tvcg.2010.93;10.1109/visual.2001.964507,"Flow visualization,feature extraction.",,49,34,775,,
TVCG,2013,Visualizing the Variability of Gradients in Uncertain 2D Scalar Fields,10.1109/tvcg.2013.92,http://dx.doi.org/10.1109/TVCG.2013.92,1948,1961,J,"In uncertain scalar fields where data values vary with a certain probability, the strength of this variability indicates the confidence in the data. It does not, however, allow inferring on the effect of uncertainty on differential quantities such as the gradient, which depend on the variability of the rate of change of the data. Analyzing the variability of gradients is nonetheless more complicated, since, unlike scalars, gradients vary in both strength and direction. This requires initially the mathematical derivation of their respective value ranges, and then the development of effective analysis techniques for these ranges. This paper takes a first step into this direction: Based on the stochastic modeling of uncertainty via multivariate random variables, we start by deriving uncertainty parameters, such as the mean and the covariance matrix, for gradients in uncertain discrete scalar fields. We do not make any assumption about the distribution of the random variables. Then, for the first time to our best knowledge, we develop a mathematical framework for computing confidence intervals for both the gradient orientation and the strength of the derivative in any prescribed direction, for instance, the mean gradient direction. While this framework generalizes to 3D uncertain scalar fields, we concentrate on the visualization of the resulting intervals in 2D fields. We propose a novel color diffusion scheme to visualize both the absolute variability of the derivative strength and its magnitude relative to the mean values. A special family of circular glyphs is introduced to convey the uncertainty in gradient orientation. For a number of synthetic and real-world data sets, we demonstrate the use of our approach for analyzing the stability of certain features in uncertain 2D scalar fields, with respect to both local derivatives and feature orientation.",Tobias Pfaffelmoser;Mihaela Mihai;Rüdiger Westermann,Tobias Pfaffelmoser;Mihaela Mihai;Rüdiger Westermann,"Computer Graphics and Visualization Group, Technische Universität München, Garching bei Munchen, Bavaria, Germany;Computer Graphics and Visualization Group, Technische Universität München, Garching bei Munchen, Bavaria, Germany;Computer Graphics and Visualization Group, Technische Universität München, Garching bei Munchen, Bavaria, Germany",0.1109/tvcg.2010.131;10.1109/visual.2004.25;10.1109/tvcg.2007.70530;10.1109/visual.2005.1532807;10.1109/tvcg.2010.150;10.1109/visual.2003.1250414;10.1109/tvcg.2007.70518;10.1109/tvcg.2010.181,"Uncertainty visualization,gradient variability,,,,,,,,,,,structural uncertainty,,,,,,,,,,,glyphs",,28,42,581,,
TVCG,2012,Topology Verification for Isosurface Extraction,10.1109/tvcg.2011.109,http://dx.doi.org/10.1109/TVCG.2011.109,952,965,J,"The broad goals of verifiable visualization rely on correct algorithmic implementations. We extend a framework for verification of isosurfacing implementations to check topological properties. Specifically, we use stratified Morse theory and digital topology to design algorithms which verify topological invariants. Our extended framework reveals unexpected behavior and coding mistakes in popular publicly available isosurface codes.",Tiago Etiene;Luis Gustavo Nonato;Carlos Eduardo Scheidegger;Julien Tierny;Thomas J. Peters;Valerio Pascucci;Robert M. Kirby;Cláudio T. Silva,Tiago Etiene;Luis Gustavo Nonato;Carlos Scheidegger;Julien Tienry;Thomas J. Peters;Valerio Pascucci;Robert M. Kirby;Claudio T. Silva,"School of Computing and SCI Institute, University of Utah, Salt Lake City, UT, USA;Departamento de Matemática Aplicada e Estatística, Universidade de São Paulo, São Carlos, SP, Brazil;AT&T Labs—Research, Madison, NJ, USA;TELECOM ParisTech, Paris, ÃŽle-de-France, FR;Department of Computer Science and Engineering, University of Connecticut, Fairfield, Way, Storrs, CT, USA;School of Computing and SCI Institute, University of Utah, Salt Lake City, UT, USA;School of Computing and SCI Institute, University of Utah, Salt Lake City, UT, USA;School of Computing and SCI Institute, University of Utah, Salt Lake City, UT, USA",0.1109/visual.2002.1183772;10.1109/tvcg.2009.194;10.1109/visual.1991.175782;10.1109/tvcg.2006.149,"Verifiable visualization,isosurface,,,,,,,,,,,topology.",,28,43,629,,
TVCG,2011,Color Lens: Adaptive Color Scale Optimization for Visual Exploration,10.1109/tvcg.2010.94,http://dx.doi.org/10.1109/TVCG.2010.94,795,807,J,"Visualization applications routinely map quantitative attributes to color using color scales. Although color is an effective visualization channel, it is limited by both display hardware and the human visual system. We propose a new interaction technique that overcomes these limitations by dynamically optimizing color scales based on a set of sampling lenses. The technique inspects the lens contents in data space, optimizes the initial color scale, and then renders the contents of the lens to the screen using the modified color scale. We present two prototype implementations of this pipeline and describe several case studies involving both information visualization and image inspection applications. We validate our approach with two mutually linked and complementary user studies comparing the Color Lens with explicit contrast control for visual search.",Niklas Elmqvist;Pierre Dragicevic;Jean-Daniel Fekete,Niklas Elmqvist;Pierre Dragicevic;Jean-Daniel Fekete,"School of Electrical and Computer Engineering, Purdue University, West Lafayette, IN, USA;INRIA Saclay Île de France INRIA LRI, Universite Paris Sud, Orsay, France;INRIA Saclay Île de France INRIA LRI, Universite Paris Sud, Orsay, France",0.1109/infvis.2004.64;10.1109/tvcg.2009.191;10.1109/infvis.2005.1532136,"Color scales,visualization,,,,,,,,,,,interaction technique,,,,,,,,,,,Magic Lens.",,22,40,998,,
TVCG,2013,Integrating Isosurface Statistics and Histograms,10.1109/tvcg.2012.118,http://dx.doi.org/10.1109/TVCG.2012.118,263,277,J,"Many data sets are sampled on regular lattices in two, three or more dimensions, and recent work has shown that statistical properties of these data sets must take into account the continuity of the underlying physical phenomena. However, the effects of quantization on the statistics have not yet been accounted for. This paper therefore reconciles the previous papers to the underlying mathematical theory, develops a mathematical model of quantized statistics of continuous functions, and proves convergence of geometric approximations to continuous statistics for regular sampling lattices. In addition, the computational cost of various approaches is considered, and recommendations made about when to use each type of statistic.",Brian Duffy;Hamish A. Carr;Torsten Möller,Brian Duffy;Hamish Carr;Torsten Möller,"Post Doctoral Research Office, Mathematical Institute University of Oxford, United Kingdom;Visualization & Virtual Reality Group, School of Computing University of Leeds, United Kingdom;Simon Fraser University, Burnaby",0.1109/visual.1997.663875;10.1109/visual.1996.568121;10.1109/visual.2003.1250414;10.1109/visual.2001.964519;10.1109/tvcg.2006.168;10.1109/tvcg.2008.160;10.1109/tvcg.2008.119;10.1109/visual.2001.964516;10.1109/tvcg.2010.182;10.1109/visual.1994.346334;10.1109/visual.1995.480807;10.1109/visual.1994.346331,"Histograms,frequency distribution,,,,,,,,,,,integration,,,,,,,,,,,geometric statistics",,20,27,811,,
CG&A,2018,ARIES: Enabling Visual Exploration and Organization of Art Image Collections,10.1109/mcg.2017.377152546,http://dx.doi.org/10.1109/MCG.2017.377152546,91,108,MAG,"Art historians have traditionally used physical light boxes to prepare exhibits or curate collections. On a light box, they can place slides or printed images, move the images around at will, group them as desired, and visual-ly compare them. The transition to digital images has rendered this workflow obsolete. Now, art historians lack well-designed, unified interactive software tools that effectively support the operations they perform with physi-cal light boxes. To address this problem, we designed ARIES (ARt Image Exploration Space), an interactive image manipulation system that enables the exploration and organization of fine digital art. The system allows images to be compared in multiple ways, offering dynamic overlays analogous to a physical light box, and sup-porting advanced image comparisons and feature-matching functions, available through computational image processing. We demonstrate the effectiveness of our system to support art historians tasks through real use cases.",Lhaylla Crissaff;Louisa Wood Ruby;Samantha Deutch;R. Luke DuBois;Jean-Daniel Fekete;Juliana Freire;Cláudio T. Silva,Lhaylla Crissaff;Louisa Wood Ruby;Samantha Deutch;R. Luke DuBois;Jean-Daniel Fekete;Juliana Freire;Claudio Silva,Universidade Federal Fluminense;The Frick Art Reference Library;The Frick Art Reference Library;New York University;INRIA;New York University;New York University,0.1109/tvcg.2008.127,"ARIES,museum,,,,,,,,,,,light box,,,,,,,,,,,art history,,,,computer graphics,applications",,13,18,706,,
TVCG,2019,Visual Analytics in Deep Learning: An Interrogative Survey for the Next Frontiers,10.1109/tvcg.2018.2843369,http://dx.doi.org/10.1109/TVCG.2018.2843369,2674,2693,J,"Deep learning has recently seen rapid development and received significant attention due to its state-of-the-art performance on previously-thought hard problems. However, because of the internal complexity and nonlinear structure of deep neural networks, the underlying decision making processes for why these models are achieving such performance are challenging and sometimes mystifying to interpret. As deep learning spreads across domains, it is of paramount importance that we equip users of deep learning with tools for understanding when a model works correctly, when it fails, and ultimately how to improve its performance. Standardized toolkits for building neural networks have helped democratize deep learning; visual analytics systems have now been developed to support model explanation, interpretation, debugging, and improvement. We present a survey of the role of visual analytics in deep learning research, which highlights its short yet impactful history and thoroughly summarizes the state-of-the-art using a human-centered interrogative framework, focusing on the Five W's and How (Why, Who, What, How, When, and Where). We conclude by highlighting research directions and open research problems. This survey helps researchers and practitioners in both visual analytics and deep learning to quickly learn key aspects of this young and rapidly growing body of research, whose impact spans a diverse range of domains.",Fred Hohman;Minsuk Kahng;Robert S. Pienta;Duen Horng Chau,Fred Hohman;Minsuk Kahng;Robert Pienta;Duen Horng Chau,"College of Computing, Georgia Tech, Atlanta, Georgia, USA;College of Computing, Georgia Tech, Atlanta, Georgia, USA;College of Computing, Georgia Tech, Atlanta, Georgia, USA;College of Computing, Georgia Tech, Atlanta, Georgia, USA",0.1109/tvcg.2017.2744718;10.1109/tvcg.2017.2744683;10.1109/tvcg.2017.2744158;10.1109/tvcg.2016.2598838;10.1109/tvcg.2017.2744358;10.1109/tvcg.2017.2744938;10.1109/vast.2017.8585721;10.1109/tvcg.2015.2467618;10.1109/tvcg.2016.2598831;10.1109/tvcg.2017.2744878;10.1109/tvcg.2017.2745141;10.1109/tvcg.2016.2598828;10.1109/tvcg.2016.2598829;10.1109/vast.2017.8585669;10.1109/tvcg.2017.2744478,"Deep learning,visual analytics,,,,,,,,,,,information visualization,,,,,,,,,,,neural networks",,291,128,6494,,
TVCG,2015,Personal Visualization and Personal Visual Analytics,10.1109/tvcg.2014.2359887,http://dx.doi.org/10.1109/TVCG.2014.2359887,420,433,J,"Data surrounds each and every one of us in our daily lives, ranging from exercise logs, to archives of our interactions with others on social media, to online resources pertaining to our hobbies. There is enormous potential for us to use these data to understand ourselves better and make positive changes in our lives. Visualization (Vis) and visual analytics (VA) offer substantial opportunities to help individuals gain insights about themselves, their communities and their interests; however, designing tools to support data analysis in non-professional life brings a unique set of research and design challenges. We investigate the requirements and research directions required to take full advantage of Vis and VA in a personal context. We develop a taxonomy of design dimensions to provide a coherent vocabulary for discussing personal visualization and personal visual analytics. By identifying and exploring clusters in the design space, we discuss challenges and share perspectives on future research. This work brings together research that was previously scattered across disciplines. Our goal is to call research attention to this space and engage researchers to explore the enabling techniques and technology that will support people to better understand data relevant to their personal lives, interests, and needs.",Dandan Huang;Melanie Tory;Bon Adriel Aseniero;Lyn Bartram;Scott Bateman;Sheelagh Carpendale;Anthony Tang 0001;Rob Woodbury,Dandan Huang;Melanie Tory;Bon Adriel Aseniero;Lyn Bartram;Scott Bateman;Sheelagh Carpendale;Anthony Tang;Robert Woodbury,University of Victoria;University of Victoria;University of Calgary;Simon Fraser University;University of Prince Edward Island;University of Calgary;University of Calgary;Simon Fraser University,0.1109/infvis.2004.5;10.1109/tvcg.2011.196;10.1109/tvcg.2010.164;10.1109/tvcg.2007.70541;10.1109/tvcg.2009.183;10.1109/tvcg.2010.129;10.1109/tvcg.2008.187;10.1109/tvcg.2012.291;10.1109/tvcg.2009.171;10.1109/tvcg.2011.174;10.1109/tvcg.2010.206,"Taxonomy,personal context,,,,,,,,,,,interaction design,,,,,,,,,,,mobile and ubiquitous visualization,,,,Taxonomy,personal context,interaction design,mobile and ubiquitous visualization",,146,84,4545,,
TVCG,2016,"A Study of Layout, Rendering, and Interaction Methods for Immersive Graph Visualization",10.1109/tvcg.2016.2520921,http://dx.doi.org/10.1109/TVCG.2016.2520921,1802,1815,J,"Information visualization has traditionally limited itself to 2D representations, primarily due to the prevalence of 2D displays and report formats. However, there has been a recent surge in popularity of consumer grade 3D displays and immersive head-mounted displays (HMDs). The ubiquity of such displays enables the possibility of immersive, stereoscopic visualization environments. While techniques that utilize such immersive environments have been explored extensively for spatial and scientific visualizations, contrastingly very little has been explored for information visualization. In this paper, we present our considerations of layout, rendering, and interaction methods for visualizing graphs in an immersive environment. We conducted a user study to evaluate our techniques compared to traditional 2D graph visualization. The results show that participants answered significantly faster with a fewer number of interactions using our techniques, especially for more difficult tasks. While the overall correctness rates are not significantly different, we found that participants gave significantly more correct answers using our techniques for larger graphs.",Oh-Hyun Kwon;Chris Muelder;Kyungwon Lee;Kwan-Liu Ma,Oh-Hyun Kwon;Chris Muelder;Kyungwon Lee;Kwan-Liu Ma,"Department of Computer Science, University of California, Davis, Davis, CA;Department of Computer Science, University of California, Davis, Davis, CA;Department of Digital Media, Ajou University, Suwon, Korea;Department of Computer Science, University of California, Davis, Davis, CA",0.1109/tvcg.2012.142;10.1109/infvis.1997.636718;10.1109/tvcg.2011.233;10.1109/tvcg.2006.147;10.1109/tvcg.2009.138;10.1109/tvcg.2011.234;10.1109/tvcg.2008.158;10.1109/tvcg.2012.192,"Graph visualization,virtual reality,,,,,,,,,,,immersive environments,,,,,,,,,,,head-mounted display,,,,Graph visualization,virtual reality,immersive environments,head-mounted display",,134,61,3751,,
TVCG,2017,Timelines Revisited: A Design Space and Considerations for Expressive Storytelling,10.1109/tvcg.2016.2614803,http://dx.doi.org/10.1109/TVCG.2016.2614803,2151,2164,J,"There are many ways to visualize event sequences as timelines. In a storytelling context where the intent is to convey multiple narrative points, a richer set of timeline designs may be more appropriate than the narrow range that has been used for exploratory data analysis by the research community. Informed by a survey of 263 timelines, we present a design space for storytelling with timelines that balances expressiveness and effectiveness, identifying 14 design choices characterized by three dimensions: representation, scale, and layout. Twenty combinations of these choices are viable timeline designs that can be matched to different narrative points, while smooth animated transitions between narrative points allow for the presentation of a cohesive story, an important aspect of both interactive storytelling and data videos. We further validate this design space by realizing the full set of viable timeline designs and transitions in a proof-of-concept sandbox implementation that we used to produce seven example timeline stories. Ultimately, this work is intended to inform and inspire the design of future tools for storytelling with timelines.",Matthew Brehmer;Bongshin Lee;Benjamin Bach;Nathalie Henry Riche;Tamara Munzner,Matthew Brehmer;Bongshin Lee;Benjamin Bach;Nathalie Henry Riche;Tamara Munzner,"Microsoft Research, Redmond, WA;Microsoft Research, Redmond, WA;Harvard University, Cambridge, MA;Microsoft Research, Redmond, WA;University of British Columbia, Vancouver, BC, Canada",0.1109/tvcg.2011.255;10.1109/tvcg.2011.179;10.1109/vast.2009.5332595;10.1109/tvcg.2013.200;10.1109/tvcg.2015.2467531;10.1109/tvcg.2015.2467732;10.1109/tvcg.2010.179;10.1109/tvcg.2013.119;10.1109/tvcg.2014.2346424;10.1109/infvis.2002.1173148;10.1109/tvcg.2007.70539;10.1109/tvcg.2013.254;10.1109/infvis.2001.963273;10.1109/tvcg.2015.2502587;10.1109/tvcg.2015.2467851;10.1109/tvcg.2012.212;10.1109/tvcg.2011.185;10.1109/tvcg.2015.2413786,"Timelines,storytelling,,,,,,,,,,,narrative visualization,,,,,,,,,,,design space,,,,animated transitions",,116,102,5088,,
TVCG,2017,Vispubdata.org: A Metadata Collection About IEEE Visualization (VIS) Publications,10.1109/tvcg.2016.2615308,http://dx.doi.org/10.1109/TVCG.2016.2615308,2199,2206,J,"We have created and made available to all a dataset with information about every paper that has appeared at the IEEE Visualization (VIS) set of conferences: InfoVis, SciVis, VAST, and Vis. The information about each paper includes its title, abstract, authors, and citations to other papers in the conference series, among many other attributes. This article describes the motivation for creating the dataset, as well as our process of coalescing and cleaning the data, and a set of three visualizations we created to facilitate exploration of the data. This data is meant to be useful to the broad data visualization community to help understand the evolution of the field and as an example document collection for text data visualization research.",Petra Isenberg;Florian Heimerl;Steffen Koch 0001;Tobias Isenberg 0001;Panpan Xu;Charles D. Stolper;Michael Sedlmair;Jian Chen 0006;Torsten Möller;John T. Stasko,Petra Isenberg;Florian Heimerl;Steffen Koch;Tobias Isenberg;Panpan Xu;Charles D. Stolper;Michael Sedlmair;Jian Chen;Torsten Möller;John Stasko,"Inria, Le Chesnay, France;University of Stuttgart, Stuttgart, Germany;University of Stuttgart, Stuttgart, Germany;Inria, Le Chesnay, France;Hong Kong University of Science and Technology, Kowloon, Hong Kong;Georgia Tech, Atlanta, GA;University Vienna, Wien, Austria;University of Maryland, College Park, MD;University Vienna, Wien, Austria;Georgia Tech, Atlanta, GA",0.1109/tvcg.2015.2467621;10.1109/tvcg.2012.324;10.1109/vast.2006.261429;10.1109/tvcg.2016.2598827,"Visualization,publication data,,,,,,,,,,,citation data",,99,20,2637,,
TVCG,2017,Revealing Patterns and Trends of Mass Mobility Through Spatial and Temporal Abstraction of Origin-Destination Movement Data,10.1109/tvcg.2016.2616404,http://dx.doi.org/10.1109/TVCG.2016.2616404,2120,2136,J,"Origin-destination (OD) movement data describe moves or trips between spatial locations by specifying the origins, destinations, start, and end times, but not the routes travelled. For studying the spatio-temporal patterns and trends of mass mobility, individual OD moves of many people are aggregated into flows (collective moves) by time intervals. Time-variant flow data pose two difficult challenges for visualization and analysis. First, flows may connect arbitrary locations (not only neighbors), thus making a graph with numerous edge intersections, which is hard to visualize in a comprehensible way. Even a single spatial situation consisting of flows in one time step is hard to explore. The second challenge is the need to analyze long time series consisting of numerous spatial situations. We present an approach facilitating exploration of long-term flow data by means of spatial and temporal abstraction. It involves a special way of data aggregation, which allows representing spatial situations by diagram maps instead of flow maps, thus reducing the intersections and occlusions pertaining to flow maps. The aggregated data are used for clustering of time intervals by similarity of the spatial situations. Temporal and spatial displays of the clustering results facilitate the discovery of periodic patterns and longer-term trends in the mass mobility behavior.",Gennady L. Andrienko;Natalia V. Andrienko;Georg Fuchs;Jo Wood,Gennady Andrienko;Natalia Andrienko;Georg Fuchs;Jo Wood,"Fraunhofer Institute IAIS, Sankt Augustin, Germany;Fraunhofer Institute IAIS, Sankt Augustin, Germany;Fraunhofer Institute IAIS, Sankt Augustin, Germany;City University, London, United Kingdom",0.1109/vast.2008.4677356;10.1109/tvcg.2011.233;10.1109/tvcg.2014.2346441;10.1109/tvcg.2011.202;10.1109/tvcg.2014.2346271;10.1109/infvis.1999.801851;10.1109/tvcg.2015.2468078;10.1109/tvcg.2015.2467851;10.1109/tvcg.2009.143;10.1109/tvcg.2015.2468111,"Movement data,mobility behavior,,,,,,,,,,,spatial flow situation,,,,,,,,,,,flow map",,88,56,2892,,
TVCG,2017,A Systematic Review of Experimental Studies on Data Glyphs,10.1109/tvcg.2016.2549018,http://dx.doi.org/10.1109/TVCG.2016.2549018,1863,1879,J,"We systematically reviewed 64 user-study papers on data glyphs to help researchers and practitioners gain an informed understanding of tradeoffs in the glyph design space. The glyphs we consider are individual representations of multi-dimensional data points, often meant to be shown in small-multiple settings. Over the past 60 years many different glyph designs were proposed and many of these designs have been subjected to perceptual or comparative evaluations. Yet, a systematic overview of the types of glyphs and design variations tested, the tasks under which they were analyzed, or even the study goals and results does not yet exist. In this paper we provide such an overview by systematically sampling and tabulating the literature on data glyph studies, listing their designs, questions, data, and tasks. In addition we present a concise overview of the types of glyphs and their design characteristics analyzed by researchers in the past, and a synthesis of the study results. Based on our meta analysis of all results we further contribute a set of design implications and a discussion on open research directions.",Johannes Fuchs 0001;Petra Isenberg;Anastasia Bezerianos;Daniel A. Keim,Johannes Fuchs;Petra Isenberg;Anastasia Bezerianos;Daniel Keim,"University of Konstanz, Konstanz, Germany;Inria, Paris, France;Univ Paris Sud, CNRS & Inria, Paris, France;University of Konstanz, Konstanz, Germany",0.1109/tvcg.2011.189;10.1109/visual.1991.175795;10.1109/tvcg.2006.155;10.1109/tvcg.2012.199;10.1109/tvcg.2012.271;10.1109/tvcg.2014.2346426;10.1109/tvcg.2013.20;10.1109/visual.2005.1532835;10.1109/tvcg.2011.194;10.1109/tvcg.2015.2467435;10.1109/tvcg.2011.217;10.1109/tvcg.2006.189,"Survey,glyphs,,,,,,,,,,,quantitative evaluation,,,,,,,,,,,glyph design",,63,103,1824,,
TVCG,2017,Coping with Volume and Variety in Temporal Event Sequences: Strategies for Sharpening Analytic Focus,10.1109/tvcg.2016.2539960,http://dx.doi.org/10.1109/TVCG.2016.2539960,1636,1649,J,"The growing volume and variety of data presents both opportunities and challenges for visual analytics. Addressing these challenges is needed for big data to provide valuable insights and novel solutions for business, security, social media, and healthcare. In the case of temporal event sequence analytics it is the number of events in the data and variety of temporal sequence patterns that challenges users of visual analytic tools. This paper describes 15 strategies for sharpening analytic focus that analysts can use to reduce the data volume and pattern variety. Four groups of strategies are proposed: (1) extraction strategies, (2) temporal folding, (3) pattern simplification strategies, and (4) iterative strategies. For each strategy, we provide examples of the use and impact of this strategy on volume and/or variety. Examples are selected from 20 case studies gathered from either our own work, the literature, or based on email interviews with individuals who conducted the analyses and developers who observed analysts using the tools. Finally, we discuss how these strategies might be combined and report on the feedback from 10 senior event sequence analysts.",Fan Du;Ben Shneiderman;Catherine Plaisant;Sana Malik;Adam Perer,Fan Du;Ben Shneiderman;Catherine Plaisant;Sana Malik;Adam Perer,"Department of Computer Science and the Human-Computer Interaction Lab, University of Maryland;Department of Computer Science and the Human-Computer Interaction Lab, University of Maryland;UMIACS and the Human-Computer Interaction Lab, University of Maryland;Department of Computer Science and the Human-Computer Interaction Lab, University of Maryland;IBM T.J. Watson Research Center",0.1109/tvcg.2011.179;10.1109/tvcg.2015.2467622;10.1109/tvcg.2014.2346452;10.1109/tvcg.2009.187;10.1109/tvcg.2012.225;10.1109/vast.2014.7042487;10.1109/tvcg.2007.70515;10.1109/tvcg.2014.2346682;10.1109/tvcg.2014.2346574;10.1109/tvcg.2013.178;10.1109/tvcg.2013.200,"Big data,temporal data,,,,,,,,,,,temporal event sequences,,,,,,,,,,,workflow,,,,visual analytics,visualization,analytic focus",,56,68,1454,,
TVCG,2015,Visual Correlation Analysis of Numerical and Categorical Data on the Correlation Map,10.1109/tvcg.2014.2350494,http://dx.doi.org/10.1109/TVCG.2014.2350494,289,303,J,"Correlation analysis can reveal the complex relationships that often exist among the variables in multivariate data. However, as the number of variables grows, it can be difficult to gain a good understanding of the correlation landscape and important intricate relationships might be missed. We previously introduced a technique that arranged the variables into a 2D layout, encoding their pairwise correlations. We then used this layout as a network for the interactive ordering of axes in parallel coordinate displays. Our current work expresses the layout as a correlation map and employs it for visual correlation analysis. In contrast to matrix displays where correlations are indicated at intersections of rows and columns, our map conveys correlations by spatial proximity which is more direct and more focused on the variables in play. We make the following new contributions, some unique to our map: (1) we devise mechanisms that handle both categorical and numerical variables within a unified framework, (2) we achieve scalability for large numbers of variables via a multi-scale semantic zooming approach, (3) we provide interactive techniques for exploring the impact of value bracketing on correlations, and (4) we visualize data relations within the sub-spaces spanned by correlated variables by projecting the data into a corresponding tessellation of the map.",Zhiyuan Zhang 0006;Kevin T. McDonnell;Erez Zadok;Klaus Mueller 0001,Zhiyuan Zhang;Kevin T. McDonnell;Erez Zadok;Klaus Mueller,"Visual Analytics and Imaging Lab at the Computer Science Department, Stony Brook University, Stony Brook, NY;Department of Mathematics and Computer Science, Dowling College, Oakdale, NY;Filesystems and Storage Lab at the Computer Science Department, Stony Brook University, Stony Brook, NY;Computer Science Department, SUNY Korea, Korea",0.1109/tvcg.2006.160;10.1109/visual.1997.663916;10.1109/visual.1990.146402;10.1109/tvcg.2012.65;10.1109/tvcg.2013.133;10.1109/tvcg.2011.178;10.1109/tvcg.2011.201;10.1109/visual.1991.175790;10.1109/tvcg.2007.70523,"Visual analytics,visual correlation analysis,,,,,,,,,,,categorical data,,,,,,,,,,,information visualization,,,,interactive interfaces",,55,37,2201,,
TVCG,2017,A Survey on Visual Approaches for Analyzing Scientific Literature and Patents,10.1109/tvcg.2016.2610422,http://dx.doi.org/10.1109/TVCG.2016.2610422,2179,2198,J,"The increasingly large number of available writings describing technical and scientific progress, calls for advanced analytic tools for their efficient analysis. This is true for many application scenarios in science and industry and for different types of writings, comprising patents and scientific articles. Despite important differences between patents and scientific articles, both have a variety of common characteristics that lead to similar search and analysis tasks. However, the analysis and visualization of these documents is not a trivial task due to the complexity of the documents as well as the large number of possible relations between their multivariate attributes. In this survey, we review interactive analysis and visualization approaches of patents and scientific articles, ranging from exploration tools to sophisticated mining methods. In a bottom-up approach, we categorize them according to two aspects: (a) data type (text, citations, authors, metadata, and combinations thereof), and (b) task (finding and comparing single entities, seeking elementary relations, finding complex patterns, and in particular temporal patterns, and investigating connections between multiple behaviours). Finally, we identify challenges and research directions in this area that ask for future investigations.",Paolo Federico 0001;Florian Heimerl;Steffen Koch 0001;Silvia Miksch,Paolo Federico;Florian Heimerl;Steffen Koch;Silvia Miksch,"Institute of Software Technology and Interactive Systems, Vienna University of Technology, Vienna, Austria;Institute for Visualization and Interactive Systems, University of Stuttgart, Stuttgart, Germany;Institute for Visualization and Interactive Systems, University of Stuttgart, Stuttgart, Germany;Institute of Software Technology and Interactive Systems, Vienna University of Technology, Vienna, Austria",0.1109/tvcg.2012.324;10.1109/tvcg.2009.139;10.1109/tvcg.2013.162;10.1109/tvcg.2009.122;10.1109/infvis.2000.885098;10.1109/tvcg.2014.2346481;10.1109/tvcg.2014.2346578;10.1109/vast.2011.6102461;10.1109/vast.2010.5652940;10.1109/tvcg.2009.202;10.1109/infvis.2004.14;10.1109/infvis.2004.39;10.1109/tvcg.2012.252;10.1109/infvis.2004.23;10.1109/vast.2011.6102441;10.1109/tvcg.2013.254;10.1109/infvis.2004.22;10.1109/vast.2011.6102443;10.1109/vast.2008.4677380;10.1109/tvcg.2013.184;10.1109/tvcg.2013.167;10.1109/tvcg.2015.2467757;10.1109/tvcg.2011.186;10.1109/tvcg.2013.109;10.1109/tvcg.2015.2467621;10.1109/infvis.2001.963287;10.1109/tvcg.2013.212;10.1109/vast.2011.6102442;10.1109/tvcg.2007.70582,"Visualization,scientific literature,,,,,,,,,,,patents,,,,,,,,,,,documents,,,,survey",,55,151,2738,,
TVCG,2016,AllAboard: Visual Exploration of Cellphone Mobility Data to Optimise Public Transport,10.1109/tvcg.2015.2440259,http://dx.doi.org/10.1109/TVCG.2015.2440259,1036,1050,J,"The deep penetration of mobile phones offers cities the ability to opportunistically monitor citizens' mobility and use data-driven insights to better plan and manage services. With large scale data on mobility patterns, operators can move away from the costly, mostly survey based, transportation planning processes, to a more data-centric view, that places the instrumented user at the center of development. In this framework, using mobile phone data to perform transit analysis and optimization represents a new frontier with significant societal impact, especially in developing countries. In this paper we present AllAboard, an intelligent tool that analyses cellphone data to help city authorities in visually exploring urban mobility and optimizing public transport. This is performed within a self contained tool, as opposed to the current solutions which rely on a combination of several distinct tools for analysis, reporting, optimisation and planning. An interactive user interface allows transit operators to visually explore the travel demand in both space and time, correlate it with the transit network, and evaluate the quality of service that a transit network provides to the citizens at very fine grain. Operators can visually test scenarios for transit network improvements, and compare the expected impact on the travellers' experience. The system has been tested using real telecommunication data for the city of Abidjan, Ivory Coast, and evaluated from a data mining, optimisation and user prospective.",Giusy Di Lorenzo;Marco Luca Sbodio;Francesco Calabrese;Michele Berlingerio;Fabio Pinelli;Rahul Nair,G. Di Lorenzo;M. Sbodio;F. Calabrese;M. Berlingerio;F. Pinelli;R. Nair,"IBM Research Ireland, IBM Technology Campus, Damastown Industrial Estate;IBM Research Ireland, IBM Technology Campus, Damastown Industrial Estate;IBM Research Ireland, IBM Technology Campus, Damastown Industrial Estate;IBM Research Ireland, IBM Technology Campus, Damastown Industrial Estate;IBM Research Ireland, IBM Technology Campus, Damastown Industrial Estate;IBM Research Ireland, IBM Technology Campus, Damastown Industrial Estate",0.1109/tvcg.2012.279;10.1109/tvcg.2013.179;10.1109/tvcg.2011.181;10.1109/tvcg.2013.228;10.1109/tvcg.2013.226,"Spatio-temporal mining,cellphone data,,,,,,,,,,,visual exploration,,,,,,,,,,,urban data mobility,,,,transit network",,53,34,1959,,
TVCG,2016,PeakVizor: Visual Analytics of Peaks in Video Clickstreams from Massive Open Online Courses,10.1109/tvcg.2015.2505305,http://dx.doi.org/10.1109/TVCG.2015.2505305,2315,2330,J,"Massive open online courses (MOOCs) aim to facilitate open-access and massive-participation education. These courses have attracted millions of learners recently. At present, most MOOC platforms record the web log data of learner interactions with course videos. Such large amounts of multivariate data pose a new challenge in terms of analyzing online learning behaviors. Previous studies have mainly focused on the aggregate behaviors of learners from a summative view; however, few attempts have been made to conduct a detailed analysis of such behaviors. To determine complex learning patterns in MOOC video interactions, this paper introduces a comprehensive visualization system called PeakVizor. This system enables course instructors and education experts to analyze the “peaks” or the video segments that generate numerous clickstreams. The system features three views at different levels: the overview with glyphs to display valuable statistics regarding the peaks detected; the flow view to present spatio-temporal information regarding the peaks; and the correlation view to show the correlation between different learner groups and the peaks. Case studies and interviews conducted with domain experts have demonstrated the usefulness and effectiveness of PeakVizor, and new findings about learning behaviors in MOOC platforms have been reported.",Qing Chen 0001;Yuanzhe Chen;Dongyu Liu;Conglei Shi;Yingcai Wu;Huamin Qu,Qing Chen;Yuanzhe Chen;Dongyu Liu;Conglei Shi;Yingcai Wu;Huamin Qu,"Hong Kong University of Science and Technology, Hong Kong;Hong Kong University of Science and Technology, Hong Kong;Hong Kong University of Science and Technology, Hong Kong;IBM T.J. Watson Research Center, New York, NY;Zhejiang University, Hangzhou, Zhejinag, China;Hong Kong University of Science and Technology, Hong Kong",0.1109/vast.2012.6400494;10.1109/tvcg.2013.196;10.1109/tvcg.2009.111;10.1109/tvcg.2012.288;10.1109/tvcg.2011.188,"MOOC,online education,,,,,,,,,,,visual analytics,,,,,,,,,,,clickstream data",,48,48,1720,,
TVCG,2015,An Efficient Framework for Generating Storyline Visualizations from Streaming Data,10.1109/tvcg.2015.2392771,http://dx.doi.org/10.1109/TVCG.2015.2392771,730,742,J,"This paper presents a novel framework for applying storyline visualizations to streaming data. The framework includes three components: a new data management scheme for processing and storing the incoming data, a layout construction algorithm specifically designed for incrementally generating storylines from streaming data, and a layout refinement algorithm for improving the legibility of the visualization. By dividing the layout computation to two separate components, one for constructing and another for refining, our framework effectively provides the users with the ability to follow and reason dynamic data. The evaluation studies of our storyline visualization framework demonstrate its efficacy to present streaming data as well as its superior performance over existing methods in terms of both computational efficiency and visual clarity.",Yuzuru Tanahashi;Chien-Hsin Hsueh;Kwan-Liu Ma,Yuzuru Tanahashi;Chien-Hsin Hsueh;Kwan-Liu Ma,"VIDI Research Group, University California, Davis, CA;VIDI Research Group, University California, Davis, CA;VIDI Research Group, University California, Davis, CA",0.1109/tvcg.2008.166;10.1109/tvcg.2010.159;10.1109/tvcg.2011.239;10.1109/infvis.2004.27;10.1109/tvcg.2006.193;10.1109/infvis.2002.1173160;10.1109/tvcg.2013.196;10.1109/tvcg.2012.212,"Storyline visualization,streaming data,,,,,,,,,,,layout algorithms,,,,,,,,,,,time-varying data,,,,Storyline visualization,streaming data,layout algorithms,time-varying data",,50,39,2085,,
TVCG,2017,Uncertainty Visualization by Representative Sampling from Prediction Ensembles,10.1109/tvcg.2016.2607204,http://dx.doi.org/10.1109/TVCG.2016.2607204,2165,2178,J,"Data ensembles are often used to infer statistics to be used for a summary display of an uncertain prediction. In a spatial context, these summary displays have the drawback that when uncertainty is encoded via a spatial spread, display glyph area increases in size with prediction uncertainty. This increase can be easily confounded with an increase in the size, strength or other attribute of the phenomenon being presented. We argue that by directly displaying a carefully chosen subset of a prediction ensemble, so that uncertainty is conveyed implicitly, such misinterpretations can be avoided. Since such a display does not require uncertainty annotation, an information channel remains available for encoding additional information about the prediction. We demonstrate these points in the context of hurricane prediction visualizations, showing how we avoid occlusion of selected ensemble elements while preserving the spatial statistics of the original ensemble, and how an explicit encoding of uncertainty can also be constructed from such a selection. We conclude with the results of a cognitive experiment demonstrating that the approach can be used to construct storm prediction displays that significantly reduce the confounding of uncertainty with storm size, and thus improve viewers' ability to estimate potential for storm damage.",Le Liu 0007;Alexander P. Boone;Ian T. Ruginski;Lace M. K. Padilla;Mary Hegarty;Sarah H. Creem-Regehr;William B. Thompson;Cem Yuksel;Donald H. House,Le Liu;Alexander P. Boone;Ian T. Ruginski;Lace Padilla;Mary Hegarty;Sarah H. Creem-Regehr;William B. Thompson;Cem Yuksel;Donald H. House,"Clemson University, Clemson, SC, 29672;Department of Psychological & Brain Sciences, University of California, Santa Barbara, CA;Department of Psychology, University of Utah, Salt Lake City, UT;Department of Psychology, University of Utah, Salt Lake City, UT;Department of Psychological & Brain Sciences, University of California, Santa Barbara, CA;Department of Psychology, University of Utah, Salt Lake City, UT;School of Computing, University of Utah, Salt Lake City, UT;School of Computing, University of Utah, Salt Lake City, UT;Clemson University, Clemson, SC, 29672",0.1109/tvcg.2014.2346594;10.1109/tvcg.2014.2346455;10.1109/tvcg.2013.143,"Implicit uncertainty presentation,ensembles,,,,,,,,,,,ensemble visualization,,,,,,,,,,,sampling,,,,uncertainty,hurricane prediction",,52,30,1895,,
TVCG,2015,The Impact of Interactivity on Comprehending 2D and 3D Visualizations of Movement Data,10.1109/tvcg.2014.2329308,http://dx.doi.org/10.1109/TVCG.2014.2329308,122,135,J,"GPS, RFID, and other technologies have made it increasingly common to track the positions of people and objects over time as they move through two-dimensional spaces. Visualizing such spatio-temporal movement data is challenging because each person or object involves three variables (two spatial variables as a function of the time variable), and simply plotting the data on a 2D geographic map can result in overplotting and occlusion that hides details. This also makes it difficult to understand correlations between space and time. Software such as GeoTime can display such data with a three-dimensional visualization, where the 3rd dimension is used for time. This allows for the disambiguation of spatially overlapping trajectories, and in theory, should make the data clearer. However, previous experimental comparisons of 2D and 3D visualizations have so far found little advantage in 3D visualizations, possibly due to the increased complexity of navigating and understanding a 3D view. We present a new controlled experimental comparison of 2D and 3D visualizations, involving commonly performed tasks that have not been tested before, and find advantages in 3D visualizations for more complex tasks. In particular, we tease out the effects of various basic interactions and find that the 2D view relies significantly on “scrubbing” the timeline, whereas the 3D view relies mainly on 3D camera navigation. Our work helps to improve understanding of 2D and 3D visualizations of spatio-temporal data, particularly with respect to interactivity.",Fereshteh Amini;Sébastien Rufiange;Zahid Hossain 0002;Quentin Ventura;Pourang Irani;Michael J. McGuffin,Fereshteh Amini;Sébastien Rufiange;Zahid Hossain;Quentin Ventura;Pourang Irani;Michael J. McGuffin,"Department of Computer Science, University of Manitoba, Winnipeg, Canada;École de technologie supérieure, Montreal, Canada;Department of Computer Science, University of Manitoba, Winnipeg, Canada;École de technologie supérieure, Montreal, Canada;Department of Computer Science, University of Manitoba, Winnipeg, Canada;École de technologie supérieure, Montreal, Canada",0.1109/tvcg.2012.265;10.1109/vast.2009.5332593;10.1109/tvcg.2007.70621;10.1109/tvcg.2007.70521;10.1109/infvis.2004.27,"Information visualization,spatio-temporal data,,,,,,,,,,,movement data,,,,,,,,,,,interactive visualization,,,,evaluation",,47,55,2147,,
TVCG,2015,An Approach to Supporting Incremental Visual Data Classification,10.1109/tvcg.2014.2331979,http://dx.doi.org/10.1109/TVCG.2014.2331979,4,17,J,"Automatic data classification is a computationally intensive task that presents variable precision and is considerably sensitive to the classifier configuration and to data representation, particularly for evolving data sets. Some of these issues can best be handled by methods that support users' control over the classification steps. In this paper, we propose a visual data classification methodology that supports users in tasks related to categorization such as training set selection; model creation, application and verification; and classifier tuning. The approach is then well suited for incremental classification, present in many applications with evolving data sets. Data set visualization is accomplished by means of point placement strategies, and we exemplify the method through multidimensional projections and Neighbor Joining trees. The same methodology can be employed by a user who wishes to create his or her own ground truth (or perspective) from a previously unlabeled data set. We validate the methodology through its application to categorization scenarios of image and text data sets, involving the creation, application, verification, and adjustment of classification models.",Jose Gustavo Paiva;William Robson Schwartz;Hélio Pedrini;Rosane Minghim,Jose Gustavo S. Paiva;William Robson Schwartz;Helio Pedrini;Rosane Minghim,"Faculty of Computer Science, Federal University of Uberlandia-UFU, Uberlandia, Minas Gerais, Brazil;Department of Computer Science, Federal University of Minas Gerais-UFMG, Belo Horizonte, Minas Gerais, Brazil;Institute of Computing, University of Campinas-UNICAMP, Campinas, Sao Paulo, Brazil;Institute of Mathematics and Computer Science, University of Sao Paulo-USP, Sao Carlos, Sao Paulo, Brazil",0.1109/tvcg.2011.212;10.1109/tvcg.2013.207;10.1109/vast.2010.5652398;10.1109/tvcg.2012.277;10.1109/vast.2012.6400492;10.1109/tvcg.2012.258;10.1109/vast.2010.5652443;10.1109/tvcg.2013.212;10.1109/vast.2007.4389002,"Visual image classification,multidimensional point placement,,,,,,,,,,,information visualization",,49,53,1827,,
TVCG,2017,Embedding Spatio-Temporal Information into Maps by Route-Zooming,10.1109/tvcg.2016.2535234,http://dx.doi.org/10.1109/TVCG.2016.2535234,1506,1519,J,"Analysis and exploration of spatio-temporal data such as traffic flow and vehicle trajectories have become important in urban planning and management. In this paper, we present a novel visualization technique called route-zooming that can embed spatio-temporal information into a map seamlessly for occlusion-free visualization of both spatial and temporal data. The proposed technique can broaden a selected route in a map by deforming the overall road network. We formulate the problem of route-zooming as a nonlinear least squares optimization problem by defining an energy function that ensures the route is broadened successfully on demand while the distortion caused to the road network is minimized. The spatio-temporal information can then be embedded into the route to reveal both spatial and temporal patterns without occluding the spatial context information. The route-zooming technique is applied in two instantiations including an interactive metro map for city tourism and illustrative maps to highlight information on the broadened roads to prove its applicability. We demonstrate the usability of our spatio-temporal visualization approach with case studies on real traffic flow data. We also study various design choices in our method, including the encoding of the time direction and choices of temporal display, and conduct a comprehensive user study to validate our embedded visualization design.",Guodao Sun;Ronghua Liang;Huamin Qu;Yingcai Wu,Guodao Sun;Ronghua Liang;Huamin Qu;Yingcai Wu,"Zhejiang University of Technology, Hangzhou, Zhejiang, China;Zhejiang University of Technology, Hangzhou, Zhejiang, China;Hong Kong University of Science and Technology, Hong Kong;State Key Lab of CAD & CG, Zhejiang University, Hangzhou, China",0.1109/tvcg.2011.195;10.1109/tvcg.2011.191;10.1109/tvcg.2009.144;10.1109/vast.2008.4677356;10.1109/tvcg.2014.2346746;10.1109/vast.2009.5332593;10.1109/tvcg.2010.193;10.1109/tvcg.2014.2346449;10.1109/tvcg.2007.70621;10.1109/tvcg.2012.265;10.1109/vast.2011.6102455,"Spatio-temporal visualization,occlusion-free visualization,,,,,,,,,,,least-square optimization",,45,30,1852,,
TVCG,2014,How to Display Group Information on Node-Link Diagrams: An Evaluation,10.1109/tvcg.2014.2315995,http://dx.doi.org/10.1109/TVCG.2014.2315995,1530,1541,J,"We present the results of evaluating four techniques for displaying group or cluster information overlaid on node-link diagrams: node coloring, GMap, BubbleSets, and LineSets. The contributions of the paper are three fold. First, we present quantitative results and statistical analyses of data from an online study in which approximately 800 subjects performed 10 types of group and network tasks in the four evaluated visualizations. Specifically, we show that BubbleSets is the best alternative for tasks involving group membership assessment; that visually encoding group information over basic node-link diagrams incurs an accuracy penalty of about 25 percent in solving network tasks; and that GMap's use of prominent group labels improves memorability. We also show that GMap's visual metaphor can be slightly altered to outperform BubbleSets in group membership assessment. Second, we discuss visual characteristics that can explain the observed quantitative differences in the four visualizations and suggest design recommendations. This discussion is supported by a small scale eye-tracking study and previous results from the visualization literature. Third, we present an easily extensible user study methodology.",Radu Jianu;Adrian Rusu;Yifan Hu 0001;Douglas Taggart,Radu Jianu;Adrian Rusu;Yifan Hu;Douglas Taggart,"School of Computing and Information Sciences, Florida International University, 11200 SW 8th Street, ECS354, Miami, FL;Department of Computer Science, Rowan University, 201 Mullica Hill Road, Glassboro, NJ;AT&T Labs Research, 180 Park Ave., Florham Park, NJ;Department of Computer Science, Rowan University, 201 Mullica Hill Road, Glassboro, NJ",0.1109/tvcg.2010.210;10.1109/tvcg.2012.245;10.1109/tvcg.2010.186;10.1109/tvcg.2012.199;10.1109/tvcg.2008.130;10.1109/tvcg.2012.233;10.1109/infvis.2005.1532126;10.1109/tvcg.2008.117;10.1109/tvcg.2009.122;10.1109/tvcg.2011.186;10.1109/tvcg.2011.82;10.1109/tvcg.2009.141,"Networks,sets,,,,,,,,,,,clustering,,,,,,,,,,,evaluation,,,,user study",,45,46,1458,,
TVCG,2015,Perception-Based Evaluation of Projection Methods for Multidimensional Data Visualization,10.1109/tvcg.2014.2330617,http://dx.doi.org/10.1109/TVCG.2014.2330617,81,94,J,"Similarity-based layouts generated by multidimensional projections or other dimension reduction techniques are commonly used to visualize high-dimensional data. Many projection techniques have been recently proposed addressing different objectives and application domains. Nonetheless, very little is known about the effectiveness of the generated layouts from a user's perspective, how distinct layouts from the same data compare regarding the typical visualization tasks they support, or how domain-specific issues affect the outcome of the techniques. Learning more about projection usage is an important step towards both consolidating their role in high-dimensional data analysis and taking informed decisions when choosing techniques. This work provides a contribution towards this goal. We describe the results of an investigation on the performance of layouts generated by projection techniques as perceived by their users. We conducted a controlled user study to test against the following hypotheses: (1) projection performance is task-dependent; (2) certain projections perform better on certain types of tasks; (3) projection performance depends on the nature of the data; and (4) subjects prefer projections with good segregation capability. We generated layouts of high-dimensional data with five techniques representative of different projection approaches. As application domains we investigated image and document data. We identified eight typical tasks, three of them related to segregation capability of the projection, three related to projection precision, and two related to incurred visual cluttering. Answers to questions were compared for correctness against `ground truth' computed directly from the data. We also looked at subject confidence and task completion times. Statistical analysis of the collected data resulted in Hypotheses 1 and 3 being confirmed, Hypothesis 2 being confirmed partially and Hypotheses 4 could not be confirmed. We discuss our findings in comparison with some numerical measures of projection layout quality. Our results offer interesting insight on the use of projection layouts in data visualization tasks and provide a departing point for further systematic investigations.",Ronak Etemadpour;Robson Motta;Jose Gustavo de Souza Paiva;Rosane Minghim;Maria Cristina Ferreira de Oliveira;Lars Linsen,Ronak Etemadpour;Robson Motta;Jose Gustavo de Souza Paiva;Rosane Minghim;Maria Cristina Ferreira de Oliveira;Lars Linsen,"School of Engineering and Science, Jacobs University, Bremen, Germany;Institute of Mathematical Sciences of São Carlos, University of São Paulo, São Carlos, Brazil;Department of Computer Science, Federal University of Uberlândia, Brazil;Institute of Mathematical Sciences of São Carlos, University of São Paulo, São Carlos, Brazil;Institute of Mathematical Sciences of São Carlos, University of São Paulo, São Carlos, Brazil;School of Engineering and Science, Jacobs University, Bremen, Germany",0.1109/tvcg.2011.229;10.1109/tvcg.2011.212;10.1109/vast.2007.4389002;10.1109/tvcg.2013.153;10.1109/vast.2009.5332628;10.1109/vast.2011.6102437,"Projections,dimension reduction,,,,,,,,,,,multidimensional data,,,,,,,,,,,perception-based evaluation",,43,45,2289,,
TVCG,2015,Learning Visualizations by Analogy: Promoting Visual Literacy through Visualization Morphing,10.1109/tvcg.2015.2413786,http://dx.doi.org/10.1109/TVCG.2015.2413786,1028,1044,J,"We propose the concept of teaching (and learning) unfamiliar visualizations by analogy, that is, demonstrating an unfamiliar visualization method by linking it to another more familiar one, where the in-betweens are designed to bridge the gap of these two visualizations and explain the difference in a gradual manner. As opposed to a textual description, our morphing explains an unfamiliar visualization through purely visual means. We demonstrate our idea by ways of four visualization pair examples: data table and parallel coordinates, scatterplot matrix and hyperbox, linear chart and spiral chart, and hierarchical pie chart and treemap. The analogy is commutative i.e. any member of the pair can be the unfamiliar visualization. A series of studies showed that this new paradigm can be an effective teaching tool. The participants could understand the unfamiliar visualization methods in all of the four pairs either fully or at least significantly better after they observed or interacted with the transitions from the familiar counterpart. The four examples suggest how helpful visualization pairings be identified and they will hopefully inspire other visualization morphings and associated transition strategies to be identified.",Puripant Ruchikachorn;Klaus Mueller 0001,Puripant Ruchikachorn;Klaus Mueller,"Chulalongkorn Business School, Chulalongkorn University, Bangkok, Thailand;Visual Analytics and Imaging Laboratory, Department of Computer Science",0.1109/visual.1991.175790;10.1109/infvis.2001.963273;10.1109/tvcg.2007.70521;10.1109/tvcg.2012.65;10.1109/tvcg.2008.153;10.1109/tvcg.2007.70582;10.1109/tvcg.2010.205;10.1109/tvcg.2007.70539;10.1109/tvcg.2007.70515;10.1109/tvcg.2013.234;10.1109/visual.2004.12;10.1109/tvcg.2012.237;10.1109/tvcg.2011.201;10.1109/tvcg.2012.275;10.1109/tvcg.2008.171,"Animation,Education,interaction,multivariate visualization,,,,,,,,,Information Visualization,,,,,,,,,,,Literacy,,,,Interaction,Multivariate Visualization,Animation,education,information visualization,literacy",,47,50,1923,,
TVCG,2014,Blood Flow Clustering and Applications inVirtual Stenting of Intracranial Aneurysms,10.1109/tvcg.2013.2297914,http://dx.doi.org/10.1109/TVCG.2013.2297914,686,701,J,"Understanding the hemodynamics of blood flow in vascular pathologies such as intracranial aneurysms is essential for both their diagnosis and treatment. Computational fluid dynamics (CFD) simulations of blood flow based on patient-individual data are performed to better understand aneurysm initiation and progression and more recently, for predicting treatment success. In virtual stenting, a flow-diverting mesh tube (stent) is modeled inside the reconstructed vasculature and integrated in the simulation. We focus on steady-state simulation and the resulting complex multiparameter data. The blood flow pattern captured therein is assumed to be related to the success of stenting. It is often visualized by a dense and cluttered set of streamlines.We present a fully automatic approach for reducing visual clutter and exposing characteristic flow structures by clustering streamlines and computing cluster representatives. While individual clustering techniques have been applied before to streamlines in 3D flow fields, we contribute a general quantitative and a domain-specific qualitative evaluation of three state-of-the-art techniques. We show that clustering based on streamline geometry as well as on domain-specific streamline attributes contributes to comparing and evaluating different virtual stenting strategies. With our work, we aim at supporting CFD engineers and interventional neuroradiologists.",Steffen Oeltze;Dirk J. Lehmann;Alexander Kuhn;Gábor Janiga;Holger Theisel;Bernhard Preim,Steffen Oeltze;Dirk J. Lehmann;Alexander Kuhn;Gábor Janiga;Holger Theisel;Bernhard Preim,"Department of Simulation and Graphics, University of Magdeburg, Magdeburg, Germany;Department of Simulation and Graphics, University of Magdeburg, Magdeburg, Germany;Zuse Insitute, Berlin, Germany;Institute of Fluid Dynamics and Thermodynamics, University of Magdeburg, Magdeburg, Germany;Department of Simulation and Graphics, University of Magdeburg, Magdeburg, Germany;Department of Simulation and Graphics, University of Magdeburg, Magdeburg, Germany",0.1109/tvcg.2012.202;10.1109/tvcg.2011.215;10.1109/visual.2005.1532779;10.1109/tvcg.2011.155;10.1109/tvcg.2011.78;10.1109/tvcg.2012.150;10.1109/tvcg.2011.243;10.1109/tvcg.2009.138,"Blood flow,aneurysm,,,,,,,,,,,virtual stenting,,,,,,,,,,,clustering,,,,evaluation",,44,50,966,,
CG&A,2016,Director's Cut: Analysis and Annotation of Soccer Matches,10.1109/mcg.2016.102,http://dx.doi.org/10.1109/MCG.2016.102,50,60,MAG,"For development and alignment of tactics and strategies, professional soccer analysts spend up to three working days manually analyzing and annotating professional soccer matches. In an effort to improve soccer player and match analysis, a visual-interactive and data-analysis support system focuses on key situations by using rule-based filtering and automatically annotating key types of soccer match elements. The authors evaluate the proposed approach by analyzing real-world soccer matches and several expert studies. Quantitative measures show the proposed methods can significantly outperform naive solutions.",Manuel Stein;Halldor Janetzko;Thorsten Breitkreutz;Daniel Seebacher;Tobias Schreck;Michael Grossniklaus;Iain D. Couzin;Daniel A. Keim,Manuel Stein;Halldór Janetzko;Thorsten Breitkreutz;Daniel Seebacher;Tobias Schreck;Michael Grossniklaus;Iain D. Couzin;Daniel A. Keim,University of Konstanz;University of Konstanz;University of Konstanz;University of Konstanz;Graz University of Technology;University of Konstanz;University of Konstanz;University of Konstanz,,"computer graphics,visual analytics,,,,,,,,,,,sport analytics,,,,,,,,,,,high-frequency spatiotemporal data",,43,2,1074,,
TVCG,2018,Keshif: Rapid and Expressive Tabular Data Exploration for Novices,10.1109/tvcg.2017.2723393,http://dx.doi.org/10.1109/TVCG.2017.2723393,2339,2352,J,"General purpose graphical interfaces for data exploration are typically based on manual visualization and interaction specifications. While designing manual specification can be very expressive, it demands high efforts to make effective decisions, therefore reducing exploratory speed. Instead, principled automated designs can increase exploratory speed, decrease learning efforts, help avoid ineffective decisions, and therefore better support data analytics novices. Towards these goals, we present Keshif, a new systematic design for tabular data exploration. To summarize a given dataset, Keshif aggregates records by value within attribute summaries, and visualizes aggregate characteristics using a consistent design based on data types. To reveal data distribution details, Keshif features three complementary linked selections: highlighting, filtering, and comparison. Keshif further increases expressiveness through aggregate metrics, absolute/part-of scale modes, calculated attributes, and saved selections, all working in synchrony. Its automated design approach also simplifies authoring of dashboards composed of summaries and individual records from raw data using fluid interaction. We show examples selected from 160+ datasets from diverse domains. Our study with novices shows that after exploring raw data for 15 minutes, our participants reached close to 30 data insights on average, comparable to other studies with skilled users using more complex tools.",Mehmet Adil Yalçin;Niklas Elmqvist;Benjamin B. Bederson,Mehmet Adil Yalçın;Niklas Elmqvist;Benjamin B. Bederson,"University of Maryland, College Park, MD;University of Maryland, College Park, MD;University of Maryland, College Park, MD",0.1109/tvcg.2015.2467051;10.1109/infvis.2000.885086;10.1109/tvcg.2015.2467191;10.1109/infvis.2004.12;10.1109/tvcg.2007.70577;10.1109/tvcg.2010.164;10.1109/tvcg.2016.2615308;10.1109/tvcg.2015.2467555;10.1109/tvcg.2014.2346452;10.1109/tvcg.2011.185;10.1109/tvcg.2015.2466971;10.1109/tvcg.2008.175;10.1109/tvcg.2015.2467757;10.1109/tvcg.2009.180;10.1109/tvcg.2014.2346747;10.1109/tvcg.2007.70594;10.1109/tvcg.2014.2346291,"Interactive data exploration and discovery,data visualization,,,,,,,,,,,data exploration,,,,,,,,,,,graphical user interfaces,,,,interaction,design,user-centered design",,40,41,1201,,
TVCG,2018,A Perception-Driven Approach to Supervised Dimensionality Reduction for Visualization,10.1109/tvcg.2017.2701829,http://dx.doi.org/10.1109/TVCG.2017.2701829,1828,1840,J,"Dimensionality reduction (DR) is a common strategy for visual analysis of labeled high-dimensional data. Low-dimensional representations of the data help, for instance, to explore the class separability and the spatial distribution of the data. Widely-used unsupervised DR methods like PCA do not aim to maximize the class separation, while supervised DR methods like LDA often assume certain spatial distributions and do not take perceptual capabilities of humans into account. These issues make them ineffective for complicated class structures. Towards filling this gap, we present a perception-driven linear dimensionality reduction approach that maximizes the perceived class separation in projections. Our approach builds on recent developments in perception-based separation measures that have achieved good results in imitating human perception. We extend these measures to be density-aware and incorporate them into a customized simulated annealing algorithm, which can rapidly generate a near optimal DR projection. We demonstrate the effectiveness of our approach by comparing it to state-of-the-art DR methods on 93 datasets, using both quantitative measure and human judgments. We also provide case studies with class-imbalanced and unlabeled data.",Yunhai Wang;Kang Feng;Xiaowei Chu;Jian Zhang 0070;Chi-Wing Fu;Michael Sedlmair;Xiaohui Yu 0001;Baoquan Chen,Yunhai Wang;Kang Feng;Xiaowei Chu;Jian Zhang;Chi-Wing Fu;Michael Sedlmair;Xiaohui Yu;Baoquan Chen,"Shandong University, Jinan City, China;Shandong University, Jinan City, China;Shandong University, Jinan City, China;CNIC, CAS, Beijing, China;Chinese University of Hong Kong, Sha Tin, Hong Kong;University of Vienna, Wien, Austria;Shandong University, Jinan City, China;Shandong University, Jinan City, China",0.1109/tvcg.2014.2330617;10.1109/tvcg.2013.153;10.1109/vast.2009.5332628;10.1109/vast.2010.5652443;10.1109/vast.2009.5332629;10.1109/vast.2012.6400490;10.1109/tvcg.2011.229;10.1109/tvcg.2016.2598495;10.1109/tvcg.2012.260,"Dimensionality reduction,supervised,,,,,,,,,,,visual class separation,,,,,,,,,,,high-dimensional data",,42,49,1594,,
TVCG,2018,Data Flow Analysis and Visualization for Spatiotemporal Statistical Data without Trajectory Information,10.1109/tvcg.2017.2666146,http://dx.doi.org/10.1109/TVCG.2017.2666146,1287,1300,J,"Geographic visualization research has focused on a variety of techniques to represent and explore spatiotemporal data. The goal of those techniques is to enable users to explore events and interactions over space and time in order to facilitate the discovery of patterns, anomalies and relationships within the data. However, it is difficult to extract and visualize data flow patterns over time for non-directional statistical data without trajectory information. In this work, we develop a novel flow analysis technique to extract, represent, and analyze flow maps of non-directional spatiotemporal data unaccompanied by trajectory information. We estimate a continuous distribution of these events over space and time, and extract flow fields for spatial and temporal changes utilizing a gravity model. Then, we visualize the spatiotemporal patterns in the data by employing flow visualization techniques. The user is presented with temporal trends of geo-referenced discrete events on a map. As such, overall spatiotemporal data flow patterns help users analyze geo-referenced temporal events, such as disease outbreaks, crime patterns, etc. To validate our model, we discard the trajectory information in an origin-destination dataset and apply our technique to the data and compare the derived trajectories and the original. Finally, we present spatiotemporal trend analysis for statistical datasets including twitter data, maritime search and rescue events, and syndromic surveillance.",Seokyeon Kim;Seongmin Jeong;Insoo Woo;Yun Jang;Ross Maciejewski;David S. Ebert,Seokyeon Kim;Seongmin Jeong;Insoo Woo;Yun Jang;Ross Maciejewski;David S. Ebert,"Sejong University, Seoul, South Korea;Sejong University, Seoul, South Korea;Intel Folsom, Folsom, CA;Sejong University, Seoul, South Korea;Arizona State University, Tempe, AZ;Purdue University, West Lafayette, IN",0.1109/tvcg.2011.110;10.1109/vast.2011.6102460;10.1109/tvcg.2009.126;10.1109/tvcg.2009.143;10.1109/tvcg.2014.2346271;10.1109/tvcg.2011.202;10.1109/vast.2007.4388992,"Spatiotemporal data visualization,kernel density estimation,,,,,,,,,,,flow map,,,,,,,,,,,gravity model",,40,53,3167,,
TVCG,2016,The Elicitation Interview Technique: Capturing People's Experiences of Data Representations,10.1109/tvcg.2015.2511718,http://dx.doi.org/10.1109/TVCG.2015.2511718,2579,2593,J,"Information visualization has become a popular tool to facilitate sense-making, discovery and communication in a large range of professional and casual contexts. However, evaluating visualizations is still a challenge. In particular, we lack techniques to help understand how visualizations are experienced by people. In this paper we discuss the potential of the Elicitation Interview technique to be applied in the context of visualization. The Elicitation Interview is a method for gathering detailed and precise accounts of human experience. We argue that it can be applied to help understand how people experience and interpret visualizations as part of exploration and data analysis processes. We describe the key characteristics of this interview technique and present a study we conducted to exemplify how it can be applied to evaluate data representations. Our study illustrates the types of insights this technique can bring to the fore, for example, evidence for deep interpretation of visual representations and the formation of interpretations and stories beyond the represented data. We discuss general visualization evaluation scenarios where the Elicitation Interview technique may be beneficial and specify what needs to be considered when applying this technique in a visualization context specifically.",Trevor Hogan;Uta Hinrichs;Eva Hornecker,Trevor Hogan;Uta Hinrichs;Eva Hornecker,"Crawford College of Art and Design, Cork Institute of Technology, Cork, Ireland;SACHI Group, School of Computer Science, University of St Andrews, Fife, United Kingdom;Faculty of Media, Bauhaus-Universität Weimar, Weimar, Germany",0.1109/tvcg.2007.70541;10.1109/tvcg.2009.111;10.1109/tvcg.2012.275;10.1109/tvcg.2015.2467452;10.1109/tvcg.2011.279;10.1109/tvcg.2010.179;10.1109/tvcg.2015.2467831;10.1109/tvcg.2008.127;10.1109/tvcg.2012.272;10.1109/tvcg.2014.2359887;10.1109/tvcg.2013.126;10.1109/tvcg.2007.70515,"Qualitative evaluation,psychophenomenology,,,,,,,,,,,phenomenology,,,,,,,,,,,elicitation interview technique,,,,thematic analysis",,46,52,3129,,
TVCG,2016,Towards An Understanding of Mobile Touch Navigation in a Stereoscopic Viewing Environment for 3D Data Exploration,10.1109/tvcg.2015.2440233,http://dx.doi.org/10.1109/TVCG.2015.2440233,1616,1629,J,"We discuss touch-based navigation of 3D visualizations in a combined monoscopic and stereoscopic viewing environment. We identify a set of interaction modes, and a workflow that helps users transition between these modes to improve their interaction experience. In our discussion we analyze, in particular, the control-display space mapping between the different reference frames of the stereoscopic and monoscopic displays. We show how this mapping supports interactive data exploration, but may also lead to conflicts between the stereoscopic and monoscopic views due to users' movement in space; we resolve these problems through synchronization. To support our discussion, we present results from an exploratory observational evaluation with domain experts in fluid mechanics and structural biology. These experts explored domain-specific datasets using variations of a system that embodies the interaction modes and workflows; we report on their interactions and qualitative feedback on the system and its workflow.",David López;Lora Oehlberg;Candemir Doger;Tobias Isenberg 0001,David López;Lora Oehlberg;Candemir Doger;Tobias Isenberg,"University of Antioquia, Antioquia, Colombia;Department of Computer Science, University of Calgary, Calgary, AB, Canada;Sabancı University, Istanbul, Turkey;Inria, France",0.1109/tvcg.2013.126;10.1109/tvcg.2011.279;10.1109/tvcg.2012.292;10.1109/tvcg.2011.224;10.1109/tvcg.2012.217;10.1109/tvcg.2010.157,"Visualization of 3D data,human-computer interaction,observational study,Visualization of 3D data,human-computer interaction,expert interaction,direct-touch input,mobile displays,stereoscopic environments,VR,AR,conceptual model of interaction,expert interaction,interaction reference frame mapping,observational study,,,,,,,,,direct-touch input,,,,mobile displays,stereoscopic environments,VR,AR,conceptual model of interaction,interaction reference frame mapping",,37,80,963,,
TVCG,2015,Representing Uncertainty in Graph Edges: An Evaluation of Paired Visual Variables,10.1109/tvcg.2015.2424872,http://dx.doi.org/10.1109/TVCG.2015.2424872,1173,1186,J,"When visualizing data with uncertainty, a common approach is to treat uncertainty as an additional dimension and encode it using a visual variable. The effectiveness of this approach depends on how the visual variables chosen for representing uncertainty and other attributes interact to influence the user's perception of each variable. We report a user study on the perception of graph edge attributes when uncertainty associated with each edge and the main edge attribute are visualized simultaneously using two separate visual variables. The study covers four visual variables that are commonly used for visualizing uncertainty on line graphical primitives: lightness, grain, fuzziness, and transparency. We select width, hue, and saturation for visualizing the main edge attribute and hypothesize that we can observe interference between the visual variable chosen to encode the main edge attribute and that to encode uncertainty, as suggested by the concept of dimensional integrality. Grouping the seven visual variables as color-based, focus-based, or geometry-based, we further hypothesize that the degree of interference is affected by the groups to which the two visual variables belong. We consider two further factors in the study: discriminability level for each visual variable as a factor intrinsic to the visual variables and graph-task type (visual search versus comparison) as a factor extrinsic to the visual variables. Our results show that the effectiveness of a visual variable in depicting uncertainty is strongly mediated by all the factors examined here. Focus-based visual variables (fuzziness, grain, and transparency) are robust to the choice of visual variables for encoding the main edge attribute, though fuzziness has stronger negative impact on the perception of width and transparency has stronger negative impact on the perception of hue than the other uncertainty visual variables. We found that interference between hue and lightness is much greater than that between saturation and lightness, though all three are color-based visual variables. We also found a compound relationship between discriminability level and the degree of dimensional integrality. We discuss the generalizability and limitation of the results and conclude with design considerations for visualizing graph uncertainty derived from these results, including recommended choices of visual variables when the relative importance of data attributes and graph tasks is known.",Hua Guo;Jeff Huang 0002;David H. Laidlaw,Hua Guo;Jeff Huang;David H. Laidlaw,"Department of Computer Science, Brown University, Providence, RI;Department of Computer Science, Brown University, Providence, RI;Department of Computer Science, Brown University, Providence, RI",0.1109/tvcg.2012.189;10.1109/tvcg.2011.185;10.1109/tvcg.2012.251;10.1109/tvcg.2012.279;10.1109/tvcg.2009.114;10.1109/tvcg.2012.220;10.1109/tvcg.2011.197,"Visual variable,perception,,,,,,,,,,,uncertainty visualization,,,,,,,,,,,graph visualization,,,,Visual variable,perception,uncertainty visualization,graph visualization",,40,40,1326,,
TVCG,2018,Line Graph or Scatter Plot? Automatic Selection of Methods for Visualizing Trends in Time Series,10.1109/tvcg.2017.2653106,http://dx.doi.org/10.1109/TVCG.2017.2653106,1141,1154,J,"Line graphs are usually considered to be the best choice for visualizing time series data, whereas sometimes also scatter plots are used for showing main trends. So far there are no guidelines that indicate which of these visualization methods better display trends in time series for a given canvas. Assuming that the main information in a time series is its overall trend, we propose an algorithm that automatically picks the visualization method that reveals this trend best. This is achieved by measuring the visual consistency between the trend curve represented by a LOESS fit and the trend described by a scatter plot or a line graph. To measure the consistency between our algorithm and user choices, we performed an empirical study with a series of controlled experiments that show a large correspondence. In a factor analysis we furthermore demonstrate that various visual and data factors have effects on the preference for a certain type of visualization.",Yunhai Wang;Fubo Han;Lifeng Zhu;Oliver Deussen;Baoquan Chen,Yunhai Wang;Fubo Han;Lifeng Zhu;Oliver Deussen;Baoquan Chen,"Shandong University, Jinan, China;Shandong University, Jinan, China;Southeast University, Nanjing, China;SIAT Shenzhen, University of Konstanz, Konstanz, Germany;Shandong University, Jinan, China",0.1109/tvcg.2010.176;10.1109/tvcg.2007.70583;10.1109/tvcg.2012.196;10.1109/tvcg.2013.65;10.1109/tvcg.2006.163;10.1109/tvcg.2014.2346320;10.1109/tvcg.2011.167;10.1109/tvcg.2015.2467751;10.1109/tvcg.2011.195;10.1109/tvcg.2008.166;10.1109/tvcg.2010.162;10.1109/infvis.1999.801851;10.1109/infvis.2001.963273;10.1109/tvcg.2010.193;10.1109/tvcg.2013.120;10.1109/tvcg.2013.187;10.1109/tvcg.2014.2346978,"Line graph,scatter plot,,,,,,,,,,,time series,,,,,,,,,,,trend",,35,49,3611,,
TVCG,2019,Using Dashboard Networks to Visualize Multiple Patient Histories: A Design Study on Post-Operative Prostate Cancer,10.1109/tvcg.2018.2803829,http://dx.doi.org/10.1109/TVCG.2018.2803829,1615,1628,J,"In this design study, we present a visualization technique that segments patients' histories instead of treating them as raw event sequences, aggregates the segments using criteria such as the whole history or treatment combinations, and then visualizes the aggregated segments as static dashboards that are arranged in a dashboard network to show longitudinal changes. The static dashboards were developed in nine iterations, to show 15 important attributes from the patients' histories. The final design was evaluated with five non-experts, five visualization experts and four medical experts, who successfully used it to gain an overview of a 2,000 patient dataset, and to make observations about longitudinal changes and differences between two cohorts. The research represents a step-change in the detail of large-scale data that may be successfully visualized using dashboards, and provides guidance about how the approach may be generalized.",Jürgen Bernard;David Sessler;Jörn Kohlhammer;Roy A. Ruddle,Jürgen Bernard;David Sessler;Jörn Kohlhammer;Roy A. Ruddle,"Fraunhofer IGD, Darmstadt, Germany;TU Darmstadt, Darmstadt, Germany;Fraunhofer IGD, Darmstadt, Germany;University of Leeds, Leeds, United Kingdom",0.1109/tvcg.2009.111;10.1109/tvcg.2011.188;10.1109/tvcg.2016.2598586;10.1109/tvcg.2012.271;10.1109/tvcg.2014.2346279;10.1109/tvcg.2015.2467325;10.1109/tvcg.2015.2467622;10.1109/visual.1990.146402;10.1109/vast.2016.7883512;10.1109/visual.1997.663916;10.1109/tvcg.2012.213;10.1109/tvcg.2009.187;10.1109/tvcg.2014.2346682;10.1109/tvcg.2016.2539960;10.1109/tvcg.2013.125,"Information visualization,visual analytics,dashboard network,,,,,,,,,,multivariate data visualization,,,,,,,,,,,electronic health care records,,,,medical data analysis,prostate cancer disease,design study,user study,evaluation,static dashboard",,36,49,1640,,
TVCG,2016,The Connected Scatterplot for Presenting Paired Time Series,10.1109/tvcg.2015.2502587,http://dx.doi.org/10.1109/TVCG.2015.2502587,2174,2186,J,"The connected scatterplot visualizes two related time series in a scatterplot and connects the points with a line in temporal sequence. News media are increasingly using this technique to present data under the intuition that it is understandable and engaging. To explore these intuitions, we (1) describe how paired time series relationships appear in a connected scatterplot, (2) qualitatively evaluate how well people understand trends depicted in this format, (3) quantitatively measure the types and frequency of misinter pretations, and (4) empirically evaluate whether viewers will preferentially view graphs in this format over the more traditional format. The results suggest that low-complexity connected scatterplots can be understood with little explanation, and that viewers are biased towards inspecting connected scatterplots over the more traditional format. We also describe misinterpretations of connected scatterplots and propose further research into mitigating these mistakes for viewers unfamiliar with the technique.",Steve Haroz;Robert Kosara;Steven L. Franconeri,Steve Haroz;Robert Kosara;Steven L. Franconeri,"Psychology Department, Northwestern University, Evanston, IL;Tableau Research, Seattle, WA;Psychology Department, Northwestern University, Evanston, IL",0.1109/tvcg.2011.175;10.1109/tvcg.2008.171;10.1109/tvcg.2008.125;10.1109/tvcg.2015.2467851;10.1109/tvcg.2010.179;10.1109/tvcg.2015.2468078;10.1109/tvcg.2014.2346250;10.1109/tvcg.2012.233,,,36,51,1238,,
TVCG,2015,Bridging Theory with Practice: An Exploratory Study of Visualization Use and Design for Climate Model Comparison,10.1109/tvcg.2015.2413774,http://dx.doi.org/10.1109/TVCG.2015.2413774,996,1014,J,"Evaluation methodologies in visualization have mostly focused on how well the tools and techniques cater to the analytical needs of the user. While this is important in determining the effectiveness of the tools and advancing the state-of-the-art in visualization research, a key area that has mostly been overlooked is how well established visualization theories and principles are instantiated in practice. This is especially relevant when domain experts, and not visualization researchers, design visualizations for analysis of their data or for broader dissemination of scientific knowledge. There is very little research on exploring the synergistic capabilities of cross-domain collaboration between domain experts and visualization researchers. To fill this gap, in this paper we describe the results of an exploratory study of climate data visualizations conducted in tight collaboration with a pool of climate scientists. The study analyzes a large set of static climate data visualizations for identifying their shortcomings in terms of visualization design. The outcome of the study is a classification scheme that categorizes the design problems in the form of a descriptive taxonomy. The taxonomy is a first attempt for systematically categorizing the types, causes, and consequences of design problems in visualizations created by domain experts. We demonstrate the use of the taxonomy for a number of purposes, such as, improving the existing climate data visualizations, reflecting on the impact of the problems for enabling domain experts in designing better visualizations, and also learning about the gaps and opportunities for future visualization research. We demonstrate the applicability of our taxonomy through a number of examples and discuss the lessons learnt and implications of our findings.",Aritra Dasgupta;Jorge Poco;Yaxing Wei;Robert B. Cook;Enrico Bertini;Cláudio T. Silva,Aritra Dasgupta;Jorge Poco;Yaxing Wei;Robert Cook;Enrico Bertini;Cláudio T. Silva,"DataONE;Department of Computer Science and Engineering, New York University, Brooklyn, NY;Environmental Sciences Division, Oak Ridge National Laboratory, Knoxville, TN;Environmental Sciences Division, Oak Ridge National Laboratory, Knoxville, TN;Department of Computer Science and Engineering, New York University, Brooklyn, NY;Department of Computer Science and Engineering, New York University, Brooklyn, NY",0.1109/infvis.1997.636792;10.1109/tvcg.2013.119;10.1109/tvcg.2012.275;10.1109/infvis.2000.885092;10.1109/vast.2006.261428;10.1109/tvcg.2011.251;10.1109/tvcg.2010.164;10.1109/tvcg.2011.279;10.1109/tvcg.2011.192,"visualization,design principles,,,,,,,,,,,climate model,,,,,,,,,,,taxonomy,,,,Visualization,design principles,climate model,taxonomy",,34,55,1496,,
CG&A,2016,StatCast Dashboard: Exploration of Spatiotemporal Baseball Data,10.1109/mcg.2016.101,http://dx.doi.org/10.1109/MCG.2016.101,28,37,MAG,"This article presents a visualization and analytics infrastructure to help query and facilitate the analysis of this new tracking data. The goal is to go beyond descriptive statistics of individual plays, allowing analysts to study diverse collections of games and game events. The StatCast Dashboard visual interface helps users query, filter, and analyze the tracking data gathered by the Major League Baseball (MLB) StatCast spatiotemporal data-tracking system. The proposed system enables the exploration of the data using a simple querying interface and a set of flexible interactive visualization tools.",Marcos Lage;Jorge Piazentin Ono;Daniel Cervone;Justin Chiang;Carlos A. Dietrich;Cláudio T. Silva,Marcos Lage;Jorge Piazentin Ono;Daniel Cervone;Justin Chiang;Carlos Dietrich;Claudio T. Silva,Universidade Federal Fluminense;New York University;New York University;Collegiate School;New York University;New York University,0.1109/vast.2014.7042478,"computer graphics,sports analytics,,,,,,,,,,,data-tracking system,,,,,,,,,,,information visualization,,,,event data,MLB,StatCast",,37,3,2251,,
CG&A,2016,BKViz: A Basketball Visual Analysis Tool,10.1109/mcg.2016.124,http://dx.doi.org/10.1109/MCG.2016.124,58,68,MAG,"The amount of data available in the sports field is difficult for coaches, analysts, and players to comprehend using classic analytics methods. Thus, new methods are necessary to help users break down that information and analyze it at a deeper level. The BKViz visual analytics system focuses on individual basketball games using classic and novel methods to reveal how players perform together and as individuals. The information is presented in interactive visualizations that allow immediate user feedback.",Antonio G. Losada;Roberto Therón;Alejandro Benito,Antonio G. Losada;Roberto Therón;Alejandro Benito,University of Salamanca;University of Salamanca;University of Salamanca,0.1109/tvcg.2013.192;10.1109/tvcg.2012.263,"computer graphics,data visualization,,,,,,,,,,,sport analytics,,,,,,,,,,,visual analytics,,,,interactive visualizations",,38,14,1330,,
TVCG,2015,ThemeDelta: Dynamic Segmentations over Temporal Topic Models,10.1109/tvcg.2014.2388208,http://dx.doi.org/10.1109/TVCG.2014.2388208,672,685,J,"We present ThemeDelta, a visual analytics system for extracting and visualizing temporal trends, clustering, and reorganization in time-indexed textual datasets. ThemeDelta is supported by a dynamic temporal segmentation algorithm that integrates with topic modeling algorithms to identify change points where significant shifts in topics occur. This algorithm detects not only the clustering and associations of keywords in a time period, but also their convergence into topics (groups of keywords) that may later diverge into new groups. The visual representation of ThemeDelta uses sinuous, variable-width lines to show this evolution on a timeline, utilizing color for categories, and line width for keyword strength. We demonstrate how interaction with ThemeDelta helps capture the rise and fall of topics by analyzing archives of historical newspapers, of U.S. presidential campaign speeches, and of social messages collected through iNeighbors, a web-based social website. ThemeDelta is evaluated using a qualitative expert user study involving three researchers from rhetoric and history using the historical newspapers corpus.",Samah Gad;Waqas Javed;Sohaib Ghani;Niklas Elmqvist;E. Thomas Ewing;Keith N. Hampton;Naren Ramakrishnan,Samah Gad;Waqas Javed;Sohaib Ghani;Niklas Elmqvist;Tom Ewing;Keith N. Hampton;Naren Ramakrishnan,"Virginia Tech, Blacksburg, VA, USA;General Electric, San Ramon, USA;KACST GIS Technology Innovation Center, Umm Al-Qura University, Makkah, Saudi Arabia;University of Maryland, College Park, MD, USA;Virginia Tech, Blacksburg, VA, USA;Rutgers University, New Brunswick, NJ, USA;Virginia Tech, Blacksburg, VA, USA",0.1109/tvcg.2011.239;10.1109/tvcg.2008.166;10.1109/vast.2007.4389005;10.1109/vast.2009.5333443;10.1109/vast.2011.6102461;10.1109/tvcg.2009.171;10.1109/tvcg.2010.175;10.1109/tvcg.2009.165;10.1109/infvis.1995.528686;10.1109/tvcg.2012.89;10.1109/tvcg.2013.196;10.1109/tvcg.2014.2346481;10.1109/infvis.2003.1249025;10.1109/tvcg.2012.212,"Language models,time-series segmentation,,,,,,,,,,,text analytics,,,,,,,,,,,visual representations,,,,Language models,time-series segmentation,text analytics,visual representations",,35,49,1265,,
TVCG,2016,An Enhanced Visualization Process Model for Incremental Visualization,10.1109/tvcg.2015.2462356,http://dx.doi.org/10.1109/TVCG.2015.2462356,1830,1842,J,"With today's technical possibilities, a stable visualization scenario can no longer be assumed as a matter of course, as underlying data and targeted display setup are much more in flux than in traditional scenarios. Incremental visualization approaches are a means to address this challenge, as they permit the user to interact with, steer, and change the visualization at intermediate time points and not just after it has been completed. In this paper, we put forward a model for incremental visualizations that is based on the established Data State Reference Model, but extends it in ways to also represent partitioned data and visualization operators to facilitate intermediate visualization updates. In combination, partitioned data and operators can be used independently and in combination to strike tailored compromises between output quality, shown data quantity, and responsiveness-i.e., frame rates. We showcase the new expressive power of this model by discussing the opportunities and challenges of incremental visualization in general and its usage in a real world scenario in particular.",Hans-Jörg Schulz;Marco Angelini;Giuseppe Santucci;Heidrun Schumann,Hans-Jörg Schulz;Marco Angelini;Giuseppe Santucci;Heidrun Schumann,"Fraunhofer IGD Rostock, Rostock, Germany;Sapienza University of Rome, Italy;Sapienza University of Rome, Italy;University of Rostock, Germany",0.1109/tvcg.2014.2346578;10.1109/visual.1994.346305;10.1109/tvcg.2012.133;10.1109/visual.1993.398860;10.1109/tvcg.2014.2346319;10.1109/tvcg.2009.110;10.1109/infvis.2000.885092;10.1109/tvcg.2014.2346574,"Visualization pipeline,data state reference model,,,,,,,,,,,progressive visualization,,,,,,,,,,,proactive visualization,,,,Visualization pipeline,data state reference model,progressive visualization,proactive visualization",,31,42,1797,,
TVCG,2016,CUBu: Universal Real-Time Bundling for Large Graphs,10.1109/tvcg.2016.2515611,http://dx.doi.org/10.1109/TVCG.2016.2515611,2550,2563,J,"Visualizing very large graphs by edge bundling is a promising method, yet subject to several challenges: speed, clutter, level-of-detail, and parameter control. We present CUBu, a framework that addresses the above problems in an integrated way. Fully GPU-based, CUBu bundles graphs of up to a million edges at interactive framerates, being over 50 times faster than comparable state-of-the-art methods, and has a simple and intuitive control of bundling parameters. CUBu extends and unifies existing bundling techniques, offering ways to control bundle shapes, separate bundles by edge direction, and shade bundles to create a level-of-detail visualization that shows both the graph core structure and its details. We demonstrate CUBu on several large graphs extracted from real-life application domains.",Matthew van der Zwan;Valeriu Codreanu;Alexandru C. Telea,Matthew van der Zwan;Valeriu Codreanu;Alexandru Telea,"University of Groningen, The Netherlands;SURFsara, Amsterdam, The Netherlands;University of Groningen, The Netherlands",0.1109/tvcg.2010.207;10.1109/infvis.2003.1249011;10.1109/tvcg.2011.223;10.1109/tvcg.2011.220;10.1109/tvcg.2009.145;10.1109/tvcg.2012.238;10.1109/tvcg.2007.70535;10.1109/tvcg.2011.233;10.1109/tvcg.2006.147;10.1109/infvis.2004.43;10.1109/tvcg.2008.135;10.1109/tvcg.2011.181;10.1109/tvcg.2011.190,"Computing methodologies: computer graphics-picture/image generation,Computing methodologies: Computer graphics-methodology and techniques",,30,54,762,,
TVCG,2018,RCLens: Interactive Rare Category Exploration and Identification,10.1109/tvcg.2017.2711030,http://dx.doi.org/10.1109/TVCG.2017.2711030,2223,2237,J,"Rare category identification is an important task in many application domains, ranging from network security, to financial fraud detection, to personalized medicine. These are all applications which require the discovery and characterization of sets of rare but structurally-similar data entities which are obscured within a larger but structurally different dataset. This paper introduces RCLens, a visual analytics system designed to support user-guided rare category exploration and identification. RCLens adopts a novel active learning-based algorithm to iteratively identify more accurate rare categories in response to user-provided feedback. The algorithm is tightly integrated with an interactive visualization-based interface which supports a novel and effective workflow for rare category identification. This paper (1) defines RCLens’ underlying active-learning algorithm; (2) describes the visualization and interaction designs, including a discussion of how the designs support user-guided rare category identification; and (3) presents results from an evaluation demonstrating RCLens’ ability to support the rare category identification process.",Hanfei Lin;Siyuan Gao;David Gotz;Fan Du;Jingrui He;Nan Cao 0001,Hanfei Lin;Siyuan Gao;David Gotz;Fan Du;Jingrui He;Nan Cao,"Tongji University, Shanghai, Shanghai, CN;Tongji University, Shanghai, Shanghai, CN;University of North Carolina at Chapel Hill, Chapel Hill, NC, US;University of Maryland at College Park, College Park, MD, US;Arizona State University, Tempe, AZ, US;Tongji University, Shanghai, Shanghai, CN",0.1109/tvcg.2015.2467196;10.1109/tvcg.2014.2346922,"Visual analytics,information visualization,,,,,,,,,,,rare category detection,,,,,,,,,,,machine learning",,28,39,972,,
TVCG,2019,KAVAGait: Knowledge-Assisted Visual Analytics for Clinical Gait Analysis,10.1109/tvcg.2017.2785271,http://dx.doi.org/10.1109/TVCG.2017.2785271,1528,1542,J,"In 2014, more than 10 million people in the US were affected by an ambulatory disability. Thus, gait rehabilitation is a crucial part of health care systems. The quantification of human locomotion enables clinicians to describe and analyze a patient's gait performance in detail and allows them to base clinical decisions on objective data. These assessments generate a vast amount of complex data which need to be interpreted in a short time period. We conducted a design study in cooperation with gait analysis experts to develop a novel Knowledge-Assisted Visual Analytics solution for clinical Gait analysis (KAVAGait). KAVAGait allows the clinician to store and inspect complex data derived during clinical gait analysis. The system incorporates innovative and interactive visual interface concepts, which were developed based on the needs of clinicians. Additionally, an explicit knowledge store (EKS) allows externalization and storage of implicit knowledge from clinicians. It makes this information available for others, supporting the process of data inspection and clinical decision making. We validated our system by conducting expert reviews, a user study, and a case study. Results suggest that KAVAGait is able to support a clinician during clinical practice by visualizing complex gait data and providing knowledge of other clinicians.",Markus Wagner 0008;Djordje Slijepcevic;Brian Horsak;Alexander Rind;Matthias Zeppelzauer;Wolfgang Aigner,Markus Wagner;Djordje Slijepcevic;Brian Horsak;Alexander Rind;Matthias Zeppelzauer;Wolfgang Aigner,"TU Wien, Wien, Austria;TU Wien, Wien, Austria;St. Pölten University of Applied Sciences, St. Pölten, Austria;TU Wien, Wien, Austria;TU Wien, Wien, Austria;TU Wien, Wien, Austria",0.1109/tvcg.2015.2502587;10.1109/tvcg.2016.2598544;10.1109/tvcg.2017.2745118;10.1109/tvcg.2016.2598588;10.1109/tvcg.2010.162;10.1109/tvcg.2012.213;10.1109/tvcg.2009.111;10.1109/tvcg.2013.192;10.1109/vast.2014.7042477;10.1109/tvcg.2017.2745181;10.1109/mcg.2015.25;10.1109/tvcg.2013.178;10.1109/tvcg.2015.2468292,"Design study,interface design,,,,,,,,,,,knowledge generation,,,,,,,,,,,knowledge-assisted,,,,visualization,visual analytics,gait analysis",,28,65,2526,,
TVCG,2018,Evaluating Cartogram Effectiveness,10.1109/tvcg.2016.2642109,http://dx.doi.org/10.1109/TVCG.2016.2642109,1077,1090,J,"Cartograms are maps in which areas of geographic regions, such as countries and states, appear in proportion to some variable of interest, such as population or income. Cartograms are popular visualizations for geo-referenced data that have been used for over a century to illustrate patterns and trends in the world around us. Despite the popularity of cartograms, and the large number of cartogram types, there are few studies evaluating the effectiveness of cartograms in conveying information. Based on a recent task taxonomy for cartograms, we evaluate four major types of cartograms: contiguous, non-contiguous, rectangular, and Dorling cartograms. We first evaluate the effectiveness of these cartogram types by quantitative performance analysis (time and error). Second, we collect qualitative data with an attitude study and by analyzing subjective preferences. Third, we compare the quantitative and qualitative results with the results of a metrics-based cartogram evaluation. Fourth, we analyze the results of our study in the context of cartography, geography, visual perception, and demography. Finally, we consider implications for design and possible improvements.",Sabrina Nusrat;Md. Jawaherul Alam;Stephen G. Kobourov,Sabrina Nusrat;Md. Jawaherul Alam;Stephen Kobourov,"University of Arizona, Tucson, AZ;University of California, Irvine, CA;University of Arizona, Tucson, AZ",0.1109/tvcg.2013.130;10.1109/infvis.2004.57;10.1109/visual.1998.745303,"Cartograms,geo-visualization,,,,,,,,,,,subjective evaluation",,28,50,1221,,
TVCG,2015,Interpolation-Based Pathline Tracing in Particle-Based Flow Visualization,10.1109/tvcg.2014.2325043,http://dx.doi.org/10.1109/TVCG.2014.2325043,68,80,J,"Particle tracing in time-varying flow fields is traditionally performed by numerical integration of the underlying vector field. This procedure can become computationally expensive, especially in scattered, particle-based flow fields, which complicate interpolation due to the lack of an explicit neighborhood structure. If such a particle-based flow field allows for the identification of consecutive particle positions, an alternative approach to particle tracing can be employed: we substitute repeated numerical integration of vector data by geometric interpolation in the highly dynamic particle system as defined by the particle-based simulation. To allow for efficient and accurate location and interpolation of changing particle neighborhoods, we develop a modified k-d tree representation that is capable of creating a dynamic partitioning of even highly compressible data sets with strongly varying particle densities. With this representation we are able to efficiently perform pathline computation by identifying, tracking, and updating an enclosing, dynamic particle neighborhood as particles move overtime. We investigate and evaluate the complexity, accuracy, and robustness of this interpolation-based alternative approach to trajectory generation in compressible and incompressible particle systems generated by simulation techniques such as Smoothed Particle Hydrodynamics (SPH).",Jennifer Chandler;Harald Obermaier;Kenneth I. Joy,Jennifer Chandler;Harald Obermaier;Kenneth I. Joy,"Institute for Data Analysis and Visualization at the University of California, Davis;Institute for Data Analysis and Visualization at the University of California, Davis;Institute for Data Analysis and Visualization at the University of California, Davis",0.1109/tvcg.2009.142;10.1109/tvcg.2010.148;10.1109/tvcg.2009.173;10.1109/tvcg.2009.154;10.1109/tvcg.2008.133;10.1109/tvcg.2009.190;10.1109/tvcg.2010.227;10.1109/tvcg.2010.156,"Pathlines,particle tracing,,,,,,,,,,,SPH,,,,,,,,,,,interpolation,,,,flow visualization,time-varying flows",,26,28,871,,
TVCG,2018,Evaluating Interactive Graphical Encodings for Data Visualization,10.1109/tvcg.2017.2680452,http://dx.doi.org/10.1109/TVCG.2017.2680452,1316,1330,J,"User interfaces for data visualization often consist of two main components: control panels for user interaction and visual representation. A recent trend in visualization is directly embedding user interaction into the visual representations. For example, instead of using control panels to adjust visualization parameters, users can directly adjust basic graphical encodings (e.g., changing distances between points in a scatterplot) to perform similar parameterizations. However, enabling embedded interactions for data visualization requires a strong understanding of how user interactions influence the ability to accurately control and perceive graphical encodings. In this paper, we study the effectiveness of these graphical encodings when serving as the method for interaction. Our user study includes 12 interactive graphical encodings. We discuss the results in terms of task performance and interaction effectiveness metrics.",Bahador Saket;Arjun Srinivasan;Eric D. Ragan;Alex Endert,Bahador Saket;Arjun Srinivasan;Eric D. Ragan;Alex Endert,"Georgia Tech, Atlanta, GA;Georgia Tech, Atlanta, GA;Texas A&M University, College Station, TX;Georgia Tech, Atlanta, GA",0.1109/tvcg.2007.70589;10.1109/tvcg.2007.70515;10.1109/vast.2012.6400486;10.1109/tvcg.2012.196;10.1109/tvcg.2016.2598620;10.1109/tvcg.2014.2346250;10.1109/tvcg.2012.204;10.1109/tvcg.2012.251;10.1109/tvcg.2016.2598839;10.1109/vast.2011.6102449;10.1109/tvcg.2016.2598446;10.1109/tvcg.2011.185,"Information visualization,user interaction,,,,,,,,,,,graphical encodings,,,,,,,,,,,graphical perception",,27,55,1780,,
TVCG,2017,Vis-A-Ware: Integrating Spatial and Non-Spatial Visualization for Visibility-Aware Urban Planning,10.1109/tvcg.2016.2520920,http://dx.doi.org/10.1109/TVCG.2016.2520920,1139,1151,J,"3D visibility analysis plays a key role in urban planning for assessing the visual impact of proposed buildings on the cityscape. A call for proposals typically yields around 30 candidate buildings that need to be evaluated with respect to selected viewpoints. Current visibility analysis methods are very time-consuming and limited to a small number of viewpoints. Further, analysts neither have measures to evaluate candidates quantitatively, nor to compare them efficiently. The primary contribution of this work is the design study of Vis-A-Ware, a visualization system to qualitatively and quantitatively evaluate, rank, and compare visibility data of candidate buildings with respect to a large number of viewpoints. Vis-A-Ware features a 3D spatial view of an urban scene and non-spatial views of data derived from visibility evaluations, which are tightly integrated by linked interaction. To enable a quantitative evaluation we developed four metrics in accordance with experts from urban planning. We illustrate the applicability of Vis-A-Ware on the basis of a use case scenario and present results from informal feedback sessions with domain experts from urban planning and development. This feedback suggests that Vis-A-Ware is a valuable tool for visibility analysis allowing analysts to answer complex questions more efficiently and objectively.",Thomas Ortner;Johannes Sorger;Harald Steinlechner;Gerd Hesina;Harald Piringer;M. Eduard Gröller,Thomas Ortner;Johannes Sorger;Harald Steinlechner;Gerd Hesina;Harald Piringer;Eduard Gröller,"VRVis Research Center, Vienna, Austria;VRVis Research Center, Vienna, Austria;VRVis Research Center, Vienna, Austria;VRVis Research Center, Vienna, Austria;VRVis Research Center, Vienna, Austria;TU Wien, Vienna, Austria",0.1109/tvcg.2011.185;10.1109/tvcg.2010.223;10.1109/tvcg.2014.2346321;10.1109/tvcg.2010.190;10.1109/tvcg.2015.2468011;10.1109/tvcg.2013.173;10.1109/tvcg.2014.2346898;10.1109/tvcg.2008.149;10.1109/vast.2010.5651694;10.1109/vast.2009.5333081;10.1109/tvcg.2014.2346893;10.1109/vast.2015.7347636;10.1109/tvcg.2009.141;10.1109/visual.2000.885739;10.1109/tvcg.2007.70574,"Geographic/geospatial visualization,visual analytics,,,,,,,,,,,integrating spatial and non-spatial data visualization,,,,,,,,,,,focus + context techniques,,,,coordinated and multiple views",,24,33,1161,,
TVCG,2016,Visualizing Dynamic Hierarchies in Graph Sequences,10.1109/tvcg.2015.2507595,http://dx.doi.org/10.1109/TVCG.2015.2507595,2343,2357,J,"Graphs are used to model relations between objects, where these objects can be grouped hierarchically based on their connectivity. In many applications, the relations change over time and so does the hierarchical group structure. We developed a visualization technique that supports the analysis of the topology and the hierarchical group structure of a dynamic graph and the tracking of changes over time. Each graph of a sequence is visualized by an adjacency matrix, where the hierarchical group structure is encoded within the matrix using indentation and nested contours, complemented by icicle plots attached to the matrices. The density within and between subgroups of the hierarchy is represented within the matrices using a gray scale. To visualize changes, transitions and dissimilarities between the hierarchically structured graphs are shown using a flow metaphor and color coding. The design of our visualization technique allows us to show more than one hierarchical group structure of the same graph by stacking the sequences, where hierarchy comparison is supported not only within but also between sequences. To improve the readability, we minimize the number of crossing curves within and between sequences based on a sorting algorithm that sweeps through the sequences of hierarchies.",Corinna Vehlow;Fabian Beck 0001;Daniel Weiskopf,Corinna Vehlow;Fabian Beck;Daniel Weiskopf,"VISUS, University of Stuttgart, Germany;VISUS, University of Stuttgart, Germany;VISUS, University of Stuttgart, Germany",0.1109/infvis.2000.885098;10.1109/tvcg.2014.2346260;10.1109/tvcg.2013.231;10.1109/tvcg.2007.70556;10.1109/tvcg.2011.226;10.1109/vast.2011.6102439;10.1109/tvcg.2014.2322594,"Dynamic graph,hierarchical graph,,,,,,,,,,,graph visualization",,24,55,1149,,
TVCG,2019,Precision Risk Analysis of Cancer Therapy with Interactive Nomograms and Survival Plots,10.1109/tvcg.2018.2817557,http://dx.doi.org/10.1109/TVCG.2018.2817557,1732,1745,J,"We present the design and evaluation of an integrated problem solving environment for cancer therapy analysis. The environment intertwines a statistical martingale model and a K Nearest Neighbor approach with visual encodings, including novel interactive nomograms, in order to compute and explain a patient's probability of survival as a function of similar patient results. A coordinated views paradigm enables exploration of the multivariate, heterogeneous and few-valued data from a large head and neck cancer repository. A visual scaffolding approach further enables users to build from familiar representations to unfamiliar ones. Evaluation with domain experts show how this visualization approach and set of streamlined workflows enable the systematic and precise analysis of a patient prognosis in the context of cohorts of similar patients. We describe the design lessons learned from this successful, multi-site remote collaboration.",G. Elisabeta Marai;Chihua Ma;Andrew Thomas Burks;Filippo Pellolio;Guadalupe Canahuate;David M. Vock;Abdallah Sherif Radwan Mohamed;Clifton David Fuller,G. Elisabeta Marai;Chihua Ma;Andrew Thomas Burks;Filippo Pellolio;Guadalupe Canahuate;David M. Vock;Abdallah S. R. Mohamed;Clifton David Fuller,"Electronic Visualization Laboratory, University of Illinois at Chicago, Chicago, IL;Electronic Visualization Laboratory, University of Illinois at Chicago, Chicago, IL;Electronic Visualization Laboratory, University of Illinois at Chicago, Chicago, IL;Electronic Visualization Laboratory, University of Illinois at Chicago, Chicago, IL;Department of Computer Science, University of Iowa, Iowa City, IA;Bioinformatics and Statistics Department, University of Minnesota, Minneapolis, MN;MD Anderson Cancer Center, University of Texas, Houston, TX;MD Anderson Cancer Center, University of Texas, Houston, TX",0.1109/tvcg.2009.108;10.1109/tvcg.2017.2744459;10.1109/tvcg.2014.2346331;10.1109/tvcg.2012.213;10.1109/tvcg.2009.111;10.1109/tvcg.2013.161;10.1109/tvcg.2014.2346591;10.1109/mcg.2014.40;10.1109/tvcg.2007.70589,"Visual analytics,precision medicine,,,,,,,,,,,design studies,,,,,,,,,,,nomograms,,,,parallel coordinate plots,activity-centered design",,24,51,1352,,
TVCG,2015,Munin: A Peer-to-Peer Middleware for Ubiquitous Analytics and Visualization Spaces,10.1109/tvcg.2014.2337337,http://dx.doi.org/10.1109/TVCG.2014.2337337,215,228,J,"We present Munin, a software framework for building ubiquitous analytics environments consisting of multiple input and output surfaces, such as tabletop displays, wall-mounted displays, and mobile devices. Munin utilizes a service-based model where each device provides one or more dynamically loaded services for input, display, or computation. Using a peer-to-peer model for communication, it leverages IP multicast to replicate the shared state among the peers. Input is handled through a shared event channel that lets input and output devices be fully decoupled. It also provides a data-driven scene graph to delegate rendering to peers, thus creating a robust, fault-tolerant, decentralized system. In this paper, we describe Munin's general design and architecture, provide several examples of how we are using the framework for ubiquitous analytics and visualization, and present a case study on building a Munin assembly for multidimensional visualization. We also present performance results and anecdotal user feedback for the framework that suggests that combining a service-oriented, data-driven model with middleware support for data sharing and event handling eases the design and execution of high performance distributed visualizations.",Sriram Karthik Badam;Eli Raymond Fisher;Niklas Elmqvist,Sriram Karthik Badam;Eli Fisher;Niklas Elmqvist,"School of Electrical & Computer Engineering, Purdue University, West Lafayette, IN;School of Electrical & Computer Engineering, Purdue University, West Lafayette, IN;School of Electrical & Computer Engineering, Purdue University, West Lafayette, IN",0.1109/tvcg.2006.178;10.1109/tvcg.2012.204;10.1109/infvis.2004.64;10.1109/tvcg.2011.185;10.1109/tvcg.2009.162;10.1109/tvcg.2008.121;10.1109/vast.2007.4388994;10.1109/tvcg.2007.70568,"Ubiquitous analytics,high-resolution displays,,,,,,,,,,,multi-display environments,,,,,,,,,,,distributed visualization,,,,framework,Ubiquitous analytics,high-resolution displays,multi-display environments,distributed visualization,framework",,21,64,861,,
TVCG,2015,Comparing Color and Leader Line Highlighting Strategies in Coordinated View Geovisualizations,10.1109/tvcg.2014.2371858,http://dx.doi.org/10.1109/TVCG.2014.2371858,339,349,J,"In most coordinated view geovisualization tools, a transient visual effect is used to highlight observations across views when brushed with a mouse or other input device. Most current geovisualization and information visualization systems use colored outlines or fills to highlight observations, but there remain a wide range of alternative visual strategies that can also be implemented and compared to color highlighting to evaluate user performance. This paper describes the results of an experiment designed to compare user performance with two highlighting methods; color and leader lines. Our study methodology uses eye-tracking to capture participant eye fixations while they answer questions that require attention to highlighted observations in multiple views. Our results show that participants extract information as efficiently from coordinated view displays that use leader line highlighting to link information as they do from those that use a specific color to highlight items. We also found no significant differences when changing the color of the highlighting effect from red to black. We conclude that leader lines show significant potential for use as an alternative highlighting method in coordinated multiple view visualizations, allowing color to be reserved for representing thematic attributes of data.",Amy L. Griffin;Anthony C. Robinson,Amy L. Griffin;Anthony C. Robinson,"School of Physical, Environmental, and Mathematical Sciences, UNSW, Canberra, Australia;GeoVISTA Center, Department of Geography, Pennsylvania State University, University Park, PA, USA",0.1109/infvis.2004.64;10.1109/tvcg.2013.154;10.1109/vast.2007.4389006;10.1109/tvcg.2012.276;10.1109/tvcg.2011.183;10.1109/infvis.2004.12;10.1109/tvcg.2013.160,"Evaluation/methodology,Graphical user interfaces,,,,,,,,,,,Interaction styles,,,,,,,,,,,Information visualization,,,,Evaluation/methodology,graphical user interfaces,interaction styles,information visualization",,23,45,807,,
TVCG,2017,A Statistical Direct Volume Rendering Framework for Visualization of Uncertain Data,10.1109/tvcg.2016.2637333,http://dx.doi.org/10.1109/TVCG.2016.2637333,2509,2520,J,"With uncertainty present in almost all modalities of data acquisition, reduction, transformation, and representation, there is a growing demand for mathematical analysis of uncertainty propagation in data processing pipelines. In this paper, we present a statistical framework for quantification of uncertainty and its propagation in the main stages of the visualization pipeline. We propose a novel generalization of Irwin-Hall distributions from the statistical viewpoint of splines and box-splines, that enables interpolation of random variables. Moreover, we introduce a probabilistic transfer function classification model that allows for incorporating probability density functions into the volume rendering integral. Our statistical framework allows for incorporating distributions from various sources of uncertainty which makes it suitable in a wide range of visualization applications. We demonstrate effectiveness of our approach in visualization of ensemble data, visualizing large datasets at reduced scale, iso-surface extraction, and visualization of noisy data.",Elham Sakhaee;Alireza Entezari,Elham Sakhaee;Alireza Entezari,"Department of Computer and Information Science and Engineering, University of Florida, Gainesville, FL;Department of Computer and Information Science and Engineering, University of Florida, Gainesville, FL",0.1109/tvcg.2013.208;10.1109/tvcg.2015.2467958;10.1109/tvcg.2013.143;10.1109/tvcg.2010.181;10.1109/tvcg.2007.70518;10.1109/tvcg.2013.90;10.1109/tvcg.2006.141;10.1109/tvcg.2012.249;10.1109/tvcg.2012.227;10.1109/visual.1997.663848,"Uncertainty visualization,direct volume rendering,,,,,,,,,,,interpolation of distributions,,,,,,,,,,,ray casting,,,,transfer function classification,data reduction,spline",,21,45,1193,,
TVCG,2017,Fast and Exact Fiber Surfaces for Tetrahedral Meshes,10.1109/tvcg.2016.2570215,http://dx.doi.org/10.1109/TVCG.2016.2570215,1782,1795,J,"Isosurfaces are fundamental geometrical objects for the analysis and visualization of volumetric scalar fields. Recent work has generalized them to bivariate volumetric fields with fiber surfaces, the pre-image of polygons in range space. However, the existing algorithm for their computation is approximate, and is limited to closed polygons. Moreover, its runtime performance does not allow instantaneous updates of the fiber surfaces upon user edits of the polygons. Overall, these limitations prevent a reliable and interactive exploration of the space of fiber surfaces. This paper introduces the first algorithm for the exact computation of fiber surfaces in tetrahedral meshes. It assumes no restriction on the topology of the input polygon, handles degenerate cases and better captures sharp features induced by polygon bends. The algorithm also allows visualization of individual fibers on the output surface, better illustrating their relationship with data features in range space. To enable truly interactive exploration sessions, we further improve the runtime performance of this algorithm. In particular, we show that it is trivially parallelizable and that it scales nearly linearly with the number of cores. Further, we study acceleration data-structures both in geometrical domain and range space and we show how to generalize interval trees used in isosurface extraction to fiber surface extraction. Experiments demonstrate the superiority of our algorithm over previous work, both in terms of accuracy and running time, with up to two orders of magnitude speedups. This improvement enables interactive edits of range polygons with instantaneous updates of the fiber surface for exploration purpose. A VTK-based reference implementation is provided as additional material to reproduce our results.",Pavol Klacansky;Julien Tierny;Hamish A. Carr;Zhao Geng,Pavol Klacansky;Julien Tierny;Hamish Carr;Zhao Geng,"University of Leeds, Leeds, United Kingdom;Sorbonne Universites, UPMC Univ Paris 06, CNRS, France;University of Leeds, Leeds, United Kingdom;University of Leeds, Leeds, United Kingdom",0.1109/visual.2003.1250354;10.1109/visual.1996.568103;10.1109/tvcg.2011.109;10.1109/tvcg.2009.194;10.1109/tvcg.2008.119;10.1109/tvcg.2012.110;10.1109/tvcg.2010.146,"Bivariate data,data segmentation,,,,,,,,,,,data analysis,,,,,,,,,,,isosurfaces,,,,continuous scatterplot",,22,38,654,,
TVCG,2019,Lineage: Visualizing Multivariate Clinical Data in Genealogy Graphs,10.1109/tvcg.2018.2811488,http://dx.doi.org/10.1109/TVCG.2018.2811488,1543,1558,J,"The majority of diseases that are a significant challenge for public and individual heath are caused by a combination of hereditary and environmental factors. In this paper we introduce Lineage, a novel visual analysis tool designed to support domain experts who study such multifactorial diseases in the context of genealogies. Incorporating familial relationships between cases with other data can provide insights into shared genomic variants and shared environmental exposures that may be implicated in such diseases. We introduce a data and task abstraction, and argue that the problem of analyzing such diseases based on genealogical, clinical, and genetic data can be mapped to a multivariate graph visualization problem. The main contribution of our design study is a novel visual representation for tree-like, multivariate graphs, which we apply to genealogies and clinical data about the individuals in these families. We introduce data-driven aggregation methods to scale to multiple families. By designing the genealogy graph layout to align with a tabular view, we are able to incorporate extensive, multivariate attributes in the analysis of the genealogy without cluttering the graph. We validate our designs by conducting case studies with our domain collaborators.",Carolina Nobre;Nils Gehlenborg;Hilary Coon;Alexander Lex,Carolina Nobre;Nils Gehlenborg;Hilary Coon;Alexander Lex,"University of Utah, Salt Lake City, UT;Harvard Medical School, Boston, MA;University of Utah, Salt Lake City, UT;University of Utah, Salt Lake City, UT",0.1109/visual.1991.175815;10.1109/infvis.2000.885091;10.1109/tvcg.2016.2598469;10.1109/tvcg.2013.173;10.1109/tvcg.2010.138;10.1109/tvcg.2011.279;10.1109/tvcg.2010.185;10.1109/tvcg.2010.159;10.1109/tvcg.2017.2744080;10.1109/tvcg.2012.213;10.1109/tvcg.2013.145;10.1109/tvcg.2014.2346441;10.1109/tvcg.2008.117,"Multivariate networks,biology visualization,,,,,,,,,,,genealogies,,,,,,,,,,,hereditary genetics,,,,multifactorial diseases",,21,76,1769,,
TVCG,2018,A Visual Analytics Framework for Identifying Topic Drivers in Media Events,10.1109/tvcg.2017.2752166,http://dx.doi.org/10.1109/TVCG.2017.2752166,2501,2515,J,"Media data has been the subject of large scale analysis with applications of text mining being used to provide overviews of media themes and information flows. Such information extracted from media articles has also shown its contextual value of being integrated with other data, such as criminal records and stock market pricing. In this work, we explore linking textual media data with curated secondary textual data sources through user-guided semantic lexical matching for identifying relationships and data links. In this manner, critical information can be identified and used to annotate media timelines in order to provide a more detailed overview of events that may be driving media topics and frames. These linked events are further analyzed through an application of causality modeling to model temporal drivers between the data series. Such causal links are then annotated through automatic entity extraction which enables the analyst to explore persons, locations, and organizations that may be pertinent to the media topic of interest. To demonstrate the proposed framework, two media datasets and an armed conflict event dataset are explored.",Yafeng Lu;Hong Wang;Steven Landis;Ross Maciejewski,Yafeng Lu;Hong Wang;Steven Landis;Ross Maciejewski,"Arizona State University, Tempe, AZ;Arizona State University, Tempe, AZ;University of Nevada, Las Vegas, NV;Arizona State University, Tempe, AZ",0.1109/tvcg.2015.2467531;10.1109/vast.2010.5652922;10.1109/vast.2010.5652885;10.1109/infvis.1995.528686;10.1109/tvcg.2014.2346919;10.1109/tvcg.2013.221;10.1109/tvcg.2015.2467757;10.1109/tvcg.2015.2467621;10.1109/tvcg.2015.2467971;10.1109/vast.2008.4677364;10.1109/vast.2014.7042487;10.1109/tvcg.2014.2346433;10.1109/vast.2012.6400485;10.1109/tvcg.2015.2467991;10.1109/tvcg.2016.2598543,"Semantic similarity,media annotation,,,,,,,,,,,visual analytics,,,,,,,,,,,causality modeling,,,,social media",,17,49,1206,,
TVCG,2018,DSPCP: A Data Scalable Approach for Identifying Relationships in Parallel Coordinates,10.1109/tvcg.2017.2661309,http://dx.doi.org/10.1109/TVCG.2017.2661309,1301,1315,J,"Parallel coordinates plots (PCPs) are a well-studied technique for exploring multi-attribute datasets. In many situations, users find them a flexible method to analyze and interact with data. Unfortunately, using PCPs becomes challenging as the number of data items grows large or multiple trends within the data mix in the visualization. The resulting overdraw can obscure important features. A number of modifications to PCPs have been proposed, including using color, opacity, smooth curves, frequency, density, and animation to mitigate this problem. However, these modified PCPs tend to have their own limitations in the kinds of relationships they emphasize. We propose a new data scalable design for representing and exploring data relationships in PCPs. The approach exploits the point/line duality property of PCPs and a local linear assumption of data to extract and represent relationship summarizations. This approach simultaneously shows relationships in the data and the consistency of those relationships. Our approach supports various visualization tasks, including mixed linear and nonlinear pattern identification, noise detection, and outlier detection, all in large data. We demonstrate these tasks on multiple synthetic and real-world datasets.",Hoa Nguyen;Paul Rosen 0001,Hoa Nguyen;Paul Rosen,"Scientific Computing and Imaging Institute, University of Utah, Salt Lake City, UT;Department of Computer Science and Engineering, University of South Florida, Tampa, FL",0.1109/tvcg.2010.146;10.1109/tvcg.2011.200;10.1109/tvcg.2008.119;10.1109/tvcg.2006.170;10.1109/tvcg.2009.131;10.1109/tvcg.2014.2346979;10.1109/tvcg.2006.138;10.1109/tvcg.2010.184;10.1109/tvcg.2008.131;10.1109/tvcg.2011.166;10.1109/visual.1997.663916;10.1109/vast.2010.5652460;10.1109/visual.1994.346302;10.1109/tvcg.2007.70523;10.1109/tvcg.2010.205;10.1109/tvcg.2009.179;10.1109/tvcg.2011.237;10.1109/visual.1990.146402,"Correlation,parallel coordinates plot,,,,,,,,,,,large data visualization",,21,64,665,,
TVCG,2015,SimpliFly: A Methodology for Simplification and Thematic Enhancement of Trajectories,10.1109/tvcg.2014.2337333,http://dx.doi.org/10.1109/TVCG.2014.2337333,107,121,J,"Movement data sets collected using today's advanced tracking devices consist of complex trajectories in terms of length, shape, and number of recorded positions. Multiple additional attributes characterizing the movement and its environment are often also included making the level of complexity even higher. Simplification of trajectories can improve the visibility of relevant information by reducing less relevant details while maintaining important movement patterns. We propose a systematic stepwise methodology for simplifying and thematically enhancing trajectories in order to support their visual analysis. The methodology is applied iteratively and is composed of: (a) a simplification step applied to reduce the morphological complexity of the trajectories, (b) a thematic enhancement step which aims at accentuating patterns of movement, and (c) the representation and interactive exploration of the results in order to make interpretations of the findings and further refinement to the simplification and enhancement process. We illustrate our methodology through an analysis example of two different types of tracks, aircraft and pedestrian movement.",Katerina Vrotsou;Halldor Janetzko;Carlo Navarra;Georg Fuchs;David Spretke;Florian Mansmann;Natalia V. Andrienko;Gennady L. Andrienko,Katerina Vrotsou;Halldor Janetzko;Carlo Navarra;Georg Fuchs;David Spretke;Florian Mansmann;Natalia Andrienko;Gennady Andrienko,"Linköping University, Sweden;University of Konstanz, Germany;Linköping University, Sweden;University of Bonn and Fraunhofer IAIS, Germany;University of Konstanz, Germany;University of Konstanz, Germany;University of Bonn and Fraunhofer IAIS, Germany;University of Bonn and Fraunhofer IAIS, Germany",0.1109/vast.2009.5332593;10.1109/tvcg.2008.165;10.1109/tvcg.2009.145;10.1109/tvcg.2011.202,"Visual analysis,trajectories,,,,,,,,,,,simplification,,,,,,,,,,,thematic enhancement,,,,clustering",,21,55,866,,
TVCG,2016,Feature Surfaces in Symmetric Tensor Fields Based on Eigenvalue Manifold,10.1109/tvcg.2015.2484343,http://dx.doi.org/10.1109/TVCG.2015.2484343,1248,1260,J,"Three-dimensional symmetric tensor fields have a wide range of applications in solid and fluid mechanics. Recent advances in the (topological) analysis of 3D symmetric tensor fields focus on degenerate tensors which form curves. In this paper, we introduce a number of feature surfaces, such as neutral surfaces and traceless surfaces, into tensor field analysis, based on the notion of eigenvalue manifold. Neutral surfaces are the boundary between linear tensors and planar tensors, and the traceless surfaces are the boundary between tensors of positive traces and those of negative traces. Degenerate curves, neutral surfaces, and traceless surfaces together form a partition of the eigenvalue manifold, which provides a more complete tensor field analysis than degenerate curves alone. We also extract and visualize the isosurfaces of tensor modes, tensor isotropy, and tensor magnitude, which we have found useful for domain applications in fluid and solid mechanics. Extracting neutral and traceless surfaces using the Marching Tetrahedra method can cause the loss of geometric and topological details, which can lead to false physical interpretation. To robustly extract neutral surfaces and traceless surfaces, we develop a polynomial description of them which enables us to borrow techniques from algebraic surface extraction, a topic well-researched by the computer-aided design (CAD) community as well as the algebraic geometry community. In addition, we adapt the surface extraction technique, called A-patches, to improve the speed of finding degenerate curves. Finally, we apply our analysis to data from solid and fluid mechanics as well as scalar field analysis.",Jonathan Palacios;Harry Yeh;Wenping Wang;Yue Zhang 0009;Robert S. Laramee;Ritesh Sharma;Thomas Schultz 0001;Eugene Zhang,Jonathan Palacios;Harry Yeh;Wenping Wang;Yue Zhang;Robert S. Laramee;Ritesh Sharma;Thomas Schultz;Eugene Zhang,"School of Electrical Engineering and Computer Science, Oregon State University, 1148 Kelley Engineering Center, Corvallis, OR;School of Civil and Construction Engineering, Oregon State University, 208 Owen Hall, Corvallis, OR;Department of Computer Science, The University of Hong Kong, Pokfulam Road, Hong Kong;School of Electrical Engineering and Computer Science, Oregon State University, 3117 Kelley Engineering Center, Corvallis, OR;Department of Computer Science, Swansea University, Wales, UK;School of Electrical Engineering and Computer Science, Oregon State University, 1148 Kelley Engineering Center, Corvallis, OR;Institute of Computer Science, University of Bonn, Friedrich-Ebert-Allee 144, Bonn, Germany;School of Electrical Engineering and Computer Science, Oregon State University, 2111 Kelley Engineering Center, Corvallis, OR",0.1109/visual.2003.1250414;10.1109/tvcg.2008.163;10.1109/tvcg.2006.181;10.1109/tvcg.2010.199;10.1109/visual.1994.346326;10.1109/tvcg.2008.148;10.1109/visual.2004.105;10.1109/visual.1999.809896;10.1109/tvcg.2007.70602;10.1109/tvcg.2009.184,"Tensor field visualization,feature-based visualization,A-patches,scalar fields,,,,,,,,,tensor field topology,,,,,,,,,,,traceless tensors,,,,A-patches,scalar fields,Tensor field visualization,feature-based visualization,tensor field topology,traceless tensors",,18,35,779,,
TVCG,2017,Analyzing Eye-Tracking Information in Visualization and Data Space: From Where on the Screen to What on the Screen,10.1109/tvcg.2016.2535340,http://dx.doi.org/10.1109/TVCG.2016.2535340,1492,1505,J,"Eye-tracking data is currently analyzed in the image space that gaze-coordinates were recorded in, generally with the help of overlays such as heatmaps or scanpaths, or with the help of manually defined areas of interest (AOI). Such analyses, which focus predominantly on where on the screen users are looking, require significant manual input and are not feasible for studies involving many subjects, long sessions, and heavily interactive visual stimuli. Alternatively, we show that it is feasible to collect and analyze eye-tracking information in data space. Specifically, the visual layout of visualizations with open source code that can be instrumented is known at rendering time, and thus can be used to relate gaze-coordinates to visualization and data objects that users view, in real time. We demonstrate the effectiveness of this approach by showing that data collected using this methodology from nine users working with an interactive visualization, was well aligned with the tasks that those users were asked to solve, and similar to annotation data produced by five human coders. Moreover, we introduce an algorithm that, given our instrumented visualization, could translate gaze-coordinates into viewed objects with greater accuracy than simply binning gazes into dynamically defined AOIs. Finally, we discuss the challenges, opportunities, and benefits of analyzing eye-tracking in visualization and data space.",Sayeed Safayet Alam;Radu Jianu,Sayeed Safayet Alam;Radu Jianu,"School of Computing and Information Sciences, Florida International University, Miami, FL;School of Computing and Information Sciences, Florida International University, Miami, FL",0.1109/tvcg.2012.252;10.1109/tvcg.2012.276;10.1109/tvcg.2011.185;10.1109/tvcg.2011.193;10.1109/tvcg.2012.215,"Eye-tracking,area of interest analysis,,,,,,,,,,,usability analysis,,,,,,,,,,,evaluation",,18,42,1834,,
TVCG,2016,ThermalPlot: Visualizing Multi-Attribute Time-Series Data Using a Thermal Metaphor,10.1109/tvcg.2015.2513389,http://dx.doi.org/10.1109/TVCG.2015.2513389,2594,2607,J,"Multi-attribute time-series data plays a vital role in many different domains, such as economics, sensor networks, and biology. An important task when making sense of such data is to provide users with an overview to identify items that show an interesting development over time, including both absolute and relative changes in multiple attributes simultaneously. However, this is not well supported by existing visualization techniques. To address this issue, we present ThermalPlot, a visualization technique that summarizes combinations of multiple attributes over time using an items position, the most salient visual variable. More precisely, the x-position in the  ThermalPlot is based on a user-defined degree-of-interest (DoI) function that combines multiple attributes over time. The y-position is determined by the relative change in the DoI value ( $\Delta$ DoI) within a user-specified time window. Animating this mapping via a moving time window gives rise to circular movements of items over time—as in thermal systems. To help the user to identify important items that match user-defined temporal patterns and to increase the technique's scalability, we adapt the level of detail of the items’ representation based on the DoI value. Furthermore, we present an interactive exploration environment for multi-attribute time-series data that ties together a carefully chosen set of visualizations, designed to support analysts in interacting with the ThermalPlot technique. We demonstrate the effectiveness of our technique by means of two usage scenarios that address the visual analysis of economic development data and of stock market data.",Holger Stitz;Samuel Gratzl;Wolfgang Aigner;Marc Streit,Holger Stitz;Samuel Gratzl;Wolfgang Aigner;Marc Streit,Johannes Kepler University Linz;Johannes Kepler University Linz;St. Poelten University of Applied Sciences;Johannes Kepler University Linz,0.1109/tvcg.2011.185;10.1109/tvcg.2008.166;10.1109/tvcg.2013.173;10.1109/tvcg.2007.70539;10.1109/tvcg.2010.162;10.1109/vast.2010.5652530;10.1109/tvcg.2008.125;10.1109/visual.1995.485140;10.1109/tvcg.2009.108;10.1109/infvis.2002.1173157;10.1109/tvcg.2013.154,"Time-dependent data,multi-attribute data,,,,,,,,,,,focus+context,,,,,,,,,,,semantic zooming",,16,41,883,,
TVCG,2018,A Vector Field Design Approach to Animated Transitions,10.1109/tvcg.2017.2750689,http://dx.doi.org/10.1109/TVCG.2017.2750689,2487,2500,J,"Animated transitions can be effective in explaining and exploring a small number of visualizations where there are drastic changes in the scene over a short interval of time. This is especially true if data elements cannot be visually distinguished by other means. Current research in animated transitions has mainly focused on linear transitions (all elements follow straight line paths) or enhancing coordinated motion through bundling of linear trajectories. In this paper, we introduce animated transition design, a technique to build smooth, non-linear transitions for clustered data with either minimal or no user involvement. The technique is flexible and simple to implement, and has the additional advantage that it explicitly enhances coordinated motion and can avoid crowding, which are both important factors to support object tracking in a scene. We investigate its usability, provide preliminary evidence for the effectiveness of this technique through metric evaluations and user study and discuss limitations and future directions.",Yong Wang 0021;Daniel Archambault;Carlos Eduardo Scheidegger;Huamin Qu,Yong Wang;Daniel Archambault;Carlos E. Scheidegger;Huamin Qu,"Hong Kong University of Science and Technology, Hong Kong;Swansea University, Swansea, United Kingdom;University of Arizona, Tucson, AZ;Hong Kong University of Science and Technology, Hong Kong",0.1109/tvcg.2014.2346424;10.1109/tvcg.2007.70539;10.1109/tvcg.2008.153;10.1109/tvcg.2015.2467992,"Information visualization,animated transitions,,,,,,,,,,,vector field design",,16,51,730,,
TVCG,2016,Dealing with Multiple Requirements in Geometric Arrangements,10.1109/tvcg.2015.2489660,http://dx.doi.org/10.1109/TVCG.2015.2489660,1223,1235,J,"Existing algorithms for building layouts from geometric primitives are typically designed to cope with requirements such as orthogonal alignment, overlap removal, optimal area usage, hierarchical organization, among others. However, most techniques are able to tackle just a few of those requirements simultaneously, impairing their use and flexibility. In this work we propose a novel methodology for building layouts from geometric primitives that concurrently addresses a wider range of requirements. Relying on multidimensional projection and mixed integer optimization, our approach arranges geometric objects in the visual space so as to generate well structured layouts that preserve the semantic relation among objects while still making an efficient use of display area. Moreover, scalability is handled through a hierarchical representation scheme combined with navigation tools. A comprehensive set of quantitative comparisons against existing geometry-based layouts and applications on text, image, and video data set visualization prove the effectiveness of our approach.",Erick Gomez Nieto;Wallace Casaca;Danilo Motta;Ivar A. Hartmann;Gabriel Taubin;Luis Gustavo Nonato,Erick Gomez-Nieto;Wallace Casaca;Danilo Motta;Ivar Hartmann;Gabriel Taubin;Luis Gustavo Nonato,"Instituto de Ciências Matemáticas e de Computação (ICMC), Universidade de São Paulo, São Carlos, Brazil;Instituto de Ciências Matemáticas e de Computação (ICMC), Universidade de São Paulo, São Carlos, Brazil;Instituto de Ciências Matemáticas e de Computação (ICMC), Universidade de São Paulo, São Carlos, Brazil;Universidade Estadual de Rio de Janeiro, Rio de Janeiro, Brazil;Brown University, School of Engineering, Providence;Instituto de Ciências Matemáticas e de Computação (ICMC), Universidade de São Paulo, São Carlos, Brazil",0.1109/tvcg.2013.242;10.1109/tvcg.2010.162;10.1109/tvcg.2013.122;10.1109/tvcg.2007.70540;10.1109/visual.1991.175815;10.1109/infvis.2001.963283;10.1109/tvcg.2010.185;10.1109/infvis.2002.1173156;10.1109/tvcg.2010.175;10.1109/tvcg.2012.250;10.1109/tvcg.2008.165,"Overlap Removal,Similarity Preserving,,,,,,,,,,,Structured Layouts,,,,,,,,,,,Area Optimization,,,,Overlap removal,similarity preserving,structured layouts,area optimization",,17,44,536,,
TVCG,2018,Indexed-Points Parallel Coordinates Visualization of Multivariate Correlations,10.1109/tvcg.2017.2698041,http://dx.doi.org/10.1109/TVCG.2017.2698041,1997,2010,J,"We address the problem of visualizing multivariate correlations in parallel coordinates. We focus on multivariate correlation in the form of linear relationships between multiple variables. Traditional parallel coordinates are well prepared to show negative correlations between two attributes by distinct visual patterns. However, it is difficult to recognize positive correlations in parallel coordinates. Furthermore, there is no support to highlight multivariate correlations in parallel coordinates. In this paper, we exploit the indexed point representation of p -flats (planes in multidimensional data) to visualize local multivariate correlations in parallel coordinates. Our method yields clear visual signatures for negative and positive correlations alike, and it supports large datasets. All information is shown in a unified parallel coordinates framework, which leads to easy and familiar user interactions for analysts who have experience with traditional parallel coordinates. The usefulness of our method is demonstrated through examples of typical multidimensional datasets.",Liang Zhou 0001;Daniel Weiskopf,Liang Zhou;Daniel Weiskopf,"Visualization Research Center (VISUS), University of Stuttgart, Stuttgart, Germany;Visualization Research Center (VISUS), University of Stuttgart, Stuttgart, Germany",0.1109/tvcg.2013.150;10.1109/vast.2012.6400488;10.1109/tvcg.2009.179;10.1109/tvcg.2010.205;10.1109/tvcg.2011.201;10.1109/infvis.2004.68;10.1109/tvcg.2006.170;10.1109/tvcg.2009.131;10.1109/tvcg.2008.119;10.1109/tvcg.2011.229;10.1109/tvcg.2015.2468291;10.1109/visual.1995.485139;10.1109/visual.1994.346302;10.1109/tvcg.2009.153;10.1109/infvis.2002.1173157;10.1109/tvcg.2013.20;10.1109/vast.2010.5652460,"Multidimensional data visualization,multivariate correlations,,,,,,,,,,,parallel coordinates",,16,48,1083,,
TVCG,2015,VisDock: A Toolkit for Cross-Cutting Interactions in Visualization,10.1109/tvcg.2015.2414454,http://dx.doi.org/10.1109/TVCG.2015.2414454,1087,1100,J,"Standard user applications provide a range of cross-cutting interaction techniques that are common to virtually all such tools: selection, filtering, navigation, layer management, and cut-and-paste. We present VisDock, a JavaScript mixin library that provides a core set of these cross-cutting interaction techniques for visualization, including selection (lasso, paths, shape selection, etc), layer management (visibility, transparency, set operations, etc), navigation (pan, zoom, overview, magnifying lenses, etc), and annotation (point-based, region-based, data-space based, etc). To showcase the utility of the library, we have released it as Open Source and integrated it with a large number of existing web-based visualizations. Furthermore, we have evaluated VisDock using qualitative studies with both developers utilizing the toolkit to build new web-based visualizations, as well as with end-users utilizing it to explore movie ratings data. Results from these studies highlight the usability and effectiveness of the toolkit from both developer and end-user perspectives.",Jungu Choi;Deok Gun Park 0001;Yuet Ling Wong;Eli Raymond Fisher;Niklas Elmqvist,Jungu Choi;Deok Gun Park;Yuet Ling Wong;Eli Fisher;Niklas Elmqvist,"Department of Electrical and Computer Engineering, Purdue University, West Lafayette, IN;College of Information Studies, University of Maryland, College Park, MD;Department of Electrical and Computer Engineering, Purdue University, West Lafayette, IN;Microsoft Corporation, Redmond, WA;College of Information Studies, University of Maryland, College Park, MD",0.1109/tvcg.2014.2346291;10.1109/tvcg.2010.205;10.1109/tvcg.2009.122;10.1109/tvcg.2009.151;10.1109/infvis.2004.46;10.1109/infvis.2004.64;10.1109/tvcg.2008.153;10.1109/infvis.2004.12;10.1109/tvcg.2011.185;10.1109/tvcg.2007.70515;10.1109/vast.2007.4389013,"Visualization system and toolkit design,interaction design,,,,,,,,,,,user interface,,,,,,,,,,,qualitative evaluation,,,,Visualization system and toolkit design,interaction design,user interface,qualitative evaluation",,12,42,952,,
TVCG,2015,Scalable Parallel Distance Field Construction for Large-Scale Applications,10.1109/tvcg.2015.2417572,http://dx.doi.org/10.1109/TVCG.2015.2417572,1187,1200,J,"Computing distance fields is fundamental to many scientific and engineering applications. Distance fields can be used to direct analysis and reduce data. In this paper, we present a highly scalable method for computing 3D distance fields on massively parallel distributed-memory machines. Anew distributed spatial data structure, named parallel distance tree, is introduced to manage the level sets of data and facilitate surface tracking overtime, resulting in significantly reduced computation and communication costs for calculating the distance to the surface of interest from any spatial locations. Our method supports several data types and distance metrics from real-world applications. We demonstrate its efficiency and scalability on state-of-the-art supercomputers using both large-scale volume datasets and surface models. We also demonstrate in-situ distance field computation on dynamic turbulent flame surfaces for a petascale combustion simulation. Our work greatly extends the usability of distance fields for demanding applications.",Hongfeng Yu 0001;Jinrong Xie;Kwan-Liu Ma;Hemanth Kolla;Jacqueline H. Chen,Hongfeng Yu;Jinrong Xie;Kwan-Liu Ma;Hemanth Kolla;Jacqueline H. Chen,"University of Nebraska-Lincoln, Lincoln, NE, USA;University of California-Davis, Davis, CA, USA;University of California-Davis, Davis, CA, USA;Sandia National Laboratories, Albuquerque, NM, USA;Sandia National Laboratories, Albuquerque, NM, USA",0.1109/tvcg.2007.70603,"distance field,in-situ processing,parallel algorithms,scalability,spatial data structures,scientific simulations,geometric modeling,large-scale scientific data analytics and visualization,,,,,parallel algorithms,,,,,,,,,,,scalability,,,,spatial data structures,scientific simulations,geometric modeling,large-scale scientific data analytics and visualization,Distance field,in-situ processing",,10,40,572,,
TVCG,2016,Comparative Local Quality Assessment of 3D Medical Image Segmentations with Focus on Statistical Shape Model-Based Algorithms,10.1109/tvcg.2015.2501813,http://dx.doi.org/10.1109/TVCG.2015.2501813,2537,2549,J,"The quality of automatic 3D medical segmentation algorithms needs to be assessed on test datasets comprising several 3D images (i.e., instances of an organ). The experts need to compare the segmentation quality across the dataset in order to detect systematic segmentation problems. However, such comparative evaluation is not supported well by current methods. We present a novel system for assessing and comparing segmentation quality in a dataset with multiple 3D images. The data is analyzed and visualized in several views. We detect and show regions with systematic segmentation quality characteristics. For this purpose, we extended a hierarchical clustering algorithm with a connectivity criterion. We combine quality values across the dataset for determining regions with characteristic segmentation quality across instances. Using our system, the experts can also identify 3D segmentations with extraordinary quality characteristics. While we focus on algorithms based on statistical shape models, our approach can also be applied to cases, where landmark correspondences among instances can be established. We applied our approach to three real datasets: liver, cochlea and facial nerve. The segmentation experts were able to identify organ regions with systematic segmentation characteristics as well as to detect outlier instances.",Tatiana von Landesberger;Dennis Basgier;Meike Becker,Tatiana von Landesberger;Dennis Basgier;Meike Becker,"Technische Universität Darmstadt, Germany;Technische Universität Darmstadt, Germany;Technische Universität Darmstadt, Germany",0.1109/vast.2014.7042491;10.1109/tvcg.2013.213;10.1109/tvcg.2010.208;10.1109/tvcg.2013.2297914;10.1109/tvcg.2006.170;10.1109/tvcg.2011.253;10.1109/tvcg.2011.189;10.1109/tvcg.2013.181;10.1109/tvcg.2011.248,"Visual analytics,3D medical image segmentation quality,,,,,,,,,,,comparison,,,,,,,,,,,clustering,,,,statistical shape models",,12,51,744,,
TVCG,2019,Exploring Variability within Ensembles of Decadal Climate Predictions,10.1109/tvcg.2018.2810919,http://dx.doi.org/10.1109/TVCG.2018.2810919,1499,1512,J,"Ensemble simulations are used in climate research to account for natural variability. For medium-term decadal predictions, each simulation run is initialized with real observations from a different day resulting in a set of possible climatic futures. Understanding the variability and the predictive power in this wealth of data is still a challenging task. In this paper, we introduce a visual analytics system to explore variability within ensembles of decadal climate predictions. We propose a new interactive visualization technique (clustering timeline) based on the Sankey diagram, which conveys a concise summary of data similarity and its changes over time. We augment the system with two additional visualizations, filled contour maps and heatmaps, to provide analysts with additional information relating the new diagram to raw data and automatic clustering results. The usefulness of the technique is demonstrated by case studies and user interviews.",Christopher P. Kappe;Michael Böttinger;Heike Leitte,Christopher P. Kappe;Michael Böttinger;Heike Leitte,"Department of Computer Science, TU Kaiserslautern, Kaiserslautern, Germany;Deutsches Klimarechenzentrum GmbH, Hamburg, Germany;Department of Computer Science, TU Kaiserslautern, Kaiserslautern, Germany",0.1109/tvcg.2009.111;10.1109/tvcg.2010.223;10.1109/tvcg.2011.239;10.1109/tvcg.2010.129;10.1109/tvcg.2014.2388208;10.1109/tvcg.2016.2598868;10.1109/tvcg.2016.2598830;10.1109/vast.2015.7347634;10.1109/tvcg.2008.166;10.1109/tvcg.2011.279;10.1109/tvcg.2013.126;10.1109/tvcg.2014.2346448;10.1109/tvcg.2014.2346751;10.1109/vast.2009.5332611;10.1109/tvcg.2010.190;10.1109/tvcg.2016.2599106,"Clustering,ensemble simulations,,,,,,,,,,,climate research,,,,,,,,,,,visual analysis",,12,51,698,,
TVCG,2016,Visual Encoding of Dissimilarity Data via Topology-Preserving Map Deformation,10.1109/tvcg.2015.2500225,http://dx.doi.org/10.1109/TVCG.2015.2500225,2200,2213,J,"We present an efficient technique for topology-preserving map deformation and apply it to the visualization of dissimilarity data in a geographic context. Map deformation techniques such as value-by-area cartograms are well studied. However, using deformation to highlight (dis)similarity between locations on a map in terms of their underlying data attributes is novel. We also identify an alternative way to represent dissimilarities on a map through the use of visual overlays. These overlays are complementary to deformation techniques and enable us to assess the quality of the deformation as well as to explore the design space of blending the two methods. Finally, we demonstrate how these techniques can be useful in several-quite different-applied contexts: travel-time visualization, social demographics research and understanding energy flowing in a wide-area power-grid.",Quirijn W. Bouts;Tim Dwyer;Jason Dykes;Bettina Speckmann;Sarah Goodwin;Nathalie Henry Riche;Sheelagh Carpendale;Ariel Liebman,Quirijn W. Bouts;Tim Dwyer;Jason Dykes;Bettina Speckmann;Sarah Goodwin;Nathalie Henry Riche;Sheelagh Carpendale;Ariel Liebman,"TU Eindhoven, The Netherlands;Monash University, Australia;City University London, United Kingdom;TU Eindhoven, The Netherlands;Monash University, Australia;Microsoft Research;University of Calgary, Canada;Monash University, Australia",0.1109/infvis.2002.1173148;10.1109/tvcg.2006.202;10.1109/tvcg.2015.2467199;10.1109/tvcg.2011.191;10.1109/tvcg.2007.70539;10.1109/tvcg.2012.192,"Dissimilarity,maps,,,,,,,,,,,cartographic visualization,,,,,,,,,,,multidimensional scaling,,,,deformation",,10,40,638,,
TVCG,2014,Exploring Flow Fields Using Space-Filling Analysis of Streamlines,10.1109/tvcg.2014.2312009,http://dx.doi.org/10.1109/TVCG.2014.2312009,1392,1404,J,"Large scale scientific simulations frequently use streamline based techniques to visualize flow fields. As the shape of a streamline is often related to some underlying property of the field, it is important to identify streamlines (or their parts) with unique geometric features. In this paper, we introduce a metric, called the box counting ratio, which measures the geometric complexity of streamlines by measuring their space-filling capacity at different scales. We propose a novel interactive visualization framework which utilizes this metric to extract, organize and visualize features of varying density and complexity hidden in large numbers of streamlines. The proposed framework extracts complex regions of varying density from the streamlines, and organizes and presents them on an interactive 2D information space, allowing user selection and visualization of streamlines. We also extend this framework to support exploration using an ensemble of measures including box counting ratio. Our framework allows the user to easily visualize and interact with features otherwise hidden in large vector field data. We strengthen our claims with case studies using combustion and climate simulation data sets.",Abon Chaudhuri;Teng-Yok Lee;Han-Wei Shen;Rephael Wenger,Abon Chaudhuri;Teng-Yok Lee;Han-Wei Shen;Rephael Wenger,"Department of Computer Science & Engineering, The Ohio State University, Columbus, OH;Department of Computer Science & Engineering, The Ohio State University, Columbus, OH;Department of Computer Science & Engineering, The Ohio State University, Columbus, OH;Department of Computer Science & Engineering, The Ohio State University, Columbus, OH",0.1109/tvcg.2011.155;10.1109/visual.1998.745289;10.1109/tvcg.2010.182;10.1109/tvcg.2007.70579;10.1109/tvcg.2008.162;10.1109/tvcg.2010.170;10.1109/visual.2002.1183789;10.1109/tvcg.2010.212;10.1109/tvcg.2011.78;10.1109/visual.1998.745333,"Flow visualization,streamlines,,,,,,,,,,,fractal dimension,,,,,,,,,,,box counting ratio,,,,multi-scale feature detection",,9,33,676,,
TVCG,2018,Semantic Flow Graph: A Framework for Discovering Object Relationships in Flow Fields,10.1109/tvcg.2017.2773071,http://dx.doi.org/10.1109/TVCG.2017.2773071,3200,3213,J,"Visual exploration of flow fields is important for studying dynamic systems. We introduce semantic flow graph (SFG), a novel graph representation and interaction framework that enables users to explore the relationships among key objects (i.e., field lines, features, and spatiotemporal regions) of both steady and unsteady flow fields. The objects and their relationships are organized as a heterogeneous graph. We assign each object a set of attributes, based on which a semantic abstraction of the heterogeneous graph is generated. This semantic abstraction is SFG. We design a suite of operations to explore the underlying flow fields based on this graph representation and abstraction mechanism. Users can flexibly reconfigure SFG to examine the relationships among groups of objects at different abstraction levels. Three linked views are developed to display SFG, its node split criteria and history, and the objects in the spatial volume. For simplicity, we introduce SFG construction and exploration for steady flow fields with critical points being the only features. Then we demonstrate that SFG can be naturally extended to deal with unsteady flow fields and multiple types of features. We experiment with multiple data sets and conduct an expert evaluation to demonstrate the effectiveness of our approach.",Jun Tao 0002;Chaoli Wang 0001;Nitesh V. Chawla;Lei Shi 0002;Seung Hyun Kim,Jun Tao;Chaoli Wang;Nitesh V. Chawla;Lei Shi;Seung Hyun Kim,"Department of Computer Science and Engineering, University of Notre Dame, Notre Dame, IN;Department of Computer Science and Engineering, University of Notre Dame, Notre Dame, IN;Department of Computer Science and Engineering, University of Notre Dame, Notre Dame, IN;State Key Laboratory of Computer Science, University of Chinese Academy of Sciences, Beijing, China;Department of Mechanical and Aerospace Engineering, Ohio State University, Columbus, OH",0.1109/tvcg.2015.2466838;10.1109/tvcg.2007.70589;10.1109/infvis.2004.18;10.1109/tvcg.2015.2467292;10.1109/visual.1997.663858;10.1109/visual.2002.1183786;10.1109/tvcg.2007.70579;10.1109/visual.2003.1250376;10.1109/tvcg.2011.78;10.1109/tvcg.2006.166,"Flow visualization,heterogeneous graph,,,,,,,,,,,semantic abstraction,,,,,,,,,,,critical points,,,,vortex cores,FTLE,field lines",,8,36,753,,
TVCG,2019,Robust Tracing and Visualization of Heterogeneous Microvascular Networks,10.1109/tvcg.2018.2818701,http://dx.doi.org/10.1109/TVCG.2018.2818701,1760,1773,J,"Advances in high-throughput imaging allow researchers to collect three-dimensional images of whole organ microvascular networks. These extremely large images contain networks that are highly complex, time consuming to segment, and difficult to visualize. In this paper, we present a framework for segmenting and visualizing vascular networks from terabyte-sized three-dimensional images collected using high-throughput microscopy. While these images require terabytes of storage, the volume devoted to the fiber network is $\approx 4$  percent of the total volume size. While the networks themselves are sparse, they are tremendously complex, interconnected, and vary widely in diameter. We describe a parallel GPU-based predictor-corrector method for tracing filaments that is robust to noise and sampling errors common in these data sets. We also propose a number of visualization techniques designed to convey the complex statistical descriptions of fibers across large tissue sections—including commonly studied microvascular characteristics, such as orientation and volume.",Pavel A. Govyadinov;Tasha Womack;Jason L. Eriksen;Guoning Chen;David Mayerich,Pavel A. Govyadinov;Tasha Womack;Jason L. Eriksen;Guoning Chen;David Mayerich,"Department of Computer Science, University of Houston, Houston, TX;Department of Pharmacological and Pharmaceutical Sciences, University of Houston, Houston, TX;Department of Pharmacological and Pharmaceutical Sciences, University of Houston, Houston, TX;Department of Computer Science, University of Houston, Houston, TX;Department of Electrical and Computer Engineering, University of Houston, Houston, TX",0.1109/tvcg.2008.179;10.1109/tvcg.2009.178;10.1109/tvcg.2015.2467435,"Microvessel,network tracking,,,,,,,,,,,glyph visualization,,,,,,,,,,,predictor-corrector,,,,segmantation,spherical harmonics,superquadrics,KESM",,8,51,541,,
TVCG,2017,Validation of SplitVectors Encoding for Quantitative Visualization of Large-Magnitude-Range Vector Fields,10.1109/tvcg.2016.2539949,http://dx.doi.org/10.1109/TVCG.2016.2539949,1691,1705,J,"We designed and evaluated SplitVectors, a new vector field display approach to help scientists perform new discrimination tasks on large-magnitude-range scientific data shown in three-dimensional (3D) visualization environments. SplitVectors uses scientific notation to display vector magnitude, thus improving legibility. We present an empirical study comparing the SplitVectors approach with three other approaches - direct linear representation, logarithmic, and text display commonly used in scientific visualizations. Twenty participants performed three domain analysis tasks: reading numerical values (a discrimination task), finding the ratio between values (a discrimination task), and finding the larger of two vectors (a pattern detection task). Participants used both mono and stereo conditions. Our results suggest the following: (1) SplitVectors improve accuracy by about 10 times compared to linear mapping and by four times to logarithmic in discrimination tasks; (2) SplitVectors have no significant differences from the textual display approach, but reduce cluttering in the scene; (3) SplitVectors and textual display are less sensitive to data scale than linear and logarithmic approaches; (4) using logarithmic can be problematic as participants' confidence was as high as directly reading from the textual display, but their accuracy was poor; and (5) Stereoscopy improved performance, especially in more challenging discrimination tasks.",Henan Zhao;Garnett W. Bryant;Wesley Griffin;Judith E. Terrill;Jian Chen 0006,Henan Zhao;Garnett W. Bryant;Wesley Griffin;Judith E. Terrill;Jian Chen,"Department of Computer Science and Electrical Engineering, University of Maryland, Baltimore County, Baltimore, MD;National Institute of Standards and Technology, Gaithersburg, MD;National Institute of Standards and Technology, Gaithersburg, MD;National Institute of Standards and Technology, Gaithersburg, MD;Department of Computer Science and Electrical Engineering, University of Maryland, Baltimore County, Baltimore, MD",0.1109/tvcg.2012.216;10.1109/tvcg.2014.2346428;10.1109/tvcg.2009.126;10.1109/tvcg.2013.126;10.1109/tvcg.2011.234;10.1109/tvcg.2009.111;10.1109/infvis.2004.10;10.1109/tvcg.2013.120;10.1109/tvcg.2011.203;10.1109/tvcg.2013.124,"Vector field,scientific visualization in virtual environments,,,,,,,,,,,quantum physics,,,,,,,,,,,visual encoding,,,,large-range data",,6,45,953,,
TVCG,2017,A Combined Eulerian-Lagrangian Data Representation for Large-Scale Applications,10.1109/tvcg.2016.2620975,http://dx.doi.org/10.1109/TVCG.2016.2620975,2248,2261,J,"The Eulerian and Lagrangian reference frames each provide a unique perspective when studying and visualizing results from scientific systems. As a result, many large-scale simulations produce data in both formats, and analysis tasks that simultaneously utilize information from both representations are becoming increasingly popular. However, due to their fundamentally different nature, drawing correlations between these data formats is a computationally difficult task, especially in a large-scale setting. In this work, we present a new data representation which combines both reference frames into a joint Eulerian-Lagrangian format. By reorganizing Lagrangian information according to the Eulerian simulation grid into a “unit cell” based approach, we can provide an efficient out-of-core means of sampling, querying, and operating with both representations simultaneously. We also extend this design to generate multi-resolution subsets of the full data to suit the viewer's needs and provide a fast flow-aware trajectory construction scheme. We demonstrate the effectiveness of our method using three large-scale real world scientific datasets and provide insight into the types of performance gains that can be achieved.",Franz Sauer;Jinrong Xie;Kwan-Liu Ma,Franz Sauer;Jinrong Xie;Kwan-Liu Ma,"Department of Computer Science, University of California at Davis, Davis, CA;Department of Computer Science, University of California at Davis, Davis, CA;Department of Computer Science, University of California at Davis, Davis, CA",0.1109/tvcg.2009.142;10.1109/visual.1997.663930;10.1109/tvcg.2014.2346423;10.1109/tvcg.2010.156;10.1109/visual.2004.55;10.1109/tvcg.2012.274,"Flow visualization,particle data,,,,,,,,,,,volume data,,,,,,,,,,,multi-resolution,,,,large-scale data,data structures",,6,33,665,,
TVCG,2016,Lightness Constancy in Surface Visualization,10.1109/tvcg.2015.2500240,http://dx.doi.org/10.1109/TVCG.2015.2500240,2107,2121,J,"Color is a common channel for displaying data in surface visualization, but is affected by the shadows and shading used to convey surface depth and shape. Understanding encoded data in the context of surface structure is critical for effective analysis in a variety of domains, such as in molecular biology. In the physical world, lightness constancy allows people to accurately perceive shadowed colors; however, its effectiveness in complex synthetic environments such as surface visualizations is not well understood. We report a series of crowdsourced and laboratory studies that confirm the existence of lightness constancy effects for molecular surface visualizations using ambient occlusion. We provide empirical evidence of how common visualization design decisions can impact viewers' abilities to accurately identify encoded surface colors. These findings suggest that lightness constancy aids in understanding color encodings in surface visualization and reveal a correlation between visualization techniques that improve color interpretation in shadow and those that enhance perceptions of surface depth. These results collectively suggest that understanding constancy in practice can inform effective visualization design.",Danielle Albers Szafir;Alper Sarikaya 0001;Michael Gleicher,Danielle Albers Szafir;Alper Sarikaya;Michael Gleicher,"Department of Computer Sciences, University of Wisconsin-Madison, Madison, WI;Department of Computer Sciences, University of Wisconsin-Madison, Madison, WI;Department of Computer Sciences, University of Wisconsin-Madison, Madison, WI",0.1109/tvcg.2008.168;10.1109/tvcg.2007.70578;10.1109/tvcg.2011.192;10.1109/tvcg.2011.161;10.1109/tvcg.2006.115,"Color, shading,and shadow,,,,,,,,,,,lightness constancy,,,,,,,,,,,molecular visualization,,,,surface visualization,visual perception",,5,67,485,,
TVCG,2014,Perceptually Uniform Motion Space,10.1109/tvcg.2014.2322363,http://dx.doi.org/10.1109/TVCG.2014.2322363,1542,1554,J,"Flow data is often visualized by animated particles inserted into a flow field. The velocity of a particle on the screen is typically linearly scaled by the velocities in the data. However, the perception of velocity magnitude in animated particles is not necessarily linear. We present a study on how different parameters affect relative motion perception. We have investigated the impact of four parameters. The parameters consist of speed multiplier, direction, contrast type and the global velocity scale. In addition, we investigated if multiple motion cues, and point distribution, affect the speed estimation. Several studies were executed to investigate the impact of each parameter. In the initial results, we noticed trends in scale and multiplier. Using the trends for the significant parameters, we designed a compensation model, which adjusts the particle speed to compensate for the effect of the parameters. We then performed a second study to investigate the performance of the compensation model. From the second study we detected a constant estimation error, which we adjusted for in the last study. In addition, we connect our work to established theories in psychophysics by comparing our model to a model based on Stevens' Power Law.",Åsmund Birkeland;Cagatay Turkay;Ivan Viola,Åsmund Birkeland;Cagatay Turkay;Ivan Viola,"Department of Informatics, University of Bergen, Bergen, Hordaland, Norway;Department of Computer Science, City University London, Room: A304C, Northampton Square, London EC1V OHB, United Kingdom;Institute of Computer Graphics and Algorithms, Vienna University of Technology, Favoritenstrasse 9-11, E186, Vienna, Austria",,"Motion visualization,motion perception,,,,,,,,,,,animation,,,,,,,,,,,evaluation,,,,perceptual model",,4,31,938,,
TVCG,2014,Direct Isosurface Ray Casting of NURBS-Based Isogeometric Analysis,10.1109/tvcg.2014.2327977,http://dx.doi.org/10.1109/TVCG.2014.2327977,1227,1240,J,"In NURBS-based isogeometric analysis, the basis functions of a 3D model's geometric description also form the basis for the solution space of variational formulations of partial differential equations. In order to visualize the results of a NURBS-based isogeometric analysis, we developed a novel GPU-based multi-pass isosurface visualization technique which performs directly on an equivalent rational Bézier representation without the need for discretization or approximation. Our approach utilizes rasterization to generate a list of intervals along the ray that each potentially contain boundary or isosurface intersections. Depth-sorting this list for each ray allows us to proceed in front-to-back order and enables early ray termination. We detect multiple intersections of a ray with the higher-order surface of the model using a sampling-based root-isolation method. The model's surfaces and the isosurfaces always appear smooth, independent of the zoom level due to our pixel-precise processing scheme. Our adaptive sampling strategy minimizes costs for point evaluations and intersection computations. The implementation shows that the proposed approach interactively visualizes volume meshes containing hundreds of thousands of Bézier elements on current graphics hardware. A comparison to a GPU-based ray casting implementation using spatial data structures indicates that our approach generally performs significantly faster while being more accurate.",Andre Schollmeyer;Bernd Froehlich 0001,Andre Schollmeyer;Bernd Froehlich,Virtual Reality Systems Group at the Bauhaus-Universität Weimar;Virtual Reality Systems Group at the Bauhaus-Universität Weimar,0.1109/tvcg.2006.154;10.1109/visual.2003.1250390;10.1109/tvcg.2007.70566;10.1109/tvcg.2012.206;10.1109/tvcg.2012.218;10.1109/visual.2000.885683,"Computer graphics,data visualization,,,,,,,,,,,isosurfaces,,,,,,,,,,,NURBS,,,,ray casting",,3,37,439,,
TVCG,2015,VectorLens: Angular Selection of Curves within 2D Dense Visualizations,10.1109/tvcg.2014.2362543,http://dx.doi.org/10.1109/TVCG.2014.2362543,402,412,J,"We investigate the selection of curves within a 2D visualization by specifying their angle or slope. Such angular selection has applications in parallel coordinates, time series visualizations, spatio-temporal movement data, etc. Our interaction technique specifies a region of interest in the visualization (with a position and diameter), a direction, and an angular tolerance, all with a single drag. We experimentally compared this angular selection technique with other techniques for selecting curves, and found that angular selection resulted in a higher number of trials that were successful on the first attempt and fewer incorrectly selected curves, and was also subjectively preferred by participants. We then present the design of a popup lens widget, called the VectorLens, that allows for easy angular selection and also allows the user to perform additional filtering operations based on type of curve. Multiple VectorLens widgets can also be instantiated to combine the results of their filtering operations with boolean operators.",Maxime Dumas;Michael J. McGuffin;Patrick Chassé,Maxime Dumas;Michael J. McGuffin;Patrick Chassé,"Croesus Finansoft, Laval, QC, Canada;Ecole de Technologie Superieure of Montreal, Montreal, QC, Canada;Croesus Finansoft, Laval, QC, Canada",0.1109/infvis.2002.1173157;10.1109/tvcg.2006.138;10.1109/tvcg.2011.237,"Information Visualization,Finance Visualization,,,,,,,,,,,Interaction Technique,,,,,,,,,,,Selection Technique,,,,Curves,Information visualization,finance visualization,interaction technique,selection technique,curves selection",,4,31,621,,
TVCG,2019,Tensor Decompositions for Integral Histogram Compression and Look-Up,10.1109/tvcg.2018.2802521,http://dx.doi.org/10.1109/TVCG.2018.2802521,1435,1446,J,"Histograms are a fundamental tool for multidimensional data analysis and processing, and many applications in graphics and visualization rely on computing histograms over large regions of interest (ROI). Integral histograms (IH) greatly accelerate the calculation in the case of rectangular regions, but come at a large extra storage cost. Based on the tensor train decomposition model, we propose a new compression and approximate retrieval algorithm to reduce the overall IH memory usage by several orders of magnitude at a user-defined accuracy. To this end we propose an incremental tensor decomposition algorithm that allows us to compress integral histograms of hundreds of gigabytes. We then encode the borders of any desired rectangular ROI in the IH tensor-compressed domain and reconstruct the target histogram at a high speed which is independent of the region size. We furthermore generalize the algorithm to support regions of arbitrary shape rather than only rectangles, as well as histogram field computation, i.e., recovering many histograms at once. We test our method with several multidimensional data sets and demonstrate that it radically speeds up costly histogram queries while avoiding storing massive, uncompressed IHs.",Rafael Ballester-Ripoll;Renato Pajarola,Rafael Ballester-Ripoll;Renato Pajarola,"Department of Informatics, University of Zürich, Zürich, Switzerland;Department of Informatics, University of Zürich, Zürich, Switzerland",0.1109/tvcg.2014.2346324;10.1109/tvcg.2011.198;10.1109/tvcg.2011.214;10.1109/tvcg.2013.152;10.1109/tvcg.2010.131,"Integral histograms,tensor decomposition,,,,,,,,,,,multidimensional compression",,3,44,441,,
TVCG,2019,Visualizing a Thinker's Life,10.1109/tvcg.2018.2824822,http://dx.doi.org/10.1109/TVCG.2018.2824822,1803,1816,J,"This paper presents a visualization framework that aids readers in understanding and analyzing the contents of medium-sized text collections that are typical for the opus of a single or few authors. We contribute several document-based visualization techniques to facilitate the exploration of the work of the German author Bazon Brock by depicting various aspects of its texts, such as the TextGenetics that shows the structure of the collection along with its chronology. The ConceptCircuit augments the TextGenetics with entities - persons and locations that were crucial to his work. All visualizations are sensitive to a wildcard-based phrase search that allows complex requests towards the author's work. Further development, as well as expert reviews and discussions with the author Bazon Brock, focused on the assessment and comparison of visualizations based on automatic topic extraction against ones that are based on expert knowledge.",Patrick Riehmann;Dora Kiesel;Martin Kohlhaas;Bernd Froehlich 0001,Patrick Riehmann;Dora Kiesel;Martin Kohlhaas;Bernd Froehlich,"Virtual Reality and Visualization Research Group, Bauhaus-Universität Weimar, Weimar, Germany;Virtual Reality and Visualization Research Group, Bauhaus-Universität Weimar, Weimar, Germany;Kohlhaas & Kohlhaas Agency in Weimar, Weimar, Germany;Virtual Reality and Visualization Research Group, Bauhaus-Universität Weimar, Weimar, Germany",0.1109/tvcg.2010.194;10.1109/vast.2012.6400485;10.1109/vast.2007.4388991;10.1109/tvcg.2013.212;10.1109/vast.2009.5333443;10.1109/vast.2014.7042493;10.1109/tvcg.2010.154;10.1109/tvcg.2011.239;10.1109/tvcg.2013.221;10.1109/tvcg.2008.172;10.1109/vast.2007.4389004,"Glyph-based techniques,text and document data,,,,,,,,,,,coordinated and multiple views",,2,58,802,,
TVCG,2018,PETMiner—A Visual Analysis Tool for Petrophysical Properties of Core Sample Data,10.1109/tvcg.2017.2682865,http://dx.doi.org/10.1109/TVCG.2017.2682865,1728,1741,J,"The aim of the PETMiner software is to reduce the time and monetary cost of analysing petrophysical data that is obtained from reservoir sample cores. Analysis of these data requires tacit knowledge to fill `gaps' so that predictions can be made for incomplete data. Through discussions with 30 industry and academic specialists, we identified three analysis use cases that exemplified the limitations of current petrophysics analysis tools. We used those use cases to develop nine core requirements for PETMiner, which is innovative because of its ability to display detailed images of the samples as data points, directly plot multiple sample properties and derived measures for comparison, and substantially reduce interaction cost. An 11-month evaluation demonstrated benefits across all three use cases by allowing a consultant to: (1) generate more accurate reservoir flow models, (2) discover a previously unknown relationship between one easy-to-measure property and another that is costly, and (3) make a 100-fold reduction in the time required to produce plots for a report.",David Graham Harrison;Nicholas D. Efford;Quentin J. Fisher;Roy A. Ruddle,Dave Graham Harrison;Nick D. Efford;Quentin J. Fisher;Roy Alan Ruddle,"Department of Computing, University of Leeds, Leeds, United Kingdom;Department of Computing, University of Leeds, Leeds, United Kingdom;Department of Petroleum Geoengineering, University of Leeds, Leeds, United Kingdom;School of Computing, University of Leeds, Leeds, United Kingdom",0.1109/tvcg.2010.190;10.1109/tvcg.2014.2346626;10.1109/tvcg.2010.223;10.1109/tvcg.2011.248;10.1109/tvcg.2008.109;10.1109/tvcg.2009.153;10.1109/tvcg.2015.2467191;10.1109/tvcg.2007.70594;10.1109/tvcg.2012.213;10.1109/tvcg.2013.124;10.1109/tvcg.2013.126,"Visualization systems and software,information visualization,,,,,,,,,,,design study",,2,39,587,,
TVCG,2012,Empirical Studies in Information Visualization: Seven Scenarios,10.1109/tvcg.2011.279,http://dx.doi.org/10.1109/TVCG.2011.279,1520,1536,J,"We take a new, scenario-based look at evaluation in information visualization. Our seven scenarios, evaluating visual data analysis and reasoning, evaluating user performance, evaluating user experience, evaluating environments and work practices, evaluating communication through visualization, evaluating visualization algorithms, and evaluating collaborative data analysis were derived through an extensive literature review of over 800 visualization publications. These scenarios distinguish different study goals and types of research questions and are illustrated through example studies. Through this broad survey and the distillation of these scenarios, we make two contributions. One, we encapsulate the current practices in the information visualization research community and, two, we provide a different approach to reaching decisions about what might be the most effective evaluation of a given information visualization. Scenarios can be used to choose appropriate research questions and goals and the provided examples can be consulted for guidance on how to design one's own study.",Heidi Lam;Enrico Bertini;Petra Isenberg;Catherine Plaisant;Sheelagh Carpendale,Heidi Lam;Enrico Bertini;Petra Isenberg;Catherine Plaisant;Sheelagh Carpendale,"Google, Inc., Mountain View, CA, USA;Department of Computer and Information Science, University of Konstanz, Konstanz, Germany;Team Aviz, INRIA, Université Paris-Sud, Orsay, France;University of Maryland, College Park, MD, USA;Department of Computer Science, University of Calgary, Calgary, AB, Canada",0.1109/vast.2010.5652880;10.1109/infvis.2003.1249031;10.1109/tvcg.2007.70539;10.1109/tvcg.2008.127;10.1109/tvcg.2007.70541;10.1109/vast.2008.4677358;10.1109/infvis.2004.5;10.1109/tvcg.2010.164;10.1109/vast.2010.5652879;10.1109/vast.2009.5332595;10.1109/tvcg.2007.70589;10.1109/tvcg.2007.70577;10.1109/infvis.2004.15;10.1109/tvcg.2009.111;10.1109/tvcg.2009.130;10.1109/tvcg.2009.140;10.1109/tvcg.2007.70596;10.1109/infvis.2004.8;10.1109/infvis.2004.68;10.1109/tvcg.2007.70594;10.1109/infvis.2000.885102;10.1109/vast.2009.5333878;10.1109/vast.2007.4388990,"Information visualization,evaluation.",,412,95,9361,,
CG&A,2016,VTK-m: Accelerating the Visualization Toolkit for Massively Threaded Architectures,10.1109/mcg.2016.48,http://dx.doi.org/10.1109/MCG.2016.48,48,58,MAG,"One of the most critical challenges for high-performance computing (HPC) scientific visualization is execution on massively threaded processors. Of the many fundamental changes we are seeing in HPC systems, one of the most profound is a reliance on new processor types optimized for execution bandwidth over latency hiding. Our current production scientific visualization software is not designed for these new types of architectures. To address this issue, the VTK-m framework serves as a container for algorithms, provides flexible data representation, and simplifies the design of visualization algorithms on new and future computer architecture.",Kenneth Moreland;Christopher M. Sewell;William Usher 0001;Li-Ta Lo;Jeremy S. Meredith;David Pugmire;James Kress;Hendrik A. Schroots;Kwan-Liu Ma;Hank Childs;Matthew Larsen;Chun-Ming Chen;Robert Maynard;Berk Geveci,Kenneth Moreland;Christopher Sewell;William Usher;Li-ta Lo;Jeremy Meredith;David Pugmire;James Kress;Hendrik Schroots;Kwan-Liu Ma;Hank Childs;Matthew Larsen;Chun-Ming Chen;Robert Maynard;Berk Geveci,"Sandia National Laboratories;Los Alamos National Laboratory;University of Utah;Los Alamos National Laboratory;Oak Ridge National Laboratory;Oak Ridge National Laboratory;University of Oregon;Intel;University of California, Davis;University of Oregon;Lawrence Livermore National Laboratory;Ohio State University;Kitware;Kitware",0.1109/visual.1999.809891,"computer graphics,high-performance computing,,,,,,,,,,,visualization software,,,,,,,,,,,parallel algorithms,,,,algorithmic structures,massively threaded processors,VTK-m framework",,98,13,1714,,
TVCG,2019,Visualization of Cultural Heritage Collection Data: State of the Art and Future Challenges,10.1109/tvcg.2018.2830759,http://dx.doi.org/10.1109/TVCG.2018.2830759,2311,2330,J,"After decades of digitization, large cultural heritage collections have emerged on the web, which contain massive stocks of content from galleries, libraries, archives, and museums. This increase in digital cultural heritage data promises new modes of analysis and increased levels of access for academic scholars and casual users alike. Going beyond the standard representations of search-centric and grid-based interfaces, a multitude of approaches has recently started to enable visual access to cultural collections, and to explore them as complex and comprehensive information spaces by the means of interactive visualizations. In contrast to conventional web interfaces, we witness a widening spectrum of innovative visualization types specially designed for rich collections from the cultural heritage sector. This new class of information visualizations gives rise to a notable diversity of interaction and representation techniques while lending currency and urgency to a discussion about principles such as serendipity, generosity, and criticality in connection with visualization design. With this survey, we review information visualization approaches to digital cultural heritage collections and reflect on the state of the art in techniques and design choices. We contextualize our survey with humanist perspectives on the field and point out opportunities for future research.",Florian Windhager;Paolo Federico 0001;Günther Schreder;Katrin Glinka;Marian Dörk;Silvia Miksch;Eva Mayr,Florian Windhager;Paolo Federico;Günther Schreder;Katrin Glinka;Marian Dörk;Silvia Miksch;Eva Mayr,"Department of Knowledge and Communication Management, Danube University Krems, Krems an der Donau, Austria;Institute of Software Technology and Interactive Systems, Vienna University of Technology, Wien, Austria;Department of Knowledge and Communication Management, Danube University Krems, Krems an der Donau, Austria;Stiftung Preussischer Kulturbesitz, Berlin, Berlin;Urban Complexity Lab, University of Applied Sciences, Potsdam, Germany;Institute of Software Technology and Interactive Systems, Vienna University of Technology, Wien, Austria;Department of Knowledge and Communication Management, Danube University Krems, Krems an der Donau, Austria",0.1109/tvcg.2015.2467971;10.1109/tvcg.2015.2467620;10.1109/tvcg.2016.2610422;10.1109/tvcg.2008.127;10.1109/tvcg.2010.136;10.1109/tvcg.2010.179;10.1109/tvcg.2015.2467752;10.1109/tvcg.2009.111;10.1109/tvcg.2012.244;10.1109/tvcg.2013.219;10.1109/tvcg.2012.252;10.1109/tvcg.2007.70541;10.1109/tvcg.2015.2467452;10.1109/tvcg.2011.255;10.1109/mcg.2017.377152546,"Information visualization,introductory and survey,,,,,,,,,,,digital libraries,,,,,,,,,,,arts and humanities",,91,166,14806,,
CG&A,2014,Visualization beyond the Desktop--the Next Big Thing,10.1109/mcg.2014.82,http://dx.doi.org/10.1109/MCG.2014.82,26,34,MAG,"Visualization is coming of age. With visual depictions being seamlessly integrated into documents, and data visualization techniques being used to understand increasingly large and complex datasets, the term ""visualization""' is becoming used in everyday conversations. But we are on a cusp; visualization researchers need to develop and adapt to today's new devices and tomorrow's technology. Today, people interact with visual depictions through a mouse. Tomorrow, they'll be touching, swiping, grasping, feeling, hearing, smelling, and even tasting data. The next big thing is multisensory visualization that goes beyond the desktop.",Jonathan C. Roberts;Panagiotis D. Ritsos;Sriram Karthik Badam;Dominique Brodbeck;Jessie Kennedy;Niklas Elmqvist,Jonathan C. Roberts;Panagiotis D. Ritsos;Sriram Karthik Badam;Dominique Brodbeck;Jessie Kennedy;Niklas Elmqvist,"Bangor University;Bangor University;University of Maryland, College Park;University of Applied Sciences and Arts Northwestern, Switzerland;Edinburgh Napier University;University of Maryland, College Park",0.1109/tvcg.2007.70541;10.1109/tvcg.2013.166,"multisensory visualization,computer graphics,input devices,proxemics,spatial interfaces,casual visualization,appropriated surfaces,Kinect,Oculus Rift,Google Glass,affective computing,ubiquitous computing,graphics,mobile visualization,Web visualization,virtual environments,reality-virtuality continuum,visual analytics,,,,,,multimedia,,,,mixed reality,augmented reality,augmented virtuality,human-computer interaction,information visualization,visualization",,84,25,3493,,
CG&A,2015,Characterizing Visualization Insights from Quantified Selfers' Personal Data Presentations,10.1109/mcg.2015.51,http://dx.doi.org/10.1109/MCG.2015.51,28,37,MAG,"Data visualization and analytics research has great potential to empower people to improve their lives by leveraging their own personal data. However, most quantified selfers (Q-Selfers) are neither visualization experts nor data scientists. Consequently, visualizations Q-Selfers created with their data are often not ideal for conveying insights. Aiming to design a visualization system to help nonexperts gain and communicate personal data insights, the authors conducted a predesign empirical study. Through the lens of Q-Selfers, they examined what insights people gain specifically from their personal data and how they use visualizations to communicate their insights. Based on their analysis of 30 quantified self-presentations, they characterized eight insight types (detail, self-reflection, trend, comparison, correlation, data summary, distribution, and outlier) and mapped the visual annotations used to communicate them. They further discussed four areas for the design of personal visualization systems, including support for encouraging self-reflection, gaining valid insight, communicating insight, and using visual annotations.",Eun Kyoung Choe;Bongshin Lee;m. c. schraefel,Eun Kyoung Choe;Bongshin Lee;m.c. schraefel,Pennsylvania State University;Microsoft Research;University of Southampton,0.1109/tvcg.2007.70594;10.1109/tvcg.2013.191;10.1109/tvcg.2010.164;10.1109/tvcg.2014.2359887,"computer graphics,visualization insights,,,,,,,,,,,personal information visualization,,,,,,,,,,,quantified self,,,,quantified selfers,personal informatics",,67,17,2908,,
TVCG,2014,An Evaluation of Depth Enhancing Perceptual Cues for Vascular Volume Visualization in Neurosurgery,10.1109/tvcg.2013.240,http://dx.doi.org/10.1109/TVCG.2013.240,391,403,J,"Cerebral vascular images obtained through angiography are used by neurosurgeons for diagnosis, surgical planning, and intraoperative guidance. The intricate branching of the vessels and furcations, however, make the task of understanding the spatial three-dimensional layout of these images challenging. In this paper, we present empirical studies on the effect of different perceptual cues (fog, pseudo-chromadepth, kinetic depth, and depicting edges) both individually and in combination on the depth perception of cerebral vascular volumes and compare these to the cue of stereopsis. Two experiments with novices and one experiment with experts were performed. The results with novices showed that the pseudo-chromadepth and fog cues were stronger cues than that of stereopsis. Furthermore, the addition of the stereopsis cue to the other cues did not improve relative depth perception in cerebral vascular volumes. In contrast to novices, the experts also performed well with the edge cue. In terms of both novice and expert subjects, pseudo-chromadepth and fog allow for the best relative depth perception. By using such cues to improve depth perception of cerebral vasculature, we may improve diagnosis, surgical planning, and intraoperative guidance.",Marta Kersten-Oertel;Sean Jy-Shyang Chen;D. Louis Collins,Marta Kersten-Oertel;Sean Jy-Shyang Chen;D. Louis Collins,"Department of Biomedical Engineering, Montreal Neurological Institute, Montreal, QC, Canada;Department of Biomedical Engineering, Montreal Neurological Institute, Montreal, QC, Canada;Department of Biomedical Engineering, Montreal Neurological Institute, Montreal, QC, Canada",0.1109/tvcg.2006.172;10.1109/visual.2000.885692;10.1109/tvcg.2007.70555;10.1109/tvcg.2012.144;10.1109/visual.1995.480795;10.1109/tvcg.2006.139;10.1109/tvcg.2008.123,"Depth cues,stereo,,,,,,,,,,,chromadepth,,,,,,,,,,,fog,,,,volume rendering,vascular data,vessels,angiography",,64,45,1212,,
TVCG,2016,Online Visual Analytics of Text Streams,10.1109/tvcg.2015.2509990,http://dx.doi.org/10.1109/TVCG.2015.2509990,2451,2466,J,"We present an online visual analytics approach to helping users explore and understand hierarchical topic evolution in high-volume text streams. The key idea behind this approach is to identify representative topics in incoming documents and align them with the existing representative topics that they immediately follow (in time). To this end, we learn a set of streaming tree cuts from topic trees based on user-selected focus nodes. A dynamic Bayesian network model has been developed to derive the tree cuts in the incoming topic trees to balance the fitness of each tree cut and the smoothness between adjacent tree cuts. By connecting the corresponding topics at different times, we are able to provide an overview of the evolving hierarchical topics. A sedimentation-based visualization has been designed to enable the interactive analysis of streaming text data from global patterns to local details. We evaluated our method on real-world datasets and the results are generally favorable.",Shixia Liu;Jialun Yin;Xiting Wang;Weiwei Cui;Kelei Cao;Jian Pei,Shixia Liu;Jialun Yin;Xiting Wang;Weiwei Cui;Kelei Cao;Jian Pei,"School of Software, Tsinghua University;Tsinghua University;Tsinghua University;Microsoft Research;Tsinghua University;Simon Fraser University, Burnaby, BC, Canada",0.1109/tvcg.2012.225;10.1109/tvcg.2014.2346919;10.1109/tvcg.2011.239;10.1109/tvcg.2014.2346433;10.1109/tvcg.2008.135;10.1109/vast.2011.6102461;10.1109/vast.2012.6400485;10.1109/tvcg.2013.162;10.1109/tvcg.2014.2346922;10.1109/tvcg.2013.227;10.1109/tvcg.2013.221,"Streaming text data,evolutionary tree clustering,,,,,,,,,,,streaming tree cut,,,,,,,,,,,streaming topic visualization",,58,46,1311,,
TVCG,2012,Visual Reasoning about Social Networks Using Centrality Sensitivity,10.1109/tvcg.2010.260,http://dx.doi.org/10.1109/TVCG.2010.260,106,120,J,"In this paper, we study the sensitivity of centrality metrics as a key metric of social networks to support visual reasoning. As centrality represents the prestige or importance of a node in a network, its sensitivity represents the importance of the relationship between this and all other nodes in the network. We have derived an analytical solution that extracts the sensitivity as the derivative of centrality with respect to degree for two centrality metrics based on feedback and random walks. We show that these sensitivities are good indicators of the distribution of centrality in the network, and how changes are expected to be propagated if we introduce changes to the network. These metrics also help us simplify a complex network in a way that retains the main structural properties and that results in trustworthy, readable diagrams. Sensitivity is also a key concept for uncertainty analysis of social networks, and we show how our approach may help analysts gain insight on the robustness of key network metrics. Through a number of examples, we illustrate the need for measuring sensitivity, and the impact it has on the visualization of and interaction with social and other scale-free networks.",Carlos D. Correa;Tarik Crnovrsanin;Kwan-Liu Ma,Carlos Correa;Tarik Crnovrsanin;Kwan-Liu Ma,"University of California,슠Davis, USA;University of California,슠Davis, USA;University of California Davis, USA",0.1109/tvcg.2009.108;10.1109/tvcg.2006.147;10.1109/infvis.2005.1532126;10.1109/tvcg.2008.151,"Social network visualization,centrality,,,,,,,,,,,sensitivity analysis,,,,,,,,,,,eigenvector and Markov importance.",,56,48,1667,,
TVCG,2013,Combining Computational Analyses and Interactive Visualization for Document Exploration and Sensemaking in Jigsaw,10.1109/tvcg.2012.324,http://dx.doi.org/10.1109/TVCG.2012.324,1646,1663,J,"Investigators across many disciplines and organizations must sift through large collections of text documents to understand and piece together information. Whether they are fighting crime, curing diseases, deciding what car to buy, or researching a new field, inevitably investigators will encounter text documents. Taking a visual analytics approach, we integrate multiple text analysis algorithms with a suite of interactive visualizations to provide a flexible and powerful environment that allows analysts to explore collections of documents while sensemaking. Our particular focus is on the process of integrating automated analyses with interactive visualizations in a smooth and fluid manner. We illustrate this integration through two example scenarios: An academic researcher examining InfoVis and VAST conference papers and a consumer exploring car reviews while pondering a purchase decision. Finally, we provide lessons learned toward the design and implementation of visual analytics systems for document exploration and understanding.",Carsten Görg;Zhicheng Liu 0001;Jaeyeon Kihm;Jaegul Choo;Haesun Park;John T. Stasko,Carsten Görg;Zhicheng Liu;Jaeyeon Kihm;Jaegul Choo;Haesun Park;John Stasko,"Computational Bioscience Program, University of Colorado, Aurora, CO, USA;Department of Computer Science, Stanford University, Stanford, CA, USA;Cornell CIS, Ithaca, NY, USA;School of Computational Science and Engineering, College of Computing, Georgia Institute of Technology, Atlanta, GA, USA;School of Computational Science and Engineering, College of Computing, Georgia Institute of Technology, Atlanta, GA, USA;School of Interactive Computing, Georgia Institute of Technology, Atlanta, GA, USA",0.1109/tvcg.2009.165;10.1109/tvcg.2011.239;10.1109/vast.2009.5333443;10.1109/tvcg.2008.172;10.1109/infvis.2000.885098;10.1109/tvcg.2009.171;10.1109/infvis.2002.1173155;10.1109/vast.2007.4389034;10.1109/vast.2009.5333248;10.1109/tvcg.2012.224;10.1109/vast.2007.4389004;10.1109/tvcg.2010.154;10.1109/vast.2008.4677359;10.1109/vast.2009.5333919,"Visual analytics,information visualization,,,,,,,,,,,sensemaking,,,,,,,,,,,exploratory search,,,,information seeking,document analysis",,56,70,3697,,
TVCG,2019,A Generative Model for Volume Rendering,10.1109/tvcg.2018.2816059,http://dx.doi.org/10.1109/TVCG.2018.2816059,1636,1650,J,"We present a technique to synthesize and analyze volume-rendered images using generative models. We use the Generative Adversarial Network (GAN) framework to compute a model from a large collection of volume renderings, conditioned on (1) viewpoint and (2) transfer functions for opacity and color. Our approach facilitates tasks for volume analysis that are challenging to achieve using existing rendering techniques such as ray casting or texture-based methods. We show how to guide the user in transfer function editing by quantifying expected change in the output image. Additionally, the generative model transforms transfer functions into a view-invariant latent space specifically designed to synthesize volume-rendered images. We use this space directly for rendering, enabling the user to explore the space of volume-rendered images. As our model is independent of the choice of volume rendering process, we show how to analyze volume-rendered images produced by direct and global illumination lighting, for a variety of volume datasets.",Matthew Berger;Jixian Li;Joshua A. Levine,Matthew Berger;Jixian Li;Joshua A. Levine,"Department of Computer Science, University of Arizona, Tucson, AZ;Department of Computer Science, University of Arizona, Tucson, AZ;Department of Computer Science, University of Arizona, Tucson, AZ",0.1109/tvcg.2010.215;10.1109/tvcg.2011.261;10.1109/tvcg.2011.173;10.1109/tvcg.2012.227;10.1109/tvcg.2009.185;10.1109/visual.2003.1250414;10.1109/tvcg.2006.148;10.1109/tvcg.2009.189;10.1109/tvcg.2008.162;10.1109/tvcg.2016.2599041;10.1109/tvcg.2015.2467294,"Volume rendering,generative models,,,,,,,,,,,deep learning,,,,,,,,,,,generative adversarial networks",,55,53,1716,,
TVCG,2019,Bridging Text Visualization and Mining: A Task-Driven Survey,10.1109/tvcg.2018.2834341,http://dx.doi.org/10.1109/TVCG.2018.2834341,2482,2504,J,"Visual text analytics has recently emerged as one of the most prominent topics in both academic research and the commercial world. To provide an overview of the relevant techniques and analysis tasks, as well as the relationships between them, we comprehensively analyzed 263 visualization papers and 4,346 mining papers published between 1992-2017 in two fields: visualization and text mining. From the analysis, we derived around 300 concepts (visualization techniques, mining techniques, and analysis tasks) and built a taxonomy for each type of concept. The co-occurrence relationships between the concepts were also extracted. Our research can be used as a stepping-stone for other researchers to 1) understand a common set of concepts used in this research topic; 2) facilitate the exploration of the relationships between visualization techniques, mining techniques, and analysis tasks; 3) understand the current practice in developing visual text analytics tools; 4) seek potential research opportunities by narrowing the gulf between visualization and mining techniques based on the analysis tasks; and 5) analyze other interdisciplinary research areas in a similar way. We have also contributed a web-based visualization tool for analyzing and understanding research trends and opportunities in visual text analytics.",Shixia Liu;Xiting Wang;Christopher Collins 0001;Wenwen Dou;Fang-Xin Ou-Yang;Mennatallah El-Assady;Liu Jiang;Daniel A. Keim,Shixia Liu;Xiting Wang;Christopher Collins;Wenwen Dou;Fangxin Ouyang;Mennatallah El-Assady;Liu Jiang;Daniel A. Keim,"Tsinghua University, Beijing, P. R. China;Microsoft Research, Beijing, China;University of Ontario, University of Ontario, Oshawa, ON, Canada;University of North Carolina at Charlotte, Charlotte, NC;Tsinghua University, Beijing, P. R. China;University of Konstanz, Konstanz, Germany;Tsinghua University, Beijing, P. R. China;University of Konstanz, Konstanz, Germany",0.1109/infvis.2001.963287;10.1109/vast.2007.4389006;10.1109/vast.2009.5333248;10.1109/tvcg.2009.165;10.1109/tvcg.2012.225;10.1109/tvcg.2012.291;10.1109/tvcg.2014.2346433;10.1109/vast.2007.4389002;10.1109/tvcg.2016.2598465;10.1109/vast.2016.7883507;10.1109/vast.2015.7347631;10.1109/tvcg.2011.239;10.1109/tvcg.2012.277;10.1109/tvcg.2012.324;10.1109/vast.2016.7883511;10.1109/tvcg.2012.226;10.1109/tvcg.2014.2346920;10.1109/tvcg.2008.172;10.1109/vast.2015.7347637;10.1109/tvcg.2014.2346431;10.1109/tvcg.2013.162;10.1109/tvcg.2013.212;10.1109/tvcg.2016.2598827;10.1109/tvcg.2016.2598667;10.1109/tvcg.2015.2467757;10.1109/tvcg.2013.186;10.1109/vast.2006.261431;10.1109/tvcg.2010.154;10.1109/vast.2010.5652932;10.1109/tvcg.2009.171;10.1109/vast.2014.7042492;10.1109/vast.2008.4677362;10.1109/vast.2017.8585505;10.1109/tvcg.2016.2598831;10.1109/vast.2012.6400557;10.1109/vast.2010.5652896;10.1109/tvcg.2012.264;10.1109/tvcg.2017.2744378;10.1109/tvcg.2016.2598829;10.1109/tvcg.2014.2346743;10.1109/tvcg.2017.2744318;10.1109/tvcg.2014.2346747;10.1109/tvcg.2015.2467554;10.1109/tvcg.2016.2598444;10.1109/vast.2009.5333428;10.1109/tvcg.2015.2509990;10.1109/tvcg.2015.2467811;10.1109/tvcg.2016.2598445;10.1109/tvcg.2014.2346677;10.1109/tvcg.2015.2467991;10.1109/vast.2014.7042495;10.1109/tvcg.2015.2467555;10.1109/vast.2011.6102456;10.1109/tvcg.2007.70570;10.1109/tvcg.2015.2467452;10.1109/tvcg.2016.2598590;10.1109/tvcg.2010.194;10.1109/tvcg.2010.175;10.1109/vast.2007.4389004;10.1109/vast.2010.5652926;10.1109/vast.2006.261417;10.1109/infvis.1998.729570;10.1109/tvcg.2011.100;10.1109/vast.2012.6400484;10.1109/vast.2012.6400560;10.1109/tvcg.2016.2598447;10.1109/vast.2009.5333443;10.1109/tvcg.2017.2745080;10.1109/vast.2010.5652922;10.1109/vast.2008.4677359;10.1109/tvcg.2009.139;10.1109/vast.2009.5333919;10.1109/vast.2012.6400485;10.1109/tvcg.2014.2388208;10.1109/tvcg.2013.167;10.1109/tvcg.2015.2467971;10.1109/tvcg.2015.2467621;10.1109/infvis.2000.885098;10.1109/tvcg.2011.179;10.1109/vast.2010.5652931;10.1109/tvcg.2014.2346919;10.1109/tvcg.2008.178;10.1109/tvcg.2012.89;10.1109/tvcg.2015.2467620;10.1109/tvcg.2015.2467531;10.1109/tvcg.2013.242;10.1109/tvcg.2009.140;10.1109/vast.2009.5333437;10.1109/vast.2008.4677364;10.1109/tvcg.2016.2615308;10.1109/tvcg.2010.179;10.1109/infvis.2000.885099;10.1109/tvcg.2006.111;10.1109/tvcg.2012.250;10.1109/tvcg.2014.2346913;10.1109/mcg.2017.21;10.1109/tvcg.2013.221;10.1109/tvcg.2008.175;10.1109/tvcg.2015.2467618;10.1109/tvcg.2007.70592;10.1109/vast.2016.7883513;10.1109/visual.1992.235198;10.1109/tvcg.2017.2745118;10.1109/vast.2011.6102461;10.1109/tvcg.2009.122;10.1109/infvis.1996.559219;10.1109/vast.2010.5652940;10.1109/infvis.1998.729568;10.1109/tvcg.2016.2610422;10.1109/tvcg.2010.183;10.1109/tvcg.2016.2598495;10.1109/tvcg.2008.138;10.1109/infvis.1996.559228;10.1109/tvcg.2014.2346922;10.1109/vast.2014.7042496,"Visualization,visual text analytics,,,,,,,,,,,text mining",,53,377,3141,,
TVCG,2014,Similarity Preserving Snippet-Based Visualization of Web Search Results,10.1109/tvcg.2013.242,http://dx.doi.org/10.1109/TVCG.2013.242,457,470,J,"Internet users are very familiar with the results of a search query displayed as a ranked list of snippets. Each textual snippet shows a content summary of the referred document (or webpage) and a link to it. This display has many advantages, for example, it affords easy navigation and is straightforward to interpret. Nonetheless, any user of search engines could possibly report some experience of disappointment with this metaphor. Indeed, it has limitations in particular situations, as it fails to provide an overview of the document collection retrieved. Moreover, depending on the nature of the query for example, it may be too general, or ambiguous, or ill expressed the desired information may be poorly ranked, or results may contemplate varied topics. Several search tasks would be easier if users were shown an overview of the returned documents, organized so as to reflect how related they are, content wise. We propose a visualization technique to display the results of web queries aimed at overcoming such limitations. It combines the neighborhood preservation capability of multidimensional projections with the familiar snippet-based representation by employing a multidimensional projection to derive two-dimensional layouts of the query search results that preserve text similarity relations, or neighborhoods. Similarity is computed by applying the cosine similarity over a ""bag-of-wordsâ' vector representation of collection built from the snippets. If the snippets are displayed directly according to the derived layout, they will overlap considerably, producing a poor visualization. We overcome this problem by defining an energy functional that considers both the overlapping among snippets and the preservation of the neighborhood structure as given in the projected layout. Minimizing this energy functional provides a neighborhood preserving two-dimensional arrangement of the textual snippets with minimum overlap. The resulting visualization conveys both a global view of the query results and visual groupings that reflect related results, as illustrated in several examples shown.",Erick Gomez Nieto;Frizzi San Roman;Paulo A. Pagliosa;Wallace Casaca;Elias S. Helou;Maria Cristina Ferreira de Oliveira;Luis Gustavo Nonato,Erick Gomez-Nieto;Frizzi San Roman;Paulo Pagliosa;Wallace Casaca;Elias S. Helou;Maria Cristina F. de Oliveira;Luis Gustavo Nonato,"Universidade de São Paulo, Instituto de Ciências Matemáticas e de Computação (ICMC), São Carlos, SP, Brazil;Universidade de São Paulo, Instituto de Ciências Matemáticas e de Computação (ICMC), São Carlos, SP, Brazil;Faculdade de Computação, Universidade Federal de Mato Grosso do Sul, Campo Grande, MP, Brazil;Universidade de São Paulo, Instituto de Ciências Matemáticas e de Computação (ICMC), São Carlos, SP, Brazil;Universidade de São Paulo, Instituto de Ciências Matemáticas e de Computação (ICMC), São Carlos, SP, Brazil;Universidade de São Paulo, Instituto de Ciências Matemáticas e de Computação (ICMC), São Carlos, SP, Brazil;Universidade de São Paulo, Instituto de Ciências Matemáticas e de Computação (ICMC), São Carlos, SP, Brazil",0.1109/tvcg.2006.111;10.1109/infvis.2004.56;10.1109/tvcg.2008.175;10.1109/tvcg.2009.176;10.1109/tvcg.2011.220,"Multidimensional projection,web search visualization",,52,35,1649,,
TVCG,2013,Similarity Measures for Enhancing Interactive Streamline Seeding,10.1109/tvcg.2012.150,http://dx.doi.org/10.1109/TVCG.2012.150,1342,1353,J,"Streamline seeding rakes are widely used in vector field visualization. We present new approaches for calculating similarity between integral curves (streamlines and pathlines). While others have used similarity distance measures, the computational expense involved with existing techniques is relatively high due to the vast number of euclidean distance tests, restricting interactivity and their use for streamline seeding rakes. We introduce the novel idea of computing streamline signatures based on a set of curve-based attributes. A signature produces a compact representation for describing a streamline. Similarity comparisons are performed by using a popular statistical measure on the derived signatures. We demonstrate that this novel scheme, including a hierarchical variant, produces good clustering results and is computed over two orders of magnitude faster than previous methods. Similarity-based clustering enables filtering of the streamlines to provide a nonuniform seeding distribution along the seeding object. We show that this method preserves the overall flow behavior while using only a small subset of the original streamline set. We apply focus + context rendering using the clusters which allows for faster and easier analysis in cases of high visual complexity and occlusion. The method provides a high level of interactivity and allows the user to easily fine tune the clustering results at runtime while avoiding any time-consuming recomputation. Our method maintains interactive rates even when hundreds of streamlines are used.",Tony McLoughlin;Mark W. Jones;Robert S. Laramee;Rami Malki;Ian Masters;Charles D. Hansen,Tony McLoughlin;Mark W. Jones;Robert S. Laramee;Rami Malki;Ian Masters;Charles D. Hansen,"Visual Computing Group, Department of Computer Science, Swansea University, Swansea, UK;Visual Computing Group, Department of Computer Science, Swansea University, Swansea, UK;Visual Computing Group, Department of Computer Science, Swansea University, Swansea, UK;Marine Energy Research Group, College of Engineering, Swansea University, Swansea, UK;Marine Energy Research Group, College of Engineering, Swansea University, Swansea, UK;School of Computing, Scientific Computing and Imaging Institute, University of Utah, Salt Lake, UT, USA",0.1109/tvcg.2008.116;10.1109/tvcg.2009.141;10.1109/tvcg.2006.116;10.1109/tvcg.2010.212;10.1109/tvcg.2011.155;10.1109/tvcg.2010.170;10.1109/tvcg.2007.70595;10.1109/tvcg.2006.147;10.1109/tvcg.2011.25,"Flow visualization,clustering,,,,,,,,,,,similarity measures,,,,,,,,,,,focus+context,,,,streamlines",,49,29,1024,,
TVCG,2011,Streamline Integration Using MPI-Hybrid Parallelism on a Large Multicore Architecture,10.1109/tvcg.2010.259,http://dx.doi.org/10.1109/TVCG.2010.259,1702,1713,J,"Streamline computation in a very large vector field data set represents a significant challenge due to the nonlocal and data-dependent nature of streamline integration. In this paper, we conduct a study of the performance characteristics of hybrid parallel programming and execution as applied to streamline integration on a large, multicore platform. With multicore processors now prevalent in clusters and supercomputers, there is a need to understand the impact of these hybrid systems in order to make the best implementation choice. We use two MPI-based distribution approaches based on established parallelization paradigms, parallelize over seeds and parallelize over blocks, and present a novel MPI-hybrid algorithm for each approach to compute streamlines. Our findings indicate that the work sharing between cores in the proposed MPI-hybrid parallel implementation results in much improved performance and consumes less communication and I/O bandwidth than a traditional, nonhybrid distributed implementation.",David Camp;Christoph Garth;Hank Childs;David Pugmire;Kenneth I. Joy,David Camp;Christoph Garth;Hank Childs;David Pugmire;Kenneth Joy,"Lawrence Berkeley National Laboratory, Department of Computer Science, University of California, Davis, USA;Department of Computer Science, University of California, Davis, CA, USA;Lawrence Berkeley National Laboratory, Department of Computer Science, University of California, Davis, USA;Oak Ridge National Laboratory, USA;Department of Computer Science, University of California, Davis, CA, USA",0.1109/visual.1994.346311;10.1109/tvcg.2009.190;10.1109/visual.2004.55;10.1109/tvcg.2007.70551,"Concurrent programming,parallel programming,,,,,,,,,,,modes of computation,,,,,,,,,,,parallelism and concurrency,,,,picture/image generation,display algorithms.",,42,27,680,,
TVCG,2012,Parallel Computation of 2D Morse-Smale Complexes,10.1109/tvcg.2011.284,http://dx.doi.org/10.1109/TVCG.2011.284,1757,1770,J,The Morse-Smale complex is a useful topological data structure for the analysis and visualization of scalar data. This paper describes an algorithm that processes all mesh elements of the domain in parallel to compute the Morse-Smale complex of large 2D datasets at interactive speeds. We employ a reformulation of the Morse-Smale complex using Forman's Discrete Morse Theory and achieve scalability by computing the discrete gradient using local accesses only. We also introduce a novel approach to merge gradient paths that ensures accurate geometry of the computed complex. We demonstrate that our algorithm performs well on both multicore environments and on massively parallel architectures such as the GPU.,Nithin Shivashankar;Senthilnathan Maadasamy;Vijay Natarajan,Nithin Shivashankar;Senthilnathan M;Vijay Natarajan,"Department of Computer Science and Automation, Indian Institute of Science, Bangalore, Karnataka, India;Department of Computer Science and Automation, Indian Institute of Science, Bangalore, Karnataka, India;Supercomputer Education and Research Centre and Department of Computer Science and Automation, Indian Institute of Science, Bangalore, Karnataka, India",0.1109/tvcg.2007.70552;10.1109/tvcg.2008.110;10.1109/tvcg.2007.70603;10.1109/tvcg.2006.186,"Topology-based methods,discrete Morse theory,,,,,,,,,,,large datasets,,,,,,,,,,,gradient pairs,,,,multicore,2D scalar functions.",,47,26,575,,
TVCG,2012,Multimodal Data Fusion Based on Mutual Information,10.1109/tvcg.2011.280,http://dx.doi.org/10.1109/TVCG.2011.280,1574,1587,J,"Multimodal visualization aims at fusing different data sets so that the resulting combination provides more information and understanding to the user. To achieve this aim, we propose a new information-theoretic approach that automatically selects the most informative voxels from two volume data sets. Our fusion criteria are based on the information channel created between the two input data sets that permit us to quantify the information associated with each intensity value. This specific information is obtained from three different ways of decomposing the mutual information of the channel. In addition, an assessment criterion based on the information content of the fused data set can be used to analyze and modify the initial selection of the voxels by weighting the contribution of each data set to the final result. The proposed approach has been integrated in a general framework that allows for the exploration of volumetric data models and the interactive change of some parameters of the fused data set. The proposed approach has been evaluated on different medical data sets with very promising results.",Roger Bramon;Imma Boada;Anton Bardera;Joaquim Rodriguez;Miquel Feixas;Josep Puig;Mateu Sbert,Roger Bramon;Imma Boada;Anton Bardera;Joaquim Rodriguez;Miquel Feixas;Josep Puig;Mateu Sbert,"University of Girona, Girona, Spain;University of Girona, Girona, Spain;University of Girona, Girona, Spain;University of Girona, Girona, Spain;University of Girona, Girona, Spain;Hospital Josep Trueta of Girona, Girona, Spain;University of Girona, Girona, Spain",0.1109/tvcg.2007.70534;10.1109/visual.2005.1532834;10.1109/tvcg.2006.152;10.1109/tvcg.2008.140;10.1109/tvcg.2010.131;10.1109/visual.2003.1250412;10.1109/visual.2002.1183764;10.1109/tvcg.2007.70560,"Multimodal visualization,image fusion,,,,,,,,,,,information theory,,,,,,,,,,,mutual information.",,45,38,2569,,
CG&A,2014,From Data to Insight: Work Practices of Analysts in the Enterprise,10.1109/mcg.2014.62,http://dx.doi.org/10.1109/MCG.2014.62,42,50,MAG,"With greater availability of data, businesses are increasingly becoming data-driven enterprises, establishing standards for data acquisition, processing, infrastructure, and decision making. Enterprises now have people dedicated to performing analytic work to support decision makers. To better understand analytic work, particularly the role of enterprise business analysts, researchers interviewed 34 analysts at a large corporation. Analytical work occurred in an ecosystem of data, tools, and people; the ecosystem's overall quality and efficiency depended on the amount of coordination and collaboration. Analysts were the bridge between business and IT, closing the semantic gap between datasets, tools, and people. This article provides an overview of the analytic work in the enterprise, describing challenges in data, tools, and practices and identifying opportunities for new tools for collaborative analytics.",Eser Kandogan;Aruna Balakrishnan;Eben M. Haber;Jeffrey S. Pierce,Eser Kandogan;Aruna Balakrishnan;Eben M. Haber;Jeffrey S. Pierce,IBM Research;Google;IBM Research;Samsung Research,0.1109/vast.2011.6102438;10.1109/vast.2010.5652880;10.1109/tvcg.2012.219,"data,analysts,,,,,,,,,,,work practices,,,,,,,,,,,visualization,,,,collaboration,enterprise,computer graphics,visual analytics,graphics",,38,12,1550,,
TVCG,2012,Hierarchical Streamline Bundles,10.1109/tvcg.2011.155,http://dx.doi.org/10.1109/TVCG.2011.155,1353,1367,J,"Effective 3D streamline placement and visualization play an essential role in many science and engineering disciplines. The main challenge for effective streamline visualization lies in seed placement, i.e., where to drop seeds and how many seeds should be placed. Seeding too many or too few streamlines may not reveal flow features and patterns either because it easily leads to visual clutter in rendering or it conveys little information about the flow field. Not only does the number of streamlines placed matter, their spatial relationships also play a key role in understanding the flow field. Therefore, effective flow visualization requires the streamlines to be placed in the right place and in the right amount. This paper introduces hierarchical streamline bundles, a novel approach to simplifying and visualizing 3D flow fields defined on regular grids. By placing seeds and generating streamlines according to flow saliency, we produce a set of streamlines that captures important flow features near critical points without enforcing the dense seeding condition. We group spatially neighboring and geometrically similar streamlines to construct a hierarchy from which we extract streamline bundles at different levels of detail. Streamline bundles highlight multiscale flow features and patterns through clustered yet not cluttered display. This selective visualization strategy effectively reduces visual clutter while accentuating visual foci, and therefore is able to convey the desired insight into the flow data.",Hongfeng Yu 0001;Chaoli Wang 0001;Ching-Kuang Shene;Jacqueline H. Chen,Hongfeng Yu;Chaoli Wang;Ching-Kuang Shene;Jacqueline H. Chen,"Sandia National Laboratories, Combustion Research Facility, Livermore, CA, USA;Department of Computer Science, Michigan Technological University, Houghton, MI, USA;Department of Computer Science, Michigan Technological University, Houghton, MI, USA;Sandia National Laboratories, Combustion Research Facility, Livermore, CA, USA",0.1109/visual.2000.885690;10.1109/visual.1999.809865;10.1109/tvcg.2009.141;10.1109/visual.2003.1250414;10.1109/tvcg.2007.70595;10.1109/visual.1999.809863;10.1109/visual.2004.32;10.1109/tvcg.2006.147;10.1109/tvcg.2006.116;10.1109/tvcg.2010.131;10.1109/tvcg.2010.212;10.1109/visual.2005.1532779;10.1109/visual.2005.1532832,"Streamline bundles,flow saliency,,,,,,,,,,,seed placement,,,,,,,,,,,hierarchical clustering,,,,level-of-detail,flow visualization.",,50,44,1083,,
TVCG,2019,Commercial Visual Analytics Systems–Advances in the Big Data Analytics Field,10.1109/tvcg.2018.2859973,http://dx.doi.org/10.1109/TVCG.2018.2859973,3011,3031,J,"Five years after the first state-of-the-art report on Commercial Visual Analytics Systems we present a reevaluation of the Big Data Analytics field. We build on the success of the 2012 survey, which was influential even beyond the boundaries of the InfoVis and Visual Analytics (VA) community. While the field has matured significantly since the original survey, we find that innovation and research-driven development are increasingly sacrificed to satisfy a wide range of user groups. We evaluate new product versions on established evaluation criteria, such as available features, performance, and usability, to extend on and assure comparability with the previous survey. We also investigate previously unavailable products to paint a more complete picture of the commercial VA landscape. Furthermore, we introduce novel measures, like suitability for specific user groups and the ability to handle complex data types, and undertake a new case study to highlight innovative features. We explore the achievements in the commercial sector in addressing VA challenges and propose novel developments that should be on systems' roadmaps in the coming years.",Michael Behrisch 0001;Dirk Streeb;Florian Stoffel;Daniel Seebacher;Brian Matejek;Stefan Hagen Weber;Sebastian Mittelstädt;Hanspeter Pfister;Daniel A. Keim,Michael Behrisch;Dirk Streeb;Florian Stoffel;Daniel Seebacher;Brian Matejek;Stefan Hagen Weber;Sebastian Mittelstädt;Hanspeter Pfister;Daniel Keim,"Harvard University, Cambridge, MA, USA;University of Konstanz, Konstanz, Germany;University of Konstanz, Konstanz, Germany;University of Konstanz, Konstanz, Germany;Harvard University, Cambridge, MA, USA;Siemens AG, Corporate Research Germany, Munich, Germany;Siemens AG, Corporate Research Germany, Munich, Germany;Harvard University, Cambridge, MA, USA;University of Konstanz, Konstanz, Germany",0.1109/vast.2009.5332611;10.1109/tvcg.2015.2467591;10.1109/tvcg.2013.125;10.1109/mcg.2014.62;10.1109/tvcg.2012.219;10.1109/vast.2012.6400554;10.1109/tvcg.2014.2346321;10.1109/tvcg.2014.2346751;10.1109/tvcg.2011.188;10.1109/tvcg.2014.2346481;10.1109/tvcg.2015.2509990;10.1109/tvcg.2016.2598830;10.1109/tvcg.2008.114;10.1109/tvcg.2014.2346248;10.1109/tvcg.2013.173;10.1109/infvis.2004.46;10.1109/tvcg.2010.184;10.1109/tvcg.2016.2598467;10.1109/tvcg.2015.2507595;10.1109/tvcg.2014.2346574;10.1109/tvcg.2016.2598468;10.1109/vast.2014.7042480;10.1109/infvis.2004.60;10.1109/tvcg.2016.2598918;10.1109/tvcg.2014.2346291;10.1109/tvcg.2015.2467132;10.1109/tvcg.2011.185;10.1109/tvcg.2008.137;10.1109/tvcg.2013.179;10.1109/tvcg.2010.144;10.1109/tvcg.2016.2599030,"System comparison,commercial landscape,,,,,,,,,,,visual analytics research,,,,,,,,,,,advances,,,,development roadmap",,36,119,2097,,
CG&A,2015,The Reality Deck--an Immersive Gigapixel Display,10.1109/mcg.2014.80,http://dx.doi.org/10.1109/MCG.2014.80,33,45,MAG,"The Reality Deck is a visualization facility offering state-of-the-art aggregate resolution and immersion. Its a 1.5-Gpixel immersive tiled display with a full 360-degree horizontal field of view. Comprising 416 high-density LED-backlit LCD displays, it visualizes gigapixel-resolution data while providing 20/20 visual acuity for most of the visualization space.",Charilaos Papadopoulos;Kaloian Petkov;Arie E. Kaufman;Klaus Mueller 0001,Charilaos Papadopoulos;Kaloian Petkov;Arie E. Kaufman;Klaus Mueller,Stony Brook University;Stony Brook University;Stony Brook University;Stony Brook University,0.1109/tvcg.2013.127,"Reality Deck,gigapixel displays,,,,,,,,,,,immersive displays,,,,,,,,,,,visualization,,,,tiled displays,visual analytics,computer graphics,graphics",,34,15,907,,
TVCG,2014,Visual Adjacency Lists for Dynamic Graphs,10.1109/tvcg.2014.2322594,http://dx.doi.org/10.1109/TVCG.2014.2322594,1590,1603,J,"We present a visual representation for dynamic, weighted graphs based on the concept of adjacency lists. Two orthogonal axes are used: one for all nodes of the displayed graph, the other for the corresponding links. Colors and labels are employed to identify the nodes. The usage of color allows us to scale the visualization to single pixel level for large graphs. In contrast to other techniques, we employ an asymmetric mapping that results in an aligned and compact representation of links. Our approach is independent of the specific properties of the graph to be visualized, but certain graphs and tasks benefit from the asymmetry. As we show in our results, the strength of our technique is the visualization of dynamic graphs. In particular, sparse graphs benefit from the compact representation. Furthermore, our approach uses visual encoding by size to represent weights and therefore allows easy quantification and comparison. We evaluate our approach in a quantitative user study that confirms the suitability for dynamic and weighted graphs. Finally, we demonstrate our approach for two examples of dynamic graphs.",Marcel Hlawatsch;Michael Burch;Daniel Weiskopf,Marcel Hlawatsch;Michael Burch;Daniel Weiskopf,"Visualization Research Center (VISUS), University of Stuttgart, Germany;Visualization Research Center (VISUS), University of Stuttgart, Germany;Visualization Research Center (VISUS), University of Stuttgart, Germany",0.1109/infvis.2004.1;10.1109/tvcg.2011.226,"Graph visualization,weighted graphs,,,,,,,,,,,dynamic graphs,,,,,,,,,,,adjacency lists",,34,47,1428,,
TVCG,2018,Graph Thumbnails: Identifying and Comparing Multiple Graphs at a Glance,10.1109/tvcg.2018.2790961,http://dx.doi.org/10.1109/TVCG.2018.2790961,3081,3095,J,"We propose Graph Thumbnails, small icon-like visualisations of the high-level structure of network data. Graph Thumbnails are designed to be legible in small multiples to support rapid browsing within large graph corpora. Compared to existing graph-visualisation techniques our representation has several advantages: (1) the visualisation can be computed in linear time; (2) it is canonical in the sense that isomorphic graphs will always have identical thumbnails; and (3) it provides precise information about the graph structure. We report the results of two user studies. The first study compares Graph Thumbnails to node-link and matrix views for identifying similar graphs. The second study investigates the comprehensibility of the different representations. We demonstrate the usefulness of this representation for summarising the evolution of protein-protein interaction networks across a range of species.",Vahan Yoghourdjian;Tim Dwyer;Karsten Klein 0001;Kim Marriott;Michael Wybrow,Vahan Yoghourdjian;Tim Dwyer;Karsten Klein;Kim Marriott;Michael Wybrow,"Monash University, Clayton, Victoria, Australia;Monash University, Clayton, Victoria, Australia;Monash University, Clayton, Victoria, Australia;Monash University, Clayton, Victoria, Australia;Monash University, Clayton, Victoria, Australia",0.1109/tvcg.2008.130;10.1109/tvcg.2013.151;10.1109/tvcg.2015.2467251;10.1109/tvcg.2016.2598958,"Network visualisation,circle packing,,,,,,,,,,,k-core decomposition,,,,,,,,,,,k-connected,,,,network identification,large networks",,30,57,1570,,
TVCG,2018,TopKube: A Rank-Aware Data Cube for Real-Time Exploration of Spatiotemporal Data,10.1109/tvcg.2017.2671341,http://dx.doi.org/10.1109/TVCG.2017.2671341,1394,1407,J,"From economics to sports to entertainment and social media, ranking objects according to some notion of importance is a fundamental tool we humans use all the time to better understand our world. With the ever-increasing amount of user-generated content found online, “what's trending” is now a commonplace phrase that tries to capture the zeitgeist of the world by ranking the most popular microblogging hashtags in a given region and time. However, before we can understand what these rankings tell us about the world, we need to be able to more easily create and explore them, given the significant scale of today's data. In this paper, we describe the computational challenges in building a real-time visual exploratory tool for finding top-ranked objects; build on the recent work involving in-memory and rank-aware data cubes to propose TopKube: a data structure that answers top-k queries up to one order of magnitude faster than the previous state of the art; demonstrate the usefulness of our methods using a set of real-world, publicly available datasets; and provide a new set of benchmarks for other researchers to validate their methods and compare to our own.",Fabio Miranda 0001;Lauro Didier Lins;James T. Klosowski;Cláudio T. Silva,Fabio Miranda;Lauro Lins;James T. Klosowski;Claudio T. Silva,"New York University, New York, NY;AT&T Labs, Florham Park, NJ;AT&T Labs, Florham Park, NJ;New York University, New York, NY",0.1109/tvcg.2016.2598694;10.1109/tvcg.2013.173;10.1109/tvcg.2014.2346452;10.1109/tvcg.2007.70570;10.1109/tvcg.2011.176;10.1109/tvcg.2012.253;10.1109/tvcg.2013.179,"Interactive visualization,data cube,,,,,,,,,,,top-K queries,,,,,,,,,,,rank merging",,31,35,1183,,
TVCG,2013,Perceptually Driven Visibility Optimization for Categorical Data Visualization,10.1109/tvcg.2012.315,http://dx.doi.org/10.1109/TVCG.2012.315,1746,1757,J,"Visualization techniques often use color to present categorical differences to a user. When selecting a color palette, the perceptual qualities of color need careful consideration. Large coherent groups visually suppress smaller groups and are often visually dominant in images. This paper introduces the concept of class visibility used to quantitatively measure the utility of a color palette to present coherent categorical structure to the user. We present a color optimization algorithm based on our class visibility metric to make categorical differences clearly visible to the user. We performed two user experiments on user preference and visual search to validate our visibility measure over a range of color palettes. The results indicate that visibility is a robust measure, and our color optimization can increase the effectiveness of categorical data visualizations.",Sungkil Lee 0002;Mike Sips;Hans-Peter Seidel,Sungkil Lee;Mike Sips;Hans-Peter Seidel,"Department of Computer Science and Engineering, Sungkyunkwan University, Suwon, South Korea;Sektion 1.5, Geoinformatik Telegrafenberg, Helmholtz Centre Potsdam, German Research Centre for GeoScience GFZ, Potsdam, Germany;Max-Planck-Institut für Informatik, Saarbrucken, Germany",0.1109/visual.1995.480803;10.1109/visual.1996.568118;10.1109/tvcg.2008.118,"Color design,visualization,,,,,,,,,,,visibility,,,,,,,,,,,user interface",,33,37,1863,,
TVCG,2013,LineAO—Improved Three-Dimensional Line Rendering,10.1109/tvcg.2012.142,http://dx.doi.org/10.1109/TVCG.2012.142,433,445,J,"Rendering large numbers of dense line bundles in three dimensions is a common need for many visualization techniques, including streamlines and fiber tractography. Unfortunately, depiction of spatial relations inside these line bundles is often difficult but critical for understanding the represented structures. Many approaches evolved for solving this problem by providing special illumination models or tube-like renderings. Although these methods improve spatial perception of individual lines or related sets of lines, they do not solve the problem for complex spatial relations between dense bundles of lines. In this paper, we present a novel approach that improves spatial and structural perception of line renderings by providing a novel ambient occlusion approach suited for line rendering in real time.",Sebastian Eichelbaum;Mario Hlawitschka;Gerik Scheuermann,Sebastian Eichelbaum;Mario Hlawitschka;Gerik Scheuermann,"Abteilung für Bild- und Signalverarbeitung, Universität Leipzig, Leipzig, Germany;Lehrstuhl für Wissenschaftliche Visualisierung, Universität Leipzig, Leipzig, Germany;Abteilung für Bild- und Signalverarbeitung, Universität Leipzig, Leipzig, Germany",0.1109/visual.1996.567777;10.1109/visual.2005.1532772;10.1109/tvcg.2009.138;10.1109/tvcg.2006.151;10.1109/tvcg.2009.157;10.1109/tvcg.2006.115;10.1109/tvcg.2006.197;10.1109/tvcg.2008.128;10.1109/visual.2004.5;10.1109/tvcg.2011.35,"GPU,ambient occlusion,,,,,,,,,,,illumination,,,,,,,,,,,diffusion tensor data,,,,fiber tracking,streamline visualization",,30,60,1206,,
CG&A,2014,Business Intelligence from Social Media: A Study from the VAST Box Office Challenge,10.1109/mcg.2014.61,http://dx.doi.org/10.1109/MCG.2014.61,58,69,MAG,"With over 16 million tweets per hour, 600 new blog posts per minute, and 400 million active users on Facebook, businesses have begun searching for ways to turn real-time consumer-based posts into actionable intelligence. The goal is to extract information from this noisy, unstructured data and use it for trend analysis and prediction. Current practices support the idea that visual analytics (VA) can help enable the effective analysis of such data. However, empirical evidence demonstrating the effectiveness of a VA solution is still lacking. A proposed VA toolkit extracts data from Bitly and Twitter to predict movie revenue and ratings. Results from the 2013 VAST Box Office Challenge demonstrate the benefit of an interactive environment for predictive analysis, compared to a purely statistical modeling approach. The VA approach used by the toolkit is generalizable to other domains involving social media data, such as sales forecasting and advertisement analysis.",Yafeng Lu;Feng Wang 0012;Ross Maciejewski,Yafeng Lu;Feng Wang;Ross Maciejewski,Arizona State University;Arizona State University;Arizona State University,0.1109/tvcg.2013.186;10.1109/vast.2012.6400557;10.1109/tvcg.2013.125,"social media,movie revenue,movie reviews,VAST Box Office Challenge,,,,,,,,,visualization,,,,,,,,,,,prediction,,,,computer graphics,graphics,visual analytics,Twitter,Bitly,linear regression",,31,19,2684,,
CG&A,2017,Spatial Analytic Interfaces: Spatial User Interfaces for In Situ Visual Analytics,10.1109/mcg.2016.38,http://dx.doi.org/10.1109/MCG.2016.38,66,79,MAG,"As wearable devices gain acceptance, we need to ask, What will user interfaces look like in a post-smartphone world? Will these future interfaces support sophisticated interactions in a mobile context? The authors draw from visual analytics concepts to address the growing need for individuals to manage information on personal devices. Spatial analytic interfaces (SAIs) can leverage the benefits of spatial interaction to enable everyday visual analytics tasks to be performed in-situ, at the most beneficial place and time. They explore the possibilities for such interfaces using head-worn display technology and discuss current developments and future research goals for the successful development of SAIs.",Barrett Ens;Pourang Irani,Barrett Ens;Pourang Irani,University of Manitoba;University of Manitoba,0.1109/tvcg.2007.70515;10.1109/tvcg.2007.70521;10.1109/tvcg.2007.70541;10.1109/tvcg.2014.2359887;10.1109/vast.2007.4389006;10.1109/tvcg.2011.183,"computer graphics,spatial user interface,,,,,,,,,,,visual analytics,,,,,,,,,,,immersive analytics,,,,augmented reality,head-worn displays",,43,24,1189,,
CG&A,2014,Visual Business Ecosystem Intelligence: Lessons from the Field,10.1109/mcg.2014.104,http://dx.doi.org/10.1109/MCG.2014.104,26,34,MAG,"Macroscopic insight into business ecosystems is becoming increasingly important. With the emergence of new digital business data, opportunities exist to develop rich, interactive visual-analytics tools. Georgia Institute of Technology researchers have been developing and implementing visual business ecosystem intelligence tools in corporate settings. This article discusses the challenges they faced, the lessons learned, and opportunities for future research.",Rahul C. Basole,Rahul C. Basole,Georgia Institute of Technology,0.1109/tvcg.2013.209;10.1109/tvcg.2011.279,"visual analytics,business ecosystem intelligence,,,,,,,,,,,risk management,,,,,,,,,,,competitive dynamics,,,,venture capital financing,strategic decision making,case studies,computer graphics,graphics",,29,13,1850,,
TVCG,2012,Efficient Computation of Combinatorial Feature Flow Fields,10.1109/tvcg.2011.269,http://dx.doi.org/10.1109/TVCG.2011.269,1563,1573,J,"We propose a combinatorial algorithm to track critical points of 2D time-dependent scalar fields. Existing tracking algorithms such as Feature Flow Fields apply numerical schemes utilizing derivatives of the data, which makes them prone to noise and involve a large number of computational parameters. In contrast, our method is robust against noise since it does not require derivatives, interpolation, and numerical integration. Furthermore, we propose an importance measure that combines the spatial persistence of a critical point with its temporal evolution. This leads to a time-aware feature hierarchy, which allows us to discriminate important from spurious features. Our method requires only a single, easy-to-tune computational parameter and is naturally formulated in an out-of-core fashion, which enables the analysis of large data sets. We apply our method to synthetic data and data sets from computational fluid dynamics and compare it to the stabilized continuous Feature Flow Field tracking algorithm.",Jan Reininghaus;Jens Kasten;Tino Weinkauf;Ingrid Hotz,Jan Reininghaus;Jens Kasten;Tino Weinkauf;Ingrid Hotz,"Zuse Institute, Konrad-Zuse-Zentrum fuer Informationstechnik, Berlin, Germany;Zuse Institute, Konrad-Zuse-Zentrum fuer Informationstechnik, Berlin, Germany;Department 4: Computer Graphics, Max Planck-Institut fur Informatik, Saarbruecken, Germany;Zuse Institute, Konrad-Zuse-Zentrum fuer Informationstechnik, Berlin, Germany",0.1109/tvcg.2008.110;10.1109/tvcg.2010.93;10.1109/tvcg.2006.186;10.1109/visual.2001.964546;10.1109/tvcg.2007.70599;10.1109/visual.2004.107;10.1109/tvcg.2007.70545,"Flow visualization,graph algorithms.",,29,41,490,,
TVCG,2018,MultiStream: A Multiresolution Streamgraph Approach to Explore Hierarchical Time Series,10.1109/tvcg.2018.2796591,http://dx.doi.org/10.1109/TVCG.2018.2796591,3160,3173,J,"Multiple time series are a set of multiple quantitative variables occurring at the same interval. They are present in many domains such as medicine, finance, and manufacturing for analytical purposes. In recent years, streamgraph visualization (evolved from ThemeRiver) has been widely used for representing temporal evolution patterns in multiple time series. However, streamgraph as well as ThemeRiver suffer from scalability problems when dealing with several time series. To solve this problem, multiple time series can be organized into a hierarchical structure where individual time series are grouped hierarchically according to their proximity. In this paper, we present a new streamgraph-based approach to convey the hierarchical structure of multiple time series to facilitate the exploration and comparisons of temporal evolution. Based on a focus+context technique, our method allows time series exploration at different granularities (e.g., from overview to details). To illustrate our approach, two usage examples are presented.",Erick Cuenca;Arnaud Sallaberry;Florence Ying Wang;Pascal Poncelet,Erick Cuenca;Arnaud Sallaberry;Florence Y. Wang;Pascal Poncelet,"LIRMM, University of Montpellier, Montpellier, France;LIRMM, Paul Valéry University of Montpellier, Montpellier, France;CSIRO, Canberra, ACT, Australia;LIRMM, University of Montpellier, Montpellier, France",0.1109/tvcg.2014.2346920;10.1109/tvcg.2014.2346919;10.1109/tvcg.2011.239;10.1109/tvcg.2013.227;10.1109/infvis.2004.11;10.1109/tvcg.2008.166;10.1109/infvis.2000.885098;10.1109/tvcg.2007.70577;10.1109/tvcg.2013.162;10.1109/vast.2007.4389005;10.1109/tvcg.2014.2346433,"Streamgraph,stacked graph,,,,,,,,,,,time series,,,,,,,,,,,aggregation,,,,multiresolution visualization,overview+detail,focus+context,fisheye",,28,36,1493,,X
CG&A,2015,ENTVis: A Visual Analytic Tool for Entropy-Based Network Traffic Anomaly Detection,10.1109/mcg.2015.97,http://dx.doi.org/10.1109/MCG.2015.97,42,50,MAG,"Entropy-based traffic metrics have received substantial attention in network traffic anomaly detection because entropy can provide fine-grained metrics of traffic distribution characteristics. However, some practical issues--such as ambiguity, lack of detailed distribution information, and a large number of false positives--affect the application of entropy-based traffic anomaly detection. In this work, we introduce a visual analytic tool called ENTVis to help users understand entropy-based traffic metrics and achieve accurate traffic anomaly detection. ENTVis provides three coordinated views and rich interactions to support a coherent visual analysis on multiple perspectives: the timeline group view for perceiving situations and finding hints of anomalies, the Radviz view for clustering similar anomalies in a period, and the matrix view for understanding traffic distributions and diagnosing anomalies in detail. Several case studies have been performed to verify the usability and effectiveness of our method. A further evaluation was conducted via expert review.",Fangfang Zhou;Wei Huang 0025;Ying Zhao 0001;Yang Shi 0007;Xing Liang;Xiaoping Fan,Fangfang Zhou;Wei Huang;Ying Zhao;Yang Shi;Xing Liang;Xiaoping Fan,"Central South University, China;Central South University, China;Central South University, China;Central South University, China;Arizona State University;Central South University and Hunan University of Finance and Economics, China",,"computer graphics,visual analytics,,,,,,,,,,,cybersecurity,,,,,,,,,,,entropy,,,,anomaly detection",,28,3,1370,,
TVCG,2016,Visual Analysis of Multi-Run Spatio-Temporal Simulations Using Isocontour Similarity for Projected Views,10.1109/tvcg.2015.2498554,http://dx.doi.org/10.1109/TVCG.2015.2498554,2037,2050,J,"Multi-run simulations are widely used to investigate how simulated processes evolve depending on varying initial conditions. Frequently, such simulations model the change of spatial phenomena over time. Isocontours have proven to be effective for the visual representation and analysis of 2D and 3D spatial scalar fields. We propose a novel visualization approach for multi-run simulation data based on isocontours. By introducing a distance function for isocontours, we generate a distance matrix used for a multidimensional scaling projection. Multiple simulation runs are represented by polylines in the projected view displaying change over time. We propose a fast calculation of isocontour differences based on a quasi-Monte Carlo approach. For interactive visual analysis, we support filtering and selection mechanisms on the multi-run plot and on linked views to physical space visualizations. Our approach can be effectively used for the visual representation of ensembles, for pattern and outlier detection, for the investigation of the influence of simulation parameters, and for a detailed analysis of the features detected. The proposed method is applicable to data of any spatial dimensionality and any spatial representation (gridded or unstructured). We validate our approach by performing a user study on synthetic data and applying it to different types of multi-run spatio-temporal simulation data.",Alexey Fofonov;Vladimir Molchanov;Lars Linsen,Alexey Fofonov;Vladimir Molchanov;Lars Linsen,"Department of Computer Science and Electrical Engineering, Jacobs University, Bremen, Germany;Department of Computer Science and Electrical Engineering, Jacobs University, Bremen, Germany;Department of Computer Science and Electrical Engineering, Jacobs University, Bremen, Germany",0.1109/tvcg.2012.110;10.1109/tvcg.2010.182;10.1109/tvcg.2009.200;10.1109/tvcg.2006.164;10.1109/tvcg.2006.168;10.1109/visual.1997.663875;10.1109/tvcg.2012.118;10.1109/tvcg.2010.181;10.1109/visual.2001.964516;10.1109/tvcg.2008.160,"Ensemble visualization,multi-run data visualization,,,,,,,,,,,spatio-temporal data visualization,,,,,,,,,,,isocontours",,26,29,1017,,
TVCG,2012,Coherent Time-Varying Graph Drawing with Multifocus+Context Interaction,10.1109/tvcg.2011.128,http://dx.doi.org/10.1109/TVCG.2011.128,1330,1342,J,"We present a new approach for time-varying graph drawing that achieves both spatiotemporal coherence and multifocus+context visualization in a single framework. Our approach utilizes existing graph layout algorithms to produce the initial graph layout, and formulates the problem of generating coherent time-varying graph visualization with the focus+context capability as a specially tailored deformation optimization problem. We adopt the concept of the super graph to maintain spatiotemporal coherence and further balance the needs for aesthetic quality and dynamic stability when interacting with time-varying graphs through focus+context visualization. Our method is particularly useful for multifocus+context visualization of time-varying graphs where we can preserve the mental map by preventing nodes in the focus from undergoing abrupt changes in size and location in the time sequence. Experiments demonstrate that our method strikes a good balance between maintaining spatiotemporal coherence and accentuating visual foci, thus providing a more engaging viewing experience for the users.",Kun-Chuan Feng;Chaoli Wang 0001;Han-Wei Shen;Tong-Yee Lee,Kun-Chuan Feng;Chaoli Wang;Han-Wei Shen;Tong-Yee Lee,"Computer Graphics Group/Visual System Laboratory, Department of Computer Science and Information Engineering, National Cheng Kung University, Tainan, Taiwan;Department of Computer Science, Michigan Technological University, Houghton, MI, USA;Department of Computer Science and Engineering, Ohio State University, Columbus, OH, USA;Computer Graphics Group/Visual System Laboratory, Department of Computer Science and Information Engineering, National Cheng Kung University, Tainan, Taiwan",0.1109/tvcg.2008.132;10.1109/infvis.2004.66;10.1109/tvcg.2006.193;10.1109/tvcg.2008.140;10.1109/infvis.2004.18,"Graph drawing,time-varying graphs,,,,,,,,,,,spatiotemporal coherence,,,,,,,,,,,focus+context visualization.",,26,32,811,,
CG&A,2016,Using Gap Charts to Visualize the Temporal Evolution of Ranks and Scores,10.1109/mcg.2016.100,http://dx.doi.org/10.1109/MCG.2016.100,38,49,MAG,"To address the limitations of traditional line chart approaches, in particular rank charts (RCs) and score charts (SCs), a novel class of line charts called gap charts (GCs) show entries that are ranked over time according to a performance metric. The main advantages of GCs are that entries never overlap (only changes in rank generate limited overlap between time steps) and gaps between entries show the magnitude of their score difference. The authors evaluate the effectiveness of GCs for performing different types of tasks and find that they outperform standard time-dependent ranking visualizations for tasks that involve identifying and understanding evolutions in both ranks and scores. They also show that GCs are a generic and scalable class of line charts by applying them to a variety of different datasets.",Charles Perin;Jeremy Boy;Frédéric Vernier,Charles Perin;Jeremy Boy;Frédéric Vernier,University of Calgary;United Nations;University Paris-Sud,0.1109/tvcg.2012.253;10.1109/tvcg.2013.192;10.1109/tvcg.2014.2346984;10.1109/tvcg.2015.2467201;10.1109/tvcg.2013.173;10.1109/tvcg.2014.2346279,"computer graphics,gap chart,infographics,,,,,,,,,,rank chart,,,,,,,,,,,score chart,,,,sports,soccer,ranking,time-series,visualization,quantitative evaluation",,24,21,520,,
CG&A,2016,Episogram: Visual Summarization of Egocentric Social Interactions,10.1109/mcg.2015.73,http://dx.doi.org/10.1109/MCG.2015.73,72,81,MAG,The key challenges of visualizing social interaction data include the difficulties of understanding the general structure of social interactions and representing the data in the context of various user activities to reveal different behavior patterns. The design of the proposed interactive visualization tool Episogram is based on an anatomy of social interaction process in which the actors and objects involved can be formally represented as a time-varying tripartite network. The authors show the effectiveness of the proposed technique using real-world datasets and user studies.,Nan Cao 0001;Yu-Ru Lin;Fan Du;Dashun Wang,Nan Cao;Yu-Ru Lin;Fan Du;Dashun Wang,TongJi University;University of Pittsburgh;University of Maryland;Northwestern University,,"computer graphics,social interactions,,,,,,,,,,,social media visualization,,,,,,,,,,,visual summarization,,,,information visualization",,21,6,750,,
TVCG,2012,Exploring Brain Connectivity with Two-Dimensional Neural Maps,10.1109/tvcg.2011.82,http://dx.doi.org/10.1109/TVCG.2011.82,978,987,J,"We introduce two-dimensional neural maps for exploring connectivity in the brain. For this, we create standard streamtube models from diffusion-weighted brain imaging data sets along with neural paths hierarchically projected into the plane. These planar neural maps combine desirable properties of low-dimensional representations, such as visual clarity and ease of tract-of-interest selection, with the anatomical familiarity of 3D brain models and planar sectional views. We distribute this type of visualization both in a traditional stand-alone interactive application and as a novel, lightweight web-accessible system. The web interface integrates precomputed neural-path representations into a geographical digital-maps framework with associated labels, metrics, statistics, and linkouts. Anecdotal and quantitative comparisons of the present method with a recently proposed 2D point representation suggest that our representation is more intuitive and easier to use and learn. Similarly, users are faster and more accurate in selecting bundles using the 2D path representation than the 2D point representation. Finally, expert feedback on the web interface suggests that it can be useful for collaboration as well as quick exploration of data.",Radu Jianu;Çagatay Demiralp;David H. Laidlaw,Radu Jianu;Cagatay Demiralp;David H. Laidlaw,"Computer Science Department, Brown University, Providence, RI, USA;Computer Science Department, Brown University, Providence, RI, USA;Computer Science Department, Brown University, Providence, RI, USA",0.1109/visual.2000.885694;10.1109/tvcg.2009.138;10.1109/visual.2005.1532859;10.1109/visual.2005.1532779;10.1109/tvcg.2009.178;10.1109/tvcg.2009.174;10.1109/tvcg.2006.147;10.1109/tvcg.2007.70577;10.1109/tvcg.2009.112;10.1109/tvcg.2009.141,"DTI fiber tracts,abstraction,,,,,,,,,,,filtration,,,,,,,,,,,path immersion,,,,interaction,coloring.",,22,43,960,,
CG&A,2014,Interactive Visual Analysis of Heterogeneous Cohort-Study Data,10.1109/mcg.2014.40,http://dx.doi.org/10.1109/MCG.2014.40,70,82,MAG,"Medical cohort studies enable the study of medical hypotheses with many samples. Often, these studies acquire a large amount of heterogeneous data from many subjects. Usually, researchers study a specific data subset to confirm or reject specific hypotheses. A new approach enables the interactive visual exploration and analysis of such data, helping to generate and validate hypotheses. A data-cube-based model handles partially overlapping data subsets during the interactive visualization. This model enables seamless integration of the heterogeneous data and the linking of spatial and nonspatial views of the data. Researchers implemented this model in a prototype application and used it to analyze data acquired in a cohort study on cognitive aging. Case studies employed the prototype to study aspects of brain connectivity, demonstrating the model's potential and flexibility.",Paolo Angelelli;Steffen Oeltze;Judit Haasz;Cagatay Turkay;Erlend Hodneland;Arvid Lundervold;Astri J. Lundervold;Bernhard Preim;Helwig Hauser,Paolo Angelelli;Steffen Oeltze;Judit Haász;Cagatay Turkay;Erlend Hodneland;Arvid Lundervold;Astri J. Lundervold;Bernhard Preim;Helwig Hauser,University of Bergen;University of Bergen;University of Bergen;University of Bergen;University of Bergen;University of Magdeburg;University of Bergen;University of Magdeburg;University of Magdeburg,0.1109/tvcg.2009.121,"heterogeneous data,medical visualization,,,,,,,,,,,interactive visual analysis,,,,,,,,,,,visual analytics,,,,graphics,computer graphics,visualization",,22,15,625,,
TVCG,2018,Perceptual Biases in Font Size as a Data Encoding,10.1109/tvcg.2017.2723397,http://dx.doi.org/10.1109/TVCG.2017.2723397,2397,2410,J,"Many visualizations, including word clouds, cartographic labels, and word trees, encode data within the sizes of fonts. While font size can be an intuitive dimension for the viewer, using it as an encoding can introduce factors that may bias the perception of the underlying values. Viewers might conflate the size of a word's font with a word's length, the number of letters it contains, or with the larger or smaller heights of particular characters (`o' versus `p' versus `b'). We present a collection of empirical studies showing that such factors-which are irrelevant to the encoded values-can indeed influence comparative judgements of font size, though less than conventional wisdom might suggest. We highlight the largest potential biases, and describe a strategy to mitigate them.",Eric Carlson Alexander;Chih-Ching Chang;Mariana Shimabukuro;Steven Franconeri;Christopher Collins 0001;Michael Gleicher,Eric Alexander;Chih-Ching Chang;Mariana Shimabukuro;Steven Franconeri;Christopher Collins;Michael Gleicher,"Carleton College, Northfield, MN;University of Wisconsin-Madison, Madison, WI;University of Ontario, University of Ontario, Oshawa, ON, Canada;Northwestern University, Evanston, IL;University of Ontario, University of Ontario, Oshawa, ON, Canada;University of Wisconsin-Madison, Madison, WI",0.1109/vast.2009.5333443;10.1109/tvcg.2012.264;10.1109/tvcg.2009.171;10.1109/tvcg.2008.172;10.1109/tvcg.2011.185,"Text and document data,cognitive and perceptual skill,,,,,,,,,,,quantitative evaluation",,20,27,819,,
TVCG,2015,Exploration of the Brain’s White Matter Structure through Visual Abstraction and Multi-Scale Local Fiber Tract Contraction,10.1109/tvcg.2015.2403323,http://dx.doi.org/10.1109/TVCG.2015.2403323,808,821,J,"We present a visualization technique for brain fiber tracts from DTI data that provides insight into the structure of white matter through visual abstraction. We achieve this abstraction by analyzing the local similarity of tract segment directions at different scales using a stepwise increase of the search range. Next, locally similar tract segments are moved toward each other in an iterative process, resulting in a local contraction of tracts perpendicular to the local tract direction at a given scale. This not only leads to the abstraction of the global structure of the white matter as represented by the tracts, but also creates volumetric voids. This increase of empty space decreases the mutual occlusion of tracts and, consequently, results in a better understanding of the brain's three-dimensional fiber tract structure. Our implementation supports an interactive and continuous transition between the original and the abstracted representations via various scale levels of similarity. We also support the selection of groups of tracts, which are highlighted and rendered with the abstracted visualization as context.",Maarten H. Everts;Eric Begue;Henk Bekker;Jos B. T. M. Roerdink;Tobias Isenberg 0001,Maarten H. Everts;Eric Begue;Henk Bekker;Jos B. T. M. Roerdink;Tobias Isenberg,"TNO, The Netherlands;University of Groningen, The Netherlands;University of Groningen, The Netherlands;Neuroimaging Center of the University Medical Center Groningen, The Netherlands;Inria, France",0.1109/visual.2005.1532779;10.1109/tvcg.2007.70602;10.1109/tvcg.2007.70532;10.1109/tvcg.2009.138;10.1109/tvcg.2006.147;10.1109/tvcg.2009.112;10.1109/tvcg.2009.141;10.1109/tvcg.2011.82;10.1109/tvcg.2006.134;10.1109/tvcg.2011.155,"Diffusion Tensor Imaging (DTI),fiber tracts,,,,,,,,,,,visual abstraction,,,,,,,,,,,multi-scale representation,,,,illustrative visualization,Diffusion tensor imaging (DTI),fiber tracts,visual abstraction,multi-scale representation,illustrative visualization",,22,46,575,,
TVCG,2019,ColorMapND: A Data-Driven Approach and Tool for Mapping Multivariate Data to Color,10.1109/tvcg.2018.2808489,http://dx.doi.org/10.1109/TVCG.2018.2808489,1361,1377,J,"A wide variety of color schemes have been devised for mapping scalar data to color. We address the challenge of color-mapping multivariate data. While a number of methods can map low-dimensional data to color, for example, using bilinear or barycentric interpolation for two or three variables, these methods do not scale to higher data dimensions. Likewise, schemes that take a more artistic approach through color mixing and the like also face limits when it comes to the number of variables they can encode. Our approach does not have these limitations. It is data driven in that it determines a proper and consistent color map from first embedding the data samples into a circular interactive multivariate color mapping display (ICD) and then fusing this display with a convex (CIE HCL) color space. The variables (data attributes) are arranged in terms of their similarity and mapped to the ICD's boundary to control the embedding. Using this layout, the color of a multivariate data sample is then obtained via modified generalized barycentric coordinate interpolation of the map. The system we devised has facilities for contrast and feature enhancement, supports both regular and irregular grids, can deal with multi-field as well as multispectral data, and can produce heat maps, choropleth maps, and diagrams such as scatterplots.",Shenghui Cheng;Wei Xu 0020;Klaus Mueller 0001,Shenghui Cheng;Wei Xu;Klaus Mueller,"Computer Science Department, Stony Brook University, Stony Brook, NY;Computer Science Department, Stony Brook University, Stony Brook, NY;Computer Science Department, Stony Brook University, Stony Brook, NY",0.1109/tvcg.2008.118;10.1109/tvcg.2015.2467931;10.1109/tvcg.2014.2346913;10.1109/tvcg.2016.2598479;10.1109/tvcg.2016.2599214;10.1109/tvcg.2016.2598918;10.1109/tvcg.2007.70623;10.1109/visual.1997.663916;10.1109/tvcg.2011.185;10.1109/tvcg.2015.2467552;10.1109/visual.1995.480803;10.1109/tvcg.2009.150;10.1109/tvcg.2012.234,"Multivariate data,color mapping,,,,,,,,,,,color space,,,,,,,,,,,high dimensional data,,,,pseudo coloring",,23,40,1149,,
TVCG,2015,Glyph-Based Video Visualization for Semen Analysis,10.1109/tvcg.2013.265,http://dx.doi.org/10.1109/TVCG.2013.265,980,993,J,"The existing efforts in computer assisted semen analysis have been focused on high speed imaging and automated image analysis of sperm motility. This results in a large amount of data, and it is extremely challenging for both clinical scientists and researchers to interpret, compare and correlate the multidimensional and time-varying measurements captured from video data. In this work, we use glyphs to encode a collection of numerical measurements taken at a regular interval and to summarize spatio-temporal motion characteristics using static visual representations. The design of the glyphs addresses the needs for (a) encoding some 20 variables using separable visual channels, (b) supporting scientific observation of the interrelationships between different measurements and comparison between different sperm cells and their flagella, and (c) facilitating the learning of the encoding scheme by making use of appropriate visual abstractions and metaphors. As a case study, we focus this work on video visualization for computer-aided semen analysis, which has a broad impact on both biological sciences and medical healthcare. We demonstrate that glyph-based visualization can serve as a means of external memorization of video data as well as an overview of a large set of spatiotemporal measurements. It enables domain scientists to make scientific observation in a cost-effective manner by reducing the burden of viewing videos repeatedly, while providing them with a new visual representation for conveying semen statistics.",Brian Duffy;Jeyarajan Thiyagalingam;Simon J. Walton;David J. Smith;Anne E. Trefethen;Jackson C. Kirkman-Brown;Eamonn A. Gaffney;Min Chen 0001,Brian Duffy;Jeyarajan Thiyagalingam;Simon Walton;David J. Smith;Anne Trefethen;Jackson C. Kirkman-Brown;Eamonn A. Gaffney;Min Chen,"Oxford eResearch Center (OeRC), University of Oxford, Oxford, Oxfordshire, United Kingdom;Oxford eResearch Center (OeRC), University of Oxford, Oxford, Oxfordshire, United Kingdom;Oxford eResearch Center (OeRC), University of Oxford, Oxford, Oxfordshire, United Kingdom;Watson Building, University of Birmingham, Edgbaston, Birmingham, United Kingdom;Oxford eResearch Center (OeRC), University of Oxford, Oxford, Oxfordshire, United Kingdom;Watson Building, University of Birmingham, Edgbaston, Birmingham, United Kingdom;Oxford eResearch Center (OeRC), University of Oxford, Oxford, Oxfordshire, United Kingdom;Oxford eResearch Center (OeRC), University of Oxford, Oxford, Oxfordshire, United Kingdom",0.1109/visual.1999.809905;10.1109/tvcg.2006.134;10.1109/tvcg.2006.194;10.1109/visual.1991.175811;10.1109/visual.2003.1250401;10.1109/visual.1993.398849;10.1109/tvcg.2009.111;10.1109/tvcg.2012.271,"Video visualization,glyph visualization,,,,,,,,,,,multivariate data,,,,,,,,,,,semen analysis,,,,flagellum locomotion",,23,70,1184,,
CG&A,2015,Design Challenges and Opportunities for Eco-Feedback in the Home,10.1109/mcg.2015.69,http://dx.doi.org/10.1109/MCG.2015.69,52,62,MAG,"Domestic energy conservation is critical to reducing energy demand and greenhouse gas emissions. Personal visualization has a role to play in the design of appropriate feedback for encouraging more effective home energy use, but the unique nature of residential energy informatics introduces new design issues. This article reviews current approaches and discusses unaddressed challenges related to better conceptual models, context, enhanced communicative scope, and functional aesthetics. Based on a proposed theoretical framework, the author identifies important gaps in the current design space of residential energy visualizations related to richer data models, a broader concept of context, an enhanced communicative scope, and a better ecological fit in the home.",Lyn Bartram,Lyn Bartram,Simon Fraser University,0.1109/tvcg.2007.70541;10.1109/tvcg.2011.196;10.1109/tvcg.2014.2359887,"computer graphics,personal visualization,,,,,,,,,,,energy conservation,,,,,,,,,,,energy visualizations,,,,in-home displays,ambient visualizations,functional aesthetics",,20,24,1032,,
TVCG,2011,Drawing Contour Trees in the Plane,10.1109/tvcg.2010.270,http://dx.doi.org/10.1109/TVCG.2010.270,1599,1611,J,"The contour tree compactly describes scalar field topology. From the viewpoint of graph drawing, it is a tree with attributes at vertices and optionally on edges. Standard tree drawing algorithms emphasize structural properties of the tree and neglect the attributes. Applying known techniques to convey this information proves hard and sometimes even impossible. We present several adaptions of popular graph drawing approaches to the problem of contour tree drawing and evaluate them. We identify five esthetic criteria for drawing contour trees and present a novel algorithm for drawing contour trees in the plane that satisfies four of these criteria. Our implementation is fast and effective for contour tree sizes usually used in interactive systems (around 100 branches) and also produces readable pictures for larger trees, as is shown for an 800 branch example.",Christian Heine 0002;Dominic Schneider;Hamish A. Carr;Gerik Scheuermann,Christian Heine;Dominic Schneider;Hamish Carr;Gerik Scheuermann,"Department of Computer Science, University of Leipzig, Germany;Department of Computer Science, University of Leipzig, Germany;School of Computing, University of Leeds, UK;Department of Computer Science, University of Leipzig, Germany",0.1109/tvcg.2009.119;10.1109/visual.2004.96;10.1109/visual.1997.663875;10.1109/tvcg.2008.143;10.1109/tvcg.2009.163;10.1109/tvcg.2007.70601,"Contour tree,graph layout.",,21,40,845,,
CG&A,2015,Visual Analytics for Early-Phase Complex Engineered System Design Support,10.1109/mcg.2015.3,http://dx.doi.org/10.1109/MCG.2015.3,41,51,MAG,"This article reports on our ongoing experiences in developing visual analytics tools for real-world CESs. Our work focuses on the early design phase during which a large design space is explored, poor alternatives are pruned, and valuable alternatives are considered further. Visual analytics tools can provide interactive discovery, exploration, and understanding of real-world complex engineered systems (CES). The proposed tool, which focuses on the early design phase, can help users perform routine CES design analysis tasks and offer stakeholder-specific visual representations of complex design models.",Rahul C. Basole;Ahsan Qamar;Hyunwoo Park;Christiaan J. J. Paredis;Leon F. McGinnis,Rahul C. Basole;Ahsan Qamar;Hyunwoo Park;Christiaan J.J. Paredis;Leon F. McGinnis,Georgia Institute of Technology;Georgia Institute of Technology;Georgia Institute of Technology;Georgia Institute of Technology;Georgia Institute of Technology,0.1109/mcg.2014.104,"computer graphics,visual analytics,,,,,,,,,,,information visualization,,,,,,,,,,,complex engineered systems,,,,model-based systems engineering,manufacturing",,18,11,635,,
CG&A,2015,Key-Node-Separated Graph Clustering and Layouts for Human Relationship Graph Visualization,10.1109/mcg.2015.115,http://dx.doi.org/10.1109/MCG.2015.115,30,40,MAG,"Many graph-drawing methods apply node-clustering techniques based on the density of edges to find tightly connected subgraphs and then hierarchically visualize the clustered graphs. However, users may want to focus on important nodes and their connections to groups of other nodes for some applications. For this purpose, it is effective to separately visualize the key nodes detected based on adjacency and attributes of the nodes. This article presents a graph visualization technique for attribute-embedded graphs that applies a graph-clustering algorithm that accounts for the combination of connections and attributes. The graph clustering step divides the nodes according to the commonality of connected nodes and similarity of feature value vectors. It then calculates the distances between arbitrary pairs of clusters according to the number of connecting edges and the similarity of feature value vectors and finally places the clusters based on the distances. Consequently, the technique separates important nodes that have connections to multiple large clusters and improves the visibility of such nodes' connections. To test this technique, this article presents examples with human relationship graph datasets, including a coauthorship and Twitter communication network dataset.",Takayuki Itoh;Karsten Klein 0001,Takayuki Itoh;Karsten Klein,"Ochanomizu University, Japan;Monash University, Australia",0.1109/tvcg.2010.260;10.1109/tvcg.2006.147,"computer graphics,graph clustering,,,,,,,,,,,graph layout,,,,,,,,,,,human relationship graph",,17,4,802,,
CG&A,2017,VisAdapt: A Visualization Tool to Support Climate Change Adaptation,10.1109/mcg.2016.49,http://dx.doi.org/10.1109/MCG.2016.49,54,65,MAG,"The web-based visualization VisAdapt tool was developed to help laypeople in the Nordic countries assess how anticipated climate change will impact their homes. The tool guides users through a three-step visual process that helps them explore risks and identify adaptive actions specifically modified to their location and house type. This article walks through the tool's multistep, user-centered design process. Although VisAdapt's target end users are Nordic homeowners, the insights gained from the development process and the lessons learned from the project are applicable to a wide range of domains.",Jimmy Johansson 0001;Tomasz Opach;Erik Glaas;Tina-Simone Schmid Neset;Carlo Navarra;Björn-Ola Linnér;Jan Ketil Rød,Jimmy Johansson;Tomasz Opach;Erik Glaas;Tina-Simone Neset;Carlo Navarra;Björn-Ola Linnér;Jan Ketil Rød,"Linköping University;Norwegian University of Science and Technology;Linköping University;Linköping University;Linköping University;Linköping University;Norwegian University of Science and Technology, University of Agder",,"computer graphics,interactive visualization,,,,,,,,,,,climate change adaptation,,,,,,,,,,,user-centered design",,15,23,919,,
TVCG,2016,UnTangle Map: Visual Analysis of Probabilistic Multi-Label Data,10.1109/tvcg.2015.2424878,http://dx.doi.org/10.1109/TVCG.2015.2424878,1149,1163,J,"Data with multiple probabilistic labels are common in many situations. For example, a movie may be associated with multiple genres with different levels of confidence. Despite their ubiquity, the problem of visualizing probabilistic labels has not been adequately addressed. Existing approaches often either discard the probabilistic information, or map the data to a low-dimensional subspace where their associations with original labels are obscured. In this paper, we propose a novel visual technique, UnTangle Map, for visualizing probabilistic multi-labels. In our proposed visualization, data items are placed inside a web of connected triangles, with labels assigned to the triangle vertices such that nearby labels are more relevant to each other. The positions of the data items are determined based on the probabilistic associations between items and labels. UnTangle Map provides both (a) an automatic label placement algorithm, and (b) adaptive interactions that allow users to control the label positioning for different information needs. Our work makes a unique contribution by providing an effective way to investigate the relationship between data items and their probabilistic labels, as well as the relationships among labels. Our user study suggests that the visualization effectively helps users discover emergent patterns and compare the nuances of probabilistic information in the data labels.",Nan Cao 0001;Yu-Ru Lin;David Gotz,Nan Cao;Yu-Ru Lin;David Gotz,"Graph Computing, IBM T.J. Watson Research Center, Yorktown Heights, NY;School of Information Sciences, University of Pittsburgh, PA;School of Information and Library Science, University of North Carolina Chapel Hill School, Mannign Hall, Chapel Hill, NC",0.1109/tvcg.2011.188;10.1109/tvcg.2010.210;10.1109/tvcg.2011.186;10.1109/tvcg.2009.122;10.1109/infvis.2004.1;10.1109/tvcg.2014.2346660;10.1109/tvcg.2011.239;10.1109/infvis.2003.1249017;10.1109/visual.1990.146402;10.1109/tvcg.2008.153;10.1109/infvis.1995.528686;10.1109/tvcg.2010.154;10.1109/tvcg.2009.140,"Visualization,Multidimensional Visualization,,,,,,,,,,,Probability Vector,,,,,,,,,,,Visualization,,,,multidimensional visualization,probability vector",,16,52,1277,,
TVCG,2019,Classification of Blood Flow Patterns in Cerebral Aneurysms,10.1109/tvcg.2018.2834923,http://dx.doi.org/10.1109/TVCG.2018.2834923,2404,2418,J,"We present a Cerebral Aneurysm Vortex Classification (CAVOCLA) that allows to classify blood flow in cerebral aneurysms. Medical studies assume a strong relation between the progression and rupture of aneurysms and flow patterns. To understand how flow patterns impact the vessel morphology, they are manually classified according to predefined classes. However, manual classifications are time-consuming and exhibit a high inter-observer variability. In contrast, our approach is more objective and faster than manual methods. The classification of integral lines, representing steady or unsteady blood flow, is based on a mapping of the aneurysm surface to a hemisphere by calculating polar-based coordinates. The lines are clustered and for each cluster a representative is calculated. Then, the polar-based coordinates are transformed to the representative as basis for the classification. Classes are based on the flow complexity. The classification results are presented by a detail-on-demand approach using a visual transition from the representative over an enclosing surface to the associated lines. Based on seven representative datasets, we conduct an informal interview with five domain experts to evaluate the system. They confirmed that CAVOCLA allows for a robust classification of intra-aneurysmal flow patterns. The detail-on-demand visualization enables an efficient exploration and interpretation of flow patterns.",Monique Meuschke;Steffen Oeltze-Jafra;Oliver Beuing;Bernhard Preim;Kai Lawonn,Monique Meuschke;Steffen Oeltze-Jafra;Oliver Beuing;Bernhard Preim;Kai Lawonn,"Department of Simulation and Graphics, University of Magdeburg, and Research Campus STIMULATE, Magdeburg, Germany;University of Leipzig, Leipzig, Germany;University Hospital of Magdeburg, Magdeburg, Germany;Department of Simulation and Graphics, University of Magdeburg, and Research Campus STIMULATE, Magdeburg, Germany;University of Koblenz-Landau, Mainz, Germany",0.1109/tvcg.2016.2599042;10.1109/visual.1996.567777;10.1109/visual.1997.663912;10.1109/tvcg.2016.2598795;10.1109/tvcg.2015.2467204;10.1109/tvcg.2015.2467961;10.1109/tvcg.2012.202;10.1109/tvcg.2013.189;10.1109/tvcg.2013.2297914;10.1109/tvcg.2015.2467203;10.1109/tvcg.2014.2346406;10.1109/mcg.2018.032421654,"Medical visualizations,aneurysms,,,,,,,,,,,blood flow,,,,,,,,,,,parametrization,,,,classification",,15,65,741,,
CG&A,2016,Knowledge-Assisted Ranking: A Visual Analytic Application for Sports Event Data,10.1109/mcg.2015.25,http://dx.doi.org/10.1109/MCG.2015.25,72,82,MAG,"Organizing sports video data for performance analysis can be challenging, especially in cases involving multiple attributes and when the criteria for sorting frequently changes depending on the user's task. The proposed visual analytic system enables users to specify a sort requirement in a flexible manner without depending on specific knowledge about individual sort keys. The authors use regression techniques to train different analytical models for different types of sorting requirements and use visualization to facilitate knowledge discovery at different stages of the process. They demonstrate the system with a rugby case study to find key instances for analyzing team and player performance. Organizing sports video data for performance analysis can be challenging in cases with multiple attributes, and when sorting frequently changes depending on the user's task. As this video shows, the proposed visual analytic system allows interactive data sorting and exploration.https://youtu.be/Cs6SLtPVDQQ.",David H. S. Chung;Matthew L. Parry;Iwan W. Griffiths;Robert S. Laramee;Rhodri Bown;Philip A. Legg;Min Chen 0001,David H.S. Chung;Matthew L. Parry;Iwan W. Griffiths;Robert S. Laramee;Rhodri Bown;Philip A. Legg;Min Chen,Swansea University;Swansea University;Swansea University;Swansea University;Welsh Rugby Union;University of the West of England;University of Oxford,0.1109/tvcg.2011.208;10.1109/tvcg.2013.173,"computer graphics,sports video data,,,,,,,,,,,visual analytic system,,,,,,,,,,,regression techniques,,,,visualization",,14,15,1013,,
TVCG,2018,The Subspace Voyager: Exploring High-Dimensional Data along a Continuum of Salient 3D Subspaces,10.1109/tvcg.2017.2672987,http://dx.doi.org/10.1109/TVCG.2017.2672987,1204,1222,J,"Analyzing high-dimensional data and finding hidden patterns is a difficult problem and has attracted numerous research efforts. Automated methods can be useful to some extent but bringing the data analyst into the loop via interactive visual tools can help the discovery process tremendously. An inherent problem in this effort is that humans lack the mental capacity to truly understand spaces exceeding three spatial dimensions. To keep within this limitation, we describe a framework that decomposes a high-dimensional data space into a continuum of generalized 3D subspaces. Analysts can then explore these 3D subspaces individually via the familiar trackball interface while using additional facilities to smoothly transition to adjacent subspaces for expanded space comprehension. Since the number of such subspaces suffers from combinatorial explosion, we provide a set of data-driven subspace selection and navigation tools which can guide users to interesting subspaces and views. A subspace trail map allows users to manage the explored subspaces, keep their bearings, and return to interesting subspaces and views. Both trackball and trail map are each embedded into a word cloud of attribute labels which aid in navigation. We demonstrate our system via several use cases in a diverse set of application areas-cluster analysis and refinement, information discovery, and supervised training of classifiers. We also report on a user study that evaluates the usability of the various interactions our system provides.",Bing Wang 0007;Klaus Mueller 0001,Bing Wang;Klaus Mueller,"Visual Analytics and Imaging Lab at the Computer Science Department, Stony Brook University, Stony Brook, NY;Visual Analytics and Imaging Lab at the Computer Science Department, Stony Brook University, Stony Brook, NY",0.1109/tvcg.2015.2413786;10.1109/tvcg.2012.65;10.1109/vast.2007.4388999;10.1109/tvcg.2016.2598495;10.1109/vast.2012.6400490;10.1109/tvcg.2015.2467615;10.1109/tvcg.2015.2467132;10.1109/tvcg.2013.101;10.1109/tvcg.2008.153;10.1109/tvcg.2014.2330617;10.1109/tvcg.2013.173;10.1109/tvcg.2007.70539;10.1109/tvcg.2013.150,"High-dimensional data,subspace navigation,,,,,,,,,,,trackball,,,,,,,,,,,PCA,,,,ant colony optimization1",,15,53,826,,
CG&A,2017,Visualizing Rank Time Series of Wikipedia Top-Viewed Pages,10.1109/mcg.2017.21,http://dx.doi.org/10.1109/MCG.2017.21,42,53,MAG,"Visual clutter is a common challenge when visualizing large rank time series data. WikiTopReader, a reader of Wikipedia page rank, lets users explore connections among top-viewed pages by connecting page-rank behaviors with page-link relations. Such a combination enhances the unweighted Wikipedia page-link network and focuses attention on the page of interest. A set of user evaluations shows that the system effectively represents evolving ranking patterns and page-wise correlation.",Jing Xia;Yumeng Hou;Yingjie Victor Chen;Zhenyu Cheryl Qian;David S. Ebert;Wei Chen 0001,Jing Xia;Yumeng Hou;Yingjie Victor Chen;Zhenyu Cheryl Qian;David S. Ebert;Wei Chen,"State Key Lab of CAD&CG, Zhejiang University;State Key Lab of CAD&CG, Zhejiang University;Purdue University;Purdue University;Purdue University;State Key Lab of CAD&CG, Zhejiang University",0.1109/tvcg.2008.181;10.1109/vast.2012.6400494;10.1109/tvcg.2012.253;10.1109/vast.2009.5333443;10.1109/tvcg.2013.173,"computer graphics,rank time series,,,,,,,,,,,page view,,,,,,,,,,,page link,,,,visualization",,13,12,829,,
CG&A,2015,Design and Effects of Personal Visualizations,10.1109/mcg.2015.74,http://dx.doi.org/10.1109/MCG.2015.74,82,93,MAG,"In an effort to determine what elements need to be considered when designing personal visualizations, this research study explores how users react to different personal visualization designs. The authors present three distinct personal visualization designs (Timeline, Spark, and Bouquet) for visualizing Facebook user data. In a scenario-based user study, they interview participants to evaluation each design's utility, exploring the visualization of the users' own data, comparing two personal visualizations, and analyzing a series of personal visualizations. The analysis of the recorded conversations suggests that the illustrative design was the most well-balanced with respect to relaying information, motivating data exploration, and providing personal insights to the users. The authors believe this study will help guide future developers regarding the design of personal visualizations.",Shimin Wang;Yuzuru Tanahashi;Nick Leaf;Kwan-Liu Ma,Shimin Wang;Yuzuru Tanahashi;Nick Leaf;Kwan-Liu Ma,University of California Davis;University of California Davis;University of California Davis;University of California Davis,0.1109/tvcg.2008.166;10.1109/tvcg.2007.70541;10.1109/tvcg.2011.196;10.1109/tvcg.2014.2359887,"computer graphics,personal visualization,,,,,,,,,,,design study,,,,,,,,,,,Facebook data",,12,15,1002,,
TVCG,2017,An Exploratory Study of Word-Scale Graphics in Data-Rich Text Documents,10.1109/tvcg.2016.2618797,http://dx.doi.org/10.1109/TVCG.2016.2618797,2275,2287,J,"We contribute an investigation of the design and function of word-scale graphics and visualizations embedded in text documents. Word-scale graphics include both data-driven representations such as word-scale visualizations and sparklines, and non-data-driven visual marks. Their design, function, and use has so far received little research attention. We present the results of an open ended exploratory study with nine graphic designers. The study resulted in a rich collection of different types of graphics, data provenance, and relationships between text, graphics, and data. Based on this corpus, we present a systematic overview of word-scale graphic designs, and examine how designers used them. We also discuss the designers' goals in creating their graphics, and characterize how they used word-scale graphics to visualize data, add emphasis, and create alternative narratives. Building on these examples, we discuss implications for the design of authoring tools for word-scale graphics and visualizations, and explore how new authoring environments could make it easier for designers to integrate them into documents.",Pascal Goffin;Jeremy Boy;Wesley Willett;Petra Isenberg,Pascal Goffin;Jeremy Boy;Wesley Willett;Petra Isenberg,"Inria, France;UN Global Pulse, New York, NY;University of Calgary, Calgary, AB, Canada;Inria, France",0.1109/tvcg.2015.2467732;10.1109/tvcg.2010.194;10.1109/tvcg.2013.210;10.1109/tvcg.2014.2346435;10.1109/tvcg.2013.192,"Word-scale visualization,word-scale graphic,,,,,,,,,,,text visualization,,,,,,,,,,,sparklines,,,,authoring tool,information visualization",,16,34,1201,,
TVCG,2014,GazeVis: Interactive 3D Gaze Visualization for Contiguous Cross-Sectional Medical Images,10.1109/tvcg.2013.271,http://dx.doi.org/10.1109/TVCG.2013.271,726,739,J,"Gaze visualization has been used to understand the results from gaze tracking studies in a wide range of fields. In the medical field, diagnoses of medical images have been studied with gaze tracking technology to understand how radiologists read medical images. While prior work were mainly based on diagnosis with a single image, recent work focused on diagnosis with consecutive cross-sectional medical images acquired from preoperative computed tomography (CT) or magnetic resonance imaging (MRI). In the diagnosis, radiologists scroll through a stack of images to get a 3D cognition of organs and lesions. Thus, it is important to understand radiologists' gaze patterns three dimensionally across such contiguous cross-sectional images. However, little has been done to visualize more complicated gaze patterns from the contiguous cross-sectional medical images. To address this problem, we present an interactive 3D gaze visualization tool, GazeVis, where InfoVis and SciVis techniques are harmonized to show the abstract gaze data along with a realistic 3D rendering of the visual stimuli (i.e., organs and lesions). We present case studies with 12 radiologists who use GazeVis to investigate gaze patterns of their colleagues with different levels of expertise, providing empirical evidences about the competence of our gaze visualization system.",Hyunjoo Song;Jihye Yun;Bo Hyoung Kim;Jinwook Seo,Hyunjoo Song;Jihye Yun;Bohyoung Kim;Jinwook Seo,"Department of Computer Science and Engineering, Seoul National University, Seoul, Korea;Department of Computer Science and Engineering, Seoul National University, Seoul, Korea;Department of Radiology, Seoul National University Bundang Hospital, Gyeonggi-do, Korea;Department of Computer Science and Engineering, Seoul National University, Seoul, Korea",0.1109/tvcg.2008.153;10.1109/tvcg.2010.155;10.1109/tvcg.2008.162;10.1109/tvcg.2010.149;10.1109/infvis.2001.963291,"Eye tracking,gaze visualization,,,,,,,,,,,volume rendering,,,,,,,,,,,medical images,,,,interaction technique",,11,48,1035,,
TVCG,2013,Physics-Based Deformable Tongue Visualization,10.1109/tvcg.2012.174,http://dx.doi.org/10.1109/TVCG.2012.174,811,823,J,"In this paper, a physics-based framework is presented to visualize the human tongue deformation. The tongue is modeled with the Finite Element Method (FEM) and driven by the motion capture data gathered during speech production. Several novel deformation visualization techniques are presented for in-depth data analysis and exploration. To reveal the hidden semantic information of the tongue deformation, we present a novel physics-based volume segmentation algorithm. This is accomplished by decomposing the tongue model into segments based on its deformation pattern with the computation of deformation subspaces and fitting the target deformation locally at each segment. In addition, the strain energy is utilized to provide an intuitive low-dimensional visualization for the high-dimensional sequential motion. Energy-interpolation-based morphing is also equipped to effectively highlight the subtle differences of the 3D deformed shapes without any visual occlusion. Our experimental results and analysis demonstrate the effectiveness of this framework. The proposed methods, though originally designed for the exploration of the tongue deformation, are also valid for general deformation analysis of other shapes.",Yin Yang 0002;Xiaohu Guo;Jennell Vick;Luis G. Torres;Thomas F. Campbell,Yin Yang;Xiaohu Guo;Jennell Vick;Luis G. Torres;Thomas F. Campbell,"Department of Computer Science, University of Texas at Dallas, Richardson, TX, USA;Department of Computer Science, University of Texas at Dallas, Richardson, TX, USA;Department of Psychological Sciences, Case Western Reserve University, USA;Department of Computer Science, University of North Carolina at Chapel Hill, USA;Callier Center for Communication Disorders, University of Texas at Dallas, Richardson, TX, USA",0.1109/tvcg.2008.125;10.1109/tvcg.2009.112;10.1109/tvcg.2009.152,"Deformable model,tongue,,,,,,,,,,,finite element method,,,,,,,,,,,modal analysis",,11,46,660,,
TVCG,2013,PIWI: Visually Exploring Graphs Based on Their Community Structure,10.1109/tvcg.2012.172,http://dx.doi.org/10.1109/TVCG.2012.172,1034,1047,J,"Community structure is an important characteristic of many real networks, which shows high concentrations of edges within special groups of vertices and low concentrations between these groups. Community related graph analysis, such as discovering relationships among communities, identifying attribute-structure relationships, and selecting a large number of vertices with desired structural features and attributes, are common tasks in knowledge discovery in such networks. The clutter and the lack of interactivity often hinder efforts to apply traditional graph visualization techniques in these tasks. In this paper, we propose PIWI, a novel graph visual analytics approach to these tasks. Instead of using Node-Link Diagrams (NLDs), PIWI provides coordinated, uncluttered visualizations, and novel interactions based on graph community structure. The novel features, applicability, and limitations of this new technique have been discussed in detail. A set of case studies and preliminary user studies have been conducted with real graphs containing thousands of vertices, which provide supportive evidence about the usefulness of PIWI in community related tasks.",Jing Yang 0001;Yujie Liu;Xin Zhang;Xiaoru Yuan;Ye Zhao 0003;Scott Barlowe;Shixia Liu,Jing Yang;Yujie Liu;Xin Zhang;Xiaoru Yuan;Ye Zhao;Scott Barlowe;Shixia Liu,"Department of Computer Science, College of Computing and Informatics, University of North Carolina at Charlotte, Charlotte, NC, USA;Department of Computer Science, College of Computing and Informatics, University of North Carolina at Charlotte, Charlotte, NC, USA;Key Laboratory of Machine Perception (Minister of Education), Center for Information Science, School of Electronics Engineering and Computer Science, Peking University, Beijing, China;Key Laboratory of Machine Perception (Minister of Education), Center for Information Science, School of Electronics Engineering and Computer Science, Peking University, Beijing, China;Department of Computer Science, Kent State University, Kent, OH, USA;Department of Computer Science, College of Computing and Informatics, University of North Carolina at Charlotte, Charlotte, NC, USA;Microsoft Research Asia, Beijing, China",0.1109/tvcg.2006.166;10.1109/tvcg.2010.205;10.1109/tvcg.2009.108;10.1109/tvcg.2006.192;10.1109/infvis.2004.46;10.1109/tvcg.2006.160;10.1109/tvcg.2007.70582;10.1109/tvcg.2009.151;10.1109/tvcg.2006.122,"Information visualization,visual analytics,,,,,,,,,,,graph visualization,,,,,,,,,,,community structure",,10,39,827,,
CG&A,2015,Understanding Digital Note-Taking Practice for Visualization,10.1109/mcg.2015.52,http://dx.doi.org/10.1109/MCG.2015.52,38,51,MAG,"As digital notebooks become common forms of external memory, keeping track of these volumes of content is also becoming increasingly difficult. Information visualization tools can provide note-takers with an overview of their content and allow them to explore diverse sets of notes, find and organize related content, and compare their notes with collaborators. To ground the design of such tools, the authors conducted a detailed mixed-methods study of digital note-taking practice. They identify a variety of editing, organization, and sharing methods used by digital note-takers, many of which result in notes becoming ""lost in the pile."" These findings form the basis for the authors' design considerations that examine how visualization can support the revisitation, organization, and sharing of digital notes.",Wesley Willett;Pascal Goffin;Petra Isenberg,Wesley Willett;Pascal Goffin;Petra Isenberg,"University of Calgary and Inria;Inria;University of Calgary, Calgary, AB, CA",0.1109/tvcg.2009.111,"computer graphics,note-taking,,,,,,,,,,,information visualization,,,,,,,,,,,personal information management",,8,20,1194,,
CG&A,2016,Evaluating Shape Alignment via Ensemble Visualization,10.1109/mcg.2015.70,http://dx.doi.org/10.1109/MCG.2015.70,60,71,MAG,"The visualization of variability in surfaces embedded in 3D, which is a type of ensemble uncertainty visualization, provides a means of understanding the underlying distribution of a collection or ensemble of surfaces. This work extends the contour boxplot technique to 3D and evaluates it against an enumeration-style visualization of the ensemble members and other conventional visualizations used by atlas builders. The authors demonstrate the efficacy of using the 3D contour boxplot ensemble visualization technique to analyze shape alignment and variability in atlas construction and analysis as a real-world application.",Mukund Raj;Mahsa Mirzargar;J. Samuel Preston;Robert M. Kirby;Ross T. Whitaker,Mukund Raj;Mahsa Mirzargar;J. Samuel Preston;Robert M. Kirby;Ross T. Whitaker,University of Utah;University of Utah;University of Utah;University of Utah;University of Utah,0.1109/tvcg.2013.143,"computer graphics,contour boxplot,,,,,,,,,,,atlas construction,,,,,,,,,,,ensemble visualization",,9,13,423,,
TVCG,2018,Multi-Material Volume Rendering with a Physically-Based Surface Reflection Model,10.1109/tvcg.2017.2784830,http://dx.doi.org/10.1109/TVCG.2017.2784830,3147,3159,J,"Rendering techniques that increase realism in volume visualization help enhance perception of the 3D features in the volume data. While techniques focusing on high-quality global illumination have been extensively studied, few works handle the interaction of light with materials in the volume. Existing techniques for light-material interaction are limited in their ability to handle high-frequency real-world material data, and the current treatment of volume data poorly supports the correct integration of surface materials. In this paper, we introduce an alternative definition for the transfer function which supports surface-like behavior at the boundaries between volume components and volume-like behavior within. We show that this definition enables multi-material rendering with high-quality, real-world material data. We also show that this approach offers an efficient alternative to pre-integrated rendering through isosurface techniques. We introduce arbitrary spatially-varying materials to achieve better multi-material support for scanned volume data. Finally, we show that it is possible to map an arbitrary set of parameters directly to a material representation for the more intuitive creation of novel materials.",Oleg Igouchkine;Yubo Zhang 0001;Kwan-Liu Ma,Oleg Igouchkine;Yubo Zhang;Kwan-Liu Ma,"University of California, Davis, CA;University of California, Davis, CA;University of California, Davis, CA",0.1109/tvcg.2014.2346351;10.1109/visual.1998.745713;10.1109/tvcg.2011.161;10.1109/tvcg.2009.204,"Volume visualization,volume rendering,,,,,,,,,,,global illumination,,,,,,,,,,,BRDF,,,,hardware acceleration",,10,41,873,,
CG&A,2015,Eye Tracking for Personal Visual Analytics,10.1109/mcg.2015.47,http://dx.doi.org/10.1109/MCG.2015.47,64,72,MAG,"In many research fields, eye tracking has become an established method to analyze the distribution of visual attention in various scenarios. In the near future, eye tracking is expected to become ubiquitous, recording massive amounts of data in everyday situations. To make use of this data, new approaches for personal visual analytics will be necessary to make the data accessible, allowing nonexpert users to re-experience interesting events and benefit from self-reflection. This article discusses how eye tracking fits in the context of personal visual analytics, the challenges that arise with its application to everyday situations, and the research perspectives of personal eye tracking. As an example, the authors present a technique for representing areas of interest (AOIs) from multiple videos: the AOI cloud. They apply this technique to examine a user's personal encounters with other people.",Kuno Kurzhals;Daniel Weiskopf,Kuno Kurzhals;Daniel Weiskopf,University of Stuttgart;University of Stuttgart,0.1109/tvcg.2008.187;10.1109/tvcg.2012.276;10.1109/tvcg.2014.2359887,"computer graphics,eye tracking,,,,,,,,,,,video visualization,,,,,,,,,,,personal visual analytics",,8,18,1216,,
TVCG,2018,Visual Analysis of Inclusion Dynamics in Two-Phase Flow,10.1109/tvcg.2017.2692781,http://dx.doi.org/10.1109/TVCG.2017.2692781,1841,1855,J,"In single-phase flow visualization, research focuses on the analysis of vector field properties. In two-phase flow, in contrast, analysis of the phase components is typically of major interest. So far, visualization research of two-phase flow concentrated on proper interface reconstruction and the analysis thereof. In this paper, we present a novel visualization technique that enables the investigation of complex two-phase flow phenomena with respect to the physics of breakup and coalescence of inclusions. On the one hand, we adapt dimensionless quantities for a localized analysis of phase instability and breakup, and provide detailed inspection of breakup dynamics with emphasis on oscillation and its interplay with rotational motion. On the other hand, we present a parametric tightly linked space-time visualization approach for an effective interactive representation of the overall dynamics. We demonstrate the utility of our approach using several two-phase CFD datasets.",Grzegorz Karol Karch;Fabian Beck 0001;Moritz Ertl;Christian Meister;Kathrin Schulte;Bernhard Weigand;Thomas Ertl;Filip Sadlo,Grzegorz Karol Karch;Fabian Beck;Moritz Ertl;Christian Meister;Kathrin Schulte;Bernhard Weigand;Thomas Ertl;Filip Sadlo,"Visualization Research Center, University of Stuttgart, Stuttgart, Germany;Institute for Computer Science and Business Information Systems, Universitat Duisburg-Essen, Duisburg, Germany;Institute of Aerospace Thermodynamics, University of Stuttgart, Stuttgart, Germany;Institute of Aerospace Thermodynamics, University of Stuttgart, Stuttgart, Germany;Institute of Aerospace Thermodynamics, University of Stuttgart, Stuttgart, Germany;Institute of Aerospace Thermodynamics, University of Stuttgart, Stuttgart, Germany;Institute for Visualization and Interactive Systems, University of Stuttgart, Stuttgart, Germany;IWR, Heidelberg University, Heidelberg, Germany",0.1109/tvcg.2014.2346423;10.1109/tvcg.2007.70614;10.1109/tvcg.2011.246;10.1109/tvcg.2006.186,"Flow visualization,two-phase flow,,,,,,,,,,,feature deformation,,,,,,,,,,,space-time analysis,,,,feature tracking",,7,45,702,,
TVCG,2019,Animation Plans for Before-and-After Satellite Images,10.1109/tvcg.2018.2796557,http://dx.doi.org/10.1109/TVCG.2018.2796557,1347,1360,J,"Before-and-after image pairs show how entities in a given region have evolved over a specific period of time. Satellite images are a major source of such data, that capture how natural phenomena or human activity impact a geographical area. These images are used both for data analysis and to illustrate the resulting findings to diverse audiences. The simple techniques used to display them, including juxtaposing, swapping and monolithic blending, often fail to convey the underlying phenomenon in a meaningful manner. We introduce Baia, a framework to create advanced animated transitions, called animation plans, between before-and-after images. Baia relies on a pixel-based transition model that gives authors much expressive power, while keeping animations for common types of changes easy to create thanks to predefined animation primitives. We describe our model, the associated animation editor, and report on two user studies. In the first study, advanced transitions enabled by Baia were compared to monolithic blending, and perceived as more realistic and better at focusing viewer's attention on a region of interest than the latter. The second study aimed at gathering feedback about the usability of Baia's animation editor.",María-Jesús Lobo;Caroline Appert;Emmanuel Pietriga,María-Jesús Lobo;Caroline Appert;Emmanuel Pietriga,"CNRS, INRIA, Université Paris-Saclay, Orsay, France;CNRS, INRIA, Université Paris-Saclay, Orsay, France;CNRS, INRIA, Université Paris-Saclay, Orsay, France",0.1109/tvcg.2014.2346424;10.1109/tvcg.2013.213;10.1109/tvcg.2013.254;10.1109/tvcg.2007.70539;10.1109/tvcg.2010.179;10.1109/infvis.1998.729563,"Animation,blending,,,,,,,,,,,staging,,,,,,,,,,,remote sensing images",,6,37,434,,
TVCG,2018,Towards High-Quality Visualization of Superfluid Vortices,10.1109/tvcg.2017.2719684,http://dx.doi.org/10.1109/TVCG.2017.2719684,2440,2455,J,"Superfluidity is a special state of matter exhibiting macroscopic quantum phenomena and acting like a fluid with zero viscosity. In such a state, superfluid vortices exist as phase singularities of the model equation with unique distributions. This paper presents novel techniques to aid the visual understanding of superfluid vortices based on the state-of-the-art non-linear Klein-Gordon equation, which evolves a complex scalar field, giving rise to special vortex lattice/ring structures with dynamic vortex formation, reconnection, and Kelvin waves, etc. By formulating a numerical model with theoretical physicists in superfluid research, we obtain high-quality superfluid flow data sets without noise-like waves, suitable for vortex visualization. By further exploring superfluid vortex properties, we develop a new vortex identification and visualization method: a novel mechanism with velocity circulation to overcome phase singularity and an orthogonal-plane strategy to avoid ambiguity. Hence, our visualizations can help reveal various superfluid vortex structures and enable domain experts for related visual analysis, such as the steady vortex lattice/ring structures, dynamic vortex string interactions with reconnections and energy radiations, where the famous Kelvin waves and decaying vortex tangle were clearly observed. These visualizations have assisted physicists to verify the superfluid model, and further explore its dynamic behavior more intuitively.",Yulong Guo;Xiaopei Liu;Chi Xiong;Xuemiao Xu;Chi-Wing Fu,Yulong Guo;Xiaopei Liu;Chi Xiong;Xuemiao Xu;Chi-Wing Fu,"School of Information Science and Technology, ShanghaiTech University, Shanghai, China;School of Information Science and Technology, ShanghaiTech University, Shanghai, China;Institute of Advanced Studies, Nanyang Technological University, Singapore;Department of Computer Science and Engineering, South China University of Technology, Guangzhou, China;Department of Computer Science and Engineering, Chinese University of Hong Kong, Sha Tin, Hong Kong",0.1109/tvcg.2008.146;10.1109/tvcg.2006.201;10.1109/tvcg.2014.2312009;10.1109/tvcg.2011.155;10.1109/tvcg.2009.190;10.1109/tvcg.2007.70545;10.1109/tvcg.2006.186;10.1109/tvcg.2006.199;10.1109/tvcg.2008.143;10.1109/tvcg.2007.70557;10.1109/tvcg.2008.183;10.1109/tvcg.2011.260;10.1109/tvcg.2012.274;10.1109/tvcg.2013.141;10.1109/tvcg.2013.18;10.1109/tvcg.2013.189;10.1109/tvcg.2009.198;10.1109/tvcg.2015.2466838,"Superfluid dynamics,vortex structure,,,,,,,,,,,visual analysis",,6,49,627,,
CG&A,2016,Sports Tournament Predictions Using Direct Manipulation,10.1109/mcg.2016.90,http://dx.doi.org/10.1109/MCG.2016.90,62,71,MAG,"An advanced interface for sports tournament predictions uses direct manipulation to allow users to make nonlinear predictions. Unlike previous interface designs, the interface helps users focus on their prediction tasks by enabling them to first choose a winner and then fill out the rest of the bracket. In real-world tests of the proposed interface (for the 2014 FIFA World Cup tournament and 2015/2016 UEFA Champions League), the authors validated the use of direct manipulation as an alternative to widgets. Using visitor interaction logs, they were able to determine the strategies people use to perform predictions and identify potential areas of improvement for further prediction interfaces.",Romain Vuillemot;Charles Perin,Romain Vuillemot;Charles Perin,Université de Lyon;University of Calgary,0.1109/tvcg.2014.2346575;10.1109/tvcg.2015.2467201;10.1109/tvcg.2014.2346250,"computer graphics,user interface design,,,,,,,,,,,nonlinear predictions,,,,,,,,,,,direct manipulation,,,,human-computer interaction,information visualization,user-generated predictions",,7,13,511,,
TVCG,2013,A Metric for the Evaluation of Dense Vector Field Visualizations,10.1109/tvcg.2012.170,http://dx.doi.org/10.1109/TVCG.2012.170,1122,1132,J,"In this work, we present an intuitive image-quality metric that is derived from the motivation of DVF visualization. It utilizes the features of the resulting image and effectively measures the similarity between the output of the visualization method and the input flow data. We use the angle between the gradient direction and the original vector field as a measure of such similarity and the gradient magnitude as an importance measure. Our metric enables the automatic evaluation of images for a given vector field and allows the comparison of different methods, parameters sets, and quality improvement strategies for a specific vector field. By integrating the metric into the image-computation process, our approach can be used to generate improved images by choosing the best parameter set. To verify the effectiveness of our method, we conducted an extensive user study that demonstrated the metric's applicability to various situations. For instance, our approach elucidated the robustness of a DVF visualization in the presence of data-altering filters, such as resampling.",Victor Matvienko;Jens H. Krüger,Victor Matvienko;Jens Krüger,"Saarland University Cluster of Excellence MMCI, IVDA group, Saarbrücken, Germany;IVDA, DFKI, Intel VCI and SCI",0.1109/visual.2001.964505;10.1109/tvcg.2009.126;10.1109/tvcg.2006.161;10.1109/tvcg.2010.227;10.1109/visual.1996.567784;10.1109/visual.2003.1250361,"Visualization evaluation,texture-based visualization,,,,,,,,,,,LIC",,6,28,683,,
TVCG,2013,Visualizing Natural Image Statistics,10.1109/tvcg.2012.312,http://dx.doi.org/10.1109/TVCG.2012.312,1228,1241,J,"Natural image statistics is an important area of research in cognitive sciences and computer vision. Visualization of statistical results can help identify clusters and anomalies as well as analyze deviation, distribution, and correlation. Furthermore, they can provide visual abstractions and symbolism for categorized data. In this paper, we begin our study of visualization of image statistics by considering visual representations of power spectra, which are commonly used to visualize different categories of images. We show that they convey a limited amount of statistical information about image categories and their support for analytical tasks is ineffective. We then introduce several new visual representations, which convey different or more information about image statistics. We apply ANOVA to the image statistics to help select statistically more meaningful measurements in our design process. A task-based user evaluation was carried out to compare the new visual representations with the conventional power spectra plots. Based on the results of the evaluation, we made further improvement of visualizations by introducing composite visual representations of image statistics.",Hui Fang 0003;Gary Kwok-Leung Tam;Rita Borgo;Andrew J. Aubrey;Philip W. Grant;Paul L. Rosin;Christian Wallraven;Douglas W. Cunningham;A. David Marshall;Min Chen 0001,Hui Fang;Gary Kwok-Leung Tam;Rita Borgo;Andrew J. Aubrey;Philip W. Grant;Paul L. Rosin;Christian Wallraven;Douglas Cunningham;David Marshall;Min Chen,"Department of Computer Science, Swansea University, Swansea, UK;Department of Computer Science, Swansea University, Swansea, UK;Department of Computer Science, Swansea University, Swansea, UK;Department of Computer Science, Cardiff University, Cardiff, UK;Department of Computer Science, Swansea University, Swansea, UK;Department of Computer Science, Cardiff University, Cardiff, UK;Department of Brain and Cognitive Engineering, Korea University, Seoul, South Korea;Brandenburg University of Technology, Germany;Department of Computer Science, Cardiff University, Cardiff, UK;Oxford e-Research Centre, University of Oxford, Oxford, UK",0.1109/tvcg.2010.161,"Image statistics,image visualization,,,,,,,,,,,usability study,,,,,,,,,,,visual design",,6,35,1301,,
TVCG,2012,Simplification of Node Position Data ;for Interactive Visualization of Dynamic Data Sets,10.1109/tvcg.2011.268,http://dx.doi.org/10.1109/TVCG.2011.268,1537,1548,J,"We propose to aid the interactive visualization of time-varying spatial data sets by simplifying node position data over the entire simulation as opposed to over individual states. Our approach is based on two observations. The first observation is that the trajectory of some nodes can be approximated well without recording the position of the node for every state. The second observation is that there are groups of nodes whose motion from one state to the next can be approximated well with a single transformation. We present data set simplification techniques that take advantage of this node data redundancy. Our techniques are general, supporting many types of simulations, they achieve good compression factors, and they allow rigorous control of the maximum node position approximation error. We demonstrate our approach in the context of finite element analysis data, of liquid flow simulation data, and of fusion simulation data.",Paul Rosen 0001;Voicu Popescu,Paul Rosen;Voicu Popescu,"Scientific Computing and Imaging Institute, University of Utah, Salt Lake, UT, USA;Computer Science Department, Purdue University, West Lafayette, IN, USA",0.1109/tvcg.2006.143;10.1109/visual.2000.885711;10.1109/visual.2002.1183794;10.1109/visual.1999.809868;10.1109/visual.2002.1183768,"Simplification of node positions,trajectory simplification,,,,,,,,,,,trajectory clustering,,,,,,,,,,,rigid body decomposition,,,,interactive visualization,simulation data compression.",,4,43,483,,
CG&A,2016,WarpIV: In Situ Visualization and Analysis of Ion Accelerator Simulations,10.1109/mcg.2016.62,http://dx.doi.org/10.1109/MCG.2016.62,22,35,MAG,"The generation of short pulses of ion beams through the interaction of an intense laser with a plasma sheath offers the possibility of compact and cheaper ion sources for many applications--from fast ignition and radiography of dense targets to hadron therapy and injection into conventional accelerators. To enable the efficient analysis of large-scale, high-fidelity particle accelerator simulations using the Warp simulation suite, the authors introduce the Warp In situ Visualization Toolkit (WarpIV). WarpIV integrates state-of-the-art in situ visualization and analysis using VisIt with Warp, supports management and control of complex in situ visualization and analysis workflows, and implements integrated analytics to facilitate query- and feature-based data analytics and efficient large-scale data analysis. WarpIV enables for the first time distributed parallel, in situ visualization of the full simulation data using high-performance compute resources as the data is being generated by Warp. The authors describe the application of WarpIV to study and compare large 2D and 3D ion accelerator simulations, demonstrating significant differences in the acceleration process in 2D and 3D simulations. WarpIV is available to the public via https://bitbucket.org/berkeleylab/warpiv. The Warp In situ Visualization Toolkit (WarpIV) supports large-scale, parallel, in situ visualization and analysis and facilitates query- and feature-based analytics, enabling for the first time high-performance analysis of large-scale, high-fidelity particle accelerator simulations while the data is being generated by the Warp simulation suite. This supplemental material https://extras.computer.org/extra/mcg2016030022s1.pdf provides more details regarding the memory profiling and optimization and the Yee grid recentering optimization results discussed in the main article.",Oliver Rübel;Burlen Loring;Jean-Luc Vay;David P. Grote;Rémi Lehe;Stepan Bulanov;Henri Vincenti;E. Wes Bethel,Oliver Rübel;Burlen Loring;Jean-Luc Vay;David P. Grote;Remi Lehe;Stepan Bulanov;Henri Vincenti;E. Wes Bethel,Lawrence Berkeley National Laboratory;Lawrence Berkeley National Laboratory;Lawrence Berkeley National Laboratory;Lawrence Livermore National Laboratory;Lawrence Berkeley National Laboratory;Lawrence Berkeley National Laboratory;Lawrence Berkeley National Laboratory;Lawrence Berkeley National Laboratory,,"computer graphics,data visualization,,,,,,,,,,,in situ visualization,,,,,,,,,,,particle rendering,,,,data analysis,nuclear sciences,plasma sciences,particle beams,ion beams",,4,13,329,,
CG&A,2017,A Decision-Support System for Sustainable Water Distribution System Planning,10.1109/mcg.2015.120,http://dx.doi.org/10.1109/MCG.2015.120,44,55,MAG,"An interactive decision-support system (DSS) can help experts prepare water resource management plans for decision makers and stakeholders. The design of the proposed prototype incorporates visualization techniques such as circle views, grid layout, small multiple maps, and node simplification to improve the data readability of water distribution systems. A case study with three urban water management and sanitary engineering experts revealed that the proposed DSS is satisfactory, efficient, and effective.",Alina Freund;Nazli Yonca Aydin;Dirk Zeckzer;Hans Hagen,Alina Freund;Nazli Yonca Aydin;Dirk Zeckzer;Hans Hagen,University of Kaiserslautern;University of Kaiserslautern;Leipzig University;University of Kaiserslautern,,"computer graphics,multiattribute visualization,,,,,,,,,,,network graphs,,,,,,,,,,,time-dependent attributes,,,,decision-support system,water resource management",,4,32,806,,
CG&A,2017,Glyph Visualization: A Fail-Safe Design Scheme Based on Quasi-Hamming Distances,10.1109/mcg.2016.66,http://dx.doi.org/10.1109/MCG.2016.66,31,41,MAG,"In many spatial and temporal visualization applications, glyphs provide an effective means for encoding multivariate data. However, because glyphs are typically small, they are vulnerable to various perceptual errors. This article introduces the concept of a quasi-Hamming distance in the context of glyph design and examines the feasibility of estimating the quasi-Hamming distance between a pair of glyphs and the minimal Hamming distance for a glyph set. The authors demonstrate the design concept by developing a file-system event visualization that can depict the activities of multiple users.",Philip A. Legg;Eamonn Maguire;Simon J. Walton;Min Chen 0001,Philip A. Legg;Eamonn Maguire;Simon Walton;Min Chen,University of the West of England;CERN European Laboratory for Particle Physics;University of Oxford;University of Oxford,0.1109/infvis.2004.27;10.1109/tvcg.2012.271;10.1109/visual.1991.175815;10.1109/tvcg.2010.132,"computer graphics,glyph-based visualization,,,,,,,,,,,information visualization,,,,,,,,,,,glyph designs",,3,18,502,,
CG&A,2017,Layered Graph Drawing for Visualizing Evaluation Structures,10.1109/mcg.2016.40,http://dx.doi.org/10.1109/MCG.2016.40,20,30,MAG,"An evaluation structure is a hierarchical structure of human cognition extracted from interviews based on the evaluation grid method. An evaluation structure can be defined as a directed acyclic graph (DAG). The authors propose a layer-assignment method that is part of the Sugiyama framework, a popular method for drawing DAGs, to satisfy the requirements for drawing evaluation structures. Their evaluations demonstrate that the layered graph drawing produced by the proposed layer-assignment method is preferred by users and aids in the understanding of evaluation structures.",Yosuke Onoue;Nobuyuki Kukimoto;Naohisa Sakamoto;Kazuo Misue;Koji Koyamada,Yosuke Onoue;Nobuyuki Kukimoto;Naohisa Sakamoto;Kazuo Misue;Koji Koyamada,Kyoto University;Kyoto University;Kyoto University;University of Tsukuba;Kyoto University,0.1109/tvcg.2009.109;10.1109/tvcg.2008.155;10.1109/tvcg.2011.185,"computer graphics,layered graph drawing,,,,,,,,,,,Sugiyama framework,,,,,,,,,,,evaluation grid method,,,,Kansei engineering",,3,29,446,,
CG&A,2015,A Graph-Based Method for Detecting Rare Events: Identifying Pathologic Cells,10.1109/mcg.2014.78,http://dx.doi.org/10.1109/MCG.2014.78,65,73,MAG,"Detection of outliers and anomalous behavior is a well-known problem in the data mining and statistics fields. Although the problem of identifying single outliers has been extensively studied in the literature, little effort has been devoted to detecting small groups of outliers that are similar to each other but markedly different from the entire population. Many real-world scenarios have small groups of outliers--for example, a group of students who excel in a classroom or a group of spammers in an online social network. In this article, the authors propose a novel method to solve this challenging problem that lies at the frontiers of outlier detection and clustering of similar groups. The method transforms a multidimensional dataset into a graph, applies a network metric to detect clusters, and renders a representation for visual assessment to find rare events. The authors tested the proposed method to detect pathologic cells in the biomedical science domain. The results are promising and confirm the available ground truth provided by the domain experts.",Eniko Szekely;Arnaud Sallaberry;Faraz Zaidi;Pascal Poncelet,Enikö Székely;Arnaud Sallaberry;Faraz Zaidi;Pascal Poncelet,"New York University;Universite Paul Valery;University of Lausanne, Karachi Institute of Economics and Technology;Université Montpellier 2",0.1109/infvis.2003.1249011,"computer graphics,outlier detection,,,,,,,,,,,rare events,,,,,,,,,,,group of outliers,,,,visualization,clustering,pathologic cells",,1,14,633,,
TVCG,2012,Unified Boundary-Aware Texturing for Interactive Volume Rendering,10.1109/tvcg.2011.285,http://dx.doi.org/10.1109/TVCG.2011.285,1942,1955,J,"In this paper, we describe a novel approach for applying texture mapping to volumetric data sets. In contrast to previous approaches, the presented technique enables a unified integration of 2D and 3D textures and thus allows to emphasize material boundaries as well as volumetric regions within a volumetric data set at the same time. One key contribution of this paper is a parametrization technique for volumetric data sets, which takes into account material boundaries and volumetric regions. Using this technique, the resulting parametrizations of volumetric data sets enable texturing effects which create a higher degree of realism in volume rendered images. We evaluate the quality of the parametrization and demonstrate the usefulness of the proposed concepts by combining volumetric texturing with volumetric lighting models to generate photorealistic volume renderings. Furthermore, we show the applicability in the area of illustrative visualization.",Timo Ropinski;Stefan Diepenbrock;Stefan Bruckner;Klaus H. Hinrichs;M. Eduard Gröller,Timo Ropinski;Stefan Diepenbrock;Stefan Bruckner;Klaus Hinrichs;Eduard Gröller,"University of Linköping, Norrköping, Sweden;University of Münster, Muenster, Germany;Vienna University of Technology, Wien, Austria;University of Münster, Muenster, Germany;Technical University Vienna, Vienna",0.1109/visual.2002.1183787;10.1109/visual.2000.885696;10.1109/tvcg.2008.120;10.1109/tvcg.2008.161;10.1109/visual.2001.964519;10.1109/visual.1998.745325;10.1109/tvcg.2008.170,"Volumetric texturing,interactive volume rendering",,0,63,531,,
TVCG,2013,Visualization and Visual Analysis of Multifaceted Scientific Data: A Survey,10.1109/tvcg.2012.110,http://dx.doi.org/10.1109/TVCG.2012.110,495,513,J,"Visualization and visual analysis play important roles in exploring, analyzing, and presenting scientific data. In many disciplines, data and model scenarios are becoming multifaceted: data are often spatiotemporal and multivariate; they stem from different data sources (multimodal data), from multiple simulation runs (multirun/ensemble data), or from multiphysics simulations of interacting phenomena (multimodel data resulting from coupled simulation models). Also, data can be of different dimensionality or structured on various types of grids that need to be related or fused in the visualization. This heterogeneity of data characteristics presents new opportunities as well as technical challenges for visualization research. Visualization and interaction techniques are thus often combined with computational analysis. In this survey, we study existing methods for visualization and interactive visual analysis of multifaceted scientific data. Based on a thorough literature review, a categorization of approaches is proposed. We cover a wide range of fields and discuss to which degree the different challenges are matched with existing solutions for visualization and visual analysis. This leads to conclusions with respect to promising research directions, for instance, to pursue new solutions for multirun and multimodel data as well as techniques that support a multitude of facets.",Johannes Kehrer;Helwig Hauser,Johannes Kehrer;Helwig Hauser,"Department of Informatics, University of Bergen, Norway, Austria;Department of Informatics, University of Bergen, Norway",0.1109/tvcg.2007.70569;10.1109/visual.2005.1532781;10.1109/visual.1994.346302;10.1109/visual.2000.885739;10.1109/tvcg.2009.197;10.1109/tvcg.2006.170;10.1109/infvis.2005.1532138;10.1109/tvcg.2007.70617;10.1109/infvis.2002.1173157;10.1109/tvcg.2007.70591;10.1109/infvis.2004.3;10.1109/visual.1999.809905;10.1109/visual.2003.1250386;10.1109/tvcg.2008.116;10.1109/tvcg.2006.117;10.1109/visual.1997.663913;10.1109/tvcg.2009.199;10.1109/visual.1994.346298;10.1109/infvis.1999.801851;10.1109/infvis.2005.1532142;10.1109/tvcg.2006.165;10.1109/tvcg.2006.164;10.1109/tvcg.2007.70588;10.1109/tvcg.2007.70560;10.1109/tvcg.2010.111;10.1109/visual.1999.809873;10.1109/visual.1996.568140;10.1109/tvcg.2007.70534;10.1109/visual.2000.885736;10.1109/visual.2001.964550;10.1109/tvcg.2008.139;10.1109/infvis.2005.1532144;10.1109/tvcg.2010.171;10.1109/tvcg.2008.145;10.1109/visual.1993.398859;10.1109/infvis.2004.10;10.1109/vast.2009.5332611;10.1109/tvcg.2010.190;10.1109/vast.2010.5652460;10.1109/tvcg.2010.181;10.1109/tvcg.2006.152;10.1109/tvcg.2011.229;10.1109/tvcg.2008.153;10.1109/tvcg.2009.155;10.1109/tvcg.2011.183;10.1109/tvcg.2007.70515,"Visualization,interactive visual analysis,,,,,,,,,,,multirun,,,,,,,,,,,multimodel,,,,multimodal,multivariate,spatiotemporal data",,258,178,8223,,
TVCG,2011,The Design Space of Implicit Hierarchy Visualization: A Survey,10.1109/tvcg.2010.79,http://dx.doi.org/10.1109/TVCG.2010.79,393,411,J,"Apart from explicit node-link representations, implicit visualizations and especially the Treemap as their frontrunner have acquired a solid position among the available techniques to visualize hierarchies. Their advantage is a highly space-efficient graphical representation that does not require explicit drawing of edges. In this paper, we survey the design space for this class of visualization techniques. We establish the design space along the four axes of dimensionality, edge representation, node representation, and layout by examining existing implicit hierarchy visualization techniques. The survey is completed by casting some light into regions of the design space that have not yet been explored. Our design space is not a mere theoretical construct, but a practically usable tool for rapid visualization development. To that end, we discuss a software implementation of the introduced design space.",Hans-Jörg Schulz;Steffen Hadlak;Heidrun Schumann,Hans-Jorg Schulz;Steffen Hadlak;Heidrun Schumann,"Department of Computer Graphics, Institute of Computer Science, Faculty of Computer Science and Electrical Engineering, University of Rostock, Rostock, Germany;Department of Computer Graphics, Institute of Computer Science, Faculty of Computer Science and Electrical Engineering, University of Rostock, Rostock, Germany;Department of Computer Graphics, Institute of Computer Science, Faculty of Computer Science and Electrical Engineering, University of Rostock, Rostock, Germany",0.1109/infvis.1996.559212;10.1109/infvis.2003.1249027;10.1109/infvis.2001.963291;10.1109/tvcg.2008.165;10.1109/visual.2004.39;10.1109/visual.1992.235217;10.1109/infvis.2002.1173153;10.1109/visual.1996.567745;10.1109/infvis.1999.801860;10.1109/infvis.2005.1532145;10.1109/tvcg.2007.70529;10.1109/visual.1991.175815;10.1109/infvis.2000.885091;10.1109/tvcg.2006.200;10.1109/infvis.1998.729557;10.1109/tvcg.2009.128;10.1109/infvis.2005.1532128,"Information visualization,hierarchy visualization,,,,,,,,,,,Treemaps,,,,,,,,,,,visualization design space,,,,rapid visualization prototyping.",,108,79,3081,,
TVCG,2013,Splatterplots: Overcoming Overdraw in Scatter Plots,10.1109/tvcg.2013.65,http://dx.doi.org/10.1109/TVCG.2013.65,1526,1538,J,"We introduce Splatterplots, a novel presentation of scattered data that enables visualizations that scale beyond standard scatter plots. Traditional scatter plots suffer from overdraw (overlapping glyphs) as the number of points per unit area increases. Overdraw obscures outliers, hides data distributions, and makes the relationship among subgroups of the data difficult to discern. To address these issues, Splatterplots abstract away information such that the density of data shown in any unit of screen space is bounded, while allowing continuous zoom to reveal abstracted details. Abstraction automatically groups dense data points into contours and samples remaining points. We combine techniques for abstraction with perceptually based color blending to reveal the relationship between data subgroups. The resulting visualizations represent the dense regions of each subgroup of the data set as smooth closed shapes and show representative outliers explicitly. We present techniques that leverage the GPU for Splatterplot computation and rendering, enabling interaction with massive data sets. We show how Splatterplots can be an effective alternative to traditional methods of displaying scatter data communicating data trends, outliers, and data set relationships much like traditional scatter plots, but scaling to data sets of higher density and up to millions of points on the screen.",Adrian Mayorga;Michael Gleicher,Adrian Mayorga;Michael Gleicher,"Department of Computer Sciences, University of Wisconsin-Madison, Madison, WI, USA;Department of Computer Sciences, University of Wisconsin-Madison, Madison, WI, USA",0.1109/tvcg.2007.70535;10.1109/tvcg.2008.119;10.1109/tvcg.2007.70596;10.1109/tvcg.2010.197;10.1109/tvcg.2009.175;10.1109/tvcg.2007.70623;10.1109/tvcg.2009.122;10.1109/tvcg.2008.153,"Scalability issues,visual design,,,,,,,,,,,perception theory,,,,,,,,,,,statistical graphics",,106,38,3282,,
TVCG,2013,KelpFusion: A Hybrid Set Visualization Technique,10.1109/tvcg.2013.76,http://dx.doi.org/10.1109/TVCG.2013.76,1846,1858,J,"We present KelpFusion: a method for depicting set membership of items on a map or other visualization using continuous boundaries. KelpFusion is a hybrid representation that bridges hull techniques such as Bubble Sets and Euler diagrams and line- and graph-based techniques such as LineSets and Kelp Diagrams. We describe an algorithm based on shortest-path graphs to compute KelpFusion visualizations. Based on a single parameter, the shortest-path graph varies from the minimal spanning tree to the convex hull of a point set. Shortest-path graphs aim to capture the shape of a point set and smoothly adapt to sets of varying densities. KelpFusion fills enclosed faces based on a set of simple legibility rules. We present the results of a controlled experiment comparing KelpFusion to Bubble Sets and LineSets. We conclude that KelpFusion outperforms Bubble Sets both in accuracy and completion time and outperforms LineSets in completion time.",Wouter Meulemans;Nathalie Henry Riche;Bettina Speckmann;Basak Alper;Tim Dwyer,Wouter Meulemans;Nathalie Henry Riche;Bettina Speckmann;Basak Alper;Tim Dwyer,"Technische Universitat Eindhoven, Eindhoven, Netherlands;Microsoft Research, Redmond, WA, USA;Technische Universitat Eindhoven, Eindhoven, Netherlands;University of California, Santa Barbara, Santa Barbara, CA, USA;Monash University, Caulfield East, VIC, Australia",0.1109/tvcg.2009.122;10.1109/tvcg.2010.210;10.1109/tvcg.2011.186,"Information visualization,visualization techniques and methodologies",,76,19,1568,,
TVCG,2012,Conceptual Recurrence Plots: Revealing Patterns in Human Discourse,10.1109/tvcg.2011.100,http://dx.doi.org/10.1109/TVCG.2011.100,988,997,J,"Human discourse contains a rich mixture of conceptual information. Visualization of the global and local patterns within this data stream is a complex and challenging problem. Recurrence plots are an information visualization technique that can reveal trends and features in complex time series data. The recurrence plot technique works by measuring the similarity of points in a time series to all other points in the same time series and plotting the results in two dimensions. Previous studies have applied recurrence plotting techniques to textual data; however, these approaches plot recurrence using term-based similarity rather than conceptual similarity of the text. We introduce conceptual recurrence plots, which use a model of language to measure similarity between pairs of text utterances, and the similarity of all utterances is measured and displayed. In this paper, we explore how the descriptive power of the recurrence plotting technique can be used to discover patterns of interaction across a series of conversation transcripts. The results suggest that the conceptual recurrence plotting technique is a useful tool for exploring the structure of human discourse.",Daniel Angus;Andrew E. Smith;Janet Wiles,Daniel Angus;Andrew Smith;Janet Wiles,"School of Information Technology and Electrical Engineering, University of Queensland, St Lucia, QLD, Australia;School of Information Technology and Electrical Engineering, Institute for Social Science Research, University of Queensland, St Lucia, QLD, Australia;School of Information Technology and Electrical Engineering, University of Queensland, St Lucia, QLD, Australia",0.1109/infvis.2002.1173155;10.1109/infvis.2004.10;10.1109/visual.1995.485140;10.1109/infvis.2000.885098,"Concept map,recurrence,,,,,,,,,,,concept,,,,,,,,,,,plotting,,,,conversation analysis,text analysis.",,65,18,1770,,
TVCG,2011,Forecasting Hotspots—A Predictive Analytics Approach,10.1109/tvcg.2010.82,http://dx.doi.org/10.1109/TVCG.2010.82,440,453,J,"Current visual analytics systems provide users with the means to explore trends in their data. Linked views and interactive displays provide insight into correlations among people, events, and places in space and time. Analysts search for events of interest through statistical tools linked to visual displays, drill down into the data, and form hypotheses based upon the available information. However, current systems stop short of predicting events. In spatiotemporal data, analysts are searching for regions of space and time with unusually high incidences of events (hotspots). In the cases where hotspots are found, analysts would like to predict how these regions may grow in order to plan resource allocation and preventative measures. Furthermore, analysts would also like to predict where future hotspots may occur. To facilitate such forecasting, we have created a predictive visual analytics toolkit that provides analysts with linked spatiotemporal and statistical analytic views. Our system models spatiotemporal events through the combination of kernel density estimation for event distribution and seasonal trend decomposition by loess smoothing for temporal predictions. We provide analysts with estimates of error in our modeling, along with spatial and temporal alerts to indicate the occurrence of statistically significant hotspots. Spatial data are distributed based on a modeling of previous event locations, thereby maintaining a temporal coherence with past events. Such tools allow analysts to perform real-time hypothesis testing, plan intervention strategies, and allocate resources to correspond to perceived threats.",Ross Maciejewski;Ryan Hafen;Stephen Rudolph;Stephen G. Larew;Michael A. Mitchell;William S. Cleveland;David S. Ebert,Ross Maciejewski;Ryan Hafen;Stephen Rudolph;Stephen G. Larew;Michael A. Mitchell;William S. Cleveland;David S. Ebert,"Purdue University, West Lafayette, IN, USA;Purdue University, West Lafayette, IN, USA;Purdue University, West Lafayette, IN, USA;Purdue University, West Lafayette, IN, USA;Purdue University, West Lafayette, IN, USA;Purdue University, West Lafayette, IN, USA;Purdue University, West Lafayette, IN, USA",0.1109/visual.2000.885679;10.1109/tvcg.2008.149;10.1109/infvis.2004.27;10.1109/vast.2007.4389006;10.1109/vast.2007.4388993;10.1109/infvis.1998.729563,"Predictive analytics,visual analytics,,,,,,,,,,,syndromic surveillance.",,64,47,2968,,
TVCG,2013,The Five Ws for Information Visualization with Application to Healthcare Informatics,10.1109/tvcg.2013.89,http://dx.doi.org/10.1109/TVCG.2013.89,1895,1910,J,"The Five Ws is a popular concept for information gathering in journalistic reporting. It captures all aspects of a story or incidence: who, when, what, where, and why. We propose a framework composed of a suite of cooperating visual information displays to represent the Five Ws and demonstrate its use within a healthcare informatics application. Here, the who is the patient, the where is the patient's body, and the when, what, why is a reasoning chain which can be interactively sorted and brushed. The patient is represented as a radial sunburst visualization integrated with a stylized body map. This display captures all health conditions of the past and present to serve as a quick overview to the interrogating physician. The reasoning chain is represented as a multistage flow chart, composed of date, symptom, data, diagnosis, treatment, and outcome. Our system seeks to improve the usability of information captured in the electronic medical record (EMR) and we show via multiple examples that our framework can significantly lower the time and effort needed to access the medical patient information required to arrive at a diagnostic conclusion.",Zhiyuan Zhang 0006;Bing Wang 0007;Faisal Ahmed 0001;I. V. Ramakrishnan;Rong Zhao;Asa Viccellio;Klaus Mueller 0001,Zhiyuan Zhang;Bing Wang;Faisal Ahmed;I.V. Ramakrishnan;Rong Zhao;Asa Viccellio;Klaus Mueller,"Visual Analytics and Imaging Laboratory at the Computer Science Department, Stony Brook University, NY, USA;Visual Analytics and Imaging Laboratory at the Computer Science Department, Stony Brook University, NY, USA;Applied Logic Laboratory at the Computer Science Department, Stony Brook University, NY, USA;Applied Logic Laboratory at the Computer Science Department, Stony Brook University, NY, USA;Computer Science Department, Stony Brook University, NY, USA;Department of Emergency Medicine, Stony Brook University Hospital, NY, USA;Visual Analytics and Imaging Laboratory at the Computer Science Department, Stony Brook University, NY, USA",0.1109/visual.1991.175815;10.1109/tvcg.2006.147;10.1109/tvcg.2012.225;10.1109/tvcg.2010.209;10.1109/infvis.2000.885091;10.1109/tvcg.2010.179,"Visual knowledge representation,data fusion and integration,,,,,,,,,,,coordinated and multiple views,,,,,,,,,,,focus and context,,,,health informatics,electronic medical record (EMR),electronic health record (EHR)",,53,41,2710,,
TVCG,2012,Streamline Embedding for 3D Vector Field Exploration,10.1109/tvcg.2011.78,http://dx.doi.org/10.1109/TVCG.2011.78,407,420,J,"We propose a new technique for visual exploration of streamlines in 3D vector fields. We construct a map from the space of all streamlines to points in IRn based on the preservation of the Hausdorff metric in streamline space. The image of a vector field under this map is a set of 2-manifolds in IRn with characteristic geometry and topology. Then standard clustering methods applied to the point sets in IRn yield a segmentation of the original vector field. Our approach provides a global analysis of 3D vector fields which incorporates the topological segmentation but yields additional information. In addition to a pure segmentation, the established map provides a natural ""parametrization” visualized by the manifolds. We test our approach on a number of synthetic and real-world data sets.",Christian Rössl;Holger Theisel,Christian Rossl;Holger Theisel,"Institut für Simulation und Graphik, AG Visual Computing, Otto-von-Guericke-Universität Magdeburg, Magdeburg, Germany;Institut für Simulation und Graphik, AG Visual Computing, Otto-von-Guericke-Universität Magdeburg, Magdeburg, Germany",0.1109/visual.2004.32;10.1109/visual.1999.809904;10.1109/visual.1999.809865;10.1109/visual.2005.1532778;10.1109/visual.1999.809863;10.1109/visual.2003.1250376;10.1109/visual.1997.663858;10.1109/visual.2005.1532779;10.1109/visual.2000.885690;10.1109/tvcg.2009.112,"Vector fields,streamline embedding,,,,,,,,,,,clustering.",,49,41,1083,,
TVCG,2013,A Survey of Visualization Pipelines,10.1109/tvcg.2012.133,http://dx.doi.org/10.1109/TVCG.2012.133,367,378,J,"The most common abstraction used by visualization libraries and applications today is what is known as the visualization pipeline. The visualization pipeline provides a mechanism to encapsulate algorithms and then couple them together in a variety of ways. The visualization pipeline has been in existence for over 20 years, and over this time many variations and improvements have been proposed. This paper provides a literature review of the most prevalent features of visualization pipelines and some of the most recent research directions.",Kenneth Moreland,Kenneth Moreland,"Sandia National Laboratories, Albuquerque, NM",0.1109/visual.1997.663888;10.1109/visual.1999.809864;10.1109/tvcg.2006.128;10.1109/visual.2005.1532788;10.1109/visual.2002.1183791;10.1109/tvcg.2010.259;10.1109/tvcg.2008.174;10.1109/tvcg.2007.70584;10.1109/visual.1996.568115;10.1109/visual.1992.235219;10.1109/visual.1992.235205;10.1109/visual.1993.398879;10.1109/visual.1991.175811;10.1109/visual.1995.480821;10.1109/visual.1999.809891;10.1109/tvcg.2007.70600;10.1109/tvcg.2008.184;10.1109/tvcg.2008.157;10.1109/visual.1998.745299,"Visualization pipelines,dataflow networks,temporal visualization,pipeline contracts,prioritized streaming,query-driven visualization,parallel visualization,task parallelism,pipeline parallelism,data parallelism,rendering,hybrid parallel,event driven,provenance,scheduling,in situ visualization,functional field model,MapReduce,domain specific languages,,,,,push model,,,,demand driven,pull model,central control,distributed control,pipeline executive,out-of-core streaming",,52,106,2802,,
TVCG,2012,"Toward Visualization for Games: Theory, Design Space, and Patterns",10.1109/tvcg.2012.77,http://dx.doi.org/10.1109/TVCG.2012.77,1956,1968,J,"Electronic games are starting to incorporate in-game telemetry that collects data about player, team, and community performance on a massive scale, and as data begins to accumulate, so does the demand for effectively analyzing this data. In this paper, we use examples from both old and new games of different genres to explore the theory and design space of visualization for games. Drawing on these examples, we define a design space for this novel research topic and use it to formulate design patterns for how to best apply visualization technology to games. We then discuss the implications that this new framework will potentially have on the design and development of game and visualization technology in the future.",Brian Bowman;Niklas Elmqvist;T. J. Jankun-Kelly,Brian Bowman;Niklas Elmqvist;T.J. Jankun-Kelly,"School of Electrical and Computer Engineering, Purdue University, West Lafayette, IN, USA;School of Electrical and Computer Engineering, Purdue University, West Lafayette, IN, USA;Department of Computer Science and Engineering, Bagley College of Engineering, Mississippi State University, MS, USA",0.1109/visual.2004.120;10.1109/tvcg.2008.166;10.1109/tvcg.2007.70541,"Computer games,video games,,,,,,,,,,,interactive entertainment,,,,,,,,,,,entertainment,,,,visualization,game analytics",,50,91,2517,,
TVCG,2013,TimeSeer: Scagnostics for High-Dimensional Time Series,10.1109/tvcg.2012.128,http://dx.doi.org/10.1109/TVCG.2012.128,470,483,J,"We introduce a method (Scagnostic time series) and an application (TimeSeer) for organizing multivariate time series and for guiding interactive exploration through high-dimensional data. The method is based on nine characterizations of the 2D distributions of orthogonal pairwise projections on a set of points in multidimensional euclidean space. These characterizations include measures, such as, density, skewness, shape, outliers, and texture. Working directly with these Scagnostic measures, we can locate anomalous or interesting subseries for further analysis. Our application is designed to handle the types of doubly multivariate data series that are often found in security, financial, social, and other sectors.",Dang Tuan Nhon;Anushka Anand;Leland Wilkinson,Tuan Nhon Dang;Anushka Anand;Leland Wilkinson,"Department of Computer Science, University of Illinois at Chicago, Chicago, IL;Department of Computer Science, University of Illinois at Chicago, Chicago, IL;SYSTAT Software Inc, University of Illinois at Chicago, Chicago, IL",0.1109/vast.2006.261423;10.1109/tvcg.2010.184;10.1109/infvis.2005.1532136;10.1109/infvis.2001.963273;10.1109/infvis.2005.1532142;10.1109/tvcg.2008.166;10.1109/infvis.1999.801851;10.1109/infvis.2000.885098;10.1109/tvcg.2008.131,"Scagnostics,scatterplot matrix,,,,,,,,,,,high-dimensional visual analytics,,,,,,,,,,,multiple time series",,43,48,1446,,
TVCG,2012,Model-Driven Design for the Visual Analysis of Heterogeneous Data,10.1109/tvcg.2011.108,http://dx.doi.org/10.1109/TVCG.2011.108,998,1010,J,"As heterogeneous data from different sources are being increasingly linked, it becomes difficult for users to understand how the data are connected, to identify what means are suitable to analyze a given data set, or to find out how to proceed for a given analysis task. We target this challenge with a new model-driven design process that effectively codesigns aspects of data, view, analytics, and tasks. We achieve this by using the workflow of the analysis task as a trajectory through data, interactive views, and analytical processes. The benefits for the analysis session go well beyond the pure selection of appropriate data sets and range from providing orientation or even guidance along a preferred analysis path to a potential overall speedup, allowing data to be fetched ahead of time. We illustrate the design process for a biomedical use case that aims at determining a treatment plan for cancer patients from the visual analysis of a large, heterogeneous clinical data pool. As an example for how to apply the comprehensive design approach, we present Stack'n'flip, a sample implementation which tightly integrates visualizations of the actual data with a map of available data sets, views, and tasks, thus capturing and communicating the analytical workflow through the required data sets.",Marc Streit;Hans-Jörg Schulz;Alexander Lex;Dieter Schmalstieg;Heidrun Schumann,Marc Streit;Hans-Jorg Schulz;Alexander Lex;Dieter Schmalstieg;Heidrun Schumann,"Institute for Computer Graphics and Vision, Graz University of Technology, Graz, Austria;Department of Computer Graphics, Institute of Computer Science, Faculty of Computer Science and Electrical Engineering, University of Rostock, Rostock, Germany;Institute for Computer Graphics and Vision, Graz University of Technology, Graz, Austria;Institute for Computer Graphics and Vision, Graz University of Technology, Graz, Austria;Department of Computer Graphics, Institute of Computer Science, Faculty of Computer Science and Electrical Engineering, University of Rostock, Rostock, Germany",0.1109/tvcg.2008.174;10.1109/tvcg.2007.70589;10.1109/infvis.2004.2;10.1109/tvcg.2008.137;10.1109/tvcg.2007.70521;10.1109/tvcg.2009.111,"Visual analytics,analysis guidance,,,,,,,,,,,model-driven design,,,,,,,,,,,multiple data sets.",,38,28,1208,,
TVCG,2013,TripAdvisor^{N-D}: A Tourism-Inspired High-Dimensional Space Exploration Framework with Overview and Detail,10.1109/tvcg.2012.65,http://dx.doi.org/10.1109/TVCG.2012.65,291,305,J,"Gaining a true appreciation of high-dimensional space remains difficult since all of the existing high-dimensional space exploration techniques serialize the space travel in some way. This is not so foreign to us since we, when traveling, also experience the world in a serial fashion. But we typically have access to a map to help with positioning, orientation, navigation, and trip planning. Here, we propose a multivariate data exploration tool that compares high-dimensional space navigation with a sightseeing trip. It decomposes this activity into five major tasks: 1) Identify the sights: use a map to identify the sights of interest and their location; 2) Plan the trip: connect the sights of interest along a specifyable path; 3) Go on the trip: travel along the route; 4) Hop off the bus: experience the location, look around, zoom into detail; and 5) Orient and localize: regain bearings in the map. We describe intuitive and interactive tools for all of these tasks, both global navigation within the map and local exploration of the data distributions. For the latter, we describe a polygonal touchpad interface which enables users to smoothly tilt the projection plane in high-dimensional space to produce multivariate scatterplots that best convey the data relationships under investigation. Motion parallax and illustrative motion trails aid in the perception of these transient patterns. We describe the use of our system within two applications: 1) the exploratory discovery of data configurations that best fit a personal preference in the presence of tradeoffs and 2) interactive cluster analysis via cluster sculpting in N-D.",Julia Eunju Nam;Klaus Mueller 0001,Julia EunJu Nam;Klaus Mueller,"Microsoft Corporation, Redmond, WA, USA;Department of Computer Science, Stony Brook University (State University of New York), Stony Brook, NY, USA",0.1109/vast.2007.4388999;10.1109/visual.1990.146402;10.1109/infvis.2004.3;10.1109/tvcg.2007.70581;10.1109/tvcg.2008.153;10.1109/vast.2010.5652484;10.1109/vast.2008.4677352,"High-dimensional data,coordinated and multiple views,,,,,,,,,,,zooming and navigation techniques,,,,,,,,,,,data transformation and representation,,,,data clustering,visual analytics",,37,35,1665,,
TVCG,2014,A Structure-Based Distance Metric for High-Dimensional Space Exploration with Multidimensional Scaling,10.1109/tvcg.2013.101,http://dx.doi.org/10.1109/TVCG.2013.101,351,364,J,"Although the euclidean distance does well in measuring data distances within high-dimensional clusters, it does poorly when it comes to gauging intercluster distances. This significantly impacts the quality of global, low-dimensional space embedding procedures such as the popular multidimensional scaling (MDS) where one can often observe nonintuitive layouts. We were inspired by the perceptual processes evoked in the method of parallel coordinates which enables users to visually aggregate the data by the patterns the polylines exhibit across the dimension axes. We call the path of such a polyline its structure and suggest a metric that captures this structure directly in high-dimensional space. This allows us to better gauge the distances of spatially distant data constellations and so achieve data aggregations in MDS plots that are more cognizant of existing high-dimensional structure similarities. Our biscale framework distinguishes far-distances from near-distances. The coarser scale uses the structural similarity metric to separate data aggregates obtained by prior classification or clustering, while the finer scale employs the appropriate euclidean distance.",Jenny Hyunjung Lee;Kevin T. McDonnell;Alla Zelenyuk;Dan Imre;Klaus Mueller 0001,Jenny Hyunjung Lee;Kevin T. McDonnell;Alla Zelenyuk;Dan Imre;Klaus Mueller,"Department of Computer Science, Center for Visual Computing, Stony Brook, NY;Department of Mathematics and Computer Science, Dowling College, Oakdale, NY;Pacific Northwest National Laboratory, Richland, WA;Imre Consulting, Richland, WA;Department of Computer Science, Center for Visual Computing, Stony Brook, NY",0.1109/infvis.2004.60;10.1109/vast.2010.5652443;10.1109/vast.2009.5332629;10.1109/vast.2010.5652940;10.1109/visual.1990.146402,"Information visualization,multivariate visualization,,,,,,,,,,,clustering,,,,,,,,,,,high-dimensional data,,,,visual analytics",,35,32,1217,,
TVCG,2013,Computing Reeb Graphs as a Union of Contour Trees,10.1109/tvcg.2012.115,http://dx.doi.org/10.1109/TVCG.2012.115,249,262,J,"The Reeb graph of a scalar function tracks the evolution of the topology of its level sets. This paper describes a fast algorithm to compute the Reeb graph of a piecewise-linear (PL) function defined over manifolds and non-manifolds. The key idea in the proposed approach is to maximally leverage the efficient contour tree algorithm to compute the Reeb graph. The algorithm proceeds by dividing the input into a set of subvolumes that have loop-free Reeb graphs using the join tree of the scalar function and computes the Reeb graph by combining the contour trees of all the subvolumes. Since the key ingredient of this method is a series of union-find operations, the algorithm is fast in practice. Experimental results demonstrate that it outperforms current generic algorithms by a factor of up to two orders of magnitude, and has a performance on par with algorithms that are catered to restricted classes of input. The algorithm also extends to handle large data that do not fit in memory.",Harish Doraiswamy;Vijay Natarajan,Harish Doraiswamy;Vijay Natarajan,"Department of Computer Science and Automation, Indian Institute of Science, IISc PO, Bangalore, India;Department of Computer Science and Automation and Supercomputer Education and Research Centre, Indian Institute of Science, IISc PO, Bangalore, India",0.1109/tvcg.2009.163;10.1109/tvcg.2009.120;10.1109/visual.2004.96;10.1109/visual.1997.663875,"Computational topology,scalar functions,,,,,,,,,,,Reeb graphs,,,,,,,,,,,level set topology,,,,out-of-core algorithm",,36,47,630,,
TVCG,2013,A Time-Dependent Vector Field Topology Based on Streak Surfaces,10.1109/tvcg.2012.131,http://dx.doi.org/10.1109/TVCG.2012.131,379,392,J,"It was shown recently how the 2D vector field topology concept, directly applicable to stationary vector fields only, can be generalized to time-dependent vector fields by replacing the role of stream lines by streak lines [1]. The present paper extends this concept to 3D vector fields. In traditional 3D vector field topology separatrices can be obtained by integrating stream lines from 0D seeds corresponding to critical points. We show that in our new concept, in contrast, 1D seeding constructs are required for computing streak-based separatrices. In analogy to the 2D generalization we show that invariant manifolds can be obtained by seeding streak surfaces along distinguished path surfaces emanating from intersection curves between codimension-1 ridges in the forward and reverse finite-time Lyapunov exponent (FTLE) fields. These path surfaces represent a time-dependent generalization of critical points and convey further structure in time-dependent topology of vector fields. Compared to the traditional approach based on FTLE ridges, the resulting streak manifolds ease the analysis of Lagrangian coherent structures (LCS) with respect to visual quality and computational cost, especially when time series of LCS are computed. We exemplify validity and utility of the new approach using both synthetic examples and computational fluid dynamics results.",Markus Üffinger;Filip Sadlo;Thomas Ertl,Markus Uffinger;Filip Sadlo;Thomas Ertl,"Institute for Visualization and Interactive Systems, Universitätsstraße, Stuttgart, Germany;Visualization Research Center, Universität Stuttgart (VISUS), Stuttgart, Germany;Institute for Visualization and Interactive Systems, Universitätsstraße, Stuttgart, Germany",0.1109/tvcg.2010.169;10.1109/tvcg.2008.133;10.1109/tvcg.2009.154;10.1109/tvcg.2009.190;10.1109/tvcg.2010.198;10.1109/tvcg.2007.70557;10.1109/tvcg.2007.70551;10.1109/tvcg.2007.70554;10.1109/visual.1998.745297;10.1109/tvcg.2010.156;10.1109/visual.1999.809896;10.1109/tvcg.2010.227;10.1109/visual.1991.175773;10.1109/visual.2004.99,"Vector field topology,Lagrangian coherent structures,,,,,,,,,,,streak lines,,,,,,,,,,,time-dependent vector fields",,30,31,514,,
TVCG,2013,Using Patterns to Encode Color Information for Dichromats,10.1109/tvcg.2012.93,http://dx.doi.org/10.1109/TVCG.2012.93,118,129,J,"Color is one of the most common ways to convey information in visualization applications. Color vision deficiency (CVD) affects approximately 200 million individuals worldwide and considerably degrades their performance in understanding such contents by creating red-green or blue-yellow ambiguities. While several content-specific methods have been proposed to resolve these ambiguities, they cannot achieve this effectively in many situations for contents with a large variety of colors. More importantly, they cannot facilitate color identification. We propose a technique for using patterns to encode color information for individuals with CVD, in particular for dichromats. We present the first content-independent method to overlay patterns on colored visualization contents that not only minimizes ambiguities but also allows color identification. Further, since overlaying patterns does not compromise the underlying original colors, it does not hamper the perception of normal trichromats. We validated our method with two user studies: one including 11 subjects with CVD and 19 normal trichromats, and focused on images that use colors to represent multiple categories; and another one including 16 subjects with CVD and 22 normal trichromats, which considered a broader set of images. Our results show that overlaying patterns significantly improves the performance of dichromats in several color-based visualization tasks, making their performance almost similar to normal trichromats'. More interestingly, the patterns augment color information in a positive manner, allowing normal trichromats to perform with greater accuracy.",Behzad Sajadi;Aditi Majumder;Manuel M. Oliveira;Rosália G. Schneider;Ramesh Raskar,Behzad Sajadi;Aditi Majumder;Manuel M. Oliveira;Rosália G. Schneider;Ramesh Raskar,"Department of Computer Science, University of California Berkeley, Irvine, CA, USA;Department of Computer Science, University of California Berkeley, Irvine, CA, USA;Instituto de Informática, Universidade Federal do Rio Grande do Sul, Porto Alegre, Brazil;Instituto de Informática, Universidade Federal do Rio Grande do Sul, Porto Alegre, Brazil;Media Laboratories, Massachusetts Institute of Technology, Cambridge, MA, USA",0.1109/tvcg.2009.113;10.1109/tvcg.2008.112,"image colour analysis,colour vision,red-green ambiguity,blue-yellow ambiguity,content-specific methods,color identification,content-independent method,colored visualization contents,normal trichromats,Image color analysis,Visualization,Three dimensional displays,data visualisation,Color,Computed tomography,Data visualization,color visualization,Color vision deficiency,visual aids,patterns in visualization,,,,image coding,,,,color-based visualization tasks,color information encoding,dichromats,visualization applications,color vision deficiency,CVD",,35,40,1414,,
TVCG,2014,A Modular Degree-of-Interest Specification for the Visual Analysis of Large Dynamic Networks,10.1109/tvcg.2013.109,http://dx.doi.org/10.1109/TVCG.2013.109,337,350,J,"Large dynamic networks are targets of analysis in many fields. Tracking temporal changes at scale in these networks is challenging due in part to the fact that small changes can be missed or drowned-out by the rest of the network. For static networks, current approaches allow the identification of specific network elements within their context. However, in the case of dynamic networks, the user is left alone with finding salient local network elements and tracking them over time. In this work, we introduce a modular DoI specification to flexibly define what salient changes are and to assign them a measure of their importance in a time-varying setting. The specification takes into account neighborhood structure information, numerical attributes of nodes/edges, and their temporal evolution. A tailored visualization of the DoI specification complements our approach. Alongside a traditional node-link view of the dynamic network, it serves as an interface for the interactive definition of a DoI function. By using it to successively refine and investigate the captured details, it supports the analysis of dynamic networks from an initial view until pinpointing a user's analysis goal. We report on applying our approach to scientific coauthorship networks and give concrete results for the DBLP data set.",James Abello;Steffen Hadlak;Heidrun Schumann;Hans-Jörg Schulz,James Abello;Steffen Hadlak;Heidrun Schumann;Hans-Jörg Schulz,"Rutgers University, Piscataway, NJ;University of Rostock, Rostock, Mecklenburg Vorpommern, Germany;University of Rostock, Rostock, Mecklenburg Vorpommern, Germany;University of Rostock, Rostock, Mecklenburg Vorpommern, Germany",0.1109/tvcg.2009.108;10.1109/tvcg.2006.148;10.1109/tvcg.2008.166;10.1109/tvcg.2008.152,"Time-varying graphs,dynamic graph visualization,,,,,,,,,,,degree-of-interest",,29,37,1695,,
TVCG,2012,Efficient Visibility Encoding for Dynamic Illumination in Direct Volume Rendering,10.1109/tvcg.2011.35,http://dx.doi.org/10.1109/TVCG.2011.35,447,462,J,"We present an algorithm that enables real-time dynamic shading in direct volume rendering using general lighting, including directional lights, point lights, and environment maps. Real-time performance is achieved by encoding local and global volumetric visibility using spherical harmonic (SH) basis functions stored in an efficient multiresolution grid over the extent of the volume. Our method enables high-frequency shadows in the spatial domain, but is limited to a low-frequency approximation of visibility and illumination in the angular domain. In a first pass, level of detail (LOD) selection in the grid is based on the current transfer function setting. This enables rapid online computation and SH projection of the local spherical distribution of visibility information. Using a piecewise integration of the SH coefficients over the local regions, the global visibility within the volume is then computed. By representing the light sources using their SH projections, the integral over lighting, visibility, and isotropic phase functions can be efficiently computed during rendering. The utility of our method is demonstrated in several examples showing the generality and interactive performance of the approach.",Joel Kronander;Daniel Jönsson;Joakim Löw;Patric Ljung;Anders Ynnerman;Jonas Unger,Joel Kronander;Daniel Jonsson;Joakim Low;Patric Ljung;Anders Ynnerman;Jonas Unger,"Department of Science and Technology (ITN), C-Research, Media and Information Technology (MIT), Linköping University, Norrkoping, Sweden;Department of Science and Technology (ITN), C-Research, Media and Information Technology (MIT), Linköping University, Norrkoping, Sweden;Department of Science and Technology (ITN), C-Research, Media and Information Technology (MIT), Linköping University, Norrkoping, Sweden;Siemens AG Corporate Research and Development, Princeton, NJ, USA;Department of Science and Technology (ITN), C-Research, Media and Information Technology (MIT), Linköping University, Norrkoping, Sweden;Department of Science and Technology (ITN), C-Research, Media and Information Technology (MIT), Linköping University, Norrkoping, Sweden",0.1109/tvcg.2007.70573;10.1109/visual.2004.62,"Volumetric illumination,precomputed radiance transfer,,,,,,,,,,,volume rendering.",,31,39,1069,,
TVCG,2013,Enhanced Spatial Stability with Hilbert and Moore Treemaps,10.1109/tvcg.2012.108,http://dx.doi.org/10.1109/TVCG.2012.108,141,148,J,"Treemaps are a well known and powerful space-filling visualisation method for displaying hierarchical data. Many alternative treemap algorithms have been proposed, often with the aim being to optimise performance across several criteria, including spatial stability to assist users in locating and monitoring items of interest. In this paper, we demonstrate that spatial stability is not fully captured by the commonly used ""distance change” (DC) metric, and we introduce a new ""location drift” (LD) metric to more fully capture spatial stability. An empirical study examines the validity and usefulness of the location drift metric, showing that it explains some effects on user performance that distance change does not. Next, we introduce ""Hilbert” and ""Moore” treemap algorithms, which are designed to achieve high spatial stability. We assess their performance in comparison to other treemaps, showing that Hilbert and Moore treemaps perform well across all stability metrics.",Susanne Tak;Andy Cockburn,Susanne Tak;Andy Cockburn,"Department of Computer Science and Software Engineering, University of Canterbury, Christchurch, New Zealand;Department of Computer Science and Software Engineering, University of Canterbury, Christchurch, New Zealand",0.1109/tvcg.2010.186;10.1109/infvis.2001.963283;10.1109/tvcg.2007.70529;10.1109/visual.1991.175815;10.1109/infvis.1999.801860,"trees (mathematics),data visualisation,location drift metric,Layout,Measurement,Stability criteria,Algorithm design and analysis,Gravity,Monitoring,spatial stability,Treemap,space-filling curve,LD,,,,,,,,,,,enhanced spatial stability,,,,Hilbert treemaps,Moore treemaps,space-filling visualisation method,hierarchical data,distance change metric,DC",,28,18,881,,
TVCG,2011,Interactive Visual Analysis of Heterogeneous Scientific Data across an Interface,10.1109/tvcg.2010.111,http://dx.doi.org/10.1109/TVCG.2010.111,934,946,J,"We present a systematic approach to the interactive visual analysis of heterogeneous scientific data. The data consist of two interrelated parts given on spatial grids over time (e.g., atmosphere and ocean part from a coupled climate model). By integrating both data parts in a framework of coordinated multiple views (with linking and brushing), the joint investigation of features across the data parts is enabled. An interface is constructed between the data parts that specifies 1) which grid cells in one part are related to grid cells in the other part, and vice versa, 2) how selections (in terms of feature extraction via brushing) are transferred between the two parts, and 3) how an update mechanism keeps the feature specification in both data parts consistent during the analysis. We also propose strategies for visual analysis that result in an iterative refinement of features specified across both data parts. Our approach is demonstrated in the context of a complex simulation of fluid-structure interaction and a multirun climate simulation.",Johannes Kehrer;Philipp Muigg;Helmut Doleisch;Helwig Hauser,Johannes Kehrer;Philipp Muigg;Helmut Doleisch;Helwig Hauser,"Department of Informatics, University of Bergen, Bergen, Norway;Institute of Computer Graphics and Algorithms, University of Technology, Vienna, Vienna, Austria;SimVis GmbH, Vienna, Austria;Department of Informatics, University of Bergen, Bergen, Norway",0.1109/visual.1997.663913;10.1109/visual.1994.346302;10.1109/visual.2000.885739;10.1109/tvcg.2007.70617;10.1109/tvcg.2009.155;10.1109/infvis.2000.885092;10.1109/visual.2001.964550,"Interactive visual analysis,heterogeneous scientific data,,,,,,,,,,,coordinated multiple views.",,27,42,942,,
TVCG,2013,Bristle Maps: A Multivariate Abstraction Technique for Geovisualization,10.1109/tvcg.2013.66,http://dx.doi.org/10.1109/TVCG.2013.66,1438,1454,J,"We present Bristle Maps, a novel method for the aggregation, abstraction, and stylization of spatiotemporal data that enables multiattribute visualization, exploration, and analysis. This visualization technique supports the display of multidimensional data by providing users with a multiparameter encoding scheme within a single visual encoding paradigm. Given a set of geographically located spatiotemporal events, we approximate the data as a continuous function using kernel density estimation. The density estimation encodes the probability that an event will occur within the space over a given temporal aggregation. These probability values, for one or more set of events, are then encoded into a bristle map. A bristle map consists of a series of straight lines that extend from, and are connected to, linear map elements such as roads, train, subway lines, and so on. These lines vary in length, density, color, orientation, and transparencyâcreating the multivariate attribute encoding scheme where event magnitude, change, and uncertainty can be mapped as various bristle parameters. This approach increases the amount of information displayed in a single plot and allows for unique designs for various information schemes. We show the application of our bristle map encoding scheme using categorical spatiotemporal police reports. Our examples demonstrate the use of our technique for visualizing data magnitude, variable comparisons, and a variety of multivariate attribute combinations. To evaluate the effectiveness of our bristle map, we have conducted quantitative and qualitative evaluations in which we compare our bristle map to conventional geovisualization techniques. Our results show that bristle maps are competitive in completion time and accuracy of tasks with various levels of complexity.",SungYe Kim;Ross Maciejewski;Abish Malik;Yun Jang;David S. Ebert;Tobias Isenberg 0001,SungYe Kim;Ross Maciejewski;Abish Malik;Yun Jang;David S. Ebert;Tobias Isenberg,"School of Electrical and Computer Engineering, Purdue University, West Lafayette, IN, USA;School of Computing, Informatics and Decision Systems Engineering, Arizona State University, Tempe, AZ, USA;School of Electrical and Computer Engineering, Purdue University, West Lafayette, IN, USA;Department of Computer Engineering, Sejong University, Seoul, South Korea;School of Electrical and Computer Engineering, Purdue University, West Lafayette, IN, USA;Team Aviz, INRIA-Saclay, Université Paris-Sud, Orsay, France",0.1109/tvcg.2006.180;10.1109/tvcg.2007.70623;10.1109/tvcg.2006.202;10.1109/tvcg.2006.198;10.1109/infvis.2005.1532144;10.1109/visual.2001.964495;10.1109/tvcg.2008.119;10.1109/tvcg.2007.70561;10.1109/infvis.2003.1249006,"Data transformation and representation,data abstraction,,,,,,,,,,,illustrative visualization,,,,,,,,,,,geovisualization",,26,43,1399,,
TVCG,2012,Robust Morse Decompositions of Piecewise Constant Vector Fields,10.1109/tvcg.2011.88,http://dx.doi.org/10.1109/TVCG.2011.88,938,951,J,"In this paper, we introduce a new approach to computing a Morse decomposition of a vector field on a triangulated manifold surface. The basic idea is to convert the input vector field to a piecewise constant (PC) vector field, whose trajectories can be computed using simple geometric rules. To overcome the intrinsic difficulty in PC vector fields (in particular, discontinuity along mesh edges), we borrow results from the theory of differential inclusions. The input vector field and its PC variant have similar Morse decompositions. We introduce a robust and efficient algorithm to compute Morse decompositions of a PC vector field. Our approach provides subtriangle precision for Morse sets. In addition, we describe a Morse set classification framework which we use to color code the Morse sets in order to enhance the visualization. We demonstrate the benefits of our approach with three well-known simulation data sets, for which our method has produced Morse decompositions that are similar to or finer than those obtained using existing techniques, and is over an order of magnitude faster.",Andrzej Szymczak;Eugene Zhang,Andrzej Szymczak;Eugene Zhang,"Department of Mathematical and Computer Sciences, Colorado Schml of Mines, Golden, CO, USA;School of Electrical Engineering and Computer Science, Oregon State University, Corvallis, OR, USA",0.1109/tvcg.2011.107;10.1109/visual.2005.1532850;10.1109/visual.2000.885716;10.1109/visual.2004.59;10.1109/visual.2001.964533,"Morse decomposition,vector field topology.",,25,41,450,,
TVCG,2013,The Generalized Sensitivity Scatterplot,10.1109/tvcg.2013.20,http://dx.doi.org/10.1109/TVCG.2013.20,1768,1781,J,"Scatterplots remain a powerful tool to visualize multidimensional data. However, accurately understanding the shape of multidimensional points from 2D projections remains challenging due to overlap. Consequently, there are a lot of variations on the scatterplot as a visual metaphor for this limitation. An important aspect often overlooked in scatterplots is the issue of sensitivity or local trend, which may help in identifying the type of relationship between two variables. However, it is not well known how or what factors influence the perception of trends from 2D scatterplots. To shed light on this aspect, we conducted an experiment where we asked people to directly draw the perceived trends on a 2D scatterplot. We found that augmenting scatterplots with local sensitivity helps to fill the gaps in visual perception while retaining the simplicity and readability of a 2D scatterplot. We call this augmentation the generalized sensitivity scatterplot (GSS). In a GSS, sensitivity coefficients are visually depicted as flow lines, which give a sense of continuity and orientation of the data that provide cues about the way data points are scattered in a higher dimensional space. We introduce a series of glyphs and operations that facilitate the analysis of multidimensional data sets using GSS, and validate with a number of well-known data sets for both regression and classification tasks.",Yu-Hsuan Chan;Carlos D. Correa;Kwan-Liu Ma,Yu-Hsuan Chan;Carlos D. Correa;Kwan-Liu Ma,"Department of Computer Science, University of California, Davis, Davis, CA, USA;Department of Computer Science, University of California, Davis, Davis, CA, USA;Department of Computer Science, University of California, Davis, Davis, CA, USA",0.1109/tvcg.2010.176;10.1109/tvcg.2008.153;10.1109/tvcg.2008.119;10.1109/vast.2010.5652460;10.1109/vast.2009.5332611;10.1109/tvcg.2009.122;10.1109/vast.2011.6102450;10.1109/vast.2008.4677368;10.1109/visual.1995.485139;10.1109/tvcg.2006.166,"Sensitivity analysis,data transformations,,,,,,,,,,,model fitting,,,,,,,,,,,multidimensional data visualization",,27,49,1018,,
TVCG,2013,Perceptually-Based Depth-Ordering Enhancement for Direct Volume Rendering,10.1109/tvcg.2012.144,http://dx.doi.org/10.1109/TVCG.2012.144,446,459,J,"Visualizing complex volume data usually renders selected parts of the volume semitransparently to see inner structures of the volume or provide a context. This presents a challenge for volume rendering methods to produce images with unambiguous depth-ordering perception. Existing methods use visual cues such as halos and shadows to enhance depth perception. Along with other limitations, these methods introduce redundant information and require additional overhead. This paper presents a new approach to enhancing depth-ordering perception of volume rendered images without using additional visual cues. We set up an energy function based on quantitative perception models to measure the quality of the images in terms of the effectiveness of depth-ordering and transparency perception as well as the faithfulness of the information revealed. Guided by the function, we use a conjugate gradient method to iteratively and judiciously enhance the results. Our method can complement existing systems for enhancing volume rendering results. The experimental results demonstrate the usefulness and effectiveness of our approach.",Lin Zheng;Yingcai Wu;Kwan-Liu Ma,Lin Zheng;Yingcai Wu;Kwan-Liu Ma,"Department of Computer Science, University of California, Davis, CA;Microsoft Research Asia, Beijing, P.R. China;Department of Computer Science, University of California, Davis, CA",0.1109/visual.1991.175805;10.1109/tvcg.2009.150;10.1109/tvcg.2007.70555;10.1109/tvcg.2009.172;10.1109/visual.2003.1250414;10.1109/tvcg.2009.138;10.1109/tvcg.2008.118;10.1109/visual.2004.64,"Volume rendering,depth ordering,,,,,,,,,,,depth perception,,,,,,,,,,,transparency,,,,visualization",,25,40,828,,
TVCG,2013,ViSizer: A Visualization Resizing Framework,10.1109/tvcg.2012.114,http://dx.doi.org/10.1109/TVCG.2012.114,278,290,J,"Visualization resizing is useful for many applications where users may use different display devices. General resizing techniques (e.g., uniform scaling) and image-resizing techniques suffer from several drawbacks, as they do not consider the content of the visualizations. This work introduces ViSizer, a perception-based framework for automatically resizing a visualization to fit any display. We formulate an energy function based on a perception model (feature congestion), which aims to determine the optimal deformation for every local region. We subsequently transform the problem into an optimization problem by the energy function. An efficient algorithm is introduced to iteratively solve the problem, allowing for automatic visualization resizing.",Yingcai Wu;Xiaotong Liu;Shixia Liu;Kwan-Liu Ma,Yingcai Wu;Xiaotong Liu;Shixia Liu;Kwan-Liu Ma,"Department of Computer Science, University of California, Davis, CA, USA;Department of Computer Science and Engineering, Ohio State University, Columbus, OH, USA;Microsoft Research Asia, Beijing, China;Department of Computer Science, University of California, Davis, CA, USA",0.1109/tvcg.2009.171;10.1109/visual.1999.809866;10.1109/tvcg.2007.70535;10.1109/infvis.2004.15;10.1109/infvis.1996.559214;10.1109/tvcg.2008.135,"Resizing,visualization framework,,,,,,,,,,,perception,,,,,,,,,,,focus+context,,,,nonlinear least squares optimization",,29,38,983,,
TVCG,2012,Morse Set Classification and Hierarchical Refinement Using Conley Index,10.1109/tvcg.2011.107,http://dx.doi.org/10.1109/TVCG.2011.107,767,782,J,"Morse decomposition provides a numerically stable topological representation of vector fields that is crucial for their rigorous interpretation. However, Morse decomposition is not unique, and its granularity directly impacts its computational cost. In this paper, we propose an automatic refinement scheme to construct the Morse Connection Graph (MCG) of a given vector field in a hierarchical fashion. Our framework allows a Morse set to be refined through a local update of the flow combinatorialization graph, as well as the connection regions between Morse sets. The computation is fast because the most expensive computation is concentrated on a small portion of the domain. Furthermore, the present work allows the generation of a topologically consistent hierarchy of MCGs, which cannot be obtained using a global method. The classification of the extracted Morse sets is a crucial step for the construction of the MCG, for which the Poincaré index is inadequate. We make use of an upper bound for the Conley index, provided by the Betti numbers of an index pair for a translation along the flow, to classify the Morse sets. This upper bound is sufficiently accurate for Morse set classification and provides supportive information for the automatic refinement process. An improved visualization technique for MCG is developed to incorporate the Conley indices. Finally, we apply the proposed techniques to a number of synthetic and real-world simulation data to demonstrate their utility.",Guoning Chen;Qingqing Deng;Andrzej Szymczak;Robert S. Laramee;Eugene Zhang,Guoning Chen;Qingqing Deng;Andrzej Szymczak;Robert S. Laramee;Eugene Zhang,"Scientific Computing and Imaging Institute, University of Utah, Salt Lake, UT, USA;School of Electrical Engineering and Computer Science, Oregon State University, Corvallis, OR, USA;Department of Mathematical and Computer Sciences, Colorado Schml of Mines, Golden, CO, USA;Department of Computer Science, Swansea University, Swansea, UK;School of Electrical Engineering and Computer Science, Oregon State University, Corvallis, OR, USA",0.1109/visual.2000.885716;10.1109/visual.2001.964507;10.1109/visual.1999.809907;10.1109/visual.2005.1532850;10.1109/tvcg.2008.110;10.1109/tvcg.2007.70552;10.1109/visual.2004.59;10.1109/visual.1997.663858,"Morse decomposition,vector field topology,,,,,,,,,,,upper bound of Conley index,,,,,,,,,,,topology refinement,,,,hierarchical refinement.",,21,40,438,,
TVCG,2013,Abstracting Attribute Space for Transfer Function Exploration and Design,10.1109/tvcg.2012.105,http://dx.doi.org/10.1109/TVCG.2012.105,94,107,J,"Currently, user centered transfer function design begins with the user interacting with a one or two-dimensional histogram of the volumetric attribute space. The attribute space is visualized as a function of the number of voxels, allowing the user to explore the data in terms of the attribute size/magnitude. However, such visualizations provide the user with no information on the relationship between various attribute spaces (e.g., density, temperature, pressure, x, y, z) within the multivariate data. In this work, we propose a modification to the attribute space visualization in which the user is no longer presented with the magnitude of the attribute; instead, the user is presented with an information metric detailing the relationship between attributes of the multivariate volumetric data. In this way, the user can guide their exploration based on the relationship between the attribute magnitude and user selected attribute information as opposed to being constrained by only visualizing the magnitude of the attribute. We refer to this modification to the traditional histogram widget as an abstract attribute space representation. Our system utilizes common one and two-dimensional histogram widgets where the bins of the abstract attribute space now correspond to an attribute relationship in terms of the mean, standard deviation, entropy, or skewness. In this manner, we exploit the relationships and correlations present in the underlying data with respect to the dimension(s) under examination. These relationships are often times key to insight and allow us to guide attribute discovery as opposed to automatic extraction schemes which try to calculate and extract distinct attributes a priori. In this way, our system aids in the knowledge discovery of the interaction of properties within volumetric data.",Ross Maciejewski;Yun Jang;Insoo Woo;Heike Jänicke;Kelly P. Gaither;David S. Ebert,Ross Maciejewski;Yun Jang;Insoo Woo;Heike Jänicke;Kelly P. Gaither;David S. Ebert,"Arizona State University, Tempe, AZ, USA;Sejong University, Seoul, South Korea;School of Electrical and Computer Engineering, Purdue University, West Lafayette, Indiana, USA;Heidelberg University, Heidelberg;Texas Advanced Computing Center, University of Texas at Austin, Austin, Texas, USA;School of Electrical and Computer Engineering, Purdue University, West Lafayette, Indiana, USA",0.1109/visual.2003.1250413;10.1109/tvcg.2008.119;10.1109/visual.1994.346302;10.1109/tvcg.2008.162;10.1109/tvcg.2008.153;10.1109/tvcg.2009.185;10.1109/tvcg.2008.140;10.1109/tvcg.2008.160;10.1109/visual.2003.1250371;10.1109/tvcg.2006.168;10.1109/visual.2003.1250402;10.1109/visual.2005.1532858;10.1109/visual.1997.663875;10.1109/visual.1998.745289;10.1109/visual.2003.1250414;10.1109/tvcg.2006.164;10.1109/visual.2001.964519;10.1109/visual.1994.346327,"user centred design,data mining,attribute space visualization,information metric,multivariate volumetric data,attribute magnitude,attribute information,histogram widget,abstract attribute space representation,mean,standard deviation,entropy,data visualisation,skewness,attribute discovery,automatic extraction schemes,Histograms,Transfer functions,Rendering (computer graphics),Measurement,Data visualization,Entropy,Image color analysis,transfer functions,information theory,Transfer function design,volume rendering,knowledge discovery,volumetric attribute space abstraction,transfer function exploration,user centered transfer function design,one-dimensional histogram,two-dimensional histogram",,20,46,1000,,
TVCG,2014,Activity Detection in Scientific Visualization,10.1109/tvcg.2013.117,http://dx.doi.org/10.1109/TVCG.2013.117,377,390,J,"For large-scale simulations, the data sets are so massive that it is sometimes not feasible to view the data with basic visualization methods, let alone explore all time steps in detail. Automated tools are necessary for knowledge discovery, i.e., to help sift through the data and isolate specific time steps that can then be further explored. Scientists study patterns and interactions and want to know when and where interesting things happen. Activity detection, the detection of specific interactions of objects which span a limited duration of time, has been an active research area in the computer vision community. In this paper, we introduce activity detection to scientific simulations and show how it can be utilized in scientific visualization. We show how activity detection allows a scientist to model an activity and can then validate their hypothesis on the underlying processes. Three case studies are presented.",Sedat Ozer;Deborah Silver;Karen G. Bemis;Pino Martin,Sedat Ozer;Deborah Silver;Karen Bemis;Pino Martin,"Vizlab, Rutgers University, Piscataway, NJ;Vizlab, Rutgers University, Piscataway, NJ;Department of Marine & Coastal Sciences, Rutgers University, Piscataway, NJ;Department of Aerospace Engineering, University of Maryland, College Park, MD",0.1109/tvcg.2007.70599;10.1109/vast.2012.6400494;10.1109/tvcg.2011.208;10.1109/visual.1998.745347;10.1109/tvcg.2006.186;10.1109/vast.2012.6400485,"Activity modeling,activity detection,,,,,,,,,,,activity recognition,,,,,,,,,,,simultaneous event detection,,,,Petri Nets,feature tracking,group tracking,time-varying scientific data analysis and visualization",,19,52,1349,,
TVCG,2012,Mesh-Driven Vector Field Clustering and Visualization: An Image-Based Approach,10.1109/tvcg.2011.25,http://dx.doi.org/10.1109/TVCG.2011.25,283,298,J,"Vector field visualization techniques have evolved very rapidly over the last two decades, however, visualizing vector fields on complex boundary surfaces from computational flow dynamics (CFD) still remains a challenging task. In part, this is due to the large, unstructured, adaptive resolution characteristics of the meshes used in the modeling and simulation process. Out of the wide variety of existing flow field visualization techniques, vector field clustering algorithms offer the advantage of capturing a detailed picture of important areas of the domain while presenting a simplified view of areas of less importance. This paper presents a novel, robust, automatic vector field clustering algorithm that produces intuitive and insightful images of vector fields on large, unstructured, adaptive resolution boundary meshes from CFD. Our bottom-up, hierarchical approach is the first to combine the properties of the underlying vector field and mesh into a unified error-driven representation. The motivation behind the approach is the fact that CFD engineers may increase the resolution of model meshes according to importance. The algorithm has several advantages. Clusters are generated automatically, no surface parameterization is required, and large meshes are processed efficiently. The most suggestive and important information contained in the meshes and vector fields is preserved while less important areas are simplified in the visualization. Users can interactively control the level of detail by adjusting a range of clustering distance measure parameters. We describe two data structures to accelerate the clustering process. We also introduce novel visualizations of clusters inspired by statistical methods. We apply our method to a series of synthetic and complex, real-world CFD meshes to demonstrate the clustering algorithm results.",Zhenmin Peng;Edward Grundy;Robert S. Laramee;Guoning Chen;Nick Croft,Zhenmin Peng;Edward Grundy;Robert S. Laramee;Guoning Chen;Nick Croft,"Department of Computer Science, Swansea University, Wales, UK;Department of Computer Science, Swansea University, Wales, UK;Department of Computer Science, Swansea University, Wales, UK;Scientific Computing and Imaging Institute, University of Utah, Salt Lake, UT, USA;School of Engineering, Swansea University, Wales, UK",0.1109/visual.2004.59;10.1109/visual.1999.809865;10.1109/visual.1999.809863;10.1109/visual.2001.964507;10.1109/visual.2003.1250364;10.1109/visual.2003.1250363;10.1109/visual.2004.32,"Vector field visualization,clustering,,,,,,,,,,,feature based,,,,,,,,,,,surfaces.",,17,31,959,,
TVCG,2011,Relation-Aware Isosurface Extraction in Multifield Data,10.1109/tvcg.2010.64,http://dx.doi.org/10.1109/TVCG.2010.64,182,191,J,"We introduce a variation density function that profiles the relationship between multiple scalar fields over isosurfaces of a given scalar field. This profile serves as a valuable tool for multifield data exploration because it provides the user with cues to identify interesting isovalues of scalar fields. Existing isosurface-based techniques for scalar data exploration like Reeb graphs, contour spectra, isosurface statistics, etc., study a scalar field in isolation. We argue that the identification of interesting isovalues in a multifield data set should necessarily be based on the interaction between the different fields. We demonstrate the effectiveness of our approach by applying it to explore data from a wide variety of applications.",Suthambhara Nagaraj;Vijay Natarajan,Suthambhara Nagaraj;Vijay Natarajan,"Department of Computer Science and Automation, Indian Institute of Science, Bangalore, India;Department of Computer Science and Automation and the Supercomputer Education and Research Centre, Indian Institute of Science, Bangalore, India",0.1109/tvcg.2006.168;10.1109/tvcg.2008.160;10.1109/tvcg.2007.70519;10.1109/tvcg.2008.119;10.1109/visual.2004.68;10.1109/visual.2001.964516;10.1109/visual.2001.964515;10.1109/visual.2001.964551;10.1109/visual.1997.663875;10.1109/tvcg.2006.165;10.1109/visual.2004.96,"Isosurface statistics,isocontours,,,,,,,,,,,variation density profile,,,,,,,,,,,persistence,,,,multifield data.",,16,23,446,,
TVCG,2011,Toward High-Quality Gradient Estimation on Regular Lattices,10.1109/tvcg.2010.37,http://dx.doi.org/10.1109/TVCG.2010.37,426,439,J,"In this paper, we present two methods for accurate gradient estimation from scalar field data sampled on regular lattices. The first method is based on the multidimensional Taylor series expansion of the convolution sum and allows us to specify design criteria such as compactness and approximation power. The second method is based on a Hilbert space framework and provides a minimum error solution in the form of an orthogonal projection operating between two approximation spaces. Both methods lead to discrete filters, which can be combined with continuous reconstruction kernels to yield highly accurate estimators as compared to the current state of the art. We demonstrate the advantages of our methods in the context of volume rendering of data sampled on Cartesian and Body-Centered Cubic lattices. Our results show significant qualitative and quantitative improvements for both synthetic and real data, while incurring a moderate preprocessing and storage overhead.",Zahid Hossain 0001;Usman R. Alim;Torsten Möller,Zahid Hossain;Usman R. Alim;Torsten Möller,"School of Computing Science, Simon Fraser University, Burnaby, BC, Canada;School of Computing Science, Simon Fraser University, Burnaby, BC, Canada;School of Computing Science, Simon Fraser University, Burnaby, BC, Canada",0.1109/visual.2004.65;10.1109/visual.2003.1250414;10.1109/visual.1994.346331;10.1109/visual.2001.964498;10.1109/visual.1997.663848,"Approximation theory,Taylor series expansion,,,,,,,,,,,normal reconstruction,,,,,,,,,,,orthogonal projection,,,,body-centered cubic lattice,box splines.",,14,31,434,,
TVCG,2013,Visualization and Analysis of Vortex-Turbine Intersections in Wind Farms,10.1109/tvcg.2013.18,http://dx.doi.org/10.1109/TVCG.2013.18,1579,1591,J,"Characterizing the interplay between the vortices and forces acting on a wind turbine's blades in a qualitative and quantitative way holds the potential for significantly improving large wind turbine design. This paper introduces an integrated pipeline for highly effective wind and force field analysis and visualization. We extract vortices induced by a turbine's rotation in a wind field, and characterize vortices in conjunction with numerically simulated forces on the blade surfaces as these vortices strike another turbine's blades downstream. The scientifically relevant issue to be studied is the relationship between the extracted, approximate locations on the blades where vortices strike the blades and the forces that exist in those locations. This integrated approach is used to detect and analyze turbulent flow that causes local impact on the wind turbine blade structure. The results that we present are based on analyzing the wind and force field data sets generated by numerical simulations, and allow domain scientists to relate vortex-blade interactions with power output loss in turbines and turbine life expectancy. Our methods have the potential to improve turbine design to save costs related to turbine operation and maintenance.",Sohail Shafii;Harald Obermaier;Rodman R. Linn;Eunmo Koo;Mario Hlawitschka;Christoph Garth;Bernd Hamann;Kenneth I. Joy,Sohail Shafii;Herald Obermaier;Rodman Linn;Eunmo Koo;Mario Hlawitschka;Christoph Garth;Bernd Hamann;Kenneth I. Joy,"Institute for Data Analysis and Visualization, Department of Computer Science, University of California, Davis, Davis, CA, USA;Institute for Data Analysis and Visualization, Department of Computer Science, University of California, Davis, Davis, CA, USA;Computational Earth Sciences Group (EES-16), Los Alamos National Laboratory, Los Alamos, NM, USA;Computational Earth Sciences Group (EES-16), Los Alamos National Laboratory, Los Alamos, NM, USA;Institut für Informatik, Universität Leipzig, Germany;Fachbereich Informatik, Technische Universität Kaiserslautern, Kaiserslautern, Germany;Institute for Data Analysis and Visualization, Department of Computer Science, University of California, Davis, Davis, CA, USA;Institute for Data Analysis and Visualization, Department of Computer Science, University of California, Davis, Davis, CA, USA",0.1109/visual.1998.745296;10.1109/visual.1991.175773;10.1109/visual.1994.346315;10.1109/visual.1994.346327;10.1109/visual.2005.1532830,"Flow visualization,applications,,,,,,,,,,,wind energy,,,,,,,,,,,turbulence,,,,vortices",,14,32,937,,
TVCG,2014,"Grouper: A Compact, Streamable Triangle Mesh Data Structure",10.1109/tvcg.2013.81,http://dx.doi.org/10.1109/TVCG.2013.81,84,98,J,"We present Grouper: an all-in-one compact file format, random-access data structure, and streamable representation for large triangle meshes. Similarly to the recently published SQuad representation, Grouper represents the geometry and connectivity of a mesh by grouping vertices and triangles into fixed-size records, most of which store two adjacent triangles and a shared vertex. Unlike SQuad, however, Grouper interleaves geometry with connectivity and uses a new connectivity representation to ensure that vertices and triangles can be stored in a coherent order that enables memory-efficient sequential stream processing. We present a linear-time construction algorithm that allows streaming out Grouper meshes using a small memory footprint while preserving the initial ordering of vertices. As a part of this construction, we show how the problem of assigning vertices and triangles to groups reduces to a well-known NP-hard optimization problem, and present a simple yet effective heuristic solution that performs well in practice. Our array-based Grouper representation also doubles as a triangle mesh data structure that allows direct access to vertices and triangles. Storing only about two integer references per triangleâi.e., less than the three vertex references stored with each triangle in a conventional indexed mesh format-Grouper answers both incidence and adjacency queries in amortized constant time. Our compact representation enables data-parallel processing on multicore computers, instant partitioning and fast transmission for distributed processing, as well as efficient out-of-core access. We demonstrate the versatility and performance benefits of Grouper using a suite of example meshes and processing kernels.",Mark Luffel;Topraj Gurung;Peter Lindstrom 0001;Jarek Rossignac,Mark Luffel;Topraj Gurung;Peter Lindstrom;Jarek Rossignac,"Visualization Graphics and Usability Center;Visualization Graphics and Usability Center;Lawrence Livermore National Laboratory, Center for Applied Scientific Computing (CASC), Livermore, CA;Visualization Graphics and Usability Center",0.1109/tvcg.2007.70585;10.1109/visual.2005.1532800;10.1109/visual.2002.1183796;10.1109/visual.2003.1250408;10.1109/tvcg.2006.169,"Mesh compression,mesh data structures,,,,,,,,,,,random access,,,,,,,,,,,out-of-core algorithms,,,,large meshes",,13,37,795,,
TVCG,2012,A 2D Flow Visualization User Study Using Explicit Flow Synthesis and Implicit Task Design,10.1109/tvcg.2011.110,http://dx.doi.org/10.1109/TVCG.2011.110,783,796,J,"This paper presents a 2D flow visualization user study that we conducted using new methodologies to increase the objectiveness. We evaluated grid-based variable-size arrows, evenly spaced streamlines, and line integral convolution (LIC) variants (basic, oriented, and enhanced versions) coupled with a colorwheel and/or rainbow color map, which are representative of many geometry-based and texture-based techniques. To reduce data-related bias, template-based explicit flow synthesis was used to create a wide variety of symmetric flows with similar topological complexity. To suppress task-related bias, pattern-based implicit task design was employed, addressing critical point recognition, critical point classification, and symmetric pattern categorization. In addition, variable-duration and fixed-duration measurement schemes were utilized for lightweight precision-critical and heavyweight judgment-intensive flow analysis tasks, respectively, to record visualization effectiveness. We eliminated outliers and used the Ryan REGWQ post-hoc homogeneous subset tests in statistical analysis to obtain reliable findings. Our study shows that a texture-based dense representation with accentuated flow streaks, such as enhanced LIC, enables intuitive perception of the flow, while a geometry-based integral representation with uniform density control, such as evenly spaced streamlines, may exploit visual interpolation to facilitate mental reconstruction of the flow. It is also shown that inappropriate color mapping (e.g., colorwheel) may add distractions to a flow representation.",Zhanping Liu;Shangshu Cai;J. Edward Swan II;Robert J. Moorhead II;Joel P. Martin;T. J. Jankun-Kelly,Zhanping Liu;Shangshu Cai;J. Edward Swan;Robert J. Moorhead;Joel P. Martin;T.J. Jankun-Kelly,"Department of Computer Science, Kentucky State University, Frankfort, KY, USA;Center for Risk Studies and Safety, University of California at Santa Barbara, Goleta, CA, USA;Department of Computer Science and Engineering, Mississippi State University, MS;Electrical and Computer Engineering Department, Mississippi State University, MS;Lockheed Martin, U.S. Army Research Laboratory, Aberdeen, MD, USA;Department of Computer Science and Engineering, Mississippi State University, MS, USA",0.1109/visual.2003.1250363;10.1109/tvcg.2006.116;10.1109/tvcg.2009.126,"Index Terms—Flow visualization,user study,,,,,,,,,,,visualization effectiveness,,,,,,,,,,,flow synthesis,,,,task design,test strategy,LIC,evenly spaced streamlines",,12,30,640,,
TVCG,2013,Lighting System for Visual Perception Enhancement in Volume Rendering,10.1109/tvcg.2012.91,http://dx.doi.org/10.1109/TVCG.2012.91,67,80,J,"We introduce a lighting system that enhances the visual cues in a rendered image for the perception of 3D volumetric objects. We divide the lighting effects into global and local effects, and deploy three types of directional lights: the key light and accessory lights (fill and detail lights). The key light provides both lighting effects and carries the visual cues for the perception of local and global shapes and depth. The cues for local shapes are conveyed by gradient; those for global shapes are carried by shadows; and those for depth are provided by shadows and translucent objects. Fill lights produce global effects to increase the perceptibility. Detail lights generate local effects to improve the cues for local shapes. Our method quantifies the perception and uses an exhaustive search to set the lights. It configures accessory lights with the consideration of preserving the global impression conveyed by the key light. It ensures the feeling of smooth light movements in animations. With simplification, it achieves interactive frame rates and produces results that are visually indistinguishable from results using the nonsimplified algorithm. The major contributions of this paper are our lighting system, perception measurement and lighting design algorithm with our indistinguishable simplification.",Lei Wang 0024;Arie E. Kaufman,Lei Wang;Arie E. Kaufman,"Department of Computer Science, Stony Brook University-SUNY, Stony Brook, NY, USA;Department of Computer Science, Stony Brook University-SUNY, Stony Brook, NY, USA",0.1109/visual.2002.1183785;10.1109/visual.2003.1250395;10.1109/tvcg.2009.172,"rendering (computer graphics),lighting,translucent objects,fill lights,Lighting,Shape,Visualization,Rendering (computer graphics),Three dimensional displays,Casting,Visual systems,spherical coordinate system,interactive frame rates,Lighting design,volume rendering,light placement,,,,,,,,lighting system,,,,visual perception enhancement,volume rendering,rendered image,3D volumetric objects,key light,accessory lights",,12,44,1231,,
TVCG,2014,Verifying Volume Rendering Using Discretization Error Analysis,10.1109/tvcg.2013.90,http://dx.doi.org/10.1109/TVCG.2013.90,140,154,J,"We propose an approach for verification of volume rendering correctness based on an analysis of the volume rendering integral, the basis of most DVR algorithms. With respect to the most common discretization of this continuous model (Riemann summation), we make assumptions about the impact of parameter changes on the rendered results and derive convergence curves describing the expected behavior. Specifically, we progressively refine the number of samples along the ray, the grid size, and the pixel size, and evaluate how the errors observed during refinement compare against the expected approximation errors. We derive the theoretical foundations of our verification approach, explain how to realize it in practice, and discuss its limitations. We also report the errors identified by our approach when applied to two publicly available volume rendering packages.",Tiago Etiene;Daniel Jönsson;Timo Ropinski;Carlos Eduardo Scheidegger;João Luiz Dihl Comba;Luis Gustavo Nonato;Robert M. Kirby;Anders Ynnerman;Cláudio T. Silva,Tiago Etiene;Daniel Jönsson;Timo Ropinski;Carlos Scheidegger;João L.D. Comba;Luis Gustavo Nonato;Robert M. Kirby;Anders Ynnerman;Cláudio T. Silva,"University of Utah, School of Computing, Salt Lake City, UT;Campus Norrköping, Linköpings Universitet, Sweden;Campus Norrköping, Linköpings Universitet, Sweden;Campus Norrköping, Linköpings Universitet, Sweden;Av. Bento Goncalves, Universidade Federal do Rio Grande do Sul, Porto Alegre, RS, Brazil;Depto Matematica Aplicada e Estatistica - ICMC/USP, Universidade de São Paulo;University of Utah, School of Computing, Salt Lake City, UT;Campus Norrköping, Linköpings Universitet, Sweden;1 MetroTech Center, New York University, Brooklyn, NY",0.1109/visual.2000.885683;10.1109/tvcg.2009.164;10.1109/tvcg.2011.109;10.1109/tvcg.2006.113;10.1109/tvcg.2009.194;10.1109/tvcg.2010.211;10.1109/visual.2003.1250384;10.1109/tvcg.2010.160,"Discretization errors,volume rendering,,,,,,,,,,,verifiable visualization,,,,,,,,,,,verification,,,,testing",,11,47,648,,
TVCG,2012,Evaluating the Role of Time in Investigative Analysis of Document Collections,10.1109/tvcg.2012.89,http://dx.doi.org/10.1109/TVCG.2012.89,1992,2004,J,"Time is a universal and essential aspect of data in any investigative analysis. It helps analysts establish causality, build storylines from evidence, and reject infeasible hypotheses. For this reason, many investigative analysis tools provide visual representations designed for making sense of temporal data. However, the field of visual analytics still needs more evidence explaining how temporal visualization actually aids the analysis process, as well as design recommendations for how to build these visualizations. To fill this gap, we conducted an insight-based qualitative study to investigate the influence of temporal visualization on investigative analysis. We found that visualizing temporal information helped participants externalize chains of events. Another contribution of our work is the lightweight evaluation approach used to collect, visualize, and analyze insight.",Bum Chul Kwon;Waqas Javed;Sohaib Ghani;Niklas Elmqvist;Ji Soo Yi;David S. Ebert,Bum chul Kwon;Waqas Javed;Sohaib Ghani;Niklas Elmqvist;Ji Soo Yi;David S. Ebert,"School of Industrial Engineering, Purdue University, West Lafayette, IN, USA;School of Electrical and Computer Engineering, Purdue University, West Lafayette, IN, USA;School of Electrical and Computer Engineering, Purdue University, West Lafayette, IN, USA;School of Electrical and Computer Engineering, Purdue University, West Lafayette, IN, USA;School of Industrial Engineering, Purdue University, West Lafayette, IN, USA;School of Electrical and Computer Engineering, Purdue University, West Lafayette, IN, USA",0.1109/vast.2009.5332595;10.1109/vast.2009.5333020;10.1109/vast.2006.261416;10.1109/vast.2008.4677358;10.1109/vast.2008.4677360;10.1109/vast.2009.5333878;10.1109/vast.2008.4677362;10.1109/tvcg.2007.70515;10.1109/tvcg.2008.121,"Qualitative evaluation,investigative analysis,,,,,,,,,,,temporal visualization,,,,,,,,,,,insight-based evaluation",,12,35,521,,
TVCG,2014,A Deformation Framework for Focus+Context Flow Visualization,10.1109/tvcg.2013.100,http://dx.doi.org/10.1109/TVCG.2013.100,42,55,J,"Striking a careful balance among coverage, occlusion, and complexity is a resounding theme in the visual understanding of large and complex three-dimensional flow fields. In this paper, we present a novel deformation framework for focus+context streamline visualization that reduces occlusion and clutter around the focal regions while compacting the context region in a full view. Unlike existing techniques that vary streamline densities, we advocate a different approach that manipulates streamline positions. This is achieved by partitioning the flow field's volume space into blocks and deforming the blocks to guide streamline repositioning. We formulate block expansion and block smoothing into energy terms and solve for a deformed grid that minimizes the objective function under the volume boundary and edge flipping constraints. Leveraging a GPU linear system solver, we demonstrate interactive focus+context visualization with 3D flow field data of various characteristics. Compared to the fisheye focus+context technique, our method can magnify multiple streamlines of focus in different regions simultaneously while minimizing the distortion through optimized deformation. Both automatic and manual feature specifications are provided for flexible focus selection and effective visualization.",Jun Tao 0002;Chaoli Wang 0001;Ching-Kuang Shene;Seung Hyun Kim,Jun Tao;Chaoli Wang;Ching-Kuang Shene;Seung Hyun Kim,"Department of Computer Science, Michigan Technological University, Houghton, MI;Department of Computer Science, Michigan Technological University, Houghton, MI;Department of Computer Science, Michigan Technological University, Houghton, MI;Department of Mechanical Engineering-Engineering Mechanics, Michigan Technological University, Houghton, MI",0.1109/visual.2005.1532850;10.1109/tvcg.2008.132;10.1109/tvcg.2007.70565;10.1109/visual.1998.745317;10.1109/tvcg.2011.243;10.1109/infvis.2004.66;10.1109/tvcg.2010.131,"Flow visualization,focus+context visualization,,,,,,,,,,,optimized deformation",,10,22,836,,
TVCG,2011,Link Conditions for Simplifying Meshes with Embedded Structures,10.1109/tvcg.2010.90,http://dx.doi.org/10.1109/TVCG.2010.90,1007,1019,J,"Interactive visualization applications benefit from simplification techniques that generate good-quality coarse meshes from high-resolution meshes that represent the domain. These meshes often contain interesting substructures, called embedded structures, and it is desirable to preserve the topology of the embedded structures during simplification, in addition to preserving the topology of the domain. This paper describes a proof that link conditions, proposed earlier, are sufficient to ensure that edge contractions preserve the topology of the embedded structures and the domain. Excluding two specific configurations, the link conditions are also shown to be necessary for topology preservation. Repeated application of edge contraction on an extended complex produces a coarser representation of the domain and the embedded structures. An extension of the quadric error metric is used to schedule edge contractions, resulting in a good-quality coarse mesh that closely approximates the input domain and the embedded structures.",Dilip Mathew Thomas;Vijay Natarajan;Georges-Pierre Bonneau,Dilip Mathew Thomas;Vijay Natarajan;Georges-Pierre Bonneau,"Department of Computer Science and Automation, Indian Institute of Science, Bangalore, India;Department of Computer Science and Automation, Supercomputer Education and Research Centre, Indian Institute of Science, Bangalore, India;LJK, INRIA Grenoble, University of Grenoble, France",0.1109/visual.1998.745312;10.1109/visual.2001.964502;10.1109/visual.2005.1532839,"Embedded structures,extended complex,,,,,,,,,,,link conditions,,,,,,,,,,,mesh simplification,,,,topology preservation,quadric error metric.",,6,21,384,,
TVCG,2012,A Versatile Optical Model for Hybrid Rendering of Volume Data,10.1109/tvcg.2011.113,http://dx.doi.org/10.1109/TVCG.2011.113,925,937,J,"In volume rendering, most optical models currently in use are based on the assumptions that a volumetric object is a collection of particles and that the macro behavior of particles, when they interact with light rays, can be predicted based on the behavior of each individual particle. However, such models are not capable of characterizing the collective optical effect of a collection of particles which dominates the appearance of the boundaries of dense objects. In this paper, we propose a generalized optical model that combines particle elements and surface elements together to characterize both the behavior of individual particles and the collective effect of particles. The framework based on a new model provides a more powerful and flexible tool for hybrid rendering of isosurfaces and transparent clouds of particles in a single scene. It also provides a more rational basis for shading, so the problem of normal-based shading in homogeneous regions encountered in conventional volume rendering can be easily avoided. The model can be seen as an extension to the classical model. It can be implemented easily, and most of the advanced numerical estimation methods previously developed specifically for the particle-based optical model, such as preintegration, can be applied to the new model to achieve high-quality rendering results.",Fei Yang;Qingde Li;Dehui Xiang;Yong Cao;Jie Tian 0001,Fei Yang;Qingde Li;Dehui Xiang;Yong Cao;Jie Tian,"Institute of Automation, Chinese Academy of Sciences, Beijing, China;Department of Computer Science, University of Hull, Hull, UK;Institute of Automation, Chinese Academy of Sciences, Beijing, China;Virginia Polytechnic Institute and State University, Blacksburg, VA, USA;Institute of Automation, Chinese Academy of Sciences, Beijing, China",0.1109/visual.2000.885683;10.1109/visual.2002.1183763;10.1109/visual.1999.809887,"Direct volume rendering,optical models,,,,,,,,,,,isosurfaces,,,,,,,,,,,preintegration,,,,ray casting,transfer function.",,4,31,690,,
TVCG,2013,The Sinogram Polygonizer for Reconstructing 3D Shapes,10.1109/tvcg.2013.87,http://dx.doi.org/10.1109/TVCG.2013.87,1911,1922,J,"This paper proposes a novel approach, the sinogram polygonizer, for directly reconstructing 3D shapes from sinograms (i.e., the primary output from X-ray computed tomography (CT) scanners consisting of projection image sequences of an object shown from different viewing angles). To obtain a polygon mesh approximating the surface of a scanned object, a grid-based isosurface polygonizer, such as Marching Cubes, has been conventionally applied to the CT volume reconstructed from a sinogram. In contrast, the proposed method treats CT values as a continuous function and directly extracts a triangle mesh based on tetrahedral mesh deformation. This deformation involves quadratic error metric minimization and optimal Delaunay triangulation for the generation of accurate, high-quality meshes. Thanks to the analytical gradient estimation of CT values, sharp features are well approximated, even though the generated mesh is very coarse. Moreover, this approach eliminates aliasing artifacts on triangle meshes.",Daiki Yamanaka;Yutaka Ohtake;Hiromasa Suzuki,Daiki Yamanaka;Yutaka Ohtake;Hiromasa Suzuki,"Department of Precision Engineering and RCAST, University of Tokyo, Meguro, Tokyo, Japan;Department of Precision Engineering and RCAST, University of Tokyo, Meguro, Tokyo, Japan;RCAST, University of Tokyo, Meguro, Tokyo, Japan",,"Shape reconstruction,X-ray CT,,,,,,,,,,,sinogram,,,,,,,,,,,isosurface polygonizer,,,,mesh generation",,3,22,720,,
CG&A,2020,Data Badges: Making an Academic Profile Through a DIY Wearable Physicalization,10.1109/mcg.2020.3025504,http://dx.doi.org/10.1109/MCG.2020.3025504,51,60,MAG,"In this pictorial, we present the design and making process of Data Badges as they were deployed during a one-week academic seminar. Data Badges are customizable physical conference badges that invite participants to make their own independent and personalized expressions of their academic profile by choosing and assembling a collection of predefined physical tokens on a flat wearable canvas. As our modular and intuitive design approach allows the construction to occur as a shared, collective activity, Data Badges take advantage of the creative, affective, and social values that underlie physicalization and its construction to engage participants in reflecting on personal data. Among other unexpected phenomena, we noticed how the freedom of assembly and interpretation encouraged a variety of appropriations, which expanded its intended representational space from fully representative to more resistive and provocative forms of data expression.",Georgia Panagiotidou;Sinem Görücü;Andrew Vande Moere,Georgia Panagiotidou;Sinem Görücü;Andrew Vande Moere,"Research[x]Design, KU Leuven;Research[x]Design, KU Leuven;Research[x]Design, KU Leuven",0.1109/tvcg.2019.2934538;10.1109/tvcg.2016.2598608,"data visualisation,physicalisation,physicalisation construction,data humanism",,10,10,666,,
CG&A,2019,Flow Field Reduction Via Reconstructing Vector Data From 3-D Streamlines Using Deep Learning,10.1109/mcg.2018.2881523,http://dx.doi.org/10.1109/MCG.2018.2881523,54,67,MAG,"We present a new approach for streamline-based flow field representation and reduction. Our method can work in the in situ visualization setting by tracing streamlines from each time step of the simulation and storing compressed streamlines for post hoc analysis where users can afford longer reconstruction time for higher reconstruction quality using decompressed streamlines. At the heart of our approach is a deep learning method for vector field reconstruction that takes the streamlines traced from the original vector fields as input and applies a two-stage process to reconstruct high-quality vector fields. To demonstrate the effectiveness of our approach, we show qualitative and quantitative results with several data sets and compare our method against the de facto method of gradient vector flow in terms of speed and quality tradeoff.",Jun Han 0010;Jun Tao 0002;Hao Zheng 0006;Hanqi Guo 0001;Danny Z. Chen;Chaoli Wang 0001,Jun Han;Jun Tao;Hao Zheng;Hanqi Guo;Danny Z. Chen;Chaoli Wang,University of Notre Dame;University of Notre Dame;University of Notre Dame;Argonne National Laboratory;University of Notre Dame;University of Notre Dame,0.1109/tvcg.2014.2346458;10.1109/tvcg.2010.131;10.1109/tvcg.2007.70595,,,32,18,773,,
CG&A,2019,Evaluating the Readability of Force Directed Graph Layouts: A Deep Learning Approach,10.1109/mcg.2018.2881501,http://dx.doi.org/10.1109/MCG.2018.2881501,40,53,MAG,"Existing graph layout algorithms are usually not able to optimize all the aesthetic properties desired in a graph layout. To evaluate how well the desired visual features are reflected in a graph layout, many readability metrics have been proposed in the past decades. However, the calculation of these readability metrics often requires access to the node and edge coordinates and is usually computationally inefficient, especially for dense graphs. Importantly, when the node and edge coordinates are not accessible, it becomes impossible to evaluate the graph layouts quantitatively. In this paper, we present a novel deep learning-based approach to evaluate the readability of graph layouts by directly using graph images. A convolutional neural network architecture is proposed and trained on a benchmark dataset of graph images, which is composed of synthetically generated graphs and graphs created by sampling from real large networks. Multiple representative readability metrics (including edge crossing, node spread, and group overlap) are considered in the proposed approach. We quantitatively compare our approach to traditional methods and qualitatively evaluate our approach by showing usage scenarios and visualizing convolutional layers. This paper is a first step towards using deep learning based methods to quantitatively evaluate images from the visualization field.",Hammad Haleem;Yong Wang 0021;Abishek Puri;Sahil Wadhwa;Huamin Qu,Hammad Haleem;Yong Wang;Abishek Puri;Sahil Wadhwa;Huamin Qu,The Hong Kong University of Science and Technology;The Hong Kong University of Science and Technology;The Hong Kong University of Science and Technology;Blackrock;The Hong Kong University of Science and Technology,0.1109/tvcg.2017.2744938;10.1109/tvcg.2016.2598831;10.1109/tvcg.2012.245;10.1109/vast.2017.8585721;10.1109/tvcg.2008.158;10.1109/tvcg.2017.2744358;10.1109/tvcg.2015.2467691;10.1109/tvcg.2018.2843369;10.1109/tvcg.2017.2743858;10.1109/tvcg.2017.2744878,,,25,20,841,,
CG&A,2018,RNNbow: Visualizing Learning Via Backpropagation Gradients in RNNs,10.1109/mcg.2018.2878902,http://dx.doi.org/10.1109/MCG.2018.2878902,39,50,MAG,"We present RNNbow, an interactive tool for visualizing the gradient flow during backpropagation in training of recurrent neural networks. By visualizing the gradient, as opposed to activations, RNNbow offers insight into how the network is learning. We show how it illustrates the vanishing gradient and the training process.",Dylan Cashman;Genevieve Patterson;Abigail Mosca;Nathan Watts;Shannon Robinson;Remco Chang,Dylan Cashman;Geneviève Patterson;Abigail Mosca;Nathan Watts;Shannon Robinson;Remco Chang,Tufts University;Microsoft Research;Tufts University;Tufts University;Tufts University;Tufts University,0.1109/vast.2017.8585721;10.1109/tvcg.2017.2744158;10.1109/tvcg.2017.2744938;10.1109/tvcg.2017.2744878;10.1109/tvcg.2016.2598831;10.1109/tvcg.2017.2744718,,,24,19,620,,
CG&A,2019,Augmented Reality Graph Visualizations,10.1109/mcg.2019.2897927,http://dx.doi.org/10.1109/MCG.2019.2897927,29,40,MAG,"Three-dimensional node-link diagrams are an important class of visualization for immersive analysis. Yet, there is little knowledge on how to visualize edges to support efficient analysis. We present an exploration of the design space for edge styles and discuss the results of a user study comparing six different edge variants.",Wolfgang Büschel;Stefan Vogt;Raimund Dachselt,Wolfgang Büschel;Stefan Vogt;Raimund Dachselt,"Interactive Media Lab, Technische Universität Dresden;Interactive Media Lab, Technische Universität Dresden;Interactive Media Lab, Technische Universität Dresden",0.1109/tvcg.2016.2520921;10.1109/tvcg.2016.2599107,,,26,15,1318,,
CG&A,2018,Visualization and the Digital Humanities:,10.1109/mcg.2018.2878900,http://dx.doi.org/10.1109/MCG.2018.2878900,26,38,MAG,"For the past two years, researchers from the visualization community and the digital humanities have come together at the IEEE VIS conference to discuss how both disciplines can work together to push research goals in their respective disciplines. In this paper, we present our experiences as a result of this collaboration.",Adam James Bradley;Mennatallah El-Assady;Katharine Coles;Eric C. Alexander;Min Chen 0001;Christopher Collins 0001;Stefan Jänicke;David Joseph Wrisley,Adam James Bradley;Mennatallah El-Assady;Katharine Coles;Eric Alexander;Min Chen;Christopher Collins;Stefan Jänicke;David Joseph Wrisley,"University of Ontario Institute of Technology;University of Utah, Salt Lake City, UT, US;University of Utah;University of Oxford, Oxford, Oxfordshire, GB;University of Ontario Institute of Technology, Oshawa, ON, CA;Universitat Leipzig, Leipzig, Sachsen, DE;New York University - Abu Dhabi Campus, Abu Dhabi, Abu Dhabi, AE;New York University Abu Dhabi",0.1109/tvcg.2011.255;10.1109/vast.2014.7042493;10.1109/tvcg.2015.2467811;10.1109/vast.2017.8585505,,,26,20,1469,,
CG&A,2019,Immersive Analytics Lessons From the Electronic Visualization Laboratory: A 25-Year Perspective,10.1109/mcg.2019.2901428,http://dx.doi.org/10.1109/MCG.2019.2901428,54,66,MAG,"This paper provides a 25-year-long perspective on immersive analytics through the lens of first-in-kind technological advancements introduced at the Electronic Visualization Laboratory, University of Illinois at Chicago, along with the challenges and lessons learned from multiple immersive analytics projects.",G. Elisabeta Marai;Jason Leigh;Andrew E. Johnson 0001,G. Elisabeta Marai;Jason Leigh;Andrew Johnson,University of Illinois at Chicago;University of Hawaii at Manoa;University of Illinois at Chicago,,,,24,12,534,,
CG&A,2017,Urban Space Explorer: A Visual Analytics System for Urban Planning,10.1109/mcg.2017.3621223,http://dx.doi.org/10.1109/MCG.2017.3621223,50,60,MAG,"Understanding people's behavior is fundamental to many planning professions (including transportation, community development, economic development, and urban design) that rely on data about frequently traveled routes, places, and social and cultural practices. Based on the results of a practitioner survey, the authors designed Urban Space Explorer, a visual analytics system that utilizes mobile social media to enable interactive exploration of public-space-related activity along spatial, temporal, and semantic dimensions.",Alireza Karduni;Isaac Cho;Ginette Wessel;William Ribarsky;Eric Sauda;Wenwen Dou,Alireza Karduni;Isaac Cho;Ginette Wessel;William Ribarsky;Eric Sauda;Wenwen Dou,"University of North Carolina, Charlotte;University of North Carolina, Charlotte;Roger Williams University;University of North Carolina, Charlotte;University of North Carolina, Charlotte;University of North Carolina, Charlotte",0.1109/tvcg.2015.2468111,"computer graphics,visual analytics,urban planning,social media,planning support",,16,15,1114,,
CG&A,2019,Comfortable Immersive Analytics With the VirtualDesk Metaphor,10.1109/mcg.2019.2898856,http://dx.doi.org/10.1109/MCG.2019.2898856,41,53,MAG,"The VirtualDesk metaphor is an opportunity for more comfortable and efficient immersive data exploration, using tangible interaction with the analyst's physical work desk and embodied manipulation of mid-air data representations. In this paper, we present an extended discussion of its underlying concepts, and review and compare two previous case studies where promising results were obtained in terms of user comfort, engagement, and usability. We also discuss findings of a novel study conducted with geovisualization experts, pointing directions for improvement and future research.",Jorge A. Wagner Filho;Carla M. D. S. Freitas;Luciana P. Nedel,Jorge A. Wagner Filho;Carla M. D. S. Freitas;Luciana Nedel,Federal University of Rio Grande do Sul;Federal University of Rio Grande do Sul;Federal University of Rio Grande do Sul,0.1109/tvcg.2017.2745941;10.1109/mcg.2014.82,,,24,16,893,,
CG&A,2018,Mapping and Visualizing Deep-Learning Urban Beautification,10.1109/mcg.2018.053491732,http://dx.doi.org/10.1109/MCG.2018.053491732,70,83,MAG,"Information visualization has great potential to make sense of the increasing amount of data generated by complex machine-learning algorithms. We design a set of visualizations for a new deep-learning algorithm called FaceLift (goodcitylife.org/facelift). This algorithm is able to generate a beautified version of a given urban image (such as from Google Street View), and our visualizations compare pairs of original and beautified images. With those visualizations, we aim at helping practitioners understand what happened during the algorithmic beautification without requiring them to be machine-learning experts. We evaluate the effectiveness of our visualizations to do just that with a survey among practitioners. From the survey results, we derive general design guidelines on how information visualization makes complex machine-learning algorithms more understandable to a general audience.",Tobias Kauer;Sagar Joglekar 0001;Miriam Redi;Luca Maria Aiello;Daniele Quercia,Tobias Kauer;Sagar Joglekar;Miriam Redi;Luca Maria Aiello;Daniele Quercia,"University of Applied Science, Potsdam;King's College, London;Nokia Bell Labs, Cambridge;Nokia Bell Labs, Cambridge;Nokia Bell Labs, Cambridge",,"information visualization,data and knowledge visualization,deep learning,urban informatics,computer graphics",,17,20,955,,
CG&A,2019,Analytic Provenance in Practice: The Role of Provenance in Real-World Visualization and Data Analysis Environments,10.1109/mcg.2019.2933419,http://dx.doi.org/10.1109/MCG.2019.2933419,30,45,MAG,"Practical data analysis scenarios involve more than just the interpretation of data through visual and algorithmic analysis. Many real-world analysis environments involve multiple types of experts and analysts working together to solve problems and make decisions, adding organizational and social requirements to the mix. We aim to provide new knowledge about the role of provenance for practical problems in a variety of analysis scenarios central to national security. We present the findings from interviews with data analysts from domains, such as intelligence analysis, cyber-security, and geospatial intelligence. In addition to covering multiple analysis domains, our study also considers practical workplace implications related to organizational roles and the level of analyst experience. The results demonstrate how different needs for provenance depend on different roles in the analysis effort (e.g., data analyst, task managers, data analyst trainers, and quality control analysts). By considering the core challenges reported along with an analysis of existing provenance-support techniques through existing research and systems, we contribute new insights about needs and opportunities for improvements to provenance-support methods.",Karthic Madanagopal;Eric D. Ragan;Perakath C. Benjamin,Karthic Madanagopal;Eric D. Ragan;Perakath Benjamin,Texas A&M University;University of Florida;Knowledge Based Systems Inc.,0.1109/vast.2016.7883515;10.1109/tvcg.2018.2865040;10.1109/tvcg.2015.2467551;10.1109/vast.2011.6102438;10.1109/mcg.2014.62,"Human-centered computing-Visual-Analytics-Provenance-Insight-provenance,Qualitative-user-study",,18,20,670,,
CG&A,2019,A Walk Among the Data,10.1109/mcg.2019.2898941,http://dx.doi.org/10.1109/MCG.2019.2898941,19,28,MAG,"We examine the potential for immersive unit visualizations—interactive virtual environments populated with objects representing individual items in a dataset. Our virtual reality prototype highlights how immersive unit visualizations can allow viewers to examine data at multiple scales, support immersive exploration, and create affective personal experiences with data.",Alexander Ivanov 0004;Kurtis Thorvald Danyluk;Christian Jacob 0001;Wesley Willett,Alexander Ivanov;Kurtis Danyluk;Christian Jacob;Wesley Willett,University of Calgary;University of Calgary;University of Calgary;University of Calgary,0.1109/tvcg.2016.2599107;10.1109/tvcg.2017.2785807,,,17,21,1090,,
CG&A,2018,VitalVizor: A Visual Analytics System for Studying Urban Vitality,10.1109/mcg.2018.053491730,http://dx.doi.org/10.1109/MCG.2018.053491730,38,53,MAG,Creating lively places with high urban vitality is an ultimate goal for urban planning and design. The VitalVizor visual analytics system employs well-established visualization and interaction techniques to facilitate user exploration of spatial physical entities and non-spatial urban design metrics when studying urban vitality.,Wei Zeng 0004;Yu Ye 0002,Wei Zeng;Yu Ye,Shenzhen Institutes of Advanced Technology;Tongji University,0.1109/tvcg.2007.70574;10.1109/tvcg.2016.2520920;10.1109/tvcg.2017.2744159;10.1109/mcg.2017.3621223,"urban vitality,tree diagram,visual analytics,computer graphics",,17,19,1028,,
CG&A,2019,Capturing and Visualizing Provenance From Data Wrangling,10.1109/mcg.2019.2941856,http://dx.doi.org/10.1109/MCG.2019.2941856,61,75,MAG,"Data quality management and assessment play a vital role for ensuring the trust in the data and its fitness-of-use for subsequent analysis. The transformation history of a data wrangling system is often insufficient for determining the usability of a dataset, lacking information how changes affected the dataset. Capturing workflow provenance along the wrangling process and combining it with descriptive information as data provenance can enable users to comprehend how these changes affected the dataset, and if they benefited data quality. We present DQProv Explorer, a system that captures and visualizes provenance from data wrangling operations. It features three visualization components: allowing the user to explore the provenance graph of operations and the data stream, the development of quality over time for a sequence of wrangling operations applied to the dataset, and the distribution of issues across the entirety of the dataset to determine error patterns.",Christian Bors;Theresia Gschwandtner;Silvia Miksch,Christian Bors;Theresia Gschwandtner;Silvia Miksch,TU Wien;TU Wien;TU Wien,0.1109/tvcg.2017.2745298;10.1109/tvcg.2015.2467551;10.1109/tvcg.2012.285,"Data Wrangling,Data Cleansing,Data Quality,Quality Metrics,Data Provenance,Sensemaking",,14,20,923,,
CG&A,2020,"A Data-Driven Introduction to Authors, Readings, and Techniques in Visualization for the Digital Humanities",10.1109/mcg.2020.2973945,http://dx.doi.org/10.1109/MCG.2020.2973945,45,57,MAG,"The newly rediscovered frontier between data visualization and the digital humanities has proven to be an exciting field of experimentation for scholars from both disciplines. This fruitful collaboration is attracting researchers from other areas of science who may be willing to create visual analysis tools that promote humanities research in its many forms. However, as the collaboration grows in complexity, it may become intimidating for these scholars to get engaged in the discipline. To facilitate this task, we have built an introduction to visualization for the digital humanities that sits on a data-driven stance adopted by the authors. In order to construct a dataset representative of the discipline, we analyze citations from a core corpus on 300 publications in visualization for the humanities obtained from recent editions of the InfoVis Vis4DH workshop, the ADHO Digital Humanities Conference, and the specialized digital humanities journal Digital Humanities Quarterly. From here, we extract referenced works and analyze more than 1900 publications in search of citation patterns, prominent authors in the field, and other interesting insights. Finally, following the path set by other researchers in the visualization and Human–Computer Interaction (HCI) communities, we analyze paper keywords to identify significant themes and research opportunities in the field.",Alejandro Benito-Santos;Roberto Therón Sánchez,Alejandro Benito-Santos;Roberto Therón Sánchez,University of Salamanca;University of Salamanca,0.1109/tvcg.2016.2598827;10.1109/tvcg.2018.2830759;10.1109/mcg.2018.2878900;10.1109/tvcg.2012.213;10.1109/tvcg.2016.2615308,,,14,18,935,,
CG&A,2020,Illustrating Changes in Time-Series Data With Data Video,10.1109/mcg.2020.2968249,http://dx.doi.org/10.1109/MCG.2020.2968249,18,31,MAG,"Understanding the changes of time-series is a common task in many application domains. Converting time-series data into videos helps an audience with little or no background knowledge gain insights and deep impressions. It essentially integrates data visualizations and animations to present the evolution of data expressively. However, it remains challenging to create this kind of data video. First, it is difficult to efficiently detect important changes and include them in the video sequence. Existing methods require much manual effort to explore the data and find changes. Second, how these changes are emphasized in the videos is also worth studying. A video without emphasis will hinder an audience from noticing those important changes. This article presents an approach that extracts and visualizes important changes of a time-series. Users can explore and modify these changes, and apply visual effects on them. Case studies and user feedback demonstrate the effectiveness and usability of our approach.",Junhua Lu;Jie Wang;Hui Ye;Yuhui Gu;Zhiyu Ding;Mingliang Xu;Wei Chen 0001,Junhua Lu;Jie Wang;Hui Ye;Yuhui Gu;Zhiyu Ding;Mingliang Xu;Wei Chen,"State Key Lab of CAD&CG, Zhejiang University;State Key Lab of CAD&CG, Zhejiang University;State Key Lab of CAD&CG, Zhejiang University;State Key Lab of CAD&CG, Zhejiang University;Cloud BU, Huawei Technologies Co Ltd;Zhengzhou University;State Key Lab of CAD&CG, Zhejiang University",0.1109/tvcg.2010.190;10.1109/tvcg.2016.2598647;10.1109/tvcg.2010.179;10.1109/tvcg.2011.255,"Data storytelling,time-series data,data video",,13,19,979,,
CG&A,2019,Cross-Platform Ubiquitous Volume Rendering Using Programmable Shaders in VTK for Scientific and Medical Visualization,10.1109/mcg.2018.2880818,http://dx.doi.org/10.1109/MCG.2018.2880818,26,43,MAG,"The visualization toolkit (VTK) is a popular cross-platform, open source toolkit for scientific and medical data visualization, processing, and analysis. It supports a wide variety of data formats, algorithms, and rendering techniques for both polygonal and volumetric data. In particular, VTK's volume rendering module has long provided a comprehensive set of features such as plane clipping, color and opacity transfer functions, lighting, and other controls needed for visualization. However, due to VTK's legacy OpenGL backend and its reliance on a deprecated API, the system did not take advantage of the latest improvements in graphics hardware or the flexibility of a programmable pipeline. Additionally, this dependence on an antiquated pipeline posed restrictions when running on emerging computing platforms, thereby limiting its overall applicability. In response to these shortcomings, the VTK community developed a new and improved volume rendering module, which not only provides a modern graphics processing unit-based implementation, but also augments its capabilities with new features such as fast volume clipping, gradient-magnitude-based opacity modulation, render to texture, and hardware-based volume picking.",Aashish Chaudhary;Sankhesh Jhaveri;Alvaro Sanchez;Lisa Sobierajski Avila;Kenneth M. Martin;Allison Vacanti;Marcus D. Hanwell;William J. Schroeder,Aashish Chaudhary;Sankhesh J. Jhaveri;Alvaro Sanchez;Lisa S. Avila;Kenneth M. Martin;Allison Vacanti;Marcus D. Hanwell;Will Schroeder,"Kitware, Inc.;Kitware, Inc.;Kitware, Inc.;Kitware, Inc.;Kitware, Inc.;Kitware, Inc.;Kitware, Inc.;Kitware, Inc.",0.1109/visual.1993.398852;10.1109/tvcg.2016.2599041,,,10,39,763,,
CG&A,2018,Belle2VR: A Virtual-Reality Visualization of Subatomic Particle Physics in the Belle II Experiment,10.1109/mcg.2018.032421652,http://dx.doi.org/10.1109/MCG.2018.032421652,33,43,MAG,"Belle2VR is an interactive virtual-reality visualization of subatomic particle physics, designed by an interdisciplinary team as an educational tool for learning about and exploring subatomic particle collisions. This article describes the tool, discusses visualization design decisions, and outlines our process for collaborative development.",Zach Duer;Leo Piilonen;George Glasson,Zach Duer;Leo Piilonen;George Glasson,Virginia Tech;Virginia Tech;Virginia Tech,,"visualization,physics,virtual reality",,11,11,416,,
CG&A,2021,Narrative Physicalization: Supporting Interactive Engagement With Personal Data,10.1109/mcg.2020.3025078,http://dx.doi.org/10.1109/MCG.2020.3025078,74,86,MAG,"Physical engagement with data necessarily influences the reflective process. However, the role of interactivity and narration are often overlooked when designing and analyzing personal data physicalizations. We introduce Narrative Physicalizations, everyday objects modified to support nuanced self-reflection through embodied engagement with personal data. Narrative physicalizations borrow from narrative visualizations, storytelling with graphs, and engagement with mundane artifacts from data-objects. Our research uses a participatory approach to research-through-design and includes two interdependent studies. In the first, personalized data physicalizations are developed for three individuals. In the second, we conduct a parallel autobiographical exploration of what constitutes personal data when using a Fitbit. Our work expands the landscape of data physicalization by introducing narrative physicalizations. It suggests an experience-centric view on data physicalization where people engage physically with their data in playful ways, making their body an active agent during the reflective process.",Maria Karyda 0002;Danielle Wilde;Mette Gislev Kjærsgaard,Maria Karyda;Danielle Wilde;Mette Gislev Kjærsgaard,"Department of Design, Aalto University;University of Southern Denmark;University of Southern Denmark",0.1109/tvcg.2010.179,"data physicalisation,personal data,embodiment",,18,20,970,,
CG&A,2018,Management of Cerebral Aneurysm Descriptors based on an Automatic Ostium Extraction,10.1109/mcg.2018.032421654,http://dx.doi.org/10.1109/MCG.2018.032421654,58,72,MAG,"We present a framework to manage cerebral aneurysms. Rupture risk evaluation is based on manually extracted descriptors, which is time-consuming. Thus, we provide an automatic solution by considering several questions: How can expert knowledge be integrated? How should meta data be defined? Which interaction techniques are needed for data exploration",Monique Meuschke;Tobias Günther;Ralph Wickenhöfer;Markus H. Gross;Bernhard Preim;Kai Lawonn,Monique Meuschke;Tobias Günther;Ralph Wickenhöfer;Markus Gross;Bernhard Preim;Kai Lawonn,University of Magdeburg;ETH Zürich;Heart of Jesus Hospital;ETH Zürich;University of Magdeburg;University of Koblenz-Landau,0.1109/tvcg.2015.2467441,"visualization,ostium extraction,cerebral aneurysms,data management,morphological descriptors,computer graphics",,7,23,218,,
CG&A,2019,A Provenance Task Abstraction Framework,10.1109/mcg.2019.2945720,http://dx.doi.org/10.1109/MCG.2019.2945720,46,60,MAG,"Visual analytics tools integrate provenance recording to externalize analytic processes or user insights. Provenance can be captured on varying levels of detail, and in turn activities can be characterized from different granularities. However, current approaches do not support inferring activities that can only be characterized across multiple levels of provenance. We propose a task abstraction framework that consists of a three stage approach, composed of 1) initializing a provenance task hierarchy, 2) parsing the provenance hierarchy by using an abstraction mapping mechanism, and 3) leveraging the task hierarchy in an analytical tool. Furthermore, we identify implications to accommodate iterative refinement, context, variability, and uncertainty during all stages of the framework. We describe a use case which exemplifies our abstraction framework, demonstrating how context can influence the provenance hierarchy to support analysis. The article concludes with an agenda, raising and discussing challenges that need to be considered for successfully implementing such a framework.",Christian Bors;John E. Wenskovitch;Michelle Dowling;Simon Attfield;Leilani Battle;Alex Endert;Olga Kulyk;Robert S. Laramee,Christian Bors;John Wenskovitch;Michelle Dowling;Simon Attfield;Leilani Battle;Alex Endert;Olga Kulyk;Robert S. Laramee,TU Wien;Virginia Tech;Virginia Tech;Middlesex University;University of Maryland;Georgia Tech;InnoValor;Swansea University,0.1109/tvcg.2014.2346575;10.1109/tvcg.2015.2467551;10.1109/tvcg.2017.2744319;10.1109/tvcg.2013.124,"Provenance,Task Abstraction,Provenance Hierarchy,Visual Analytics,Framework,Conceptual Model,Sensemaking",,9,18,466,,
CG&A,2020,PixelClipper: Supporting Public Engagement and Conversation About Visualizations,10.1109/mcg.2020.2968906,http://dx.doi.org/10.1109/MCG.2020.2968906,57,70,MAG,"In this article, we present PixelClipper, a tool built for facilitating data engagement events. PixelClipper supports conversations around visualizations in public settings through annotation and commenting capabilities. It is recognized that understanding data is important for an informed society. However, even when visualizations are available on the web, open data is not yet reaching all audiences. Public facilitated events centered around data visualizations may help bridge this gap. PixelClipper is designed to promote discussion and engagement with visualizations in public settings. It allows viewers to quickly and expressively extract visual clippings from visualizations and add comments to them. Ambient and facilitator displays attract attention by showing clippings. They function as entry points to the full visualizations while supporting deeper conversations about the visualizations and data. We describe the design goals of PixelClipper, share our experiences from deploying it, and discuss its future potential in supporting data visualization engagement events.",Jagoda Walny;Sarah Storteboom;Richard Pusch;Steven Munsu Hwang;Søren Knudsen;Sheelagh Carpendale;Wesley Willett,Jagoda Walny;Sarah Storteboom;Richard Pusch;Steven Munsu Hwang;Søren Knudsen;Sheelagh Carpendale;Wesley Willett,University of Calgary;University of Calgary;University of Calgary;University of Calgary;University of Calgary and University of Copenhagen;University of Calgary and Simon Fraser University;University of Calgary,0.1109/tvcg.2007.70577;10.1109/tvcg.2010.179,,,8,10,509,,
CG&A,2018,OpenSpace: Changing the Narrative of Public Dissemination in Astronomical Visualization from What to How,10.1109/mcg.2018.032421653,http://dx.doi.org/10.1109/MCG.2018.032421653,44,57,MAG,"We present the development of an open-source software called OpenSpace that bridges the gap between scientific discoveries and public dissemination and thus paves the way for the next generation of science communication and data exploration. We describe how the platform enables interactive presentations of dynamic and time-varying processes by domain experts to the general public. The concepts are demonstrated through four cases: Image acquisitions of the New Horizons and Rosetta spacecraft, the dissemination of space weather phenomena, and the display of high-resolution planetary images. Each case has been presented at public events with great success. These cases highlight the details of data acquisition, rather than presenting the final results, showing the audience the value of supporting the efforts of the scientific discovery.",Alexander Bock 0002;Emil Axelsson;Carter Emmart;Masha Kuznetsova;Charles D. Hansen;Anders Ynnerman,Alexander Bock;Emil Axelsson;Carter Emmart;Masha Kuznetsova;Charles Hansen;Anders Ynnerman,New York University;Linköping University;American Museum of Natural History;Community Coordinated Modeling Center;University of Utah;University of Utah,0.1109/scivis.2015.7429487,"public dissemination,astronomical visualization,computer graphics",,6,12,336,,
CG&A,2018,Graphoto: Aesthetically Pleasing Charts for Casual Information Visualization,10.1109/mcg.2018.2879066,http://dx.doi.org/10.1109/MCG.2018.2879066,67,82,MAG,"Graphoto is a framework that automatically generates a photo or adjusts an existing one to match a line graph. Since aesthetics is an important element in visualizing personal data, Graphoto provides users with aesthetically pleasing displays for casual line graph information visualization. More specifically, after creating a line graph of the input data, a photo that resembles the input data on the line graph is selected from a photo archive. If a selected photo does not match the line graph, we deform the photo to match the line graph. Once the photo matches the line graph of the data, the line graph is superimposed on the photo using different colors and styles depending on the user's artistic preferences. Additional embellishments are integrated into Graphoto, such as tick marks and text labels. We further present a user study to show the effectiveness of Graphoto in terms of data interpretation and aesthetics.",Ji Hwan Park;Arie E. Kaufman;Klaus Mueller 0001,Ji Hwan Park;Arie Kaufman;Klaus Mueller,"Stony Brook University, Stony Brook, NY, US;Stony Brook University, Stony Brook, NY, US;Stony Brook University, Stony Brook, NY, US",0.1109/tvcg.2010.162;10.1109/tvcg.2014.2359887;10.1109/tvcg.2013.234;10.1109/tvcg.2012.197;10.1109/tvcg.2011.196;10.1109/infvis.2003.1249031;10.1109/tvcg.2007.70541;10.1109/infvis.2004.8,,,6,26,745,,
CG&A,2019,Personalized Sketch-Based Brushing in Scatterplots,10.1109/mcg.2018.2881502,http://dx.doi.org/10.1109/MCG.2018.2881502,28,39,MAG,"Brushing is at the heart of most modern visual analytics solutions and effective and efficient brushing is crucial for successful interactive data exploration and analysis. As the user plays a central role in brushing, several data-driven brushing tools have been designed that are based on predicting the user's brushing goal. All of these general brushing models learn the users' average brushing preference, which is not optimal for every single user. In this paper, we propose an innovative framework that offers the user opportunities to improve the brushing technique while using it. We realized this framework with a CNN-based brushing technique and the result shows that with additional data from a particular user, the model can be refined (better performance in terms of accuracy), eventually converging to a personalized model based on a moderate amount of retraining.",Chaoran Fan;Helwig Hauser,Chaoran Fan;Helwig Hauser,University of Bergen;University of Bergen,0.1109/tvcg.2017.2743859;10.1109/visual.1995.485139,,,5,20,390,,
CG&A,2021,CLEVis: A Semantic Driven Visual Analytics System for Community Level Events,10.1109/mcg.2020.2973939,http://dx.doi.org/10.1109/MCG.2020.2973939,49,62,MAG,"Community-level event (CLE) datasets, such as police reports of crime events, contain abundant semantic information of event situations, and descriptions in a geospatial-temporal context. They are critical for frontline users, such as police officers and social workers, to discover and examine insights about community neighborhoods. We propose CLEVis, a neighborhood visual analytics system for CLE datasets, to help frontline users explore events for insights at community regions of interest, namely fine-grained geographical resolutions, such as small neighborhoods around local restaurants, churches, and schools. CLEVis fully utilizes semantic information by integrating automatic algorithms and interactive visualizations. The design and development of CLEVis are conducted with solid collaborations with real-world community workers and social scientists. Case studies and user feedback are presented with real-world datasets and applications.",Chao Ma 0023;Ye Zhao 0003;Andrew Curtis;Farah Kamw;Shamal Al-Dohuki;Jing Yang 0001;Suphanut Jamonnak;Ismael Ali,Chao Ma;Ye Zhao;Andrew Curtis;Farah Kamw;Shamal AL-Dohuki;Jing Yang;Suphanut Jamonnak;Ismael Ali,"Kent State University, Kent, OH, USA;Kent State University, Kent, OH, USA;Case Western Reserve University, Cleveland, OH, USA;Concordia University, Ann Arbor, MI, USA;University of Duhok, Dohuk, Kurdistan Region, AJ, Iraq;UNC Charlotte, Charlotte, NC, USA;Kent State University, Kent, OH, USA;University of Zakho, Dohuk, Kurdistan Region, AJ, Iraq",0.1109/vast.2011.6102456;10.1109/tvcg.2014.2346926;10.1109/tvcg.2016.2598585;10.1109/vast.2012.6400557;10.1109/tvcg.2013.179;10.1109/mcg.2016.49;10.1109/vast.2017.8585658;10.1109/vast.2011.6102498;10.1109/tvcg.2018.2834341,,,5,20,389,,
CG&A,2021,Exploring the Design Space of Sankey Diagrams for the Food-Energy-Water Nexus,10.1109/mcg.2019.2927556,http://dx.doi.org/10.1109/MCG.2019.2927556,25,34,MAG,"In this work, we define a set of design requirements relating to Sankey diagrams for supporting food–energy–water nexus understanding and propose the network embodied sectoral trajectory diagram design, a visualization design that incorporates a number of characteristics from Sankey diagrams, treemaps, and graphs, to improve the readability and minimize the negative impact of edge crossings that are common in traditional Sankey diagrams.",Brandon Mathis;Yuxin Ma;Michelle Mancenido;Ross Maciejewski,Brandon Mathis;Yuxin Ma;Michelle Mancenido;Ross Maciejewski,"Arizona State University, Tempe, AZ, USA;Arizona State University, Tempe, AZ, USA;Arizona State University, Glendale, AZ, USA;Arizona State University, Tempe, AZ, USA",0.1109/tvcg.2011.190;10.1109/scivis.2015.7429485,,,6,12,568,,
CG&A,2020,Nano for the Public: An Exploranation Perspective,10.1109/mcg.2020.2973120,http://dx.doi.org/10.1109/MCG.2020.2973120,32,42,MAG,"Public understanding of contemporary scientific issues is critical for the future of society. Public spaces, such as science centers, can impact the communication of science by providing active knowledge-building experiences of scientific phenomena. In contributing to this vision, we have previously developed an interactive visualization as part of a public exhibition about nano. We reflect on how the immersive design and features of the exhibit contribute as a tool for science communication in light of the emerging paradigm of exploranation, and offer some forward-looking perspectives about what this notion has to offer the domain.",Gunnar E. Höst;Karljohan E. Lundin Palmerius;Konrad J. Schönborn,Gunnar Höst;Karljohan Palmerius;Konrad Schönborn,Linköping University;Linköping University;Linköping University,,"N.2 E-learning tools < N. Learning Technologies,N.6 Devices for learning < N. Learning Technologies,H.5.1.b Artificial,augmented,and virtual realities < H.5.1 Multimedia Information Systems < H.5 Information Interfaces and Representation (HCI) < H Information Technology and Systems,N.1.e Educational simulations < N.1 Learning environments < N. Learning Technologies,I.6.3 Applications < I.6 Simulation,Modeling,and Visualization < I Computing Methodologies",,5,10,539,,
CG&A,2020,Move&Find: The Value of Kinaesthetic Experience in a Casual Data Representation,10.1109/mcg.2020.3025385,http://dx.doi.org/10.1109/MCG.2020.3025385,61,75,MAG,"The value of a data representation is traditionally judged based on aspects like effectiveness and efficiency that are important in utilitarian or work-related contexts. Most multisensory data representations, however, are employed in casual contexts where creativity, affective, physical, intellectual, and social engagement might be of greater value. We introduce Move&Find, a multisensory data representation in which people pedalled on a bicycle to exert the energy required to power a search query on Google's servers. To evaluate Move&Find, we operationalized a framework suitable to evaluate the value of data representations in casual contexts and experimentally compared Move&Find to a corresponding visualization. With Move&Find, participants achieved a higher understanding of the data. Move&Find was judged to be more creative and encouraged more physical and social engagement—components of value that would have been missed using more traditional evaluation frameworks.",Jörn Hurtienne;Franzisca Maas;Astrid Carolus;Daniel Reinhardt;Cordula Baur;Carolin Wienrich,Jörn Hurtienne;Franzisca Maas;Astrid Carolus;Daniel Reinhardt;Cordula Baur;Carolin Wienrich,Julius-Maximilians-Universität Würzburg;Julius-Maximilians-Universität Würzburg;Julius-Maximilians-Universität Würzburg;Julius-Maximilians-Universität Würzburg;Julius-Maximilians-Universität Würzburg;Julius-Maximilians-Universität Würzburg,0.1109/tvcg.2007.70541,,,9,18,475,,
CG&A,2020,Aggregated Ensemble Views for Deep Water Asteroid Impact Simulations,10.1109/mcg.2019.2915215,http://dx.doi.org/10.1109/MCG.2019.2915215,72,81,MAG,"Simulation ensembles such as the ones simulating deep water asteroid impacts have many facets. Their analysis in terms of detecting spatiotemporal patterns, comparing multiple runs, and analyzing the influence of simulation parameters requires aggregation at multiple levels. We propose respective visual encodings embedded in an interactive visual analysis tool.",Simon Leistikow;Karim Huesmann;Alexey Fofonov;Lars Linsen,Simon Leistikow;Karim Huesmann;Alexey Fofonov;Lars Linsen,"Westfälische Wilhelms-Universität Münster, Germany;Westfälische Wilhelms-Universität Münster, Germany;Jacobs University, Bremen, Germany;Westfälische Wilhelms-Universität Münster, Germany",0.1109/tvcg.2015.2498554,,,4,5,385,,
CG&A,2017,Typology of Uncertainty in Static Geolocated Graphs for Visualization,10.1109/mcg.2017.3621220,http://dx.doi.org/10.1109/MCG.2017.3621220,18,27,MAG,"Static geolocated graphs have nodes connected by edges, where both can have geographic location and associated attributes. For example, it can be uncertain exactly where a node is located or whether an edge between two nodes exists. Because source data is often incomplete or inexact, it is necessary to visualize this uncertainty to help users make appropriate decisions. The proposed typology of uncertainty extends related typologies with specific features needed for characterizing uncertainty in static geolocated graphs.",Tatiana von Landesberger;Sebastian Bremm;Marcel Wunderlich,Tatiana von Landesberger;Sebastian Bremm;Marcel Wunderlich,Technical University of Darmstadt;Fresenius AG;Technical University of Darmstadt,0.1109/tvcg.2010.260;10.1109/vast.2011.6102455;10.1109/tvcg.2015.2467691;10.1109/tvcg.2012.285;10.1109/tvcg.2012.279;10.1109/vast.2009.5332611;10.1109/tvcg.2015.2424872;10.1109/tvcg.2010.176;10.1109/tvcg.2015.2467752;10.1109/tvcg.2012.220;10.1109/tvcg.2016.2598919;10.1109/tvcg.2016.2607204;10.1109/vast.2011.6102442;10.1109/tvcg.2015.2467554;10.1109/tvcg.2013.232,"computer graphics,geographic data science,node uncertainty,edge uncertainty,spatial databases,GIS,networks,visualization",,4,48,572,,
CG&A,2018,Application-Driven Design: Help Students Understand Employment and See the “Big Picture”,10.1109/mcg.2018.032421656,http://dx.doi.org/10.1109/MCG.2018.032421656,90,105,MAG,Few tools for career exploration utilize visualizations despite their potential to help students understand the intangible relationships between jobs and majors. Our application-driven design combines the intuitiveness of node-link diagrams and the scalability of aggregation-based techniques to combine an overview of a job database with the option for individualized exploration.,Li Liu 0028;Deborah Silver;Karen G. Bemis,Li Liu;Deborah Silver;Karen Bemis,Rutgers University;Rutgers University;Rutgers University,0.1109/tvcg.2009.111;10.1109/tvcg.2006.147;10.1109/visual.1990.146402;10.1109/tvcg.2012.254,"career counseling,categorical data,circular layout,visualization",,3,14,361,,
CG&A,2021,QuteVis: Visually Studying Transportation Patterns Using Multisketch Query of Joint Traffic Situations,10.1109/mcg.2019.2911230,http://dx.doi.org/10.1109/MCG.2019.2911230,35,48,MAG,"QuteVis uses multisketch query and visualization to discover specific times and days in history with specified joint traffic patterns at different city locations. Users can use touch input devices to define, edit, and modify multiple sketches on a city map. A set of visualizations and interactions is provided to help users browse and compare retrieved traffic situations and discover potential influential factors. QuteVis is built upon a transport database that integrates heterogeneous data sources with an optimized spatial indexing and weighted similarity computation. An evaluation with real-world data and domain experts demonstrates that QuteVis is useful in urban transportation applications in modern cities.",Shamal Al-Dohuki;Ye Zhao 0003;Farah Kamw;Jing Yang 0001;Xinyue Ye;Wei Chen 0001,Shamal AL-Dohuki;Ye Zhao;Farah Kamw;Jing Yang;Xinyue Ye;Wei Chen,"Kent State University, Kent, OH, USA;Kent State University, Kent, OH, USA;Kent State University, Kent, OH, USA;University of North Carolina at Charlotte, Charlotte, NC, USA;New Jersey Institute of Technology, Newark, NJ, USA;Zhejiang University, Hangzhou, China",0.1109/tvcg.2013.191;10.1109/tvcg.2013.179;10.1109/vast.2012.6400491;10.1109/tvcg.2015.2467112;10.1109/tvcg.2015.2467153;10.1109/tvcg.2014.2346265;10.1109/vast.2014.7042486;10.1109/tvcg.2013.226;10.1109/tvcg.2016.2598416,,,3,20,505,,
CG&A,2020,What We Talk About When We Talk About Data Physicality,10.1109/mcg.2020.3024146,http://dx.doi.org/10.1109/MCG.2020.3024146,25,37,MAG,"Data physicalizations “map data to physical form,” yet many canonical examples are not based on external data sets. To address this contradiction, I argue that the practice of physicalization forces us to rethink traditional notions of data. This article proposes a conceptual framework to examine how physicalizations relate to data. This article develops a two-dimensional conceptual space for comparing different perspectives on data used in physicalization, drawing from design theory and critical data studies literature. One axis distinguishes between epistemological and ontological perspectives, focusing on the relationship between data and the mind. The second axis distinguishes how data relate to the world, differentiating between representational and relational perspectives. To clarify the aesthetic and conceptual implications of these different perspectives, the article discusses examples of data physicalization for each quadrant of the continuous space. It further uses the framework to examine the explicit and implicit assumptions about data in physicalization literature. As a theoretical article, it encourages practitioners to think about how data relate to the manifestations and the phenomena they try to capture. It invites exploration of the relationship between data and the world as a generative source of creative tension.",Dietmar Offenhuber,Dietmar Offenhuber,Northeastern University,0.1109/tvcg.2019.2934788,,,11,28,781,,
CG&A,2021,Data Clothing and BigBarChart: Designing Physical Data Reports on Indoor Pollutants for Individuals and Communities,10.1109/mcg.2020.3025322,http://dx.doi.org/10.1109/MCG.2020.3025322,87,98,MAG,"In response to participant preferences and new ethics guidelines, researchers are increasingly sharing data with health study participants, including data on their own household chemical exposures. Data physicalization may be a useful tool for these communications, because it is thought to be accessible to a general audience and emotionally engaged. However, there are limited studies of data physicalization in the wild with diverse communities. Our application of this method in the Green Housing Study is an early example of using data physicalization in environmental health report-back. We gathered feedback through community meetings, prototype testing, and semistructured interviews, leading to the development of data t-shirts and other garments and person-sized bar charts. We found that participants were enthusiastic about data physicalizations, it connected them to their previous experience, and they had varying desires to share their data. Our findings suggest that researchers can enhance environmental communications by further developing the human experience of physicalizations and engaging diverse communities.",Laura J. Perovich;Phoebe Cai;Amber Guo;Kristin Zimmerman;Katherine Paseman;Dayanna Espinoza Silva;Julia G. Brody,Laura J. Perovich;Phoebe Cai;Amber Guo;Kristin Zimmerman;Katherine Paseman;Dayanna Espinoza Silva;Julia G. Brody,"Northeastern University, Boston, MA, USA;Harvard University, Cambridge, MA, USA;Microsoft, Seattle, WA, USA;Weber Group, Sellersburg, IN, USA;Fix the Mask, Walnut, CA, USA;Oracle, Santa Clara, CA, USA;Silent Spring Institute, Newton, MA, USA",0.1109/tvcg.2016.2598498;10.1109/tvcg.2016.2598608,,,4,22,409,,
CG&A,2020,Towards Placental Surface Vasculature Exploration in Virtual Reality,10.1109/mcg.2018.2881985,http://dx.doi.org/10.1109/MCG.2018.2881985,28,39,MAG,"We present a case study evaluating the potential for interactively identifying placental surface blood vessels using magnetic resonance imaging (MRI) scans in virtual reality (VR) environments. We visualized the MRI data using direct volume rendering in a high-fidelity CAVE-like VR system, allowing medical professionals to identify relevant placental vessels directly from volume visualizations in the VR system, without prior vessel segmentation. Participants were able to trace most of the observable vascular structure, and consistently identified blood vessels down to diameters of 1 mm, an important requirement in diagnosing vascular diseases. Qualitative feedback from our participants suggests that our VR visualization is easy to understand and allows intuitive data exploration, but complex user interactions remained a challenge. Using these observations, we discuss implications and requirements for spatial tracing user interaction methods in VR environments. We believe that VR MRI visualizations are the next step towards effective surgery planning for prenatal diseases.",Johannes Novotny;Wesley Miller;François I. Luks;Derek Merck;Scott Collins;David H. Laidlaw,Johannes Novotny;Wesley R. Miller;François I. Luks;Derek Merck;Scott Collins;David H. Laidlaw,Brown University;Brown University;Rhode Island Hospital;Rhode Island Hospital;Rhode Island Hospital;Brown University,0.1109/tvcg.2012.292,,,4,9,461,,
CG&A,2020,Many Views Are Not Enough: Designing for Synoptic Insights in Cultural Collections,10.1109/mcg.2020.2985368,http://dx.doi.org/10.1109/MCG.2020.2985368,58,71,MAG,"Cultural object collections attract and delight spectators since ancient times. Yet, they also easily overwhelm visitors due to their perceptual richness and associated information. Similarly, digitized collections appear as complex, multifaceted phenomena, which can be challenging to grasp and navigate. Though visualizations can create various types of collection overviews for that matter, they do not easily assemble into a “big picture” or lead to an integrated understanding. We introduce coherence techniques to maximize connections between multiple views and apply them to the prototype PolyCube system of collection visualization: with map, set, and network visualizations it makes spatial, categorical, and relational collection aspects visible. For the essential temporal dimension, it offers four different views: superimposition, animation, juxtaposition, and space–time cube representations. A user study confirmed that better integrated visualizations support synoptic, cross-dimensional insights. An outlook is dedicated to the system's applicability within other arts and humanities data domains.",Florian Windhager;Saminu Salisu;Roger A. Leite;Velitchko Andreev Filipov;Silvia Miksch;Günther Schreder;Eva Mayr,Florian Windhager;Saminu Salisu;Roger A. Leite;Velitchko Filipov;Silvia Miksch;Günther Schreder;Eva Mayr,Danube University Krems;Danube University Krems;Vienna University of Technology;Vienna University of Technology;Vienna University of Technology;Danube University Krems;Danube University Krems,0.1109/tvcg.2013.124;10.1109/tvcg.2013.153;10.1109/tvcg.2018.2830759;10.1109/mcg.2018.2878900,,,4,20,1007,,
CG&A,2017,Impact of Spatial Scales on the Intercomparison of Climate Scenarios,10.1109/mcg.2017.3621222,http://dx.doi.org/10.1109/MCG.2017.3621222,40,49,MAG,"Scenario analysis has been widely applied in climate science to understand the impact of climate change on the future human environment, but intercomparison and similarity analysis of different climate scenarios based on multiple simulation runs remain challenging. Although spatial heterogeneity plays a key role in modeling climate and human systems, little research has been performed to understand the impact of spatial variations and scales on similarity analysis of climate scenarios. To address this issue, the authors developed a geovisual analytics framework that lets users perform similarity analysis of climate scenarios from the Global Change Assessment Model (GCAM) using a hierarchical clustering approach.",Wei Luo;Michael Steptoe;Zheng Chang;Robert Link;Leon Clarke;Ross Maciejewski,Wei Luo;Michael Steptoe;Zheng Chang;Robert Link;Leon Clarke;Ross Maciejewski,"University of California, Santa Barbara;Arizona State University;Amazon Corporate;Pacific Northwest National Laboratory;Pacific Northwest National Laboratory;Arizona State University",0.1109/infvis.2000.885088,"computer graphics,geographic data science,scenario analysis,hierarchical clustering,geographical visualization,spatial scale",,2,10,374,,
CG&A,2018,Toward a Multimodal Diagnostic Exploratory Visualization of Focal Cortical Dysplasia,10.1109/mcg.2018.032421655,http://dx.doi.org/10.1109/MCG.2018.032421655,73,89,MAG,"Focal cortical dysplasia (FCD) is a malformation of cortical development and a common cause of pharmacoresistant epilepsy. Resective surgery of clear-cut lesions may be curative. However, the localization of the seizure focus and the evaluation of its spatial extent can be challenging in many situations. For concordance assessment, medical studies show the relevance of accurate correlation of multisource imaging sequences. to improve the sensitivity and specificity of the evaluation. In this paper, we share the process we went through to reach our simple, but effective, solution for integrating multi-volume rendering into an exploratory visualization environment for the diagnosis of FCD. We focus on fetching of multiple data assigned to a sample when they are rendered. Knowing that the major diagnostic role of multiple volumes is to complement information, we demonstrate that appropriate geometric transformations in the texture space are sufficient for accomplishing this task. This allows us to fully implement our proposal in the OpenGL rendering pipeline and to easily integrate it into the existing visual diagnostic application. Both time performance and the visual quality of our proposal were evaluated with a set of clinical data volumes for assessing the potential practical impact of our solution in routine diagnostic use.",Shin-Ting Wu;Raphael Voltoline;Wallace Souza Loos;José Angel Iván Rubianes Silva;Lionis de Souza Watanabe;Barbara Amorim;Ana Carolina Coan;Fernando Cendes;Clarissa L. Yasuda,Shin-Ting Wu;Raphael Voltoline;Wallace S. Loos;J.A. Ivan Rubianes Silva;Lionis S. Watanabe;Bárbara J. Amorim;A. Carolina Coan;Fernando Cendes;Clarissa L. Yasuda,"University of Campinas;School of Electrical and Computer Engineering, University of Campinas;School of Electrical and Computer Engineering, University of Campinas;University of Campinas;Clinical Hospital, University of Campinas;Clinical Hospital, University of Campinas;School of Medical Sciences, University of Campinas;School of Medical Sciences, University of Campinas;School of Medical Sciences, University of Campinas",0.1109/tvcg.2007.70560,"life and medical sciences,interactive environments,volume visualization,computer graphics",,2,20,270,,
CG&A,2021,Dynamic 3-D Visualization of Climate Model Development and Results,10.1109/mcg.2020.3042587,http://dx.doi.org/10.1109/MCG.2020.3042587,17,25,MAG,"Climate models play a significant role in the understanding of climate change, and the effective presentation and interpretation of their results is important for both the scientific community and the general public. In the case of the latter audience—which has become increasingly concerned with the implications of climate change for society—there is a requirement for visualizations which are compelling and engaging. We describe the use of ParaView, a well-established visualization application, to produce images and animations of results from a large set of modeling experiments, and their use in the promulgation of climate research results. Visualization can also make useful contributions to development, particularly for complex large-scale applications such as climate models. We present early results from the construction of a next-generation climate model which has been designed for use on exascale compute platforms, and show how visualization has helped in the development process, particularly with regard to higher model resolutions and novel data representations.",Jeremy Walton;Samantha V. Adams;Wolfgang Hayek;Piotr Florek;Harold Dyson,Jeremy Walton;Samantha Adams;Wolfgang Hayek;Piotr Florek;Harold Dyson,"Met Office Hadley Centre for Climate Science and Services, Exeter, U.K.;Met Office Informatics Lab, Exeter, U.K.;National Institute of Water and Atmospheric Research, Wellington, New Zealand;Met Office Hadley Centre for Climate Science and Services, Exeter, U.K.;Met Office Hadley Centre for Climate Science and Services, Exeter, U.K.",,,,2,20,550,,
CG&A,2017,Name Profiler Toolkit,10.1109/mcg.2017.3621224,http://dx.doi.org/10.1109/MCG.2017.3621224,61,71,MAG,"The Name Profiler Toolkit is a visual analytics system designed to enable the interactive exploration and analysis of forename and surname geographical distributions across the United States. The toolkit utilizes 78 million records from US public telephone directories, links the location data to demographic data from the US Census Bureau and Zillow, and allows users to interactively compare distributions of names and name attributes. Using the forename and surname data as a case study, the authors developed a methodology for exploring joint probability distributions of categorical spatial data and demonstrate how such data can be linked to secondary sources of information (such as income and age) to derive further insights from the data.",Feng Wang 0012;Brett Hansen;Ryan Simmons;Ross Maciejewski,Feng Wang;Brett Hansen;Ryan Simmons;Ross Maciejewski,Arizona State University;Arizona State University;Arizona State University;Arizona State University,,"computer graphics,geographic data science,geographical visualization,geo-genealogy,density estimation,Name Profiler Toolkit,visual analytics,data visualization",,1,21,175,,
CG&A,2018,Designing Effective Visual Interactive Systems despite Sparse Availability of Domain Information,10.1109/mcg.2018.053491731,http://dx.doi.org/10.1109/MCG.2018.053491731,54,69,MAG,"Tailoring visualization and interaction design to the demands of an application is challenging if domain information is unavailable or confidential. This article discusses a process-centric design approach, allowing for inferring design goals indirectly from informal interviews with practitioners and stakeholders. The design benefits from their expertise, while secrets remain secret.",Benjamin Karer;Alina Freund;Michael Horst;Inga Scheler;Thomas Kossurok;Franz-Josef Brandt,Benjamin Karer;Alina Freund;Michael Horst;Inga Scheler;Thomas Kossurok;Franz-Josef Brandt,University of Kaiserslautern;University of Kaiserslautern;Westpfalz Police Headquarters;University of Kaiserslautern;Westpfalz Police Headquarters;Westpfalz Police Headquarters,0.1109/tvcg.2014.2346323;10.1109/tvcg.2009.111;10.1109/tvcg.2015.2462356;10.1109/tvcg.2012.213;10.1109/tvcg.2015.2467271;10.1109/tvcg.2011.209,"design study,domain requirements,applications,design methodology,computer graphics",,1,20,277,,
CG&A,2021,Slave Voyages: Reflections on Data Sculptures,10.1109/mcg.2020.3025183,http://dx.doi.org/10.1109/MCG.2020.3025183,65,73,MAG,"This pictorial presents the development of a data sculpture, followed by our reflections inspired by Research through Design (RtD) and Dahlstedt's process-based model of artistic creativity. We use the notion of negotiation between concept and material representation to reflect on the ideation, design process, production, and the exhibition of “Slave Voyages” — a set of data sculptures that depicts slave traffic from Africa to the American continent. The work was initially produced as an assignment on physicalization for the Design course at the Federal University of Rio de Janeiro. Our aim is to open discussion on material representation and negotiation in the creative process of data physicalization.",Doris Kosminsky;Douglas Thomaz de Oliveira,Doris Kosminsky;Douglas Thomaz de Oliveira,"Universidade Federal do Rio de Janeiro, Rio de Janeiro, Brazil;Universidade Federal do Rio de Janeiro, Rio de Janeiro, Brazil",0.1109/tvcg.2019.2934539,,,3,18,422,,
CG&A,2019,PUMA-V: Optimizing Parallel Code Performance Through Interactive Visualization,10.1109/mcg.2018.2877113,http://dx.doi.org/10.1109/MCG.2018.2877113,84,99,MAG,Performance optimization for parallel loop-oriented programs compromises between parallelism and locality. We present a visualization interface that allows programmers to assist the compiler in generating optimal code. It greatly improves the user's understanding of the transformations that took place and aids in making additional transformations in a visually intuitive way.,Eric Papenhausen;Matthew Harper Langston;Benoît Meister;Richard Lethin;Klaus Mueller 0001,Eric Papenhausen;M. Harper Langston;Benoit Meister;Richard A. Lethin;Klaus Mueller,"Stony Brook University;Reservoir Labs, Inc.;Reservoir Labs, Inc.;Reservoir Labs, Inc.;Stony Brook University",,,,0,20,241,,
TVCG,2019,"Multidimensional Projection for Visual Analytics: Linking Techniques with Distortions, Tasks, and Layout Enrichment",10.1109/tvcg.2018.2846735,http://dx.doi.org/10.1109/TVCG.2018.2846735,2650,2673,J,"Visual analysis of multidimensional data requires expressive and effective ways to reduce data dimensionality to encode them visually. Multidimensional projections (MDP) figure among the most important visualization techniques in this context, transforming multidimensional data into scatter plots whose visual patterns reflect some notion of similarity in the original data. However, MDP come with distortions that make these visual patterns not trustworthy, hindering users to infer actual data characteristics. Moreover, the patterns present in the scatter plots might not be enough to allow a clear understanding of multidimensional data, motivating the development of layout enrichment methodologies to operate together with MDP. This survey attempts to cover the main aspects of MDP as a visualization and visual analytic tool. It provides detailed analysis and taxonomies as to the organization of MDP techniques according to their main properties and traits, discussing the impact of such properties for visual perception and other human factors. The survey also approaches the different types of distortions that can result from MDP mappings and it overviews existing mechanisms to quantitatively evaluate such distortions. A qualitative analysis of the impact of distortions on the different analytic tasks performed by users when exploring multidimensional data through MDP is also presented. Guidelines for choosing the best MDP for an intended task are also provided as a result of this analysis. Finally, layout enrichment schemes to debunk MDP distortions and/or reveal relevant information not directly inferable from the scatter plot are reviewed and discussed in the light of new taxonomies. We conclude the survey providing future research axes to fill discovered gaps in this domain.",Luis Gustavo Nonato;Michaël Aupetit 0001,Luis Gustavo Nonato;Michaël Aupetit,"University of São Paulo, São Paulo, Brazil;Qatar Computing Research Institute, Hamad Bin Khalifa University Doha, Qatar",0.1109/tvcg.2011.229;10.1109/vast.2012.6400486;10.1109/visual.1996.567787;10.1109/tvcg.2016.2598838;10.1109/tvcg.2015.2467717;10.1109/tvcg.2012.250;10.1109/tvcg.2015.2489660;10.1109/tvcg.2013.183;10.1109/tvcg.2015.2467931;10.1109/tvcg.2013.150;10.1109/vast.2010.5652443;10.1109/tvcg.2014.2346276;10.1109/tvcg.2015.2467552;10.1109/tvcg.2016.2598667;10.1109/tvcg.2011.188;10.1109/tvcg.2013.242;10.1109/tvcg.2013.188;10.1109/tvcg.2008.138;10.1109/tvcg.2011.220;10.1109/tvcg.2017.2701829;10.1109/tvcg.2010.207;10.1109/tvcg.2016.2598495;10.1109/tvcg.2013.65;10.1109/tvcg.2013.182;10.1109/infvis.1995.528686;10.1109/tvcg.2013.124;10.1109/tvcg.2014.2346481;10.1109/tvcg.2013.212;10.1109/tvcg.2010.154;10.1109/infvis.2004.60;10.1109/infvis.2002.1173161,"Multidimensional projection,dimensionality reduction,multidimensional scaling,error analysis,layout enrichment",,121,182,3187,,
TVCG,2019,Task-Based Effectiveness of Basic Visualizations,10.1109/tvcg.2018.2829750,http://dx.doi.org/10.1109/TVCG.2018.2829750,2505,2512,J,"Visualizations of tabular data are widely used; understanding their effectiveness in different task and data contexts is fundamental to scaling their impact. However, little is known about how basic tabular data visualizations perform across varying data analysis tasks. In this paper, we report results from a crowdsourced experiment to evaluate the effectiveness of five small scale (5-34 data points) two-dimensional visualization types-Table, Line Chart, Bar Chart, Scatterplot, and Pie Chart-across ten common data analysis tasks using two datasets. We find the effectiveness of these visualization types significantly varies across task, suggesting that visualization design would benefit from considering context-dependent effectiveness. Based on our findings, we derive recommendations on which visualizations to choose based on different tasks. We finally train a decision tree on the data we collected to drive a recommender, showcasing how to effectively engineer experimental user data into practical visualization systems.",Bahador Saket;Alex Endert;Çagatay Demiralp,Bahador Saket;Alex Endert;Çağatay Demiralp,"Georgia Tech, Atlanta, GA;Georgia Tech, Atlanta, GA;IBM Research, Yorktown Heights, NY",0.1109/tvcg.2016.2598920;10.1109/infvis.2004.10;10.1109/tvcg.2015.2467671;10.1109/tvcg.2014.2346320;10.1109/tvcg.2016.2598839;10.1109/tvcg.2015.2467191;10.1109/tvcg.2007.70594;10.1109/tvcg.2017.2745138;10.1109/tvcg.2014.2346298;10.1109/tvcg.2014.2346979;10.1109/tvcg.2017.2680452,"Information visualization,visualization types,visualization effectiveness,graphical perception",,87,43,3449,,
TVCG,2020,A Task-Based Taxonomy of Cognitive Biases for Information Visualization,10.1109/tvcg.2018.2872577,http://dx.doi.org/10.1109/TVCG.2018.2872577,1413,1432,J,"Information visualization designers strive to design data displays that allow for efficient exploration, analysis, and communication of patterns in data, leading to informed decisions. Unfortunately, human judgment and decision making are imperfect and often plagued by cognitive biases. There is limited empirical research documenting how these biases affect visual data analysis activities. Existing taxonomies are organized by cognitive theories that are hard to associate with visualization tasks. Based on a survey of the literature we propose a task-based taxonomy of 154 cognitive biases organized in 7 main categories. We hope the taxonomy will help visualization researchers relate their design to the corresponding possible biases, and lead to new research that detects and addresses biased judgment and decision making in data visualization.",Evanthia Dimara;Steven Franconeri;Catherine Plaisant;Anastasia Bezerianos;Pierre Dragicevic,Evanthia Dimara;Steven Franconeri;Catherine Plaisant;Anastasia Bezerianos;Pierre Dragicevic,"INRIA, Orsay, France;Northwestern University, Evanston, USA;University of Maryland, College Park, USA;University of Paris-Sud;INRIA, Orsay, France",0.1109/tvcg.2015.2467591;10.1109/tvcg.2011.174;10.1109/tvcg.2016.2599211;10.1109/tvcg.2014.2346979;10.1109/tvcg.2012.199;10.1109/tvcg.2015.2467758;10.1109/tvcg.2017.2745138;10.1109/tvcg.2016.2598594;10.1109/vast.2017.8585669;10.1109/vast.2017.8585665;10.1109/tvcg.2013.124;10.1109/tvcg.2014.2346298;10.1109/tvcg.2016.2598618;10.1109/tvcg.2017.2744138;10.1109/tvcg.2018.2865233;10.1109/tvcg.2013.173;10.1109/tvcg.2016.2598589;10.1109/vast.2009.5333920;10.1109/tvcg.2015.2413774;10.1109/tvcg.2015.2467732;10.1109/infvis.2004.10,"Cognitive bias,visualization,taxonomy,classification,decision making",,64,249,3935,,
TVCG,2018,Atom: A Grammar for Unit Visualizations,10.1109/tvcg.2017.2785807,http://dx.doi.org/10.1109/TVCG.2017.2785807,3032,3043,J,"Unit visualizations are a family of visualizations where every data item is represented by a unique visual mark-a visual unit-during visual encoding. For certain datasets and tasks, unit visualizations can provide more information, better match the user's mental model, and enable novel interactions compared to traditional aggregated visualizations. Current visualization grammars cannot fully describe the unit visualization family. In this paper, we characterize the design space of unit visualizations to derive a grammar that can express them. The resulting grammar is called Atom, and is based on passing data through a series of layout operations that divide the output of previous operations recursively until the size and position of every data point can be determined. We evaluate the expressive power of the grammar by both using it to describe existing unit visualizations, as well as to suggest new unit visualizations.",Deokgun Park 0001;Steven Mark Drucker;Roland Fernandez;Niklas Elmqvist,Deokgun Park;Steven M. Drucker;Roland Fernandez;Niklas Elmqvist,"University of Maryland, College Park, MD;Microsoft Research, Redmond, WA;University of Maryland, College Park, MD;Microsoft Research, Redmond, WA",0.1109/tvcg.2015.2467091;10.1109/tvcg.2011.185;10.1109/tvcg.2010.144;10.1109/tvcg.2009.174;10.1109/tvcg.2007.70539;10.1109/tvcg.2016.2598828;10.1109/tvcg.2010.197;10.1109/infvis.2002.1173156;10.1109/tvcg.2014.2346424;10.1109/tvcg.2010.79;10.1109/infvis.2003.1249018;10.1109/tvcg.2007.70535;10.1109/tvcg.2016.2599030;10.1109/tvcg.2008.153;10.1109/tvcg.2013.227;10.1109/tvcg.2014.2346292;10.1109/tvcg.2012.205;10.1109/tvcg.2011.227;10.1109/infvis.2001.963283,"Visualization grammar,unit visualizations,declarative specification",,66,61,1582,,
TVCG,2020,An Evaluation of Semantically Grouped Word Cloud Designs,10.1109/tvcg.2019.2904683,http://dx.doi.org/10.1109/TVCG.2019.2904683,2748,2761,J,"Word clouds continue to be a popular tool for summarizing textual information, despite their well-documented deficiencies for analytic tasks. Much of their popularity rests on their playful visual appeal. In this paper, we present the results of a series of controlled experiments that show that layouts in which words are arranged into semantically and visually distinct zones are more effective for understanding the underlying topics than standard word cloud layouts. White space separators and/or spatially grouped color coding led to significantly stronger understanding of the underlying topics compared to a standard Wordle layout, while simultaneously scoring higher on measures of aesthetic appeal. This work is an advance on prior research on semantic layouts for word clouds because that prior work has either not ensured that the different semantic groupings are visually or semantically distinct, or has not performed usability studies. An additional contribution of this work is the development of a dataset for a semantic category identification task that can be used for replication of these results or future evaluations of word cloud designs.",Marti A. Hearst;Emily Pedersen;Lekha Patil;Elsie Lee;Paul Laskowski;Steven Franconeri,Marti A. Hearst;Emily Pedersen;Lekha Patil;Elsie Lee;Paul Laskowski;Steven Franconeri,"UC Berkeley, Berkeley, USA;UC Berkeley, Berkeley, USA;UC Berkeley, Berkeley, USA;Northwestern University, Evanston, USA;UC Berkeley, Berkeley, USA;Northwestern University, Evanston, USA",0.1109/tvcg.2017.2745859;10.1109/tvcg.2009.171;10.1109/tvcg.2017.2746018;10.1109/tvcg.2009.122;10.1109/vast.2009.5333443;10.1109/tvcg.2010.175;10.1109/vast.2014.7042494,"Information visualization,word clouds,text analysis,data analytics,evaluation",,50,41,1849,,
TVCG,2020,Supporting Story Synthesis: Bridging the Gap between Visual Analytics and Storytelling,10.1109/tvcg.2018.2889054,http://dx.doi.org/10.1109/TVCG.2018.2889054,2499,2516,J,"Visual analytics usually deals with complex data and uses sophisticated algorithmic, visual, and interactive techniques supporting the analysis. Findings and results of the analysis often need to be communicated to an audience that lacks visual analytics expertise. This requires analysis outcomes to be presented in simpler ways than that are typically used in visual analytics systems. However, not only analytical visualizations may be too complex for target audiences but also the information that needs to be presented. Analysis results may consist of multiple components, which may involve multiple heterogeneous facets. Hence, there exists a gap on the path from obtaining analysis findings to communicating them, within which two main challenges lie: information complexity and display complexity. We address this problem by proposing a general framework where data analysis and result presentation are linked by story synthesis, in which the analyst creates and organises story contents. Unlike previous research, where analytic findings are represented by stored display states, we treat findings as data constructs. We focus on selecting, assembling and organizing findings for further presentation rather than on tracking analysis history and enabling dual (i.e., explorative and communicative) use of data displays. In story synthesis, findings are selected, assembled, and arranged in meaningful layouts that take into account the structure of information and inherent properties of its components. We propose a workflow for applying the proposed conceptual framework in designing visual analytics systems and demonstrate the generality of the approach by applying it to two diverse domains, social media and movement analysis.",Siming Chen 0001;Jie Li 0006;Gennady L. Andrienko;Natalia V. Andrienko;Yun Wang 0012;Phong H. Nguyen;Cagatay Turkay,Siming Chen;Jie Li;Gennady Andrienko;Natalia Andrienko;Yun Wang;Phong H. Nguyen;Cagatay Turkay,"Fraunhofer Institute IAIS, Sankt Augustin, Germany;College of Intelligence and Computing, Tianjin University, Tianjin, China;Fraunhofer Institute IAIS, Sankt Augustin, Germany;Fraunhofer Institute IAIS, Sankt Augustin, Germany;Microsoft Research Asia, Beijing, China;City, University of London, London, United Kingdom;City, University of London, London, United Kingdom",0.1109/vast.2012.6400485;10.1109/tvcg.2018.2865024;10.1109/vast.2016.7883515;10.1109/tvcg.2017.2745279;10.1109/vast.2006.261430;10.1109/tvcg.2018.2882449;10.1109/tvcg.2010.179;10.1109/tvcg.2016.2614803;10.1109/tvcg.2017.2744322;10.1109/tvcg.2008.165;10.1109/tvcg.2012.252;10.1109/tvcg.2013.167;10.1109/tvcg.2013.221;10.1109/tvcg.2013.132;10.1109/tvcg.2013.119;10.1109/tvcg.2011.255;10.1109/tvcg.2015.2467531;10.1109/tvcg.2013.191;10.1109/vast.2016.7883510;10.1109/vast.2010.5652922;10.1109/tvcg.2013.196;10.1109/tvcg.2014.2346919;10.1109/tvcg.2012.291;10.1109/vast.2017.8585638,"Story synthesis,visual analytics,social media,spatio-temporal data",,52,70,2464,,
TVCG,2018,StreamExplorer: A Multi-Stage System for Visually Exploring Events in Social Streams,10.1109/tvcg.2017.2764459,http://dx.doi.org/10.1109/TVCG.2017.2764459,2758,2772,J,"Analyzing social streams is important for many applications, such as crisis management. However, the considerable diversity, increasing volume, and high dynamics of social streams of large events continue to be significant challenges that must be overcome to ensure effective exploration. We propose a novel framework by which to handle complex social streams on a budget PC. This framework features two components: 1) an online method to detect important time periods (i.e., subevents), and 2) a tailored GPU-assisted Self-Organizing Map (SOM) method, which clusters the tweets of subevents stably and efficiently. Based on the framework, we present StreamExplorer to facilitate the visual analysis, tracking, and comparison of a social stream at three levels. At a macroscopic level, StreamExplorer uses a new glyph-based timeline visualization, which presents a quick multi-faceted overview of the ebb and flow of a social stream. At a mesoscopic level, a map visualization is employed to visually summarize the social stream from either a topical or geographical aspect. At a microscopic level, users can employ interactive lenses to visually examine and explore the social stream from different perspectives. Two case studies and a task-based evaluation are used to demonstrate the effectiveness and usefulness of StreamExplorer.",Yingcai Wu;Zhutian Chen;Guodao Sun;Xiao Xie;Nan Cao 0001;Shixia Liu;Weiwei Cui,Yingcai Wu;Chen Zhu-Tian;Guodao Sun;Xiao Xie;Nan Cao;Shixia Liu;Weiwei Cui,"State Key Lab of CAD&CG, Zhejiang University, Hangzhou, Zhejiang, China;Hong Kong University of Science and Technology, Hong Kong;Zhejiang University of Technology, Hangzhou, Zhejiang, China;State Key Lab of CAD&CG, Zhejiang University, Hangzhou, Zhejiang, China;College of Design and Innovation, Tongji University, Shanghai, China;School of Software, Tsinghua University, Beijing, China;Microsoft Research, Beijing, China",0.1109/vast.2011.6102456;10.1109/tvcg.2012.291;10.1109/tvcg.2010.129;10.1109/vast.2012.6400557;10.1109/tvcg.2015.2467531;10.1109/tvcg.2016.2614803;10.1109/tvcg.2015.2467991;10.1109/tvcg.2013.227;10.1109/tvcg.2011.179;10.1109/vast.2012.6400552;10.1109/tvcg.2015.2392771;10.1109/tvcg.2015.2509990;10.1109/vast.2010.5652922;10.1109/tvcg.2016.2598590;10.1109/tvcg.2013.196;10.1109/tvcg.2014.2346919;10.1109/tvcg.2013.186;10.1109/tvcg.2011.188;10.1109/tvcg.2014.2346920;10.1109/tvcg.2010.183;10.1109/tvcg.2014.2346912,"Social media visualization,visual analytics,social stream,streaming data,self-organizing map",,39,48,1535,,
TVCG,2021,Net2Vis – A Visual Grammar for Automatically Generating Publication-Tailored CNN Architecture Visualizations,10.1109/tvcg.2021.3057483,http://dx.doi.org/10.1109/TVCG.2021.3057483,2980,2991,J,"To convey neural network architectures in publications, appropriate visualizations are of great importance. While most current deep learning papers contain such visualizations, these are usually handcrafted just before publication, which results in a lack of a common visual grammar, significant time investment, errors, and ambiguities. Current automatic network visualization tools focus on debugging the network itself and are not ideal for generating publication visualizations. Therefore, we present an approach to automate this process by translating network architectures specified in Keras into visualizations that can directly be embedded into any publication. To do so, we propose a visual grammar for convolutional neural networks (CNNs), which has been derived from an analysis of such figures extracted from all ICCV and CVPR papers published between 2013 and 2019. The proposed grammar incorporates visual encoding, network layout, layer aggregation, and legend generation. We have further realized our approach in an online system available to the community, which we have evaluated through expert feedback, and a quantitative study. It not only reduces the time needed to generate network visualizations for publications, but also enables a unified and unambiguous visualization design.",Alex Bäuerle;Christian van Onzenoodt;Timo Ropinski,Alex Bäuerle;Christian van Onzenoodt;Timo Ropinski,"Visual Computing Group at Ulm University, Ulm, Germany;Visual Computing Group at Ulm University, Ulm, Germany;Visual Computing Group at Ulm University, Ulm, Germany",0.1109/tvcg.2016.2614803;10.1109/tvcg.2009.111;10.1109/tvcg.2018.2843369;10.1109/tvcg.2018.2864500;10.1109/tvcg.2016.2598831;10.1109/tvcg.2017.2744938;10.1109/tvcg.2017.2744718;10.1109/tvcg.2017.2744878;10.1109/tvcg.2017.2746018;10.1109/tvcg.2019.2921323,"Neural networks,architecture visualization,graph layouting",,40,65,921,,X
TVCG,2021,EmotionCues: Emotion-Oriented Visual Summarization of Classroom Videos,10.1109/tvcg.2019.2963659,http://dx.doi.org/10.1109/TVCG.2019.2963659,3168,3181,J,"Analyzing students’ emotions from classroom videos can help both teachers and parents quickly know the engagement of students in class. The availability of high-definition cameras creates opportunities to record class scenes. However, watching videos is time-consuming, and it is challenging to gain a quick overview of the emotion distribution and find abnormal emotions. In this article, we propose EmotionCues, a visual analytics system to easily analyze classroom videos from the perspective of emotion summary and detailed analysis, which integrates emotion recognition algorithms with visualizations. It consists of three coordinated views: a summary view depicting the overall emotions and their dynamic evolution, a character view presenting the detailed emotion status of an individual, and a video view enhancing the video analysis with further details. Considering the possible inaccuracy of emotion recognition, we also explore several factors affecting the emotion analysis, such as face size and occlusion. They provide hints for inferring the possible inaccuracy and the corresponding reasons. Two use cases and interviews with end users and domain experts are conducted to show that the proposed system could be useful and effective for analyzing emotions in the classroom videos.",Haipeng Zeng;Xinhuan Shu;Yanbang Wang;Yong Wang 0021;Liguo Zhang;Ting-Chuen Pong;Huamin Qu,Haipeng Zeng;Xinhuan Shu;Yanbang Wang;Yong Wang;Liguo Zhang;Ting-Chuen Pong;Huamin Qu,"Hong Kong University of Science and Technology, Hong Kong;Hong Kong University of Science and Technology, Hong Kong;Hong Kong University of Science and Technology, Hong Kong;Hong Kong University of Science and Technology, Hong Kong;Harbin Engineering University, Harbin, China;Hong Kong University of Science and Technology, Hong Kong;Hong Kong University of Science and Technology, Hong Kong",0.1109/tvcg.2015.2467591;10.1109/tvcg.2006.194;10.1109/tvcg.2015.2467194;10.1109/tvcg.2013.265;10.1109/tvcg.2017.2745181;10.1109/tvcg.2011.208;10.1109/tvcg.2013.168;10.1109/tvcg.2019.2934656;10.1109/tvcg.2013.173;10.1109/tvcg.2009.111;10.1109/vast.2009.5332611;10.1109/vast.2014.7042496;10.1109/visual.2003.1250401;10.1109/tvcg.2011.239;10.1109/tvcg.2013.196,"Emotion,classroom videos,visual summarization,visual analytics",,38,60,3518,,
TVCG,2021,Analyzing Dynamic Hypergraphs with Parallel Aggregated Ordered Hypergraph Visualization,10.1109/tvcg.2019.2933196,http://dx.doi.org/10.1109/TVCG.2019.2933196,1,13,J,"Parallel Aggregated Ordered Hypergraph(PAOH) is a novel technique to visualize dynamic hypergraphs. Hypergraphs are a generalization of graphs where edges can connect several vertices. Hypergraphs can be used to model networks of business partners or co-authorship networks with multiple authors per article. A dynamic hypergraph evolves over discrete time slots. PAOH represents vertices as parallel horizontal bars and hyperedges as vertical lines, using dots to depict the connections to one or more vertices. We describe a prototype implementation of Parallel Aggregated Ordered Hypergraph, report on a usability study with 9 participants analyzing publication data, and summarize the improvements made. Two case studies and several examples are provided. We believe that PAOH is the first technique to provide a highly readable representation of dynamic hypergraphs. It is easy to learn and well suited for medium size dynamic hypergraphs (50-500 vertices) such as those commonly generated by digital humanities projects-our driving application domain.",Paola Valdivia;Paolo Buono;Catherine Plaisant;Nicole Dufournaud;Jean-Daniel Fekete,Paola Valdivia;Paolo Buono;Catherine Plaisant;Nicole Dufournaud;Jean-Daniel Fekete,"Inria, Saclay, France;University of Bari, Italy;University of Maryland, USA;École des Hautes Études en Sciences Sociales, Paris, France;Inria, Saclay, France",0.1109/tvcg.2013.254;10.1109/tvcg.2011.226;10.1109/tvcg.2015.2392771;10.1109/tvcg.2015.2467691;10.1109/tvcg.2014.2346249;10.1109/tvcg.2014.2346248,"dynamic graph,interaction,case study,dynamic hypergraph,digital humanities,usability ",,36,50,1657,,
TVCG,2021,Visual Cause Analytics for Traffic Congestion,10.1109/tvcg.2019.2940580,http://dx.doi.org/10.1109/TVCG.2019.2940580,2186,2201,J,"Urban traffic congestion has become an important issue not only affecting our daily lives, but also limiting economic development. The primary cause of urban traffic congestion is that the number of vehicles is higher than the permissible limit of the road. Previous studies have focused on dispersing traffic volume by detecting urban traffic congestion zones and predicting future trends. However, to solve the fundamental problem, it is necessary to discover the cause of traffic congestion. Nevertheless, it is difficult to find a research which presents an approach to identify the causes of traffic congestion. In this paper, we propose a technique to analyze the cause of traffic congestion based on the traffic flow theory. We extract vehicle flows from traffic data, such as GPS trajectory and Vehicle Detector data. We detect vehicle flow changes utilizing the entropy from the information theory. Then, we build cumulative vehicle count curves (N-curve) that can quantify the flow of the vehicles in the traffic congestion area. The N-curves are classified into four different traffic congestion patterns by a convolutional neural network. Analyzing the causes and influence of traffic congestion is difficult and requires considerable experience and knowledge. Therefore, we present a visual analytics system that can efficiently perform a series of processes to analyze the cause and influence of traffic congestion. Through case studies, we have evaluated that our system can classify the causes of traffic congestion and can be used efficiently in road planning.",Mingyu Pi;Hanbyul Yeon;Hyesook Son;Yun Jang,Mingyu Pi;Hanbyul Yeon;Hyesook Son;Yun Jang,"Sejong University, Seoul, South Korea;Sejong University, Seoul, South Korea;Sejong University, Seoul, South Korea;Sejong University, Seoul, South Korea",0.1109/tvcg.2018.2851227;10.1109/tvcg.2016.2535234;10.1109/tvcg.2016.2598416;10.1109/tvcg.2015.2467771;10.1109/tvcg.2015.2467592;10.1109/tvcg.2016.2598432;10.1109/tvcg.2015.2440259;10.1109/infvis.2003.1249025;10.1109/vast.2015.7347679;10.1109/tvcg.2007.70528;10.1109/tvcg.2015.2467931;10.1109/vast.2008.4677356;10.1109/vast.2015.7347630;10.1109/tvcg.2011.185;10.1109/tvcg.2013.228;10.1109/tvcg.2013.226;10.1109/tvcg.2014.2346746;10.1109/tvcg.2014.2346893;10.1109/vast.2014.7042486;10.1109/tvcg.2009.145;10.1109/vast.2011.6102455;10.1109/vast.2012.6400556,"Causes of traffic congestion,traffic flow theory,information entropy,convolutional neural network,visual analytics",,34,95,2771,,
TVCG,2019,A Semantic-Based Method for Visualizing Large Image Collections,10.1109/tvcg.2018.2835485,http://dx.doi.org/10.1109/TVCG.2018.2835485,2362,2377,J,"Interactive visualization of large image collections is important and useful in many applications, such as personal album management and user profiling on images. However, most prior studies focus on using low-level visual features of images, such as texture and color histogram, to create visualizations without considering the more important semantic information embedded in images. This paper proposes a novel visual analytic system to analyze images in a semantic-aware manner. The system mainly comprises two components: a semantic information extractor and a visual layout generator. The semantic information extractor employs an image captioning technique based on convolutional neural network (CNN) to produce descriptive captions for images, which can be transformed into semantic keywords. The layout generator employs a novel co-embedding model to project images and the associated semantic keywords to the same 2D space. Inspired by the galaxy metaphor, we further turn the projected 2D space to a galaxy visualization of images, in which semantic keywords and images are visually encoded as stars and planets. Our system naturally supports multi-scale visualization and navigation, in which users can immediately see a semantic overview of an image collection and drill down for detailed inspection of a certain group of images. Users can iteratively refine the visual layout by integrating their domain knowledge into the co-embedding process. Two task-based evaluations are conducted to demonstrate the effectiveness of our system.",Xiao Xie;Xiwen Cai;Junpei Zhou;Nan Cao 0001;Yingcai Wu,Xiao Xie;Xiwen Cai;Junpei Zhou;Nan Cao;Yingcai Wu,"State Key Lab of CAD&CG, Alibaba-Zhejiang University, Hangzhou, China;State Key Lab of CAD&CG, Zhejiang University, Hangzhou, China;State Key Lab of CAD&CG, Zhejiang University, Hangzhou, China;College of Design and Innovation, Tongji University, Shanghai, China;State Key Lab of CAD&CG, Alibaba-Zhejiang University, Hangzhou, China",0.1109/tvcg.2010.175;10.1109/tvcg.2015.2467621;10.1109/tvcg.2014.2388208;10.1109/tvcg.2014.2346431;10.1109/tvcg.2013.162;10.1109/tvcg.2012.324;10.1109/tvcg.2011.179;10.1109/tvcg.2017.2744098;10.1109/tvcg.2009.112;10.1109/tvcg.2014.2346594;10.1109/tvcg.2016.2598831;10.1109/tvcg.2017.2744938;10.1109/tvcg.2017.2764895;10.1109/tvcg.2009.201;10.1109/vast.2006.261425;10.1109/tvcg.2013.212;10.1109/infvis.1996.559223;10.1109/tvcg.2016.2598445,"Image visualization,semantic layout,CNN,image captioning",,32,54,1449,,
TVCG,2020,Inviwo — A Visualization System with Usage Abstraction Levels,10.1109/tvcg.2019.2920639,http://dx.doi.org/10.1109/TVCG.2019.2920639,3241,3254,J,"The complexity of today's visualization applications demands specific visualization systems tailored for the development of these applications. Frequently, such systems utilize levels of abstraction to improve the application development process, for instance by providing a data flow network editor. Unfortunately, these abstractions result in several issues, which need to be circumvented through an abstraction-centered system design. Often, a high level of abstraction hides low level details, which makes it difficult to directly access the underlying computing platform, which would be important to achieve an optimal performance. Therefore, we propose a layer structure developed for modern and sustainable visualization systems allowing developers to interact with all contained abstraction levels. We refer to this interaction capabilities as usage abstraction levels, since we target application developers with various levels of experience. We formulate the requirements for such a system, derive the desired architecture, and present how the concepts have been exemplary realized within the Inviwo visualization system. Furthermore, we address several specific challenges that arise during the realization of such a layered architecture, such as communication between different computing platforms, performance centered encapsulation, as well as layer-independent development by supporting cross layer documentation and debugging capabilities.",Daniel Jönsson;Peter Steneteg;Erik Sundén;Rickard Englund;Sathish Kottravel;Martin Falk;Anders Ynnerman;Ingrid Hotz;Timo Ropinski,Daniel Jönsson;Peter Steneteg;Erik Sundén;Rickard Englund;Sathish Kottravel;Martin Falk;Anders Ynnerman;Ingrid Hotz;Timo Ropinski,"Linköing University, Linköing, Sweden;Linköing University, Linköing, Sweden;Linköing University, Linköing, Sweden;Linköing University, Linköing, Sweden;Linköing University, Linköing, Sweden;Linköing University, Linköing, Sweden;Linköing University, Linköing, Sweden;Linköing University, Linköing, Sweden;Ulm University, Ulm, Germany",0.1109/tvcg.2018.2864816;10.1109/tvcg.2018.2865152;10.1109/tvcg.2016.2598430;10.1109/tvcg.2010.126;10.1109/tvcg.2015.2467294;10.1109/mcg.2016.48;10.1109/tvcg.2012.133;10.1109/tvcg.2016.2598826;10.1109/tvcg.2015.2467952;10.1109/scivis.2015.7429487;10.1109/visual.2005.1532788;10.1109/tvcg.2018.2865265;10.1109/tvcg.2017.2743980,"Visualization systems,data visualization,visual analytics,data analysis,computer graphics,image processing",,29,55,1160,,
TVCG,2021,Volumetric Isosurface Rendering with Deep Learning-Based Super-Resolution,10.1109/tvcg.2019.2956697,http://dx.doi.org/10.1109/TVCG.2019.2956697,3064,3078,J,"Rendering an accurate image of an isosurface in a volumetric field typically requires large numbers of data samples. Reducing this number lies at the core of research in volume rendering. With the advent of deep learning networks, a number of architectures have been proposed recently to infer missing samples in multidimensional fields, for applications such as image super-resolution. In this article, we investigate the use of such architectures for learning the upscaling of a low resolution sampling of an isosurface to a higher resolution, with reconstruction of spatial detail and shading. We introduce a fully convolutional neural network, to learn a latent representation generating smooth, edge-aware depth and normal fields as well as ambient occlusions from a low resolution depth and normal field. By adding a frame-to-frame motion loss into the learning stage, upscaling can consider temporal variations and achieves improved frame-to-frame coherence. We assess the quality of inferred results and compare it to bi-linear and cubic upscaling. We do this for isosurfaces which were never seen during training, and investigate the improvements when the network can train on the same or similar isosurfaces. We discuss remote visualization and foveated rendering as potential applications.",Sebastian Weiss;Mengyu Chu;Nils Thuerey;Rüdiger Westermann,Sebastian Weiss;Mengyu Chu;Nils Thuerey;Rüdiger Westermann,"Technical University of Munich, München, Germany;Technical University of Munich, München, Germany;Technical University of Munich, München, Germany;Technical University of Munich, München, Germany",0.1109/visual.1999.809911;10.1109/visual.1994.346320;10.1109/tvcg.2017.2744238;10.1109/visual.2003.1250384;10.1109/tvcg.2012.274;10.1109/tvcg.2019.2934255;10.1109/tvcg.2018.2816059,"Machine learning,extraction of surfaces (isosurfaces, material boundaries),volume rendering",,31,59,1091,,
TVCG,2020,MARVisT: Authoring Glyph-Based Visualization in Mobile Augmented Reality,10.1109/tvcg.2019.2892415,http://dx.doi.org/10.1109/TVCG.2019.2892415,2645,2658,J,"Recent advances in mobile augmented reality (AR) techniques have shed new light on personal visualization for their advantages of fitting visualization within personal routines, situating visualization in a real-world context, and arousing users’ interests. However, enabling non-experts to create data visualization in mobile AR environments is challenging given the lack of tools that allow in-situ design while supporting the binding of data to AR content. Most existing AR authoring tools require working on personal computers or manually creating each virtual object and modifying its visual attributes. We systematically study this issue by identifying the specificity of AR glyph-based visualization authoring tool and distill four design considerations. Following these design considerations, we design and implement MARVisT, a mobile authoring tool that leverages information from reality to assist non-experts in addressing relationships between data and virtual glyphs, real objects and virtual glyphs, and real objects and data. With MARVisT, users without visualization expertise can bind data to real-world objects to create expressive AR glyph-based visualizations rapidly and effortlessly, reshaping the representation of the real world with data. We use several examples to demonstrate the expressiveness of MARVisT. A user study with non-experts is also conducted to evaluate the authoring experience of MARVisT.",Zhutian Chen;Yijia Su;Yifang Wang 0001;Qianwen Wang;Huamin Qu;Yingcai Wu,Chen Zhu-Tian;Yijia Su;Yifang Wang;Qianwen Wang;Huamin Qu;Yingcai Wu,"State Key Lab of CAD&CG, Zhejiang University, Hangzhou, Zhejiang, China;Hong Kong University of Science and Technology, Hong Kong;Hong Kong University of Science and Technology, Hong Kong;Hong Kong University of Science and Technology, Hong Kong;Hong Kong University of Science and Technology, Hong Kong;State Key Lab of CAD&CG, Zhejiang University, Hangzhou, P.R. China",0.1109/tvcg.2013.134;10.1109/tvcg.2016.2598620;10.1109/tvcg.2015.2467951;10.1109/tvcg.2015.2467191;10.1109/tvcg.2014.2359887;10.1109/tvcg.2014.2346292;10.1109/tvcg.2016.2598608;10.1109/tvcg.2014.2352953;10.1109/tvcg.2018.2865152;10.1109/tvcg.2016.2599030;10.1109/tvcg.2016.2598839;10.1109/tvcg.2012.197;10.1109/tvcg.2013.191;10.1109/tvcg.2011.185;10.1109/tvcg.2013.210;10.1109/tvcg.2017.2745941;10.1109/tvcg.2014.2346291;10.1109/tvcg.2007.70541,"Personal visualization,augmented reality,mobile interactions,authoring tool",,33,63,1975,,
TVCG,2019,Correlation Judgment and Visualization Features: A Comparative Study,10.1109/tvcg.2018.2810918,http://dx.doi.org/10.1109/TVCG.2018.2810918,1474,1488,J,"Recent visualization research efforts have incorporated experimental techniques and perceptual models from the vision science community. Perceptual laws such as Weber's law, for example, have been used to model the perception of correlation in scatterplots. While this thread of research has progressively refined the modeling of the perception of correlation in scatterplots, it remains unclear as to why such perception can be modeled using relatively simple functions, e.g., linear and log-linear. In this paper, we investigate a longstanding hypothesis that people use visual features in a chart as a proxy for statistical measures like correlation. For a given scatterplot, we extract 49 candidate visual features and evaluate which best align with existing models and participant judgments. The results support the hypothesis that people attend to a small number of visual features when discriminating correlation in scatterplots. We discuss how this result may account for prior conflicting findings, and how visual features provide a baseline for future model-based approaches in visualization evaluation and design.",Fumeng Yang;Lane T. Harrison;Ronald A. Rensink;Steven L. Franconeri;Remco Chang,Fumeng Yang;Lane T. Harrison;Ronald A. Rensink;Steven L. Franconeri;Remco Chang,"Department of Computer Science, Brown University, Providence, RI;Department of Computer Science, Worcester Polytechnic Institute, Worcester, MA;Departments of Computer Science and Psychology, University of British Columbia, Vancouver, BC, Canada;Psychology Department, Northwestern University, Evanston, IL;Department of Computer Science, Tufts University, Medford, MA",0.1109/tvcg.2014.2346978;10.1109/tvcg.2017.2744359;10.1109/infvis.2005.1532142;10.1109/tvcg.2015.2467671;10.1109/tvcg.2014.2346979,"Information visualization,perception and psychophysics,evaluation/methodology,Weber's law,power law",,32,60,1393,,
TVCG,2018,PhotoRecomposer: Interactive Photo Recomposition by Cropping,10.1109/tvcg.2017.2764895,http://dx.doi.org/10.1109/TVCG.2017.2764895,2728,2742,J,"We present a visual analysis method for interactively recomposing a large number of photos based on example photos with high-quality composition. The recomposition method is formulated as a matching problem between photos. The key to this formulation is a new metric for accurately measuring the composition distance between photos. We have also developed an earth-mover-distance-based online metric learning algorithm to support the interactive adjustment of the composition distance based on user preferences. To better convey the compositions of a large number of example photos, we have developed a multi-level, example photo layout method to balance multiple factors such as compactness, aspect ratio, composition distance, stability, and overlaps. By introducing an EulerSmooth-based straightening method, the composition of each photos is clearly displayed. The effectiveness and usefulness of the method has been demonstrated by the experimental results, user study, and case studies.",Yuan Liang;Xiting Wang;Song-Hai Zhang;Shi-Min Hu 0001;Shixia Liu,Yuan Liang;Xiting Wang;Song-Hai Zhang;Shi-Min Hu;Shixia Liu,"Tsinghua University, Beijing, China;Tsinghua University, Beijing, China;Tsinghua University, Beijing, China;Tsinghua University, Beijing, China;Tsinghua University, Beijing, China",0.1109/infvis.1999.801855;10.1109/tvcg.2011.212;10.1109/tvcg.2015.2489660;10.1109/vast.2006.261425;10.1109/tvcg.2015.2467992;10.1109/infvis.2003.1249019;10.1109/tvcg.2010.136;10.1109/tvcg.2014.2346437,"Photo recomposition,example-based learning,earth mover’s distance,metric learning,photo summarization",,26,62,720,,
TVCG,2021,VIS30K: A Collection of Figures and Tables From IEEE Visualization Conference Publications,10.1109/tvcg.2021.3054916,http://dx.doi.org/10.1109/TVCG.2021.3054916,3826,3833,J,"We present the VIS30K dataset, a collection of 29,689 images that represents 30 years of figures and tables from each track of the IEEE Visualization conference series (Vis, SciVis, InfoVis, VAST). VIS30K's comprehensive coverage of the scientific literature in visualization not only reflects the progress of the field but also enables researchers to study the evolution of the state-of-the-art and to find relevant work based on graphical content. We describe the dataset and our semi-automatic collection process, which couples convolutional neural networks (CNN) with curation. Extracting figures and tables semi-automatically allows us to verify that no images are overlooked or extracted erroneously. To improve quality further, we engaged in a peer-search process for high-quality figures from early IEEE Visualization papers. With the resulting data, we also contribute VISImageNavigator (VIN, visimagenavigator.github.io), a web-based tool that facilitates searching and exploring VIS30K by author names, paper keywords, title and abstract, and years.",Jian Chen 0006;Meng Ling;Rui Li 0067;Petra Isenberg;Tobias Isenberg 0001;Michael Sedlmair;Torsten Möller;Robert S. Laramee;Han-Wei Shen;Katharina Wünsche;Qiru Wang,Jian Chen;Meng Ling;Rui Li;Petra Isenberg;Tobias Isenberg;Michael Sedlmair;Torsten Möller;Robert S. Laramee;Han-Wei Shen;Katharina Wünsche;Qiru Wang,"The Ohio State University, Columbus, OH, USA;The Ohio State University, Columbus, OH, USA;The Ohio State University, Columbus, OH, USA;CNRS, Inria, LISN, Université Paris-Saclay, Saint-Aubin, France;CNRS, Inria, LISN, Université Paris-Saclay, Saint-Aubin, France;University of Stuttgart, Stuttgart, Germany;University of Vienna, Wien, Austria;University of Nottingham, Nottingham, U.K;The Ohio State University, Columbus, OH, USA;University of Vienna, Wien, Austria;University of Nottingham, Nottingham, U.K",0.1109/tvcg.2006.122;10.1109/tvcg.2014.2346324;10.1109/visual.1995.480819;10.1109/tvcg.2007.70568;10.1109/tvcg.2016.2615308;10.1109/tvcg.2016.2598827;10.1109/tvcg.2013.126;10.1109/tvcg.2012.110;10.1109/tvcg.2013.234;10.1109/tvcg.2019.2934540;10.1109/tvcg.2018.2865142;10.1109/tvcg.2009.139;10.1109/tvcg.2011.279;10.1109/tvcg.2010.157,"Visualization,IEEE VIS,InfoVis,SciVis,VAST,dataset,bibliometrics,images,figures,tables",,25,44,1551,,X
TVCG,2020,A Systematic Review of Visualization in Building Information Modeling,10.1109/tvcg.2019.2907583,http://dx.doi.org/10.1109/TVCG.2019.2907583,3109,3127,J,"Building Information Modeling (BIM) employs data-rich 3D CAD models for large-scale facility design, construction, and operation. These complex datasets contain a large amount and variety of information, ranging from design specifications to real-time sensor data. They are used by architects and engineers for various analysis and simulations throughout a facility's life cycle. Many techniques from different visualization fields could be used to analyze these data. However, the BIM domain still remains largely unexplored by the visualization community. The goal of this article is to encourage visualization researchers to increase their involvement with BIM. To this end, we present the results of a systematic review of visualization in current BIM practice. We use a novel taxonomy to identify main application areas and analyze commonly employed techniques. From this domain characterization, we highlight future research opportunities brought forth by the unique features of BIM. For instance, exploring the synergies between scientific and information visualization to integrate spatial and non-spatial data. We hope this article raises awareness to interesting new challenges the BIM domain brings to the visualization community.",Paulo Ivson 0001;André Moreira;Francisco Queiroz;Wallas H. S. dos Santos;Waldemar Celes 0001,Paulo Ivson;André Moreira;Francisco Queiroz;Wallas Santos;Waldemar Celes,"Tecgraf Institute/PUC-Rio, Brazil;Tecgraf Institute/PUC-Rio, Brazil;Tecgraf Institute/PUC-Rio, Brazil;IBM, Armonk, USA;Tecgraf Institute/PUC-Rio, Brazil",0.1109/tvcg.2012.110;10.1109/tvcg.2006.147;10.1109/tvcg.2010.79;10.1109/tvcg.2006.193;10.1109/tvcg.2014.2346454;10.1109/tvcg.2016.2598468;10.1109/tvcg.2015.2467191;10.1109/tvcg.2014.2346574;10.1109/tvcg.2016.2598664;10.1109/tvcg.2009.144;10.1109/tvcg.2013.226;10.1109/tvcg.2012.213;10.1109/tvcg.2007.70539;10.1109/tvcg.2007.70515;10.1109/tvcg.2015.2468011;10.1109/tvcg.2008.149;10.1109/tvcg.2007.70535;10.1109/tvcg.2013.126;10.1109/tvcg.2017.2745105;10.1109/tvcg.2018.2865152;10.1109/tvcg.2016.2549018;10.1109/tvcg.2011.242;10.1109/tvcg.2010.162;10.1109/tvcg.2014.2346320;10.1109/tvcg.2009.152,"Visualization techniques and methodologies,information visualization,computer-aided design,building information modeling,survey",,27,202,1786,,
TVCG,2022,ConfusionFlow: A Model-Agnostic Visualization for Temporal Analysis of Classifier Confusion,10.1109/tvcg.2020.3012063,http://dx.doi.org/10.1109/TVCG.2020.3012063,1222,1236,J,"Classifiers are among the most widely used supervised machine learning algorithms. Many classification models exist, and choosing the right one for a given task is difficult. During model selection and debugging, data scientists need to assess classifiers' performances, evaluate their learning behavior over time, and compare different models. Typically, this analysis is based on single-number performance measures such as accuracy. A more detailed evaluation of classifiers is possible by inspecting class errors. The confusion matrix is an established way for visualizing these class errors, but it was not designed with temporal or comparative analysis in mind. More generally, established performance analysis systems do not allow a combined temporal and comparative analysis of class-level information. To address this issue, we propose ConfusionFlow, an interactive, comparative visualization tool that combines the benefits of class confusion matrices with the visualization of performance characteristics over time. ConfusionFlow is model-agnostic and can be used to compare performances for different model types, model architectures, and/or training and test datasets. We demonstrate the usefulness of ConfusionFlow in a case study on instance selection strategies in active learning. We further assess the scalability of ConfusionFlow and present a use case in the context of neural network pruning.",Andreas P. Hinterreiter;Peter Ruch;Holger Stitz;Martin Ennemoser;Jürgen Bernard;Hendrik Strobelt;Marc Streit,Andreas Hinterreiter;Peter Ruch;Holger Stitz;Martin Ennemoser;Jürgen Bernard;Hendrik Strobelt;Marc Streit,"Johannes Kepler University Linz, Linz, Austria;Imperial College London, London, United Kingdom;Johannes Kepler University Linz, Linz, Austria;Johannes Kepler University Linz, Linz, Austria;Salesbeat GmbH, Leonding, Austria;Datavisyn GmbH, Linz, Austria;Imperial College London, London, United Kingdom",0.1109/tvcg.2016.2598828;10.1109/tvcg.2018.2864504;10.1109/tvcg.2018.2864500;10.1109/tvcg.2014.2346660;10.1109/tvcg.2017.2744683;10.1109/tvcg.2017.2744718;10.1109/tvcg.2017.2744358;10.1109/vast.2011.6102453;10.1109/tvcg.2018.2843369;10.1109/tvcg.2017.2744878;10.1109/vast.2017.8585721;10.1109/tvcg.2018.2864499;10.1109/tvcg.2017.2744818;10.1109/tvcg.2011.185;10.1109/tvcg.2018.2865077,"Classification,performance analysis,time series visualization,machine learning,information visualization,quality assessment",,21,63,947,,
TVCG,2022,ChartSeer: Interactive Steering Exploratory Visual Analysis With Machine Intelligence,10.1109/tvcg.2020.3018724,http://dx.doi.org/10.1109/TVCG.2020.3018724,1500,1513,J,"During exploratory visual analysis (EVA), analysts need to continually determine which subsequent activities to perform, such as which data variables to explore or how to present data variables visually. Due to the vast combinations of data variables and visual encodings that are possible, it is often challenging to make such decisions. Further, while performing local explorations, analysts often fail to attend to the holistic picture that is emerging from their analysis, leading them to improperly steer their EVA. These issues become even more impactful in the real world analysis scenarios where EVA occurs in multiple asynchronous sessions that could be completed by one or more analysts. To address these challenges, this work proposes ChartSeer, a system that uses machine intelligence to enable analysts to visually monitor the current state of an EVA and effectively identify future activities to perform. ChartSeer utilizes deep learning techniques to characterize analyst-created data charts to generate visual summaries and recommend appropriate charts for further exploration based on user interactions. A case study was first conducted to demonstrate the usage of ChartSeer in practice, followed by a controlled study to compare ChartSeer’s performance with a baseline during EVA tasks. The results demonstrated that ChartSeer enables analysts to adequately understand current EVA status and advance their analysis by creating charts with increased coverage and visual encoding diversity.",Jian Zhao 0010;Mingming Fan 0001;Mi Feng,Jian Zhao;Mingming Fan;Mi Feng,"University of Waterloo, Waterloo, ON, Canada;Rochester Institute of Technology, Rochester, NY, USA;Twitter Inc, San Francisco, CA, USA",0.1109/tvcg.2013.188;10.1109/tvcg.2007.70577;10.1109/tvcg.2018.2865240;10.1109/tvcg.2009.162;10.1109/vast.2010.5652880;10.1109/tvcg.2018.2865117;10.1109/tvcg.2016.2598446;10.1109/tvcg.2015.2467851;10.1109/tvcg.2016.2599030;10.1109/tvcg.2016.2598543;10.1109/tvcg.2014.2346573;10.1109/tvcg.2009.122;10.1109/tvcg.2019.2934433;10.1109/tvcg.2014.2346321;10.1109/tvcg.2013.119;10.1109/tvcg.2016.2598466;10.1109/tvcg.2015.2467191;10.1109/tvcg.2017.2745279;10.1109/tvcg.2013.124;10.1109/tvcg.2007.70594,"Exploratory visual analysis,interactive steering,visualization recommendation,machine learning",,24,70,1457,,
TVCG,2020,The Effect of Color Scales on Climate Scientists’ Objective and Subjective Performance in Spatial Data Analysis Tasks,10.1109/tvcg.2018.2876539,http://dx.doi.org/10.1109/TVCG.2018.2876539,1577,1591,J,"Geographical maps encoded with rainbow color scales are widely used by climate scientists. Despite a plethora of evidence from the visualization and vision sciences literature about the shortcomings of the rainbow color scale, they continue to be preferred over perceptually optimal alternatives. To study and analyze this mismatch between theory and practice, we present a web-based user study that compares the effect of color scales on performance accuracy for climate-modeling tasks. In this study, we used pairs of continuous geographical maps generated using climatological metrics for quantifying pairwise magnitude difference and spatial similarity. For each pair of maps, 39 scientist-observers judged: i) the magnitude of their difference, ii) their degree of spatial similarity, and iii) the region of greatest dissimilarity between them. Besides the rainbow color scale, two other continuous color scales were chosen such that all three of them covaried two dimensions (luminance monotonicity and hue banding), hypothesized to have an impact on task performance. We also analyzed subjective performance measures, such as user confidence, perceived accuracy, preference, and familiarity in using the different color scales. We found that monotonic luminance scales produced significantly more accurate judgments of magnitude difference but were not superior in spatial comparison tasks, and that hue banding had differential effects based on the task and conditions. Scientists expressed the highest preference and perceived confidence and accuracy with the rainbow, despite its poor performance on the magnitude comparison tasks. We also report on interesting interactions among stimulus conditions, tasks, and color scales, that lead to open research questions.",Aritra Dasgupta;Jorge Poco;Bernice E. Rogowitz;Kyungsik Han;Enrico Bertini;Cláudio T. Silva,Aritra Dasgupta;Jorge Poco;Bernice Rogowitz;Kyungsik Han;Enrico Bertini;Cláudio T. Silva,"New Jersey Institute of Technology, Newark, USA;Fundação Getulio Vargas, Rio de Janeiro, Brazil;Visual Perspectives Research and Consulting, Ossining, USA;Ajou University, Suwon, South Korea;New York University, New York, USA;New York University, New York, USA",0.1109/tvcg.2016.2598544;10.1109/tvcg.2017.2743978;10.1109/tvcg.2011.192;10.1109/tvcg.2015.2413774;10.1109/visual.1995.480803;10.1109/visual.2002.1183788,"Visualization,color maps,rainbow color map,user study",,22,51,947,,
TVCG,2022,InfoColorizer: Interactive Recommendation of Color Palettes for Infographics,10.1109/tvcg.2021.3085327,http://dx.doi.org/10.1109/TVCG.2021.3085327,4252,4266,J,"When designing infographics, general users usually struggle with getting desired color palettes using existing infographic authoring tools, which sometimes sacrifice customizability, require design expertise, or neglect the influence of elements’ spatial arrangement. We propose a data-driven method that provides flexibility by considering users’ preferences, lowers the expertise barrier via automation, and tailors suggested palettes to the spatial layout of elements. We build a recommendation engine by utilizing deep learning techniques to characterize good color design practices from data, and further develop InfoColorizer, a tool that allows users to obtain color palettes for their infographics in an interactive and dynamic manner. To validate our method, we conducted a comprehensive four-part evaluation, including case studies, a controlled user study, a survey study, and an interview study. The results indicate that InfoColorizer can provide compelling palette recommendations with adequate flexibility, allowing users to effectively obtain high-quality color design for input infographics with low effort.",Linping Yuan;Ziqi Zhou;Jian Zhao 0010;Yiqiu Guo;Fan Du;Huamin Qu,Lin-Ping Yuan;Ziqi Zhou;Jian Zhao;Yiqiu Guo;Fan Du;Huamin Qu,"Hong Kong University of Science and Technology, Hong Kong;University of Waterloo, Waterloo, ON, Canada;University of Waterloo, Waterloo, ON, Canada;Xi'an Jiaotong University, Xi'an, China;Adobe Research, San Jose, CA, USA;Hong Kong University of Science and Technology, Hong Kong",0.1109/tvcg.2012.315;10.1109/tvcg.2020.3030406;10.1109/tvcg.2018.2864912;10.1109/tvcg.2019.2934398;10.1109/tvcg.2016.2598620;10.1109/tvcg.2015.2467191;10.1109/tvcg.2015.2467471;10.1109/tvcg.2020.3030396;10.1109/tvcg.2014.2346277;10.1109/tvcg.2020.3030467;10.1109/tvcg.2017.2744359;10.1109/tvcg.2019.2934284;10.1109/tvcg.2011.185;10.1109/tvcg.2019.2934785;10.1109/tvcg.2016.2598918;10.1109/tvcg.2013.234;10.1109/tvcg.2017.2744198;10.1109/tvcg.2018.2865240,"Color palettes design,infographics,visualization recommendation,machine learning",,26,71,1326,,
TVCG,2021,Interweaving Multimodal Interaction With Flexible Unit Visualizations for Data Exploration,10.1109/tvcg.2020.2978050,http://dx.doi.org/10.1109/TVCG.2020.2978050,3519,3533,J,"Multimodal interfaces that combine direct manipulation and natural language have shown great promise for data visualization. Such multimodal interfaces allow people to stay in the flow of their visual exploration by leveraging the strengths of one modality to complement the weaknesses of others. In this article, we introduce an approach that interweaves multimodal interaction combining direct manipulation and natural language with flexible unit visualizations. We employ the proposed approach in a proof-of-concept system, DataBreeze. Coupling pen, touch, and speech-based multimodal interaction with flexible unit visualizations, DataBreeze allows people to create and interact with both systematically bound (e.g., scatterplots, unit column charts) and manually customized views, enabling a novel visual data exploration experience. We describe our design process along with DataBreeze's interface and interactions, delineating specific aspects of the design that empower the synergistic use of multiple modalities. We also present a preliminary user study with DataBreeze, highlighting the data exploration patterns that participants employed. Finally, reflecting on our design process and preliminary user study, we discuss future research directions.",Arjun Srinivasan;Bongshin Lee;John T. Stasko,Arjun Srinivasan;Bongshin Lee;John Stasko,"Georgia Institute of Technology, Atlanta, GA, USA;Microsoft Research, Redmond, WA, USA;Georgia Institute of Technology, Atlanta, GA, USA",0.1109/tvcg.2012.275;10.1109/tvcg.2014.2346293;10.1109/tvcg.2013.191;10.1109/tvcg.2011.185;10.1109/tvcg.2012.204;10.1109/tvcg.2013.205;10.1109/tvcg.2018.2865151;10.1109/tvcg.2016.2598839;10.1109/tvcg.2017.2785807;10.1109/mcg.2014.82;10.1109/tvcg.2017.2745219;10.1109/tvcg.2011.201;10.1109/tvcg.2018.2865159;10.1109/tvcg.2017.2744684,"Multimodal interaction,natural language interfaces,speech interaction,pen and touch interaction,unit visualizations",,20,81,893,,
TVCG,2020,Feature Level-Sets: Generalizing Iso-Surfaces to Multi-Variate Data,10.1109/tvcg.2018.2867488,http://dx.doi.org/10.1109/TVCG.2018.2867488,1308,1319,J,"Iso-surfaces or level-sets provide an effective and frequently used means for feature visualization. However, they are restricted to simple features for uni-variate data. The approach does not scale when moving to multi-variate data or when considering more complex feature definitions. In this paper, we introduce the concept of traits and feature level-sets, which can be understood as a generalization of level-sets as it includes iso-surfaces, and fiber surfaces as special cases. The concept is applicable to a large class of traits defined as subsets in attribute space, which can be arbitrary combinations of points, lines, surfaces and volumes. It is implemented into a system that provides an interface to define traits in an interactive way and multiple rendering options. We demonstrate the effectiveness of the approach using multi-variate data sets of different nature, including vector and tensor data, from different application domains.",Jochen Jankowai;Ingrid Hotz,Jochen Jankowai;Ingrid Hotz,"Department of Science and Technology, Linköping Institute of Technology, Norrköping, Sweden;Department of Science and Technology, Linköping Institute of Technology, Norrköping, Sweden",0.1109/tvcg.2016.2570215;10.1109/tvcg.2016.2599040;10.1109/tvcg.2008.131;10.1109/tvcg.2008.162,"Multivariate visualization,visualization techniques and methodologies,approximation of surfaces and contours",,16,33,702,,
TVCG,2021,CrimAnalyzer: Understanding Crime Patterns in São Paulo,10.1109/tvcg.2019.2947515,http://dx.doi.org/10.1109/TVCG.2019.2947515,2313,2328,J,"Sao Paulo is the largest city in South America, with crime rates that reflect its size. The number and type of crimes vary considerably around the city, assuming different patterns depending on urban and social characteristics of each particular location. Previous works have mostly focused on the analysis of crimes with the intent of uncovering patterns associated to social factors, seasonality, and urban routine activities. Therefore, those studies and tools are more global in the sense that they are not designed to investigate specific regions of the city such as particular neighborhoods, avenues, or public areas. Tools able to explore specific locations of the city are essential for domain experts to accomplish their analysis in a bottom-up fashion, revealing how urban features related to mobility, passersby behavior, and presence of public infrastructures (e.g., terminals of public transportation and schools) can influence the quantity and type of crimes. In this paper, we present CrimAnalyzer, a visual analytic tool that allows users to study the behavior of crimes in specific regions of a city. The system allows users to identify local hotspots and the pattern of crimes associated to them, while still showing how hotspots and corresponding crime patterns change overtime. CrimAnalyzer has been developed from the needs of a team of experts in criminology and deals with three major challenges: i) flexibility to explore local regions and understand their crime patterns, ii) identification of spatial crime hotspots that might not be the most prevalent ones in terms of the number of crimes but that are important enough to be investigated, and iii) understand the dynamic of crime patterns overtime. The effectiveness and usefulness of the proposed system are demonstrated by qualitative and quantitative comparisons as well as by case studies run by domain experts involving real data. The experiments show the capability of CrimAnalyzer in identifying crime-related phenomena.",Germain Garcia Zanabria;Jaqueline Silveira;Jorge Poco;Afonso Paiva 0001;Marcelo Batista Nery;Cláudio T. Silva;Sergio Adorno;Luis Gustavo Nonato,Germain Garcıa;Jaqueline Silveira;Jorge Poco;Afonso Paiva;Marcelo Batista Nery;Claudio T. Silva;Sérgio Adorno;Luis Gustavo Nonato,"Instituto de Ciências Matemáticas e de Computação, Universidade de São Paulo, São Carlos, Brazil;Instituto de Ciências Matemáticas e de Computação, Universidade de São Paulo, São Carlos, Brazil;Fundação Getúlio Vargas, Brazil;Instituto de Ciências Matemáticas e de Computação, Universidade de São Paulo, São Carlos, Brazil;RIDC -FAPESP and Institute of Advanced Studies – Global Cities Program, Brazil;New York University, New York, NY, USA;Núcleo de Estudos da Violência da USP, São Paulo, Brazil;Instituto de Ciências Matemáticas e de Computação, Universidade de São Paulo, São Carlos, Brazil",0.1109/tvcg.2009.111;10.1109/tvcg.2019.2904063;10.1109/vast.2015.7347624,"Crime data,spatio-temporal data,visual analytics,non-negative matrix factorization",,18,56,1342,,
TVCG,2021,ArchiText: Interactive Hierarchical Topic Modeling,10.1109/tvcg.2020.2981456,http://dx.doi.org/10.1109/TVCG.2020.2981456,3644,3655,J,"Human-in-the-loop topic modeling allows users to explore and steer the process to produce better quality topics that align with their needs. When integrated into visual analytic systems, many existing automated topic modeling algorithms are given interactive parameters to allow users to tune or adjust them. However, this has limitations when the algorithms cannot be easily adapted to changes, and it is difficult to realize interactivity closely supported by underlying algorithms. Instead, we emphasize the concept of tight integration, which advocates for the need to co-develop interactive algorithms and interactive visual analytic systems in parallel to allow flexibility and scalability. In this article, we describe design goals for efficiently and effectively executing the concept of tight integration among computation, visualization, and interaction for hierarchical topic modeling of text data. We propose computational base operations for interactive tasks to achieve the design goals. To instantiate our concept, we present ArchiText, a prototype system for interactive hierarchical topic modeling, which offers fast, flexible, and algorithmically valid analysis via tight integration. Utilizing interactive hierarchical topic modeling, our technique lets users generate, explore, and flexibly steer hierarchical topics to discover more informed topics and their document memberships.",Hannah Kim 0001;Barry L. Drake;Alex Endert;Haesun Park,Hannah Kim;Barry Drake;Alex Endert;Haesun Park,"Georgia Institute of Technology, Atlanta, GA, USA;Georgia Tech Research Institute, Atlanta, GA, USA;Georgia Institute of Technology, Atlanta, GA, USA;Georgia Institute of Technology, Atlanta, GA, USA",0.1109/tvcg.2014.2346578;10.1109/tvcg.2016.2598446;10.1109/visual.1998.745302;10.1109/tvcg.2015.2509990;10.1109/tvcg.2016.2598445;10.1109/tvcg.2015.2467615;10.1109/tvcg.2014.2346433;10.1109/tvcg.2013.162;10.1109/tvcg.2017.2745080;10.1109/tvcg.2018.2864769;10.1109/vast.2011.6102449;10.1109/vast.2012.6400486;10.1109/tvcg.2014.2346431;10.1109/tvcg.2013.212;10.1109/tvcg.2010.154;10.1109/infvis.2000.885091;10.1109/tvcg.2017.2745078;10.1109/tvcg.2008.138,"Text analytics,topic modeling,nonnegative matrix factorization,hierarchical topics,visual analytics",,17,50,1111,,
TVCG,2021,Can Visualization Alleviate Dichotomous Thinking? Effects of Visual Representations on the Cliff Effect,10.1109/tvcg.2021.3073466,http://dx.doi.org/10.1109/TVCG.2021.3073466,3397,3409,J,"Common reporting styles for statistical results in scientific articles, such as p-values and confidence intervals (CI), have been reported to be prone to dichotomous interpretations, especially with respect to the null hypothesis significance testing framework. For example when the p-value is small enough or the CIs of the mean effects of a studied drug and a placebo are not overlapping, scientists tend to claim significant differences while often disregarding the magnitudes and absolute differences in the effect sizes. This type of reasoning has been shown to be potentially harmful to science. Techniques relying on the visual estimation of the strength of evidence have been recommended to reduce such dichotomous interpretations but their effectiveness has also been challenged. We ran two experiments on researchers with expertise in statistical analysis to compare several alternative representations of confidence intervals and used Bayesian multilevel models to estimate the effects of the representation styles on differences in researchers' subjective confidence in the results. We also asked the respondents' opinions and preferences in representation styles. Our results suggest that adding visual information to classic CI representation can decrease the tendency towards dichotomous interpretations - measured as the `cliff effect': the sudden drop in confidence around p-value 0.05 - compared with classic CI visualization and textual representation of the CI with p-values. All data and analyses are publicly available at https://github.com/helske/statvis.",Jouni Helske;Satu Helske;Matthew Cooper 0001;Anders Ynnerman;Lonni Besançon,Jouni Helske;Satu Helske;Matthew Cooper;Anders Ynnerman;Lonni Besançon,"Department of Mathematics and Statistics, University of Jyväskylä, Jyväskylä, Finland;Department of Social Research, University of Turku, Turku, Finland;Department of Science and Technology, Linköping University, Norrköping, Sweden;Department of Science and Technology, Linköping University, Norrköping, Sweden;Department of Science and Technology, Linköping University, Norrköping, Sweden",0.1109/tvcg.2018.2864913;10.1109/tvcg.2018.2864889;10.1109/tvcg.2018.2864909;10.1109/tvcg.2014.2346298,"Statistical inference,visualization,cliff effect,confidence intervals,hypothesis testing,Bayesian inference",,24,78,2099,,X
TVCG,2020,Feature Tracking by Two-Step Optimization,10.1109/tvcg.2018.2883630,http://dx.doi.org/10.1109/TVCG.2018.2883630,2219,2233,J,"Tracking the temporal evolution of features in time-varying data is a key method in visualization. For typical feature definitions, such as vortices, objects are sparsely distributed over the data domain. In this paper, we present a novel approach for tracking both sparse and space-filling features. While the former comprise only a small fraction of the domain, the latter form a set of objects whose union covers the domain entirely while the individual objects are mutually disjunct. Our approach determines the assignment of features between two successive time-steps by solving two graph optimization problems. It first resolves one-to-one assignments of features by computing a maximum-weight, maximum-cardinality matching on a weighted bi-partite graph. Second, our algorithm detects events by creating a graph of potentially conflicting event explanations and finding a weighted, independent set in it. We demonstrate our method's effectiveness on synthetic and simulation data sets, the former of which enables quantitative evaluation because of the availability of ground-truth information. Here, our method performs on par or better than a well-established reference algorithm. In addition, manual visual inspection by our collaborators confirm the results' plausibility for simulation data.",Andrea Schnorr;Dirk N. Helmrich;Dominik Denker;Torsten W. Kuhlen;Bernd Hentschel 0001,Andrea Schnorr;Dirk N. Helmrich;Dominik Denker;Torsten W. Kuhlen;Bernd Hentschel,"JARA – High-Performance Computing and the Visual Computing Institute, RWTH Aachen University, Aachen, Germany;JARA – High-Performance Computing and the Visual Computing Institute, RWTH Aachen University, Aachen, Germany;Institute for Combustion Technology, RWTH Aachen University, Aachen, Germany;JARA – High-Performance Computing and the Visual Computing Institute, RWTH Aachen University, Aachen, Germany;JARA – High-Performance Computing and the Visual Computing Institute, RWTH Aachen University, Aachen, Germany",0.1109/tvcg.2006.186;10.1109/tvcg.2013.131;10.1109/tvcg.2013.117;10.1109/tvcg.2008.110;10.1109/visual.1998.745288;10.1109/visual.2004.107;10.1109/tvcg.2010.93;10.1109/visual.1996.567807;10.1109/tvcg.2014.2346423,"Global optimization,simulation output analysis,flow visualization",,15,40,690,,
TVCG,2020,Visual Genealogy of Deep Neural Networks,10.1109/tvcg.2019.2921323,http://dx.doi.org/10.1109/TVCG.2019.2921323,3340,3352,J,"A comprehensive and comprehensible summary of existing deep neural networks (DNNs) helps practitioners understand the behaviour and evolution of DNNs, offers insights for architecture optimization, and sheds light on the working mechanisms of DNNs. However, this summary is hard to obtain because of the complexity and diversity of DNN architectures. To address this issue, we develop DNN Genealogy, an interactive visualization tool, to offer a visual summary of representative DNNs and their evolutionary relationships. DNN Genealogy enables users to learn DNNs from multiple aspects, including architecture, performance, and evolutionary relationships. Central to this tool is a systematic analysis and visualization of 66 representative DNNs based on our analysis of 140 papers. A directed acyclic graph is used to illustrate the evolutionary relationships among these DNNs and highlight the representative DNNs. A focus + context visualization is developed to orient users during their exploration. A set of network glyphs is used in the graph to facilitate the understanding and comparing of DNNs in the context of the evolution. Case studies demonstrate that DNN Genealogy provides helpful guidance in understanding, applying, and optimizing DNNs. DNN Genealogy is extensible and will continue to be updated to reflect future advances in DNNs.",Qianwen Wang;Jun Yuan 0003;Shuxin Chen;Hang Su 0006;Huamin Qu;Shixia Liu,Qianwen Wang;Jun Yuan;Shuxin Chen;Hang Su;Huamin Qu;Shixia Liu,"Hong Kong University of Science and Technology, Kowloon, Hong Kong;Tsinghua University, Beijing, China;Tsinghua University, Beijing, China;Tsinghua University, Beijing, China;Hong Kong University of Science and Technology, Kowloon, Hong Kong;Tsinghua University, Beijing, China",0.1109/tvcg.2017.2744938;10.1109/tvcg.2009.108;10.1109/tvcg.2017.2744878;10.1109/tvcg.2017.2744718;10.1109/tvcg.2017.2744158;10.1109/tvcg.2016.2598495;10.1109/tvcg.2016.2598831;10.1109/tvcg.2017.2744683;10.1109/tvcg.2011.187;10.1109/tvcg.2016.2598838;10.1109/tvcg.2017.2744358;10.1109/vast.2017.8585721;10.1109/tvcg.2018.2834341,"Interactive visual summary,information visualization,educational tool,deep neural networks",,15,69,1113,,
TVCG,2022,The Unmet Data Visualization Needs of Decision Makers Within Organizations,10.1109/tvcg.2021.3074023,http://dx.doi.org/10.1109/TVCG.2021.3074023,4101,4112,J,"When an organization chooses one course of action over alternatives, this task typically falls on a decision maker with relevant knowledge, experience, and understanding of context. Decision makers rely on data analysis, which is either delegated to analysts, or done on their own. Often the decision maker combines data, likely uncertain or incomplete, with non-formalized knowledge within a multi-objective problem space, weighing the recommendations of analysts within broader contexts and goals. As most past research in visual analytics has focused on understanding the needs and challenges of data analysts, less is known about the tasks and challenges of organizational decision makers, and how visualization support tools might help. Here we characterize the decision maker as a domain expert, review relevant literature in management theories, and report the results of an empirical survey and interviews with people who make organizational decisions. We identify challenges and opportunities for novel visualization tools, including trade-off overviews, scenario-based analysis, interrogation tools, flexible data input and collaboration support. Our findings stress the need to expand visualization design beyond data analysis into tools for information management.",Evanthia Dimara;Harry Zhang;Melanie Tory;Steven Franconeri,Evanthia Dimara;Harry Zhang;Melanie Tory;Steven Franconeri,"Utrecht University, Utrecht, CS, Netherlands;Northwestern University, Evanston, IL, USA;Tableau Software, Palo Alto, CA, USA;Northwestern University, Evanston, IL, USA",0.1109/tvcg.2013.89;10.1109/tvcg.2019.2934283;10.1109/tvcg.2018.2864903;10.1109/tvcg.2016.2598608;10.1109/tvcg.2017.2743990;10.1109/tvcg.2018.2865040;10.1109/tvcg.2018.2859973;10.1109/mcg.2019.2933419;10.1109/tvcg.2012.219;10.1109/tvcg.2010.177;10.1109/tvcg.2018.2864889;10.1109/tvcg.2019.2934286;10.1109/tvcg.2018.2872577;10.1109/tvcg.2013.173;10.1109/tvcg.2016.2598589;10.1109/vast.2011.6102457;10.1109/vast.2015.7347636;10.1109/mcg.2014.62;10.1109/tvcg.2017.2745138,"Decision making,visualization,interview,survey,organizations,management,business intelligence",,18,77,1551,,
TVCG,2020,Exploring the Sensitivity of Choropleths under Attribute Uncertainty,10.1109/tvcg.2019.2892483,http://dx.doi.org/10.1109/TVCG.2019.2892483,2576,2590,J,"The choropleth map is an essential tool for spatial data analysis. However, the underlying attribute values of a spatial unit greatly influence the statistical analyses and map classification procedures when generating a choropleth map. If the attribute values incorporate a range of uncertainty, a critical task is determining how much the uncertainty impacts both the map visualization and the statistical analysis. In this paper, we present a visual analytics system that enhances our understanding of the impact of attribute uncertainty on data visualization and statistical analyses of these data. Our system consists of a parallel coordinates-based uncertainty specification view, an impact river and impact matrix visualization for region-based and simulation-based analysis, and a dual-choropleth map and t-SNE plot for visualizing the changes in classification and spatial autocorrelation over the range of uncertainty in the attribute values. We demonstrate our system through three use cases illustrating the impact of attribute uncertainty in geographic analysis.",Zhaosong Huang;Yafeng Lu;Elizabeth A. Mack;Wei Chen 0001;Ross Maciejewski,Zhaosong Huang;Yafeng Lu;Elizabeth A. Mack;Wei Chen;Ross Maciejewski,"State Key Lab of CAD & CG, Zhejiang University, Hangzhou, China;School of Computing, Informatics & Decision Systems Engineering, Arizona State University, Tempe, USA;Department of Geography, Michigan State University, East Lansing, USA;State Key Lab of CAD & CG, Zhejiang University, Hangzhou;School of Computing, Informatics & Decision Systems Engineering, Arizona State University, Tempe, USA",0.1109/tvcg.2015.2468111;10.1109/tvcg.2017.2745085;10.1109/vast.2009.5332584;10.1109/tvcg.2009.114;10.1109/tvcg.2015.2467752;10.1109/tvcg.2011.197;10.1109/tvcg.2016.2598541;10.1109/vast.2010.5652443;10.1109/tvcg.2007.70523;10.1109/visual.1992.235199,"Geospatial analysis,uncertainty,visualization,choropleth",,15,86,660,,X
TVCG,2022,Interactive Visual Exploration of Longitudinal Historical Career Mobility Data,10.1109/tvcg.2021.3067200,http://dx.doi.org/10.1109/TVCG.2021.3067200,3441,3455,J,"The increased availability of quantitative historical datasets has provided new research opportunities for multiple disciplines in social science. In this article, we work closely with the constructors of a new dataset, CGED-Q (China Government Employee Database-Qing), that records the career trajectories of over 340,000 government officials in the Qing bureaucracy in China from 1760 to 1912. We use these data to study career mobility from a historical perspective and understand social mobility and inequality. However, existing statistical approaches are inadequate for analyzing career mobility in this historical dataset with its fine-grained attributes and long time span, since they are mostly hypothesis-driven and require substantial effort. We propose CareerLens, an interactive visual analytics system for assisting experts in exploring, understanding, and reasoning from historical career data. With CareerLens, experts examine mobility patterns in three levels-of-detail, namely, the macro-level providing a summary of overall mobility, the meso-level extracting latent group mobility patterns, and the micro-level revealing social relationships of individuals. We demonstrate the effectiveness and usability of CareerLens through two case studies and receive encouraging feedback from follow-up interviews with domain experts.",Yifang Wang 0001;Hongye Liang;Xinhuan Shu;Jiachen Wang;Ke Xu;Zikun Deng;Cameron Campbell;Bijia Chen;Yingcai Wu;Huamin Qu,Yifang Wang;Hongye Liang;Xinhuan Shu;Jiachen Wang;Ke Xu;Zikun Deng;Cameron Campbell;Bijia Chen;Yingcai Wu;Huamin Qu,"State Key Lab of CAD&CG, Zhejiang University, Hangzhou, China;State Key Lab of CAD&CG, Zhejiang University, Hangzhou, China;Hong Kong University of Science and Technology, Hong Kong;State Key Lab of CAD&CG, Zhejiang University, Hangzhou, China;New York University, New York, NY, USA;State Key Lab of CAD&CG, Zhejiang University, Hangzhou, China;Hong Kong University of Science and Technology, Hong Kong;Renmin University of China, Beijing, China;State Key Lab of CAD&CG, Zhejiang University, Hangzhou, China;Hong Kong University of Science and Technology, Hong Kong",0.1109/tvcg.2018.2865041;10.1109/tvcg.2014.2346682;10.1109/tvcg.2011.179;10.1109/tvcg.2012.225;10.1109/tvcg.2015.2467620;10.1109/vast.2016.7883512;10.1109/tvcg.2018.2864885;10.1109/tvcg.2017.2745320;10.1109/tvcg.2017.2745083;10.1109/vast50239.2020.00009;10.1109/tvcg.2019.2934630;10.1109/tvcg.2017.2744218;10.1109/tvcg.2011.185,"Digital humanities,quantitative history,career mobility,visual analytics",,14,52,2131,,
TVCG,2019,A Scalable Hybrid Scheme for Ray-Casting of Unstructured Volume Data,10.1109/tvcg.2018.2833113,http://dx.doi.org/10.1109/TVCG.2018.2833113,2349,2361,J,"We present an algorithm for parallel volume rendering that is a hybrid between classical object order and image order techniques. The algorithm operates on unstructured grids (and structured ones), and thus can deal with block boundaries interleaving in complex ways. It also deals effectively with cases that are prone to load imbalance, i.e., cases where cell sizes differ dramatically, either because of the nature of the input data, or because of the effects of the camera transformation. The algorithm divides work over resources such that each phase of its processing is bounded in the amount of computation it can perform. We demonstrate its efficacy through a series of studies, varying over camera position, data set size, transfer function, image size, and processor count. At its biggest, our experiments scaled up to 8,192 processors and operated on data sets with more than one billion cells. In total, we find that our hybrid algorithm performs well in all cases. This is because our algorithm naturally adapts its computation based on workload, and can operate like either an object order technique or an image order technique in scenarios where those techniques are efficient.",Roba Binyahib;Tom Peterka;Matthew Larsen;Kwan-Liu Ma;Hank Childs,Roba Binyahib;Tom Peterka;Matthew Larsen;Kwan-Liu Ma;Hank Childs,"University of Oregon, Eugene, OR;Argonne National Laboratory, Lemont, IL;Lawrence Livermore National Laboratory, Livermore, CA;University of California at Davis, Davis, CA;University of Oregon, Eugene, OR",0.1109/visual.2002.1183757;10.1109/mcg.2016.48,"Volume rendering,parallel visualization,large scale visualization",,14,27,561,,
TVCG,2022,"Rainbow Dash: Intuitiveness, Interpretability and Memorability of the Rainbow Color Scheme in Visualization",10.1109/tvcg.2020.3035823,http://dx.doi.org/10.1109/TVCG.2020.3035823,2722,2733,J,"After demonstrating that rainbow colors are still commonly used in scientific publications, we comparatively evaluate the rainbow and sequential color schemes on choropleth and isarithmic maps in an empirical user study with 544 participants to examine if a) people intuitively associate order for the colors in these schemes, b) they can successfully conduct perceptual and semantic map reading and recall tasks with quantitative data where order may have implicit or explicit importance. We find that there is little to no agreement in ordering of rainbow colors while sequential colors are indeed intuitively ordered by the participants with a strong dark is more bias. Sequential colors facilitate most quantitative map reading tasks better than the rainbow colors, whereas rainbow colors competitively facilitate extracting specific values from a map, and may support hue recall better than sequential. We thus contribute to dark- versus light is more bias debate, demonstrate why and when rainbow colors may impair performance, and add further nuance to our understanding of this highly popular, yet highly criticized color scheme.",Izabela Malgorzata Golebiowska;Arzu Çöltekin,Izabela M. Gołbiowska;Arzu Çöltekin,"Faculty of Geography and Regional Studies, University of Warsaw, Warszawa, Poland;Institute of Interactive Technologies, University of Applied Sciences and Arts Northwestern Switzerland, Brugg-Windisch, Switzerland",0.1109/tvcg.2018.2865147;10.1109/visual.2001.964510;10.1109/tvcg.2011.192;10.1109/tvcg.2016.2598918;10.1109/tvcg.2017.2744359;10.1109/tvcg.2017.2743978;10.1109/tvcg.2018.2855742,"Color,visualization,colormap,color perception,visual design",,15,57,1391,,
TVCG,2020,WeSeer: Visual Analysis for Better Information Cascade Prediction of WeChat Articles,10.1109/tvcg.2018.2867776,http://dx.doi.org/10.1109/TVCG.2018.2867776,1399,1412,J,"Social media, such as Facebook and WeChat, empowers millions of users to create, consume, and disseminate online information on an unprecedented scale. The abundant information on social media intensifies the competition of WeChat Public Official Articles (i.e., posts) for gaining user attention due to the zero-sum nature of attention. Therefore, only a small portion of information tends to become extremely popular while the rest remains unnoticed or quickly disappears. Such a typical “long-tail” phenomenon is very common in social media. Thus, recent years have witnessed a growing interest in predicting the future trend in the popularity of social media posts and understanding the factors that influence the popularity of the posts. Nevertheless, existing predictive models either rely on cumbersome feature engineering or sophisticated parameter tuning, which are difficult to understand and improve. In this paper, we study and enhance a point process-based model by incorporating visual reasoning to support communication between the users and the predictive model for a better prediction result. The proposed system supports users to uncover the working mechanism behind the model and improve the prediction accuracy accordingly based on the insights gained. We use realistic WeChat articles to demonstrate the effectiveness of the system and verify the improved model on a large scale of WeChat articles. We also elicit and summarize the feedback from WeChat domain experts.",Quan Li;Ziming Wu;Lingling Yi;Kristanto Sean N;Huamin Qu;Xiaojuan Ma,Quan Li;Ziming Wu;Lingling Yi;Kristanto Sean N.;Huamin Qu;Xiaojuan Ma,"Hong Kong University of Science and Technology, Hong Kong;Hong Kong University of Science and Technology, Hong Kong;WeChat, Tencent, Shenzhen, China;Hong Kong University of Science and Technology, Hong Kong, China;Hong Kong University of Science and Technology, Hong Kong;Hong Kong University of Science and Technology, Hong Kong",0.1109/tvcg.2014.2346578;10.1109/tvcg.2014.2346922;10.1109/tvcg.2015.2467991;10.1109/vast.2016.7883510;10.1109/tvcg.2014.2346920;10.1109/tvcg.2010.82;10.1109/tvcg.2012.291;10.1109/tvcg.2013.125;10.1109/tvcg.2013.186;10.1109/tvcg.2014.2346926,"Visual reasoning,propagation prediction,model understanding,information propagation visualization",,13,49,1061,,
TVCG,2022,Nebula: A Coordinating Grammar of Graphics,10.1109/tvcg.2021.3076222,http://dx.doi.org/10.1109/TVCG.2021.3076222,4127,4140,J,"In multiple coordinated views (MCVs), visualizations across views update their content in response to users’ interactions in other views. Interactive systems provide direct manipulation to create coordination between views, but are restricted to limited types of predefined templates. By contrast, textual specification languages enable flexible coordination but expose technical burden. To bridge the gap, we contribute Nebula, a grammar based on natural language for coordinating visualizations in MCVs. The grammar design is informed by a novel framework based on a systematic review of 176 coordinations from existing theories and applications, which describes coordination by demonstration, i.e., how coordination is performed by users. With the framework, Nebula specification formalizes coordination as a composition of user- and coordination-triggered interactions in origin and destination views, respectively, along with potential data transformation between the interactions. We evaluate Nebula by demonstrating its expressiveness with a gallery of diverse examples and analyzing its usability on cognitive dimensions.",Ran Chen;Xinhuan Shu;Jiahui Chen;Di Weng;Junxiu Tang;Siwei Fu;Yingcai Wu,Ran Chen;Xinhuan Shu;Jiahui Chen;Di Weng;Junxiu Tang;Siwei Fu;Yingcai Wu,"State Key Lab of CAD&CG, Zhejiang University, Hangzhou, China;Hong Kong University of Science and Technology, Hong Kong;State Key Lab of CAD&CG, Zhejiang University, Hangzhou, China;State Key Lab of CAD&CG, Zhejiang University, Hangzhou, China;State Key Lab of CAD&CG, Zhejiang University, Hangzhou, China;Zhejiang Lab, Hangzhou, China;State Key Lab of CAD&CG, Zhejiang University, Hangzhou, China",0.1109/tvcg.2016.2598479;10.1109/tvcg.2018.2865139;10.1109/tvcg.2007.70515;10.1109/tvcg.2020.3030360;10.1109/tvcg.2017.2745078;10.1109/tvcg.2016.2598432;10.1109/tvcg.2013.173;10.1109/tvcg.2018.2865126;10.1109/tvcg.2017.2744198;10.1109/infvis.2002.1173142;10.1109/tvcg.2017.2743859;10.1109/tvcg.2016.2599030;10.1109/tvcg.2009.174;10.1109/tvcg.2015.2467091;10.1109/infvis.2004.12;10.1109/tvcg.2011.185;10.1109/tvcg.2020.3030367;10.1109/tvcg.2019.2934668;10.1109/tvcg.2016.2598497,"Coordination,multiple coordinated views,interactive visualization,grammar of graphics",,11,40,917,,
TVCG,2021,A Virtual Reality Memory Palace Variant Aids Knowledge Retrieval from Scholarly Articles,10.1109/tvcg.2020.3009003,http://dx.doi.org/10.1109/TVCG.2020.3009003,4359,4373,J,"We present exploratory research of virtual reality techniques and mnemonic devices to assist in retrieving knowledge from scholarly articles. We used abstracts of scientific publications to represent knowledge in scholarly articles; participants were asked to read, remember, and retrieve knowledge from a set of abstracts. We conducted an experiment to compare participants’ recall and recognition performance in three different conditions: a control condition without a pre-specified strategy to test baseline individual memory ability, a condition using an image-based variant of a mnemonic called a “memory palace,” and a condition using a virtual reality-based variant of a memory palace. Our analyses show that using a virtual reality-based memory palace variant greatly increased the amount of knowledge retrieved and retained over the baseline, and it shows a moderate improvement over the other image-based memory palace variant. Anecdotal feedback from participants suggested that personalizing a memory palace variant would be appreciated. Our results support the value of virtual reality for some high-level cognitive tasks and help improve future applications of virtual reality and visualization.",Fumeng Yang;Jing Qian;Johannes Novotny;David Badre;Cullen D. Jackson;David H. Laidlaw,Fumeng Yang;Jing Qian;Johannes Novotny;David Badre;Cullen D. Jackson;David H. Laidlaw,"Department of Computer Science, Brown University, Providence, RI, USA;Department of Computer Science, Brown University, Providence, RI, USA;Department of Computer Science, Brown University, Providence, RI, USA;Department of Cognitive, Linguistic & Psychological Sciences, Brown University, Providence, RI, USA;Beth Israel Deaconess Medical Center, Harvard University, Boston, MA, USA;Department of Computer Science, Brown University, Providence, RI, USA",0.1109/tvcg.2013.205;10.1109/tvcg.2009.127;10.1109/tvcg.2007.70596;10.1109/tvcg.2016.2520921;10.1109/tvcg.2019.2934803;10.1109/tvcg.2018.2865192;10.1109/tvcg.2013.234,"Virtual reality,mnemonic devices,natural language documents,human memory,spatialization,spatial memory",,12,98,1243,,
TVCG,2019,The Effect of Edge Bundling and Seriation on Sensemaking of Biclusters in Bipartite Graphs,10.1109/tvcg.2018.2861397,http://dx.doi.org/10.1109/TVCG.2018.2861397,2983,2998,J,"Exploring coordinated relationships (e.g., shared relationships between two sets of entities) is an important analytics task in a variety of real-world applications, such as discovering similarly behaved genes in bioinformatics, detecting malware collusions in cyber security, and identifying products bundles in marketing analysis. Coordinated relationships can be formalized as biclusters. In order to support visual exploration of biclusters, bipartite graphs based visualizations have been proposed, and edge bundling is used to show biclusters. However, it suffers from edge crossings due to possible overlaps of biclusters, and lacks in-depth understanding of its impact on user exploring biclusters in bipartite graphs. To address these, we propose a novel bicluster-based seriation technique that can reduce edge crossings in bipartite graphs drawing and conducted a user experiment to study the effect of edge bundling and this proposed technique on visualizing biclusters in bipartite graphs. We found that they both had impact on reducing entity visits for users exploring biclusters, and edge bundles helped them find more justified answers. Moreover, we identified four key trade-offs that inform the design of future bicluster visualizations. The study results suggest that edge bundling is critical for exploring biclusters in bipartite graphs, which helps to reduce low-level perceptual problems and support high-level inferences.",Maoyuan Sun;Jian Zhao 0010;Hao Wu 0041;Kurt Luther;Chris North 0001;Naren Ramakrishnan,Maoyuan Sun;Jian Zhao;Hao Wu;Kurt Luther;Chris North;Naren Ramakrishnan,"Department of Computer and Information Science, University of Massachusetts Dartmouth, North Dartmouth, MA, USA;FX Palo Alto Laboratory, Palo Alto, CA, USA;Google, Mountain View, CA, USA;Computer Science Department, Virginia Tech, Blacksburg, VA, USA;Computer Science Department, Virginia Tech, Blacksburg, VA, USA;Computer Science Department, Virginia Tech, Blacksburg, VA, USA",0.1109/tvcg.2006.147;10.1109/tvcg.2015.2467552;10.1109/tvcg.2014.2346279;10.1109/tvcg.2008.135;10.1109/tvcg.2015.2467813;10.1109/tvcg.2016.2598958;10.1109/tvcg.2017.2744458;10.1109/tvcg.2014.2346665,"Bicluster,edge bundling,seriation,visual analytics",,11,46,604,,
TVCG,2021,Why Visualize? Untangling a Large Network of Arguments,10.1109/tvcg.2019.2940026,http://dx.doi.org/10.1109/TVCG.2019.2940026,2220,2236,J,"Visualization has been deemed a useful technique by researchers and practitioners, alike, leaving a trail of arguments behind that reason why visualization works. In addition, examples of misleading usages of visualizations in information communication have occasionally been pointed out. Thus, to contribute to the fundamental understanding of our discipline, we require a comprehensive collection of arguments on “why visualize?” (or “why not?”), untangling the rationale behind positive and negative viewpoints. In this paper, we report a theoretical study to understand the underlying reasons of various arguments; their relationships (e.g., built-on, and conflict); and their respective dependencies on tasks, users, and data. We curated an argumentative network based on a collection of arguments from various fields, including information visualization, cognitive science, psychology, statistics, philosophy, and others. Our work proposes several categorizations for the arguments, and makes their relations explicit. We contribute the first comprehensive and systematic theoretical study of the arguments on visualization. Thereby, we provide a roadmap towards building a foundation for visualization theory and empirical research as well as for practical application in the critique and design of visualizations. In addition, we provide our argumentation network and argument collection online at https://whyvis.dbvis.de, supported by an interactive visualization.",Dirk Streeb;Mennatallah El-Assady;Daniel A. Keim;Min Chen 0001,Dirk Streeb;Mennatallah El-Assady;Daniel A. Keim;Min Chen,"Group of Data Analysis and Visualization, University of Konstanz, Konstanz, Germany;Group of Data Analysis and Visualization, University of Konstanz, Konstanz, Germany;Group of Data Analysis and Visualization, University of Konstanz, Konstanz, Germany;Department of Engineering Science, University of Oxford, Oxford, United Kingdom",0.1109/tvcg.2008.121;10.1109/tvcg.2014.2346325;10.1109/tvcg.2012.199;10.1109/tvcg.2007.70515;10.1109/tvcg.2011.251;10.1109/tvcg.2010.132;10.1109/tvcg.2014.2346481;10.1109/tvcg.2016.2598829;10.1109/vast.2015.7347625,"Visualization,theory,argument network,cognition,design",,9,85,959,,
TVCG,2022,Visual Cascade Analytics of Large-Scale Spatiotemporal Data,10.1109/tvcg.2021.3071387,http://dx.doi.org/10.1109/TVCG.2021.3071387,2486,2499,J,"Many spatiotemporal events can be viewed as contagions. These events implicitly propagate across space and time by following cascading patterns, expanding their influence, and generating event cascades that involve multiple locations. Analyzing such cascading processes presents valuable implications in various urban applications, such as traffic planning and pollution diagnostics. Motivated by the limited capability of the existing approaches in mining and interpreting cascading patterns, we propose a visual analytics system called VisCas. VisCas combines an inference model with interactive visualizations and empowers analysts to infer and interpret the latent cascading patterns in the spatiotemporal context. To develop VisCas, we address three major challenges 1) generalized pattern inference; 2) implicit influence visualization; and 3) multifaceted cascade analysis. For the first challenge, we adapt the state-of-the-art cascading network inference technique to general urban scenarios, where cascading patterns can be reliably inferred from large-scale spatiotemporal data. For the second and third challenges, we assemble a set of effective visualizations to support location navigation, influence inspection, and cascading exploration, and facilitate the in-depth cascade analysis. We design a novel influence view based on a three-fold optimization strategy for analyzing the implicit influences of the inferred patterns. We demonstrate the capability and effectiveness of VisCas with two case studies conducted on real-world traffic congestion and air pollution datasets with domain experts.",Zikun Deng;Di Weng;Yuxuan Liang;Jie Bao 0003;Yu Zheng 0004;Tobias Schreck;Mingliang Xu;Yingcai Wu,Zikun Deng;Di Weng;Yuxuan Liang;Jie Bao;Yu Zheng;Tobias Schreck;Mingliang Xu;Yingcai Wu,"State Key Lab of CAD&CG, Zhejiang University, Hangzhou, China;State Key Lab of CAD&CG, Zhejiang University, Hangzhou, China;School of Computing, National University of Singapore, Singapore;JD Intelligent Cities Research, JD Technology, Beijing, China;JD Intelligent Cities Research, JD Technology, Beijing, China;Graz University of Technology, Graz, Austria;School of Information Engineering and Henan Institute of Advanced Technology, Zhengzhou University, Zhengzhou, China;State Key Lab of CAD&CG, Zhejiang University, Hangzhou, China",0.1109/tvcg.2020.3030428;10.1109/tvcg.2009.111;10.1109/vast.2011.6102455;10.1109/tvcg.2018.2865018;10.1109/tvcg.2016.2598432;10.1109/vast.2012.6400491;10.1109/tvcg.2020.3030458;10.1109/vast50239.2020.00009;10.1109/tvcg.2018.2865041;10.1109/tvcg.2020.3030359;10.1109/tvcg.2014.2346893;10.1109/tvcg.2018.2864811;10.1109/vast.2014.7042488;10.1109/tvcg.2009.200;10.1109/tvcg.2019.2922597;10.1109/tvcg.2018.2851227;10.1109/tvcg.2017.2744159;10.1109/tvcg.2018.2865126;10.1109/tvcg.2013.228;10.1109/tvcg.2018.2864844;10.1109/tvcg.2015.2468111;10.1109/tvcg.2016.2535234;10.1109/tvcg.2014.2346449;10.1109/tvcg.2013.226;10.1109/infvis.2004.1;10.1109/tvcg.2013.145;10.1109/tvcg.2018.2864885;10.1109/vast.2012.6400557;10.1109/tvcg.2015.2467619;10.1109/tvcg.2018.2889054;10.1109/tvcg.2019.2940580;10.1109/tvcg.2007.70523;10.1109/tvcg.2015.2467592,"Spatial cascade,pattern mining,spatiotemporal data",,10,75,1177,,X
TVCG,2022,embComp: Visual Interactive Comparison of Vector Embeddings,10.1109/tvcg.2020.3045918,http://dx.doi.org/10.1109/TVCG.2020.3045918,2953,2969,J,"This article introduces embComp, a novel approach for comparing two embeddings that capture the similarity between objects, such as word and document embeddings. We survey scenarios where comparing these embedding spaces is useful. From those scenarios, we derive common tasks, introduce visual analysis methods that support these tasks, and combine them into a comprehensive system. One of embComp’s central features are overview visualizations that are based on metrics for measuring differences in the local structure around objects. Summarizing these local metrics over the embeddings provides global overviews of similarities and differences. Detail views allow comparison of the local structure around selected objects and relating this local information to the global views. Integrating and connecting all of these components, embComp supports a range of analysis workflows that help understand similarities and differences between embedding spaces. We assess our approach by applying it in several use cases, including understanding corpora differences via word vector embeddings, and understanding algorithmic differences in generating embeddings.",Florian Heimerl;Christoph Kralj;Torsten Möller;Michael Gleicher,Florian Heimerl;Christoph Kralj;Torsten Möller;Michael Gleicher,"Department of Computer Science, University of Wisconsin-Madison (UW-Madison), Madison, WI, USA;Faculty of Computer Sciences and Data Science, Uni Vienna Sensengasse 6, University of Vienna, Wien, Austria;Faculty of Computer Sciences and Data Science, Uni Vienna Sensengasse 6, University of Vienna, Wien, Austria;Department of Computer Science, University of Wisconsin-Madison (UW-Madison), Madison, WI, USA",0.1109/vast.2018.8802454;10.1109/tvcg.2017.2745085;10.1109/tvcg.2017.2745141;10.1109/tvcg.2015.2467618;10.1109/vast.2016.7883507;10.1109/vast.2010.5652392;10.1109/tvcg.2016.2615308;10.1109/tvcg.2009.108;10.1109/tvcg.2015.2467717;10.1109/tvcg.2017.2744199;10.1109/tvcg.2016.2598667;10.1109/vast.2012.6400486;10.1109/tvcg.2017.2745158;10.1109/tvcg.2017.2744478,"Visual analytics,visual comparison,machine learning,vector embeddings",,11,63,651,,
TVCG,2020,Aggregated Dendrograms for Visual Comparison between Many Phylogenetic Trees,10.1109/tvcg.2019.2898186,http://dx.doi.org/10.1109/TVCG.2019.2898186,2732,2747,J,"We address the visual comparison of multiple phylogenetic trees that arises in evolutionary biology, specifically between one reference tree and a collection of dozens to hundreds of other trees. We abstract the domain questions of phylogenetic tree comparison as tasks to look for supporting or conflicting evidence for hypotheses that requires inspection of both topological structure and attribute values at different levels of detail in the tree collection. We introduce the new visual encoding idiom of aggregated dendrograms to concisely summarize the topological relationships between interactively chosen focal subtrees according to biologically meaningful criteria, and provide a layout algorithm that automatically adapts to the available screen space. We design and implement the ADView system, which represents trees at multiple levels of detail across multiple views: the entire collection, a subset of trees, an individual tree, specific subtrees of interest, and the individual branch level. We benchmark the algorithms developed for ADView, compare its information density to previous work, and demonstrate its utility for quickly gathering evidence about biological hypotheses through usage scenarios with data from recently published phylogenetic analysis and case studies of expert use with real-world data, drawn from a summative interview study.",Zipeng Liu;Shing Hei Zhan;Tamara Munzner,Zipeng Liu;Shing Hei Zhan;Tamara Munzner,"Computer Science, University of British Columbia, Vancouver, Canada;Zoology, University of British Columbia, Vancouver, Canada;Computer Science, University of British Columbia, Vancouver, Canada",0.1109/tvcg.2013.231;10.1109/tvcg.2015.2467733;10.1109/tvcg.2015.2468078;10.1109/tvcg.2015.2507595;10.1109/tvcg.2012.226;10.1109/vast.2011.6102439;10.1109/tvcg.2017.2744199;10.1109/tvcg.2017.2744198,"Tree comparison,phylogenetic trees,level of detail",,11,49,761,,
TVCG,2021,Task-Based Effectiveness of Interactive Contiguous Area Cartograms,10.1109/tvcg.2020.3041745,http://dx.doi.org/10.1109/TVCG.2020.3041745,2136,2152,J,"Cartograms are map-based data visualizations in which the area of each map region is proportional to an associated numeric data value (e.g., population or gross domestic product). A cartogram is called contiguous if it conforms to this area principle while also keeping neighboring regions connected. Because of their distorted appearance, contiguous cartograms have been criticized as difficult to read. Some authors have suggested that cartograms may be more legible if they are accompanied by interactive features (e.g., animations, linked brushing, or infotips). We conducted an experiment to evaluate this claim. Participants had to perform visual analysis tasks with interactive and noninteractive contiguous cartograms. The task types covered various aspects of cartogram readability, ranging from elementary lookup tasks to synoptic tasks (i.e., tasks in which participants had to summarize high-level differences between two cartograms). Elementary tasks were carried out equally well with and without interactivity. Synoptic tasks, by contrast, were more difficult without interactive features. With access to interactivity, however, most participants answered even synoptic questions correctly. In a subsequent survey, participants rated the interactive features as “easy to use” and “helpful.” Our study suggests that interactivity has the potential to make contiguous cartograms accessible even for those readers who are unfamiliar with interactive computer graphics or do not have a prior affinity to working with maps. Among the interactive features, animations had the strongest positive effect, so we recommend them as a minimum of interactivity when contiguous cartograms are displayed on a computer screen.",Ian K. Duncan;Shi Tingsheng;Simon T. Perrault;Michael T. Gastner,Ian K. Duncan;Shi Tingsheng;Simon T. Perrault;Michael T. Gastner,"Yale-NUS College, Singapore, Singapore;Yale-NUS College, Singapore, Singapore;Singapore University of Technology and Design, Singapore, Singapore;Yale-NUS College, Singapore, Singapore",0.1109/tvcg.2016.2599030;10.1109/tvcg.2018.2796557;10.1109/tvcg.2011.185;10.1109/tvcg.2016.2642109;10.1109/tvcg.2013.130;10.1109/tvcg.2016.2598862,"Cartogram,geovisualization,interactive data exploration,quantitative evaluation",,10,100,1255,,X
TVCG,2021,Visual Analysis of Class Separations With Locally Linear Segments,10.1109/tvcg.2020.3011155,http://dx.doi.org/10.1109/TVCG.2020.3011155,241,253,J,"High-dimensional labeled data widely exists in many real-world applications such as classification and clustering. One main task in analyzing such datasets is to explore class separations and class boundaries derived from machine learning models. Dimension reduction techniques are commonly applied to support analysts in exploring the underlying decision boundary structures by depicting a low-dimensional representation of the data distributions from multiple classes. However, such projection-based analyses are limited due to their lack of ability to show separations in complex non-linear decision boundary structures and can suffer from heavy distortion and low interpretability. To overcome these issues of separability and interpretability, we propose a visual analysis approach that utilizes the power of explainability from linear projections to support analysts when exploring non-linear separation structures. Our approach is to extract a set of locally linear segments that approximate the original non-linear separations. Unlike traditional projection-based analysis where the data instances are mapped to a single scatterplot, our approach supports the exploration of complex class separations through multiple local projection results. We conduct case studies on two labeled datasets to demonstrate the effectiveness of our approach.",Yuxin Ma;Ross Maciejewski,Yuxin Ma;Ross Maciejewski,"School of Computing, Informatics & Decision Systems Engineering, Arizona State University, Tempe, AZ, USA;School of Computing, Informatics & Decision Systems Engineering, Arizona State University, Tempe, AZ, USA",0.1109/tvcg.2017.2672987;10.1109/tvcg.2012.65;10.1109/tvcg.2017.2745258;10.1109/tvcg.2013.65;10.1109/tvcg.2014.2346594;10.1109/tvcg.2013.101;10.1109/tvcg.2014.2346482;10.1109/tvcg.2016.2598495;10.1109/tvcg.2008.153;10.1109/tvcg.2013.182;10.1109/tvcg.2011.220;10.1109/tvcg.2013.173;10.1109/tvcg.2017.2701829;10.1109/infvis.2003.1249017;10.1109/tvcg.2017.2744098;10.1109/tvcg.2018.2846735,"Visual analysis,dimension reduction,class separation",,10,62,932,,X
TVCG,2022,Declutter and Focus: Empirically Evaluating Design Guidelines for Effective Data Communication,10.1109/tvcg.2021.3068337,http://dx.doi.org/10.1109/TVCG.2021.3068337,3351,3364,J,"Data visualization design has a powerful effect on which patterns we see as salient and how quickly we see them. The visualization practitioner community prescribes two popular guidelines for creating clear and efficient visualizations: declutter and focus. The declutter guidelines suggest removing non-critical gridlines, excessive labeling of data values, and color variability to improve aesthetics and to maximize the emphasis on the data relative to the design itself. The focus guidelines for explanatory communication recommend including a clear headline that describes the relevant data pattern, highlighting a subset of relevant data values with a unique color, and connecting those values to written annotations that contextualize them in a broader argument. We evaluated how these recommendations impact recall of the depicted information across cluttered, decluttered, and decluttered+focused designs of six graph topics. Undergraduate students were asked to redraw previously seen visualizations, to recall their topics and main conclusions, and to rate the varied designs on aesthetics, clarity, professionalism, and trustworthiness. Decluttering designs led to higher ratings on professionalism, and adding focus to the design led to higher ratings on aesthetics and clarity. They also showed better memory for the highlighted pattern in the data, as reflected across redrawings of the original visualization and typed free-response conclusions, though we do not know whether these results would generalize beyond our memory-based tasks. The results largely empirically validate the intuitions of visualization designers and practitioners. The stimuli, data, analysis code, and Supplementary Materials are available at https://osf.io/wes9u/.",Kiran Ajani;Elsie Lee;Cindy Xiong;Cole Nussbaumer Knaflic;William Kemper;Steven Franconeri,Kiran Ajani;Elsie Lee;Cindy Xiong;Cole Nussbaumer Knaflic;William Kemper;Steven Franconeri,"School of Medicine, Case Western Reserve University, Cleveland, OH, USA;School of Information, University of Michigan, Ann Arbor, MI, USA;CICS, UMass Amherst, Amherst, MA, USA;Storytelling with Data, Milwaukee, WI, USA;Northwestern University, Evanston, IL, USA;Northwestern University, Evanston, IL, USA",0.1109/tvcg.2019.2917689;10.1109/tvcg.2010.179;10.1109/tvcg.2011.255;10.1109/tvcg.2019.2934801;10.1109/tvcg.2011.242;10.1109/tvcg.2013.234;10.1109/tvcg.2015.2467732,"Data visualization,data communication,data storytelling,empirical evaluation,visualization aesthetics",,11,74,1557,,X
TVCG,2021,Visualizing Hierarchical Performance Profiles of Parallel Codes Using CallFlow,10.1109/tvcg.2019.2953746,http://dx.doi.org/10.1109/TVCG.2019.2953746,2455,2468,J,"Calling context trees (CCTs) couple performance metrics with call paths, helping understand the execution and performance of parallel programs. To identify performance bottlenecks, programmers and performance analysts visually explore CCTs to form and validate hypotheses regarding degraded performance. However, due to the complexity of parallel programs, existing visual representations do not scale to applications running on a large number of processors. We present CallFlow, an interactive visual analysis tool that provides a high-level overview of CCTs together with semantic refinement operations to progressively explore CCTs. Using a flow-based metaphor, we visualize a CCT by treating execution time as a resource spent during the call chain, and demonstrate the effectiveness of our design with case studies on large-scale, production simulation codes.",Huu Tan Nguyen;Abhinav Bhatele;Nikhil Jain;Suraj P. Kesavan;Harsh Bhatia;Todd Gamblin;Kwan-Liu Ma;Peer-Timo Bremer,Huu Tan Nguyen;Abhinav Bhatele;Nikhil Jain;Suraj P. Kesavan;Harsh Bhatia;Todd Gamblin;Kwan-Liu Ma;Peer-Timo Bremer,"Department of Computer Science, University of California, Davis, CA, USA;Department of Computer Science, University of Maryland, College Park, MD, USA;NVIDIA, Inc, Santa Clara, CA;Department of Computer Science, University of California, Davis, CA, USA;Lawrence Livermore National Laboratory, Center for Applied Scientific Computing, Livermore, CA, USA;Lawrence Livermore National Laboratory, Center for Applied Scientific Computing, Livermore, CA, USA;Department of Computer Science, University of California, Davis, CA, USA;Lawrence Livermore National Laboratory, Center for Applied Scientific Computing, Livermore, CA, USA",0.1109/infvis.2001.963283;10.1109/tvcg.2018.2865026;10.1109/tvcg.2013.200;10.1109/tvcg.2006.156;10.1109/tvcg.2006.120;10.1109/infvis.2002.1173148;10.1109/visual.1991.175815;10.1109/tvcg.2012.213;10.1109/tvcg.2009.111;10.1109/tvcg.2011.209;10.1109/tvcg.2015.2466971,"Performance analysis,software visualization,visual analytics,hierarchical data,coordinated and multiple views",,10,59,731,,
TVCG,2022,Inspecting the Running Process of Horizontal Federated Learning via Visual Analytics,10.1109/tvcg.2021.3074010,http://dx.doi.org/10.1109/TVCG.2021.3074010,4085,4100,J,"As a decentralized training approach, horizontal federated learning (HFL) enables distributed clients to collaboratively learn a machine learning model while keeping personal/private information on local devices. Despite the enhanced performance and efficiency of HFL over local training, clues for inspecting the behaviors of the participating clients and the federated model are usually lacking due to the privacy-preserving nature of HFL. Consequently, the users can only conduct a shallow-level analysis of potential abnormal behaviors and have limited means to assess the contributions of individual clients and implement the necessary intervention. Visualization techniques have been introduced to facilitate the HFL process inspection, usually by providing model metrics and evaluation results as a dashboard representation. Although the existing visualization methods allow a simple examination of the HFL model performance, they cannot support the intensive exploration of the HFL process. In this article, strictly following the HFL privacy-preserving protocol, we design an exploratory visual analytics system for the HFL process termed HFLens, which supports comparative visual interpretation at the overview, communication round, and client instance levels. Specifically, the proposed system facilitates the investigation of the overall process involving all clients, the correlation analysis of clients’ information in one or different communication round(s), the identification of potential anomalies, and the contribution assessment of each HFL client. Two case studies confirm the efficacy of our system. Experts’ feedback suggests that our approach indeed helps in understanding and diagnosing the HFL process better.",Quan Li;Xiguang Wei;Huanbin Lin;Yang Liu 0165;Tianjian Chen;Xiaojuan Ma,Quan Li;Xiguang Wei;Huanbin Lin;Yang Liu;Tianjian Chen;Xiaojuan Ma,"School of Information Science and Technology, ShanghaiTech University, Shanghai, China;AI Department, Shenzhen Semacare Medical Technology Co., Ltd, Shenzhen, Guangdong, China;AI Group, WeBank, Shenzhen, China;AI Group, WeBank, Shenzhen, China;AI Group, WeBank, Shenzhen, China;Department of Computer Science and Engineering, Hong Kong University of Science and Technology, Hong Kong",0.1109/tvcg.2013.173;10.1109/tvcg.2016.2598838;10.1109/tvcg.2017.2744878;10.1109/vast.2018.8802454;10.1109/tvcg.2017.2744683;10.1109/tvcg.2016.2598831;10.1109/tvcg.2016.2598828,"Federated learning,anomaly detection,contribution assessment,visualization",,10,66,1271,,
TVCG,2022,Tracking Internal Frames of Reference for Consistent Molecular Distribution Functions,10.1109/tvcg.2021.3051632,http://dx.doi.org/10.1109/TVCG.2021.3051632,3126,3137,J,"In molecular analysis, spatial distribution functions (SDF) are fundamental instruments in answering questions related to spatial occurrences and relations of atomic structures over time. Given a molecular trajectory, SDFs can, for example, reveal the occurrence of water in relation to particular structures and hence provide clues of hydrophobic and hydrophilic regions. For the computation of meaningful distribution functions, the definition of molecular reference structures is essential. Therefore we introduce the concept of an internal frame of reference (IFR) for labeled point sets that represent selected molecular structures, and we propose an algorithm for tracking the IFR over time and space using a variant of Kabsch’s algorithm. This approach lets us generate a consistent space for the aggregation of the SDF for molecular trajectories and molecular ensembles. We demonstrate the usefulness of the technique by applying it to temporal molecular trajectories as well as ensemble datasets. The examples include different docking scenarios with DNA, insulin, and aspirin.",Robin Skånberg;Martin Falk;Mathieu Linares;Anders Ynnerman;Ingrid Hotz,Robin Skånberg;Martin Falk;Mathieu Linares;Anders Ynnerman;Ingrid Hotz,"Scientific Visualization Group, Linköping University, Linköping, Sweden;Scientific Visualization Group, Linköping University, Linköping, Sweden;Scientific Visualization Group, Linköping University, Linköping, Sweden;Scientific Visualization Group, Linköping University, Linköping, Sweden;Scientific Visualization Group, Linköping University, Linköping, Sweden",0.1109/tvcg.2018.2864507,"Molecule visualization,molecular dynamics,interactive exploration",,8,35,310,,
TVCG,2019,A Model of Spatial Directness in Interactive Visualization,10.1109/tvcg.2018.2848906,http://dx.doi.org/10.1109/TVCG.2018.2848906,2514,2528,J,"We discuss the concept of directness in the context of spatial interaction with visualization. In particular, we propose a model that allows practitioners to analyze and describe the spatial directness of interaction techniques, ultimately to be able to better understand interaction issues that may affect usability. To reach these goals, we distinguish between different types of directness. Each type of directness depends on a particular mapping between different spaces, for which we consider the data space, the visualization space, the output space, the user space, the manipulation space, and the interaction space. In addition to the introduction of the model itself, we also show how to apply it to several real-world interaction scenarios in visualization, and thus discuss the resulting types of spatial directness, without recommending either more direct or more indirect interaction techniques. In particular, we will demonstrate descriptive and evaluative usage of the proposed model, and also briefly discuss its generative usage.",Stefan Bruckner;Tobias Isenberg 0001;Timo Ropinski;Alexander Wiebel,Stefan Bruckner;Tobias Isenberg;Timo Ropinski;Alexander Wiebel,"University of Bergen, Norway, Bergen, Norway;Université Paris-Saclay, France;Ulm University, Ulm, Germany;Hochschule Worms University of Applied Sciences, Worms, Germany",0.1109/tvcg.2008.109;10.1109/visual.1991.175794;10.1109/tvcg.2015.2440233;10.1109/tvcg.2013.134;10.1109/vast.2008.4677361;10.1109/visual.2005.1532781;10.1109/tvcg.2014.2346325;10.1109/tvcg.2007.70515;10.1109/tvcg.2010.131;10.1109/tvcg.2008.120;10.1109/tvcg.2010.132;10.1109/tvcg.2008.121;10.1109/tvcg.2012.217;10.1109/tvcg.2015.2467202;10.1109/tvcg.2011.234;10.1109/tvcg.2012.292;10.1109/tvcg.2008.153;10.1109/vast.2011.6102445;10.1109/scivis.2015.7429514;10.1109/tvcg.2010.157;10.1109/tvcg.2016.2599217,"Visualization,direct interaction,human-computer interaction (HCI)",,11,101,1024,,
TVCG,2022,Deconstructing Categorization in Visualization Recommendation: A Taxonomy and Comparative Study,10.1109/tvcg.2021.3085751,http://dx.doi.org/10.1109/TVCG.2021.3085751,4225,4239,J,"Visualization recommendation (VisRec) systems provide users with suggestions for potentially interesting and useful next steps during exploratory data analysis. These recommendations are typically organized into categories based on their analytical actions, i.e., operations employed to transition from the current exploration state to a recommended visualization. However, despite the emergence of a plethora of VisRec systems in recent work, the utility of the categories employed by these systems in analytical workflows has not been systematically investigated. Our article explores the efficacy of recommendation categories by formalizing a taxonomy of common categories and developing a system, Frontier, that implements these categories. Using Frontier, we evaluate workflow strategies adopted by users and how categories influence those strategies. Participants found recommendations that add attributes to enhance the current visualization and recommendations that filter to sub-populations to be comparatively most useful during data exploration. Our findings pave the way for next-generation VisRec systems that are adaptive and personalized via carefully chosen, effective recommendation categories.",Doris Jung Lin Lee;Vidya Setlur;Melanie Tory;Karrie Karahalios;Aditya G. Parameswaran,Doris Jung-Lin Lee;Vidya Setlur;Melanie Tory;Karrie Karahalios;Aditya Parameswaran,"University of California, Berkeley, Berkeley, CA, USA;Tableau Research, Palo Alto, CA, USA;Northeastern University, Boston, MA, USA;Urbana-Champaign, University of Illinois, Champaign, IL, USA;University of California, Berkeley, Berkeley, CA, USA",0.1109/tvcg.2012.252;10.1109/vast.2009.5333443;10.1109/tvcg.2010.154;10.1109/tvcg.2017.2723393;10.1109/tvcg.2018.2864526;10.1109/tvcg.2014.2346452;10.1109/tvcg.2014.2346573;10.1109/tvcg.2010.164;10.1109/tvcg.2018.2865240;10.1109/infvis.2005.1532142;10.1109/tvcg.2015.2467323;10.1109/tvcg.2013.124;10.1109/tvcg.2016.2599030;10.1109/tvcg.2015.2467191;10.1109/tvcg.2007.70594;10.1109/tvcg.2018.2865145;10.1109/tvcg.2016.2598466,"Visual analysis,analytical workflow,discovery-driven analysis,visualization recommendations",,10,77,567,,
TVCG,2019,Decal-Lenses: Interactive Lenses on Surfaces for Multivariate Visualization,10.1109/tvcg.2018.2850781,http://dx.doi.org/10.1109/TVCG.2018.2850781,2568,2582,J,"We present decal-lenses, a new interaction technique that extends the concept of magic lenses to augment and manage multivariate visualizations on arbitrary surfaces. Our object-space lenses follow the surface geometry and allow the user to change the point of view during data exploration while maintaining a spatial reference to positions where one or more lenses were placed. Each lens delimits specific regions of the surface where one or more attributes can be selected or combined. Similar to 2D lenses, the user interacts with our lenses in real-time, switching between different attributes within the lens context. The user can also visualize the surface data representations from the point of view of each lens by using local cameras. To place lenses on surfaces of intricate geometry, such as the human brain, we introduce the concept of support surfaces for designing interaction techniques. Support surfaces provide a way to place and interact with the lenses while avoiding holes and occluded regions during data exploration. We further extend decal-lenses to arbitrary regions using brushing and lassoing operations. We discuss the applicability of our technique and present several examples where our lenses can be useful to create a customized exploration of multivariate data on surfaces.",Allan Rocha;Julio Daniel Silva;Usman R. Alim;Sheelagh Carpendale;Mario Costa Sousa,Allan Rocha;Julio Daniel Silva;Usman R. Alim;Sheelagh Carpendale;Mario Costa Sousa,"Department of Computer Science, University of Calgary, Calgary, AB, Canada;Department of Computer Science, University of Calgary, Calgary, AB, Canada;Department of Computer Science, University of Calgary, Calgary, AB, Canada;Department of Computer Science, University of Calgary, Calgary, AB, Canada;Department of Computer Science, University of Calgary, Calgary, AB, Canada",0.1109/tvcg.2006.124;10.1109/tvcg.2006.140;10.1109/tvcg.2007.70534;10.1109/tvcg.2012.110;10.1109/visual.1998.745317;10.1109/tvcg.2014.2346406;10.1109/tvcg.2011.243;10.1109/tvcg.2016.2598866;10.1109/tvcg.2008.168,"Focus+context,lenses,interaction,design,multivariate,visualization,surfaces,decal",,8,60,546,,
TVCG,2021,HyperLabels: Browsing of Dense and Hierarchical Molecular 3D Models,10.1109/tvcg.2020.2975583,http://dx.doi.org/10.1109/TVCG.2020.2975583,3493,3504,J,"We present a method for the browsing of hierarchical 3D models in which we combine the typical navigation of hierarchical structures in a 2D environment—using clicks on nodes, links, or icons—with a 3D spatial data visualization. Our approach is motivated by large molecular models, for which the traditional single-scale navigational metaphors are not suitable. Multi-scale phenomena, e. g., in astronomy or geography, are complex to navigate due to their large data spaces and multi-level organization. Models from structural biology are in addition also densely crowded in space and scale. Cutaways are needed to show individual model subparts. The camera has to support exploration on the level of a whole virus, as well as on the level of a small molecule. We address these challenges by employing HyperLabels: active labels that—in addition to their annotational role—also support user interaction. Clicks on HyperLabels select the next structure to be explored. Then, we adjust the visualization to showcase the inner composition of the selected subpart and enable further exploration. Finally, we use a breadcrumbs panel for orientation and as a mechanism to traverse upwards in the model hierarchy. We demonstrate our concept of hierarchical 3D model browsing using two exemplary models from meso-scale biology.",David Kouril;Tobias Isenberg 0001;Barbora Kozlíková;Miriah Meyer;M. Eduard Gröller;Ivan Viola,David Kouřil;Tobias Isenberg;Barbora Kozlíková;Miriah Meyer;M. Eduard Gröller;Ivan Viola,"TU Wien, Wien, Austria;CNRS, Inria, LRI, Université Paris-Saclay, Saint-Aubin, France;Masaryk University, Brno, Czech Republic;University of Utah, Salt Lake City, UT, USA;TU Wien, Wien, Austria;King Abdullah University of Science and Technology (KAUST), Thuwal, Saudi Arabia",0.1109/visual.2004.48;10.1109/tvcg.2006.152;10.1109/tvcg.2007.70539;10.1109/tvcg.2018.2864508;10.1109/tvcg.2019.2934334;10.1109/tvcg.2017.2744518;10.1109/tvcg.2017.2743981;10.1109/visual.2003.1250400;10.1109/tvcg.2006.140;10.1109/tvcg.2018.2864491;10.1109/tvcg.2008.168;10.1109/tvcg.2007.70565;10.1109/tvcg.2006.124,"Scientific visualization,navigation,3D molecular data,multi-scale data,hierarchical data,HyperLabels",,8,74,1106,,
TVCG,2020,Interactive Visualization and On-Demand Processing of Large Volume Data: A Fully GPU-Based Out-of-Core Approach,10.1109/tvcg.2019.2912752,http://dx.doi.org/10.1109/TVCG.2019.2912752,3008,3021,J,"In a wide range of scientific fields, 3D datasets production capabilities have widely evolved in recent years, especially with the rapid increase in their sizes. As a result, many large-scale applications, including visualization or processing, have become challenging to address. A solution to this issue lies in providing out-of-core algorithms specifically designed to handle datasets significantly larger than memory. In this article, we present a new approach that extends the broad interactive addressing principles already established in the field of out-of-core volume rendering on GPUs to allow on-demand processing during the visualization stage. We propose a pipeline designed to manage data as regular 3D grids regardless of the underlying application. It relies on a caching approach with a virtual memory addressing system coupled to an efficient parallel management on GPU to provide efficient access to data in interactive time. It allows any visualization or processing application to leverage the flexibility of its structure by managing multi-modality datasets. Furthermore, we show that our system delivers good performance on a single standard PC with low memory budget on the GPU.",Jonathan Sarton;Nicolas Courilleau;Yannick Rémion;Laurent Lucas,Jonathan Sarton;Nicolas Courilleau;Yannick Remion;Laurent Lucas,"Université de Reims Champagne-Ardenne, Reims, France;Université de Reims Champagne-Ardenne, Reims, France;Université de Reims Champagne-Ardenne, Reims, France;Université de Reims Champagne-Ardenne, Reims, France",0.1109/visual.2003.1250384;10.1109/tvcg.2012.240;10.1109/tvcg.2009.178,"GPU,caching system,out-of-core data management,large data,interactive visualization,on-demand processing",,7,35,781,,
TVCG,2022,Affective Congruence in Visualization Design: Influences on Reading Categorical Maps,10.1109/tvcg.2021.3050118,http://dx.doi.org/10.1109/TVCG.2021.3050118,2867,2878,J,"Recent work in data visualization has demonstrated that small, perceptually-distinct color palettes—such as those used in categorical mapping—can connote significant affective qualities. Data that are mapped or otherwise visualized are also often emotive in nature, either inherently (e.g., climate change, disease mortality rates), or by design, such as can be found in visual storytelling. However, little is known about how the affective qualities of color interact with those of data context in visualization design. This article describes the results of a crowdsourced study on the influence of affectively congruent versus incongruent color schemes on categorical map-reading response. We report both objective (pattern detection; area comparison) and subjective (affective quality; appropriateness; preference) measures of map-reader response. Our results suggest that affectively congruent colors amplify perceptions of the affective qualities of maps with emotive topics, affective incongruence may cause confusion, and that affective congruence is particularly influential in maps of positive-leaning data topics. Finally, we offer preliminary design recommendations for balancing color congruence with other design factors, and for synthesizing color and affective context in thematic map design.",Cary L. Anderson;Anthony C. Robinson,Cary L. Anderson;Anthony C. Robinson,"Katz Graduate School of Business, Marketing and Business Economics Area, University of Pittsburgh, Pittsburgh, PA, USA;GeoVISTA Center, Department of Geography, The Pennsylvania State University, University Park, PA, USA",0.1109/visual.1990.146372;10.1109/tvcg.2016.2599214;10.1109/tvcg.2010.179;10.1109/vast.2012.6400540;10.1109/tvcg.2015.2467471;10.1109/tvcg.2018.2865147;10.1109/visual.2001.964510;10.1109/tvcg.2012.315;10.1109/tvcg.2016.2598918,"Color,visualization,emotion,design,cartography",,8,63,824,,
TVCG,2022,A State-of-the-Art Survey of Tasks for Tree Design and Evaluation With a Curated Task Dataset,10.1109/tvcg.2021.3064037,http://dx.doi.org/10.1109/TVCG.2021.3064037,3563,3584,J,"In the field of information visualization, the concept of “tasks” is an essential component of theories and methodologies for how a visualization researcher or a practitioner understands what tasks a user needs to perform and how to approach the creation of a new design. In this article, we focus on the collection of tasks for tree visualizations, a common visual encoding in many domains ranging from biology to computer science to geography. In spite of their commonality, no prior efforts exist to collect and abstractly define tree visualization tasks. We present a literature review of tree visualization articles and generate a curated dataset of over 200 tasks. To enable effective task abstraction for trees, we also contribute a novel extension of the Multi-Level Task Typology to include more specificity to support tree-specific tasks as well as a systematic procedure to conduct task abstractions for tree visualizations. All tasks in the dataset were abstracted with the novel typology extension and analyzed to gain a better understanding of the state of tree visualizations. These abstracted tasks can benefit visualization researchers and practitioners as they design evaluation studies or compare their analytical tasks with ones previously studied in the literature to make informed decisions about their design. We also reflect on our novel methodology and advocate more broadly for the creation of task-based knowledge repositories for different types of visualizations. The Supplemental Material, which can be found on the Computer Society Digital Library at http://doi.ieeecomputersociety.org/10.1109/TVCG.2021.3064037, will be maintained on OSF: https://osf.io/u5ehs/.",Aditeya Pandey;Uzma Haque Syeda;Chaitya Shah;John A. Guerra-Gomez;Michelle A. Borkin,Aditeya Pandey;Uzma Haque Syeda;Chaitya Shah;John A. Guerra-Gomez;Michelle A. Borkin,"Northeastern University, Boston, MA, USA;Northeastern University, Boston, MA, USA;Northeastern University, Boston, MA, USA;Northeastern University, Boston, MA, USA;Northeastern University, Boston, MA, USA",0.1109/visual.1991.175815;10.1109/tvcg.2019.2934535;10.1109/infvis.2001.963285;10.1109/tvcg.2018.2829750;10.1109/vast.2006.261450;10.1109/infvis.2002.1173153;10.1109/tvcg.2008.171;10.1109/tvcg.2012.272;10.1109/tvcg.2017.2743959;10.1109/tvcg.2006.147;10.1109/tvcg.2012.213;10.1109/tvcg.2011.279;10.1109/tvcg.2010.157;10.1109/tvcg.2009.167;10.1109/infvis.2002.1173148;10.1109/tvcg.2011.193;10.1109/infvis.2004.70;10.1109/infvis.2001.963290;10.1109/tvcg.2008.172;10.1109/vast.2011.6102453;10.1109/tvcg.2010.185;10.1109/tvcg.2013.231;10.1109/tvcg.2007.70537;10.1109/tvcg.2013.124;10.1109/tvcg.2016.2549018;10.1109/tvcg.2018.2834341;10.1109/tvcg.2013.120,"STAR,tree,tasks,task abstraction,theory,datasets",,8,103,595,,
TVCG,2019,FeatureLego: Volume Exploration Using Exhaustive Clustering of Super-Voxels,10.1109/tvcg.2018.2856744,http://dx.doi.org/10.1109/TVCG.2018.2856744,2725,2737,J,"We present a volume exploration framework, FeatureLego, that uses a novel voxel clustering approach for efficient selection of semantic features. We partition the input volume into a set of compact super-voxels that represent the finest selection granularity. We then perform an exhaustive clustering of these super-voxels using a graph-based clustering method. Unlike the prevalent brute-force parameter sampling approaches, we propose an efficient algorithm to perform this exhaustive clustering. By computing an exhaustive set of clusters, we aim to capture as many boundaries as possible and ensure that the user has sufficient options for efficiently selecting semantically relevant features. Furthermore, we merge all the computed clusters into a single tree of meta-clusters that can be used for hierarchical exploration. We implement an intuitive user-interface to interactively explore volumes using our clustering approach. Finally, we show the effectiveness of our framework on multiple real-world datasets of different modalities.",Shreeraj Jadhav;Saad Nadeem;Arie E. Kaufman,Shreeraj Jadhav;Saad Nadeem;Arie Kaufman,"Department of Computer Science, Stony Brook University, Stony Brook, NY, USA;Department of Medical Physics, Memorial Sloan Kettering Cancer Center, New York, NY, USA;School of Engineering and Applies Sciences (SEAS), Harvard University",0.1109/tvcg.2011.246;10.1109/tvcg.2011.261;10.1109/tvcg.2008.147;10.1109/tvcg.2012.231;10.1109/tvcg.2009.185;10.1109/tvcg.2006.168;10.1109/tvcg.2014.2346321;10.1109/tvcg.2010.190;10.1109/tvcg.2008.159;10.1109/tvcg.2011.248;10.1109/tvcg.2013.177;10.1109/tvcg.2011.253,"Volume visualization,hierarchical exploration,voxel clustering",,6,40,588,,
TVCG,2022,Multi-Level Area Balancing of Clustered Graphs,10.1109/tvcg.2020.3038154,http://dx.doi.org/10.1109/TVCG.2020.3038154,2682,2696,J,"We present a multi-level area balancing technique for laying out clustered graphs to facilitate a comprehensive understanding of the complex relationships that exist in various fields, such as life sciences and sociology. Clustered graphs are often used to model relationships that are accompanied by attribute-based grouping information. Such information is essential for robust data analysis, such as for the study of biological taxonomies or educational backgrounds. Hence, the ability to smartly arrange textual labels and packing graphs within a certain screen space is therefore desired to successfully convey the attribute data . Here we propose to hierarchically partition the input screen space using Voronoi tessellations in multiple levels of detail. In our method, the position of textual labels is guided by the blending of constrained forces and the forces derived from centroidal Voronoi cells. The proposed algorithm considers three main factors: (1) area balancing, (2) schematized space partitioning, and (3) hairball management. We primarily focus on area balancing, which aims to allocate a uniform area for each textual label in the diagram. We achieve this by first untangling a general graph to a clustered graph through textual label duplication, and then coupling with spanning-tree-like visual integration. We illustrate the feasibility of our approach with examples and then evaluate our method by comparing it with well-known conventional approaches and collecting feedback from domain experts.",Hsiang-Yun Wu;Martin Nöllenburg;Ivan Viola,Hsiang-Yun Wu;Martin Nöllenburg;Ivan Viola,"TU Wien, Vienna, Austria;TU Wien, Vienna, Austria;King Abdullah University of Science and Technology (KAUST), Thuwal, Saudi Arabia",0.1109/tvcg.2015.2467251;10.1109/tvcg.2008.141;10.1109/tvcg.2011.205;10.1109/tvcg.2017.2745919;10.1109/infvis.2001.963283;10.1109/tvcg.2010.136;10.1109/tvcg.2009.122;10.1109/tvcg.2011.186;10.1109/tvcg.2013.76,"Graph drawing,Voronoi tessellation,multi-level,spatially-efficient layout",,6,71,1157,,
TVCG,2022,Conceptual Metaphor and Graphical Convention Influence the Interpretation of Line Graphs,10.1109/tvcg.2021.3088343,http://dx.doi.org/10.1109/TVCG.2021.3088343,1209,1221,J,"Many metaphors in language reflect conceptual metaphors that structure thought. In line with metaphorical expressions such as ‘high number’, experiments show that people associate larger numbers with upward space. Consistent with this metaphor, high numbers are conventionally depicted in high positions on the $y$y-axis of line graphs. People also associate good and bad (emotional valence) with upward and downward locations, in line with metaphorical expressions such as ‘uplifting’ and ‘down in the dumps’. Graphs depicting good quantities (e.g., vacation days) are consistent with graphical convention and the valence metaphor, because ‘more’ of the good quantity is represented by higher $y$y-axis positions. In contrast, graphs depicting bad quantities (e.g., murders) are consistent with graphical convention, but not the valence metaphor, because more of the bad quantity is represented by higher (rather than lower) $y$y-axis positions. We conducted two experiments (N = 300 per experiment) where participants answered questions about line graphs depicting good and bad quantities. For some graphs, we inverted the conventional axis ordering of numbers. Line graphs that aligned (versus misaligned) with valence metaphors (up = good) were easier to interpret, but this beneficial effect did not outweigh the adverse effect of inverting the axis numbering. Line graphs depicting good (versus bad) quantities were easier to interpret, as were graphs that depicted quantity using the $x$x-axis (versus $y$y-axis). Our results suggest that conceptual metaphors matter for the interpretation of line graphs. However, designers of line graphs are warned against subverting graphical convention to align with conceptual metaphors.",Greg Woodin;Bodo Winter;Lace M. K. Padilla,Greg Woodin;Bodo Winter;Lace Padilla,"Department of English Language and Linguistics, University of Birmingham, Birmingham, U.K.;Department of English Language and Linguistics, University of Birmingham, Birmingham, U.K.;Spatial Perception, Applied Cognition & Education Lab, University of California Merced, Merced, CA, USA",0.1109/tvcg.2011.175,"Conceptual metaphor theory,more is up,mental number line,cognition,linguistics,emotional valence,line graph,axis reversal,handedness,empirical evaluation",,6,80,893,,X
TVCG,2020,Real-Time Exploration of Large Spatiotemporal Datasets Based on Order Statistics,10.1109/tvcg.2019.2914446,http://dx.doi.org/10.1109/TVCG.2019.2914446,3314,3326,J,"In recent years sophisticated data structures based on datacubes have been proposed to perform interactive visual exploration of large datasets. While powerful, these approaches overlook the important fact that aggregations used to produce datacubes do not represent the actual distribution of the data being analyzed. As a result, these methods might produce biased results as well as hide important features in the data. In this paper, we introduce the Quantile Datacube Structure (QDS) that bridges this gap by supporting interactive visual exploration based on order statistics. To achieve this, QDS makes use of an efficient non-parametric distribution approximation scheme called p-digest and employs a novel datacube indexing scheme that reduces the memory usage of previous datacube methods. This enables interactive slicing and dicing while accurately approximating the distribution of quantitative variables of interest. We present two case studies that illustrate the ability of QDS to not only build order statistics based visualizations interactively but also to perform event detection on very large datasets. Finally, we present extensive experimental results that validate the effectiveness of QDS regarding memory usage and accuracy in the approximation of order statistics for real-world datasets.",Cícero A. L. Pahins;Nivan Ferreira;João Luiz Dihl Comba,Cícero A. L. Pahins;Nivan Ferreira;João L. Comba,"Instituto de Informática, Universidade Federal do Rio Grande do Sul, Porto Alegre, Brazil;Centro de Informática, Universidade Federal de Pernambuco, Recife, Brazil;Instituto de Informática, Universidade Federal do Rio Grande do Sul, Porto Alegre, Brazil",0.1109/tvcg.2014.2346298;10.1109/tvcg.2017.2744685;10.1109/tvcg.2013.179;10.1109/tvcg.2016.2598624;10.1109/tvcg.2016.2598694;10.1109/tvcg.2014.2346452;10.1109/tvcg.2017.2671341;10.1109/tvcg.2014.2346449,"Data structures for visualization,order statistics,quantile sketch,visual analytics,event detection",,6,47,643,,
TVCG,2020,Taxonomizer: Interactive Construction of Fully Labeled Hierarchical Groupings from Attributes of Multivariate Data,10.1109/tvcg.2019.2895642,http://dx.doi.org/10.1109/TVCG.2019.2895642,2875,2890,J,"Organizing multivariate data spaces by their dimensions or attributes can be a rather difficult task. Most of the work in this area focuses on the statistical aspects such as correlation clustering, dimension reduction, and the like. These methods typically produce hierarchies in which the leaf nodes are labeled by the attribute names while the inner nodes are often represented by just a statistical measure and criterion, such as a threshold. This makes them difficult to understand for mainstream users. Taxonomies in science, biology, engineering, etc. on the other hand, are easy to comprehend since they provide meaningful labels at the inner nodes as well. Labeling inner nodes of taxonomies automatically requires the identification of hypernyms. Our proposed framework, called Taxonomizer, takes a visual analytics approach to meet this challenge. It appeals to the wisdom of humans to liaise with state of the art data analytics, neural word embeddings, and lexical databases. It consists of a set of visual tools that starts out with an automatically computed hierarchy where the leaf nodes are the original data attributes, and it then allows users to sculpt high-quality taxonomies for any multivariate dataset.",Salman Mahmood;Klaus Mueller 0001,Salman Mahmood;Klaus Mueller,"Department of Computer Science, Visual Analytics and Imaging Laboratory, Stony Brook University, Stony Brook, USA;Department of Computer Science, Visual Analytics and Imaging Laboratory, Stony Brook University, Stony Brook, USA",0.1109/visual.2004.39;10.1109/visual.1992.235217;10.1109/vast.2012.6400487;10.1109/tvcg.2016.2598876;10.1109/tvcg.2010.79,"High-dimensional data,data fusion and integration,hierarchy data,taxonomy,neural embeddings,lexical databases",,6,52,466,,
TVCG,2020,Fourier Opacity Optimization for Scalable Exploration,10.1109/tvcg.2019.2915222,http://dx.doi.org/10.1109/TVCG.2019.2915222,3204,3216,J,"Over the past decades, scientific visualization became a fundamental aspect of modern scientific data analysis. Across all data-intensive research fields, ranging from structural biology to cosmology, data sizes increase rapidly. Dealing with the growing large-scale data is one of the top research challenges of this century. For the visual exploratory data analysis, interactivity, a view-dependent visibility optimization and frame coherence are indispensable. In this work, we extend the recent decoupled opacity optimization framework to enable a navigation without occlusion of important features through large geometric data. By expressing the accumulation of importance and optical depth in Fourier basis, the computation, evaluation and rendering of optimized transparent geometry become not only order-independent, but also operate within a fixed memory bound. We study the quality of our Fourier approximation in terms of accuracy, memory requirements and efficiency for both the opacity computation, as well as the order-independent compositing. We apply the method to different point, line and surface data sets originating from various research fields, including meteorology, health science, astrophysics and organic chemistry.",Irene Baeza Rojo;Markus H. Gross;Tobias Günther,Irene Baeza Rojo;Markus Gross;Tobias Günther,"Computer Graphics Laboratory, ETH Zürich, Zürich, Switzerland;Computer Graphics Laboratory, ETH Zürich, Zürich, Switzerland;Computer Graphics Laboratory, ETH Zürich, Zürich, Switzerland",0.1109/tvcg.2010.166;10.1109/tvcg.2010.173;10.1109/tvcg.2010.131;10.1109/tvcg.2010.212;10.1109/visual.1996.567777;10.1109/tvcg.2009.138;10.1109/visual.2004.48;10.1109/tvcg.2011.155;10.1109/tvcg.2007.70595;10.1109/tvcg.2012.150;10.1109/tvcg.2015.2467411;10.1109/tvcg.2015.2467203;10.1109/tvcg.2009.172,"Scientific visualization,opacity optimization,Fourier approximation",,7,65,612,,
TVCG,2022,HisVA: A Visual Analytics System for Studying History,10.1109/tvcg.2021.3086414,http://dx.doi.org/10.1109/TVCG.2021.3086414,4344,4359,J,"Studying history involves many difficult tasks. Examples include searching for proper data in a large event space, understanding stories of historical events by time and space, and finding relationships among events that may not be apparent. Instructors who extensively use well-organized and well-argued materials (e.g., textbooks and online resources) can lead students to a narrow perspective in understanding history and prevent spontaneous investigation of historical events, with the students asking their own questions. In this article, we proposed HisVA, a visual analytics system that allows the efficient exploration of historical events from Wikipedia using three views: event, map, and resource. HisVA provides an effective event exploration space, where users can investigate relationships among historical events by reviewing and linking them in terms of space and time. To evaluate our system, we present two usage scenarios, a user study with a qualitative analysis of user exploration strategies, and in-class deployment results.",Dongyun Han;Gorakh Parsad;Hwiyeon Kim;Jaekyom Shim;Oh-Sang Kwon;Kyung A. Son;Jooyoung Lee;Isaac Cho;Sungahn Ko,Dongyun Han;Gorakh Parsad;Hwiyeon Kim;Jaekyom Shim;Oh-Sang Kwon;Kyung A. Son;Jooyoung Lee;Isaac Cho;Sungahn Ko,"Utah State University, Logan, UT, USA;UNIST, Ulsan, South Korea;UNIST, Ulsan, South Korea;UNIST, Ulsan, South Korea;UNIST, Ulsan, South Korea;UNIST, Ulsan, South Korea;UNIST, Ulsan, South Korea;Utah State University, Logan, UT, USA;UNIST, Ulsan, South Korea",0.1109/tvcg.2016.2598920;10.1109/vast.2012.6400485;10.1109/tvcg.2017.2744478;10.1109/tvcg.2013.200;10.1109/tvcg.2016.2598797;10.1109/tvcg.2019.2922597;10.1109/tvcg.2018.2830759;10.1109/tvcg.2015.2467971,"Visualization for education,event visualization,studying history,Wikipedia",,5,70,752,,
TVCG,2022,Understanding Missing Links in Bipartite Networks With MissBiN,10.1109/tvcg.2020.3032984,http://dx.doi.org/10.1109/TVCG.2020.3032984,2457,2469,J,"The analysis of bipartite networks is critical in a variety of application domains, such as exploring entity co-occurrences in intelligence analysis and investigating gene expression in bio-informatics. One important task is missing link prediction, which infers the existence of unseen links based on currently observed ones. In this article, we propose a visual analysis system, MissBiN, to involve analysts in the loop for making sense of link prediction results. MissBiN equips a novel method for link prediction in a bipartite network by leveraging the information of bi-cliques in the network. It also provides an interactive visualization for understanding the algorithm outputs. The design of MissBiN is based on three high-level analysis questions (what, why, and how) regarding missing links, which are distilled from the literature and expert interviews. We conducted quantitative experiments to assess the performance of the proposed link prediction algorithm, and interviewed two experts from different domains to demonstrate the effectiveness of MissBiN as a whole. We also provide a comprehensive usage scenario to illustrate the usefulness of the tool in an application of intelligence analysis.",Jian Zhao 0010;Maoyuan Sun;Francine Chen 0001;Patrick Chiu,Jian Zhao;Maoyuan Sun;Francine Chen;Patrick Chiu,"University of Waterloo, Waterloo, ON, Canada;Northern Illinois University, DeKalb, IL, USA;FXPAL, Palo Alto, CA, USA;FXPAL, Palo Alto, CA, USA",0.1109/tvcg.2007.70582;10.1109/tvcg.2017.2744458;10.1109/tvcg.2013.179;10.1109/tvcg.2015.2467813;10.1109/tvcg.2018.2861397;10.1109/tvcg.2014.2346752;10.1109/tvcg.2013.124;10.1109/tvcg.2011.250;10.1109/tvcg.2010.138,"Missing link prediction,bipartite network,bi-clique,interactive visualization,visual analytics",,5,64,319,,
TVCG,2021,Characterizing the Quality of Insight by Interactions: A Case Study,10.1109/tvcg.2020.2977634,http://dx.doi.org/10.1109/TVCG.2020.2977634,3410,3424,J,"Understanding the quality of insight has become increasingly important with the trend of allowing users to post comments during visual exploration, yet approaches for qualifying insight are rare. This article presents a case study to investigate the possibility of characterizing the quality of insight via the interactions performed. To do this, we devised the interaction of a visualization tool-MediSyn-for insight generation. MediSyn supports five types of interactions: selecting, connecting, elaborating, exploring, and sharing. We evaluated MediSyn with 14 participants by allowing them to freely explore the data and generate insights. We then extracted seven interaction patterns from their interaction logs and correlated the patterns to four aspects of insight quality. The results show the possibility of qualifying insights via interactions. Among other findings, exploration actions can lead to unexpected insights; the drill-down pattern tends to increase the domain values of insights. A qualitative analysis shows that using domain knowledge to guide exploration can positively affect the domain value of derived insights. We discuss the study's implications, lessons learned, and future research opportunities.",Chen He 0003;Luana Micallef;Liye He;Gopal Peddinti;Tero Aittokallio;Giulio Jacucci,Chen He;Luana Micallef;Liye He;Gopal Peddinti;Tero Aittokallio;Giulio Jacucci,"Department of Computer Science, University of Helsinki, Helsinki, Finland;Human-Centered Computing, Department of Computer Science, University of Copenhagen, Denmark;Institute for Molecular Medicine Finland, University of Helsinki, Helsinki, Finland;VTT Technical Research Center of Finland Oy, Espoo, Finland;Institute for Molecular Medicine Finland, University of Helsinki, Helsinki, Finland;Department of Computer Science, University of Helsinki, Helsinki, Finland",0.1109/tvcg.2017.2745279;10.1109/tvcg.2016.2598543;10.1109/vast.2010.5653598;10.1109/tvcg.2008.137;10.1109/vast.2009.5333020;10.1109/tvcg.2007.70577;10.1109/tvcg.2015.2467613;10.1109/tvcg.2013.164;10.1109/tvcg.2007.70515;10.1109/tvcg.2018.2865117;10.1109/vast.2014.7042482;10.1109/vast.2010.5653587;10.1109/vast.2009.5333023;10.1109/tvcg.2015.2467551;10.1109/tvcg.2010.177;10.1109/mcg.2015.51;10.1109/tvcg.2016.2598471;10.1109/tvcg.2012.252;10.1109/tvcg.2018.2865040;10.1109/vast.2016.7883520;10.1109/vast.2008.4677362;10.1109/tvcg.2018.2802520;10.1109/tvcg.2015.2467871;10.1109/tvcg.2014.2346575;10.1109/vast.2016.7883515;10.1109/tvcg.2015.2467611;10.1109/tvcg.2016.2598797;10.1109/mcg.2019.2933419,"Insight,interaction,interaction pattern,entity,visualization,insight-based evaluation",,6,71,598,,
TVCG,2020,On Evaluating Runtime Performance of Interactive Visualizations,10.1109/tvcg.2019.2898435,http://dx.doi.org/10.1109/TVCG.2019.2898435,2848,2862,J,"As our field matures, evaluation of visualization techniques has extended from reporting runtime performance to studying user behavior. Consequently, many methodologies and best practices for user studies have evolved. While maintaining interactivity continues to be crucial for the exploration of large data sets, no similar methodological foundation for evaluating runtime performance has been developed. Our analysis of 50 recent visualization papers on new or improved techniques for rendering volumes or particles indicates that only a very limited set of parameters like different data sets, camera paths, viewport sizes, and GPUs are investigated, which make comparison with other techniques or generalization to other parameter ranges at least questionable. To derive a deeper understanding of qualitative runtime behavior and quantitative parameter dependencies, we developed a framework for the most exhaustive performance evaluation of volume and particle visualization techniques that we are aware of, including millions of measurements on ten different GPUs. This paper reports on our insights from statistical analysis of this data, discussing independent and linear parameter behavior and non-obvious effects. We give recommendations for best practices when evaluating runtime performance of scientific visualization applications, which can serve as a starting point for more elaborate models of performance quantification.",Valentin Bruder;Christoph Müller 0001;Steffen Frey;Thomas Ertl,Valentin Bruder;Christoph Müller;Steffen Frey;Thomas Ertl,"Visualization Research Center, University of Stuttgart, Stuttgart, Germany;Visualization Research Center, University of Stuttgart, Stuttgart, Germany;Visualization Research Center, University of Stuttgart, Stuttgart, Germany;Visualization Research Center, University of Stuttgart, Stuttgart, Germany",0.1109/tvcg.2006.115;10.1109/tvcg.2007.70517;10.1109/tvcg.2014.2346319;10.1109/tvcg.2015.2467963;10.1109/tvcg.2016.2598430;10.1109/tvcg.2016.2599040;10.1109/tvcg.2009.157;10.1109/tvcg.2017.2744438;10.1109/tvcg.2017.2744238;10.1109/visual.2003.1250384;10.1109/scivis.2015.7429492;10.1109/tvcg.2015.2467293;10.1109/tvcg.2017.2743979;10.1109/tvcg.2008.147;10.1109/tvcg.2009.120;10.1109/tvcg.2006.146;10.1109/tvcg.2007.70518;10.1109/tvcg.2012.232;10.1109/tvcg.2011.113;10.1109/tvcg.2011.198;10.1109/tvcg.2011.35,"Performance evaluation,scientific visualization,volume rendering,particle rendering",,5,75,719,,
TVCG,2021,DimLift: Interactive Hierarchical Data Exploration Through Dimensional Bundling,10.1109/tvcg.2021.3057519,http://dx.doi.org/10.1109/TVCG.2021.3057519,2908,2922,J,"The identification of interesting patterns and relationships is essential to exploratory data analysis. This becomes increasingly difficult in high dimensional datasets. While dimensionality reduction techniques can be utilized to reduce the analysis space, these may unintentionally bury key dimensions within a larger grouping and obfuscate meaningful patterns. With this work we introduce DimLift, a novel visual analysis method for creating and interacting with dimensional bundles. Generated through an iterative dimensionality reduction or user-driven approach, dimensional bundles are expressive groups of dimensions that contribute similarly to the variance of a dataset. Interactive exploration and reconstruction methods via a layered parallel coordinates plot allow users to lift interesting and subtle relationships to the surface, even in complex scenarios of missing and mixed data types. We exemplify the power of this technique in an expert case study on clinical cohort data alongside two additional case examples from nutrition and ecology.",Laura A. Garrison;Juliane Müller 0003;Stefanie Schreiber;Steffen Oeltze-Jafra;Helwig Hauser;Stefan Bruckner,Laura Garrison;Juliane Müller;Stefanie Schreiber;Steffen Oeltze-Jafra;Helwig Hauser;Stefan Bruckner,"Department of Informatics & Mohn Medical Imaging and Visualization Centre, Department of Radiology, Haukeland University Hospital, University of Bergen, Bergen, Norway;Department of Neurology, Otto von Guericke University Magdeburg, Magdeburg, Germany;Department of Neurology, Center for Behavioral Brain Sciences, Otto von Guericke University Magdeburg, Magdeburg, Germany;Department of Neurology, Center for Behavioral Brain Sciences, Otto von Guericke University Magdeburg, Magdeburg, Germany;Department of Informatics & Mohn Medical Imaging and Visualization Centre, Department of Radiology, Haukeland University Hospital, University of Bergen, Bergen, Norway;Department of Informatics & Mohn Medical Imaging and Visualization Centre, Department of Radiology, Haukeland University Hospital, University of Bergen, Bergen, Norway",0.1109/tvcg.2014.2346325;10.1109/infvis.2003.1249026;10.1109/vast.2012.6400488;10.1109/vast.2010.5652392;10.1109/tvcg.2013.150;10.1109/infvis.2004.68;10.1109/tvcg.2011.178;10.1109/tvcg.2018.2865047;10.1109/tvcg.2021.3056424;10.1109/tvcg.2011.185;10.1109/tvcg.2016.2598495;10.1109/infvis.2002.1173157;10.1109/tvcg.2010.177,"Dimensionality reduction,interactive visual analysis,visual analytics,parallel coordinates",,5,59,889,,X
TVCG,2021,Vis-a-Vis: Visual Exploration of Visualization Source Code Evolution,10.1109/tvcg.2019.2963651,http://dx.doi.org/10.1109/TVCG.2019.2963651,3153,3167,J,"Developing an algorithm for a visualization prototype often involves the direct comparison of different development stages and design decisions, and even minor modifications may dramatically affect the results. While existing development tools provide visualizations for gaining general insight into performance and structural aspects of the source code, they neglect the central importance of result images unique to graphical algorithms. In this article, we present a novel approach that enables visualization programmers to simultaneously explore the evolution of their algorithm during the development phase together with its corresponding visual outcomes by providing an automatically updating meta visualization. Our interactive system allows for the direct comparison of all development states on both the visual and the source code level, by providing easy to use navigation and comparison tools. The on-the-fly construction of difference images, source code differences, and a visual representation of the source code structure further enhance the user's insight into the states' interconnected changes over time. Our solution is accessible via a web-based interface that provides GPU-accelerated live execution of C++ and GLSL code, as well as supporting a domain-specific programming language for scientific visualization.",Fabian Bolte;Stefan Bruckner,Fabian Bolte;Stefan Bruckner,"Department of Informatics, University of Bergen, Bergen, Norway;Department of Informatics, University of Bergen, Bergen, Norway",0.1109/tvcg.2008.137;10.1109/visual.2005.1532788;10.1109/tvcg.2018.2865039;10.1109/tvcg.2018.2865024;10.1109/tvcg.2014.2346321;10.1109/tvcg.2016.2599030;10.1109/tvcg.2011.185;10.1109/visual.2005.1532859;10.1109/tvcg.2011.229;10.1109/tvcg.2018.2864836;10.1109/tvcg.2015.2467449;10.1109/visual.2000.885678,"Visualization system and toolkit design,user interfaces,integrating spatial and non-spatial data visualization,software visualization",,4,56,817,,
TVCG,2021,SplitStreams: A Visual Metaphor for Evolving Hierarchies,10.1109/tvcg.2020.2973564,http://dx.doi.org/10.1109/TVCG.2020.2973564,3571,3584,J,"The visualization of hierarchically structured data over time is an ongoing challenge and several approaches exist trying to solve it. Techniques such as animated or juxtaposed tree visualizations are not capable of providing a good overview of the time series and lack expressiveness in conveying changes over time. Nested streamgraphs provide a better understanding of the data evolution, but lack the clear outline of hierarchical structures at a given timestep. Furthermore, these approaches are often limited to static hierarchies or exclude complex hierarchical changes in the data, limiting their use cases. We propose a novel visual metaphor capable of providing a static overview of all hierarchical changes over time, as well as clearly outlining the hierarchical structure at each individual time step. Our method allows for smooth transitions between treemaps and nested streamgraphs, enabling the exploration of the trade-off between dynamic behavior and hierarchical structure. As our technique handles topological changes of all types, it is suitable for a wide range of applications. We demonstrate the utility of our method on several use cases, evaluate it with a user study, and provide its full source code.",Fabian Bolte;Mahsan Nourani;Eric D. Ragan;Stefan Bruckner,Fabian Bolte;Mahsan Nourani;Eric D. Ragan;Stefan Bruckner,"Department of Informatics, University of Bergen, Bergen, Norway;Department of Computer & Information Science & Engineering, University of Florida, Gainesville, FL, USA;Department of Computer & Information Science & Engineering, University of Florida, Gainesville, FL, USA;Department of Informatics, University of Bergen, Bergen, Norway",0.1109/tvcg.2011.239;10.1109/tvcg.2012.225;10.1109/tvcg.2011.185;10.1109/tvcg.2013.196;10.1109/tvcg.2012.212;10.1109/tvcg.2018.2796591;10.1109/tvcg.2018.2865265;10.1109/visual.1991.175815;10.1109/tvcg.2007.70529;10.1109/tvcg.2013.162;10.1109/tvcg.2012.108;10.1109/tvcg.2014.2346433;10.1109/tvcg.2017.2745140;10.1109/tvcg.2007.70568;10.1109/tvcg.2008.166,"Visualization,hierarchy data,time-varying data,streamgraphs,treemaps",,5,39,558,,
TVCG,2019,SolarView: Low Distortion Radial Embedding with a Focus,10.1109/tvcg.2018.2865361,http://dx.doi.org/10.1109/TVCG.2018.2865361,2969,2982,J,"We propose a novel type of low distortion radial embedding which focuses on one specific entity and its closest neighbors. Our embedding preserves near-exact distances to the focus entity and aims to minimize distortion between the other entities. We present an interactive exploration tool SolarView which places the focus entity at the center of a “solar system” and embeds its neighbors guided by concentric circles. SolarView provides an implementation of our novel embedding and several state-of-the-art dimensionality reduction and embedding techniques, which we adapted to our setting in various ways. We experimentally evaluated our embedding and compared it to these state-of-the-art techniques. The results show that our embedding competes with these techniques and achieves low distortion in practice. Our method performs particularly well when the visualization, and hence the embedding, adheres to the solar system design principle of our application. Nonetheless-as with all dimensionality reduction techniques-the distortion may be high. We leverage interaction techniques to give clear visual cues that allow users to accurately judge distortion. We illustrate the use of SolarView by exploring the high-dimensional metric space of bibliographic entity similarities.",Thom Castermans;Kevin Verbeek;Bettina Speckmann;Michel A. Westenberg;Rob Koopman;Shenghui Wang 0001;Hein van den Berg;Arianna Betti,Thom Castermans;Kevin Verbeek;Bettina Speckmann;Michel A. Westenberg;Rob Koopman;Shenghui Wang;Hein van den Berg;Arianna Betti,"TU Eindhoven, Eindhoven, AZ, Netherlands;TU Eindhoven, Eindhoven, AZ, Netherlands;TU Eindhoven, Eindhoven, AZ, Netherlands;TU Eindhoven, Eindhoven, AZ, Netherlands;OCLC, Leiden, XA, Netherlands;OCLC, Leiden, XA, Netherlands;University of Amsterdam, Amsterdam, WX, Netherlands;University of Amsterdam, Amsterdam, WX, Netherlands",0.1109/infvis.1998.729559;10.1109/tvcg.2015.2467717;10.1109/tvcg.2014.2330617;10.1109/tvcg.2017.2745141;10.1109/infvis.2001.963287;10.1109/tvcg.2015.2467618;10.1109/tvcg.2007.70539;10.1109/tvcg.2013.124;10.1109/visual.1994.346302,"Dimensionality reduction,radial embedding,visualizing distortion",,4,39,506,,
TVCG,2020,Eiffel: Evolutionary Flow Map for Influence Graph Visualization,10.1109/tvcg.2019.2906900,http://dx.doi.org/10.1109/TVCG.2019.2906900,2944,2960,J,"The visualization of evolutionary influence graphs is important for performing many real-life tasks such as citation analysis and social influence analysis. The main challenges include how to summarize large-scale, complex, and time-evolving influence graphs, and how to design effective visual metaphors and dynamic representation methods to illustrate influence patterns over time. In this work, we present Eiffel, an integrated visual analytics system that applies triple summarizations on evolutionary influence graphs in the nodal, relational, and temporal dimensions. In numerical experiments, Eiffel summarization results outperformed those of traditional clustering algorithms with respect to the influence-flow-based objective. Moreover, a flow map representation is proposed and adapted to the case of influence graph summarization, which supports two modes of evolutionary visualization (i.e., flip-book and movie) to expedite the analysis of influence graph dynamics. We conducted two controlled user experiments to evaluate our technique on influence graph summarization and visualization respectively. We also showcased the system in the evolutionary influence analysis of two typical scenarios, the citation influence of scientific papers and the social influence of emerging online events. The evaluation results demonstrate the value of Eiffel in the visual analysis of evolutionary influence graphs.",Yucheng Huang;Lei Shi 0002;Yue Su;Yifan Hu 0001;Hanghang Tong;Chaoli Wang 0001;Tong Yang 0003;Deyun Wang;Shuo Liang,Yucheng Huang;Lei Shi;Yue Su;Yifan Hu;Hanghang Tong;Chaoli Wang;Tong Yang;Deyun Wang;Shuo Liang,"State Key Laboratory of Computer Science, Institute of Software, Chinese Academy of Sciences, Beijing, China;Beijing Advanced Innovation Center for Big Data and Brain Computing, School of Computer Science and Engineering, Beihang University, Beijing, China;State Key Laboratory of Computer Science, Institute of Software, Chinese Academy of Sciences and UCAS, Beijing, China;Yahoo Labs, New York, USA;School of Computing, Informatics, Decision Systems Engineering, Arizona State University, Tempe, USA;Department of Computer Science & Engineering, University of Notre Dame, Notre Dame, USA;Department of Computer Science, Peking University, Beijing, China;State Key Laboratory of Computer Science, Institute of Software, Chinese Academy of Sciences and UCAS, Beijing, China;Academy of Arts & Design, Tsinghua University, Beijing, China",0.1109/tvcg.2009.143;10.1109/vast.2016.7883510;10.1109/tvcg.2012.291;10.1109/tvcg.2015.2467621;10.1109/tvcg.2006.120;10.1109/vast.2007.4389006;10.1109/tvcg.2008.125,"Influence graph,dynamic visualization,citation analysis",,5,58,851,,
TVCG,2021,ProReveal: Progressive Visual Analytics With Safeguards,10.1109/tvcg.2019.2962404,http://dx.doi.org/10.1109/TVCG.2019.2962404,3109,3122,J,"We present a new visual exploration concept - Progressive Visual Analytics with Safeguards - that helps people manage the uncertainty arising from progressive data exploration. Despite its potential benefits, intermediate knowledge from progressive analytics can be incorrect due to various machine and human factors, such as a sampling bias or misinterpretation of uncertainty. To alleviate this problem, we introduce PVA-Guards, safeguards people can leave on uncertain intermediate knowledge that needs to be verified, and derive seven PVA-Guards based on previous visualization task taxonomies. PVA-Guards provide a means of ensuring the correctness of the conclusion and understanding the reason when intermediate knowledge becomes invalid. We also present ProReveal, a proof-of-concept system designed and developed to integrate the seven safeguards into progressive data exploration. Finally, we report a user study with 14 participants, which shows people voluntarily employed PVA-Guards to safeguard their findings and ProReveal's PVA-Guard view provides an overview of uncertain intermediate knowledge. We believe our new concept can also offer better consistency in progressive data exploration, alleviating people's heterogeneous interpretation of uncertainty.",Jaemin Jo;Sehi L'Yi;Bongshin Lee;Jinwook Seo,Jaemin Jo;Sehi L’Yi;Bongshin Lee;Jinwook Seo,"Department of Computer Science and Engineering, Seoul National University, Seoul, Republic of Korea;Department of Computer Science and Engineering, Seoul National University, Seoul, Republic of Korea;Microsoft Research, Redmond, WA, USA;Department of Computer Science and Engineering, Seoul National University, Seoul, Republic of Korea",0.1109/tvcg.2014.2346298;10.1109/tvcg.2014.2346574;10.1109/tvcg.2017.2744358;10.1109/tvcg.2016.2598470;10.1109/tvcg.2015.2462356;10.1109/tvcg.2014.2346578;10.1109/tvcg.2011.185;10.1109/tvcg.2015.2467191,"Progressive visual analytics,intermediate knowledge representation,hypothesis testing,scalability,uncertainty",,5,51,1282,,
TVCG,2018,An Analysis of Automated Visual Analysis Classification: Interactive Visualization Task Inference of Cancer Genomics Domain Experts,10.1109/tvcg.2017.2734659,http://dx.doi.org/10.1109/TVCG.2017.2734659,2270,2283,J,"We show how mouse interaction log classification can help visualization toolsmiths understand how their tools are used “in the wild” through an evaluation of MAGI - a cancer genomics visualization tool. Our primary contribution is an evaluation of twelve visual analysis task classifiers, which compares predictions to task inferences made by pairs of genomics and visualization experts. Our evaluation uses common classifiers that are accessible to most visualization evaluators: k-nearest neighbors, linear support vector machines, and random forests. By comparing classifier predictions to visual analysis task inferences made by experts, we show that simple automated task classification can have up to 73 percent accuracy and can separate meaningful logs from “junk” logs with up to 91 percent accuracy. Our second contribution is an exploration of common MAGI interaction trends using classification predictions, which expands current knowledge about ecological cancer genomics visualization tasks. Our third contribution is a discussion of how automated task classification can inform iterative tool design. These contributions suggest that mouse interaction log analysis is a viable method for (1) evaluating task requirements of client-side-focused tools, (2) allowing researchers to study experts on larger scales than is typically possible with in-lab observation, and (3) highlighting potential tool evaluation bias.",Connor Gramazio;Jeff Huang 0002;David H. Laidlaw,Connor C. Gramazio;Jeff Huang;David H. Laidlaw,"Department of Computer Science, Brown University, Providence, RI;Department of Computer Science, Brown University, Providence, RI;Department of Computer Science, Brown University, Providence, RI",0.1109/tvcg.2013.124;10.1109/tvcg.2011.108;10.1109/tvcg.2014.2346575;10.1109/vast.2008.4677365;10.1109/tvcg.2015.2467551;10.1109/tvcg.2015.2467871;10.1109/vast.2006.261421;10.1109/tvcg.2012.225;10.1109/vast.2014.7042487;10.1109/tvcg.2015.2467611;10.1109/vast.2014.7042482;10.1109/tvcg.2010.163;10.1109/tvcg.2014.2346431;10.1109/tvcg.2011.279;10.1109/tvcg.2015.2467613;10.1109/tvcg.2009.108,"Classification,task analysis,visual analysis,biology visualization,visualization,cancer genomics",,3,45,684,,
TVCG,2022,Words of Estimative Correlation: Studying Verbalizations of Scatterplots,10.1109/tvcg.2020.3023537,http://dx.doi.org/10.1109/TVCG.2020.3023537,1967,1981,J,"Natural language and visualization are being increasingly deployed together for supporting data analysis in different ways, from multimodal interaction to enriched data summaries and insights. Yet, researchers still lack systematic knowledge on how viewers verbalize their interpretations of visualizations, and how they interpret verbalizations of visualizations in such contexts. We describe two studies aimed at identifying characteristics of data and charts that are relevant in such tasks. The first study asks participants to verbalize what they see in scatterplots that depict various levels of correlations. The second study then asks participants to choose visualizations that match a given verbal description of correlation. We extract key concepts from responses, organize them in a taxonomy and analyze the categorized responses. We observe that participants use a wide range of vocabulary across all scatterplots, but particular concepts are preferred for higher levels of correlation. A comparison between the studies reveals the ambiguity of some of the concepts. We discuss how the results could inform the design of multimodal representations aligned with the data and analytical tasks, and present a research roadmap to deepen the understanding about visualizations and natural language.",Rafael Henkin;Cagatay Turkay,Rafael Henkin;Cagatay Turkay,"Centre for Translational Bioinformatics, Queen Mary, University of London, London, U.K.;Centre for Interdisciplinary Methodologies, University of Warwick, Coventry, U.K.",0.1109/tvcg.2016.2598862;10.1109/tvcg.2015.2467671;10.1109/tvcg.2019.2934668;10.1109/tvcg.2017.2744684;10.1109/infvis.2005.1532142;10.1109/tvcg.2017.2745219;10.1109/tvcg.2018.2865145;10.1109/tvcg.2014.2346979;10.1109/tvcg.2019.2917689,"Information visualization,natural language generation,natural language processing,human-computer interaction",,3,50,415,,
TVCG,2021,Visualization of 3D Stress Tensor Fields Using Superquadric Glyphs on Displacement Streamlines,10.1109/tvcg.2020.2968911,http://dx.doi.org/10.1109/TVCG.2020.2968911,3264,3276,J,"Stress tensor fields play a central role in solid mechanics studies, but their visualization in 3D space remains challenging as the information-dense multi-variate tensor needs to be sampled in 3D space while avoiding clutter. Taking cues from current tensor visualizations, we adapted glyph-based visualization for stress tensors in 3D space. We also developed a testing framework and performed user studies to evaluate the various glyph-based tensor visualizations for objective accuracy measures, and subjective user feedback for each visualization method. To represent the stress tensor, we color encoded the original superquadric glyph, and in the user study, we compared it to superquadric glyphs developed for second-order symmetric tensors. We found that color encoding improved the user accuracy measures, while the users also rated our method the highest. We compared our method of placing stress tensor glyphs on displacement streamlines to the glyph placement on a 3D grid. In the visualization, we modified the glyph to show both the stress tensor and the displacement vector at each sample point. The participants preferred our method of glyph placement on displacement streamlines as it highlighted the underlying continuous structure in the tensor field.",Mohak Patel;David H. Laidlaw,Mohak Patel;David H. Laidlaw,"Department of Computer Science, Brown University, Providence, RI, USA;Department of Computer Science, Brown University, Providence, RI, USA",0.1109/visual.1999.809894;10.1109/visual.1992.235193;10.1109/tvcg.2015.2467435;10.1109/tvcg.2010.199;10.1109/tvcg.2015.2467031;10.1109/visual.2004.80;10.1109/tvcg.2009.184;10.1109/tvcg.2016.2598998;10.1109/tvcg.2006.134,"3D stress tensor field,visualization,glyph,glyph placement,virtual reality,user study",,3,44,700,,
TVCG,2022,"Implicit Error, Uncertainty and Confidence in Visualization: An Archaeological Case Study",10.1109/tvcg.2021.3088339,http://dx.doi.org/10.1109/TVCG.2021.3088339,4389,4402,J,"While we know that the visualization of quantifiable uncertainty impacts the confidence in insights, little is known about whether the same is true for uncertainty that originates from aspects so inherent to the data that they can only be accounted for qualitatively. Being embedded within an archaeological project, we realized how assessing such qualitative uncertainty is crucial in gaining a holistic and accurate understanding of regional spatio-temporal patterns of human settlements over millennia. We therefore investigated the impact of visualizing qualitative implicit errors on the sense-making process via a probe that deliberately represented three distinct implicit errors, i.e., differing collection methods, subjectivity of data interpretations and assumptions on temporal continuity. By analyzing the interactions of 14 archaeologists with different levels of domain expertise, we discovered that novices became more actively aware of typically overlooked data issues and domain experts became more confident of the visualization itself. We observed how participants quoted social factors to alleviate some uncertainty, while in order to minimize it they requested additional contextual breadth or depth of the data. While our visualization did not alleviate all uncertainty, we recognized how it sparked reflective meta-insights regarding methodological directions of the data. We believe our findings inform future visualizations on how to handle the complexity of implicit errors for a range of user typologies and for highly data-critical application domains such as the digital humanities.",Georgia Panagiotidou;Ralf Vandam;Jeroen Poblome;Andrew Vande Moere,Georgia Panagiotidou;Ralf Vandam;Jeroen Poblome;Andrew Vande Moere,"RxD, KU Leuven, Leuven, Belgium;Sagalassos Archaeological Research Project, KU Leuven, Leuven, Belgium;Sagalassos Archaeological Research Project, KU Leuven, Leuven, Belgium;RxD, KU Leuven, Leuven, Belgium",0.1109/tvcg.2018.2865241;10.1109/tvcg.2018.2830759;10.1109/tvcg.2015.2467452;10.1109/tvcg.2012.279;10.1109/tvcg.2019.2934287;10.1109/tvcg.2013.132;10.1109/tvcg.2019.2934790;10.1109/tvcg.2008.121;10.1109/tvcg.2014.2346481;10.1109/tvcg.2015.2511718;10.1109/tvcg.2014.2346265;10.1109/tvcg.2018.2864913;10.1109/tvcg.2015.2467591;10.1109/tvcg.2016.2598544;10.1109/tvcg.2018.2864889;10.1109/tvcg.2020.3030426;10.1109/tvcg.2015.2467811,"Data uncertainty,data visualization,implicit error,qualitative study,digital humanities,design study,archaeology",,4,70,564,,
TVCG,2021,Integrated Dual Analysis of Quantitative and Qualitative High-Dimensional Data,10.1109/tvcg.2021.3056424,http://dx.doi.org/10.1109/TVCG.2021.3056424,2953,2966,J,"The Dual Analysis framework is a powerful enabling technology for the exploration of high dimensional quantitative data by treating data dimensions as first-class objects that can be explored in tandem with data values. In this article, we extend the Dual Analysis framework through the joint treatment of quantitative (numerical) and qualitative (categorical) dimensions. Computing common measures for all dimensions allows us to visualize both quantitative and qualitative dimensions in the same view. This enables a natural joint treatment of mixed data during interactive visual exploration and analysis. Several measures of variation for nominal qualitative data can also be applied to ordinal qualitative and quantitative data. For example, instead of measuring variability from a mean or median, other measures assess inter-data variation or average variation from a mode. In this work, we demonstrate how these measures can be integrated into the Dual Analysis framework to explore and generate hypotheses about high-dimensional mixed data. A medical case study using clinical routine data of patients suffering from Cerebral Small Vessel Disease (CSVD), conducted with a senior neurologist and a medical student, shows that a joint Dual Analysis approach for quantitative and qualitative data can rapidly lead to new insights based on which new hypotheses may be generated.",Juliane Müller 0003;Laura A. Garrison;Philipp Ulbrich;Stefanie Schreiber;Stefan Bruckner;Helwig Hauser;Steffen Oeltze-Jafra,Juliane Muller;Laura Garrison;Philipp Ulbrich;Stefanie Schreiber;Stefan Bruckner;Helwig Hauser;Steffen Oeltze-Jafra,"Department of Neurology, Otto von Guericke University Magdeburg, Magdeburg, Germany;Department of Informatics & Mohn Medical Imaging and Visualization Centre, Department of Radiology, Haukeland University Hospital, University of Bergen, Bergen, Norway;Department of Neurology, Center for Behavioral Brain Sciences, Otto von Guericke University Magdeburg, Magdeburg, Germany;Department of Neurology, Center for Behavioral Brain Sciences, Otto von Guericke University Magdeburg, Magdeburg, Germany;Department of Informatics & Mohn Medical Imaging and Visualization Centre, Department of Radiology, Haukeland University Hospital, University of Bergen, Bergen, Norway;Department of Informatics & Mohn Medical Imaging and Visualization Centre, Department of Radiology, Haukeland University Hospital, University of Bergen, Bergen, Norway;Department of Neurology, Center for Behavioral Brain Sciences, Otto von Guericke University Magdeburg, Magdeburg, Germany",0.1109/tvcg.2010.216;10.1109/tvcg.2013.122;10.1109/tvcg.2011.185;10.1109/tvcg.2007.70569;10.1109/mcg.2014.40;10.1109/tvcg.2015.2467931;10.1109/vast.2017.8585647;10.1109/tvcg.2014.2350494;10.1109/tvcg.2011.178;10.1109/tvcg.2012.110;10.1109/tvcg.2018.2864907,"Dual analysis approach,high-dimensional data,mixed data,mixed statistical analysis",,3,61,1044,,X
TVCG,2021,A Discrete Probabilistic Approach to Dense Flow Visualization,10.1109/tvcg.2020.3006995,http://dx.doi.org/10.1109/TVCG.2020.3006995,4347,4358,J,"Dense flow visualization is a popular visualization paradigm. Traditionally, the various models and methods in this area use a continuous formulation, resting upon the solid foundation of functional analysis. In this work, we examine a discrete formulation of dense flow visualization. From probability theory, we derive a similarity matrix that measures the similarity between different points in the flow domain, leading to the discovery of a whole new class of visualization models. Using this matrix, we propose a novel visualization approach consisting of the computation of spectral embeddings, i.e., characteristic domain maps, defined by particle mixture probabilities. These embeddings are scalar fields that give insight into the mixing processes of the flow on different scales. The approach of spectral embeddings is already well studied in image segmentation, and we see that spectral embeddings are connected to Fourier expansions and frequencies. We showcase the utility of our method using different 2D and 3D flows.",Daniel Preuß;Tino Weinkauf;Jens Harald Krüger,Daniel Preuß;Tino Weinkauf;Jens Krüger,"COVIDAG, the University of Duisburg-Essen, Duisburg, Germany;KTH Royal Institute of Technology, Stockholm, Sweden;COVIDAG, the University of Duisburg-Essen, Duisburg, Germany",0.1109/visual.1999.809865;10.1109/visual.1999.809863;10.1109/tvcg.2018.2856772;10.1109/tvcg.2011.25;10.1109/tvcg.2011.78;10.1109/visual.2001.964507;10.1109/tvcg.2013.229;10.1109/tvcg.2010.227;10.1109/tvcg.2012.170;10.1109/tvcg.2012.198;10.1109/visual.1999.809892;10.1109/visual.1994.346313;10.1109/visual.1997.663897,"Flow visualization,volume visualization,spectral methods",,2,57,422,,
TVCG,2020,Topic-Based Exploration and Embedded Visualizations for Research Idea Generation,10.1109/tvcg.2018.2873011,http://dx.doi.org/10.1109/TVCG.2018.2873011,1592,1607,J,"This work analyzes sensemaking frameworks and experiments with an iteratively designed visual analysis tool to identify design implications for facilitating research idea generation using visualizations. Our tool, ThoughtFlow, structures and visualizes literature collections using topic models to bridge the information gap between core activities during research ideation. To help users stay focused on a topic while discovering relevant documents, we designed and analyzed usage patterns for two types of embedded visualization that help determine document relevance while minimizing distraction. We analyzed how research ideation outcomes and processes differ when using ThoughtFlow and conventional search engines by augmenting insight-based evaluation with concept-map analysis. Our results suggest that operations afforded by topic models match well with later ideation stages when coherent topics have emerged, but not with early stages when users are still relying heavily on individual keywords to gather background knowledge. We also present qualitative evidence that citation sparklines encourage more exploration of recommended references, and that a preference for paper thumbnails may depend on the consistency between the evidence and the current mental frame.",Hua Guo;David H. Laidlaw,Hua Guo;David H. Laidlaw,"Brown University, Providence, USA;Brown University, Providence, USA",0.1109/tvcg.2014.2346452;10.1109/tvcg.2015.2467613;10.1109/vast.2011.6102461;10.1109/tvcg.2010.129;10.1109/tvcg.2015.2509990;10.1109/vast.2014.7042494;10.1109/tvcg.2013.212;10.1109/tvcg.2012.252;10.1109/tvcg.2015.2467757;10.1109/tvcg.2015.2467621;10.1109/tvcg.2011.239;10.1109/tvcg.2007.70515,"Visual analysis,empirical study,sensemaking,cognition",,3,42,874,,
TVCG,2022,Optimization and Augmentation for Data Parallel Contour Trees,10.1109/tvcg.2021.3064385,http://dx.doi.org/10.1109/TVCG.2021.3064385,3471,3485,J,"Contour trees are used for topological data analysis in scientific visualization. While originally computed with serial algorithms, recent work has introduced a vector-parallel algorithm. However, this algorithm is relatively slow for fully augmented contour trees which are needed for many practical data analysis tasks. We therefore introduce a representation called the hyperstructure that enables efficient searches through the contour tree and use it to construct a fully augmented contour tree in data parallel, with performance on average 6 times faster than the state-of-the-art parallel algorithm in the TTK topological toolkit.",Hamish A. Carr;Oliver Rübel;Gunther H. Weber;James P. Ahrens,Hamish A. Carr;Oliver Rübel;Gunther H. Weber;James P. Ahrens,"University of Leeds, Leeds, U.K.;Computational Research Division, Lawrence Berkeley National Laboratory, Berkeley, CA, USA;Computational Research Division, Lawrence Berkeley National Laboratory, Berkeley, CA, USA;Los Alamos National Laboratory, Livermore, NM, USA",0.1109/tvcg.2017.2743938;10.1109/mcg.2016.48;10.1109/visual.2004.96;10.1109/tvcg.2019.2934257;10.1109/visual.2002.1183812,"Computational topology,contour tree,parallel algorithms",,2,41,347,,
TVCG,2021,Unordered Task-Parallel Augmented Merge Tree Construction,10.1109/tvcg.2021.3076875,http://dx.doi.org/10.1109/TVCG.2021.3076875,3585,3596,J,"Contemporary scientific data sets require fast and scalable topological analysis to enable visualization, simplification and interaction. Within this field, parallel merge tree construction has seen abundant recent contributions, with a trend of decentralized, task-parallel or SMP-oriented algorithms dominating in terms of total runtime. However, none of these recent approaches computed complete merge trees on distributed systems, leaving this field to traditional divide & conquer approaches. This article introduces a scalable, parallel and distributed algorithm for merge tree construction outperforming the previously fastest distributed solution by a factor of around three. This is achieved by a task-parallel identification of individual merge tree arcs by growing regions around critical points in the data, without any need for ordered progression or global data structures, based on a novel insight introducing a sufficient local boundary for region growth.",Kilian Werner;Christoph Garth,Kilian Werner;Christoph Garth,"Scientific Visualization Lab, University of Kaiserslautern, Kaiserslautern, Germany;Scientific Visualization Lab, University of Kaiserslautern, Kaiserslautern, Germany",0.1109/tvcg.2007.70601;10.1109/visual.2004.96,"Scientific visualization,topological data analysis,task parallelism,distributed architecture",,1,41,753,,X
TVCG,2020,Embedding Meta Information into Visualizations,10.1109/tvcg.2019.2916098,http://dx.doi.org/10.1109/TVCG.2019.2916098,3189,3203,J,"In this work, we study how to co-locate meta information with visualizations by directly embedding information into visualizations. This allows for visualizations to carry provenance and authorship information themselves for reproducibility. We call these self-describing visualizations-reproducible, authenticatable, and documentable. Self-describing visualizations can be used to extend existing visualization provenance systems. Herein, we start with a survey of existing digital image watermarking literature. We search for and classify watermarking algorithms that can support scientific visualizations. Using our payload-resilience testing framework, we evaluate and recommend algorithms supporting various use cases in the payload-resiliency space, and present guidelines for optimizing visualizations to improve payload capacities and embedding robustness. We demonstrate the efficacy of self-describing visualizations with two sample application implementations: (1) adding an embedding filter as a part the standard rendering pipeline, (2) creating a web reader to automatically and reliably extract provenance information from scientific publications for review and dissemination.",Alok Hota;Jian Huang 0007,Alok Hota;Jian Huang,"Department of Electrical Engineering and Computer Science, University of Tennessee, Knoxville, TN, USA;Department of Electrical Engineering and Computer Science, University of Tennessee, Knoxville, TN, USA",0.1109/tvcg.2016.2599041;10.1109/infvis.2004.16;10.1109/tvcg.2015.2467551,"Scientific visualization,reproducibility,visualization systems,digital image watermarking",,1,76,651,,
TVCG,2021,MineTime Insight: Visualizing Meeting Habits to Promote Informed Scheduling Decisions,10.1109/tvcg.2019.2941208,http://dx.doi.org/10.1109/TVCG.2019.2941208,1986,1999,J,"Corporate meetings are a crucial part of business activities. While numerous academic papers investigated how to make the scheduling process of meetings faster or even automatic, little work has been done yet to facilitate the retrospective reasoning about how time is spent on meetings. Traditional calendar applications do not allow users to extract actionable statistics although it has been shown that reflection-oriented design can increase the users' understanding of their habits and can thereby encourage a shift towards better practices. In this paper, we present MineTime Insight, a tool made of multiple coordinated views for the exploration of personal calendar data, with the overarching goal of improving short and long-term scheduling decisions. Despite being focused on the working environment, our work builds upon recent results in the field of Personal Visual Analytics, as it targets users not necessarily expert in visualization and data analysis. We demonstrate the potential of MineTime Insight, when applied to the agenda of an executive manager. Finally, we discuss the results of an informal user study and a field study. Our results suggest that our visual representations are perceived as easy to understand and helpful towards a change in the scheduling habits.",Marco Ancona;Marilou Beyeler;Markus H. Gross;Tobias Günther,Marco Ancona;Marilou Beyeler;Markus Gross;Tobias Günther,"ETH Zurich, Zürich, Switzerland;ETH Zurich, Zürich, Switzerland;ETH Zurich, Zürich, Switzerland;ETH Zurich, Zürich, Switzerland",0.1109/tvcg.2016.2614803;10.1109/tvcg.2014.2359887;10.1109/tvcg.2007.70541;10.1109/tvcg.2014.2346298;10.1109/tvcg.2007.70535,"Scheduling,calendar,personal visual analytics,casual information visualization,virtual assistant",,1,53,576,,
TVCG,2019,Visualization and Visual Analysis of Ensemble Data: A Survey,10.1109/tvcg.2018.2853721,http://dx.doi.org/10.1109/TVCG.2018.2853721,2853,2872,J,"Over the last decade, ensemble visualization has witnessed a significant development due to the wide availability of ensemble data, and the increasing visualization needs from a variety of disciplines. From the data analysis point of view, it can be observed that many ensemble visualization works focus on the same facet of ensemble data, use similar data aggregation or uncertainty modeling methods. However, the lack of reflections on those essential commonalities and a systematic overview of those works prevents visualization researchers from effectively identifying new or unsolved problems and planning for further developments. In this paper, we take a holistic perspective and provide a survey of ensemble visualization. Specifically, we study ensemble visualization works in the recent decade, and categorize them from two perspectives: (1) their proposed visualization techniques; and (2) their involved analytic tasks. For the first perspective, we focus on elaborating how conventional visualization techniques (e.g., surface, volume visualization techniques) have been adapted to ensemble data; for the second perspective, we emphasize how analytic tasks (e.g., comparison, clustering) have been performed differently for ensemble data. From the study of ensemble visualization literature, we have also identified several research trends, as well as some future research opportunities.",Junpeng Wang;Subhashis Hazarika;Cheng Li;Han-Wei Shen,Junpeng Wang;Subhashis Hazarika;Cheng Li;Han-Wei Shen,"Department of Computer Science and Engineering, The Ohio State University, Columbus, OH, USA;Department of Computer Science and Engineering, The Ohio State University, Columbus, OH, USA;Department of Computer Science and Engineering, The Ohio State University, Columbus, OH, USA;Department of Computer Science and Engineering, The Ohio State University, Columbus, OH, USA",0.1109/tvcg.2016.2598870;10.1109/tvcg.2014.2346755;10.1109/tvcg.2012.110;10.1109/tvcg.2015.2467198;10.1109/tvcg.2009.155;10.1109/tvcg.2016.2607204;10.1109/tvcg.2016.2598830;10.1109/tvcg.2011.203;10.1109/tvcg.2016.2637333;10.1109/tvcg.2010.171;10.1109/tvcg.2016.2598869;10.1109/tvcg.2014.2346455;10.1109/tvcg.2015.2467204;10.1109/tvcg.2013.141;10.1109/tvcg.2013.143;10.1109/scivis.2015.7429487;10.1109/tvcg.2010.181;10.1109/tvcg.2013.208;10.1109/tvcg.2015.2467958;10.1109/visual.2003.1250412;10.1109/tvcg.2014.2346448;10.1109/tvcg.2010.111;10.1109/vast.2015.7347634;10.1109/mcg.2015.70;10.1109/tvcg.2013.144;10.1109/tvcg.2013.138;10.1109/visual.2001.964550;10.1109/tvcg.2013.92;10.1109/tvcg.2017.2743989;10.1109/tvcg.2014.2346321;10.1109/tvcg.2013.147;10.1109/tvcg.2017.2744099;10.1109/tvcg.2010.190;10.1109/tvcg.2016.2598868;10.1109/tvcg.2015.2498554;10.1109/vast.2015.7347635;10.1109/tvcg.2014.2346744;10.1109/tvcg.2015.2468093;10.1109/tvcg.2017.2745178,"Ensemble data,visualization and visual analysis,literature analysis,taxonomy",,88,120,3069,,
TVCG,2020,t-viSNE: Interactive Assessment and Interpretation of t-SNE Projections,10.1109/tvcg.2020.2986996,http://dx.doi.org/10.1109/TVCG.2020.2986996,2696,2714,J,"t-Distributed Stochastic Neighbor Embedding (t-SNE) for the visualization of multidimensional data has proven to be a popular approach, with successful applications in a wide range of domains. Despite their usefulness, t-SNE projections can be hard to interpret or even misleading, which hurts the trustworthiness of the results. Understanding the details of t-SNE itself and the reasons behind specific patterns in its output may be a daunting task, especially for non-experts in dimensionality reduction. In this article, we present t-viSNE, an interactive tool for the visual exploration of t-SNE projections that enables analysts to inspect different aspects of their accuracy and meaning, such as the effects of hyper-parameters, distance and neighborhood preservation, densities and costs of specific neighborhoods, and the correlations between dimensions and visual patterns. We propose a coherent, accessible, and well-integrated collection of different views for the visualization of t-SNE projections. The applicability and usability of t-viSNE are demonstrated through hypothetical usage scenarios with real data sets. Finally, we present the results of a user study where the tool's effectiveness was evaluated. By bringing to light information that would normally be lost after running t-SNE, we hope to support analysts in using t-SNE and making its results better understandable.",Angelos Chatzimparmpas;Rafael Messias Martins;Andreas Kerren,Angelos Chatzimparmpas;Rafael M. Martins;Andreas Kerren,"Department of Computer Science and Media Technology, Linnaeus University, Växjö, Sweden;Department of Computer Science and Media Technology, Linnaeus University, Växjö, Sweden;Department of Computer Science and Media Technology, Linnaeus University, Växjö, Sweden",0.1109/infvis.1998.729559;10.1109/vast.2012.6400487;10.1109/tvcg.2015.2467717;10.1109/tvcg.2018.2864812;10.1109/tvcg.2018.2865146;10.1109/tvcg.2018.2864477;10.1109/tvcg.2017.2745085;10.1109/visual.1990.146402;10.1109/vast.2010.5652885;10.1109/tvcg.2016.2598495;10.1109/tvcg.2018.2846735;10.1109/tvcg.2011.220;10.1109/tvcg.2018.2865047;10.1109/tvcg.2018.2865194;10.1109/tvcg.2015.2467615;10.1109/tvcg.2016.2598446;10.1109/tvcg.2019.2934251,"Interpretable t-SNE,dimensionality reduction,high-dimensional data,explainable machine learning,visualization",,83,81,2326,,X
TVCG,2020,TTHRESH: Tensor Compression for Multidimensional Visual Data,10.1109/tvcg.2019.2904063,http://dx.doi.org/10.1109/TVCG.2019.2904063,2891,2903,J,"Memory and network bandwidth are decisive bottlenecks when handling high-resolution multidimensional data sets in visualization applications, and they increasingly demand suitable data compression strategies. We introduce a novel lossy compression algorithm for multidimensional data over regular grids. It leverages the higher-order singular-value decomposition (HOSVD), a generalization of the SVD to three dimensions and higher, together with bit-plane, run-length and arithmetic coding to compress the HOSVD transform coefficients. Our scheme degrades the data particularly smoothly and achieves lower mean squared error than other state-of-the-art algorithms at low-to-medium bit rates, as it is required in data archiving and management for visualization purposes. Further advantages of the proposed algorithm include very fine bit rate selection granularity and the ability to manipulate data at very small cost in the compression domain, for example to reconstruct filtered and/or subsampled versions of all (or selected parts) of the data set.",Rafael Ballester-Ripoll;Peter Lindstrom 0001;Renato Pajarola,Rafael Ballester-Ripoll;Peter Lindstrom;Renato Pajarola,"Department of Informatics, University of Zürich, Zürich, Switzerland;Lawrence Livermore National Laboratory, Center for Applied Scientific Computing, Livermore, USA;Department of Informatics, University of Zürich, Zürich, Switzerland",0.1109/visual.2001.964531;10.1109/visual.2002.1183757;10.1109/tvcg.2014.2346458;10.1109/tvcg.2011.214;10.1109/tvcg.2018.2802521,"Transform-based compression,scientific visualization,higher-order singular value decomposition,Tucker model,tensor decompositions",,73,45,1328,,
TVCG,2020,"A Visual Analytics System for Exploring, Monitoring, and Forecasting Road Traffic Congestion",10.1109/tvcg.2019.2922597,http://dx.doi.org/10.1109/TVCG.2019.2922597,3133,3146,J,"We present an interactive visual analytics system that enables traffic congestion exploration, surveillance, and forecasting based on vehicle detector data. Through domain expert collaboration, we have extracted task requirements, incorporated the Long Short-Term Memory (LSTM) model for congestion forecasting, and designed a weighting method for detecting the causes of congestion and congestion propagation directions. Our visual analytics system is designed to enable users to explore congestion causes, directions, and severity. Congestion conditions of a city are visualized using a Volume-Speed Rivers (VSRivers) visualization that simultaneously presents traffic volumes and speeds. To evaluate our system, we report performance comparison results, wherein our model is more accurate than other forecasting algorithms. We demonstrate the usefulness of our system in the traffic management and congestion broadcasting domains through three case studies and domain expert feedback.",Chunggi Lee;Yeonjun Kim;Seungmin Jin;Dongmin Kim;Ross Maciejewski;David S. Ebert;Sungahn Ko,Chunggi Lee;Yeonjun Kim;Seungmin Jin;Dongmin Kim;Ross Maciejewski;David Ebert;Sungahn Ko,UNIST;UNIST;UNIST;UNIST;Arizona State University;Purdue University;UNIST,0.1109/tvcg.2015.2467591;10.1109/tvcg.2015.2440259;10.1109/tvcg.2015.2467592;10.1109/tvcg.2016.2535234;10.1109/tvcg.2013.226;10.1109/tvcg.2014.2346893;10.1109/vast.2015.7347630;10.1109/tvcg.2013.228;10.1109/vast.2012.6400556;10.1109/vast.2014.7042486;10.1109/tvcg.2014.2346746,"Traffic,road,congestion,visualization,deep learning,LSTM,surveillance,forecasting,predictive analysis",,58,62,3216,,
TVCG,2020,ScatterNet: A Deep Subjective Similarity Model for Visual Analysis of Scatterplots,10.1109/tvcg.2018.2875702,http://dx.doi.org/10.1109/TVCG.2018.2875702,1562,1576,J,"Similarity measuring methods are widely adopted in a broad range of visualization applications. In this work, we address the challenge of representing human perception in the visual analysis of scatterplots by introducing a novel deep-learning-based approach, ScatterNet, captures perception-driven similarities of such plots. The approach exploits deep neural networks to extract semantic features of scatterplot images for similarity calculation. We create a large labeled dataset consisting of similar and dissimilar images of scatterplots to train the deep neural network. We conduct a set of evaluations including performance experiments and a user study to demonstrate the effectiveness and efficiency of our approach. The evaluations confirm that the learned features capture the human perception of scatterplot similarity effectively. We describe two scenarios to show how ScatterNet can be applied in visual analysis applications.",Yuxin Ma;Anthony K. H. Tung;Wei Wang 0059;Xiang Gao;Zhigeng Pan;Wei Chen 0001,Yuxin Ma;Anthony K. H. Tung;Wei Wang;Xiang Gao;Zhigeng Pan;Wei Chen,"State Key Lab of CAD&CG, Zhejiang University, Hangzhou, China;National University of Singapore, Singapore;National University of Singapore, Singapore;Hangzhou Normal University, Yuhang, China;Hangzhou Normal University, Yuhang, China;State Key Lab of CAD&CG, Zhejiang University, Hangzhou, China",0.1109/tvcg.2014.2346978;10.1109/vast.2011.6102437;10.1109/vast.2015.7347683;10.1109/vast.2006.261423;10.1109/tvcg.2009.153;10.1109/tvcg.2015.2467196;10.1109/tvcg.2014.2346922;10.1109/tvcg.2010.184;10.1109/tvcg.2016.2598467;10.1109/tvcg.2011.229;10.1109/vast.2016.7883519;10.1109/tvcg.2015.2467153;10.1109/tvcg.2014.2346594;10.1109/tvcg.2013.181;10.1109/tvcg.2013.224;10.1109/tvcg.2012.258;10.1109/tvcg.2017.2744098;10.1109/tvcg.2012.275;10.1109/tvcg.2015.2467671;10.1109/tvcg.2012.128;10.1109/tvcg.2014.2346572;10.1109/vast.2014.7042480;10.1109/tvcg.2015.2467323;10.1109/infvis.2005.1532142;10.1109/tvcg.2014.2346979,"Scatterplot,similarity measuring,deep learning,visualization,visual exploration",,44,62,1960,,
TVCG,2021,OoDAnalyzer: Interactive Analysis of Out-of-Distribution Samples,10.1109/tvcg.2020.2973258,http://dx.doi.org/10.1109/TVCG.2020.2973258,3335,3349,J,"One major cause of performance degradation in predictive models is that the test samples are not well covered by the training data. Such not well-represented samples are called OoD samples. In this article, we propose OoDAnalyzer, a visual analysis approach for interactively identifying OoD samples and explaining them in context. Our approach integrates an ensemble OoD detection method and a grid-based visualization. The detection method is improved from deep ensembles by combining more features with algorithms in the same family. To better analyze and understand the OoD samples in context, we have developed a novel kNN-based grid layout algorithm motivated by Hall's theorem. The algorithm approximates the optimal layout and has O(kN2)O(kN2) time complexity, faster than the grid layout algorithm with overall best performance but O(N3)O(N3) time complexity. Quantitative evaluation and case studies were performed on several datasets to demonstrate the effectiveness and usefulness of OoDAnalyzer.",Changjian Chen;Jun Yuan 0003;Yafeng Lu;Yang Liu 0014;Hang Su 0006;Songtao Yuan;Shixia Liu,Changjian Chen;Jun Yuan;Yafeng Lu;Yang Liu;Hang Su;Songtao Yuan;Shixia Liu,"Department of Computer Science & Technology, BNRist, School of Software, Tsinghua University, Haidian, Beijing, China;Department of Computer Science & Technology, BNRist, School of Software, Tsinghua University, Haidian, Beijing, China;BloombergL.P, New York, NY, USA;Microsoft Research Asia, Haidian, Beijing, China;Department of Computer Science & Technology, BNRist, School of Software, Tsinghua University, Haidian, Beijing, China;First Affiliated Hospital of Nanjing Medical University, Nanjing, China;Department of Computer Science & Technology, BNRist, School of Software, Tsinghua University, Haidian, Beijing, China",0.1109/tvcg.2017.2744199;10.1109/tvcg.2016.2598831;10.1109/tvcg.2019.2921323;10.1109/tvcg.2017.2744685;10.1109/tvcg.2017.2744419;10.1109/tvcg.2018.2864843;10.1109/tvcg.2018.2865026;10.1109/tvcg.2018.2834341;10.1109/vast47406.2019.8986943;10.1109/tvcg.2015.2467251;10.1109/tvcg.2017.2744938;10.1109/tvcg.2015.2467991;10.1109/tvcg.2018.2864844;10.1109/tvcg.2016.2598664;10.1109/tvcg.2014.2346922;10.1109/tvcg.2015.2467196;10.1109/tvcg.2012.245,"Out-of-Distribution detection,grid layout,interactive visualization",,41,67,2342,,
TVCG,2020,FlowNet: A Deep Learning Framework for Clustering and Selection of Streamlines and Stream Surfaces,10.1109/tvcg.2018.2880207,http://dx.doi.org/10.1109/TVCG.2018.2880207,1732,1744,J,"For effective flow visualization, identifying representative flow lines or surfaces is an important problem which has been studied. However, no work can solve the problem for both lines and surfaces. In this paper, we present FlowNet, a single deep learning framework for clustering and selection of streamlines and stream surfaces. Given a collection of streamlines or stream surfaces generated from a flow field data set, our approach converts them into binary volumes and then employs an autoencoder to learn their respective latent feature descriptors. These descriptors are used to reconstruct binary volumes for error estimation and network training. Once converged, the feature descriptors can well represent flow lines or surfaces in the latent space. We perform dimensionality reduction of these feature descriptors and cluster the projection results accordingly. This leads to a visual interface for exploring the collection of flow lines or surfaces via clustering, filtering, and selection of representatives. Intuitive user interactions are provided for visual reasoning of the collection with ease. We validate and explain our deep learning framework from multiple perspectives, demonstrate the effectiveness of FlowNet using several flow field data sets of different characteristics, and compare our approach against state-of-the-art streamline and stream surface selection algorithms.",Jun Han 0010;Jun Tao 0002;Chaoli Wang 0001,Jun Han;Jun Tao;Chaoli Wang,"Department of Computer Science and Engineering, University of Notre Dame, Notre Dame, USA;Department of Computer Science and Engineering, University of Notre Dame, Notre Dame, USA;Department of Computer Science and Engineering, University of Notre Dame, Notre Dame, USA",0.1109/visual.1993.398877;10.1109/tvcg.2008.163;10.1109/tvcg.2011.155;10.1109/tvcg.2013.2297914;10.1109/tvcg.2011.78;10.1109/tvcg.2014.2346416;10.1109/tvcg.2010.212;10.1109/tvcg.2010.131,"Flow visualization,streamlines,stream surfaces,deep learning,autoencoder,feature descriptor,clustering,selection",,34,43,1841,,
TVCG,2019,Graph Drawing by Stochastic Gradient Descent,10.1109/tvcg.2018.2859997,http://dx.doi.org/10.1109/TVCG.2018.2859997,2738,2748,J,"A popular method of force-directed graph drawing is multidimensional scaling using graph-theoretic distances as input. We present an algorithm to minimize its energy function, known as stress, by using stochastic gradient descent (SGD) to move a single pair of vertices at a time. Our results show that SGD can reach lower stress levels faster and more consistently than majorization, without needing help from a good initialization. We then show how the unique properties of SGD make it easier to produce constrained layouts than previous approaches. We also show how SGD can be directly applied within the sparse stress approximation of Ortmann et al. [1], making the algorithm scalable up to large graphs.",Jonathan X. Zheng;Samraat Pawar;Dan F. M. Goodman,Jonathan X. Zheng;Samraat Pawar;Dan F. M. Goodman,"Department of Electrical and Electronic Engineering, Imperial College London, London, United Kingdom;Department of Life Sciences, Imperial College London, Ascot, United Kingdom;Department of Electrical and Electronic Engineering, Imperial College London, London, United Kingdom",0.1109/tvcg.2011.185,"Graph drawing,multidimensional scaling,constraints,relaxation,stochastic gradient descent",,39,34,1268,,
TVCG,2021,Constructing Spaces and Times for Tactical Analysis in Football,10.1109/tvcg.2019.2952129,http://dx.doi.org/10.1109/TVCG.2019.2952129,2280,2297,J,"A possible objective in analyzing trajectories of multiple simultaneously moving objects, such as football players during a game, is to extract and understand the general patterns of coordinated movement in different classes of situations as they develop. For achieving this objective, we propose an approach that includes a combination of query techniques for flexible selection of episodes of situation development, a method for dynamic aggregation of data from selected groups of episodes, and a data structure for representing the aggregates that enables their exploration and use in further analysis. The aggregation, which is meant to abstract general movement patterns, involves construction of new time-homomorphic reference systems owing to iterative application of aggregation operators to a sequence of data selections. As similar patterns may occur at different spatial locations, we also propose constructing new spatial reference systems for aligning and matching movements irrespective of their absolute locations. The approach was tested in application to tracking data from two Bundesliga games of the 2018/2019 season. It enabled detection of interesting and meaningful general patterns of team behaviors in three classes of situations defined by football experts. The experts found the approach and the underlying concepts worth implementing in tools for football analysts.",Gennady L. Andrienko;Natalia V. Andrienko;Gabriel Anzer;Pascal Bauer;Guido Budziak;Georg Fuchs;Dirk Hecker;Hendrik Weber;Stefan Wrobel,Gennady Andrienko;Natalia Andrienko;Gabriel Anzer;Pascal Bauer;Guido Budziak;Georg Fuchs;Dirk Hecker;Hendrik Weber;Stefan Wrobel,"Fraunhofer IAIS, Sankt Augustin, Germany;Fraunhofer IAIS, Sankt Augustin, Germany;Sportec Solutions GmbH, Köln, Germany;DFB Akademie, Frankfurt, Germany;TU Eindhoven, Eindhoven, AZ, The Netherlands;Fraunhofer IAIS, Sankt Augustin, Germany;Fraunhofer IAIS, Sankt Augustin, Germany;DFL Deutsche Fussball Liga GmbH, Frankfurt, Germany;Fraunhofer IAIS, Sankt Augustin, Germany",0.1109/mcg.2016.102;10.1109/tvcg.2017.2745181;10.1109/tvcg.2013.192;10.1109/tvcg.2018.2889054;10.1109/visual.1991.175794;10.1109/tvcg.2017.2744322;10.1109/vast.2008.4677356;10.1109/tvcg.2018.2865041;10.1109/tvcg.2013.193;10.1109/tvcg.2018.2864811,"Visual analytics,movement data,coordinated movement,sport analytics,football,soccer",,39,57,2072,,
TVCG,2020,The Curse of Knowledge in Visual Data Communication,10.1109/tvcg.2019.2917689,http://dx.doi.org/10.1109/TVCG.2019.2917689,3051,3062,J,"A viewer can extract many potential patterns from any set of visualized data values. But that means that two people can see different patterns in the same visualization, potentially leading to miscommunication. Here, we show that when people are primed to see one pattern in the data as visually salient, they believe that naïve viewers will experience the same visual salience. Participants were told one of multiple backstories about political events that affected public polling data, before viewing a graph that depicted those data. One pattern in the data was particularly visually salient to them given the backstory that they heard. They then predicted what naïve viewers would most visually salient on the visualization. They were strongly influenced by their own knowledge, despite explicit instructions to ignore it, predicting that others would find the same patterns to be most visually salient. This result reflects a psychological phenomenon known as the curse of knowledge, where an expert struggles to re-create the state of mind of a novice. The present findings show that the curse of knowledge also plagues the visual perception of data, explaining why people can fail to connect with audiences when they communicate patterns in data.",Cindy Xiong;Lisanne van Weelden;Steven Franconeri,Cindy Xiong;Lisanne Van Weelden;Steven Franconeri,"Northwestern University, Evanston, USA;Utrecht University, Utrecht, Netherlands;Northwestern University, Evanston, USA",0.1109/tvcg.2010.179;10.1109/tvcg.2012.221;10.1109/tvcg.2014.2346419;10.1109/vast.2017.8585665;10.1109/tvcg.2018.2865233;10.1109/tvcg.2016.2598594;10.1109/tvcg.2012.197;10.1109/tvcg.2013.234;10.1109/tvcg.2015.2467732;10.1109/tvcg.2017.2744138;10.1109/tvcg.2011.255;10.1109/infvis.2003.1249031;10.1109/tvcg.2011.175,"Cognitive biases,data communication,expertise,information visualization,perception and cognition",,45,47,2231,,
TVCG,2019,COPE: Interactive Exploration of Co-Occurrence Patterns in Spatial Time Series,10.1109/tvcg.2018.2851227,http://dx.doi.org/10.1109/TVCG.2018.2851227,2554,2567,J,"Spatial time series is a common type of data dealt with in many domains, such as economic statistics and environmental science. There have been many studies focusing on finding and analyzing various kinds of events in time series; the term `event' refers to significant changes or occurrences of particular patterns formed by consecutive attribute values. We focus on a further step in event analysis: discover temporal relationship patterns between event locations, i.e., repeated cases when there is a specific temporal relationship (same time, before, or after) between events occurring at two locations. This can provide important clues for understanding the formation and spreading mechanisms of events and interdependencies among spatial locations. We propose a visual exploration framework COPE (Co-Occurrence Pattern Exploration), which allows users to extract events of interest from data and detect various co-occurrence patterns among them. Case studies and expert reviews were conducted to verify the effectiveness and scalability of COPE using two real-world datasets.",Jie Li 0006;Siming Chen 0001;Kang Zhang 0001;Gennady L. Andrienko;Natalia V. Andrienko,Jie Li;Siming Chen;Kang Zhang;Gennady Andrienko;Natalia Andrienko,"School of Computer Software, Tianjin University, China;Fraunhofer Institute IAIS, Rhein-Sieg, North Rhine-Westphalia, Germany;University of Texas, Dallas, TX, USA;City University, London, UK;City University, London, UK",0.1109/tvcg.2015.2468111;10.1109/vast.2012.6400553;10.1109/vast.2014.7042489;10.1109/tvcg.2015.2468078;10.1109/vast.2016.7883512;10.1109/tvcg.2012.265;10.1109/tvcg.2017.2744686;10.1109/tvcg.2015.2467194;10.1109/tvcg.2015.2467851;10.1109/tvcg.2013.200;10.1109/tvcg.2017.2745278;10.1109/tvcg.2015.2505305;10.1109/tvcg.2015.2467619;10.1109/vast.2014.7042488;10.1109/tvcg.2007.70523,"Co-occurrence patterns,spatiotemporal visualization,spatial time series,visual analytics",,35,60,1517,,
TVCG,2021,DPVis: Visual Analytics With Hidden Markov Models for Disease Progression Pathways,10.1109/tvcg.2020.2985689,http://dx.doi.org/10.1109/TVCG.2020.2985689,3685,3700,J,"Clinical researchers use disease progression models to understand patient status and characterize progression patterns from longitudinal health records. One approach for disease progression modeling is to describe patient status using a small number of states that represent distinctive distributions over a set of observed measures. Hidden Markov models (HMMs) and its variants are a class of models that both discover these states and make inferences of health states for patients. Despite the advantages of using the algorithms for discovering interesting patterns, it still remains challenging for medical experts to interpret model outputs, understand complex modeling parameters, and clinically make sense of the patterns. To tackle these problems, we conducted a design study with clinical scientists, statisticians, and visualization experts, with the goal to investigate disease progression pathways of chronic diseases, namely type 1 diabetes (T1D), Huntington's disease, Parkinson's disease, and chronic obstructive pulmonary disease (COPD). As a result, we introduce DPVis which seamlessly integrates model parameters and outcomes of HMMs into interpretable and interactive visualizations. In this article, we demonstrate that DPVis is successful in evaluating disease progression models, visually summarizing disease states, interactively exploring disease progression patterns, and building, analyzing, and comparing clinically relevant patient subgroups.",Bum Chul Kwon;Vibha Anand;Kristen A. Severson;Soumya Ghosh;Zhaonan Sun;Brigitte I. Frohnert;Markus Lundgren;Kenney Ng,Bum Chul Kwon;Vibha Anand;Kristen A. Severson;Soumya Ghosh;Zhaonan Sun;Brigitte I. Frohnert;Markus Lundgren;Kenney Ng,"IBM Research, Cambridge, NY, USA;IBM Research, Cambridge, NY, USA;IBM Research, Cambridge, NY, USA;IBM Research, Cambridge, NY, USA;IBM Research, Cambridge, NY, USA;University of Colorado Denver, Denver, CO, USA;Department of Clinical Sciences Malmö, Lund University, Lund, Sweden;IBM Research, Cambridge, NY, USA",0.1109/tvcg.2009.187;10.1109/tvcg.2018.2865076;10.1109/tvcg.2012.225;10.1109/tvcg.2017.2745085;10.1109/tvcg.2018.2865027;10.1109/tvcg.2015.2467622;10.1109/tvcg.2014.2346591;10.1109/tvcg.2018.2864886;10.1109/tvcg.2015.2467555;10.1109/tvcg.2016.2598446;10.1109/tvcg.2015.2467591;10.1109/tvcg.2014.2346574;10.1109/mcg.2014.40;10.1109/tvcg.2017.2745320;10.1109/tvcg.2018.2864885;10.1109/tvcg.2019.2934790;10.1109/tvcg.2019.2934609;10.1109/vast.2015.7347682;10.1109/tvcg.2018.2865043;10.1109/tvcg.2016.2598469;10.1109/tvcg.2015.2467733;10.1109/tvcg.2017.2745118;10.1109/tvcg.2014.2346682;10.1109/tvcg.2019.2934661;10.1109/tvcg.2018.2803829;10.1109/tvcg.2017.2745278;10.1109/tvcg.2017.2745083;10.1109/tvcg.2013.200;10.1109/tvcg.2015.2467325;10.1109/tvcg.2016.2598797;10.1109/tvcg.2018.2817557,"Disease progression,hidden markov model,state space model,diabetes,huntington's,parkinson's,interpretability",,31,78,1180,,
TVCG,2021,"Tilt Map: Interactive Transitions Between Choropleth Map, Prism Map and Bar Chart in Immersive Environments",10.1109/tvcg.2020.3004137,http://dx.doi.org/10.1109/TVCG.2020.3004137,4507,4519,J,"We introduce Tilt Map, a novel interaction technique for intuitively transitioning between 2D and 3D map visualisations in immersive environments. Our focus is visualising data associated with areal features on maps, for example, population density by state. Tilt Map transitions from 2D choropleth maps to 3D prism maps to 2D bar charts to overcome the limitations of each. Our article includes two user studies. The first study compares subjects’ task performance interpreting population density data using 2D choropleth maps and 3D prism maps in virtual reality (VR). We observed greater task accuracy with prism maps, but faster response times with choropleth maps. The complementarity of these views inspired our hybrid Tilt Map design. Our second study compares Tilt Map to: a side-by-side arrangement of the various views; and interactive toggling between views. The results indicate benefits for Tilt Map in user preference; and accuracy (versus side-by-side) and time (versus toggle).",Yalong Yang 0001;Tim Dwyer;Kim Marriott;Bernhard Jenny;Sarah Goodwin,Yalong Yang;Tim Dwyer;Kim Marriott;Bernhard Jenny;Sarah Goodwin,"School of Engineering and Applied Sciences, Harvard University, Cambridge, MA, USA;Department of Human-Centred Computing, Faculty of Information Technology, Monash University, Clayton, VIC, Australia;Department of Human-Centred Computing, Faculty of Information Technology, Monash University, Clayton, VIC, Australia;Department of Human-Centred Computing, Faculty of Information Technology, Monash University, Clayton, VIC, Australia;Department of Human-Centred Computing, Faculty of Information Technology, Monash University, Clayton, VIC, Australia",0.1109/tvcg.2013.130;10.1109/tvcg.2016.2598885;10.1109/tvcg.2015.2467951;10.1109/tvcg.2016.2598862;10.1109/tvcg.2007.70539;10.1109/tvcg.2018.2865192;10.1109/tvcg.2013.166;10.1109/tvcg.2019.2934415;10.1109/tvcg.2008.165,"Immersive analytics,mixed / augmented reality,virtual reality,geographic visualization,interaction techniques",,34,49,1303,,
TVCG,2021,VRIA: A Web-Based Framework for Creating Immersive Analytics Experiences,10.1109/tvcg.2020.2965109,http://dx.doi.org/10.1109/TVCG.2020.2965109,3213,3225,J,"We present VRIA, a Web-based framework for creating Immersive Analytics (IA) experiences in Virtual Reality. VRIA is built upon WebVR, A-Frame, React and D3.js, and offers a visualization creation workflow which enables users, of different levels of expertise, to rapidly develop Immersive Analytics experiences for the Web. The use of these open-standards Web-based technologies allows us to implement VR experiences in a browser and offers strong synergies with popular visualization libraries, through the HTML Document Object Model (DOM). This makes VRIA ubiquitous and platform-independent. Moreover, by using WebVR's progressive enhancement, the experiences VRIA creates are accessible on a plethora of devices. We elaborate on our motivation for focusing on open-standards Web technologies, present the VRIA creation workflow and detail the underlying mechanics of our framework. We also report on techniques and optimizations necessary for implementing Immersive Analytics experiences on the Web, discuss scalability implications of our framework, and present a series of use case applications to demonstrate the various features of VRIA. Finally, we discuss current limitations of our framework, the lessons learned from its development, and outline further extensions.",Peter W. S. Butcher;Nigel W. John;Panagiotis D. Ritsos,Peter W. S. Butcher;Nigel W. John;Panagiotis D. Ritsos,"Department of Computer Science, Chester University, Chester, United Kingdom;Department of Computer Science, Chester University, Chester, United Kingdom;School of Computer Science and Electronic Engineering, Bangor University, Bangor, United Kingdom",0.1109/tvcg.2018.2865191;10.1109/tvcg.2016.2599107;10.1109/tvcg.2017.2745941;10.1109/visual.2001.964545;10.1109/tvcg.2012.204;10.1109/tvcg.2016.2598608;10.1109/tvcg.2013.134;10.1109/tvcg.2011.185;10.1109/tvcg.2009.174;10.1109/tvcg.2015.2467091;10.1109/tvcg.2016.2599030;10.1109/tvcg.2018.2865144;10.1109/mcg.2014.82;10.1109/tvcg.2018.2865152;10.1109/infvis.2004.64,"Immersive analytics,virtual reality,web technologies",,33,53,1845,,
TVCG,2021,Interactive Steering of Hierarchical Clustering,10.1109/tvcg.2020.2995100,http://dx.doi.org/10.1109/TVCG.2020.2995100,3953,3967,J,"Hierarchical clustering is an important technique to organize big data for exploratory data analysis. However, existing one-size-fits-all hierarchical clustering methods often fail to meet the diverse needs of different users. To address this challenge, we present an interactive steering method to visually supervise constrained hierarchical clustering by utilizing both public knowledge (e.g., Wikipedia) and private knowledge from users. The novelty of our approach includes 1) automatically constructing constraints for hierarchical clustering using knowledge (knowledge-driven) and intrinsic data distribution (data-driven), and 2) enabling the interactive steering of clustering through a visual interface (user-driven). Our method first maps each data item to the most relevant items in a knowledge base. An initial constraint tree is then extracted using the ant colony optimization algorithm. The algorithm balances the tree width and depth and covers the data items with high confidence. Given the constraint tree, the data items are hierarchically clustered using evolutionary Bayesian rose tree. To clearly convey the hierarchical clustering results, an uncertainty-aware tree visualization has been developed to enable users to quickly locate the most uncertain sub-hierarchies and interactively improve them. The quantitative evaluation and case study demonstrate that the proposed approach facilitates the building of customized clustering trees in an efficient and effective manner.",Weikai Yang;Xiting Wang;Jie Lu;Wenwen Dou;Shixia Liu,Weikai Yang;Xiting Wang;Jie Lu;Wenwen Dou;Shixia Liu,"School of Software, BNRist, Tsinghua University, China;Microsoft Research, Beijing, China;School of Software, BNRist, Tsinghua University, China;University of North Carolina at Charlotte, Charlotte, NC, USA;School of Software, BNRist, Tsinghua University, China",0.1109/tvcg.2015.2509990;10.1109/tvcg.2014.2346433;10.1109/tvcg.2013.162;10.1109/vast.2007.4388999;10.1109/tvcg.2010.138;10.1109/tvcg.2011.188;10.1109/tvcg.2016.2598831;10.1109/tvcg.2017.2764895;10.1109/tvcg.2017.2744938;10.1109/tvcg.2017.2745085;10.1109/tvcg.2018.2834341;10.1109/tvcg.2018.2864477;10.1109/tvcg.2015.2424872,"Hierarchical clustering,constrained clustering,exploratory data analysis,tree visualization",,28,53,1583,,
TVCG,2020,Semantics-Space-Time Cube: A Conceptual Framework for Systematic Analysis of Texts in Space and Time,10.1109/tvcg.2018.2882449,http://dx.doi.org/10.1109/TVCG.2018.2882449,1789,1806,J,"We propose an approach to analyzing data in which texts are associated with spatial and temporal references with the aim to understand how the text semantics vary over space and time. To represent the semantics, we apply probabilistic topic modeling. After extracting a set of topics and representing the texts by vectors of topic weights, we aggregate the data into a data cube with the dimensions corresponding to the set of topics, the set of spatial locations (e.g., regions), and the time divided into suitable intervals according to the scale of the planned analysis. Each cube cell corresponds to a combination (topic, location, time interval) and contains aggregate measures characterizing the subset of the texts concerning this topic and having the spatial and temporal references within these location and interval. Based on this structure, we systematically describe the space of analysis tasks on exploring the interrelationships among the three heterogeneous information facets, semantics, space, and time. We introduce the operations of projecting and slicing the cube, which are used to decompose complex tasks into simpler subtasks. We then present a design of a visual analytics system intended to support these subtasks. To reduce the complexity of the user interface, we apply the principles of structural, visual, and operational uniformity while respecting the specific properties of each facet. The aggregated data are represented in three parallel views corresponding to the three facets and providing different complementary perspectives on the data. The views have similar look-and-feel to the extent allowed by the facet specifics. Uniform interactive operations applicable to any view support establishing links between the facets. The uniformity principle is also applied in supporting the projecting and slicing operations on the data cube. We evaluate the feasibility and utility of the approach by applying it in two analysis scenarios using geolocated social media data for studying people's reactions to social and natural events of different spatial and temporal scales.",Jie Li 0006;Siming Chen 0001;Wei Chen 0001;Gennady L. Andrienko;Natalia V. Andrienko,Jie Li;Siming Chen;Wei Chen;Gennady Andrienko;Natalia Andrienko,"College of Intelligence and Computing, Tianjin University, Tianjin, China;Fraunhofer Institute IAIS, Sankt Augustin, Germany;State Key Lab of Cad&CG, ZheJiang University, Hangzhou, P. R. China;Fraunhofer Institute IAIS, Sankt Augustin, Germany;Fraunhofer Institute IAIS, Sankt Augustin, Germany",0.1109/tvcg.2013.186;10.1109/vast.2011.6102488;10.1109/vast.2017.8585658;10.1109/tvcg.2012.291;10.1109/vast.2012.6400553;10.1109/tvcg.2012.233;10.1109/vast.2012.6400557;10.1109/vast.2012.6400485;10.1109/tvcg.2014.2346922;10.1109/tvcg.2015.2509990;10.1109/tvcg.2014.2329308;10.1109/tvcg.2013.179;10.1109/tvcg.2013.221;10.1109/tvcg.2014.2346919;10.1109/vast.2016.7883511;10.1109/tvcg.2013.162;10.1109/tvcg.2014.2346433;10.1109/infvis.2000.885098;10.1109/tvcg.2014.2346920;10.1109/tvcg.2013.212;10.1109/tvcg.2016.2598694;10.1109/tvcg.2016.2598624,"Spatiotemporal visualization,semantic visualization,data cube,interactive exploration,visual analytics",,27,62,1364,,
TVCG,2019,Shadow Accrual Maps: Efficient Accumulation of City-Scale Shadows Over Time,10.1109/tvcg.2018.2802945,http://dx.doi.org/10.1109/TVCG.2018.2802945,1559,1574,J,"Large scale shadows from buildings in a city play an important role in determining the environmental quality of public spaces. They can be both beneficial, such as for pedestrians during summer, and detrimental, by impacting vegetation and by blocking direct sunlight. Determining the effects of shadows requires the accumulation of shadows over time across different periods in a year. In this paper, we propose a simple yet efficient class of approach that uses the properties of sun movement to track the changing position of shadows within a fixed time interval. We use this approach to extend two commonly used shadow techniques, shadow maps and ray tracing, and demonstrate the efficiency of our approach. Our technique is used to develop an interactive visual analysis system, Shadow Profiler, targeted at city planners and architects that allows them to test the impact of shadows for different development scenarios. We validate the usefulness of this system through case studies set in Manhattan, a dense borough of New York City.",Fabio Miranda 0001;Harish Doraiswamy;Marcos Lage;Luc Wilson;Mondrian Hsieh;Cláudio T. Silva,Fabio Miranda;Harish Doraiswamy;Marcos Lage;Luc Wilson;Mondrian Hsieh;Cláudio T. Silva,"New York University, New York, NY;New York University, New York, NY;Universidade Federal Fluminense, Niteroi, Rio de Janeiro, Brazil;Kohn Pedersen Fox Associates PC, New York, NY;Kohn Pedersen Fox Associates PC, New York, NY;New York University, New York, NY",0.1109/tvcg.2016.2520920;10.1109/tvcg.2014.2346893;10.1109/tvcg.2013.228;10.1109/vast.2008.4677356;10.1109/tvcg.2007.70523;10.1109/tvcg.2014.2346898;10.1109/tvcg.2007.70574;10.1109/tvcg.2013.226,"Shadow accumulation,shadow accrual maps,visual analysis,urban development",,26,69,817,,
TVCG,2020,Edit Distance between Merge Trees,10.1109/tvcg.2018.2873612,http://dx.doi.org/10.1109/TVCG.2018.2873612,1518,1531,J,"Topological structures such as the merge tree provide an abstract and succinct representation of scalar fields. They facilitate effective visualization and interactive exploration of feature-rich data. A merge tree captures the topology of sub-level and super-level sets in a scalar field. Estimating the similarity between merge trees is an important problem with applications to feature-directed visualization of time-varying data. We present an approach based on tree edit distance to compare merge trees. The comparison measure satisfies metric properties, it can be computed efficiently, and the cost model for the edit operations is both intuitive and captures well-known properties of merge trees. Experimental results on time-varying scalar fields, 3D cryo electron microscopy data, shape data, and various synthetic datasets show the utility of the edit distance towards a feature-driven analysis of scalar fields.",Raghavendra Sridharamurthy;Talha Bin Masood;Adhitya Kamakshidasan;Vijay Natarajan,Raghavendra Sridharamurthy;Talha Bin Masood;Adhitya Kamakshidasan;Vijay Natarajan,"Department of Computer Science and Automation, Indian Institute of Science, Bangalore, India;Department of Computer Science and Automation, Indian Institute of Science, Bangalore, India;Department of Computer Science and Automation, Indian Institute of Science, Bangalore, India;Department of Computer Science and Automation, Indian Institute of Science, Bangalore, India",0.1109/tvcg.2008.163;10.1109/tvcg.2006.165;10.1109/tvcg.2014.2346448;10.1109/tvcg.2011.236;10.1109/tvcg.2013.148;10.1109/tvcg.2014.2346332;10.1109/tvcg.2010.198;10.1109/tvcg.2012.115;10.1109/tvcg.2017.2743938,"Merge tree,scalar field,distance measure,persistence,edit distance",,26,50,948,,
TVCG,2022,SSR-TVD: Spatial Super-Resolution for Time-Varying Data Analysis and Visualization,10.1109/tvcg.2020.3032123,http://dx.doi.org/10.1109/TVCG.2020.3032123,2445,2456,J,"We present SSR-TVD, a novel deep learning framework that produces coherent spatial super-resolution (SSR) of time-varying data (TVD) using adversarial learning. In scientific visualization, SSR-TVD is the first work that applies the generative adversarial network (GAN) to generate high-resolution volumes for three-dimensional time-varying data sets. The design of SSR-TVD includes a generator and two discriminators (spatial and temporal discriminators). The generator takes a low-resolution volume as input and outputs a synthesized high-resolution volume. To capture spatial and temporal coherence in the volume sequence, the two discriminators take the synthesized high-resolution volume(s) as input and produce a score indicating the realness of the volume(s). Our method can work in the in situ visualization setting by downscaling volumetric data from selected time steps as the simulation runs and upscaling downsampled volumes to their original resolution during postprocessing. To demonstrate the effectiveness of SSR-TVD, we show quantitative and qualitative results with several time-varying data sets of different characteristics and compare our method against volume upscaling using bicubic interpolation and a solution solely based on CNN.",Jun Han 0010;Chaoli Wang 0001,Jun Han;Chaoli Wang,"Department of Computer Science and Engineering, University of Notre Dame, Notre Dame, IN, USA;Department of Computer Science and Engineering, University of Notre Dame, Notre Dame, IN, USA",0.1109/tvcg.2020.3030346;10.1109/tvcg.2018.2816059;10.1109/mcg.2018.2881523;10.1109/tvcg.2019.2956697,"Time-varying data visualization,deep learning,super-resolution,generative adversarial network",,24,48,848,,
TVCG,2019,Measuring and Modeling the Feature Detection Threshold Functions of Colormaps,10.1109/tvcg.2018.2855742,http://dx.doi.org/10.1109/TVCG.2018.2855742,2777,2790,J,"Pseudocoloring is one of the most common techniques used in scientific visualization. To apply pseudocoloring to a scalar field, the field value at each point is represented using one of a sequence of colors (called a colormap). One of the principles applied in generating colormaps is uniformity and previously the main method for determining uniformity has been the application of uniform color spaces. In this paper we present a new method for evaluating the feature detection threshold function across a colormap. The method is used in crowdsourced studies for the direct evaluation of nine colormaps for three feature sizes. The results are used to test the hypothesis that a uniform color space (CIELAB) will accurately model colormapped feature detection thresholds compared to a model where the chromaticity components have reduced weights. The hypothesis that feature detection can be predicted solely on the basis of luminance is also tested. The results reject both hypotheses and we demonstrate how reduced weights on the green-red and blue-yellow terms of the CIELAB color space creates a more accurate model when the task is the detection of smaller features in colormapped data. Both the method itself and modified CIELAB can be used in colormap design and evaluation.",Colin Ware;Terece L. Turton;Roxana Bujack;Francesca Samsel;Piyush Shrivastava;David H. Rogers 0001,Colin Ware;Terece L. Turton;Roxana Bujack;Francesca Samsel;Piyush Shrivastava;David H. Rogers,"University of New Hampshire, Durham, NH, USA;Los Alamos National Laboratory, Los Alamos, NM, USA;Los Alamos National Laboratory, Los Alamos, NM, USA;Center for Agile Technology, University of Texas at Austin, Austin, TX, USA;University of New Hampshire, Durham, NH, USA;Los Alamos National Laboratory, Los Alamos, NM, USA",0.1109/tvcg.2016.2599106;10.1109/tvcg.2017.2744359;10.1109/tvcg.2017.2743978;10.1109/visual.2002.1183788;10.1109/visual.1995.480803;10.1109/visual.2001.964510,"Colormapping,color perception",,25,62,2163,,
TVCG,2019,Smart Brushing for Parallel Coordinates,10.1109/tvcg.2018.2808969,http://dx.doi.org/10.1109/TVCG.2018.2808969,1575,1590,J,"The Parallel Coordinates plot is a popular tool for the visualization of high-dimensional data. One of the main challenges when using parallel coordinates is occlusion and overplotting resulting from large data sets. Brushing is a popular approach to address these challenges. Since its conception, limited improvements have been made to brushing both in the form of visual design and functional interaction. We present a set of novel, smart brushing techniques that enhance the standard interactive brushing of a parallel coordinates plot. We introduce two new interaction concepts: Higher-order, sketch-based brushing, and smart, data-driven brushing. Higher-order brushes support interactive, flexible, n-dimensional pattern searches involving an arbitrary number of dimensions. Smart, data-driven brushing provides interactive, real-time guidance to the user during the brushing process based on derived meta-data. In addition, we implement a selection of novel enhancements and user options that complement the two techniques as well as enhance the exploration and analytical ability of the user. We demonstrate the utility and evaluate the results using a case study with a large, high-dimensional, real-world telecommunication data set and we report domain expert feedback from the data suppliers.",Richard C. Roberts;Robert S. Laramee;Gary A. Smith;Paul Brookes;Tony D'Cruze,Richard C. Roberts;Robert S. Laramee;Gary A. Smith;Paul Brookes;Tony D'Cruze,"Department of Computer Science, Swansea University, Swansea, Wales;Department of Computer Science, Swansea University, Swansea, Wales;QPC Ltd, Mold, United Kingdom;QPC Ltd, Mold, United Kingdom;QPC Ltd, Mold, United Kingdom",0.1109/vast.2006.261452;10.1109/visual.1994.346302;10.1109/tvcg.2015.2466992;10.1109/visual.1995.485139;10.1109/tvcg.2010.176;10.1109/infvis.2002.1173157;10.1109/tvcg.2011.166;10.1109/tvcg.2015.2467872,"Multivariate visualization,parallel coordinates,call center,glyph,brushing,interaction techniques",,23,50,931,,
TVCG,2021,Analyzing the Noise Robustness of Deep Neural Networks,10.1109/tvcg.2020.2969185,http://dx.doi.org/10.1109/TVCG.2020.2969185,3289,3304,J,"Adversarial examples, generated by adding small but intentionally imperceptible perturbations to normal examples, can mislead deep neural networks (DNNs) to make incorrect predictions. Although much work has been done on both adversarial attack and defense, a fine-grained understanding of adversarial examples is still lacking. To address this issue, we present a visual analysis method to explain why adversarial examples are misclassified. The key is to compare and analyze the datapaths of both the adversarial and normal examples. A datapath is a group of critical neurons along with their connections. We formulate the datapath extraction as a subset selection problem and solve it by constructing and training a neural network. A multi-level visualization consisting of a network-level visualization of data flows, a layer-level visualization of feature maps, and a neuron-level visualization of learned features, has been designed to help investigate how datapaths of adversarial and normal examples diverge and merge in the prediction process. A quantitative evaluation and a case study were conducted to demonstrate the promise of our method to explain the misclassification of adversarial examples.",Kelei Cao;Mengchen Liu;Hang Su 0006;Jing Wu 0004;Jun Zhu 0001;Shixia Liu,Kelei Cao;Mengchen Liu;Hang Su;Jing Wu;Jun Zhu;Shixia Liu,"School of Software, BNRist, Tsinghua University, Beijing, China;Microsoft, Redmond, WA, USA;Department of Computer Science and Technology, Institute for AI, THBI Lab, Tsinghua University, Beijing, China;Cardiff University, Cardiff, United Kingdom;Department of Computer Science and Technology, Institute for AI, THBI Lab, Tsinghua University, Beijing, China;School of Software, BNRist, Tsinghua University, Beijing, China",0.1109/tvcg.2016.2598838;10.1109/tvcg.2017.2744878;10.1109/tvcg.2016.2598831;10.1109/tvcg.2017.2744718;10.1109/tvcg.2019.2934631;10.1109/tvcg.2018.2864504;10.1109/tvcg.2018.2864500;10.1109/tvcg.2018.2843369;10.1109/tvcg.2017.2744683;10.1109/tvcg.2017.2744158;10.1109/vast.2017.8585721;10.1109/tvcg.2018.2865044;10.1109/tvcg.2018.2865027;10.1109/tvcg.2017.2744938;10.1109/tvcg.2016.2598496;10.1109/vast.2018.8802509;10.1109/tvcg.2017.2744358;10.1109/tvcg.2011.239;10.1109/tvcg.2017.2744378;10.1109/tvcg.2017.2744199;10.1109/tvcg.2015.2467618,"Robustness,deep neural networks,adversarial examples,explainable machine learning",,17,55,1923,,
TVCG,2021,Interactive Graph Construction for Graph-Based Semi-Supervised Learning,10.1109/tvcg.2021.3084694,http://dx.doi.org/10.1109/TVCG.2021.3084694,3701,3716,J,"Semi-supervised learning (SSL) provides a way to improve the performance of prediction models (e.g., classifier) via the usage of unlabeled samples. An effective and widely used method is to construct a graph that describes the relationship between labeled and unlabeled samples. Practical experience indicates that graph quality significantly affects the model performance. In this paper, we present a visual analysis method that interactively constructs a high-quality graph for better model performance. In particular, we propose an interactive graph construction method based on the large margin principle. We have developed a river visualization and a hybrid visualization that combines a scatterplot, a node-link diagram, and a bar chart to convey the label propagation of graph-based SSL. Based on the understanding of the propagation, a user can select regions of interest to inspect and modify the graph. We conducted two case studies to showcase how our method facilitates the exploitation of labeled and unlabeled samples for improving model performance.",Changjian Chen;Zhaowei Wang;Jing Wu 0004;Xiting Wang;Lan-Zhe Guo;Yufeng Li 0008;Shixia Liu,Changjian Chen;Zhaowei Wang;Jing Wu;Xiting Wang;Lan-Zhe Guo;Yu-Feng Li;Shixia Liu,"School of Software, BNRist, Tsinghua University, Beijing, China;School of Software, BNRist, Tsinghua University, Beijing, China;Cardiff University, Cardiff, U.K.;Microsoft Research Asia, Beijing, China;Nanjing University, Nanjing, Jiangsu, China;Nanjing University, Nanjing, Jiangsu, China;School of Software, BNRist, Tsinghua University, Beijing, China",0.1109/tvcg.2014.2346919;10.1109/tvcg.2015.2509990;10.1109/tvcg.2011.239;10.1109/tvcg.2007.70589;10.1109/tvcg.2019.2934266;10.1109/vast47406.2019.8986917;10.1109/vast47406.2019.8986940;10.1109/tvcg.2017.2744818;10.1109/tvcg.2011.190;10.1109/tvcg.2020.3030432;10.1109/tvcg.2017.2711030;10.1109/vast.2016.7883508;10.1109/tvcg.2013.164;10.1109/vast.2017.8585484;10.1109/tvcg.2018.2864843;10.1109/vast47406.2019.8986943;10.1109/tvcg.2012.279;10.1109/tvcg.2013.212;10.1109/tvcg.2016.2598838,"Semi-supervised learning,unlabeled samples,graph quality",,20,67,2140,,X
TVCG,2019,An Exploratory Framework for Cyclone Identification and Tracking,10.1109/tvcg.2018.2810068,http://dx.doi.org/10.1109/TVCG.2018.2810068,1460,1473,J,"Analyzing depressions plays an important role in meteorology, especially in the study of cyclones. In particular, the study of the temporal evolution of cyclones requires a robust depression tracking framework. To cope with this demand we propose a pipeline for the exploration of cyclones and their temporal evolution. This entails a generic framework for their identification and tracking. The fact that depressions and cyclones are not well-defined objects and their shape and size characteristics change over time makes this task especially challenging. Our method combines the robustness of topological approaches and the detailed tracking information from optical flow analysis. At first cyclones are identified within each time step based on well-established topological concepts. Then candidate tracks are computed from an optical flow field. These tracks are clustered within a moving time window to distill dominant coherent cyclone movements, which are then forwarded to a final tracking step. In contrast to previous methods our method requires only a few intuitive parameters. An integration into an exploratory framework helps in the study of cyclone movement by identifying smooth, representative tracks. Multiple case studies demonstrate the effectiveness of the method in tracking cyclones, both in the northern and southern hemisphere.",Akash Anil Valsangkar;Joy Merwin Monteiro;Vidya Narayanan 0001;Ingrid Hotz;Vijay Natarajan,Akash Anil Valsangkar;Joy Merwin Monteiro;Vidya Narayanan;Ingrid Hotz;Vijay Natarajan,"Department of Computer Science and Automation, Indian Institute of Science, Bangalore, India;Department of Meteorology, Stockholm University, Stockholm, Sweden;Computer Science Department, Carnegie Mellon University, Pittsburgh, PA;Department of Science and Technology, Linkoping University, Linkoping, Sweden;Department of Computer Science and Automation, Indian Institute of Science, Bangalore, India",0.1109/tvcg.2013.131;10.1109/tvcg.2011.269,"Cyclone,scalar field,time-varying data,track graph,spatio-temporal clustering,tracking",,19,29,652,,
TVCG,2019,Exploration Strategies for Discovery of Interactivity in Visualizations,10.1109/tvcg.2018.2802520,http://dx.doi.org/10.1109/TVCG.2018.2802520,1407,1420,J,"We investigate how people discover the functionality of an interactive visualization that was designed for the general public. While interactive visualizations are increasingly available for public use, we still know little about how the general public discovers what they can do with these visualizations and what interactions are available. Developing a better understanding of this discovery process can help inform the design of visualizations for the general public, which in turn can help make data more accessible. To unpack this problem, we conducted a lab study in which participants were free to use their own methods to discover the functionality of a connected set of interactive visualizations of public energy data. We collected eye movement data and interaction logs as well as video and audio recordings. By analyzing this combined data, we extract exploration strategies that the participants employed to discover the functionality in these interactive visualizations. These exploration strategies illuminate possible design directions for improving the discoverability of a visualization's functionality.",Tanja Blascheck;Lindsay MacDonald Vermeulen;Jo Vermeulen;Charles Perin;Wesley Willett;Thomas Ertl;Sheelagh Carpendale,Tanja Blascheck;Lindsay MacDonald Vermeulen;Jo Vermeulen;Charles Perin;Wesley Willett;Thomas Ertl;Sheelagh Carpendale,"University of Stuttgart, Stuttgart, Germany;Alexandra Institute, Aarhus N, Denmark;Aarhus University, Aarhus N, Denmark;University of Calgary, Calgary, AB, Canada;University of Calgary, Calgary, AB, Canada;University of Stuttgart, Stuttgart, Germany;University of Calgary, Calgary, AB, Canada",0.1109/tvcg.2007.70589;10.1109/tvcg.2015.2467613;10.1109/tvcg.2015.2467732;10.1109/tvcg.2014.2346420;10.1109/tvcg.2012.229;10.1109/mcg.2016.90;10.1109/tvcg.2015.2467325;10.1109/tvcg.2011.193;10.1109/tvcg.2010.179;10.1109/tvcg.2014.2346984;10.1109/tvcg.2013.119;10.1109/tvcg.2007.70577;10.1109/tvcg.2015.2467201;10.1109/tvcg.2014.2346250;10.1109/tvcg.2015.2467871,"Discovery,visualization,open data,evaluation,eye tracking,interaction logs,think-aloud",,22,77,1768,,
TVCG,2020,Hyper-Objective Vortices,10.1109/tvcg.2018.2868760,http://dx.doi.org/10.1109/TVCG.2018.2868760,1532,1547,J,"Almost all properties of vector fields, including magnitude, direction, λ2 and vorticity change under arbitrary movements of the observer. This is undesirable since measurements of physical properties should ideally not depend on the way the (virtual) measurement device moves. There are some properties that are invariant under certain types of reference frame transformations: Galilean invariance (invariance under equal-speed translation) and objectivity (invariance under any smooth rotation and translation of the reference frame). In this paper, we introduce even harder conditions than objectivity: we demand invariance under any smooth similarity transformation (rotation, translation and uniform scale) as well as invariance under any smooth affine transformation of the reference frame. We show that these new hyper-objective measures allow the extraction of vortices that change their volume or deform. Further, we present a generic approach that transforms almost any vortex measure into a hyper-objective one. We apply our methods to vortex extraction in 2D and 3D vector fields, and analyze the numerical robustness, extraction time and the minimization residuals for the Galilean invariant, objective, and the two new hyper-objective approaches.",Tobias Günther;Holger Theisel,Tobias Günther;Holger Theisel,"Computer Graphics Laboratory, ETH Zürich, Zürich, Switzerland;Visual Computing Group, University of Magdeburg, Magdeburg, Germany",0.1109/tvcg.2015.2467200;10.1109/visual.1998.745296;10.1109/visual.1999.809896;10.1109/tvcg.2007.70545;10.1109/tvcg.2011.249;10.1109/tvcg.2014.2346415,"Flow visualization,vortex extraction,objectivity,affine invariance",,19,49,350,,
TVCG,2020,Multimodal Analysis of Video Collections: Visual Exploration of Presentation Techniques in TED Talks,10.1109/tvcg.2018.2889081,http://dx.doi.org/10.1109/TVCG.2018.2889081,2429,2442,J,"While much research in the educational field has revealed many presentation techniques, they often overlap and are even occasionally contradictory. Exploring presentation techniques used in TED Talks could provide evidence for a practical guideline. This study aims to explore the verbal and non-verbal presentation techniques from a collection of TED Talks. However, such analysis is challenging due to the difficulties of analyzing multimodal video collections consisted of frame images, text, and metadata. This paper proposes a visual analytic system to analyze multimodal content in video collections. The system features three views at different levels: the Projection view with novel glyphs to facilitate cluster analysis regarding presentation styles; the Comparison View to present temporal distribution and concurrences of presentation techniques and support intra-cluster analysis; and the Video View to enable contextualized exploration of a video. We conduct a case study with language education experts and university students to provide anecdotal evidence about the effectiveness of our approach, and report new findings about presentation techniques in TED Talks. Quantitative feedback from a user study confirms the usefulness of our visual system for multimodal analysis of video collections.",Aoyu Wu;Huamin Qu,Aoyu Wu;Huamin Qu,"Hong Kong University of Science and Technology, Hong Kong, China;Hong Kong University of Science and Technology, Hong Kong, China",0.1109/tvcg.2017.2744118;10.1109/tvcg.2017.2745181;10.1109/tvcg.2013.192;10.1109/tvcg.2016.2598586;10.1109/tvcg.2013.265,"Visual analytics,multimedia visualization,multimodal analysis",,19,42,1756,,
TVCG,2021,Visualization of Blockchain Data: A Systematic Review,10.1109/tvcg.2019.2963018,http://dx.doi.org/10.1109/TVCG.2019.2963018,3135,3152,J,"We present a systematic review of visual analytics tools used for the analysis of blockchains-related data. The blockchain concept has recently received considerable attention and spurred applications in a variety of domains. We systematically and quantitatively assessed 76 analytics tools that have been proposed in research as well as online by professionals and blockchain enthusiasts. Our classification of these tools distinguishes (1) target blockchains, (2) blockchain data, (3) target audiences, (4) task domains, and (5) visualization types. Furthermore, we look at which aspects of blockchain data have already been explored and point out areas that deserve more investigation in the future.",Natkamon Tovanich;Nicolas Heulot;Jean-Daniel Fekete;Petra Isenberg,Natkamon Tovanich;Nicolas Heulot;Jean-Daniel Fekete;Petra Isenberg,"IRT SystemX, Paris-Saclay, Palaiseau, France;IRT SystemX, Paris-Saclay, Palaiseau, France;Inria, Rocquencourt, France;Inria, Rocquencourt, France",0.1109/tvcg.2018.2864814;10.1109/tvcg.2007.70541;10.1109/tvcg.2017.2744199;10.1109/vast.2010.5652896;10.1109/tvcg.2014.2346574;10.1109/tvcg.2012.279,"Blockchain,bitcoin,ethereum,information visualization,visual analytics,state-of-the-art survey",,22,126,2210,,
TVCG,2020,LDA Ensembles for Interactive Exploration and Categorization of Behaviors,10.1109/tvcg.2019.2904069,http://dx.doi.org/10.1109/TVCG.2019.2904069,2775,2792,J,"We define behavior as a set of actions performed by some actor during a period of time. We consider the problem of analyzing a large collection of behaviors by multiple actors, more specifically, identifying typical behaviors and spotting anomalous behaviors. We propose an approach leveraging topic modeling techniques - LDA (Latent Dirichlet Allocation) Ensembles - to represent categories of typical behaviors by topics that are obtained through topic modeling a behavior collection. When such methods are applied to text in natural languages, the quality of the extracted topics are usually judged based on the semantic relatedness of the terms pertinent to the topics. This criterion, however, is not necessarily applicable to topics extracted from non-textual data, such as action sets, since relationships between actions may not be obvious. We have developed a suite of visual and interactive techniques supporting the construction of an appropriate combination of topics based on other criteria, such as distinctiveness and coverage of the behavior set. Two case studies on analyzing operation behaviors in the security management system and visiting behaviors in an amusement park, and the expert evaluation of the first case study demonstrate the effectiveness of our approach.",Siming Chen 0001;Natalia V. Andrienko;Gennady L. Andrienko;Linara Adilova;Jérémie Barlet;Jörg Kindermann;Phong H. Nguyen;Olivier Thonnard;Cagatay Turkay,Siming Chen;Natalia Andrienko;Gennady Andrienko;Linara Adilova;Jeremie Barlet;Jörg Kindermann;Phong H. Nguyen;Olivier Thonnard;Cagatay Turkay,"Fraunhofer Institute IAIS, Sankt Augustin, Germany;Fraunhofer Institute IAIS, Sankt Augustin, Germany;Fraunhofer Institute IAIS, Sankt Augustin, Germany;Fraunhofer Institute IAIS, Sankt Augustin, Germany;Amadeus, Nice, France;Fraunhofer Institute IAIS, Sankt Augustin, Germany;City, University of London, London, United Kingdom;Amadeus, Nice, France;City, University of London, London, United Kingdom",0.1109/tvcg.2010.129;10.1109/vast.2014.7042493;10.1109/tvcg.2010.154;10.1109/vast.2016.7883520;10.1109/tvcg.2013.212;10.1109/tvcg.2016.2598445;10.1109/tvcg.2017.2745080;10.1109/tvcg.2011.239;10.1109/tvcg.2013.200;10.1109/tvcg.2018.2864885;10.1109/tvcg.2014.2331979;10.1109/tvcg.2014.2346433;10.1109/tvcg.2013.162;10.1109/tvcg.2015.2467618,"LDA,visual analytics,user behavior",,19,79,923,,
TVCG,2021,The Making of Continuous Colormaps,10.1109/tvcg.2019.2961674,http://dx.doi.org/10.1109/TVCG.2019.2961674,3048,3063,J,"Continuous colormaps are integral parts of many visualization techniques, such as heat-maps, surface plots, and flow visualization. Despite that the critiques of rainbow colormaps have been around and well-acknowledged for three decades, rainbow colormaps are still widely used today. One reason behind the resilience of rainbow colormaps is the lack of tools for users to create a continuous colormap that encodes semantics specific to the application concerned. In this paper, we present a web-based software system, CCC-Tool (short for Charting Continuous Colormaps) under the URL https://ccctool.com, for creating, editing, and analyzing such application-specific colormaps. We introduce the notion of “colormap specification (CMS)” that maintains the essential semantics required for defining a color mapping scheme. We provide users with a set of advanced utilities for constructing CMS's with various levels of complexity, examining their quality attributes using different plots, and exporting them to external application software. We present two case studies, demonstrating that the CCC-Tool can help domain scientists as well as visualization experts in designing semantically-rich colormaps.",Pascal Nardini;Min Chen 0001;Francesca Samsel;Roxana Bujack;Michael Böttinger;Gerik Scheuermann,Pascal Nardini;Min Chen;Francesca Samsel;Roxana Bujack;Michael Böttinger;Gerik Scheuermann,"Institute of Computer Science, University of Leipzig, Leipzig, Germany;Department of Engineering Science, University of Oxford, Oxford, United Kingdom;Center for Agile Technology, University of Texas at Austin, Austin, TX, USA;Data Science at Scale Team, Los Alamos National Laboratory, Los Alamos, NM, USA;German Climate Computing Center (DKRZ), Hamburg, Germany;Institute of Computer Science, University of Leipzig, Leipzig, Germany",0.1109/visual.1990.146383;10.1109/visual.2001.964510;10.1109/tvcg.2010.150;10.1109/visual.1995.480803;10.1109/tvcg.2017.2743978;10.1109/tvcg.2018.2865147;10.1109/tvcg.2016.2599214;10.1109/visual.1990.146372;10.1109/tvcg.2017.2744320;10.1109/tvcg.2016.2598918;10.1109/tvcg.2017.2744359,"CCC-Tool,charting continuous colormaps,colormap specification,perceptual uniformity,colormap analysis",,17,91,811,,
TVCG,2022,Visual Analytics for RNN-Based Deep Reinforcement Learning,10.1109/tvcg.2021.3076749,http://dx.doi.org/10.1109/TVCG.2021.3076749,4141,4155,J,"Deep reinforcement learning (DRL) targets to train an autonomous agent to interact with a pre-defined environment and strives to achieve specific goals through deep neural networks (DNN). Recurrent neural network (RNN) based DRL has demonstrated superior performance, as RNNs can effectively capture the temporal evolution of the environment and respond with proper agent actions. However, apart from the outstanding performance, little is known about how RNNs understand the environment internally and what has been memorized over time. Revealing these details is extremely important for deep learning experts to understand and improve DRLs, which in contrast, is also challenging due to the complicated data transformations inside these models. In this article, we propose Deep Reinforcement Learning Interactive Visual Explorer (DRLIVE), a visual analytics system to effectively explore, interpret, and diagnose RNN-based DRLs. Having focused on DRL agents trained for different Atari games, DRLIVE accomplishes three tasks: game episode exploration, RNN hidden/cell state examination, and interactive model perturbation. Using the system, one can flexibly explore a DRL agent through interactive visualizations, discover interpretable RNN cells by prioritizing RNN hidden/cell states with a set of metrics, and further diagnose the DRL model by interactively perturbing its inputs. Through concrete studies with multiple deep learning experts, we validated the efficacy of DRLIVE.",Junpeng Wang;Wei Zhang 0189;Hao Yang 0007;Chin-Chia Michael Yeh;Liang Wang 0047,Junpeng Wang;Wei Zhang;Hao Yang;Chin-Chia Michael Yeh;Liang Wang,"Visa Research, Palo Alto, CA, USA;Visa Research, Palo Alto, CA, USA;Visa Research, Palo Alto, CA, USA;Visa Research, Palo Alto, CA, USA;Visa Research, Palo Alto, CA, USA",0.1109/tvcg.2017.2744938;10.1109/tvcg.2020.3030461;10.1109/tvcg.2017.2744358;10.1109/tvcg.2018.2864504;10.1109/tvcg.2018.2864500;10.1109/mcg.2018.2878902;10.1109/tvcg.2018.2843369;10.1109/tvcg.2019.2921323;10.1109/tvcg.2016.2598838;10.1109/tvcg.2017.2744878;10.1109/tvcg.2018.2864812;10.1109/tvcg.2017.2744158;10.1109/tvcg.2017.2744683;10.1109/vast.2017.8585721;10.1109/tvcg.2018.2865044;10.1109/tvcg.2018.2864499;10.1109/tvcg.2019.2934631;10.1109/vast.2018.8802509;10.1109/tvcg.2020.3030350;10.1109/tvcg.2017.2744718;10.1109/tvcg.2016.2598831,"Deep reinforcement learning (DRL),recurrent neural network (RNN),model interpretation,visual analytics",,14,48,1727,,
TVCG,2022,Showing Data About People: A Design Space of Anthropographics,10.1109/tvcg.2020.3023013,http://dx.doi.org/10.1109/TVCG.2020.3023013,1661,1679,J,"When showing data about people, visualization designers and data journalists often use design strategies that presumably help the audience relate to those people. The term anthropographics has been recently coined to refer to this practice and the resulting visualizations. Anthropographics is a rich and growing area, but the work so far has remained scattered. Despite preliminary empirical work and a few web essays written by practitioners, there is a lack of clear language for thinking about and communicating about anthropographics. We address this gap by introducing a conceptual framework and a design space for anthropographics. Our design space consists of seven elementary design dimensions that can be reasonably hypothesized to have some effect on prosocial feelings or behavior. It extends a previous design space and is informed by an analysis of 105 visualizations collected from newspapers, websites, and research articles. We use our conceptual framework and design space to discuss trade-offs, common design strategies, as well as future opportunities for design and research in the area of anthropographics.",Luiz Augusto de Macêdo Morais;Yvonne Jansen;Nazareno Andrade;Pierre Dragicevic,Luiz Morais;Yvonne Jansen;Nazareno Andrade;Pierre Dragicevic,"Universidade Federal de Campina Grande, Campina Grande, Brazil;Sorbonne Université, CNRS, ISIR, Paris, France;Universidade Federal de Campina Grande, Campina Grande, Brazil;CNRS, Inria, LRI, Université Paris-Saclay, Orsay, France",0.1109/tvcg.2014.2359887;10.1109/tvcg.2011.255;10.1109/tvcg.2013.119;10.1109/tvcg.2012.197;10.1109/tvcg.2013.234;10.1109/tvcg.2019.2934788;10.1109/tvcg.2010.179;10.1109/tvcg.2016.2598608;10.1109/tvcg.2016.2599030,"Anthropographics,design space,empathy,compassion,prosocial behavior",,19,92,1037,,
TVCG,2021,Probabilistic Data-Driven Sampling via Multi-Criteria Importance Analysis,10.1109/tvcg.2020.3006426,http://dx.doi.org/10.1109/TVCG.2020.3006426,4439,4454,J,"Although supercomputers are becoming increasingly powerful, their components have thus far not scaled proportionately. Compute power is growing enormously and is enabling finely resolved simulations that produce never-before-seen features. However, I/O capabilities lag by orders of magnitude, which means only a fraction of the simulation data can be stored for post hoc analysis. Prespecified plans for saving features and quantities of interest do not work for features that have not been seen before. Data-driven intelligent sampling schemes are needed to detect and save important parts of the simulation while it is running. Here, we propose a novel sampling scheme that reduces the size of the data by orders-of-magnitude while still preserving important regions. The approach we develop selects points with unusual data values and high gradients. We demonstrate that our approach outperforms traditional sampling schemes on a number of tasks.",Ayan Biswas;Soumya Dutta;Earl Lawrence;John Patchett;Jon C. Calhoun;James P. Ahrens,Ayan Biswas;Soumya Dutta;Earl Lawrence;John Patchett;Jon C. Calhoun;James Ahrens,"Los Alamos National Laboratory, Los Alamos, NM, USA;Los Alamos National Laboratory, Los Alamos, NM, USA;Los Alamos National Laboratory, Los Alamos, NM, USA;Los Alamos National Laboratory, Los Alamos, NM, USA;Clemson University, Clemson, SC, USA;Los Alamos National Laboratory, Los Alamos, NM, USA",0.1109/tvcg.2011.280;10.1109/tvcg.2010.215;10.1109/tvcg.2014.2346458;10.1109/visual.2004.48;10.1109/tvcg.2007.70519;10.1109/tvcg.2016.2598604;10.1109/tvcg.2013.133;10.1109/visual.1996.567752,"Importance sampling,data reduction,error quantification,feature preservation",,13,56,943,,
TVCG,2021,UrbanMotion: Visual Analysis of Metropolitan-Scale Sparse Trajectories,10.1109/tvcg.2020.2992200,http://dx.doi.org/10.1109/TVCG.2020.2992200,3881,3899,J,"Visualizing massive scale human movement in cities plays an important role in solving many of the problems that modern cities face (e.g., traffic optimization, business site configuration). In this article, we study a big mobile location dataset that covers millions of city residents, but is temporally sparse on the trajectory of individual user. Mapping sparse trajectories to illustrate population movement poses several challenges from both analysis and visualization perspectives. In the literature, there are a few techniques designed for sparse trajectory visualization; yet they do not consider trajectories collected from mobile apps that possess long-tailed sparsity with record intervals as long as hours. This article introduces UrbanMotion, a visual analytics system that extends the original wind map design by supporting map-matched local movements, multi-directional population flows, and population distributions. Effective methods are proposed to extract and aggregate population movements from dense parts of the trajectories leveraging their long-tailed sparsity. Both characteristic and anomalous patterns are discovered and visualized. We conducted three case studies, one comparative experiment, and collected expert feedback in the application domains of commuting analysis, event detection, and business site configuration. The study result demonstrates the significance and effectiveness of our system in helping to complete key analytics tasks for urban users.",Lei Shi 0002;Congcong Huang;Meijun Liu;Jia Yan;Tao Jiang 0054;Zhihao Tan;Yifan Hu 0001;Wei Chen 0001;Xiatian Zhang,Lei Shi;Congcong Huang;Meijun Liu;Jia Yan;Tao Jiang;Zhihao Tan;Yifan Hu;Wei Chen;Xiatian Zhang,"SKLSDE and Beijing Advanced Innovation Center for Big Data and Brain Computing, School of Computer Science and Engineering, Beihang University, Beijing, China;SKLCS, Institute of Software, Chinese Academy of Sciences, Beijing, China;SKLSDE and Beijing Advanced Innovation Center for Big Data and Brain Computing, School of Computer Science and Engineering, Beihang University, Beijing, China;SKLCS, Institute of Software, Chinese Academy of Sciences, Beijing, China;SKLCS, Institute of Software, Chinese Academy of Sciences, Beijing, China;SKLCS, Institute of Software, Chinese Academy of Sciences, Beijing, China;Yahoo Labs, Sunnyvale, CA, USA;State Key Lab of CAD&CG, Zhejiang University, Hangzhou, China;Beijing Tendcloud Tianxia Technology Co., Ltd, Beijing, China",0.1109/tvcg.2008.125;10.1109/tvcg.2011.181;10.1109/tvcg.2016.2616404;10.1109/tvcg.2016.2598885;10.1109/tvcg.2015.2468111;10.1109/tvcg.2017.2743918;10.1109/tvcg.2009.143;10.1109/tvcg.2013.226;10.1109/tvcg.2016.2598432;10.1109/tvcg.2015.2467619;10.1109/vast.2011.6102455;10.1109/tvcg.2016.2598585;10.1109/tvcg.2014.2346746;10.1109/tvcg.2012.265,"Movement visualization,sparse trajectory,wind map",,14,72,1405,,
TVCG,2022,Uncertainty Visualization of 2D Morse Complex Ensembles Using Statistical Summary Maps,10.1109/tvcg.2020.3022359,http://dx.doi.org/10.1109/TVCG.2020.3022359,1955,1966,J,"Morse complexes are gradient-based topological descriptors with close connections to Morse theory. They are widely applicable in scientific visualization as they serve as important abstractions for gaining insights into the topology of scalar fields. Data uncertainty inherent to scalar fields due to randomness in their acquisition and processing, however, limits our understanding of Morse complexes as structural abstractions. We, therefore, explore uncertainty visualization of an ensemble of 2D Morse complexes that arises from scalar fields coupled with data uncertainty. We propose several statistical summary maps as new entities for quantifying structural variations and visualizing positional uncertainties of Morse complexes in ensembles. Specifically, we introduce three types of statistical summary maps – the probabilistic map, the significance map, and the survival map – to characterize the uncertain behaviors of gradient flows. We demonstrate the utility of our proposed approach using wind, flow, and ocean eddy simulation datasets.",Tushar M. Athawale;Dan Maljovec;Lin Yan 0003;Chris R. Johnson 0001;Valerio Pascucci;Bei Wang 0001,Tushar M. Athawale;Dan Maljovec;Lin Yan;Chris R. Johnson;Valerio Pascucci;Bei Wang,"Scientific Computing & Imaging (SCI) Institute, University of Utah, Salt Lake City, UT, USA;Scientific Computing & Imaging (SCI) Institute, University of Utah, Salt Lake City, UT, USA;Scientific Computing & Imaging (SCI) Institute, University of Utah, Salt Lake City, UT, USA;Scientific Computing & Imaging (SCI) Institute, University of Utah, Salt Lake City, UT, USA;Scientific Computing & Imaging (SCI) Institute, University of Utah, Salt Lake City, UT, USA;Scientific Computing & Imaging (SCI) Institute, University of Utah, Salt Lake City, UT, USA",0.1109/tvcg.2013.92;10.1109/tvcg.2018.2864432;10.1109/tvcg.2008.163;10.1109/tvcg.2019.2934242;10.1109/tvcg.2011.269;10.1109/tvcg.2014.2346448;10.1109/tvcg.2018.2864510;10.1109/tvcg.2010.213;10.1109/tvcg.2016.2637333;10.1109/tvcg.2006.186;10.1109/tvcg.2012.209;10.1109/tvcg.2018.2864889;10.1109/tvcg.2018.2864505;10.1109/tvcg.2018.2853721;10.1109/tvcg.2015.2467958;10.1109/tvcg.2013.208;10.1109/tvcg.2013.143,"Morse complexes,uncertainty visualization,topological data analysis",,10,63,691,,
TVCG,2020,Scientific Visualization as a Microservice,10.1109/tvcg.2018.2879672,http://dx.doi.org/10.1109/TVCG.2018.2879672,1760,1774,J,"In this paper, we propose using a decoupled architecture to create a microservice that can deliver scientific visualization remotely with efficiency, scalability, and superior availability, affordability and accessibility. Through our effort, we have created an open source platform, Tapestry, which can be deployed on Amazon AWS as a production use microservice. The applications we use to demonstrate the efficacy of the Tapestry microservice in this work are: (1) embedding interactive visualizations into lightweight web pages, (2) creating scientific visualization movies that are fully controllable by the viewers, (3) serving as a rendering engine for high-end displays such as power-walls, and (4) embedding data-intensive visualizations into augmented reality devices efficiently. In addition, we show results of an extensive performance study, and suggest how applications can make optimal use of microservices such as Tapestry.",Mohammad Raji;Alok Hota;Tanner Hobson;Jian Huang 0007,Mohammad Raji;Alok Hota;Tanner Hobson;Jian Huang,"Department of Electrical Engineering and Computer Science, University of Tennessee, Knoxville, USA;Department of Electrical Engineering and Computer Science, University of Tennessee, Knoxville, USA;Department of Electrical Engineering and Computer Science, University of Tennessee, Knoxville, USA;Department of Electrical Engineering and Computer Science, University of Tennessee, Knoxville, USA",0.1109/tvcg.2016.2599041;10.1109/tvcg.2011.185;10.1109/tvcg.2010.181;10.1109/visual.2005.1532788,"Scientific visualization,visualization systems,cloud computing,web applications,and distributed visualization",,7,44,1081,,
TVCG,2022,Touch and Beyond: Comparing Physical and Virtual Reality Visualizations,10.1109/tvcg.2020.3023336,http://dx.doi.org/10.1109/TVCG.2020.3023336,1930,1940,J,"We compare physical and virtual reality (VR) versions of simple data visualizations and explore how the addition of virtual annotation and filtering tools affects how viewers solve basic data analysis tasks. We report on two studies, inspired by previous examinations of data physicalizations. The first study examines differences in how viewers interact with physical hand-scale, virtual hand-scale, and virtual table-scale visualizations and the impact that the different forms had on viewer&#x2019;s problem solving behavior. A second study examines how interactive annotation and filtering tools might support new modes of use that transcend the limitations of physical representations. Our results highlight challenges associated with virtual reality representations and hint at the potential of interactive annotation and filtering tools in VR visualizations.",Kurtis Thorvald Danyluk;Teoman Ulusoy;Wei Wei;Wesley Willett,Kurtis Danyluk;Teoman Ulusoy;Wei Wei;Wesley Willett,"Department of Computer Science, University of Calgary, Calgary, AB, Canada;Department of Computer Science, University of Calgary, Calgary, AB, Canada;Department of Computer Science, University of Calgary, Calgary, AB, Canada;Department of Computer Science, University of Calgary, Calgary, AB, Canada",0.1109/tvcg.2016.2520921;10.1109/tvcg.2016.2599107;10.1109/mcg.2019.2898941;10.1109/tvcg.2015.2467951,"Human-computer interaction,visualization,data visualization,virtual reality,physicalization",,13,42,1605,,
TVCG,2022,Learning Adaptive Sampling and Reconstruction for Volume Visualization,10.1109/tvcg.2020.3039340,http://dx.doi.org/10.1109/TVCG.2020.3039340,2654,2667,J,"A central challenge in data visualization is to understand which data samples are required to generate an image of a data set in which the relevant information is encoded. In this article, we make a first step towards answering the question of whether an artificial neural network can predict where to sample the data with higher or lower density, by learning of correspondences between the data, the sampling patterns and the generated images. We introduce a novel neural rendering pipeline, which is trained end-to-end to generate a sparse adaptive sampling structure from a given low-resolution input image, and reconstructs a high-resolution image from the sparse set of samples. For the first time, to the best of our knowledge, we demonstrate that the selection of structures that are relevant for the final visual representation can be jointly learned together with the reconstruction of this representation from these structures. Therefore, we introduce differentiable sampling and reconstruction stages, which can leverage back-propagation based on supervised losses solely on the final image. We shed light on the adaptive sampling patterns generated by the network pipeline and analyze its use for volume visualization including isosurface and direct volume rendering.",Sebastian Weiss;Mustafa Isik;Justus Thies;Rüdiger Westermann,Sebastian Weiss;Mustafa IşIk;Justus Thies;Rüdiger Westermann,"Technical University of Munich, München, Germany;Technical University of Munich, München, Germany;Technical University of Munich, München, Germany;Technical University of Munich, München, Germany",0.1109/tvcg.2019.2956697;10.1109/tvcg.2014.2346319;10.1109/mcg.2018.2881523;10.1109/tvcg.2018.2816059,"Volume visualization,adaptive sampling,deep learning",,10,64,721,,
CG&A,2017,Physical Visualization of Geospatial Datasets,10.1109/mcg.2017.38,http://dx.doi.org/10.1109/MCG.2017.38,61,69,MAG,Geospatial datasets are too complex to easily visualize and understand on a computer screen. Combining digital fabrication with a discrete global grid system (DGGS) can produce physical models of the Earth for visualizing multiresolution geospatial datasets. This proposed approach includes a mechanism for attaching a set of 3D printed segments to produce a scalable model of the Earth. The authors have produced two models that support the attachment of different datasets both in 2D and 3D format.,Hessam Djavaherpour;Ali Mahdavi-Amiri;Faramarz F. Samavati,Hessam Djavaherpour;Ali Mahdavi-Amiri;Faramarz F. Samavati,University of Calgary;University of Calgary;University of Calgary,0.1109/tvcg.2014.2346292,"computer graphics,information visualization,Digital Earth,DGGS,digital fabrication",,10,26,805,,
TVCG,2021,A Comparison of Rendering Techniques for 3D Line Sets With Transparency,10.1109/tvcg.2020.2975795,http://dx.doi.org/10.1109/TVCG.2020.2975795,3361,3376,J,"This article presents a comprehensive study of rendering techniques for 3D line sets with transparency. The rendering of transparent lines is widely used for visualizing trajectories of tracer particles in flow fields. Transparency is then used to fade out lines deemed unimportant, based on, for instance, geometric properties or attributes defined along with them. Accurate blending of transparent lines requires rendering the lines in back-to-front or front-to-back order, yet enforcing this order for space-filling 3D line sets with extremely high-depth complexity becomes challenging. In this article, we study CPU and GPU rendering techniques for transparent 3D line sets. We compare accurate and approximate techniques using optimized implementations and several benchmark data sets. We discuss the effects of data size and transparency on quality, performance, and memory consumption. Based on our study, we propose two improvements to per-pixel fragment lists and multi-layer alpha blending. The first improves the rendering speed via an improved GPU sorting operation, and the second improves rendering quality via transparency-based bucketing.",Michael Kern;Christoph Neuhauser;Torben Maack;Mengjiao Han;Will Usher 0001;Rüdiger Westermann,Michael Kern;Christoph Neuhauser;Torben Maack;Mengjiao Han;Will Usher;Rüdiger Westermann,"Computer Graphics & Visualization Group, Technische Universität München, Garching bei MÜnchen, Germany;Computer Graphics & Visualization Group, Technische Universität München, Garching bei MÜnchen, Germany;Computer Graphics & Visualization Group, Technische Universität München, Garching bei MÜnchen, Germany;Scientific Computing and Imaging Institute, University of Utah, Salt Lake City, UT, USA;Scientific Computing and Imaging Institute, University of Utah, Salt Lake City, UT, USA;Computer Graphics & Visualization Group, Technische Universität München, Garching bei MÜnchen, Germany",0.1109/scivis.2015.7429492;10.1109/tvcg.2016.2599041;10.1109/tvcg.2013.2297914;10.1109/tvcg.2019.2915222,"Scientific visualization,line rendering,order-independent transparency",,9,44,566,,
TVCG,2020,Detection and Visualization of Splat and Antisplat Events in Turbulent Flows,10.1109/tvcg.2019.2920157,http://dx.doi.org/10.1109/TVCG.2019.2920157,3147,3162,J,"Splat and antisplat events are a widely found phenomenon in three-dimensional turbulent flow fields. Splats are observed when fluid locally impinges on an impermeable surface transferring energy from the normal component to the tangential velocity components, while antisplats relate to the inverted situation. These events affect a variety of flow properties, such as the transfer of kinetic energy between velocity components and the transfer of heat, so that their investigation can provide new insight into these issues. Here, we propose the first Lagrangian method for the detection of splats and antisplats as features of an unsteady flow field. Our method utilizes the concept of strain tensors on flow-embedded flat surfaces to extract disjoint regions in which splat and antisplat events of arbitrary scale occur. We validate the method with artificial flow fields of increasing complexity. Subsequently, the method is used to analyze application data stemming from a direct numerical simulation of the turbulent flow over a backward facing step. Our results show that splat and antisplat events can be identified efficiently and reliably even in such a complex situation, demonstrating that the new method constitutes a well-suited tool for the analysis of turbulent flows.",Baldwin Nsonga;Martin Niemann;Jochen Fröhlich;Joachim Staib;Stefan Gumhold;Gerik Scheuermann,Baldwin Nsonga;Martin Niemann;Jochen Fröhlich;Joachim Staib;Stefan Gumhold;Gerik Scheuermann,"Institute of Computer Science, Leipzig University, Augustusplatz 10, Leipzig, Germany;TU Dresden, George-Bähr-Straße-3c, Institute of Fluid Mechanics, Dresden, Germany;TU Dresden, George-Bähr-Straße-3c, Institute of Fluid Mechanics, Dresden, Germany;TU Dresden, Nöthnitzer Straße 46, Institute of Software and Multimedia Technology, Dresden, Germany;TU Dresden, Nöthnitzer Straße 46, Institute of Software and Multimedia Technology, Dresden, Germany;Institute of Computer Science, Leipzig University, Augustusplatz 10, Leipzig, Germany",0.1109/tvcg.2012.142;10.1109/tvcg.2015.2467436,"Flow visualization,visualization techniques and methodologies",,10,41,622,,
TVCG,2019,Extreme-Scale Stochastic Particle Tracing for Uncertain Unsteady Flow Visualization and Analysis,10.1109/tvcg.2018.2856772,http://dx.doi.org/10.1109/TVCG.2018.2856772,2710,2724,J,"We present an efficient and scalable solution to estimate uncertain transport behaviors - stochastic flow maps (SFMs) - for visualizing and analyzing uncertain unsteady flows. Computing flow maps from uncertain flow fields is extremely expensive because it requires many Monte Carlo runs to trace densely seeded particles in the flow. We reduce the computational cost by decoupling the time dependencies in SFMs so that we can process shorter sub time intervals independently and then compose them together for longer time periods. Adaptive refinement is also used to reduce the number of runs for each location. We parallelize over tasks-packets of particles in our design - to achieve high efficiency in MPI/thread hybrid programming. Such a task model also enables CPU/GPU coprocessing. We show the scalability on two supercomputers, Mira (up to 256K Blue Gene/Q cores) and Titan (up to 128K Opteron cores and 8K GPUs), that can trace billions of particles in seconds.",Hanqi Guo 0001;Wenbin He;Sangmin Seo;Han-Wei Shen;Emil M. Constantinescu;Chunhui Liu;Tom Peterka,Hanqi Guo;Wenbin He;Sangmin Seo;Han-Wei Shen;Emil Mihai Constantinescu;Chunhui Liu;Tom Peterka,"Mathematics and Computer Science Division, Argonne National Laboratory, Lemont, IL, USA;Department of Computer Science and Engineering, Ohio State University, Columbus, OH, USA;Ground X Inc., Seoul, Korea;Department of Computer Science and Engineering, Ohio State University, Columbus, OH, USA;Mathematics and Computer Science Division, Argonne National Laboratory, Argonne, IL, USA;Faculty of Science, Kyoto University, Kyoto, Japan;Mathematics and Computer Science Division, Argonne National Laboratory, Lemont, IL, USA",0.1109/tvcg.2017.2744059;10.1109/tvcg.2010.259;10.1109/tvcg.2007.70554;10.1109/tvcg.2013.128;10.1109/tvcg.2010.227;10.1109/tvcg.2014.2346418;10.1109/tvcg.2013.144;10.1109/tvcg.2013.143;10.1109/tvcg.2011.219,"Parallel particle tracing,uncertain flow visualization,CPU-GPU hybrid parallelism",,9,45,583,,
TVCG,2022,Accelerating Unstructured Mesh Point Location With RT Cores,10.1109/tvcg.2020.3042930,http://dx.doi.org/10.1109/TVCG.2020.3042930,2852,2866,J,"We present a technique that leverages ray tracing hardware available in recent Nvidia RTX GPUs to solve a problem other than classical ray tracing. Specifically, we demonstrate how to use these units to accelerate the point location of general unstructured elements consisting of both planar and bilinear faces. This unstructured mesh point location problem has previously been challenging to accelerate on GPU architectures; yet, the performance of these queries is crucial to many unstructured volume rendering and compute applications. Starting with a CUDA reference method, we describe and evaluate three approaches that reformulate these point queries to incrementally map algorithmic complexity to these new hardware ray tracing units. Each variant replaces the simpler problem of point queries with a more complex one of ray queries. Initial variants exploit ray tracing cores for accelerated BVH traversal, and subsequent variants use ray-triangle intersections and per-face metadata to detect point-in-element intersections. Although these later variants are more algorithmically complex, they are significantly faster than the reference method thanks to hardware acceleration. Using our approach, we improve the performance of an unstructured volume renderer by up to $4\times$4× for tetrahedral meshes and up to $15\times$15× for general bilinear element meshes, matching, or out-performing state-of-the-art solutions while simultaneously improving on robustness and ease-of-implementation.",Nate Morrical;Ingo Wald;Will Usher 0001;Valerio Pascucci,Nate Morrical;Ingo Wald;Will Usher;Valerio Pascucci,"SCI Institute, University of Utah, Salt Lake City, UT, USA;NVIDIA, Santa Clara, CA, USA;SCI Institute, University of Utah, Salt Lake City, UT, USA;SCI Institute, University of Utah, Salt Lake City, UT, USA",0.1109/tvcg.2016.2599041;10.1109/tvcg.2011.216;10.1109/tvcg.2007.70588;10.1109/tvcg.2012.218;10.1109/tvcg.2020.3030470,"Scientific ray tracing,unstructured scalar data,GPGPU,simulation,volume rendering",,9,43,576,,
TVCG,2021,Conceptual Model of Visual Analytics for Hands-on Cybersecurity Training,10.1109/tvcg.2020.2977336,http://dx.doi.org/10.1109/TVCG.2020.2977336,3425,3437,J,"Hands-on training is an effective way to practice theoretical cybersecurity concepts and increase participants' skills. In this article, we discuss the application of visual analytics principles to the design, execution, and evaluation of training sessions. We propose a conceptual model employing visual analytics that supports the sensemaking activities of users involved in various phases of the training life cycle. The model emerged from our long-term experience in designing and organizing diverse hands-on cybersecurity training sessions. It provides a classification of visualizations and can be used as a framework for developing novel visualization tools supporting phases of the training life-cycle. We demonstrate the model application on examples covering two types of cybersecurity training programs.",Radek Oslejsek;Vít Rusnák;Karolína Dockalová Burská;Valdemar Svábenský;Jan Vykopal;Jakub Cegan,Radek Ošlejšek;Vít Rusňák;Karolína Burská;Valdemar Švábenský;Jan Vykopal;Jakub Čegan,"Faculty of Informatics, Masaryk University, Brno, Czech Republic;Institute of Computer Science, Masaryk University, Brno, Czech Republic;Faculty of Informatics, Masaryk University, Brno, Czech Republic;Institute of Computer Science and Faculty of Informatics, Masaryk University, Brno, Czech Republic;Institute of Computer Science and Faculty of Informatics, Masaryk University, Brno, Czech Republic;Institute of Computer Science, Masaryk University, Brno, Czech Republic",0.1109/tvcg.2014.2346481;10.1109/tvcg.2012.213;10.1109/tvcg.2015.2467771,"Visual analytics,cybersecurity,hands-on training,classification,educatio",,9,54,869,,
TVCG,2021,SpotSDC: Revealing the Silent Data Corruption Propagation in High-Performance Computing Systems,10.1109/tvcg.2020.2994954,http://dx.doi.org/10.1109/TVCG.2020.2994954,3938,3952,J,"The trend of rapid technology scaling is expected to make the hardware of high-performance computing (HPC) systems more susceptible to computational errors due to random bit flips. Some bit flips may cause a program to crash or have a minimal effect on the output, but others may lead to silent data corruption (SDC), i.e., undetected yet significant output errors. Classical fault injection analysis methods employ uniform sampling of random bit flips during program execution to derive a statistical resiliency profile. However, summarizing such fault injection result with sufficient detail is difficult, and understanding the behavior of the fault-corrupted program is still a challenge. In this article, we introduce SpotSDC, a visualization system to facilitate the analysis of a program's resilience to SDC. SpotSDC provides multiple perspectives at various levels of detail of the impact on the output relative to where in the source code the flipped bit occurs, which bit is flipped, and when during the execution it happens. SpotSDC also enables users to study the code protection and provide new insights to understand the behavior of a fault-injected program. Based on lessons learned, we demonstrate how what we found can improve the fault injection campaign method.",Zhimin Li;Harshitha Menon;Dan Maljovec;Yarden Livnat;Shusen Liu 0001;Kathryn M. Mohror;Peer-Timo Bremer;Valerio Pascucci,Zhimin Li;Harshitha Menon;Dan Maljovec;Yarden Livnat;Shusen Liu;Kathryn Mohror;Peer-Timo Bremer;Valerio Pascucci,"Scientific Computing and Imaging Institute, University of Utah, Salt Lake City, UT, USA;Lawrence Livermore National Laboratory, Livermore, CA, USA;Scientific Computing and Imaging Institute, University of Utah, Salt Lake City, UT, USA;Scientific Computing and Imaging Institute, University of Utah, Salt Lake City, UT, USA;Lawrence Livermore National Laboratory, Livermore, CA, USA;Lawrence Livermore National Laboratory, Livermore, CA, USA;Lawrence Livermore National Laboratory, Livermore, CA, USA;Scientific Computing and Imaging Institute, University of Utah, Salt Lake City, UT, USA",0.1109/tvcg.2018.2865149;10.1109/tvcg.2018.2811488;10.1109/tvcg.2018.2843369;10.1109/tvcg.2014.2346456;10.1109/tvcg.2012.286;10.1109/tvcg.2018.2865026;10.1109/tvcg.2014.2346458;10.1109/tvcg.2018.2853721;10.1109/tvcg.2014.2346455;10.1109/tvcg.2013.143,"Fault injection sampling,error propagation,information visualization,silent data corruption",,8,57,855,,
TVCG,2021,FTK: A Simplicial Spacetime Meshing Framework for Robust and Scalable Feature Tracking,10.1109/tvcg.2021.3073399,http://dx.doi.org/10.1109/TVCG.2021.3073399,3463,3480,J,"We present the Feature Tracking Kit (FTK), a framework that simplifies, scales, and delivers various feature-tracking algorithms for scientific data. The key of FTK is our simplicial spacetime meshing scheme that generalizes both regular and unstructured spatial meshes to spacetime while tessellating spacetime mesh elements into simplices. The benefits of using simplicial spacetime meshes include (1) reducing ambiguity cases for feature extraction and tracking, (2) simplifying the handling of degeneracies using symbolic perturbations, and (3) enabling scalable and parallel processing. The use of simplicial spacetime meshing simplifies and improves the implementation of several feature-tracking algorithms for critical points, quantum vortices, and isosurfaces. As a software framework, FTK provides end users with VTK/ParaView filters, Python bindings, a command line interface, and programming interfaces for feature-tracking applications. We demonstrate use cases as well as scalability studies through both synthetic data and scientific applications including tokamak, fluid dynamics, and superconductivity simulations. We also conduct end-to-end performance studies on the Summit supercomputer. FTK is open sourced under the MIT license: https://github.com/hguo/ftk.",Hanqi Guo 0001;David Lenz;Jiayi Xu 0001;Xin Liang 0001;Wenbin He;Iulian R. Grindeanu;Han-Wei Shen;Tom Peterka;Todd S. Munson;Ian T. Foster,Hanqi Guo;David Lenz;Jiayi Xu;Xin Liang;Wenbin He;Iulian R. Grindeanu;Han-Wei Shen;Tom Peterka;Todd Munson;Ian Foster,"Mathematics and Computer Science Division, Argonne National Laboratory, Lemont, IL, USA;Mathematics and Computer Science Division, Argonne National Laboratory, Lemont, IL, USA;Department of Computer Science and Engineering, Ohio State University, Columbus, OH, USA;Department of Computer Science, Missouri University of Science and Technology, Rolla, MO, USA;Bosch Research North America, Sunnyvale, CA, USA;Mathematics and Computer Science Division, Argonne National Laboratory, Lemont, IL, USA;Department of Computer Science and Engineering, Ohio State University, Columbus, OH, USA;Mathematics and Computer Science Division, Argonne National Laboratory, Lemont, IL, USA;Mathematics and Computer Science Division, Argonne National Laboratory, Lemont, IL, USA;Data Science and Learning Division, Argonne National Laboratory, Lemont, IL, USA",0.1109/tvcg.2011.269;10.1109/tvcg.2006.173;10.1109/visual.2002.1183786;10.1109/tvcg.2010.93;10.1109/mcg.2016.48;10.1109/visual.2000.885716;10.1109/visual.1991.175782;10.1109/tvcg.2010.198;10.1109/visual.2004.107;10.1109/tvcg.2015.2466838;10.1109/tvcg.2017.2743938;10.1109/visual.1996.567807;10.1109/visual.1998.745288;10.1109/tvcg.2017.2719684,"Feature tracking,spacetime meshing,distributed and parallel processing,critical points,isosurfaces,vortices",,8,66,484,,X
TVCG,2018,Is There a Robust Technique for Selecting Aspect Ratios in Line Charts?,10.1109/tvcg.2017.2787113,http://dx.doi.org/10.1109/TVCG.2017.2787113,3096,3110,J,"The aspect ratio of a line chart heavily influences the perception of the underlying data. Different methods explore different criteria in choosing aspect ratios, but so far, it was still unclear how to select aspect ratios appropriately for any given data. This paper provides a guideline for the user to choose aspect ratios for any input 1D curves by conducting an in-depth analysis of aspect ratio selection methods both theoretically and experimentally. By formulating several existing methods as line integrals, we explain their parameterization invariance. Moreover, we derive a new and improved aspect ratio selection method, namely the $L_1$ -LOR (local orientation resolution), with a certain degree of parameterization invariance. Furthermore, we connect different methods, including AL (arc length based method), the banking to 45 $^\circ$ principle, RV (resultant vector) and AS (average absolute slope), as well as  $L_1$ -LOR and AO (average absolute orientation). We verify these connections by a comparative evaluation involving various data sets, and show that the selections by RV and  $L_1$ -LOR are complementary to each other for most data. Accordingly, we propose the dual-scale banking technique that combines the strengths of RV and $L_1$ -LOR, and demonstrate its practicability using multiple real-world data sets.",Yunhai Wang;Zeyu Wang 0005;Lifeng Zhu;Jian Zhang 0070;Chi-Wing Fu;Zhanglin Cheng;Changhe Tu;Baoquan Chen,Yunhai Wang;Zeyu Wang;Lifeng Zhu;Jian Zhang;Chi-Wing Fu;Zhanglin Cheng;Changhe Tu;Baoquan Chen,"Shandong University, Qingdao, Shandong, China;Shandong University, Qingdao;Southeast University, Nanjing, Jiangsu, China;Computer Network Information Center, Chinese Academy of Sciences, Beijing, China;Chinese University of Hong Kong, Hong Kong;VRHIT Shenzhen Institutes of Advanced Technology, Shenzhen, Guangdong, China;Shandong University, Qingdao, Shandong, China;Shandong University, Qingdao, Shandong, China",0.1109/tvcg.2013.187;10.1109/tvcg.2012.196;10.1109/tvcg.2010.186;10.1109/tvcg.2014.2346979;10.1109/tvcg.2015.2467671;10.1109/tvcg.2006.163;10.1109/tvcg.2011.167;10.1109/tvcg.2010.162,"Aspect ratio,parameterization invariance,line integral,banking to 45 $^\circ$    ,orientation resolution",,9,26,760,,
TVCG,2022,Scalable Scalable Vector Graphics: Automatic Translation of Interactive SVGs to a Multithread VDOM for Fast Rendering,10.1109/tvcg.2021.3059294,http://dx.doi.org/10.1109/TVCG.2021.3059294,3219,3234,J,"The dominant markup language for Web visualizations—Scalable Vector Graphics (SVG)—is comparatively easy to learn, and is open, accessible, customizable via CSS, and searchable via the DOM, with easy interaction handling and debugging. Because these attributes allow visualization creators to focus on design on implementation details, tools built on top of SVG, such as D3.js, are essential to the visualization community. However, slow SVG rendering can limit designs by effectively capping the number of on-screen data points, and this can force visualization creators to switch to Canvas or WebGL. These are less flexible (e.g., no search or styling via CSS), and harder to learn. We introduce Scalable Scalable Vector Graphics (SSVG) to reduce these limitations and allow complex and smooth visualizations to be created with SVG. SSVG automatically translates interactive SVG visualizations into a dynamic virtual DOM (VDOM) to bypass the browser's slow ‘to specification’ rendering by intercepting JavaScript function calls. De-coupling the SVG visualization specification from SVG rendering, and obtaining a dynamic VDOM, creates flexibility and opportunity for visualization system research. SSVG uses this flexibility to free up the main thread for more interactivity and renders the visualization with Canvas or WebGL on a web worker. Together, these concepts create a drop-in JavaScript library which can improve rendering performance by 3–9× with only one line of code added. To demonstrate applicability, we describe the use of SSVG on multiple example visualizations including published visualization research. A free copy of this article, collected data, and source code are available as open science at osf.io/ge8wp.",Michail Schwab;David Saffo;Nicholas Bond;Shash Sinha;Cody Dunne;Jeff Huang 0002;James Tompkin 0001;Michelle A. Borkin,Michail Schwab;David Saffo;Nicholas Bond;Shash Sinha;Cody Dunne;Jeff Huang;James Tompkin;Michelle A. Borkin,"Northeastern University, Boston, MA, USA;Northeastern University, Boston, MA, USA;Northeastern University, Boston, MA, USA;Brown University, Providence, RI, USA;Northeastern University, Boston, MA, USA;Brown University, Providence, RI, USA;Brown University, Providence, RI, USA;Northeastern University, Boston, MA, USA",0.1109/tvcg.2017.2750689;10.1109/tvcg.2016.2598919;10.1109/tvcg.2011.185;10.1109/tvcg.2016.2615308;10.1109/tvcg.2018.2865141;10.1109/tvcg.2014.2346452,"Visualization systems,SVG,performance,virtual DOM,rendering,D3.js",,7,41,710,,
TVCG,2022,Real-Time Denoising of Volumetric Path Tracing for Direct Volume Rendering,10.1109/tvcg.2020.3037680,http://dx.doi.org/10.1109/TVCG.2020.3037680,2734,2747,J,"Direct volume rendering (DVR) using volumetric path tracing (VPT) is a scientific visualization technique that simulates light transport with objects’ matter using physically-based lighting models. Monte Carlo (MC) path tracing is often used with surface models, yet its application for volumetric models is difficult due to the complexity of integrating MC light-paths in volumetric media with none or smooth material boundaries. Moreover, auxiliary geometry-buffers (G-buffers) produced for volumes are typically very noisy, failing to guide image denoisers relying on that information to preserve image details. This makes existing real-time denoisers, which take noise-free G-buffers as their input, less effective when denoising VPT images. We propose the necessary modifications to an image-based denoiser previously used when rendering surface models, and demonstrate effective denoising of VPT images. In particular, our denoising exploits temporal coherence between frames, without relying on noise-free G-buffers, which has been a common assumption of existing denoisers for surface-models. Our technique preserves high-frequency details through a weighted recursive least squares that handles heterogeneous noise for volumetric models. We show for various real data sets that our method improves the visual fidelity and temporal stability of VPT during classic DVR operations such as camera movements, modifications of the light sources, and editions to the volume transfer function.",José Antonio Iglesias Guitián;Prajita Mane;Bochang Moon,Jose A. Iglesias-Guitian;Prajita Mane;Bochang Moon,"Computer Vision Center, Universitat Autònoma de Barcelona, Bellaterra, Spain;Gwangju Institute of Science and Technology, Gwangju, South Korea;Gwangju Institute of Science and Technology, Gwangju, South Korea",0.1109/tvcg.2011.161;10.1109/tvcg.2013.90;10.1109/tvcg.2017.2744438;10.1109/tvcg.2016.2598430;10.1109/tvcg.2012.232;10.1109/tvcg.2011.35,"Volume rendering,global illumination,path-tracing,participating media,image-space filtering,real-time denoising",,8,62,976,,
TVCG,2019,Preserving Command Line Workflow for a Package Management System Using ASCII DAG Visualization,10.1109/tvcg.2018.2859974,http://dx.doi.org/10.1109/TVCG.2018.2859974,2804,2820,J,"Package managers provide ease of access to applications by removing the time-consuming and sometimes completely prohibitive barrier of successfully building, installing, and maintaining the software for a system. A package dependency contains dependencies between all packages required to build and run the target software. Package management system developers, package maintainers, and users may consult the dependency graph when a simple listing is insufficient for their analyses. However, users working in a remote command line environment must disrupt their workflow to visualize dependency graphs in graphical programs, possibly needing to move files between devices or incur forwarding lag. Such is the case for users of Spack, an open source package management system originally developed to ease the complex builds required by supercomputing environments. To preserve the command line workflow of Spack, we develop an interactive ASCII visualization for its dependency graphs. Through interviews with Spack maintainers, we identify user goals and corresponding visual tasks for dependency graphs. We evaluate the use of our visualization through a command line-centered study, comparing it to the system's two existing approaches. We observe that despite the limitations of the ASCII representation, our visualization is preferred by participants when approached from a command line interface workflow.",Katherine E. Isaacs;Todd Gamblin,Katherine E. Isaacs;Todd Gamblin,"University of Arizona, Tucson, AZ, USA;Lawrence Livermore National Laboratory, Livermore, CA, USA",0.1109/tvcg.2014.2346452;10.1109/tvcg.2015.2467251;10.1109/tvcg.2013.151;10.1109/infvis.2004.1,"Software visualization,information visualization,command line interface",,8,54,469,,
TVCG,2022,Impact of Cognitive Biases on Progressive Visualization,10.1109/tvcg.2021.3051013,http://dx.doi.org/10.1109/TVCG.2021.3051013,3093,3112,J,"Progressive visualization is fast becoming a technique in the visualization community to help users interact with large amounts of data. With progressive visualization, users can examine intermediate results of complex or long running computations, without waiting for the computation to complete. While this has shown to be beneficial to users, recent research has identified potential risks. For example, users may misjudge the uncertainty in the intermediate results and draw incorrect conclusions or see patterns that are not present in the final results. In this article, we conduct a comprehensive set of studies to quantify the advantages and limitations of progressive visualization. Based on a recent report by Micallef et al., we examine four types of cognitive biases that can occur with progressive visualization: uncertainty bias, illusion bias, control bias, and anchoring bias. The results of the studies suggest a cautious but promising use of progressive visualization – while there can be significant savings in task completion time, accuracy can be negatively affected in certain conditions. These findings confirm earlier reports of the benefits and drawbacks of progressive visualization and that continued research into mitigating the effects of cognitive biases is necessary.",Marianne Procopio;Abigail Mosca;Carlos Scheidegger;Eugene Wu 0002;Remco Chang,Marianne Procopio;Ab Mosca;Carlos Scheidegger;Eugene Wu;Remco Chang,"Tufts University, Medford, MA, USA;Tufts University, Medford, MA, USA;University of Arizona, Tucson, AZ, USA;Columbia University, New York, NY, USA;Tufts University, Medford, MA, USA",0.1109/tvcg.2015.2467752;10.1109/tvcg.2014.2346578;10.1109/tvcg.2014.2346298;10.1109/tvcg.2015.2462356;10.1109/tvcg.2014.2346452;10.1109/tvcg.2018.2864909;10.1109/tvcg.2017.2744138;10.1109/vast.2017.8585665;10.1109/tvcg.2019.2934287;10.1109/tvcg.2018.2872577;10.1109/vast.2017.8585669;10.1109/tvcg.2016.2598470;10.1109/tvcg.2014.2346574;10.1109/tvcg.2017.2744358;10.1109/tvcg.2019.2917689,"Progressive visualization,cognitive bias",,7,53,758,,X
TVCG,2021,CMed: Crowd Analytics for Medical Imaging Data,10.1109/tvcg.2019.2953026,http://dx.doi.org/10.1109/TVCG.2019.2953026,2869,2880,J,"We present a visual analytics framework, CMed, for exploring medical image data annotations acquired from crowdsourcing. CMed can be used to visualize, classify, and filter crowdsourced clinical data based on a number of different metrics such as detection rate, logged events, and clustering of the annotations. CMed provides several interactive linked visualization components to analyze the crowd annotation results for a particular video and the associated workers. Additionally, all results of an individual worker can be inspected using multiple linked views in our CMed framework. We allow a crowdsourcing application analyst to observe patterns and gather insights into the crowdsourced medical data, helping him/her design future crowdsourcing applications for optimal output from the workers. We demonstrate the efficacy of our framework with two medical crowdsourcing studies: polyp detection in virtual colonoscopy videos and lung nodule detection in CT thin-slab maximum intensity projection videos. We also provide experts’ feedback to show the effectiveness of our framework. Lastly, we share the lessons we learned from our framework with suggestions for integrating our framework into a clinical workflow.",Ji Hwan Park;Saad Nadeem;Saeed Boorboor;Joseph Marino;Arie E. Kaufman,Ji Hwan Park;Saad Nadeem;Saeed Boorboor;Joseph Marino;Arie Kaufman,"Brookhaven National Laboratory, Upton, NY, USA;Memorial Sloan Kettering Cancer Center, New York, NY, USA;Department of Computer Science, Stony Brook University, Stony Brook, NY, USA;Department of Computer Science, Stony Brook University, Stony Brook, NY, USA;Department of Computer Science, Stony Brook University, Stony Brook, NY, USA",0.1109/tvcg.2008.185;10.1109/tvcg.2011.208;10.1109/tvcg.2013.168;10.1109/tvcg.2016.2598695;10.1109/vast.2016.7883508;10.1109/tvcg.2013.164,"Crowdsourcing,medical imaging,virtual colonoscopy,lung nodules,visual analytics",,6,42,624,,
TVCG,2020,How People Visually Represent Discrete Constraint Problems,10.1109/tvcg.2019.2895085,http://dx.doi.org/10.1109/TVCG.2019.2895085,2603,2619,J,"Problems such as timetabling or personnel allocation can be modeled and solved using discrete constraint programming languages. However, while existing constraint solving software solves such problems quickly in many cases, these systems involve specialized languages that require significant time and effort to learn and apply. These languages are typically text-based and often difficult to interpret and understand quickly, especially for people without engineering or mathematics backgrounds. Visualization could provide an alternative way to model and understand such problems. Although many visual programming languages exist for procedural languages, visual encoding of problem specifications has not received much attention. Future problem visualization languages could represent problem elements and their constraints unambiguously, but without unnecessary cognitive burdens for those needing to translate their problem's mental representation into diagrams. As a first step towards such languages, we executed a study that catalogs how people represent constraint problems graphically. We studied three groups with different expertise: non-computer scientists, computer scientists and constraint programmers and analyzed their marks on paper (e.g., arrows), gestures (e.g., pointing) and the mappings to problem concepts (e.g., containers, sets). We provide foundations to guide future tool designs allowing people to effectively grasp, model and solve problems through visual representations.",Xu Zhu;Miguel A. Nacenta;Özgür Akgün;Peter Nightingale,Xu Zhu;Miguel A. Nacenta;Özgür Akgün;Peter Nightingale,"School of Computer Science, University of St. Andrews, St. Andrews, United Kingdom;School of Computer Science, University of St. Andrews, St. Andrews, United Kingdom;School of Computer Science, University of St. Andrews, St. Andrews, United Kingdom;School of Computer Science, University of St. Andrews, St. Andrews, United Kingdom",0.1109/tvcg.2010.177;10.1109/tvcg.2011.251;10.1109/tvcg.2017.2745919;10.1109/tvcg.2008.137;10.1109/tvcg.2015.2467551;10.1109/tvcg.2016.2598545,"Problem visualization,problem modeling,problem solving,constraint programming,visual programming languages",,5,87,581,,
TVCG,2021,Phoenixmap: An Abstract Approach to Visualize 2D Spatial Distributions,10.1109/tvcg.2019.2945960,http://dx.doi.org/10.1109/TVCG.2019.2945960,2000,2014,J,"The multidimensional nature of spatial data poses a challenge for visualization. In this paper, we introduce Phoenixmap, a simple abstract visualization method to address the issue of visualizing multiple spatial distributions at once. The Phoenixmap approach starts by identifying the enclosed outline of the point collection, then assigns different widths to outline segments according to the segments' corresponding inside regions. Thus, one 2D distribution is represented as an outline with varied thicknesses. Phoenixmap is capable of overlaying multiple outlines and comparing them across categories of objects in a 2D space. We chose heatmap as a benchmark spatial visualization method and conducted user studies to compare performances among Phoenixmap, heatmap, and dot distribution map. Based on the analysis and participant feedback, we demonstrate that Phoenixmap 1) allows users to perceive and compare spatial distribution data efficiently; 2) frees up graphics space with a concise form that can provide visualization design possibilities like overlapping; and 3) provides a good quantitative perceptual estimating capability given the proper legends. Finally, we discuss several possible applications of Phoenixmap and present one visualization of multiple species of birds' active regions in a nature preserve.",Junhan Zhao;Xiang Liu;Chen Guo;Zhenyu Cheryl Qian;Yingjie Victor Chen,Junhan Zhao;Xiang Liu;Chen Guo;Zhenyu Cheryl Qian;Yingjie Victor Chen,"Department of Computer Graphics Technology, Purdue University, West Lafayette, IN, USA;Department of Computer and Information Technology, Purdue University, West Lafayette, IN, USA;School of Media Arts and Design, James Madison University, Harrisonburg, VA, USA;Department of Art and Design, Purdue University, West Lafayette, IN, USA;Department of Computer Graphics Technology, Purdue University, West Lafayette, IN, USA",0.1109/tvcg.2007.70623;10.1109/tvcg.2006.198;10.1109/tvcg.2011.181;10.1109/tvcg.2013.66;10.1109/visual.2001.964550;10.1109/tvcg.2012.265;10.1109/tvcg.2013.65,"Data visualization,visualization,algorithms,geospastial analysis",,5,46,675,,
TVCG,2022,Augmenting Parallel Coordinates Plots With Color-Coded Stacked Histograms,10.1109/tvcg.2020.3038446,http://dx.doi.org/10.1109/TVCG.2020.3038446,2563,2576,J,"We introduce Parallel Histogram Plot (PHP), a technique that overcomes the innate limitations of parallel coordinates plot (PCP) by attaching stacked-bar histograms with discrete color schemes to PCP. The color-coded histograms enable users to see an overview of the whole data without cluttering or scalability issues. Each rectangle in the PHP histograms is color coded according to the data ranking by a selected attribute. This color-coding scheme allows users to visually examine relationships between attributes, even between those that are displayed far apart, without repositioning or reordering axes. We adopt the Visual Information Seeking Mantra so that the polylines of the original PCP can be used to show details of a small number of selected items when the cluttering problem subsides. We also design interactions, such as a focus+context technique, to help users investigate small regions of interest in a space-efficient manner. We provide a real-world example in which PHP is effectively utilized compared with other visualizations, and we perform a controlled user study to evaluate the performance of PHP in helping users estimate the correlation between attributes. The results demonstrate that the performance of PHP was consistent in the estimation of correlations between two attributes regardless of the distance between them.",Jinwook Bok;Bo Hyoung Kim;Jinwook Seo,Jinwook Bok;Bohyoung Kim;Jinwook Seo,"Seoul National University, Seoul, South Korea;Hankuk University of Foreign Studies, Seoul, South Korea;Seoul National University, Seoul, South Korea",0.1109/tvcg.2006.170;10.1109/tvcg.2018.2808969;10.1109/tvcg.2015.2467872;10.1109/tvcg.2007.70523;10.1109/tvcg.2011.166;10.1109/infvis.2002.1173157;10.1109/tvcg.2009.131;10.1109/tvcg.2011.201;10.1109/tvcg.2010.184;10.1109/tvcg.2017.2661309;10.1109/tvcg.2006.138;10.1109/infvis.2004.68;10.1109/tvcg.2016.2598830;10.1109/tvcg.2015.2466992;10.1109/tvcg.2009.179,"Parallel coordinates plots,parallel histogram plots,color-coded stacked histogram",,7,48,1619,,
TVCG,2020,eFESTA: Ensemble Feature Exploration with Surface Density Estimates,10.1109/tvcg.2018.2879866,http://dx.doi.org/10.1109/TVCG.2018.2879866,1716,1731,J,"We propose surface density estimate (SDE) to model the spatial distribution of surface features-isosurfaces, ridge surfaces, and streamsurfaces-in 3D ensemble simulation data. The inputs of SDE computation are surface features represented as polygon meshes, and no field datasets are required (e.g., scalar fields or vector fields). The SDE is defined as the kernel density estimate of the infinite set of points on the input surfaces and is approximated by accumulating the surface densities of triangular patches. We also propose an algorithm to guide the selection of a proper kernel bandwidth for SDE computation. An ensemble Feature Exploration method based on Surface densiTy EstimAtes (eFESTA) is then proposed to extract and visualize the major trends of ensemble surface features. For an ensemble of surface features, each surface is first transformed into a density field based on its contribution to the SDE, and the resulting density fields are organized into a hierarchical representation based on the pairwise distances between them. The hierarchical representation is then used to guide visual exploration of the density fields as well as the underlying surface features. We demonstrate the application of our method using isosurface in ensemble scalar fields, Lagrangian coherent structures in uncertain unsteady flows, and streamsurfaces in ensemble fluid flows.",Wenbin He;Hanqi Guo 0001;Han-Wei Shen;Tom Peterka,Wenbin He;Hanqi Guo;Han-Wei Shen;Tom Peterka,"Department of Computer Science and Engineering, Ohio State University, Columbus, USA;Mathematics and Computer Science Division, Argonne National Laboratory, Lemont, USA;Department of Computer Science and Engineering, Ohio State University, Columbus, USA;Mathematics and Computer Science Division, Argonne National Laboratory, Lemont, USA",0.1109/tvcg.2017.2744099;10.1109/visual.1996.568116;10.1109/tvcg.2011.203;10.1109/tvcg.2015.2467204;10.1109/tvcg.2016.2598868;10.1109/tvcg.2009.131;10.1109/tvcg.2011.181;10.1109/tvcg.2010.181;10.1109/tvcg.2013.143;10.1109/tvcg.2014.2346455;10.1109/mcg.2015.70;10.1109/tvcg.2013.208;10.1109/tvcg.2016.2637333;10.1109/tvcg.2015.2467958;10.1109/tvcg.2017.2745178;10.1109/tvcg.2012.238,"Density estimation,ensemble data visualization,uncertainty visualization,feature exploration",,4,71,475,,
TVCG,2022,Visual Analysis of Multi-Parameter Distributions Across Ensembles of 3D Fields,10.1109/tvcg.2021.3061925,http://dx.doi.org/10.1109/TVCG.2021.3061925,3530,3545,J,"For an ensemble of 3D multi-parameter fields, we present a visual analytics workflow to analyse whether and which parts of a selected multi-parameter distribution is present in all ensemble members. Supported by a parallel coordinate plot, a multi-parameter brush is applied to all ensemble members to select data points with similar multi-parameter distribution. By a combination of spatial sub-division and a covariance analysis of partitioned sub-sets of data points, a tight partition in multi-parameter space with reduced number of selected data points is obtained. To assess the representativeness of the selected multi-parameter distribution across the ensemble, we propose a novel extension of violin plots that can show multiple parameter distributions simultaneously. We investigate the visual design that effectively conveys (dis-)similarities in multi-parameter distributions, and demonstrate that users can quickly comprehend parameter-specific differences regarding distribution shape and representativeness from a side-by-side view of these plots. In a 3D spatial view, users can analyse and compare the spatial distribution of selected data points in different ensemble members via interval-based isosurface raycasting. In two real-world application cases we show how our approach is used to analyse the multi-parameter distributions across an ensemble of 3D fields.",Alexander Kumpf;Josef Stumpfegger;Patrick Fabian Härtl;Rüdiger Westermann,Alexander Kumpf;Josef Stumpfegger;Patrick Fabian Härtl;Rüdiger Westermann,"Computer Graphics & Visualization Group, Technical University of Munich (TUM), München, Germany;Computer Graphics & Visualization Group, Technical University of Munich (TUM), München, Germany;Computer Graphics & Visualization Group, Technical University of Munich (TUM), München, Germany;Computer Graphics & Visualization Group, Technical University of Munich (TUM), München, Germany",0.1109/tvcg.2012.110;10.1109/tvcg.2015.2466992;10.1109/vast.2015.7347634;10.1109/tvcg.2011.248;10.1109/tvcg.2018.2853721;10.1109/visual.1994.346302;10.1109/tvcg.2013.143;10.1109/infvis.2004.60;10.1109/tvcg.2015.2498554;10.1109/tvcg.2018.2864801;10.1109/tvcg.2017.2744099;10.1109/tvcg.2014.2346321;10.1109/tvcg.2010.181;10.1109/tvcg.2018.2808969;10.1109/tvcg.2015.2467872;10.1109/tvcg.2010.138;10.1109/tvcg.2014.2346448;10.1109/tvcg.2015.2467436;10.1109/tvcg.2010.190;10.1109/tvcg.2012.65;10.1109/infvis.2002.1173161;10.1109/tvcg.2008.167,"Ensemble visualization,multi-parameter visualization,3D rendering,distribution comparison,parallel coordinates",,3,69,525,,
TVCG,2022,Multiscale Unfolding: Illustratively Visualizing the Whole Genome at a Glance,10.1109/tvcg.2021.3065443,http://dx.doi.org/10.1109/TVCG.2021.3065443,3456,3470,J,"We present Multiscale Unfolding, an interactive technique for illustratively visualizing multiple hierarchical scales of DNA in a single view, showing the genome at different scales and demonstrating how one scale spatially folds into the next. The DNA's extremely long sequential structure—arranged differently on several distinct scale levels—is often lost in traditional 3D depictions, mainly due to its multiple levels of dense spatial packing and the resulting occlusion. Furthermore, interactive exploration of this complex structure is cumbersome, requiring visibility management like cut-aways. In contrast to existing temporally controlled multiscale data exploration, we allow viewers to always see and interact with any of the involved scales. For this purpose we separate the depiction into constant-scale and scale transition zones. Constant-scale zones maintain a single-scale representation, while still linearly unfolding the DNA. Inspired by illustration, scale transition zones connect adjacent constant-scale zones via level unfolding, scaling, and transparency. We thus represent the spatial structure of the whole DNA macro-molecule, maintain its local organizational characteristics, linearize its higher-level organization, and use spatially controlled, understandable interpolation between neighboring scales. We also contribute interaction techniques that provide viewers with a coarse-to-fine control for navigating within our all-scales-in-one-view representations and visual aids to illustrate the size differences. Overall, Multiscale Unfolding allows viewers to grasp the DNA's structural composition from chromosomes to the atoms, with increasing levels of “unfoldedness,” and can be applied in data-driven illustration and communication.",Sarkis Halladjian;David Kouril;Haichao Miao;M. Eduard Gröller;Ivan Viola;Tobias Isenberg 0001,Sarkis Halladjian;David Kouřil;Haichao Miao;M. Eduard Gröller;Ivan Viola;Tobias Isenberg,"CNRS, Inria, LISN, Université Paris-Saclay, Saint-Aubin, France;TU Wien, Vienna, Austria;TU Wien, Vienna, Austria;TU Wien, Vienna, Austria;King Abdullah University of Science and Technology, Thuwal, Saudi Arabia;CNRS, Inria, LISN, Université Paris-Saclay, Saint-Aubin, France",0.1109/tvcg.2007.70515;10.1109/tvcg.2020.2975583;10.1109/tvcg.2007.70550;10.1109/tvcg.2017.2744199;10.1109/tvcg.2019.2934334;10.1109/tvcg.2017.2744518;10.1109/tvcg.2017.2744278;10.1109/tvcg.2011.192;10.1109/tvcg.2019.2934555;10.1109/tvcg.2013.124;10.1109/visual.1991.175794;10.1109/tvcg.2019.2934283;10.1109/tvcg.2015.2403323;10.1109/tvcg.2017.2743958;10.1109/tvcg.2017.2743981,"Multiscale visualization,spatially-controlled scale transition,visual abstraction,illustrative visualization,genome,DNA",,4,72,889,,
TVCG,2019,Popup-Plots: Warping Temporal Data Visualization,10.1109/tvcg.2018.2841385,http://dx.doi.org/10.1109/TVCG.2018.2841385,2443,2457,J,"Temporal data visualization is used to analyze dependent variables that vary over time, with time being an independent variable. Visualizing temporal data is inherently difficult, due to the many aspects that need to be communicated to the users (e.g., time and variable changes). This is an important topic in visualization, and a wide range of visualization techniques dealing with different tasks have already been designed. In this paper we propose popup-plots, a novel concept where the common interaction of 3D rotation is used to navigate through the data. This allows the users to view the data from different perspectives without having to learn and adapt to new interaction concepts. Popup-plots are therefore a novel method for visualizing and interacting with dependent variables over time. We extend 2D plots with the temporal information by bending the space according to the time. The bending is calculated based on a spherical coordinates approach, which is continuously influenced by the viewing direction towards the plot. Hence, the plot can be viewed from various angles with seamless transitions in between, offering the possibility to analyze different aspects of the represented data. As the current viewing direction is inherently depicted by the shape of the data, the users are able to deduce which part of the data is currently viewed. The temporal information is encoded into the visualization itself, resembling annual rings of a tree. We demonstrate our method by applying it to data from two different domains, comprising measurements at spatial positions over time, and we also evaluated the usability of our solution.",Johanna Schmidt;Dominik Fleischmann;Bernhard Preim;Norbert Brändle;Gabriel Mistelbauer,Johanna Schmidt;Dominik Fleischmann;Bernhard Preim;Norbert Brändle;Gabriel Mistelbauer,"AIT Austrian Institute of Technology, Vienna, Austria;Stanford University, Stanford University, Stanford, CA;Otto-von-Guericke University, Magdeburg, Germany;AIT Austrian Institute of Technology, Vienna, Austria;Otto-von-Guericke University, Magdeburg, Germany",0.1109/infvis.2003.1249004;10.1109/infvis.2001.963273;10.1109/tvcg.2015.2467851;10.1109/tvcg.2015.2466992;10.1109/infvis.2002.1173155;10.1109/tvcg.2013.196;10.1109/infvis.2000.885098;10.1109/tvcg.2008.166;10.1109/tvcg.2012.265,"Temporal data,time-dependent visualization,3D plots,ellipsoidal coordinate system",,4,55,761,,
TVCG,2021,Dataless Sharing of Interactive Visualization,10.1109/tvcg.2020.2984708,http://dx.doi.org/10.1109/TVCG.2020.2984708,3656,3669,J,"Interactive visualization has become a powerful insight-revealing medium. However, the close dependency of interactive visualization on its data inhibits its shareability. Users have to choose between the two extremes of (i) sharing non-interactive dataless formats such as images and videos, or (ii) giving access to their data and software to others with no control over how the data will be used. In this work, we fill the gap between the two extremes and present a new system, called Loom. Loom captures interactive visualizations as standalone dataless objects. Users can interact with Loom objects as if they still have the original software and data that created those visualizations. Yet, Loom objects are completely independent and can therefore be shared online without requiring the data or the visualization software. Loom objects are efficient to store and use, and provide privacy preserving mechanisms. We demonstrate Loom's efficacy with examples of scientific visualization using Paraview, information visualization using Tableau, and journalistic visualization from New York Times.",Mohammad Raji;Jeremiah Duncan;Tanner Hobson;Jian Huang 0007,Mohammad Raji;Jeremiah Duncan;Tanner Hobson;Jian Huang,"University of Tennessee, Knoxville, TN, USA;University of Tennessee, Knoxville, TN, USA;University of Tennessee, Knoxville, TN, USA;University of Tennessee, Knoxville, TN, USA",0.1109/tvcg.2016.2599030;10.1109/visual.2005.1532788;10.1109/tvcg.2008.184;10.1109/tvcg.2009.120;10.1109/tvcg.2011.185;10.1109/tvcg.2013.124;10.1109/tvcg.2008.137;10.1109/tvcg.2018.2865039,"Shareable visualizations,visualization recordings,user interaction",,4,48,969,,
TVCG,2020,Measuring the Effects of Scalar and Spherical Colormaps on Ensembles of DMRI Tubes,10.1109/tvcg.2019.2898438,http://dx.doi.org/10.1109/TVCG.2019.2898438,2818,2833,J,"We report empirical study results on the color encoding of ensemble scalar and orientation to visualize diffusion magnetic resonance imaging (DMRI) tubes. The experiment tested six scalar colormaps for average fractional anisotropy (FA) tasks (grayscale, blackbody, diverging, isoluminant-rainbow, extended-blackbody, and coolwarm) and four three-dimensional (3D) spherical colormaps for tract tracing tasks (uniform gray, absolute, eigenmaps, and Boy's surface embedding). We found that extended-blackbody, coolwarm, and blackbody remain the best three approaches for identifying ensemble average in 3D. Isoluminant-rainbow colormap led to the same ensemble mean accuracy as other colormaps. However, more than 50 percent of the answers consistently had higher estimates of the ensemble average, independent of the mean values. The number of hues, not luminance, influences ensemble estimates of mean values. For ensemble orientation-tracing tasks, we found that both Boy's surface embedding (greatest spatial resolution and contrast) and absolute colormaps (lowest spatial resolution and contrast) led to more accurate answers than the eigenmaps scheme (medium resolution and contrast), acting as the uncanny-valley phenomenon of visualization design in terms of accuracy. Absolute colormap broadly used in brain science is a good default spherical colormap. We could conclude from our study that human visual processing of a chunk of colors differs from that of single colors.",Jian Chen 0006;Guohao Zhang;Wesley Chiou;David H. Laidlaw;Alexander P. Auchus,Jian Chen;Guohao Zhang;Wesley Chiou;David H. Laidlaw;Alexander P. Auchus,"Computer Science and Engineering Department, The Ohio State University, USA;Department of Computer Science and Electrical Engineering, University of Maryland, Baltimore County, USA;Department of Computer Science and Electrical Engineering, University of Maryland, Baltimore County, USA;Computer Science Department, Brown University, Providence, USA;Neurology Department, University of Mississippi Medical Center, Jackson, USA",0.1109/tvcg.2015.2467551;10.1109/tvcg.2011.110;10.1109/tvcg.2011.25;10.1109/visual.2001.964510;10.1109/tvcg.2009.126;10.1109/tvcg.2013.126;10.1109/tvcg.2010.181;10.1109/tvcg.2014.2346428;10.1109/tvcg.2009.125;10.1109/tvcg.2016.2539949;10.1109/tvcg.2006.172;10.1109/tvcg.2009.111;10.1109/visual.1999.809886;10.1109/tvcg.2012.216;10.1109/tvcg.2011.192;10.1109/tvcg.2006.180;10.1109/tvcg.2017.2744359;10.1109/tvcg.2017.2743978;10.1109/visual.2002.1183788;10.1109/tvcg.2016.2598918,"Ensemble visualization,diffusion magnetic resonance imaging,quantitative validation,colormap",,4,79,838,,
TVCG,2020,Ray-Based Exploration of Large Time-Varying Volume Data Using Per-Ray Proxy Distributions,10.1109/tvcg.2019.2920130,http://dx.doi.org/10.1109/TVCG.2019.2920130,3299,3313,J,"The analysis and visualization of data created from simulations on modern supercomputers is a daunting challenge because the incredible compute power of modern supercomputers allow scientists to generate datasets with very high spatial and temporal resolutions. The limited bandwidth and capacity of networking and storage devices connecting supercomputers to analysis machines become the major bottleneck for data analysis such that simply moving the whole dataset from the supercomputer to a data analysis machine is infeasible. A common approach to visualize high temporal resolution simulation datasets under constrained I/O is to reduce the sampling rate in the temporal domain while preserving the original spatial resolution at the time steps. Data interpolation between the sampled time steps alone may not be a viable option since it may suffer from large errors, especially when using a lower sampling rate. We present a novel ray-based representation storing ray based histograms and depth information that recovers the evolution of volume data between sampled time steps. Our view-dependent proxy allows for a good trade off between compactly representing the time-varying data and leveraging temporal coherence within the data by utilizing interpolation between time steps, ray histograms, depth information, and codebooks. Our approach is able to provide fast rendering in the context of transfer function exploration to support visualization of feature evolution in time-varying data.",Ko-Chih Wang;Tzu-Hsuan Wei;Naeem Shareef;Han-Wei Shen,Ko-Chih Wang;Tzu-Hsuan Wei;Naeem Shareef;Han-Wei Shen,"Department of Computer Science and Engineering, Ohio State University, Columbus, OH, USA;Department of Computer Science and Engineering, Ohio State University, Columbus, OH, USA;Department of Computer Science and Engineering, Ohio State University, Columbus, OH, USA;Department of Computer Science and Engineering, Ohio State University, Columbus, OH, USA",0.1109/mcg.2016.48;10.1109/tvcg.2013.152;10.1109/tvcg.2006.137;10.1109/tvcg.2014.2346324;10.1109/tvcg.2010.215;10.1109/tvcg.2016.2620975;10.1109/visual.2001.964520;10.1109/tvcg.2006.143;10.1109/tvcg.2016.2598604;10.1109/visual.2001.964531,"Data visualization,time-varying data,large data modeling,scientific simulation",,5,40,426,,
TVCG,2021,Void Space Surfaces to Convey Depth in Vessel Visualizations,10.1109/tvcg.2020.2993992,http://dx.doi.org/10.1109/TVCG.2020.2993992,3913,3925,J,"To enhance depth perception and thus data comprehension, additional depth cues are often used in 3D visualizations of complex vascular structures. There is a variety of different approaches described in the literature, ranging from chromadepth color coding over depth of field to glyph-based encodings. Unfortunately, the majority of existing approaches suffers from the same problem: As these cues are directly applied to the geometry's surface, the display of additional information on the vessel wall, such as other modalities or derived attributes, is impaired. To overcome this limitation we propose Void Space Surfaces which utilizes empty space in between vessel branches to communicate depth and their relative positioning. This allows us to enhance the depth perception of vascular structures without interfering with the spatial data and potentially superimposed parameter information. With this article, we introduce Void Space Surfaces, describe their technical realization, and show their application to various vessel trees. Moreover, we report the outcome of two user studies which we have conducted in order to evaluate the perceptual impact of Void Space Surfaces compared to existing vessel visualization techniques and discuss expert feedback.",Julian Kreiser;Pedro Hermosilla;Timo Ropinski,Julian Kreiser;Pedro Hermosilla;Timo Ropinski,"Visual Computing Group, Ulm University, Ulm, Germany;Visual Computing Group, Ulm University, Ulm, Germany;Visual Computing Group, Ulm University, Ulm, Germany",0.1109/tvcg.2006.172;10.1109/visual.2000.885694;10.1109/visual.2001.964538;10.1109/tvcg.2008.123;10.1109/tvcg.2013.240;10.1109/tvcg.2011.192;10.1109/tvcg.2017.2744438,"Depth perception,void space surface,chromadepth",,3,40,419,,
TVCG,2021,Shape-Driven Coordinate Ordering for Star Glyph Sets via Reinforcement Learning,10.1109/tvcg.2021.3052167,http://dx.doi.org/10.1109/TVCG.2021.3052167,3034,3047,J,"We present a neural optimization model trained with reinforcement learning to solve the coordinate ordering problem for sets of star glyphs. Given a set of star glyphs associated to multiple class labels, we propose to use shape context descriptors to measure the perceptual distance between pairs of glyphs, and use the derived silhouette coefficient to measure the perception of class separability within the entire set. To find the optimal coordinate order for the given set, we train a neural network using reinforcement learning to reward orderings with high silhouette coefficients. The network consists of an encoder and a decoder with an attention mechanism. The encoder employs a recurrent neural network (RNN) to encode input shape and class information, while the decoder together with the attention mechanism employs another RNN to output a sequence with the new coordinate order. In addition, we introduce a neural network to efficiently estimate the similarity between shape context descriptors, which allows to speed up the computation of silhouette coefficients and thus the training of the axis ordering network. Two user studies demonstrate that the orders provided by our method are preferred by users for perceiving class separation. We tested our model on different settings to show its robustness and generalization abilities and demonstrate that it allows to order input sets with unseen data size, data dimension, or number of classes. We also demonstrate that our model can be adapted to coordinate ordering of other types of plots such as RadViz by replacing the proposed shape-aware silhouette coefficient with the corresponding quality metric to guide network training.",Ruizhen Hu;Bin Chen;Juzhan Xu;Oliver van Kaick;Oliver Deussen;Hui Huang 0004,Ruizhen Hu;Bin Chen;Juzhan Xu;Oliver van Kaick;Oliver Deussen;Hui Huang,"College of Computer Science and Software Engineering, Shenzhen University, Shenzhen, China;College of Computer Science and Software Engineering, Shenzhen University, Shenzhen, China;College of Computer Science and Software Engineering, Shenzhen University, Shenzhen, China;School of Computer Science, Carleton University, Ottawa, ON, Canada;Department of Computer and Information Science, University of Konstanz, Konstanz, Germany;College of Computer Science and Software Engineering, Shenzhen University, Shenzhen, China",0.1109/infvis.1998.729559;10.1109/vast.2009.5332628;10.1109/vast.2010.5652433;10.1109/tvcg.2014.2346426;10.1109/visual.1997.663916;10.1109/tvcg.2010.184,"Star glyph set,coordinate ordering,reinforcement learning,shape context",,3,28,377,,X
TVCG,2021,A Progressive Approach to Scalar Field Topology,10.1109/tvcg.2021.3060500,http://dx.doi.org/10.1109/TVCG.2021.3060500,2833,2850,J,"This article introduces progressive algorithms for the topological analysis of scalar data. Our approach is based on a hierarchical representation of the input data and the fast identification of topologically invariant vertices, which are vertices that have no impact on the topological description of the data and for which we show that no computation is required as they are introduced in the hierarchy. This enables the definition of efficient coarse-to-fine topological algorithms, which leverage fast update mechanisms for ordinary vertices and avoid computation for the topologically invariant ones. We demonstrate our approach with two examples of topological algorithms (critical point extraction and persistence diagram computation), which generate interpretable outputs upon interruption requests and which progressively refine them otherwise. Experiments on real-life datasets illustrate that our progressive strategy, in addition to the continuous visual feedback it provides, even improves run time performance with regard to non-progressive algorithms and we describe further accelerations with shared-memory parallelism. We illustrate the utility of our approach in batch-mode and interactive setups, where it respectively enables the control of the execution time of complete topological pipelines as well as previews of the topological features found in a dataset, with progressive updates delivered within interactive times.",Jules Vidal;Pierre Guillou;Julien Tierny,Jules Vidal;Pierre Guillou;Julien Tierny,"CNRS, Sorbonne Université, Paris, France;CNRS, Sorbonne Université, Paris, France;CNRS, Sorbonne Université, Paris, France",0.1109/tvcg.2018.2864848;10.1109/infvis.2004.60;10.1109/tvcg.2008.110;10.1109/tvcg.2009.163;10.1109/tvcg.2017.2743980;10.1109/visual.2004.96;10.1109/tvcg.2014.2346403;10.1109/visual.2002.1183810;10.1109/tvcg.2009.186;10.1109/visual.2000.885703;10.1109/tvcg.2016.2599017;10.1109/tvcg.2017.2743938;10.1109/tvcg.2011.269;10.1109/tvcg.2011.249;10.1109/tvcg.2007.70603;10.1109/tvcg.2015.2467432;10.1109/tvcg.2006.186,"Topological data analysis,scalar data,progressive visualization",,3,106,394,,X
TVCG,2021,Interactive Focus+Context Rendering for Hexahedral Mesh Inspection,10.1109/tvcg.2021.3074607,http://dx.doi.org/10.1109/TVCG.2021.3074607,3505,3518,J,"The visual inspection of a hexahedral mesh with respect to element quality is difficult due to clutter and occlusions that are produced when rendering all element faces or their edges simultaneously. Current approaches overcome this problem by using focus on specific elements that are then rendered opaque, and carving away all elements occluding their view. In this work, we make use of advanced GPU shader functionality to generate a focus+context rendering that highlights the elements in a selected region and simultaneously conveys the global mesh structure and deformation field. To achieve this, we propose a gradual transition from edge-based focus rendering to volumetric context rendering, by combining fragment shader-based edge and face rendering with per-pixel fragment lists. A fragment shader smoothly transitions between wireframe and face-based rendering, including focus-dependent rendering style and depth-dependent edge thickness and halos, and per-pixel fragment lists are used to blend fragments in correct visibility order. To maintain the global mesh structure in the context regions, we propose a new method to construct a sheet-based level-of-detail hierarchy and smoothly blend it with volumetric information. The user guides the exploration process by moving a lens-like hotspot. Since all operations are performed on the GPU, interactive frame rates are achieved even for large meshes.",Christoph Neuhauser;Junpeng Wang;Rüdiger Westermann,Christoph Neuhauser;Junpeng Wang;Rüdiger Westermann,"Computer Graphics & Visualization Group, Technische Universität München, Garching, Germany;Computer Graphics & Visualization Group, Technische Universität München, Garching, Germany;Computer Graphics & Visualization Group, Technische Universität München, Garching, Germany",0.1109/visual.2003.1250390;10.1109/tvcg.2006.110;10.1109/tvcg.2009.138;10.1109/tvcg.2018.2864827;10.1109/tvcg.2017.2744238;10.1109/tvcg.2010.212;10.1109/tvcg.2020.2975795,"Visualization of hex-meshes,real-time rendering,GPUs",,3,42,377,,X
TVCG,2022,"Geometry-Driven Detection, Tracking and Visual Analysis of Viscous and Gravitational Fingers",10.1109/tvcg.2020.3017568,http://dx.doi.org/10.1109/TVCG.2020.3017568,1514,1528,J,"Viscous and gravitational flow instabilities cause a displacement front to break up into finger-like fluids. The detection and evolutionary analysis of these fingering instabilities are critical in multiple scientific disciplines such as fluid mechanics and hydrogeology. However, previous detection methods of the viscous and gravitational fingers are based on density thresholding, which provides limited geometric information of the fingers. The geometric structures of fingers and their evolution are important yet little studied in the literature. In this article, we explore the geometric detection and evolution of the fingers in detail to elucidate the dynamics of the instability. We propose a ridge voxel detection method to guide the extraction of finger cores from three-dimensional (3D) scalar fields. After skeletonizing finger cores into skeletons, we design a spanning tree based approach to capture how fingers branch spatially from the finger skeletons. Finally, we devise a novel geometric-glyph augmented tracking graph to study how the fingers and their branches grow, merge, and split over time. Feedback from earth scientists demonstrates the usefulness of our approach to performing spatio-temporal geometric analyses of fingers.",Jiayi Xu 0001;Soumya Dutta;Wenbin He;Joachim Moortgat;Han-Wei Shen,Jiayi Xu;Soumya Dutta;Wenbin He;Joachim Moortgat;Han-Wei Shen,"Department of Computer Science and Engineering, The Ohio State University, Columbus, OH, USA;Data Science at Scale Team, Los Alamos National Laboratory, Los Alamos, NM, USA;Department of Computer Science and Engineering, The Ohio State University, Columbus, OH, USA;School of Earth Sciences, The Ohio State University, Columbus, OH, USA;Department of Computer Science and Engineering, The Ohio State University, Columbus, OH, USA",0.1109/tvcg.2017.2743938;10.1109/tvcg.2018.2864849;10.1109/tvcg.2008.165;10.1109/visual.1991.175815;10.1109/visual.1996.567807;10.1109/tvcg.2010.270;10.1109/tvcg.2015.2467413,"Viscous and gravitational fingering,topological and geometric data analysis,ridge detection,spatio-temporal visualization,tracking graph",,1,50,359,,
TVCG,2022,TransVis: Integrated Distant and Close Reading of Othello Translations,10.1109/tvcg.2020.3012778,http://dx.doi.org/10.1109/TVCG.2020.3012778,1397,1414,J,"Studying variation among time-evolved translations is a valuable research area for cultural heritage. Understanding how and why translations vary reveals cultural, ideological, and even political influences on literature as well as author relations. In this article, we introduce a novel integrated visual application to support distant and close reading of a collection of Othello translations. We present a new interactive application that provides an alignment overview of all the translations and their correspondences in parallel with smooth zooming and panning capability to integrate distant and close reading within the same view. We provide a range of filtering and selection options to customize the alignment overview as well as focus on specific subsets. Selection and filtering are responsive to expert user preferences and update the analytical text metrics interactively. Also, we introduce a customized view for close reading which preserves the history of selections and the alignment overview state and enables backtracing and re-examining them. Finally, we present a new Term-Level Comparisons view (TLC) to compare and convey relative term weighting in the context of an alignment. Our visual design is guided by, used and evaluated by a domain expert specialist in German translations of Shakespeare.",Mohammad Alharbi;Robert S. Laramee;Tom Cheesman,Mohammad Alharbi;Robert S Laramee;Tom Cheesman,"Department of Computer Science, Swansea University, Swansea, UK;School of Computer Science, University of Nottingham, Nottingham, UK;College of Arts and Humanities, Swansea University, Swansea, UK",0.1109/tvcg.2012.213;10.1109/tvcg.2015.2511718;10.1109/tvcg.2007.70539;10.1109/infvis.2001.963287;10.1109/tvcg.2006.170;10.1109/tvcg.2017.2744199;10.1109/tvcg.2013.130;10.1109/vast.2009.5333443;10.1109/vast.2007.4389004;10.1109/tvcg.2014.2346677;10.1109/tvcg.2007.70515;10.1109/visual.1990.146402;10.1109/tvcg.2014.2346431;10.1109/tvcg.2013.124;10.1109/tvcg.2015.2466992,"Text visualization,othello,parallel translations",,3,91,521,,
TVCG,2022,3D Virtual Pancreatography,10.1109/tvcg.2020.3020958,http://dx.doi.org/10.1109/TVCG.2020.3020958,1457,1468,J,"We present 3D virtual pancreatography (VP), a novel visualization procedure and application for non-invasive diagnosis and classification of pancreatic lesions, the precursors of pancreatic cancer. Currently, non-invasive screening of patients is performed through visual inspection of 2D axis-aligned CT images, though the relevant features are often not clearly visible nor automatically detected. VP is an end-to-end visual diagnosis system that includes: A machine learning based automatic segmentation of the pancreatic gland and the lesions, a semi-automatic approach to extract the primary pancreatic duct, a machine learning based automatic classification of lesions into four prominent types, and specialized 3D and 2D exploratory visualizations of the pancreas, lesions and surrounding anatomy. We combine volume rendering with pancreas- and lesion-centric visualizations and measurements for effective diagnosis. We designed VP through close collaboration and feedback from expert radiologists, and evaluated it on multiple real-world CT datasets with various pancreatic lesions and case studies examined by the expert radiologists.",Shreeraj Jadhav;Konstantin Dmitriev;Joseph Marino;Matthew A. Barish;Arie E. Kaufman,Shreeraj Jadhav;Konstantin Dmitriev;Joseph Marino;Matthew Barish;Arie E. Kaufman,"Computer Science Department, Stony Brook University, Stony Brook, NY, USA;Computer Science Department, Stony Brook University, Stony Brook, NY, USA;Computer Science Department, Stony Brook University, Stony Brook, NY, USA;Department of Radiology, Stony Brook Medicine, Stony Brook, NY, USA;Computer Science Department, Stony Brook University, Stony Brook, NY, USA",0.1109/tvcg.2014.2346405;10.1109/tvcg.2009.136;10.1109/visual.2004.104;10.1109/tvcg.2016.2598791;10.1109/tvcg.2010.134;10.1109/visual.2003.1250414;10.1109/tvcg.2013.215;10.1109/tvcg.2016.2598826;10.1109/visual.2003.1250353;10.1109/tvcg.2010.200;10.1109/visual.2000.885732;10.1109/visual.1999.809912;10.1109/visual.1998.745337,"Visual diagnosis,pancreatic cancer,automatic segmentation,lesion classification,planar reformation",,3,66,651,,
TVCG,2022,"TimeTubesX: A Query-Driven Visual Exploration of Observable, Photometric, and Polarimetric Behaviors of Blazars",10.1109/tvcg.2020.3025090,http://dx.doi.org/10.1109/TVCG.2020.3025090,1917,1929,J,"Blazars are celestial bodies of high interest to astronomers. In particular, through the analysis of photometric and polarimetric observations of blazars, astronomers aim to understand the physics of the blazar's relativistic jet. However, it is challenging to recognize correlations and time variations of the observed polarization, intensity, and color of the emitted light. In our prior study, we proposed TimeTubes to visualize a blazar dataset as a 3D volumetric tube. In this paper, we build primarily on the TimeTubes representation of blazar datasets to present a new visual analytics environment named TimeTubesX, into which we have integrated sophisticated feature and pattern detection techniques for effective location of observable and recurring time variation patterns in long-term, multi-dimensional datasets. Automatic feature extraction detects time intervals corresponding to well-known blazar behaviors. Dynamic visual querying allows users to search long-term observations for time intervals similar to a time interval of interest (query-by-example) or a sketch of temporal patterns (query-by-sketch). Users are also allowed to build up another visual query guided by the time interval of interest found in the previous process and refine the results. We demonstrate how TimeTubesX has been used successfully by domain experts for the detailed analysis of blazar datasets and report on the results.",Naoko Sawada;Makoto Uemura;Johanna Beyer;Hanspeter Pfister;Issei Fujishiro,Naoko Sawada;Makoto Uemura;Johanna Beyer;Hanspeter Pfister;Issei Fujishiro,"Keio University, Yokohama, Japan;Hiroshima University, Higashihiroshima, Japan;Harvard University, Cambridge, MA, USA;Harvard University, Cambridge, MA, USA;Keio University, Yokohama, Japan",0.1109/vast.2016.7883519;10.1109/tvcg.2009.121;10.1109/vast.2016.7883518;10.1109/vast.2007.4389013;10.1109/visual.1995.485139;10.1109/tvcg.2008.153;10.1109/tvcg.2008.182,"Visual analytics,feature extraction,visual query,multi-dimensional,time-dependent visualization,astrophysics,blazar",,1,52,437,,
TVCG,2021,AgentVis: Visual Analysis of Agent Behavior With Hierarchical Glyphs,10.1109/tvcg.2020.2985923,http://dx.doi.org/10.1109/TVCG.2020.2985923,3626,3643,J,"Glyphs representing complex behavior provide a useful and common means of visualizing multivariate data. However, due to their complex shape, overlapping, and occlusion of glyphs is a common and prominent limitation. This limits the number of discreet data tuples that can be displayed in a given image. Using a real-world application, glyphs are used to depict agent behavior in a call center. However, many call centers feature thousands of agents. A standard approach representing thousands of agents with glyphs does not scale. To accommodate the visualization incorporating thousands of glyphs we develop clustering of overlapping glyphs into a single parent glyph. This hierarchical glyph represents the mean value of all child agent glyphs, removing overlap and reduTcing visual clutter. Multi-variate clustering techniques are explored and developed in collaboration with domain experts in the call center industry. We implement dynamic control of glyph clusters according to zoom level and customized distance metrics, to utilize image space with reduced overplotting and cluttering. We demonstrate our technique with examples and a usage scenario using real-world call-center data to visualize thousands of call center agents, revealing insight into their behavior and reporting feedback from expert call-center analysts.",Dylan Rees;Robert S. Laramee;Paul Brookes;Tony D'Cruze;Gary A. Smith;Aslam Miah,Dylan Rees;Robert S. Laramee;Paul Brookes;Tony D'Cruze;Gary A. Smith;Aslam Miah,"Swansea University, Swansea, United Kingdom;University of Nottingham, Nottingham, United Kingdom;QPC Ltd, Mold, United Kingdom;QPC Ltd, Mold, United Kingdom;Aria Solutions, Calgary, AB, Canada;Llansamlet, Admiral Group plc, Swansea, United Kingdom",0.1109/tvcg.2008.136;10.1109/tvcg.2018.2808969;10.1109/tvcg.2009.111;10.1109/tvcg.2016.2549018;10.1109/visual.1993.398849;10.1109/tvcg.2016.2598918;10.1109/tvcg.2016.2598920;10.1109/infvis.2005.1532142;10.1109/tvcg.2015.2511718;10.1109/mcg.2015.25;10.1109/tvcg.2012.213;10.1109/tvcg.2017.2745138;10.1109/visual.1990.146402;10.1109/infvis.2004.60;10.1109/tvcg.2007.70535,"Glyph,clustering,multivariate visualization",,2,65,569,,
TVCG,2019,Efficient Local Statistical Analysis via Point-Wise Histograms in Tetrahedral Meshes and Curvilinear Grids,10.1109/tvcg.2018.2796555,http://dx.doi.org/10.1109/TVCG.2018.2796555,1392,1406,J,"Local histograms (i.e., point-wise histograms computed from local regions of mesh vertices) have been used in many data analysis and visualization applications. Previous methods for computing local histograms mainly work for regular or rectilinear grids only. In this paper, we develop theory and novel algorithms for computing local histograms in tetrahedral meshes and curvilinear grids. Our algorithms are theoretically sound and efficient, and work effectively and fast in practice. Our main focus is on scalar fields, but the algorithms also work for vector fields as a by-product with small, easy modifications. Our methods can benefit information theoretic and other distribution-driven analysis. The experiments demonstrate the efficacy of our new techniques, including a utility case study on tetrahedral vector field visualization.",Bo Zhou;Yi-Jen Chiang;Cong Wang,Bo Zhou;Yi-Jen Chiang;Cong Wang,"CSE Department, New York University, Brooklyn, NY;CSE Department, New York University, Brooklyn, NY;CSE Department, New York University, Brooklyn, NY",0.1109/tvcg.2009.185;10.1109/tvcg.2008.119;10.1109/tvcg.2012.231;10.1109/tvcg.2010.182;10.1109/tvcg.2013.152;10.1109/tvcg.2010.131;10.1109/tvcg.2012.118;10.1109/tvcg.2010.156;10.1109/tvcg.2011.246;10.1109/tvcg.2006.168;10.1109/tvcg.2008.160,"Tetrahedral meshes and curvilinear grids,scalar field data,vector field data,geometry-based techniques,mathematical foundations for visualization",,1,52,230,,
TVCG,2021,Imma Sort by Two or More Attributes With Interpretable Monotonic Multi-Attribute Sorting,10.1109/tvcg.2020.3043487,http://dx.doi.org/10.1109/TVCG.2020.3043487,2369,2384,J,"Many choice problems often involve multiple attributes which are mentally challenging, because only one attribute is neatly sorted while others could be randomly arranged. We hypothesize that perceiving approximately monotonic trends across multiple attributes is key to the overall interpretability of sorted results, because users can easily predict the attribute values of the next items. We extend a ranking principal curve model to tune monotonic trends in attributes and present Imma Sort to sort items by multiple attributes simultaneously by trading-off the monotonicity in the primary sorted attribute to increase the human predictability for other attributes. We characterize how it performs for varying attribute correlations, attribute preferences, list lengths and number of attributes. We further extend Imma Sort with ImmaAnchor and ImmaCenter to improve the learnability and efficiency to search sorted items with conflicting attributes. We demonstrate usage scenarios for two applications and evaluate its learnability, usability, interpretability, and user performance in prediction and search tasks. We find that Imma Sort improves the interpretability and satisfaction of sorting by > 2 attributes. We discuss why, when, where, and how to deploy Imma Sort for real-world applications.",Yan Lyu;Fan Gao;I-Shuen Wu;Brian Y. Lim,Yan Lyu;Fan Gao;I-Shuen Wu;Brian Y. Lim,"School of Computing, National University of Singapore, Singapore;School of Electronic and Information Engineering, South China University of Technology, Guangzhou, China;School of Computing, National University of Singapore, Singapore;School of Computing, National University of Singapore, Singapore",0.1109/tvcg.2008.181;10.1109/tvcg.2012.253;10.1109/tvcg.2016.2598589;10.1109/tvcg.2013.173;10.1109/tvcg.2017.2745078,"Multi-attribute sorting,decision making,interpretability,human predictability,predictive interpretability",,2,54,643,,X
CG&A,2021,Remote Instruction for Data Visualization Design—A Report From the Trenches,10.1109/mcg.2021.3116042,http://dx.doi.org/10.1109/MCG.2021.3116042,15,24,MAG,"In this article, we report on our experiences of running visual design workshops within the context of a master’s level data visualization course, in a remote setting. These workshops aim to teach students to explore visual design space for data by creating and discussing hand-drawn sketches. We describe the technical setup employed, the different parts of the workshop, how the actual sessions were run, and to what extent the remote version can substitute for in-person sessions. In general, the visual designs created by the students as well as the feedback provided by them indicate that the setup described here can be a feasible replacement for in-person visual design workshops.",Jan Aerts;Jannes Peeters;Jelmer Bot;Danai Kafetzaki;Houda Lamqaddam,Jan Aerts;Jannes Peeters;Jelmer Bot;Danai Kafetzaki;Houda Lamqaddam,"Hasselt University, Hasselt, Belgium;Hasselt University, Hasselt, Belgium;Hasselt University, Hasselt, Belgium;Hasselt University, Hasselt, Belgium;KU Leuven, Leuven, Belgium",0.1109/tvcg.2015.2467271,,,3,16,620,,
CG&A,2022,Technology Trends and Challenges for Large-Scale Scientific Visualization,10.1109/mcg.2022.3176325,http://dx.doi.org/10.1109/MCG.2022.3176325,114,119,MAG,"Scientific visualization is a key approach to understanding the growing massive streams of data from scientific simulations and experiments. In this article, I review technology trends including the positive effects of Moore's law on science, the significant gap between processing and data storage speeds, the emergence of hardware accelerators for ray-tracing, and the availability of robust machine learning techniques. These trends represent changes to the status quo and present the scientific visualization community with a new set of challenges. A major challenge involves extending our approaches to visualize the modern scientific process, which includes scientific verification and validation. Another key challenge to the community is the growing number, size, and complexity of scientific datasets. A final challenge is to take advantage of emerging technology trends in custom hardware and machine learning to significantly improve the large-scale data visualization process.",James P. Ahrens,James Ahrens,"Los Alamos National Laboratory, NM, USA",0.1109/tvcg.2018.2853721;10.1109/tvcg.2011.229;10.1109/tvcg.2016.2599030;10.1109/tvcg.2020.3006426;10.1109/tvcg.2017.2743938;10.1109/tvcg.2016.2599041,,,3,16,595,,
CG&A,2022,VisVisual: A Toolkit for Teaching and Learning Data Visualization,10.1109/mcg.2022.3176199,http://dx.doi.org/10.1109/MCG.2022.3176199,20,26,MAG,"This article describes the motivation, design, and evaluation of the VisVisual toolkit to engage students in learning essential visualization concepts, algorithms, and techniques. The toolkit includes four independent components: 1) VolumeVisual, 2) FlowVisual, 3) GraphVisual, and 4) TreeVisual, covering scalar and vector data visualization in scientific visualization and graph and tree layouts in information visualization. Complementary to the toolkit design is resource development, aiming to help instructors integrate VisVisual into their curriculum.",Chaoli Wang 0001,Chaoli Wang,"University of Notre Dame, Notre Dame, IN, USA",0.1109/tvcg.2011.185;10.1109/infvis.2004.64;10.1109/tvcg.2007.70577,,,4,13,431,,
CG&A,2021,STSRNet: Deep Joint Space–Time Super-Resolution for Vector Field Visualization,10.1109/mcg.2021.3097555,http://dx.doi.org/10.1109/MCG.2021.3097555,122,132,MAG,"We propose STSRNet, a joint space–time super-resolution deep learning based model for time-varying vector field data. Our method is designed to reconstruct high temporal resolution and high spatial resolution vector fields sequence from the corresponding low-resolution key frames. For large scale simulations, only data from a subset of time steps with reduced spatial resolution can be stored for post hoc analysis. In this article, we leverage a deep learning model to capture the nonlinear complex changes of vector field data with a two-stage architecture: the first stage deforms a pair of low spatial resolution (LSR) key frames forward and backward to generate the intermediate LSR frames, and the second stage performs spatial super-resolution to output the high-resolution sequence. Our method is scalable and can handle different datasets. We demonstrate the effectiveness of our framework with several datasets through quantitative and qualitative evaluations.",Yifei An;Han-Wei Shen;Guihua Shan;Guan Li;Jun Liu 0059,Yifei An;Han-Wei Shen;Guihua Shan;Guan Li;Jun Liu,"University of Chinese Academy of Sciences, Beijing, China;The Ohio State University, Columbus, OH, USA;University of Chinese Academy of Sciences, Beijing, China;Chinese Academy of Sciences, Beijing, China;Chinese Academy of Sciences, Beijing, China",0.1109/tvcg.2019.2934255,,,11,19,441,,
CG&A,2023,Finding Their Data Voice: Practices and Challenges of Dashboard Users,10.1109/mcg.2021.3136545,http://dx.doi.org/10.1109/MCG.2021.3136545,22,36,MAG,"Dashboards are the ubiquitous means of data communication within organizations. Yet we have limited understanding of how they factor into data practices in the workplace, particularly for data workers who do not self-identify as professional analysts. We focus on data workers who use dashboards as a primary interface to data, reporting on an interview study that characterizes their data practices and the accompanying barriers to seamless data interaction. While dashboards are typically designed for data consumption, our findings show that dashboard users have far more diverse needs. To capture these activities, we frame data workers’ practices as data conversations: conversations with data capture classic analysis (asking and answering data questions), while conversations through and around data involve constructing representations and narratives for sharing and communication. Dashboard users faced substantial barriers in their data conversations: their engagement with data was often intermittent, dependent on experts, and involved an awkward assembly of tools. We challenge the visualization and analytics community to embrace dashboard users as a population and design tools that blend seamlessly into their work contexts.",Melanie Tory;Lyn Bartram;Brittany Fiore-Gartland;Anamaria Crisan,Melanie Tory;Lyn Bartram;Brittany Fiore-Gartland;Anamaria Crisan,"Northeastern University, Portland, ME, USA;Simon Fraser University, Surrey, BC, Canada;Tableau Software, Seattle, WA, USA;Tableau Research, Seattle, WA, USA",0.1109/tvcg.2019.2934593;10.1109/tvcg.2018.2864903;10.1109/mcg.2014.62;10.1109/tvcg.2012.219;10.1109/tvcg.2018.2865040;10.1109/tvcg.2021.3114830;10.1109/tvcg.2021.3074023;10.1109/tvcg.2014.2346292;10.1109/tvcg.2020.2978050,,,9,21,658,,
CG&A,2021,What Students Learn With Personal Data Physicalization,10.1109/mcg.2021.3115417,http://dx.doi.org/10.1109/MCG.2021.3115417,48,58,MAG,"I describe the results of implementing a personal data physicalization assignment in an information visualization course for senior undergraduate and graduate students in computer science and software engineering. By collecting data about themselves and representing this data in physical forms, students were able to 1) learn about data visualization, 2) design creatively, and 3) learn about themselves. While data physicalization in education has been explored with nontechnical and novice audiences, the experience I report in this article provides evidence that data physicalization also has benefits for technical, visualization-savvy students.",Charles Perin,Charles Perin,"University of Victoria, Victoria, BC, Canada",0.1109/tvcg.2014.2346292;10.1109/tvcg.2015.2467831;10.1109/tvcg.2007.70541;10.1109/tvcg.2014.2359887,,,13,18,593,,
CG&A,2021,DeepGD: A Deep Learning Framework for Graph Drawing Using GNN,10.1109/mcg.2021.3093908,http://dx.doi.org/10.1109/MCG.2021.3093908,32,44,MAG,"In the past decades, many graph drawing techniques have been proposed for generating aesthetically pleasing graph layouts. However, it remains a challenging task since different layout methods tend to highlight different characteristics of the graphs. Recently, studies on deep-learning-based graph drawing algorithms have emerged but they are often not generalizable to arbitrary graphs without retraining. In this article, we propose a Convolutional-Graph-Neural-Network-based deep learning framework, DeepGD, which can draw arbitrary graphs once trained. It attempts to generate layouts by compromising among multiple prespecified aesthetics considering a good graph layout usually complies with multiple aesthetics simultaneously. In order to balance the tradeoff, we propose two adaptive training strategies, which adjust the weight factor of each aesthetic dynamically during training. The quantitative and qualitative assessment of DeepGD demonstrates that it is capable of drawing arbitrary graphs effectively, while being flexible at accommodating different aesthetic criteria.",Xiaoqi Wang;Kevin Yen;Yifan Hu 0001;Han-Wei Shen,Xiaoqi Wang;Kevin Yen;Yifan Hu;Han-Wei Shen,"The Ohio State University, Columbus, OH, USA;Yahoo! Research, New York, NY, USA;Yahoo! Research, New York, NY, USA;The Ohio State University, Columbus, OH, USA",0.1109/tvcg.2019.2934396;10.1109/mcg.2018.2881501;10.1109/tvcg.2019.2934798,,,8,19,850,,
CG&A,2022,Situated Visual Analysis and Live Monitoring for Manufacturing,10.1109/mcg.2022.3157961,http://dx.doi.org/10.1109/MCG.2022.3157961,33,44,MAG,"Modern machines continuously log status reports over long periods of time, which are valuable data to optimize working routines. Data visualization is a commonly used tool to gain insights into these data, mostly in retrospective (e.g., to determine causal dependencies between the faults of different machines). We present an approach to bring such visual analyses to the shop floor to support reacting to faults in real time. This approach combines spatio-temporal analyses of time series using a handheld touch device with augmented reality for live monitoring. Important information augments machines directly in their real-world context, and detailed logs of current and historical events are displayed on the handheld device. In collaboration with an industry partner, we designed and tested our approach on a live production line to obtain feedback from operators. We compare our approach for monitoring and analysis with existing solutions that are currently deployed.",Michael Becher;Dominik Herr;Christoph Müller 0001;Kuno Kurzhals;Guido Reina;Lena Wagner;Thomas Ertl;Daniel Weiskopf,Michael Becher;Dominik Herr;Christoph Müller;Kuno Kurzhals;Guido Reina;Lena Wagner;Thomas Ertl;Daniel Weiskopf,"University of Stuttgart, Stuttgart, Germany;University of Stuttgart, Stuttgart, Germany;University of Stuttgart, Stuttgart, Germany;University of Stuttgart, Stuttgart, Germany;University of Stuttgart, Stuttgart, Germany;Robert Bosch GmbH, Bühl, Germany;University of Stuttgart, Stuttgart, Germany;University of Stuttgart, Stuttgart, Germany",0.1109/tvcg.2014.2346454;10.1109/tvcg.2016.2598664;10.1109/tvcg.2021.3114835;10.1109/tvcg.2009.111,,,9,20,574,,
CG&A,2022,"Visualization for Architecture, Engineering, and Construction: Shaping the Future of Our Built World",10.1109/mcg.2022.3149837,http://dx.doi.org/10.1109/MCG.2022.3149837,10,20,MAG,"Our built world is one of the most important factors for a livable future, accounting for massive impact on resource and energy use, as well as climate change, but also the social and economic aspects that come with population growth. The architecture, engineering, and construction industry is facing the challenge that it needs to substantially increase its productivity, let alone the quality of buildings of the future. In this article, we discuss these challenges in more detail, focusing on how digitization can facilitate this transformation of the industry, and link them to opportunities for visualization and augmented reality research. We illustrate solution strategies for advanced building systems based on wood and fiber.",Moataz Abdelaal;Felix Amtsberg;Michael Becher;Rebeca Duque Estrada;Fabian Kannenberg;Aimée Sousa Calepso;Hans Jakob Wagner;Guido Reina;Michael Sedlmair;Achim Menges;Daniel Weiskopf,Moataz Abdelaal;Felix Amtsberg;Michael Becher;Rebeca Duque Estrada;Fabian Kannenberg;Aimée Sousa Calepso;Hans Jakob Wagner;Guido Reina;Michael Sedlmair;Achim Menges;Daniel Weiskopf,"University of Stuttgart, Stuttgart, Germany;University of Stuttgart, Stuttgart, Germany;University of Stuttgart, Stuttgart, Germany;University of Stuttgart, Stuttgart, Germany;University of Stuttgart, Stuttgart, Germany;University of Stuttgart, Stuttgart, Germany;University of Stuttgart, Stuttgart, Germany;University of Stuttgart, Stuttgart, Germany;University of Stuttgart, Stuttgart, Germany;University of Stuttgart, Stuttgart, Germany;University of Stuttgart, Stuttgart, Germany",0.1109/tvcg.2011.279;10.1109/tvcg.2018.2865241;10.1109/tvcg.2012.213;10.1109/tvcg.2017.2745105,,,9,20,1011,,
CG&A,2021,Interactive Visualization of Hyperspectral Images Based on Neural Networks,10.1109/mcg.2021.3097730,http://dx.doi.org/10.1109/MCG.2021.3097730,57,66,MAG,"It is challenging to interpret hyperspectral images in an intuitive and meaningful way, as they usually contain hundreds of dimensions. We develop a visualization tool for hyperspectral images based on neural networks, which allows a user to specify the regions of interest, select bands of interest, and obtain hyperspectral classification results in a scatterplot generated from hyperspectral features. A cascade neural network is trained to generate a scatterplot that matches the cluster centers labeled by the user. The inferred scatterplot not only shows the clusters of points, but also reveals relationships of substances. The trained neural network can be reused for time-varying hyperspectral data analysis without retraining. Our visualization solution can keep domain experts in the analytical loop and provide an intuitive analysis of hyperspectral images while identifying different substances, which are difficult to be realized using existing hyperspectral image analysis techniques.",Feiyu Zhu;Yu Pan;Tian Gao;Harkamal Walia;Hongfeng Yu 0001,Feiyu Zhu;Yu Pan;Tian Gao;Harkamal Walia;Hongfeng Yu,"University of Nebraska-Lincoln, Lincoln, NE, USA;University of Nebraska-Lincoln, Lincoln, NE, USA;University of Nebraska-Lincoln, Lincoln, NE, USA;University of Nebraska-Lincoln, Lincoln, NE, USA;University of Nebraska-Lincoln, Lincoln, NE, USA",,,,7,12,500,,
CG&A,2021,Activity Worksheets for Teaching and Learning Data Visualization,10.1109/mcg.2021.3115396,http://dx.doi.org/10.1109/MCG.2021.3115396,25,36,MAG,"In this work, the data visualization activity (DVA) worksheet method for teaching and learning data visualization is presented. The DVA worksheet method consists of a series of activity worksheets developed to guide novice instructors and students through the data visualization process. The activity worksheets help new faculty and visualization instructors, lacking formal training in pedagogy and data visualization, learn the data visualization process, design course work, and develop curriculum. The worksheets can be used for individual activities, or as a collection of activities to support data visualization capacity building. Each worksheet focuses on an individual step in the process, allowing the worksheets to be tailored to discipline-specific data visualization needs. We share the motivation and evolution of the worksheets from paper-based to the semi-automated process utilized in fall 2020. We conclude this work with a discussion and areas for improvement.",Vetria L. Byrd;Nicole Dwenger,Vetria L. Byrd;Nicole Dwenger,"Purdue University, West Lafayette, IN, USA;Purdue University, West Lafayette, IN, USA",0.1109/tvcg.2014.2346331;10.1109/tvcg.2012.213;10.1109/tvcg.2015.2467271;10.1109/tvcg.2009.111,,,8,19,564,,
CG&A,2022,SUBPLEX: A Visual Analytics Approach to Understand Local Model Explanations at the Subpopulation Level,10.1109/mcg.2022.3199727,http://dx.doi.org/10.1109/MCG.2022.3199727,24,36,MAG,"Understanding the interpretation of machine learning (ML) models has been of paramount importance when making decisions with societal impacts, such as transport control, financial activities, and medical diagnosis. While local explanation techniques are popular methods to interpret ML models on a single instance, they do not scale to the understanding of a model’s behavior on the whole dataset. In this article, we outline the challenges and needs of visually analyzing local explanations and propose SUBPLEX, a visual analytics approach to help users understand local explanations with subpopulation visual analysis. SUBPLEX provides steerable clustering and projection visualization techniques that allow users to derive interpretable subpopulations of local explanations with users’ expertise. We evaluate our approach through two use cases and experts’ feedback.",Jun Yuan;Gromit Yeuk-Yin Chan;Brian Barr;Kyle Overton;Kim Rees;Luis Gustavo Nonato;Enrico Bertini;Cláudio T. Silva,Jun Yuan;Gromit Yeuk-Yin Chan;Brian Barr;Kyle Overton;Kim Rees;Luis Gustavo Nonato;Enrico Bertini;Claudio T. Silva,"New York University, Brooklyn, NY, USA;New York University, Brooklyn, NY, USA;Capital One, McLean, VA, USA;Capital One, McLean, VA, USA;Capital One, McLean, VA, USA;Universidade de São Paulo, São Paulo, Brazil;Northeastern University, Boston, MA, USA;New York University, Brooklyn, NY, USA",0.1109/tvcg.2018.2846735;10.1109/tvcg.2017.2744319;10.1109/tvcg.2018.2865076;10.1109/tvcg.2017.2745258;10.1109/tvcg.2020.3030342,,,6,20,444,,
TVCG,2023,Anchorage: Visual Analysis of Satisfaction in Customer Service Videos Via Anchor Events,10.1109/tvcg.2023.3245609,http://dx.doi.org/10.1109/TVCG.2023.3245609,1,13,J,"Delivering customer services through video communications has brought new opportunities to analyze customer satisfaction for quality management. However, due to the lack of reliable self-reported responses, service providers are troubled by the inadequate estimation of customer services and the tedious investigation into multimodal video recordings. We introduce Anchorage, a visual analytics system to evaluate customer satisfaction by summarizing multimodal behavioral features in customer service videos and revealing abnormal operations in the service process. We leverage the semantically meaningful operations to introduce structured event understanding into videos which help service providers quickly navigate to events of their interest. Anchorage supports a comprehensive evaluation of customer satisfaction from the service and operation levels and efficient analysis of customer behavioral dynamics via multifaceted visualization views. We extensively evaluate Anchorage through a case study and a carefully-designed user study. The results demonstrate its effectiveness and usability in assessing customer satisfaction using customer service videos. We found that introducing event contexts in assessing customer satisfaction can enhance its performance without compromising annotation precision. Our approach can be adapted in situations where unlabelled and unstructured videos are collected along with sequential records.",Kam Kwai Wong;Xingbo Wang;Yong Wang;Jianben He;Rong Zhang;Huamin Qu,Kam Kwai Wong;Xingbo Wang;Yong Wang;Jianben He;Rong Zhang;Huamin Qu,"Hong Kong University of Science and Technology, Hong Kong;Hong Kong University of Science and Technology, Hong Kong;Singapore Management University, Singapore;Hong Kong University of Science and Technology, Hong Kong;Hong Kong University of Science and Technology, Hong Kong;Hong Kong University of Science and Technology, Hong Kong",,"Customer satisfaction,video data,,video visualization,visual analytics",,6,0,168,,
TVCG,2023,XNLI: Explaining and Diagnosing NLI-based Visual Data Analysis,10.1109/tvcg.2023.3240003,http://dx.doi.org/10.1109/TVCG.2023.3240003,1,14,J,"Natural language interfaces (NLIs) enable users to flexibly specify analytical intentions in data visualization. However, diagnosing the visualization results without understanding the underlying generation process is challenging. Our research explores how to provide explanations for NLIs to help users locate the problems and further revise the queries. We present XNLI, an explainable NLI system for visual data analysis. The system introduces a Provenance Generator to reveal the detailed process of visual transformations, a suite of interactive widgets to support error adjustments, and a Hint Generator to provide query revision hints based on the analysis of user queries and interactions. Two usage scenarios of XNLI and a user study verify the effectiveness and usability of the system. Results suggest that XNLI can significantly enhance task accuracy without interrupting the NLI-based analysis process.",Yingchaojie Feng;Xingbo Wang;Bo Pan;Kam Kwai Wong;Yi Ren;Shi Liu;Zihan Yan;Yuxin Ma;Huamin Qu;Wei Chen,Yingchaojie Feng;Xingbo Wang;Bo Pan;Kam Kwai Wong;Yi Ren;Shi Liu;Zihan Yan;Yuxin Ma;Huamin Qu;Wei Chen,"The State Key Lab of CAD & CG, Zhejiang University, Hangzhou, Zhejiang, China;Hong Kong University of Science and Technology, Hong Kong, China;The State Key Lab of CAD & CG, Zhejiang University, Hangzhou, Zhejiang, China;Hong Kong University of Science and Technology, Hong Kong, China;The State Key Lab of CAD & CG, Zhejiang University, Hangzhou, Zhejiang, China;The State Key Lab of CAD & CG, Zhejiang University, Hangzhou, Zhejiang, China;MIT Media Lab, Cambridge, MA, USA;Department of Computer Science and Engineering, Southern University of Science and Technology, Guangdong, China;Hong Kong University of Science and Technology, Hong Kong, China;Laboratory of Art and Archaeology Image (Zhejiang University), Ministry of Education, China",,"Natural language interface,visual data analysis,,explainability",,6,0,369,,
CG&A,2021,Cartolabe: A Web-Based Scalable Visualization of Large Document Collections,10.1109/mcg.2020.3033401,http://dx.doi.org/10.1109/MCG.2020.3033401,76,88,MAG,"We describe Cartolabe, a web-based multiscale system for visualizing and exploring large textual corpora based on topics, introducing a novel mechanism for the progressive visualization of filtering queries. Initially designed to represent and navigate through scientific publications in different disciplines, Cartolabe has evolved to become a generic framework and accommodate various corpora, ranging from Wikipedia (4.5M entries) to the French National Debate (4.3M entries). Cartolabe is made of two modules: The first relies on natural language processing methods, converting a corpus and its entities (documents, authors, and concepts) into high-dimensional vectors, computing their projection on the two-dimensional plane, and extracting meaningful labels for regions of the plane. The second module is a web-based visualization, displaying tiles computed from the multidimensional projection of the corpus using the Umap projection method. This visualization module aims at enabling users with no expertise in visualization and data analysis to get an overview of their corpus, and to interact with it: exploring, querying, filtering, panning, and zooming on regions of semantic interest. Three use cases are discussed to illustrate Cartolabe’s versatility and ability to bring large-scale textual corpus visualization and exploration to a wide audience.",Philippe Caillou;Jonas Renault;Jean-Daniel Fekete;Anne-Catherine Letournel;Michèle Sebag,Philippe Caillou;Jonas Renault;Jean-Daniel Fekete;Anne-Catherine Letournel;Michèle Sebag,"Université Paris-Saclay, CNRS Inria, LRI, Gif-sur-Yvette, France;Université Paris-Saclay, CNRS Inria, LRI, Gif-sur-Yvette, France;Université Paris-Saclay, CNRS Inria, LRI, Gif-sur-Yvette, France;Université Paris-Saclay, CNRS Inria, LRI, Gif-sur-Yvette, France;Université Paris-Saclay, CNRS Inria, LRI, Gif-sur-Yvette, France",0.1109/tvcg.2013.212;10.1109/tvcg.2013.179;10.1109/tvcg.2018.2846735,,,7,14,331,,
CG&A,2021,Visualization Design Sprints for Online and On-Campus Courses,10.1109/mcg.2021.3115413,http://dx.doi.org/10.1109/MCG.2021.3115413,37,47,MAG,"We present how to integrate Design Sprints and project-based learning into introductory visualization courses. A design sprint is a unique process based on rapid prototyping and user testing to define goals and validate ideas before starting costly development. The well-defined, interactive, and time-constrained design cycle makes design sprints a promising option for teaching project-based and active-learning-centered courses to increase student engagement and hands-on experience. Over the past five years, we have adjusted the design sprint methodology for teaching a range of visualization courses. We present a detailed guide on incorporating design sprints into large undergraduate and small professional development courses in both online and on-campus settings. Design sprint results, including quantitative and qualitative student feedback, show that design sprints engage students and help practice and apply visualization and design skills. We provide design sprint teaching materials, show examples of student-created work, and discuss limitations and lessons learned.",Johanna Beyer;Yalong Yang 0001;Hanspeter Pfister,Johanna Beyer;Yalong Yang;Hanspeter Pfister,"John A. Paulson School of Engineering and Applied Sciences, Harvard University, Cambridge, MA, USA;College of Engineering, Virginia Tech, Blacksburg, VA, USA;John A. Paulson School of Engineering and Applied Sciences, Harvard University, Cambridge, MA, USA",,,,4,15,456,,
CG&A,2021,A Didactic Framework for Analyzing Learning Activities to Design InfoVis Courses,10.1109/mcg.2021.3115416,http://dx.doi.org/10.1109/MCG.2021.3115416,80,90,MAG,"Data visualization is a powerful tool to cope with the demands of our current information age. In order to understand and be able to develop visualizations for specific use cases, data visualization activities (vis activities) have been proposed in recent years. These highly effective tools focus on practical relevance, reflection, and discussion in order to teach data visualization knowledge in a variety of contexts. However, the conscious selection of one or more vis activities for learners in comprehensive courses remains difficult. We aim to support this process by proposing a didactic vis framework. Based on Bloom's revised learning taxonomy, we decompose vis activities into distinct learning activities with their specific learning goals. By assigning the learning goals to the cognitive process and knowledge dimensions, a didactic course structure can be planned and evaluated. To demonstrate this didactic vis framework, we conducted several workshops based on an existing interface construction kit.",Mandy Keck;Elena Stoll;Dietrich Kammer,Mandy Keck;Elena Stoll;Dietrich Kammer,"University of Applied Sciences Upper Austria, Campus Hagenberg, Hagenberg, Austria;University of Applied Sciences Dresden, Dresden, Germany;University of Applied Sciences Dresden, Dresden, Germany",,,,4,20,321,,
CG&A,2021,Through the Looking Glass: Insights Into Visualization Pedagogy Through Sentiment Analysis of Peer Review Text,10.1109/mcg.2021.3115387,http://dx.doi.org/10.1109/MCG.2021.3115387,59,70,MAG,"Peer review is a widely utilized feedback mechanism for engaging students. As a pedagogical method, it has been shown to improve educational outcomes, but we have found limited empirical measurement of peer review in visualization courses. In addition to increasing engagement, peer review provides diverse feedback and reinforces recently learned course concepts through critical evaluation of others’ work. We discuss the construction and application of peer review in two visualization courses from different colleges at the University of South Florida. We then analyze student projects and peer review text via sentiment analysis to infer insights for visualization educators, including the focus of course content, engagement across student groups, student mastery of concepts, course trends over time, and expert intervention effectiveness. Finally, we provide suggestions for adapting peer review to other visualization courses to engage students and increase instructor understanding of the peer review process.",Zachariah J. Beasley;Alon Friedman;Paul Rosen 0001,Zachariah J. Beasley;Alon Friedman;Paul Rosen,"University of South Florida, Tampa, FL, USA;University of South Florida, Tampa, FL, USA;University of South Florida, Tampa, FL, USA",,,,4,23,244,,
CG&A,2021,Surgical Navigation System for Low-Dose-Rate Brachytherapy Based on Mixed Reality,10.1109/mcg.2019.2963657,http://dx.doi.org/10.1109/MCG.2019.2963657,113,123,MAG,"This article presents a personalized mixed reality (MR) surgical assistance system for brachytherapy. Using a novel, modified multi-information fusion method, the fusion of virtual organs and a preoperative plan for an actual patient and the real-time tracking of surgical tools were achieved. Using the quaternion-based iterative closest point (QICP) algorithm and a hand-eye calibration method, the preoperative plan can be fused into individual patients. Using the electromagnetic (EM) tracker, users can track the surgery tools in real time, without multiple CT scans, and doctors can immediately perform the surgery. We performed a series of experiments, including phantom and animal experiments, to test the accuracy and efficiency of the system. In the phantom experiment, the average needle location error was 0.957 mm. Based on the results of animal experiments, the needle insertion error was 2.416 mm. All experimental results indicated that the procedure could be applied in further clinical studies.",Zeyang Zhou;Zhiyong Yang 0002;Shan Jiang 0009;Xiaodong Ma;Fujun Zhang;Huzheng Yan,Zeyang Zhou;Zhiyong Yang;Shan Jiang;Xiaodong Ma;Fujun Zhang;Huzheng Yan,"Tianjin University, Tianjin, China;Tianjin University, Tianjin, China;Tianjin University, Tianjin, China;Tianjin University, Tianjin, China;Sun Yat-sen University Cancer Center, Guangzhou, Guangdong Province, China;Sun Yat-sen University Cancer Center, Guangzhou, Guangdong Province, China",,"Virtual and augmented reality,Applications,,Medical information systems,Medical simulation",,6,13,535,,
CG&A,2022,"Giga Graph Cities: Their Buckets, Buildings, Waves, and Fragments",10.1109/mcg.2022.3172650,http://dx.doi.org/10.1109/MCG.2022.3172650,53,64,MAG,"Graph Cities are the 3-D visual representations of partitions of a graph edge set into maximal connected subgraphs, each of which is called a fixed point of degree peeling. Each such connected subgraph is visually represented as a Building. A polylog bucketization of the size distribution of the subgraphs represented by the buildings generates a 2-D position for each bucket. The Delaunay triangulation of the bucket building locations determines the street network. We illustrate Graph Cities for the Friendster social network (1.8 billion edges), a co-occurrence keywords network derived from the Internet Movie Database (115 million edges), and a patent citation network (16.5 million edges). Up to 2 billion edges, all the elements of their corresponding Graph Cities are built in a few minutes (excluding I/O time). Our ultimate goal is to provide tools to build humanly interpretable descriptions of any graph, without being constrained by the graph size.",James Abello;Haoyang Zhang;Daniel Nakhimovich;Chengguizi Han;Mridul Aanjaneya,James Abello;Haoyang Zhang;Daniel Nakhimovich;Chengguizi Han;Mridul Aanjaneya,"Department of Computer Science, Rutgers University, Piscataway, NJ, USA;Department of Computer Science, Rutgers University, Piscataway, NJ, USA;Department of Computer Science, Rutgers University, Piscataway, NJ, USA;Department of Computer Science, Rutgers University, Piscataway, NJ, USA;Department of Computer Science, Rutgers University, Piscataway, NJ, USA",0.1109/tvcg.2006.120;10.1109/tvcg.2018.2790961,,,3,19,282,,
CG&A,2021,Visual Clustering Factors in Scatterplots,10.1109/mcg.2021.3098804,http://dx.doi.org/10.1109/MCG.2021.3098804,79,89,MAG,"Cluster analysis is an important technique in data analysis. However, there is no encompassing theory on scatterplots to evaluate clustering. Human visual perception is regarded as a gold standard to evaluate clustering. The cluster analysis based on human visual perception requires the participation of many probands, to obtain diverse data, and hence is a challenge to do. We contribute an empirical and data-driven study on human perception for visual clustering of large scatterplot data. First, we systematically construct and label a large, publicly available scatterplot dataset. Second, we carry out a qualitative analysis based on the dataset and summarize the influence of visual factors on clustering perception. Third, we use the labeled datasets to train a deep neural network for modeling human visual clustering perception. Our experiments show that the data-driven model successfully models the human visual perception, and outperforms conventional clustering algorithms in synthetic and real datasets.",Jiazhi Xia;Weixing Lin;Guang Jiang;Yunhai Wang;Wei Chen 0001;Tobias Schreck,Jiazhi Xia;Weixing Lin;Guang Jiang;Yunhai Wang;Wei Chen;Tobias Schreck,"Central South University, Hunan, China;Central South University, Hunan, China;Central South University, Hunan, China;Shandong University, Jinan, China;Zhejiang University, Hangzhou, China;Graz University of Technology, Graz, Styria, Austria",0.1109/tvcg.2017.2701829;10.1109/tvcg.2017.2745258;10.1109/vast.2016.7883517;10.1109/tvcg.2018.2875702,,,8,20,789,,
CG&A,2022,Reflections on Visualization Research Projects in the Manufacturing Industry,10.1109/mcg.2022.3156846,http://dx.doi.org/10.1109/MCG.2022.3156846,21,32,MAG,"The rise of Industry 4.0 and cyber-physical systems has led to an abundance of large amounts of data, particularly in the manufacturing industry. Visualization and visual analytics play essential roles in harnessing this data. They have already been acknowledged as being among the key enabling technologies in the fourth industrial revolution. However, there are many challenges attached to applying visualization successfully, both from the manufacturing industry and visualization research perspectives. As members of research institutions involved in several applied research projects dealing with visualization in manufacturing, we characterized and analyzed our experiences for a detailed qualitative view, to distill important lessons learned, and to identify research gaps. With this article, we aim to provide added value and guidance for both manufacturing engineers and visualization researchers to avoid pitfalls and make such interdisciplinary endeavors more successful.",Lena Cibulski;Johanna Schmidt;Wolfgang Aigner,Lena Cibulski;Johanna Schmidt;Wolfgang Aigner,"Fraunhofer Institute for Computer Graphics Research IGD, Darmstadt, Germany;VRVis Zentrum für Virtual Reality und Visualisierung Forschungs-GmbH, Vienna, Austria;St. Pölten University of Applied Sciences, St. Poelten, Austria",0.1109/tvcg.2019.2934275;10.1109/tvcg.2014.2346454;10.1109/tvcg.2016.2598664;10.1109/tvcg.2017.2743990;10.1109/tvcg.2019.2934539;10.1109/tvcg.2016.2598589;10.1109/tvcg.2016.2598592;10.1109/tvcg.2012.213;10.1109/tvcg.2019.2934538,,,2,20,598,,
CG&A,2022,Embracing Disciplinary Diversity in Visualization,10.1109/mcg.2022.3209605,http://dx.doi.org/10.1109/MCG.2022.3209605,64,71,MAG,"Visualization is inherently diverse and is employed in countless domains to enable meaningful interactions with data. There is tremendous opportunity in embracing disciplinary diversity to widen the pool of contributions to visualization design, research, and practice. We describe a few examples of diverse approaches: scientific method, design studies, tool building, participatory research, and co-design with communities, data storytelling, and autographic design. We discuss opening the aperture, pushing back on what we, as a community, deem acceptable and rigorous, and what can be gained through greater inclusivity of approaches.",Tatiana Losev;Justin Raynor;Sheelagh Carpendale;Melanie Tory,Tatiana Losev;Justin Raynor;Sheelagh Carpendale;Melanie Tory,"Simon Fraser University, Burnaby, BC, Canada;Northeastern University, Boston, MA, USA;Simon Fraser University, Burnaby, BC, Canada;Northeastern University, Portland, ME, USA",0.1109/tvcg.2019.2934788;10.1109/tvcg.2012.213;10.1109/tvcg.2018.2865076;10.1109/tvcg.2021.3114756;10.1109/tvcg.2019.2934790,,,2,17,292,,
CG&A,2022,Visual Parameter Space Analysis for Optimizing the Quality of Industrial Nonwovens,10.1109/mcg.2022.3155867,http://dx.doi.org/10.1109/MCG.2022.3155867,56,67,MAG,"Technical textiles, in particular, nonwovens used, for example, in medical masks, have become increasingly important in our daily lives. The quality of these textiles depends on the manufacturing process parameters that cannot be easily optimized in live settings. In this article, we present a visual analytics framework that enables interactive parameter space exploration and parameter optimization in industrial production processes of nonwovens. Therefore, we survey analysis strategies used in optimizing industrial production processes of nonwovens and support them in our tool. To enable real-time interaction, we augment the digital twin with a machine learning surrogate model for rapid quality computations. In addition, we integrate mechanisms for sensitivity analysis that ensure consistent product quality under mild parameter changes. In our case study, we explore the finding of optimal parameter sets, investigate the input–output relationship between parameters, and conduct a sensitivity analysis to find settings that result in robust quality.",Viny Saajan Victor;Andre Schmeißer;Heike Leitte;Simone Gramsch,Viny Saajan Victor;Andre Schmeißer;Heike Leitte;Simone Gramsch,"Fraunhofer ITWM, Fraunhofer-Platz 1, Kaiserslautern, Germany;Fraunhofer ITWM, Fraunhofer-Platz 1, Kaiserslautern, Germany;TU Kaiserslautern, Postfach 3049, Kaiserslautern, Germany;Fraunhofer ITWM, Fraunhofer-Platz 1, Kaiserslautern, Germany",0.1109/tvcg.2014.2346321;10.1109/tvcg.2016.2598589;10.1109/tvcg.2011.248;10.1109/tvcg.2016.2598830,,,1,20,340,,
CG&A,2023,A Multiscale Geospatial Dataset and an Interactive Visualization Dashboard for Computational Epidemiology and Open Scientific Research,10.1109/mcg.2022.3230444,http://dx.doi.org/10.1109/MCG.2022.3230444,39,52,MAG,"The coronavirus disease (COVID-19) continued to strike as a highly infectious and fast-spreading disease in 2020 and 2021. As the research community actively responded to this pandemic, we saw the release of many COVID-19-related datasets and visualization dashboards. However, existing resources are insufficient to support multiscale and multifaceted modeling or simulation, which is suggested to be important by the computational epidemiology literature. This work presents a curated multiscale geospatial dataset with an interactive visualization dashboard under the context of COVID-19. This open dataset will allow researchers to conduct numerous projects or analyses relating to COVID-19 or simply geospatial-related scientific studies. The interactive visualization platform enables users to visualize the spread of the disease at different scales (e.g., country level to individual neighborhoods), and allows users to interact with the policies enforced at these scales (e.g., the closure of borders and lockdowns) to observe their impacts on the epidemiology.",Muhammad Usman 0010;Honglu Zhou;Seonghyeon Moon;Xun Zhang;Petros Faloutsos;Mubbasir Kapadia,Muhammad Usman;Honglu Zhou;Seonghyeon Moon;Xun Zhang;Petros Faloutsos;Mubbasir Kapadia,"Department of Information and Computer Science, King Fahd University of Petroleum and Minerals, Dhahran, Saudi Arabia;Department of Computer Science, Rutgers University, Piscataway, NJ, USA;Department of Computer Science, Rutgers University, Piscataway, NJ, USA;Department of Computer Science, Rutgers University, Piscataway, NJ, USA;Department of Electrical Engineering and Computer Science, York University, Toronto, ON, Canada;Department of Computer Science, Rutgers University, Piscataway, NJ, USA",0.1109/tvcg.2022.3165385,,,0,21,433,,
CG&A,2022,Stress Visualization for Interface Optimization of a Hybrid Component Using Surface Tensor Spines,10.1109/mcg.2022.3149875,http://dx.doi.org/10.1109/MCG.2022.3149875,45,55,MAG,"In lightweight construction, engineers focus on designing and optimizing lightweight components without compromising their strength and durability. In this process, materials such as polymers are commonly considered for a hybrid construction, or even used as a complete replacement. In this work, we focus on a hybrid component design combining metal and carbon fiber reinforced polymer parts. Here, engineers seek to optimize the interface connection between a polymer and a metal part through the placement of load transmission elements in a mechanical millimetric mesoscale level. To assist engineers in the placement and design process, we extend tensor spines, a 3-D tensor-based visualization technique, to surfaces. This is accomplished by combining texture-based techniques with tensor data. Moreover, we apply a parametrization based on a remeshing process to provide visual guidance during the placement. Finally, we demonstrate and discuss real test cases to validate the benefit of our approach.",Vanessa Kretzschmar;Allan Rocha;Fabian Günther;Markus Stommel;Gerik Scheuermann,Vanessa Kretzschmar;Allan Rocha;Fabian Günther;Markus Stommel;Gerik Scheuermann,"Leipzig University, Leipzig, Germany;Seequent Solutions, Calgary, AB, Canada;TU Dortmund University, Dortmund, Germany;Leibniz Institute of Polymer Research Dresden, Dresden, Germany;Leipzig University, Leipzig, Germany",0.1109/tvcg.2016.2598866;10.1109/tvcg.2018.2850781,,,1,19,261,,
TVCG,2023,"IF-City: Intelligible Fair City Planning to Measure, Explain and Mitigate Inequality",10.1109/tvcg.2023.3239909,http://dx.doi.org/10.1109/TVCG.2023.3239909,1,18,J,"With the increasing pervasiveness of Artificial Intelligence (AI), many visual analytics tools have been proposed to examine fairness, but they mostly focus on data scientist users. Instead, tackling fairness must be inclusive and involve domain experts with specialized tools and workflows. Thus, domain-specific visualizations are needed for algorithmic fairness. Furthermore, while much work on AI fairness has focused on predictive decisions, less has been done for fair allocation and planning, which require human expertise and iterative design to integrate myriad constraints. We propose the Intelligible Fair Allocation (IF-Alloc) Framework that leverages explanations of causal attribution (Why), contrastive (Why Not) and counterfactual reasoning (What If, How To) to aid domain experts to assess and alleviate unfairness in allocation problems. We apply the framework to fair urban planning for designing cities that provide equal access to amenities and benefits for diverse resident types. Specifically, we propose an interactive visual tool, Intelligible Fair City Planner (IF-City), to help urban planners to perceive inequality across groups, identify and attribute sources of inequality, and mitigate inequality with automatic allocation simulations and constraint-satisfying recommendations (IF-Plan). We demonstrate and evaluate the usage and usefulness of IF-City on a real neighborhood in New York City, US, with practicing urban planners from multiple countries, and discuss generalizing our findings, application, and framework to other use cases and applications of fair allocation.",Yan Lyu;Hangxin Lu;Min Kyung Lee;Gerhard Schmitt;Brian Y. Lim,Yan Lyu;Hangxin Lu;Min Kyung Lee;Gerhard Schmitt;Brian Y. Lim,"School of Computer Science and Engineering, Southeast University, Nanjing, China;Future Cities Laboratory, Singapore-ETH Centre, Singapore, Singapore;School of Information, The University of Texas at Austin, US;Future Cities Laboratory, Singapore-ETH Centre, Singapore, Singapore;School of Computing, National University of Singapore, Singapore, Singapore",,"Explainable artificial intelligence,fairness,,intelligibility,resource allocation,urban planning",,1,0,292,,
CG&A,2023,Lessons Learned From Quantitatively Exploring Visualization Rubric Utilization for Peer Feedback,10.1109/mcg.2022.3149683,http://dx.doi.org/10.1109/MCG.2022.3149683,10,21,MAG,"We present our experience of adapting a rubric for peer feedback in our data visualization course and exploring the utilization of that rubric by students across two semesters. We first discuss the results of an automatable quantitative analysis of the rubric responses, and then compare those results to a qualitative analysis of summative survey responses from students regarding the rubric and peer-feedback process. We conclude with lessons learned about the visualization rubric we used, as well as what we learned more broadly about using quantitative analysis to explore this type of data. These lessons may be useful for other educators wanting to utilize the same data visualization rubric, or wanting to explore the utilization of rubrics already deployed for peer feedback.",Daniel J. Barajas;Xornam S. Apedoe;David Guy Brizan;Alark P. Joshi;Sophie J. Engle,Daniel J. Barajas;Xornam S. Apedoe;David G. Brizan;Alark P. Joshi;Sophie J. Engle,"University of San Francisco, San Francisco, CA, USA;University of San Francisco, San Francisco, CA, USA;University of San Francisco, San Francisco, CA, USA;University of San Francisco, San Francisco, CA, USA;University of San Francisco, San Francisco, CA, USA",0.1109/tvcg.2015.2467091,,,0,20,234,,
CG&A,2022,Narrative In Situ Visual Analysis for Large-Scale Ocean Eddy Evolution,10.1109/mcg.2022.3167044,http://dx.doi.org/10.1109/MCG.2022.3167044,65,73,MAG,"The rapid development of high-performance computing systems has led to a rapid increase in the speed of flow field simulation calculations. However, large-scale simulation output data lead to storage bottlenecks and inefficient data analysis. In this work, we used in situ visualization to process the simulation analysis of large-scale flow fields. Combined with narrative visual analysis, we designed a large-scale ocean flow field eddy evolution analysis system based on in situ visualization. Our system can generate high-precision eddy streamline structures in real time and supports eddy statistical analysis and tracking analysis at different ocean regional scales. Through the case data analysis of ocean simulation, we demonstrated the efficiency and effectiveness of the system.",Xiaoyang Han;Xiaomin Yu;Guan Li;Jun Liu 0059;Ying Zhao 0001;Guihua Shan,Xiaoyang Han;Xiaomin Yu;Guan Li;Jun Liu;Ying Zhao;Guihua Shan,"Computer Network Information Center, Chinese Academy of Sciences, University of Chinese Academy of Sciences, Beijing, China;Computer Network Information Center, Chinese Academy of Sciences, University of Chinese Academy of Sciences, Beijing, China;Computer Network Information Center, Chinese Academy of Sciences, Beijing, China;Computer Network Information Center, Chinese Academy of Sciences, Beijing, China;Central South University, Changsha, China;Computer Network Information Center, Chinese Academy of Sciences, University of Chinese Academy of Sciences, Beijing, China",0.1109/tvcg.2010.259;10.1109/tvcg.2013.119;10.1109/vast.2008.4677364;10.1109/tvcg.2015.2467411,,,0,20,295,,
TVCG,2023,Towards Better Modeling With Missing Data: A Contrastive Learning-Based Visual Analytics Perspective,10.1109/tvcg.2023.3285210,http://dx.doi.org/10.1109/TVCG.2023.3285210,1,18,J,"Missing data can pose a challenge for machine learning (ML) modeling. To address this, current approaches are categorized into feature imputation and label prediction and are primarily focused on handling missing data to enhance ML performance. These approaches rely on the observed data to estimate the missing values and therefore encounter three main shortcomings in imputation, including the need for different imputation methods for various missing data mechanisms, heavy dependence on the assumption of data distribution, and potential introduction of bias. This study proposes a Contrastive Learning (CL) framework to model observed data with missing values, where the ML model learns the similarity between an incomplete sample and its complete counterpart and the dissimilarity between other samples. Our proposed approach demonstrates the advantages of CL without requiring any imputation. To enhance interpretability, we introduce CIVis, a visual analytics system that incorporates interpretable techniques to visualize the learning process and diagnose the model status. Users can leverage their domain knowledge through interactive sampling to identify negative and positive pairs in CL. The output of CIVis is an optimized model that takes specified features and predicts downstream tasks. We provide two usage scenarios in regression and classification tasks and conduct quantitative experiments, expert interviews, and a qualitative user study to demonstrate the effectiveness of our approach. In short, this study offers a valuable contribution to addressing the challenges associated with ML modeling in the presence of missing data by providing a practical solution that achieves high predictive accuracy and model interpretability.",Laixin Xie;Yang Ouyang;Longfei Chen;Ziming Wu;Quan Li,Laixin Xie;Yang Ouyang;Longfei Chen;Ziming Wu;Quan Li,"School of Information Science and Technology, ShanghaiTech University, and Shanghai Engineering Research Center of Intelligent Vision and Imaging, China;School of Information Science and Technology, ShanghaiTech University, and Shanghai Engineering Research Center of Intelligent Vision and Imaging, China;School of Information Science and Technology, ShanghaiTech University, and Shanghai Engineering Research Center of Intelligent Vision and Imaging, China;Tencent Inc., Shenzhen, Guangdong, China;School of Information Science and Technology, ShanghaiTech University, and Shanghai Engineering Research Center of Intelligent Vision and Imaging, China",,"Contrastive learning,data imputation,,explainable AI,missing data",,0,0,297,,
TVCG,2023,Force-Directed Graph Layouts Revisited: A New Force Based on the T-Distribution,10.1109/tvcg.2023.3238821,http://dx.doi.org/10.1109/TVCG.2023.3238821,1,14,J,"In this paper, we propose the t-FDP model, a force-directed placement method based on a novel bounded short-range force (t-force) defined by Student’s t-distribution. Our formulation is flexible, exerts limited repulsive forces for nearby nodes and can be adapted separately in its short- and long-range effects. Using such forces in force-directed graph layouts yields better neighborhood preservation than current methods, while maintaining low stress errors. Our efficient implementation using a Fast Fourier Transform is one order of magnitude faster than state-of-the-art methods and two orders faster on the GPU, enabling us to perform parameter tuning by globally and locally adjusting the t-force in real-time for complex graphs. We demonstrate the quality of our approach by numerical evaluation against state-of-the-art approaches and extensions for interactive exploration.",Fahai Zhong;Mingliang Xue;Jian Zhang;Fan Zhang;Rui Ban;Oliver Deussen;Yunhai Wang,Fahai Zhong;Mingliang Xue;Jian Zhang;Fan Zhang;Rui Ban;Oliver Deussen;Yunhai Wang,"Department of Computer Science, Shandong University, China;Department of Computer Science, Shandong University, China;Computer Network Information Center, Chinese Academy of Sciences, Beijing, China;School of Computer Science and Technology, SDTBU, China;Intelligent Network Design Institute, CITC, Beijing, China;Computer and Information Science, University of Konstanz, Konstanz, Germany;Department of Computer Science, Shandong University, China",,"FFT,force directed placement,,graph layout,student’s t-distribution",,0,0,237,,
TVCG,2023,DL4SciVis: A State-of-the-Art Survey on Deep Learning for Scientific Visualization,10.1109/tvcg.2022.3167896,http://dx.doi.org/10.1109/TVCG.2022.3167896,3714,3733,J,"Since 2016, we have witnessed the tremendous growth of artificial intelligence+visualization (AI+VIS) research. However, existing survey articles on AI+VIS focus on visual analytics and information visualization, not scientific visualization (SciVis). In this article, we survey related deep learning (DL) works in SciVis, specifically in the direction of DL4SciVis: designing DL solutions for solving SciVis problems. To stay focused, we primarily consider works that handle scalar and vector field data but exclude mesh data. We classify and discuss these works along six dimensions: domain setting, research task, learning type, network architecture, loss function, and evaluation metric. The article concludes with a discussion of the remaining gaps to fill along the discussed dimensions and the grand challenges we need to tackle as a community. This state-of-the-art survey guides SciVis researchers in gaining an overview of this emerging topic and points out future directions to grow this research.",Chaoli Wang 0001;Jun Han 0010,Chaoli Wang;Jun Han,"Department of Computer Science and Engineering, University of Notre Dame, Notre Dame, IN, USA;Department of Computer Science and Engineering, University of Notre Dame, Notre Dame, IN, USA",0.1109/tvcg.2020.3030346;10.1109/tvcg.2021.3114815;10.1109/tvcg.2020.3032123;10.1109/mcg.2018.2881523;10.1109/tvcg.2021.3109460;10.1109/mcg.2021.3097730;10.1109/tvcg.2020.3030344;10.1109/tvcg.2020.3030374;10.1109/tvcg.2021.3106142;10.1109/tvcg.2019.2956697;10.1109/tvcg.2021.3099002;10.1109/tvcg.2020.3039340;10.1109/tvcg.2018.2816059;10.1109/tvcg.2022.3159114;10.1109/tvcg.2020.3028947;10.1109/mcg.2021.3097555;10.1109/tvcg.2018.2843369,"Scientific visualization,deep learning,,survey",,17,186,1003,,
TVCG,2022,A Framework for Evaluating Dashboards in Healthcare,10.1109/tvcg.2022.3147154,http://dx.doi.org/10.1109/TVCG.2022.3147154,1715,1731,J,"In the era of ‘information overload’, effective information provision is essential for enabling rapid response and critical decision making. In making sense of diverse information sources, dashboards have become an indispensable tool, providing fast, effective, adaptable, and personalized access to information for professionals and the general public alike. However, these objectives place heavy requirements on dashboards as information systems in usability and effective design. Understanding these issues is challenging given the absence of consistent and comprehensive approaches to dashboard evaluation. In this article we systematically review literature on dashboard implementation in healthcare, where dashboards have been employed widely, and where there is widespread interest for improving the current state of the art, and subsequently analyse approaches taken towards evaluation. We draw upon consolidated dashboard literature and our own observations to introduce a general definition of dashboards which is more relevant to current trends, together with seven evaluation scenarios - task performance, behaviour change, interaction workflow, perceived engagement, potential utility, algorithm performance and system implementation. These scenarios distinguish different evaluation purposes which we illustrate through measurements, example studies, and common challenges in evaluation study design. We provide a breakdown of each evaluation scenario, and highlight some of the more subtle questions. We demonstrate the use of the proposed framework by a design study guided by this framework. We conclude by comparing this framework with existing literature, outlining a number of active discussion points and a set of dashboard evaluation best practices for the academic, clinical and software development communities alike.",Mengdie Zhuang;David Concannon;Ed Manley,Mengdie Zhuang;David Concannon;Ed Manley,"Information School, University of Sheffield, Sheffield, U.K.;Centre for Advanced Spatial Analysis, University College London, London, U.K.;School of Geography, University of Leeds, Leeds, U.K.",0.1109/tvcg.2018.2803829;10.1109/tvcg.2013.126;10.1109/tvcg.2011.229;10.1109/tvcg.2018.2864903;10.1109/tvcg.2009.111;10.1109/tvcg.2015.2467195;10.1109/tvcg.2011.279;10.1109/tvcg.2012.213,"Visualization,dashboard,,evaluation,healthcare",,16,90,2047,,
TVCG,2022,Outcome-Explorer: A Causality Guided Interactive Visual Interface for Interpretable Algorithmic Decision Making,10.1109/tvcg.2021.3102051,http://dx.doi.org/10.1109/TVCG.2021.3102051,4728,4740,J,"The widespread adoption of algorithmic decision-making systems has brought about the necessity to interpret the reasoning behind these decisions. The majority of these systems are complex black box models, and auxiliary models are often used to approximate and then explain their behavior. However, recent research suggests that such explanations are not overly accessible to lay users with no specific expertise in machine learning and this can lead to an incorrect interpretation of the underlying model. In this article, we show that a predictive and interactive model based on causality is inherently interpretable, does not require any auxiliary model, and allows both expert and non-expert users to understand the model comprehensively. To demonstrate our method we developed Outcome Explorer, a causality guided interactive interface, and evaluated it by conducting think-aloud sessions with three expert users and a user study with 18 non-expert users. All three expert users found our tool to be comprehensive in supporting their explanation needs while the non-expert users were able to understand the inner workings of a model easily.",Md. Naimul Hoque;Klaus Mueller 0001,Md Naimul Hoque;Klaus Mueller,"Computer Science Department, Stony Brook University, Stony Brook, NY, USA;Computer Science Department, Stony Brook University, Stony Brook, NY, USA",0.1109/vast.2017.8585647;10.1109/tvcg.2015.2467931;10.1109/tvcg.2018.2864812;10.1109/tvcg.2011.185;10.1109/tvcg.2017.2744718;10.1109/tvcg.2019.2934659;10.1109/tvcg.2018.2843369;10.1109/tvcg.2020.3028957;10.1109/tvcg.2020.3028956,"Explainable AI,causality,,visual analytics,human-computer interaction",,12,58,841,,
TVCG,2023,The Reality of the Situation: A Survey of Situated Analytics,10.1109/tvcg.2023.3285546,http://dx.doi.org/10.1109/TVCG.2023.3285546,1,19,J,"The advent of low-cost, accessible, and high-performance augmented reality (AR) has shed light on a situated form of analytics where in-situ visualizations embedded in the real world can facilitate sensemaking based on the user's physical location. In this work, we identify prior literature in this emerging field with a focus on the technologies enabling such situated analytics. After collecting 47 relevant situated analytics systems, we classify them using a taxonomy of three dimensions: situating triggers, view situatedness, and data depiction. We then identify four archetypical patterns in our classification using an ensemble cluster analysis. Finally, we discuss several insights and design guidelines that we learned from our analysis.",Sungbok Shin;Andrea Batch;Peter W. S. Butcher;Panagiotis D. Ritsos;Niklas Elmqvist,Sungbok Shin;Andrea Batch;Peter W. S. Butcher;Panagiotis D. Ritsos;Niklas Elmqvist,"University of Maryland, College Park, MD, USA;University of Maryland, College Park, MD, USA;Bangor University, Bangor, U.K.;Bangor University, Bangor, U.K.;University of Maryland, College Park, MD, USA",,"situated analytics,situated visualization,,augmented reality,immersive analytics,data visualization",,12,0,419,,
TVCG,2022,Designing With Pictographs: Envision Topics Without Sacrificing Understanding,10.1109/tvcg.2021.3092680,http://dx.doi.org/10.1109/TVCG.2021.3092680,4515,4530,J,"Past studies have shown that when a visualization uses pictographs to encode data, they have a positive effect on memory, engagement, and assessment of risk. However, little is known about how pictographs affect one’s ability to understand a visualization, beyond memory for values and trends. We conducted two crowdsourced experiments to compare the effectiveness of using pictographs when showing part-to-whole relationships. In Experiment 1, we compared pictograph arrays to more traditional bar and pie charts. We tested participants’ ability to generate high-level insights following Bloom’s taxonomy of educational objectives via 6 free-response questions. We found that accuracy for extracting information and generating insights did not differ overall between the two versions. To explore the motivating differences between the designs, we conducted a second experiment where participants compared charts containing pictograph arrays to more traditional charts on 5 metrics and explained their reasoning. We found that some participants preferred the way that pictographs allowed them to envision the topic more easily, while others preferred traditional bar and pie charts because they seem less cluttered and faster to read. These results suggest that, at least in simple visualizations depicting part-to-whole relationships, the choice of using pictographs has little influence on sensemaking and insight extraction. When deciding whether to use pictograph arrays, designers should consider visual appeal, perceived comprehension time, ease of envisioning the topic, and clutteredness.",Alyxander Burns;Cindy Xiong;Steven Franconeri;Alberto Cairo;Narges Mahyar,Alyxander Burns;Cindy Xiong;Steven Franconeri;Alberto Cairo;Narges Mahyar,"College of Information and Computer Sciences, University of Massachusetts Amherst, Amherst, MA, USA;Department of Psychology, Northwestern University, Evanston, IL, USA;Department of Psychology, Northwestern University, Evanston, IL, USA;School of Communication, University of Miami, Coral Gables, FL, USA;College of Information and Computer Sciences, University of Massachusetts Amherst, Amherst, MA, USA",0.1109/tvcg.2020.3030375;10.1109/tvcg.2018.2865158;10.1109/tvcg.2007.70541;10.1109/tvcg.2013.210;10.1109/tvcg.2015.2467732;10.1109/tvcg.2013.234;10.1109/mcg.2018.2879066,"Infographics,pictographs,,design,graph comprehension,understanding,casual sensemaking",,8,72,865,,
TVCG,2023,Explaining With Examples: Lessons Learned From Crowdsourced Introductory Description of Information Visualizations,10.1109/tvcg.2021.3128157,http://dx.doi.org/10.1109/TVCG.2021.3128157,1638,1650,J,"Data visualizations have been increasingly used in oral presentations to communicate data patterns to the general public. Clear verbal introductions of visualizations to explain how to interpret the visually encoded information are essential to convey the takeaways and avoid misunderstandings. We contribute a series of studies to investigate how to effectively introduce visualizations to the audience with varying degrees of visualization literacy. We begin with understanding how people are introducing visualizations. We crowdsource 110 introductions of visualizations and categorize them based on their content and structures. From these crowdsourced introductions, we identify different introduction strategies and generate a set of introductions for evaluation. We conduct experiments to systematically compare the effectiveness of different introduction strategies across four visualizations with 1,080 participants. We find that introductions explaining visual encodings with concrete examples are the most effective. Our study provides both qualitative and quantitative insights into how to construct effective verbal introductions of visualizations in presentations, inspiring further research in data storytelling.",Leni Yang;Cindy Xiong;Jason K. Wong;Aoyu Wu;Huamin Qu,Leni Yang;Cindy Xiong;Jason K. Wong;Aoyu Wu;Huamin Qu,"Hong Kong University of Science and Technology, Hong Kong;University of Massachusetts Amherst, Amherst, MA, USA;Hong Kong University of Science and Technology, Hong Kong;Hong Kong University of Science and Technology, Hong Kong;Hong Kong University of Science and Technology, Hong Kong",0.1109/tvcg.2015.2467195;10.1109/tvcg.2019.2917689;10.1109/tvcg.2015.2413786;10.1109/tvcg.2016.2598920;10.1109/tvcg.2010.179;10.1109/tvcg.2018.2829750;10.1109/tvcg.2020.3030396;10.1109/tvcg.2021.3114823;10.1109/tvcg.2015.2502587;10.1109/tvcg.2021.3068337,"Narrative visualization,oral presentation,,introduction",,9,45,661,,
TVCG,2022,VISAtlas: An Image-based Exploration and Query System for Large Visualization Collections via Neural Image Embedding,10.1109/tvcg.2022.3229023,http://dx.doi.org/10.1109/TVCG.2022.3229023,1,15,J,"High-quality visualization collections are beneficial for a variety of applications including visualization reference and data-driven visualization design. The visualization community has created many visualization collections, and developed interactive exploration systems for the collections. However, the systems are mainly based on extrinsic attributes like authors and publication years, whilst neglect intrinsic property (i.e., visual appearance) of visualizations, hindering visual comparison and query of visualization designs. This paper presents VISAtlas, an image-based approach empowered by neural image embedding, to facilitate exploration and query for visualization collections. To improve embedding accuracy, we create a comprehensive collection of synthetic and real-world visualizations, and use it to train a convolutional neural network (CNN) model with a triplet loss for taxonomical classification of visualizations. Next, we design a coordinated multiple view (CMV) system that enables multi-perspective exploration and design retrieval based on visualization embeddings. Specifically, we design a novel embedding overview that leverages contextual layout framework to preserve the context of the embedding vectors with the associated visualization taxonomies, and density plot and sampling techniques to address the overdrawing problem. We demonstrate in three case studies and one user study the effectiveness of VISAtlas in supporting comparative analysis of visualization collections, exploration of composite visualizations, and image-based retrieval of visualization designs. The studies reveal that real-world visualization collections (e.g., Beagle and VIS30K) better accord with the richness and diversity of visualization designs than synthetic collections (e.g., Data2Vis), inspiring composite visualizations are identified in real-world collections, and distinct design patterns exist in visualizations from different sources.",Yilin Ye;Rong Huang;Wei Zeng,Yilin Ye;Rong Huang;Wei Zeng,"Hong Kong University of Science and Technology, Hong Kong, China;Hong Kong University of Science and Technology, Hong Kong, China;Hong Kong University of Science and Technology, Hong Kong, China",,"Visualization collection,image embedding,,visual query,image visualization,design pattern",,9,0,607,,
TVCG,2022,Visualization in Motion: A Research Agenda and Two Evaluations,10.1109/tvcg.2022.3184993,http://dx.doi.org/10.1109/TVCG.2022.3184993,3546,3562,J,"We contribute a research agenda for visualization in motion and two experiments to understand how well viewers can read data from moving visualizations. We define visualizations in motion as visual data representations that are used in contexts that exhibit relative motion between a viewer and an entire visualization. Sports analytics, video games, wearable devices, or data physicalizations are example contexts that involve different types of relative motion between a viewer and a visualization. To analyze the opportunities and challenges for designing visualization in motion, we show example scenarios and outline a first research agenda. Motivated primarily by the prevalence of and opportunities for visualizations in sports and video games we started to investigate a small aspect of our research agenda: the impact of two important characteristics of motion—speed and trajectory on a stationary viewer's ability to read data from moving donut and bar charts. We found that increasing speed and trajectory complexity did negatively affect the accuracy of reading values from the charts and that bar charts were more negatively impacted. In practice, however, this impact was small: both charts were still read fairly accurately.",Lijie Yao;Anastasia Bezerianos;Romain Vuillemot;Petra Isenberg,Lijie Yao;Anastasia Bezerianos;Romain Vuillemot;Petra Isenberg,"CNRS, Inria, LISN, Université Paris-Saclay, Gif-sur-Yvette, France;CNRS, Inria, LISN, Université Paris-Saclay, Gif-sur-Yvette, France;ÉCole Centrale de Lyon, CNRS, UMR5205, LIRIS, Université de Lyon, France;CNRS, Inria, LISN, Université Paris-Saclay, Gif-sur-Yvette, France",0.1109/tvcg.2007.70539;10.1109/tvcg.2008.153;10.1109/tvcg.2019.2934784;10.1109/tvcg.2010.186;10.1109/tvcg.2021.3133511;10.1109/tvcg.2016.2598415;10.1109/tvcg.2019.2952129;10.1109/tvcg.2013.254;10.1109/vast.2016.7883506;10.1109/tvcg.2012.251;10.1109/tvcg.2013.163;10.1109/tvcg.2013.166;10.1109/tvcg.2020.3030460;10.1109/tvcg.2015.2413786;10.1109/visual.2001.964496;10.1109/tvcg.2019.2934243;10.1109/tvcg.2017.2744218;10.1109/tvcg.2014.2346320;10.1109/tvcg.2016.2598608;10.1109/tvcg.2016.2598498;10.1109/tvcg.2017.2744359;10.1109/tvcg.2017.2745181;10.1109/tvcg.2020.3030392;10.1109/tvcg.2018.2865041;10.1109/tvcg.2018.2865142;10.1109/tvcg.2012.77;10.1109/tvcg.2021.3114806;10.1109/tvcg.2014.2346424,"Visualization,visualization in motion,,perception,research agenda,movement,motion",,9,116,962,,X
TVCG,2023,ShortcutLens: A Visual Analytics Approach for Exploring Shortcuts in Natural Language Understanding Dataset,10.1109/tvcg.2023.3236380,http://dx.doi.org/10.1109/TVCG.2023.3236380,1,15,J,"Benchmark datasets play an important role in evaluating Natural Language Understanding (NLU) models. However, shortcuts—unwanted biases in the benchmark datasets—can damage the effectiveness of benchmark datasets in revealing models' real capabilities. Since shortcuts vary in coverage, productivity, and semantic meaning, it is challenging for NLU experts to systematically understand and avoid them when creating benchmark datasets. In this paper, we develop a visual analytics system, ShortcutLens, to help NLU experts explore shortcuts in NLU benchmark datasets. The system allows users to conduct multi-level exploration of shortcuts. Specifically, Statistics View helps users grasp the statistics such as coverage and productivity of shortcuts in the benchmark dataset. Template View employs hierarchical and interpretable templates to summarize different types of shortcuts. Instance View allows users to check the corresponding instances covered by the shortcuts. We conduct case studies and expert interviews to evaluate the effectiveness and usability of the system. The results demonstrate that ShortcutLens supports users in gaining a better understanding of benchmark dataset issues through shortcuts, inspiring them to create challenging and pertinent benchmark datasets.",Zhihua Jin;Xingbo Wang;Furui Cheng;Chunhui Sun;Qun Liu;Huamin Qu,Zhihua Jin;Xingbo Wang;Furui Cheng;Chunhui Sun;Qun Liu;Huamin Qu,"Hong Kong University of Science and Technology, Hong Kong, China;Hong Kong University of Science and Technology, Hong Kong, China;Hong Kong University of Science and Technology, Hong Kong, China;Peking University, Beijing, China;Huawei Noah's Ark Lab, Hong Kong, China;Hong Kong University of Science and Technology, Hong Kong, China",,"Visual Analytics,Natural Language Understanding,,Shortcut",,7,0,228,,
TVCG,2023,DMiner: Dashboard Design Mining and Recommendation,10.1109/tvcg.2023.3251344,http://dx.doi.org/10.1109/TVCG.2023.3251344,1,15,J,"Dashboards, which comprise multiple views on a single display, help analyze and communicate multiple perspectives of data simultaneously. However, creating effective and elegant dashboards is challenging since it requires careful and logical arrangement and coordination of multiple visualizations. To solve the problem, we propose a data-driven approach for mining design rules from dashboards and automating dashboard organization. Specifically, we focus on two prominent aspects of the organization: arrangement, which describes the position, size, and layout of each view in the display space; and coordination, which indicates the interaction between pairwise views. We build a new dataset containing 854 dashboards crawled online, and develop feature engineering methods for describing the single views and view-wise relationships in terms of data, encoding, layout, and interactions. Further, we identify design rules among those features and develop a recommender for dashboard design. We demonstrate the usefulness of DMiner through an expert study and a user study. The expert study shows that our extracted design rules are reasonable and conform to the design practice of experts. Moreover, a comparative user study shows that our recommender could help automate dashboard organization and reach human-level performance. In summary, our work offers a promising starting point for design mining visualizations to build recommenders.",Yanna Lin;Haotian Li;Aoyu Wu;Yong Wang;Huamin Qu,Yanna Lin;Haotian Li;Aoyu Wu;Yong Wang;Huamin Qu,"Hong Kong University of Science and Technology, Hong Kong;Hong Kong University of Science and Technology, Hong Kong;Hong Kong University of Science and Technology, Hong Kong;Singapore Management University, Singapore;Hong Kong University of Science and Technology, Hong Kong",,"Design Mining,Visualization Recommendation,,Multiple-view Visualization,Dashboards",,5,0,443,,
TVCG,2022,GEViTRec: Data Reconnaissance Through Recommendation Using a Domain-Specific Visualization Prevalence Design Space,10.1109/tvcg.2021.3107749,http://dx.doi.org/10.1109/TVCG.2021.3107749,4855,4872,J,"Genomic Epidemiology (genEpi) is a branch of public health that uses many different data types including tabular, network, genomic, and geographic, to identify and contain outbreaks of deadly diseases. Due to the volume and variety of data, it is challenging for genEpi domain experts to conduct data reconnaissance; that is, have an overview of the data they have and make assessments toward its quality, completeness, and suitability. We present an algorithm for data reconnaissance through automatic visualization recommendation, GEViTRec. Our approach handles a broad variety of dataset types and automatically generates visually coherent combinations of charts, in contrast to existing systems that primarily focus on singleton visual encodings of tabular datasets. We automatically detect linkages across multiple input datasets by analyzing non-numeric attribute fields, creating a data source graph within which we analyze and rank paths. For each high-ranking path, we specify chart combinations with positional and color alignments between shared fields, using a gradual binding approach to transform initial partial specifications of singleton charts to complete specifications that are aligned and oriented consistently. A novel aspect of our approach is its combination of domain-agnostic elements with domain-specific information that is captured through a domain-specific visualization prevalence design space. Our implementation is applied to both synthetic data and real Ebola outbreak data. We compare GEViTRec's output to what previous visualization recommendation systems would generate, and to manually crafted visualizations used by practitioners. We conducted formative evaluations with ten genEpi experts to assess the relevance and interpretability of our results. Code, Data, and Study Materials Availability: https://github.com/amcrisan/GEVitRec.",Anamaria Crisan;Shannah Fisher;Jennifer L. Gardy;Tamara Munzner,Anamaria Crisan;Shannah E. Fisher;Jennifer L. Gardy;Tamara Munzner,"Tableau Research, Seattle, WA, USA;University of British Columbia, Vancouver, BC, Canada;Gates Foundation, Seattle, WA, USA;University of British Columbia, Vancouver, BC, Canada",0.1109/tvcg.2007.70617;10.1109/tvcg.2018.2864903;10.1109/tvcg.2019.2934283;10.1109/tvcg.2015.2467201;10.1109/tvcg.2015.2467191;10.1109/tvcg.2012.110;10.1109/tvcg.2017.2785807;10.1109/tvcg.2009.128;10.1109/tvcg.2016.2599030;10.1109/tvcg.2018.2865158;10.1109/infvis.2004.12;10.1109/mcg.2014.40;10.1109/infvis.1997.636792;10.1109/tvcg.2007.70577;10.1109/tvcg.2020.3030419;10.1109/tvcg.2017.2744198;10.1109/tvcg.2007.70594;10.1109/tvcg.2018.2865240;10.1109/tvcg.2008.109;10.1109/tvcg.2014.2346260;10.1109/tvcg.2018.2811488,"Heterogeneous data,multiple coordinated views,,data reconnaissance,bioinformatics",,4,63,808,,
TVCG,2022,Reasoning Affordances with Tables and Bar Charts,10.1109/tvcg.2022.3232959,http://dx.doi.org/10.1109/TVCG.2022.3232959,1,13,J,"A viewer's existing beliefs can prevent accurate reasoning with data visualizations. In particular, confirmation bias can cause people to overweigh information that confirms their beliefs, and dismiss information that disconfirms them. We tested whether confirmation bias exists when people reason with visualized data and whether certain visualization designs can elicit less biased reasoning strategies. We asked crowdworkers to solve reasoning problems that had the potential to evoke both poor reasoning strategies and confirmation bias. We created two scenarios, one in which we primed people with a belief before asking them to make a decision, and another in which people held pre-existing beliefs. The data was presented as either a table, a bar table, or a bar chart. To correctly solve the problem, participants should use a complex reasoning strategy to compare two ratios, each between two pairs of values. But participants could also be tempted to use simpler, superficial heuristics, shortcuts, or biased strategies to reason about the problem. Presenting the data in a table format helped participants reason with the correct ratio strategy while showing the data as a bar table or a bar chart led participants towards incorrect heuristics. Confirmation bias was not significantly present when beliefs were primed, but it was present when beliefs were pre-existing. Additionally, the table presentation format was more likely to afford the ratio reasoning strategy, and the use of ratio strategy was more likely to lead to the correct answer. These findings suggest that data presentation formats can affect affordances for reasoning.",Cindy Xiong;Elsie Lee-Robbins;Icy Zhang;Aimen Gaba;Steven Franconeri,Cindy Xiong;Elsie Lee-Robbins;Icy Zhang;Aimen Gaba;Steven Franconeri,"University of Massachusetts, Amherst, U.K.;University of Michigan, Ann Arbor, U.K.;University of California Los Angeles, Los Angeles, U.K.;University of Massachusetts, Amherst, U.K.;Northwestern University, Evanston, U.K.",,"Data visualization,Tabular displays,,Empirical evaluation,Reasoning",,3,0,317,,
TVCG,2023,Understanding How In-Visualization Provenance Can Support Trade-Off Analysis,10.1109/tvcg.2022.3171074,http://dx.doi.org/10.1109/TVCG.2022.3171074,3758,3774,J,"In domains, such as agronomy or manufacturing, experts need to consider trade-offs when making decisions that involve several, often competing, objectives. Such analysis is complex and may be conducted over long periods of time, making it hard to revisit. In this paper, we consider the use of analytic provenance mechanisms to aid experts recall and keep track of trade-off analysis. We implemented VisProm, a web-based trade-off analysis system, that incorporates in-visualization provenance views, designed to help experts keep track of trade-offs and their objectives. We used VisProm as a technology probe to understand user needs and explore the potential role of provenance in this context. Through observation sessions with three groups of experts analyzing their own data, we make the following contributions. We first, identify eight high-level tasks that experts engaged in during trade-off analysis, such as locating and characterizing interest zones in the trade-off space, and show how these tasks can be supported by provenance visualization. Second, we refine findings from previous work on provenance purposes such as recall and reproduce, by identifying specific objects of these purposes related to trade-off analysis, such as interest zones, and exploration structure (e.g., exploration of alternatives and branches). Third, we discuss insights on how the identified provenance objects and our designs support these trade-off analysis tasks, both when revisiting past analysis and while actively exploring. And finally, we identify new opportunities for provenance-driven trade-off analysis, for example related to monitoring the coverage of the trade-off space, and tracking alternative trade-off scenarios.",Mehdi Chakhchoukh;Nadia Boukhelifa;Anastasia Bezerianos,Mehdi Chakhchoukh;Nadia Boukhelifa;Anastasia Bezerianos,"CNRS, INRIA, UMR MIA-Paris, AgroParisTech, INRAE, University Paris-Saclay, Gif-sur-Yvette, France;UMR MIA-Paris, AgroParisTech, INRAE, University Paris-Saclay, Palaiseau, France;CNRS, INRIA, University Paris-Saclay, Gif-sur-Yvette, France",0.1109/tvcg.2017.2745279;10.1109/tvcg.2008.137;10.1109/tvcg.2016.2599058;10.1109/tvcg.2007.70589;10.1109/tvcg.2021.3114862;10.1109/tvcg.2021.3114827;10.1109/tvcg.2016.2598797;10.1109/tvcg.2015.2467551;10.1109/mcg.2019.2933419;10.1109/tvcg.2008.153;10.1109/tvcg.2017.2744738;10.1109/tvcg.2015.2468011;10.1109/tvcg.2014.2346321;10.1109/tvcg.2017.2745138;10.1109/tvcg.2016.2598589;10.1109/tvcg.2013.173,"Decision making,multi-criteria,,provenance,qualitative study,trade-offs,visualization",,3,49,376,,
TVCG,2022,Multilevel Visual Analysis of Aggregate Geo-Networks,10.1109/tvcg.2022.3229953,http://dx.doi.org/10.1109/TVCG.2022.3229953,1,16,J,"Numerous patterns found in urban phenomena, such as air pollution and human mobility, can be characterized as many directed geospatial networks (geo-networks) that represent spreading processes in urban space. These geo-networks can be analyzed from multiple levels, ranging from the macro-level of summarizing all geo-networks, meso-level of comparing or summarizing parts of geo-networks, and micro-level of inspecting individual geo-networks. Most of the existing visualizations cannot support multilevel analysis well. These techniques work by: 1) showing geo-networks separately with multiple maps leads to heavy context switching costs between different maps; 2) summarizing all geo-networks into a single network can lead to the loss of individual information; 3) drawing all geo-networks onto one map might suffer from the visual scalability issue in distinguishing individual geo-networks. In this study, we propose GeoNetverse, a novel visualization technique for analyzing aggregate geo-networks from multiple levels. Inspired by metro maps, GeoNetverse balances the overview and details of the geo-networks by placing the edges shared between geo-networks in a stacked manner. To enhance the visual scalability, GeoNetverse incorporates a level-of-detail rendering, a progressive crossing minimization, and a coloring technique. A set of evaluations was conducted to evaluate GeoNetverse from multiple perspectives.",Zikun Deng;Shifu Chen;Xiao Xie;Guodao Sun;Mingliang Xu;Di Weng;Yingcai Wu,Zikun Deng;Shifu Chen;Xiao Xie;Guodao Sun;Mingliang Xu;Di Weng;Yingcai Wu,"State Key Lab of CAD&CG, Zhejiang University, Hangzhou, China;State Key Lab of CAD&CG, Zhejiang University, Hangzhou, China;Department of Sport Science, Zhejiang University, Hangzhou, China;College of Computer Science and Technology, Zhejiang University of Technology, Hangzhou, China;School of Computer and Artificial Intelligence, Zhengzhou University, Zhengzhou, China;Microsoft Research Asia, China;State Key Lab of CAD&CG, Zhejiang University, Hangzhou, China",,"Geospatial network,multilevel analysis,,information visualization,graph drawing",,3,0,272,,
TVCG,2023,uxSense: Supporting User Experience Analysis with Visualization and Computer Vision,10.1109/tvcg.2023.3241581,http://dx.doi.org/10.1109/TVCG.2023.3241581,1,15,J,"Analyzing user behavior from usability evaluation can be a challenging and time-consuming task, especially as the number of participants and the scale and complexity of the evaluation grows. We propose UXSENSE, a visual analytics system using machine learning methods to extract user behavior from audio and video recordings as parallel time-stamped data streams. Our implementation draws on pattern recognition, computer vision, natural language processing, and machine learning to extract user sentiment, actions, posture, spoken words, and other features from such recordings. These streams are visualized as parallel timelines in a web-based front-end, enabling the researcher to search, filter, and annotate data across time and space. We present the results of a user study involving professional UX researchers evaluating user data using uxSense. In fact, we used uxSense itself to evaluate their sessions.",Andrea Batch;Yipeng Ji;Mingming Fan;Jian Zhao;Niklas Elmqvist,Andrea Batch;Yipeng Ji;Mingming Fan;Jian Zhao;Niklas Elmqvist,"University of Maryland, College Park, MD, USA;University of Waterloo, ON, Canada;Hong Kong University of Science and Technology (Guangzhou) and Hong Kong University of Science and Technology, Hong Kong;University of Waterloo, ON, Canada;University of Maryland, College Park, MD, USA",,"Visualization,visual analytics,,evaluation,video analytics,machine learning,deep learning,computer vision",,4,0,377,,
TVCG,2022,From Invisible to Visible: Impacts of Metadata in Communicative Data Visualization,10.1109/tvcg.2022.3231716,http://dx.doi.org/10.1109/TVCG.2022.3231716,1,16,J,"Leaving the context of visualizations invisible can have negative impacts on understanding and transparency. While common wisdom suggests that recontextualizing visualizations with metadata (e.g., disclosing the data source or instructions for decoding the visualizations' encoding) may counter these effects, the impact remains largely unknown. To fill this gap, we conducted two experiments. In Experiment 1, we explored how chart type, topic, and user goal impacted which categories of metadata participants deemed most relevant. We presented 64 participants with four real-world visualizations. For each visualization, participants were given four goals and selected the type of metadata they most wanted from a set of 18 types. Our results indicated that participants were most interested in metadata which explained the visualization's encoding for goals related to understanding and metadata about the source of the data for assessing trustworthiness. In Experiment 2, we explored how these two types of metadata impact transparency, trustworthiness and persuasiveness, information relevance, and understanding. We asked 144 participants to explain the main message of two pairs of visualizations (one with metadata and one without); rate them on scales of transparency and relevance; and then predict the likelihood that they were selected for a presentation to policymakers. Our results suggested that visualizations with metadata were perceived as more thorough than those without metadata, but similarly relevant, accurate, clear, and complete. Additionally, we found that metadata did not impact the accuracy of the information extracted from visualizations, but may have influenced which information participants remembered as important or interesting.",Alyxander Burns;Christiana Lee;Thai On;Cindy Xiong;Evan Peck;Narges Mahyar,Alyxander Burns;Christiana Lee;Thai On;Cindy Xiong;Evan Peck;Narges Mahyar,"Mount Holyoke College, USA;University of Massachusetts Amherst, USA;University of Massachusetts Amherst, USA;University of Massachusetts Amherst, USA;Bucknell University, USA;University of Massachusetts Amherst, USA",,"Visualization,metadata,,understanding,transparency,trust",,3,0,314,,
TVCG,2023,Analysis of Wildfire Visualization Systems for Research and Training: Are They up for the Challenge of the Current State of Wildfires?,10.1109/tvcg.2023.3258440,http://dx.doi.org/10.1109/TVCG.2023.3258440,1,20,J,"Wildfires affect many regions across the world. The accelerated progression of global warming has amplified their frequency and scale, deepening their impact on human life, the economy, and the environment. The temperature rise has been driving wildfires to behave unpredictably compared to those previously observed, challenging researchers and fire management agencies to understand the factors behind this behavioral change. Furthermore, this change has rendered fire personnel training outdated and lost its ability to adequately prepare personnel to respond to these new fires. Immersive visualization can play a key role in tackling the growing issue of wildfires. Therefore, this survey reviews various studies that use immersive and non-immersive data visualization techniques to depict wildfire behavior and train first responders and planners. This paper identifies the most useful characteristics of these systems. While these studies support knowledge creation for certain situations, there is still scope to comprehensively improve immersive systems to address the unforeseen dynamics of wildfires.",Carlos A. Tirado Cortes;Susanne Thurow;Alex Ong;Jason J. Sharples;Tomasz Bednarz;Grant Stevens;Dennis Del Favero,Carlos A. Tirado Cortes;Susanne Thurow;Alex Ong;Jason J. Sharples;Tomasz Bednarz;Grant Stevens;Dennis Del Favero,"iCinema Research Centre, The University of New South Wales, Kensington, NSW, Australia;iCinema Research Centre, The University of New South Wales, Kensington, NSW, Australia;iCinema Research Centre, The University of New South Wales, Kensington, NSW, Australia;School of Science, The University of New South Wales, Canberra, ACT, Australia;NVIDIA Corporation, Sydney, NSW, Australia;iCinema Research Centre, The University of New South Wales, Kensington, NSW, Australia;iCinema Research Centre, The University of New South Wales, Kensington, NSW, Australia",,"Immersive wildfire training,immersive wildfire visualization,,modelling,simulation,wildfire,wildfire visualization",,3,0,228,,
TVCG,2023,Interactive Volume Visualization Via Multi-Resolution Hash Encoding Based Neural Representation,10.1109/tvcg.2023.3293121,http://dx.doi.org/10.1109/TVCG.2023.3293121,1,14,J,"Implicit neural networks have demonstrated immense potential in compressing volume data for visualization. However, despite their advantages, the high costs of training and inference have thus far limited their application to offline data processing and non-interactive rendering. In this paper, we present a novel solution that leverages modern GPU tensor cores, a well-implemented CUDA machine learning framework, an optimized global-illumination-capable volume rendering algorithm, and a suitable acceleration data structure to enable real-time direct ray tracing of volumetric neural representations. Our approach produces high-fidelity neural representations with a peak signal-to-noise ratio (PSNR) exceeding 30 dB, while reducing their size by up to three orders of magnitude. Remarkably, we show that the entire training step can fit within a rendering loop, bypassing the need for pre-training. Additionally, we introduce an efficient out-of-core training strategy to support extreme-scale volume data, making it possible for our volumetric neural representation training to scale up to terascale on a workstation with an NVIDIA RTX 3090 GPU. Our method significantly outperforms state-of-the-art techniques in terms of training time, reconstruction quality, and rendering performance, making it an ideal choice for applications where fast and accurate visualization of large-scale volume data is paramount.",Qi Wu;David Bauer;Michael J. Doyle;Kwan-Liu Ma,Qi Wu;David Bauer;Michael J. Doyle;Kwan-Liu Ma,"University of California, Davis, USA;University of California, Davis, USA;Intel Corporation, USA;University of California, Davis, USA",,"Implicit neural representation,path tracing,,ray marching,volume visualization",,2,0,330,,
TVCG,2023,A Qualitative Interview Study of Distributed Tracing Visualisation: A Characterisation of Challenges and Opportunities,10.1109/tvcg.2023.3241596,http://dx.doi.org/10.1109/TVCG.2023.3241596,1,12,J,"Distributed tracing tools have emerged in recent years to enable operators of modern internet applications to troubleshoot cross-component problems in deployed applications. Due to the rich, detailed diagnostic data captured by distributed tracing tools, effectively presenting this data is important. However, use of visualisation to enable sensemaking of this complex data in distributed tracing tools has received relatively little attention. Consequently, operators struggle to make effective use of existing tools. In this paper we present the first characterisation of distributed tracing visualisation through a qualitative interview study with six practitioners from two large internet companies. Across two rounds of 1-on-1 interviews we use grounded theory coding to establish users, extract concrete use cases and identify shortcomings of existing distributed tracing tools. We derive guidelines for development of future distributed tracing tools and expose several open research problems that have wide reaching implications for visualisation research and other domains.",Thomas Davidson;Emily Wall;Jonathan Mace,Thomas Davidson;Emily Wall;Jonathan Mace,"Max Planck Institute for Software Systems, University of Saarland, Saarbrücken, Germany;Emory University, Atlanta, GA, USA;Max Planck Institute for Software Systems, University of Saarland, Saarbrücken, Germany",,"Visualisation,Distributed Tracing,,Systems",,4,0,334,,
TVCG,2023,RadVolViz: An Information Display-Inspired Transfer Function Editor for Multivariate Volume Visualization,10.1109/tvcg.2023.3263856,http://dx.doi.org/10.1109/TVCG.2023.3263856,1,16,J,"In volume visualization transfer functions are widely used for mapping voxel properties to color and opacity. Typically, volume density data are scalars which require simple 1D transfer functions to achieve this mapping. If the volume densities are vectors of three channels, one can straightforwardly map each channel to either red, green or blue, which requires a trivial extension of the 1D transfer function editor. We devise a new method that applies to volume data with more than three channels. These types of data often arise in scientific scanning applications, where the data are separated into spectral bands or chemical elements. Our method expands on prior work in which a multivariate information display, RadViz, was fused with a radial color map, in order to visualize multi-band 2D images. In this work, we extend this joint interface to blended volume rendering. The information display allows users to recognize the presence and value distribution of the multivariate voxels and the joint volume rendering display visualizes their spatial distribution. We design a set of operators and lenses that allow users to interactively control the mapping of the multivariate voxels to opacity and color. This enables users to isolate or emphasize volumetric structures with desired multivariate properties. Furthermore, it turns out that our method also enables more insightful displays even for RGB data. We demonstrate our method with three datasets obtained from spectral electron microscopy, high energy X-ray scanning, and atmospheric science.",Ayush Kumar;Xinyu Zhang;Huolin L. Xin;Hanfei Yan;Xiaojing Huang;Wei Xu;Klaus Mueller,Ayush Kumar;Xinyu Zhang;Huolin L. Xin;Hanfei Yan;Xiaojing Huang;Wei Xu;Klaus Mueller,"Department of Computer Science, Stony Brook University, Stony Brook, NY, USA;Department of Computer Science, Stony Brook University, Stony Brook, NY, USA;Department of Physics and Astronomy, UC Irvine, Irvine, CA, USA;Brookhaven National Lab, Upton, NY, USA;Brookhaven National Lab, Upton, NY, USA;Brookhaven National Lab, Upton, NY, USA;Department of Computer Science, Stony Brook University, Stony Brook, NY, USA",,"Battery,color mapping,,multi channel data,multivariate data,transfer function,volume rendering,volume visualization",,3,0,198,,
TVCG,2023,Creating Emordle: Animating Word Cloud for Emotion Expression,10.1109/tvcg.2023.3286392,http://dx.doi.org/10.1109/TVCG.2023.3286392,1,14,J,"We propose emordle, a conceptual design that animates wordles (compact word clouds) to deliver their emotional context to audiences. To inform the design, we first reviewed online examples of animated texts and animated wordles, and summarized strategies for injecting emotion into the animations. We introduced a composite approach that extends an existing animation scheme for one word to multiple words in a wordle with two global factors: the randomness of text animation (entropy) and the animation speed (speed). To create an emordle, general users can choose one predefined animated scheme that matches the intended emotion class and fine-tune the emotion intensity with the two parameters. We designed proof-of-concept emordle examples for four basic emotion classes, namely happiness, sadness, anger, and fear. We conducted two controlled crowdsourcing studies to evaluate our approach. The first study confirmed that people generally agreed on the conveyed emotions from well-crafted animations, and the second one demonstrated that our identified factors helped fine-tune the extent of the emotion delivered. We also invited general users to create their own emordles based on our proposed framework. Through this user study, we confirmed the effectiveness of the approach. We concluded with implications for future research opportunities of supporting emotion expression in visualizations.",Liwenhan Xie;Xinhuan Shu;Jeon Cheol Su;Yun Wang;Siming Chen;Huamin Qu,Liwenhan Xie;Xinhuan Shu;Jeon Cheol Su;Yun Wang;Siming Chen;Huamin Qu,"Department of Computer Science and Engineering, Hong Kong University of Science and Technology, Hong Kong, China;Department of Computer Science and Engineering, Hong Kong University of Science and Technology, Hong Kong, China;Department of Computer Science and Engineering, Hong Kong University of Science and Technology, Hong Kong, China;Microsoft Research Asia, Beijing, China;School of Data Science, Fudan University, Shanghai, China;Department of Computer Science and Engineering, Hong Kong University of Science and Technology, Hong Kong, China",,"Wordle,Animation,,Affective Visualization,Authoring,Casual Visualization",,4,0,237,,
TVCG,2022,GraphDecoder: Recovering Diverse Network Graphs from Visualization Images via Attention-Aware Learning,10.1109/tvcg.2022.3225554,http://dx.doi.org/10.1109/TVCG.2022.3225554,1,17,J,"DNGs are diverse network graphs with texts and different styles of nodes and edges, including mind maps, modeling graphs, and flowcharts. They are high-level visualizations that are easy for humans to understand but difficult for machines. Inspired by the process of human perception of graphs, we propose a method called GraphDecoder to extract data from raster images. Given a raster image, we extract the content based on a neural network. We built a semantic segmentation network based on U-Net. We increase the attention mechanism module, simplify the network model, and design a specific loss function to improve the model's ability to extract graph data. After this semantic segmentation network, we can extract the data of all nodes and edges. We then combine these data to obtain the topological relationship of the entire DNG. We also provide an interactive interface for users to redesign the DNGs. We verify the effectiveness of our method by evaluations and user studies on datasets collected on the Internet and generated datasets.",Sicheng Song;Chenhui Li;Dong Li;Juntong Chen;Changbo Wang,Sicheng Song;Chenhui Li;Dong Li;Juntong Chen;Changbo Wang,"School of Computer Science and Technology, East China Normal University, Shanghai, China;School of Computer Science and Technology, East China Normal University, Shanghai, China;School of Computer Science and Technology, East China Normal University, Shanghai, China;School of Computer Science and Technology, East China Normal University, Shanghai, China;School of Computer Science and Technology, East China Normal University, Shanghai, China",,"Information visualization,Chart mining,,Semantic segmentation,Network graph,Attention mechanism",,2,0,291,,
TVCG,2023,Towards Visualization Thumbnail Designs That Entice Reading Data-Driven Articles,10.1109/tvcg.2023.3278304,http://dx.doi.org/10.1109/TVCG.2023.3278304,1,16,J,"As online news increasingly include data journalism, there is a corresponding increase in the incorporation of visualization in article thumbnail images. However, little research exists on the design rationale for visualization thumbnails, such as resizing, cropping, simplifying, and embellishing charts that appear within the body of the associated article. Therefore, in this paper we aim to understand these design choices and determine what makes a visualization thumbnail inviting and interpretable. To this end, we first survey visualization thumbnails collected online and discuss visualization thumbnail practices with data journalists and news graphics designers. Based on the survey and discussion results, we then define a design space for visualization thumbnails and conduct a user study with four types of visualization thumbnails derived from the design space. The study results indicate that different chart components play different roles in attracting reader attention and enhancing reader understandability of the visualization thumbnails. We also find various thumbnail design strategies for effectively combining the charts' components, such as a data summary with highlights and data labels, and a visual legend with text labels and Human Recognizable Objects (HROs), into thumbnails. Ultimately, we distill our findings into design implications that allow effective visualization thumbnail designs for data-rich news articles. Our work can thus be seen as a first step toward providing structured guidance on how to design compelling thumbnails for data stories.",Hwiyeon Kim;Joohee Kim;Yunha Han;Hwajung Hong;Oh-Sang Kwon;Young-Woo Park;Niklas Elmqvist;Sungahn Ko;Bum Chul Kwon,Hwiyeon Kim;Joohee Kim;Yunha Han;Hwajung Hong;Oh-Sang Kwon;Young-Woo Park;Niklas Elmqvist;Sungahn Ko;Bum Chul Kwon,"UNIST, Ulsan, South Korea;UNIST, Ulsan, South Korea;UNIST, Ulsan, South Korea;KAIST, Daejeon, South Korea;UNIST, Ulsan, South Korea;UNIST, Ulsan, South Korea;University of Maryland, College Park, MD, USA;UNIST, Ulsan, South Korea;IBM Research, Cambridge, MA, USA",,"Data journalism,data stories,,data-driven storytelling,online news,thumbnail images,visualization",,1,0,247,,
TVCG,2022,MitoVis: A Unified Visual Analytics System for End-to-End Neuronal Mitochondria Analysis,10.1109/tvcg.2022.3233548,http://dx.doi.org/10.1109/TVCG.2022.3233548,1,15,J,"Neurons have a polarized structure, with dendrites and axons, and compartment-specific functions can be affected by the dwelling mitochondria. Recent studies have shown that the morphology of mitochondria is closely related to the functions of neurons and neurodegenerative diseases. However, the conventional mitochondria analysis workflow mainly relies on manual annotations and generic image-processing software. Moreover, even though there have been recent developments in automatic mitochondria analysis using deep learning, the application of existing methods in a daily analysis remains challenging because the performance of a pretrained deep learning model can vary depending on the target data, and there are always errors in inference time, requiring human proofreading. To address these issues, we introduce MitoVis, a novel visualization system for end-to-end data processing and an interactive analysis of the morphology of neuronal mitochondria. MitoVis introduces a novel active learning framework based on recent contrastive learning, which allows accurate fine-tuning of the neural network model. MitoVis also provides novel visual guides for interactive proofreading so that users can quickly identify and correct errors in the result with minimal effort. We demonstrate the usefulness and efficacy of the system via case studies conducted by neuroscientists. The results show that MitoVis achieved up to 13.3× faster total analysis time in the case study compared to the conventional manual analysis workflow.",JunYoung Choi;Hyun-Jic Oh;Hakjun Lee;Suyeon Kim;Seok-Kyu Kwon;Won-Ki Jeong,JunYoung Choi;Hyun-Jic Oh;Hakjun Lee;Suyeon Kim;Seok-Kyu Kwon;Won-Ki Jeong,"Korea University, Seoul, Korea;Korea University, Seoul, Korea;Korea University, Seoul, Korea;Korea University, Seoul, Korea;Korea Institute of Science and Technology, Seoul, Korea;Korea University, Seoul, Korea",,"Biomedical and medical visualization,intelligence analysis,,machine learning,task and requirements analysis,user interfaces",,1,0,265,,
TVCG,2023,Evaluating the Impact of Uncertainty Visualization on Model Reliance,10.1109/tvcg.2023.3251950,http://dx.doi.org/10.1109/TVCG.2023.3251950,1,15,J,"Machine learning models have gained traction as decision support tools for tasks that require processing copious amounts of data. However, to achieve the primary benefits of automating this part of decision-making, people must be able to trust the machine learning model's outputs. In order to enhance people's trust and promote appropriate reliance on the model, visualization techniques such as interactive model steering, performance analysis, model comparison, and uncertainty visualization have been proposed. In this study, we tested the effects of two uncertainty visualization techniques in a college admissions forecasting task, under two task difficulty levels, using Amazon's Mechanical Turk platform. Results show that (1) people's reliance on the model depends on the task difficulty and level of machine uncertainty and (2) ordinal forms of expressing model uncertainty are more likely to calibrate model usage behavior. These outcomes emphasize that reliance on decision support tools can depend on the cognitive accessibility of the visualization technique and perceptions of model performance and task difficulty.",Jieqiong Zhao;Yixuan Wang;Michelle V. Mancenido;Erin K. Chiou;Ross Maciejewski,Jieqiong Zhao;Yixuan Wang;Michelle V. Mancenido;Erin K. Chiou;Ross Maciejewski,"Arizona State University, USA;Arizona State University, USA;Arizona State University, USA;Arizona State University, USA;Arizona State University, USA",,"Uncertainty,model reliance,,trust,human-machine collaborations",,2,0,321,,
TVCG,2023,Visual Explanation for Open-domain Question Answering with BERT,10.1109/tvcg.2023.3243676,http://dx.doi.org/10.1109/TVCG.2023.3243676,1,18,J,"Open-domain question answering (OpenQA) is an essential but challenging task in natural language processing that aims to answer questions in natural language formats on the basis of large-scale unstructured passages. Recent research has taken the performance of benchmark datasets to new heights, especially when these datasets are combined with techniques for machine reading comprehension based on Transformer models. However, as identified through our ongoing collaboration with domain experts and our review of literature, three key challenges limit their further improvement: (i) complex data with multiple long texts, (ii) complex model architecture with multiple modules, and (iii) semantically complex decision process. In this paper, we present VEQA, a visual analytics system that helps experts understand the decision reasons of OpenQA and provides insights into model improvement. The system summarizes the data flow within and between modules in the OpenQA model as the decision process takes place at the summary, instance and candidate levels. Specifically, it guides users through a summary visualization of dataset and module response to explore individual instances with a ranking visualization that incorporates context. Furthermore, VEQA supports fine-grained exploration of the decision flow within a single module through a comparative tree visualization. We demonstrate the effectiveness of VEQA in promoting interpretability and providing insights into model enhancement through a case study and expert evaluation.",Zekai Shao;Shuran Sun;Yuheng Zhao;Siyuan Wang;Zhongyu Wei;Tao Gui;Cagatay Turkay;Siming Chen,Zekai Shao;Shuran Sun;Yuheng Zhao;Siyuan Wang;Zhongyu Wei;Tao Gui;Cagatay Turkay;Siming Chen,"Fudan University, China;Fudan University, China;Fudan University, China;Fudan University, China;Fudan University, China;Fudan University, China;University of Warwick, U.K.;Fudan University, China",,"Open-domain Question Answering,Explainable Machine Learning,,Visual Analytics",,1,0,581,,
TVCG,2023,Image Collage on Arbitrary Shape via Shape-Aware Slicing and Optimization,10.1109/tvcg.2023.3262039,http://dx.doi.org/10.1109/TVCG.2023.3262039,1,13,J,"Image collage is a very useful tool for visualizing an image collection. Most of the existing methods and commercial applications for generating image collages are designed on simple shapes, such as rectangular and circular layouts. This greatly limits the use of image collages in some artistic and creative settings. Although there are some methods that can generate irregularly-shaped image collages, they often suffer from severe image overlapping and excessive blank space. This prevents such methods from being effective information communication tools. In this paper, we present a shape slicing algorithm and an optimization scheme that can create image collages of arbitrary shapes in an informative and visually pleasing manner given an input shape and an image collection. To overcome the challenge of irregular shapes, we propose a novel algorithm, called Shape-Aware Slicing, which partitions the input shape into cells based on medial axis and binary slicing tree. Shape-Aware Slicing, which is designed specifically for irregular shapes, takes human perception and shape structure into account to generate visually pleasing partitions. Then, the layout is optimized by analyzing input images with the goal of maximizing the total salient regions of the images. To evaluate our method, we conduct extensive experiments and compare our results against previous work. The evaluations show that our proposed algorithm can efficiently arrange image collections on irregular shapes and create visually superior results than prior work and existing commercial tools.",Dong-Yi Wu;Thi-Ngoc-Hanh Le;Sheng-Yi Yao;Yun-Chen Lin;Tong-Yee Lee,Dong-Yi Wu;Thi-Ngoc-Hanh Le;Sheng-Yi Yao;Yun-Chen Lin;Tong-Yee Lee,"National Cheng-Kung University, Taiwan;National Cheng-Kung University, Taiwan;National Cheng-Kung University, Taiwan;National Cheng-Kung University, Taiwan;National Cheng-Kung University, Taiwan",,"Image collection visualization,image collage,,irregular shape layout",,0,0,174,,
TVCG,2023,Interactive Subspace Cluster Analysis Guided by Semantic Attribute Associations,10.1109/tvcg.2023.3256376,http://dx.doi.org/10.1109/TVCG.2023.3256376,1,13,J,"Multivariate datasets with many variables are increasingly common in many application areas. Most methods approach multivariate data from a singular perspective. Subspace analysis techniques, on the other hand. provide the user a set of subspaces which can be used to view the data from multiple perspectives. However, many subspace analysis methods produce a huge amount of subspaces, a number of which are usually redundant. The enormity of the number of subspaces can be overwhelming to analysts, making it difficult for them to find informative patterns in the data. In this paper, we propose a new paradigm that constructs semantically consistent subspaces. These subspaces can then be expanded into more general subspaces by ways of conventional techniques. Our framework uses the labels/meta-data of a dataset to learn the semantic meanings and associations of the attributes. We employ a neural network to learn a semantic word embedding of the attributes and then divide this attribute space into semantically consistent subspaces. The user is provided with a visual analytics interface that guides the analysis process. We show via various examples that these semantic subspaces can help organize the data and guide the user in finding interesting patterns in the dataset.",Salman Mahmood;Klaus Mueller,Salman Mahmood;Klaus Mueller,"Computer Science Department, Stony Brook University, New York, NY, USA;Computer Science Department, Stony Brook University, New York, NY, USA",,"High-dimensional data,multivariate data,,subspace clustering,subspace analysis,cluster analysis",,1,0,226,,
TVCG,2023,Investigating the Visual Utility of Differentially Private Scatterplots,10.1109/tvcg.2023.3292391,http://dx.doi.org/10.1109/TVCG.2023.3292391,1,16,J,"Increasingly, visualization practitioners are working with, using, and studying private and sensitive data. There can be many stakeholders interested in the resulting analyses-but widespread sharing of the data can cause harm to individuals, companies, and organizations. Practitioners are increasingly turning to differential privacy to enable public data sharing with a guaranteed amount of privacy. Differential privacy algorithms do this by aggregating data statistics with noise, and this now-private data can be released visually with differentially private scatterplots. While the private visual output is affected by the algorithm choice, privacy level, bin number, data distribution, and user task, there is little guidance on how to choose and balance the effect of these parameters. To address this gap, we had experts examine 1,200 differentially private scatterplots created with a variety of parameter choices and tested their ability to see aggregate patterns in the private output (i.e. the visual utility of the chart). We synthesized these results to provide easy-to-use guidance for visualization practitioners releasing private data through scatterplots. Our findings also provide a ground truth for visual utility, which we use to benchmark automated utility metrics from various fields. We demonstrate how multi-scale structural similarity (MS-SSIM), the metric most strongly correlated with our study's utility results, can be used to optimize parameter selection. A free copy of this paper along with all supplemental materials is available at https://osf.io/wej4s/.",Liudas Panavas;Tarik Crnovrsanin;Jane Lydia Adams;Jonathan Ullman;Ali Sargavad;Melanie Tory;Cody Dunne,Liudas Panavas;Tarik Crnovrsanin;Jane Lydia Adams;Jonathan Ullman;Ali Sargavad;Melanie Tory;Cody Dunne,"Northeastern University, USA;Northeastern University, USA;Northeastern University, USA;Northeastern University, USA;University of Massachusetts, Amherst, USA;Northeastern University, USA;Northeastern University, USA",,"Scatterplots,differential privacy,,data study,visual utility",,0,0,118,,
TVCG,2022,GPU Accelerated 3D Tomographic Reconstruction and Visualization from Noisy Electron Microscopy Tilt-Series,10.1109/tvcg.2022.3230445,http://dx.doi.org/10.1109/TVCG.2022.3230445,1,15,J,"We present a novel framework for 3D tomographic reconstruction and visualization of tomograms from noisy electron microscopy tilt-series. Our technique takes as an input aligned tilt-series from cryogenic electron microscopy and creates denoised 3D tomograms using a proximal jointly-optimized approach that iteratively performs reconstruction and denoising, relieving the users of the need to select appropriate denoising algorithms in the pre-reconstruction or post-reconstruction steps. The whole process is accelerated by exploiting parallelism on modern GPUs, and the results can be visualized immediately after the reconstruction using volume rendering tools incorporated in the framework. We show that our technique can be used with multiple combinations of reconstruction algorithms and regularizers, thanks to the flexibility provided by proximal algorithms. Additionally, the reconstruction framework is open-source and can be easily extended with additional reconstruction and denoising methods. Furthermore, our approach enables visualization of reconstruction error throughout the iterative process within the reconstructed tomogram and on projection planes of the input tilt-series. We evaluate our approach in comparison with state-of-the-art approaches and additionally show how our error visualization can be used for reconstruction evaluation.",Julio Rey Ramirez;Peter Rautek;Ciril Bohak;Ondřej Strnad;Zheyuan Zhang;Sai Li;Ivan Viola;Wolfgang Heidrich,Julio Rey Ramirez;Peter Rautek;Ciril Bohak;Ondřej Strnad;Zheyuan Zhang;Sai Li;Ivan Viola;Wolfgang Heidrich,"Visual Computing Center at King Abdullah University of Science and Technology (KAUST), Thuwal, Kingdom of Saudi Arabia;Visual Computing Center at King Abdullah University of Science and Technology (KAUST), Thuwal, Kingdom of Saudi Arabia;Visual Computing Center at King Abdullah University of Science and Technology (KAUST), Thuwal, Kingdom of Saudi Arabia;Visual Computing Center at King Abdullah University of Science and Technology (KAUST), Thuwal, Kingdom of Saudi Arabia;School of Life Sciences, Tsinghua University, Beijing, China;School of Life Sciences, Tsinghua University, Beijing, China;Visual Computing Center at King Abdullah University of Science and Technology (KAUST), Thuwal, Kingdom of Saudi Arabia;Visual Computing Center at King Abdullah University of Science and Technology (KAUST), Thuwal, Kingdom of Saudi Arabia",,"tomographic reconstruction,electron tomography,,tilt-series,visualization,cryo-ET,GPU acceleration",,0,0,446,,
TVCG,2023,Fuzzy Spreadsheet: Understanding and Exploring Uncertainties in Tabular Calculations,10.1109/tvcg.2021.3119212,http://dx.doi.org/10.1109/TVCG.2021.3119212,1463,1477,J,"Spreadsheet-based tools provide a simple yet effective way of calculating values, which makes them the number-one choice for building and formalizing simple models for budget planning and many other applications. A cell in a spreadsheet holds one specific value and gives a discrete, overprecise view of the underlying model. Therefore, spreadsheets are of limited use when investigating the inherent uncertainties of such models and answering what-if questions. Existing extensions typically require a complex modeling process that cannot easily be embedded in a tabular layout. In Fuzzy Spreadsheet, a cell can hold and display a distribution of values. This integrated uncertainty-handling immediately conveys sensitivity and robustness information. The fuzzification of the cells enables calculations not only with precise values but also with distributions, and probabilities. We conservatively added and carefully crafted visuals to maintain the look and feel of a traditional spreadsheet while facilitating what-if analyses. Given a user-specified reference cell, Fuzzy Spreadsheet automatically extracts and visualizes contextually relevant information, such as impact, uncertainty, and degree of neighborhood, for the selected and related cells. To evaluate its usability and the perceived mental effort required, we conducted a user study. The results show that our approach outperforms traditional spreadsheets in terms of answer correctness, response time, and perceived mental effort in almost all tasks tested.",Vaishali Dhanoa;Conny Walchshofer;Andreas P. Hinterreiter;Eduard Gröller;Marc Streit,Vaishali Dhanoa;Conny Walchshofer;Andreas Hinterreiter;Eduard Gröller;Marc Streit,"Pro2Future GmbH, Linz, Austria;Johannes Kepler University Linz, Linz, Austria;Johannes Kepler University Linz, Linz, Austria;TU Wien, Vienna, Austria;Johannes Kepler University Linz, Linz, Austria",0.1109/infvis.2004.10;10.1109/tvcg.2021.3114830;10.1109/tvcg.2011.185;10.1109/tvcg.2013.124;10.1109/tvcg.2010.176;10.1109/tvcg.2010.222;10.1109/tvcg.2018.2865077;10.1109/tvcg.2019.2934287;10.1109/tvcg.2013.154;10.1109/tvcg.2007.70518;10.1109/tvcg.2018.2865149;10.1109/tvcg.2009.114;10.1109/tvcg.2010.181;10.1109/tvcg.2012.285,"Uncertainty visualization,tabular data,,spreadsheet augmentation",,0,58,491,,
TVCG,2023,Semi-Automatic Layout Adaptation for Responsive Multiple-View Visualization Design,10.1109/tvcg.2023.3240356,http://dx.doi.org/10.1109/TVCG.2023.3240356,1,15,J,"Multiple-view (MV) visualizations have become ubiquitous for visual communication and exploratory data visualization. However, most existing MV visualizations are designed for the desktop, which can be unsuitable for the continuously evolving displays of varying screen sizes. In this paper, we present a two-stage adaptation framework that supports the automated retargeting and semi-automated tailoring of a desktop MV visualization for rendering on devices with displays of varying sizes. First, we cast layout retargeting as an optimization problem and propose a simulated annealing technique that can automatically preserve the layout of multiple views. Second, we enable fine-tuning for the visual appearance of each view, using a rule-based auto configuration method complemented with an interactive interface for chart-oriented encoding adjustment. To demonstrate the feasibility and expressivity of our proposed approach, we present a gallery of MV visualizations that have been adapted from the desktop to small displays. We also report the result of a user study comparing visualizations generated using our approach with those by existing methods. The outcome indicates that the participants generally prefer visualizations generated using our approach and find them to be easier to use.",Wei Zeng;Xi Chen;Yihan Hou;Lingdan Shao;Zhe Chu;Remco Chang,Wei Zeng;Xi Chen;Yihan Hou;Lingdan Shao;Zhe Chu;Remco Chang,"Hong Kong University of Science and Technology (Guangzhou) and the Hong Kong University of Science and Technology, China;Shenzhen Institute of Advanced Technology, Chinese Academy of Sciences, China;Hong Kong University of Science and Technology (Guangzhou) and the Hong Kong University of Science and Technology, China;Shenzhen Institute of Advanced Technology, Chinese Academy of Sciences, China;Shenzhen Institute of Advanced Technology, Chinese Academy of Sciences, China;Tufts University, USA",,"Layout adaptation,mobile devices,,multiple-view visualization,responsive design",,2,0,359,,
TVCG,2023,Are Metrics Enough? Guidelines for Communicating and Visualizing Predictive Models to Subject Matter Experts,10.1109/tvcg.2023.3259341,http://dx.doi.org/10.1109/TVCG.2023.3259341,1,16,J,"Presenting a predictive model's performance is a communication bottleneck that threatens collaborations between data scientists and subject matter experts. Accuracy and error metrics alone fail to tell the whole story of a model – its risks, strengths, and limitations – making it difficult for subject matter experts to feel confident in their decision to use a model. As a result, models may fail in unexpected ways or go entirely unused, as subject matter experts disregard poorly presented models in favor of familiar, yet arguably substandard methods. In this paper, we describe an iterative study conducted with both subject matter experts and data scientists to understand the gaps in communication between these two groups. We find that, while the two groups share common goals of understanding the data and predictions of the model, friction can stem from unfamiliar terms, metrics, and visualizations – limiting the transfer of knowledge to SMEs and discouraging clarifying questions being asked during presentations. Based on our findings, we derive a set of communication guidelines that use visualization as a common medium for communicating the strengths and weaknesses of a model. We provide a demonstration of our guidelines in a regression modeling scenario and elicit feedback on their use from subject matter experts. From our demonstration, subject matter experts were more comfortable discussing a model's performance, more aware of the trade-offs for the presented model, and better equipped to assess the model's risks – ultimately informing and contextualizing the model's use beyond text and numbers.",Ashley Suh;Gabriel Appleby;Erik W. Anderson;Luca Finelli;Remco Chang;Dylan Cashman,Ashley Suh;Gabriel Appleby;Erik W. Anderson;Luca Finelli;Remco Chang;Dylan Cashman,"Tufts University, Medford, USA;Tufts University, Medford, USA;Novartis Pharmaceuticals Corporation, Data Science and AI, Switzerland;Novartis Pharmaceuticals Corporation, Data Science and AI, Switzerland;Tufts University, Medford, USA;Novartis Pharmaceuticals Corporation, Data Science and AI, Switzerland",,"Visualization techniques and methodologies,Human factors,,Modeling and prediction,Data communications aspects",,1,0,221,,
TVCG,2023,PanVA: Pangenomic Variant Analysis,10.1109/tvcg.2023.3282364,http://dx.doi.org/10.1109/TVCG.2023.3282364,1,15,J,"Genomics researchers increasingly use multiple reference genomes to comprehensively explore genetic variants underlying differences in detectable characteristics between organisms. Pangenomes allow for an efficient data representation of multiple related genomes and their associated metadata. However, current visual analysis approaches for exploring these complex genotype-phenotype relationships are often based on single reference approaches or lack adequate support for interpreting the variants in the genomic context with heterogeneous (meta)data. This design study introduces PanVA, a visual analytics design for pangenomic variant analysis developed with the active participation of genomics researchers. The design uniquely combines tailored visual representations with interactions such as sorting, grouping, and aggregation, allowing users to navigate and explore different perspectives on complex genotype-phenotype relations. Through evaluation in the context of plants and pathogen research, we show that PanVA helps researchers explore variants in genes and generate hypotheses about their role in phenotypic variation.",Astrid van den Brandt;Eef M. Jonkheer;Dirk-Jan M. van Workum;Huub van de Wetering;Sandra Smit;Anna Vilanova,Astrid van den Brandt;Eef M. Jonkheer;Dirk-Jan M. van Workum;Huub van de Wetering;Sandra Smit;Anna Vilanova,"Department of Mathematics and Computer Science, Eindhoven University of Technology, Eindhoven, The Netherlands;Bioinformatics Group, Wageningen University & Research, Wageningen, The Netherlands;Bioinformatics Group, Wageningen University & Research, Wageningen, The Netherlands;Department of Mathematics and Computer Science, Eindhoven University of Technology, Eindhoven, The Netherlands;Bioinformatics Group, Wageningen University & Research, Wageningen, The Netherlands;Department of Mathematics and Computer Science, Eindhoven University of Technology, Eindhoven, The Netherlands",,"Visual analytics,design study,,pangenomics,comparative genomics,variant analysis",,1,0,153,,
TVCG,2023,FS/DS: A Theoretical Framework for the Dual Analysis of Feature Space and Data Space,10.1109/tvcg.2023.3288356,http://dx.doi.org/10.1109/TVCG.2023.3288356,1,17,J,"With the surge of data-driven analysis techniques, there is a rising demand for enhancing the exploration of large high-dimensional data by enabling interactions for the joint analysis of features (i.e., dimensions). Such a dual analysis of the feature space and data space is characterized by three components, (1) a view visualizing feature summaries, (2) a view that visualizes the data records, and (3) a bidirectional linking of both plots triggered by human interaction in one of both visualizations, e.g., Linking & Brushing. Dual analysis approaches span many domains, e.g., medicine, crime analysis, and biology. The proposed solutions encapsulate various techniques, such as feature selection or statistical analysis. However, each approach establishes a new definition of dual analysis. To address this gap, we systematically reviewed published dual analysis methods to investigate and formalize the key elements, such as the techniques used to visualize the feature space and data space, as well as the interaction between both spaces. From the information elicited during our review, we propose a unified theoretical framework for dual analysis, encompassing all existing approaches extending the field. We apply our proposed formalization describing the interactions between each component and relate them to the addressed tasks. Additionally, we categorize the existing approaches using our framework and derive future research directions to advance dual analysis by including state-of-the-art visual analysis techniques to improve data exploration.",Frederik L. Dennig;Matthias Miller;Daniel A. Keim;Mennatallah El-Assady,Frederik L. Dennig;Matthias Miller;Daniel A. Keim;Mennatallah El-Assady,"University of Konstanz, Germany;AI Center, ETH Zu¨ rich, Switzerland;University of Konstanz, Germany;University of Konstanz, Germany",,"Visual analytics,dual analysis,,feature space,data space,feature exploration,mixed data,high-dimensional data",,0,0,208,,
TVCG,2022,AI4VIS: Survey on Artificial Intelligence Approaches for Data Visualization,10.1109/tvcg.2021.3099002,http://dx.doi.org/10.1109/TVCG.2021.3099002,5049,5070,J,"Visualizations themselves have become a data format. Akin to other data formats such as text and images, visualizations are increasingly created, stored, shared, and (re-)used with artificial intelligence (AI) techniques. In this survey, we probe the underlying vision of formalizing visualizations as an emerging data format and review the recent advance in applying AI techniques to visualization data (AI4VIS). We define visualization data as the digital representations of visualizations in computers and focus on data visualization (e.g., charts and infographics). We build our survey upon a corpus spanning ten different fields in computer science with an eye toward identifying important common interests. Our resulting taxonomy is organized around WHAT is visualization data and its representation, WHY and HOW to apply AI to visualization data. We highlight a set of common tasks that researchers apply to the visualization data and present a detailed discussion of AI approaches developed to accomplish those tasks. Drawing upon our literature review, we discuss several important research questions surrounding the management and exploitation of visualization data, as well as the role of AI in support of those processes. We make the list of surveyed papers and related material available online at.",Aoyu Wu;Yun Wang 0012;Xinhuan Shu;Dominik Moritz;Weiwei Cui;Haidong Zhang;Dongmei Zhang 0001;Huamin Qu,Aoyu Wu;Yun Wang;Xinhuan Shu;Dominik Moritz;Weiwei Cui;Haidong Zhang;Dongmei Zhang;Huamin Qu,"Hong Kong University of Science and Technology, Hong Kong;Microsoft Research Asia, Beijing, China;Hong Kong University of Science and Technology, Hong Kong;Carnegie Mellon University, Pittsburgh, PA, USA;Microsoft Research Asia, Beijing, China;Microsoft Research Asia, Beijing, China;Microsoft Research Asia, Beijing, China;Hong Kong University of Science and Technology, Hong Kong",0.1109/tvcg.2020.2984708;10.1109/tvcg.2016.2599030;10.1109/tvcg.2019.2963651;10.1109/tvcg.2011.185;10.1109/tvcg.2018.2865232;10.1109/tvcg.2012.110;10.1109/tvcg.2020.3030403;10.1109/tvcg.2020.3030387;10.1109/tvcg.2020.3030343;10.1109/tvcg.2020.3030360;10.1109/tvcg.2020.3030338;10.1109/tvcg.2018.2865240;10.1109/tvcg.2020.3030351;10.1109/tvcg.2020.3018724;10.1109/tvcg.2013.234;10.1109/tvcg.2007.70594;10.1109/tvcg.2020.3030378;10.1109/tvcg.2019.2934668;10.1109/tvcg.2012.128;10.1109/tvcg.2018.2865138;10.1109/tvcg.2020.3030423;10.1109/tvcg.2020.3030448;10.1109/tvcg.2019.2934284;10.1109/tvcg.2016.2598876;10.1109/tvcg.2012.229;10.1109/tvcg.2019.2934785;10.1109/tvcg.2017.2744320;10.1109/tvcg.2018.2864526;10.1109/tvcg.2015.2467191;10.1109/tvcg.2018.2875702;10.1109/tvcg.2018.2865145;10.1109/tvcg.2019.2934398,"Survey,data visualization,,artificial intelligence,data format,machine learning",,57,147,4167,,
TVCG,2022,Survey on Visual Analysis of Event Sequence Data,10.1109/tvcg.2021.3100413,http://dx.doi.org/10.1109/TVCG.2021.3100413,5091,5112,J,"Event sequence data record series of discrete events in the time order of occurrence. They are commonly observed in a variety of applications ranging from electronic health records to network logs, with the characteristics of large-scale, high-dimensional and heterogeneous. This high complexity of event sequence data makes it difficult for analysts to manually explore and find patterns, resulting in ever-increasing needs for computational and perceptual aids from visual analytics techniques to extract and communicate insights from event sequence datasets. In this paper, we review the state-of-the-art visual analytics approaches, characterize them with our proposed design space, and categorize them based on analytical tasks and applications. From our review of relevant literature, we have also identified several remaining research challenges and future research opportunities.",Yi Guo;Shunan Guo;Zhuochen Jin;Smiti Kaul;David Gotz;Nan Cao 0001,Yi Guo;Shunan Guo;Zhuochen Jin;Smiti Kaul;David Gotz;Nan Cao,"Intelligent Big Data Visualization Lab, Tongji University, Shanghai, China;Intelligent Big Data Visualization Lab, Tongji University, Shanghai, China;Intelligent Big Data Visualization Lab, Tongji University, Shanghai, China;Visual Analysis and Communication Lab, University of North Carolina at Chapel Hill, Chapel Hill, NC, USA;Visual Analysis and Communication Lab, University of North Carolina at Chapel Hill, Chapel Hill, NC, USA;Intelligent Big Data Visualization Lab, Tongji University, Shanghai, China",0.1109/tvcg.2018.2864885;10.1109/tvcg.2014.2346682;10.1109/vast.2006.261421;10.1109/vast.2016.7883512;10.1109/tvcg.2016.2539960;10.1109/tvcg.2014.2346454;10.1109/tvcg.2007.70528;10.1109/tvcg.2020.2985689;10.1109/tvcg.2015.2467622;10.1109/tvcg.2017.2745320;10.1109/mcg.2015.73;10.1109/tvcg.2011.188;10.1109/tvcg.2015.2467196;10.1109/tvcg.2012.291;10.1109/tvcg.2020.3030465;10.1109/tvcg.2017.2745278;10.1109/tvcg.2020.3028957;10.1109/tvcg.2018.2865026;10.1109/tvcg.2014.2346920;10.1109/vast.2017.8585721;10.1109/tvcg.2019.2934609;10.1109/tvcg.2016.2598664;10.1109/tvcg.2009.116;10.1109/tvcg.2018.2865076;10.1109/tvcg.2014.2346922;10.1109/tvcg.2014.2350494;10.1109/tvcg.2018.2865027;10.1109/tvcg.2018.2864886;10.1109/tvcg.2016.2598797;10.1109/tvcg.2016.2614803;10.1109/infvis.2004.5;10.1109/tvcg.2015.2467591;10.1109/tvcg.2017.2744158;10.1109/tvcg.2009.117;10.1109/tvcg.2015.2505305;10.1109/tvcg.2019.2934263;10.1109/tvcg.2017.2745083;10.1109/vast.2012.6400494;10.1109/tvcg.2020.3030358;10.1109/vast.2017.8585647;10.1109/tvcg.2015.2467931;10.1109/tvcg.2009.187;10.1109/tvcg.2012.225;10.1109/vast.2009.5332595;10.1109/vast.2015.7347682,"Visual analysis,event sequences,,visualization",,43,141,2621,,
TVCG,2022,A Survey on ML4VIS: Applying Machine Learning Advances to Data Visualization,10.1109/tvcg.2021.3106142,http://dx.doi.org/10.1109/TVCG.2021.3106142,5134,5153,J,"Inspired by the great success of machine learning (ML), researchers have applied ML techniques to visualizations to achieve a better design, development, and evaluation of visualizations. This branch of studies, known as ML4VIS, is gaining increasing research attention in recent years. To successfully adapt ML techniques for visualizations, a structured understanding of the integration of ML4VIS is needed. In this article, we systematically survey 88 ML4VIS studies, aiming to answer two motivating questions: “what visualization processes can be assisted by ML?” and “how ML techniques can be used to solve visualization problems? ”This survey reveals seven main processes where the employment of ML techniques can benefit visualizations: Data Processing4VIS, Data-VIS Mapping, Insight Communication, Style Imitation, VIS Interaction, VIS Reading, and User Profiling. The seven processes are related to existing visualization theoretical models in an ML4VIS pipeline, aiming to illuminate the role of ML-assisted visualization in general visualizations. Meanwhile, the seven processes are mapped into main learning tasks in ML to align the capabilities of ML with the needs in visualization. Current practices and future opportunities of ML4VIS are discussed in the context of the ML4VIS pipeline and the ML-VIS mapping. While more studies are still needed in the area of ML4VIS, we hope this article can provide a stepping-stone for future exploration. A web-based interactive browser of this survey is available at https://ml4vis.github.io.",Qianwen Wang;Zhutian Chen;Yong Wang 0021;Huamin Qu,Qianwen Wang;Chen Zhu-Tian;Yong Wang;Huamin Qu,"Harvard University, Cambridge, MA, USA;University of California San Diego, La Jolla, CA, USA;Singapore Management University, Singapore, Singapore;Hong Kong University of Science and Technology, Hong Kong",0.1109/tvcg.2018.2865138;10.1109/tvcg.2018.2816059;10.1109/tvcg.2018.2865240;10.1109/tvcg.2017.2701829;10.1109/tvcg.2017.2734659;10.1109/tvcg.2019.2934785;10.1109/tvcg.2019.2934398;10.1109/tvcg.2018.2875702;10.1109/tvcg.2019.2934433;10.1109/tvcg.2014.2346575;10.1109/tvcg.2019.2934396;10.1109/mcg.2018.2881501;10.1109/tvcg.2019.2934668;10.1109/tvcg.2010.179;10.1109/tvcg.2013.234;10.1109/tvcg.2020.3030351;10.1109/tvcg.2020.3030343;10.1109/mcg.2018.2881502;10.1109/tvcg.2020.3030448;10.1109/tvcg.2020.3030374;10.1109/tvcg.2020.3030423;10.1109/tvcg.2020.3030467;10.1109/tvcg.2020.3030387;10.1109/tvcg.2019.2934284;10.1109/tvcg.2018.2864838;10.1109/tvcg.2018.2864769;10.1109/tvcg.2014.2346481;10.1109/tvcg.2016.2598495;10.1109/tvcg.2009.111;10.1109/tvcg.2018.2834341;10.1109/tvcg.2017.2744320;10.1109/tvcg.2017.2743858;10.1109/tvcg.2021.3100413;10.1109/tvcg.2019.2934283,"ML4VIS,machine learning,,data visualization,survey",,42,149,1987,,
TVCG,2023,RagRug: A Toolkit for Situated Analytics,10.1109/tvcg.2022.3157058,http://dx.doi.org/10.1109/TVCG.2022.3157058,3281,3297,J,"We present RagRug, an open-source toolkit for situated analytics. The abilities of RagRug go beyond previous immersive analytics toolkits by focusing on specific requirements emerging when using augmented reality (AR) rather than virtual reality. RagRug combines state of the art visual encoding capabilities with a comprehensive physical-virtual model, which lets application developers systematically describe the physical objects in the real world and their role in AR. We connect AR visualizations with data streams from the Internet of Things using distributed dataflow. To this end, we use reactive programming patterns so that visualizations become context-aware, i.e., they adapt to events coming in from the environment. The resulting authoring system is low-code; it emphasises describing the physical and the virtual world and the dataflow between the elements contained therein. We describe the technical design and implementation of RagRug, and report on five example applications illustrating the toolkit’s abilities.",Philipp Fleck;Aimée Sousa Calepso;Sebastian Hubenschmid;Michael Sedlmair;Dieter Schmalstieg,Philipp Fleck;Aimée Sousa Calepso;Sebastian Hubenschmid;Michael Sedlmair;Dieter Schmalstieg,"Institute of Computer Graphics and Vision, Graz University of Technology, Graz, Austria;University of Stuttgart, Stuttgart, Germany;University of Konstanz, Konstanz, Germany;University of Stuttgart, Stuttgart, Germany;Institute of Computer Graphics and Vision, Graz University of Technology, Graz, Austria",0.1109/vast.2012.6400559;10.1109/vast.2016.7883506;10.1109/tvcg.2009.174;10.1109/tvcg.2011.185;10.1109/tvcg.2020.2965109;10.1109/tvcg.2019.2892415;10.1109/infvis.2004.64;10.1109/tvcg.2013.134;10.1109/tvcg.2020.3030450;10.1109/tvcg.2012.204;10.1109/tvcg.2020.3030460;10.1109/tvcg.2015.2467091;10.1109/tvcg.2018.2865152;10.1109/tvcg.2016.2598608;10.1109/tvcg.2007.70515;10.1109/tvcg.2006.184,"Augmented reality,immersive analytics,,situated analytics,visual analytics,visualization",,28,79,1373,,
TVCG,2022,A Unified Understanding of Deep NLP Models for Text Classification,10.1109/tvcg.2022.3184186,http://dx.doi.org/10.1109/TVCG.2022.3184186,4980,4994,J,"The rapid development of deep natural language processing (NLP) models for text classification has led to an urgent need for a unified understanding of these models proposed individually. Existing methods cannot meet the need for understanding different models in one framework due to the lack of a unified measure for explaining both low-level (e.g., words) and high-level (e.g., phrases) features. We have developed a visual analysis tool, DeepNLPVis, to enable a unified understanding of NLP models for text classification. The key idea is a mutual information-based measure, which provides quantitative explanations on how each layer of a model maintains the information of input words in a sample. We model the intra- and inter-word information at each layer measuring the importance of a word to the final prediction as well as the relationships between words, such as the formation of phrases. A multi-level visualization, which consists of a corpus-level, a sample-level, and a word-level visualization, supports the analysis from the overall training set to individual samples. Two case studies on classification tasks and comparison between models demonstrate that DeepNLPVis can help users effectively identify potential problems caused by samples and model architectures and then make informed improvements.",Zhen Li 0044;Xiting Wang;Weikai Yang;Jing Wu 0004;Zhengyan Zhang;Zhiyuan Liu 0001;Maosong Sun 0001;Hui Zhang 0013;Shixia Liu,Zhen Li;Xiting Wang;Weikai Yang;Jing Wu;Zhengyan Zhang;Zhiyuan Liu;Maosong Sun;Hui Zhang;Shixia Liu,"School of Software, BNRist, Tsinghua University, Beijing, China;Microsoft Research Asia, Beijing, China;School of Software, BNRist, Tsinghua University, Beijing, China;Cardiff University, Cardiff, U.K.;Department of Computer Science and Technology, BNRist, Tsinghua University, Beijing, China;Department of Computer Science and Technology, BNRist, Tsinghua University, Beijing, China;Department of Computer Science and Technology, BNRist, Tsinghua University, Beijing, China;School of Software, BNRist, Tsinghua University, Beijing, China;School of Software, BNRist, Tsinghua University, Beijing, China",0.1109/tvcg.2017.2744158;10.1109/vast.2017.8585721;10.1109/tvcg.2020.3028976;10.1109/tvcg.2016.2598828;10.1109/tvcg.2018.2864499;10.1109/tvcg.2017.2744938;10.1109/tvcg.2018.2865230;10.1109/tvcg.2018.2843369;10.1109/mcg.2018.2878902;10.1109/tvcg.2018.2865044;10.1109/tvcg.2018.2865027;10.1109/tvcg.2012.212;10.1109/tvcg.2013.196;10.1109/vast.2010.5652931;10.1109/tvcg.2011.239,"Explainable AI,visual debugging,,visual analytics,deep NLP model,information-based interpretation",,22,50,2054,,X
TVCG,2022,A Survey of Perception-Based Visualization Studies by Task,10.1109/tvcg.2021.3098240,http://dx.doi.org/10.1109/TVCG.2021.3098240,5026,5048,J,"Knowledge of human perception has long been incorporated into visualizations to enhance their quality and effectiveness. The last decade, in particular, has shown an increase in perception-based visualization research studies. With all of this recent progress, the visualization community lacks a comprehensive guide to contextualize their results. In this report, we provide a systematic and comprehensive review of research studies on perception related to visualization. This survey reviews perception-focused visualization studies since 1980 and summarizes their research developments focusing on low-level tasks, further breaking techniques down by visual encoding and visualization type. In particular, we focus on how perception is used to evaluate the effectiveness of visualizations, to help readers understand and apply the principles of perception of their visualization designs through a task-optimized approach. We concluded our report with a summary of the weaknesses and open research questions in the area.",Ghulam Jilani Quadri;Paul Rosen 0001,Ghulam Jilani Quadri;Paul Rosen,"Department of Computer Science and Engineering, University of South Florida, Tampa, FL, USA;Department of Computer Science and Engineering, University of South Florida, Tampa, FL, USA",0.1109/tvcg.2015.2467471;10.1109/tvcg.2014.2346983;10.1109/tvcg.2014.2346978;10.1109/tvcg.2013.124;10.1109/tvcg.2014.2346979;10.1109/tvcg.2014.2346320;10.1109/tvcg.2018.2810918;10.1109/vast.2010.5652443;10.1109/tvcg.2019.2934397;10.1109/tvcg.2020.3030365;10.1109/tvcg.2016.2598839;10.1109/tvcg.2015.2467191;10.1109/tvcg.2017.2723397;10.1109/tvcg.2006.184;10.1109/tvcg.2017.2746018;10.1109/tvcg.2012.264;10.1109/tvcg.2016.2642109;10.1109/tvcg.2016.2598862;10.1109/tvcg.2019.2934556;10.1109/tvcg.2012.315;10.1109/vast.2012.6400540;10.1109/tvcg.2016.2598594;10.1109/tvcg.2015.2467591;10.1109/tvcg.2012.233;10.1109/tvcg.2018.2864914;10.1109/tvcg.2015.2467759;10.1109/tvcg.2017.2744359;10.1109/tvcg.2017.2745138;10.1109/tvcg.2019.2934801;10.1109/tvcg.2019.2934284;10.1109/tvcg.2018.2864884;10.1109/infvis.2004.1;10.1109/tvcg.2019.2934786;10.1109/tvcg.2010.162;10.1109/tvcg.2018.2865077;10.1109/tvcg.2019.2934400;10.1109/tvcg.2013.183;10.1109/tvcg.2015.2424872;10.1109/tvcg.2018.2875702;10.1109/tvcg.2017.2744184;10.1109/tvcg.2015.2467872;10.1109/tvcg.2017.2653106;10.1109/tvcg.2013.20;10.1109/tvcg.2017.2744138;10.1109/tvcg.2017.2744339;10.1109/tvcg.2014.2346572;10.1109/tvcg.2018.2864912;10.1109/tvcg.2008.155;10.1109/tvcg.2017.2744685;10.1109/tvcg.2017.2680452;10.1109/tvcg.2018.2864907;10.1109/tvcg.2018.2829750;10.1109/tvcg.2017.2661309;10.1109/tvcg.2015.2467671,"Visualization,perception,,graphical perception,visual analytics tasks,evaluation,survey",,20,166,1659,,
TVCG,2023,Labeling Out-of-View Objects in Immersive Analytics to Support Situated Visual Searching,10.1109/tvcg.2021.3133511,http://dx.doi.org/10.1109/TVCG.2021.3133511,1831,1844,J,"Augmented Reality (AR) embeds digital information into objects of the physical world. Data can be shown in-situ, thereby enabling real-time visual comparisons and object search in real-life user tasks, such as comparing products and looking up scores in a sports game. While there have been studies on designing AR interfaces for situated information retrieval, there has only been limited research on AR object labeling for visual search tasks in the spatial environment. In this article, we identify and categorize different design aspects in AR label design and report on a formal user study on labels for out-of-view objects to support visual search tasks in AR. We design three visualization techniques for out-of-view object labeling in AR, which respectively encode the relative physical position (height-encoded), the rotational direction (angle-encoded), and the label values (value-encoded) of the objects. We further implement two traditional in-view object labeling techniques, where labels are placed either next to the respective objects (situated) or at the edge of the AR FoV (boundary). We evaluate these five different label conditions in three visual search tasks for static objects. Our study shows that out-of-view object labels are beneficial when searching for objects outside the FoV, spatial orientation, and when comparing multiple spatially sparse objects. Angle-encoded labels with directional cues of the surrounding objects have the overall best performance with the highest user satisfaction. We discuss the implications of our findings for future immersive AR interface design.",Tica Lin;Yalong Yang 0001;Johanna Beyer;Hanspeter Pfister,Tica Lin;Yalong Yang;Johanna Beyer;Hanspeter Pfister,"John A. Paulson School of Engineering and Applied Sciences, Harvard University, Cambridge, MA, USA;Department of Computer Science, Virginia Tech, Blacksburg, VA, USA;John A. Paulson School of Engineering and Applied Sciences, Harvard University, Cambridge, MA, USA;John A. Paulson School of Engineering and Applied Sciences, Harvard University, Cambridge, MA, USA",0.1109/tvcg.2016.2598608;10.1109/tvcg.2019.2934555;10.1109/tvcg.2013.124;10.1109/tvcg.2008.109;10.1109/tvcg.2020.3030427;10.1109/tvcg.2017.2785807;10.1109/tvcg.2007.70539,"Object labeling,mixed / augmented reality,,immersive analytics,situated analytics,data visualization",,18,71,843,,
TVCG,2023,EpiMob: Interactive Visual Analytics of Citywide Human Mobility Restrictions for Epidemic Control,10.1109/tvcg.2022.3165385,http://dx.doi.org/10.1109/TVCG.2022.3165385,3586,3601,J,"The outbreak of coronavirus disease (COVID-19) has swept across more than 180 countries and territories since late January 2020. As a worldwide emergency response, governments have implemented various measures and policies, such as self-quarantine, travel restrictions, work from home, and regional lockdown, to control the spread of the epidemic. These countermeasures seek to restrict human mobility because COVID-19 is a highly contagious disease that is spread by human-to-human transmission. Medical experts and policymakers have expressed the urgency to effectively evaluate the outcome of human restriction policies with the aid of big data and information technology. Thus, based on big human mobility data and city POI data, an interactive visual analytics system called Epidemic Mobility (EpiMob) was designed in this study. The system interactively simulates the changes in human mobility and infection status in response to the implementation of a certain restriction policy or a combination of policies (e.g., regional lockdown, telecommuting, screening). Users can conveniently designate the spatial and temporal ranges for different mobility restriction policies. Then, the results reflecting the infection situation under different policies are dynamically displayed and can be flexibly compared and analyzed in depth. Multiple case studies consisting of interviews with domain experts were conducted in the largest metropolitan area of Japan (i.e., Greater Tokyo Area) to demonstrate that the system can provide insight into the effects of different human mobility restriction policies for epidemic control, through measurements and comparisons.",Chuang Yang;Zhiwen Zhang;Zipei Fan;Renhe Jiang;Quanjun Chen;Xuan Song 0001;Ryosuke Shibasaki,Chuang Yang;Zhiwen Zhang;Zipei Fan;Renhe Jiang;Quanjun Chen;Xuan Song;Ryosuke Shibasaki,"Center for Spatial Information Science, University of Tokyo, Bunkyo City, Tokyo, Japan;Center for Spatial Information Science, University of Tokyo, Bunkyo City, Tokyo, Japan;Center for Spatial Information Science, University of Tokyo, Bunkyo City, Tokyo, Japan;Center for Spatial Information Science, University of Tokyo, Bunkyo City, Tokyo, Japan;Center for Spatial Information Science, University of Tokyo, Bunkyo City, Tokyo, Japan;Center for Spatial Information Science, University of Tokyo, Bunkyo City, Tokyo, Japan;Center for Spatial Information Science, University of Tokyo, Bunkyo City, Tokyo, Japan",0.1109/tvcg.2020.3030415;10.1109/vast.2011.6102457;10.1109/tvcg.2020.3030437,"Human mobility simulation,epidemic control,,visual analytics,interactive system,big trajectory data",,15,55,767,,
TVCG,2023,CoordNet: Data Generation and Visualization Generation for Time-Varying Volumes via a Coordinate-Based Neural Network,10.1109/tvcg.2022.3197203,http://dx.doi.org/10.1109/TVCG.2022.3197203,4951,4963,J,"Although deep learning has demonstrated its capability in solving diverse scientific visualization problems, it still lacks generalization power across different tasks. To address this challenge, we propose CoordNet, a single coordinate-based framework that tackles various tasks relevant to time-varying volumetric data visualization without modifying the network architecture. The core idea of our approach is to decompose diverse task inputs and outputs into a unified representation (i.e., coordinates and values) and learn a function from coordinates to their corresponding values. We achieve this goal using a residual block-based implicit neural representation architecture with periodic activation functions. We evaluate CoordNet on data generation (i.e., temporal super-resolution and spatial super-resolution) and visualization generation (i.e., view synthesis and ambient occlusion prediction) tasks using time-varying volumetric data sets of various characteristics. The experimental results indicate that CoordNet achieves better quantitative and qualitative results than the state-of-the-art approaches across all the evaluated tasks. Source code and pre-trained models are available at https://github.com/stevenhan1991/CoordNet.",Jun Han 0010;Chaoli Wang 0001,Jun Han;Chaoli Wang,"School of Data Science, The Chinese University of Hong Kong, Shenzhen, Guangdong, China;Department of Computer Science and Engineering, University of Notre Dame, Notre Dame, IN, USA",0.1109/tvcg.2018.2816059;10.1109/tvcg.2020.3030344;10.1109/tvcg.2019.2934255;10.1109/tvcg.2020.3032123;10.1109/tvcg.2021.3114815;10.1109/tvcg.2020.3030346;10.1109/tvcg.2019.2934312;10.1109/tvcg.2020.3028947;10.1109/tvcg.2019.2934375;10.1109/tvcg.2022.3167896;10.1109/tvcg.2008.140;10.1109/tvcg.2020.3039340,"Volume visualization,implicit neural representation,,data generation,visualization generation",,11,42,872,,
TVCG,2023,VisImages: A Fine-Grained Expert-Annotated Visualization Dataset,10.1109/tvcg.2022.3155440,http://dx.doi.org/10.1109/TVCG.2022.3155440,3298,3311,J,"Images in visualization publications contain rich information, e.g., novel visualization designs and implicit design patterns of visualizations. A systematic collection of these images can contribute to the community in many aspects, such as literature analysis and automated tasks for visualization. In this paper, we build and make public a dataset, VisImages, which collects 12,267 images with captions from 1,397 papers in IEEE InfoVis and VAST. Built upon a comprehensive visualization taxonomy, the dataset includes 35,096 visualizations and their bounding boxes in the images. We demonstrate the usefulness of VisImages through three use cases: 1) investigating the use of visualizations in the publications with VisImages Explorer, 2) training and benchmarking models for visualization classification, and 3) localizing visualizations in the visual analytics systems automatically.",Dazhen Deng;Yihong Wu 0003;Xinhuan Shu;Jiang Wu;Siwei Fu;Weiwei Cui;Yingcai Wu,Dazhen Deng;Yihong Wu;Xinhuan Shu;Jiang Wu;Siwei Fu;Weiwei Cui;Yingcai Wu,"State Key Lab of CAD&CG, Zhejiang University, Hangzhou, China;State Key Lab of CAD&CG, Zhejiang University, Hangzhou, China;Department of Computer Science and Engineering, Hong Kong University of Science and Technology, Hong Kong;State Key Lab of CAD&CG, Zhejiang University, Hangzhou, China;Zhejiang Lab, Hangzhou, Zhejiang, China;Microsoft Research Asia, Beijing, China;State Key Lab of CAD&CG, Zhejiang University, Hangzhou, China",0.1109/tvcg.2020.3030396;10.1109/tvcg.2013.234;10.1109/tvcg.2011.185;10.1109/tvcg.2021.3114863;10.1109/tvcg.2021.3076222;10.1109/tvcg.2016.2615308;10.1109/tvcg.2016.2599030;10.1109/tvcg.2015.2467732;10.1109/tvcg.2018.2865138;10.1109/tvcg.2021.3114877;10.1109/tvcg.2010.175;10.1109/tvcg.2018.2865018;10.1109/tvcg.2010.138;10.1109/tvcg.2010.183;10.1109/tvcg.2013.221;10.1109/tvcg.2016.2598827;10.1109/tvcg.2016.2610422;10.1109/tvcg.2021.3099002;10.1109/tvcg.2020.3030338;10.1109/tvcg.2021.3054916;10.1109/tvcg.2021.3114826;10.1109/tvcg.2021.3114875,"Visualization dataset,crowdsourcing,,literature analysis,visualization classification,visualization detection",,12,64,691,,
TVCG,2023,GNNLens: A Visual Analytics Approach for Prediction Error Diagnosis of Graph Neural Networks,10.1109/tvcg.2022.3148107,http://dx.doi.org/10.1109/TVCG.2022.3148107,3024,3038,J,"Graph Neural Networks (GNNs) aim to extend deep learning techniques to graph data and have achieved significant progress in graph analysis tasks (e.g., node classification) in recent years. However, similar to other deep neural networks like Convolutional Neural Networks (CNNs) and Recurrent Neural Networks (RNNs), GNNs behave like a black box with their details hidden from model developers and users. It is therefore difficult to diagnose possible errors of GNNs. Despite many visual analytics studies being done on CNNs and RNNs, little research has addressed the challenges for GNNs. This paper fills the research gap with an interactive visual analysis tool, GNNLens, to assist model developers and users in understanding and analyzing GNNs. Specifically, Parallel Sets View and Projection View enable users to quickly identify and validate error patterns in the set of wrong predictions; Graph View and Feature Matrix View offer a detailed analysis of individual nodes to assist users in forming hypotheses about the error patterns. Since GNNs jointly model the graph structure and the node features, we reveal the relative influences of the two types of information by comparing the predictions of three models: GNN, Multi-Layer Perceptron (MLP), and GNN Without Using Features (GNNWUF). Two case studies and interviews with domain experts demonstrate the effectiveness of GNNLens in facilitating the understanding of GNN models and their errors.",Zhihua Jin;Yong Wang 0021;Qianwen Wang;Yao Ming;Tengfei Ma 0001;Huamin Qu,Zhihua Jin;Yong Wang;Qianwen Wang;Yao Ming;Tengfei Ma;Huamin Qu,"Hong Kong University of Science and Technology, Hong Kong, China;Singapore Management University, Singapore;Harvard University, Cambridge, MA, USA;Bloomberg LP, New York, NY, USA;IBM T. J. Watson Research Center, Yorktown Heights, NY, USA;Hong Kong University of Science and Technology, Hong Kong, China",0.1109/tvcg.2018.2843369;10.1109/tvcg.2016.2598831;10.1109/vast.2017.8585721;10.1109/tvcg.2018.2864504;10.1109/tvcg.2019.2934798;10.1109/tvcg.2018.2864499;10.1109/tvcg.2014.2346660;10.1109/tvcg.2018.2864812;10.1109/tvcg.2017.2744358;10.1109/tvcg.2017.2744158;10.1109/tvcg.2018.2865044;10.1109/tvcg.2017.2744938;10.1109/tvcg.2018.2864500;10.1109/infvis.2005.1532139;10.1109/tvcg.2016.2598828;10.1109/tvcg.2019.2934619;10.1109/tvcg.2018.2865043;10.1109/tvcg.2017.2744718;10.1109/visual.1990.146402;10.1109/vast.2018.8802454,"Graph neural networks,error diagnosis,,visualization",,11,67,1222,,
TVCG,2022,FeatureEnVi: Visual Analytics for Feature Engineering Using Stepwise Selection and Semi-Automatic Extraction Approaches,10.1109/tvcg.2022.3141040,http://dx.doi.org/10.1109/TVCG.2022.3141040,1773,1791,J,"The machine learning (ML) life cycle involves a series of iterative steps, from the effective gathering and preparation of the data—including complex feature engineering processes—to the presentation and improvement of results, with various algorithms to choose from in every step. Feature engineering in particular can be very beneficial for ML, leading to numerous improvements such as boosting the predictive results, decreasing computational times, reducing excessive noise, and increasing the transparency behind the decisions taken during the training. Despite that, while several visual analytics tools exist to monitor and control the different stages of the ML life cycle (especially those related to data and algorithms), feature engineering support remains inadequate. In this paper, we present FeatureEnVi, a visual analytics system specifically designed to assist with the feature engineering process. Our proposed system helps users to choose the most important feature, to transform the original features into powerful alternatives, and to experiment with different feature generation combinations. Additionally, data space slicing allows users to explore the impact of features on both local and global scales. FeatureEnVi utilizes multiple automatic feature selection techniques; furthermore, it visually guides users with statistical evidence about the influence of each feature (or subsets of features). The final outcome is the extraction of heavily engineered features, evaluated by multiple validation metrics. The usefulness and applicability of FeatureEnVi are demonstrated with two use cases and a case study. We also report feedback from interviews with two ML experts and a visualization researcher who assessed the effectiveness of our system.",Angelos Chatzimparmpas;Rafael Messias Martins;Kostiantyn Kucher;Andreas Kerren,Angelos Chatzimparmpas;Rafael M. Martins;Kostiantyn Kucher;Andreas Kerren,"Department of Computer Science and Media Technology, Linnaeus University, Växjö, Sweden;Department of Computer Science and Media Technology, Linnaeus University, Växjö, Sweden;Department of Computer Science and Media Technology, Linnaeus University, Växjö, Sweden;Department of Computer Science and Media Technology, Linnaeus University, Växjö, Sweden",0.1109/tvcg.2017.2744378;10.1109/vast47406.2019.8986940;10.1109/vast.2011.6102448;10.1109/tvcg.2014.2346482;10.1109/tvcg.2017.2711030;10.1109/tvcg.2013.173;10.1109/vast.2014.7042495;10.1109/tvcg.2009.153;10.1109/tvcg.2011.178;10.1109/tvcg.2012.219;10.1109/vast.2015.7347637;10.1109/tvcg.2008.153;10.1109/infvis.2003.1249006;10.1109/tvcg.2015.2468291;10.1109/vast.2008.4677368;10.1109/tvcg.2018.2865043;10.1109/tvcg.2020.2986996;10.1109/tvcg.2020.3030352;10.1109/tvcg.2014.2346574;10.1109/tvcg.2019.2934267;10.1109/tvcg.2018.2864825;10.1109/tvcg.2019.2934631;10.1109/tvcg.2013.125,"Feature selection,feature extraction,,feature engineering,machine learning,visual analytics,visualization",,13,112,1066,,X
TVCG,2023,DXplorer: A Unified Visualization Framework for Interactive Dendritic Spine Analysis Using 3D Morphological Features,10.1109/tvcg.2021.3116656,http://dx.doi.org/10.1109/TVCG.2021.3116656,1424,1437,J,"Dendritic spines are dynamic, submicron-scale protrusions on neuronal dendrites that receive neuronal inputs. Morphological changes in the dendritic spine often reflect alterations in physiological conditions and are indicators of various neuropsychiatric conditions. However, owing to the highly dynamic and heterogeneous nature of spines, accurate measurement and objective analysis of spine morphology are major challenges in neuroscience research. Most conventional approaches for analyzing dendritic spines are based on two-dimensional (2D) images, which barely reflect the actual three-dimensional (3D) shapes. Although some recent studies have attempted to analyze spines with various 3D-based features, it is still difficult to objectively categorize and analyze spines based on 3D morphology. Here, we propose a unified visualization framework for an interactive 3D dendritic spine analysis system, DXplorer, that displays 3D rendering of spines and plots the high-dimensional features extracted from the 3D mesh of spines. With this system, users can perform the clustering of spines interactively and explore and analyze dendritic spines based on high-dimensional features. We propose a series of high-dimensional morphological features extracted from a 3D mesh of dendritic spines. In addition, an interactive machine learning classifier with visual exploration and user feedback using an interactive 3D mesh grid view ensures a more precise classification based on the spine phenotype. A user study and two case studies were conducted to quantitatively verify the performance and usability of the DXplorer. We demonstrate that the system performs the entire analytic process effectively and provides high-quality, accurate, and objective analysis.",Junyoung Choi;Sang-Eun Lee;YeIn Lee;Eunji Cho;Sunghoe Chang;Won-Ki Jeong,JunYoung Choi;Sang-Eun Lee;YeIn Lee;Eunji Cho;Sunghoe Chang;Won-Ki Jeong,"Ulsan National Institute of Science and Technology, Ulsan, South Korea;Seoul National University College of Medicine, Seoul, South Korea;Korea University, Seoul, South Korea;Seoul National University College of Medicine, Seoul, South Korea;Seoul National University College of Medicine, Seoul, South Korea;Korea University, Seoul, South Korea",0.1109/tvcg.2019.2934547;10.1109/visual.2003.1250384;10.1109/tvcg.2017.2744199;10.1109/tvcg.2017.2744805,"Biomedical and medical visualization,machine learning,,task and requirements analysis,user interfaces,intelligence analysis",,10,43,668,,
TVCG,2023,Molecumentary: Adaptable Narrated Documentaries Using Molecular Visualization,10.1109/tvcg.2021.3130670,http://dx.doi.org/10.1109/TVCG.2021.3130670,1733,1747,J,"We present a method for producing documentary-style content using real-time scientific visualization. We introduce molecumentaries, i.e., molecular documentaries featuring structural models from molecular biology, created through adaptable methods instead of the rigid traditional production pipeline. Our work is motivated by the rapid evolution of scientific visualization and it potential in science dissemination. Without some form of explanation or guidance, however, novices and lay-persons often find it difficult to gain insights from the visualization itself. We integrate such knowledge using the verbal channel and provide it along an engaging visual presentation. To realize the synthesis of a molecumentary, we provide technical solutions along two major production steps: (1) preparing a story structure and (2) turning the story into a concrete narrative. In the first step, we compile information about the model from heterogeneous sources into a story graph. We combine local knowledge with external sources to complete the story graph and enrich the final result. In the second step, we synthesize a narrative, i.e., story elements presented in sequence, using the story graph. We then traverse the story graph and generate a virtual tour, using automated camera and visualization transitions. We turn texts written by domain experts into verbal representations using text-to-speech functionality and provide them as a commentary. Using the described framework, we synthesize fly-throughs with descriptions: automatic ones that mimic a manually authored documentary or semi-automatic ones which guide the documentary narrative solely through curated textual input.",David Kouril;Ondrej Strnad;Peter Mindek;Sarkis Halladjian;Tobias Isenberg 0001;M. Eduard Gröller;Ivan Viola,David Kouřil;Ondřej Strnad;Peter Mindek;Sarkis Halladjian;Tobias Isenberg;M. Eduard Gröller;Ivan Viola,"Masaryk University, Brno, Czech Republic;King Abdullah University of Science and Technology (KAUST), Thuwal, Saudi Arabia;TU Wien and Nanographics GmbH, Vienna, Austria;CNRS, Inria, LISN, Université Paris-Saclay, Gif-sur-Yvette, France;CNRS, Inria, LISN, Université Paris-Saclay, Gif-sur-Yvette, France;TU Wien and the VRVis Research Center, Wien, Austria;King Abdullah University of Science and Technology (KAUST), Thuwal, Saudi Arabia",0.1109/tvcg.2019.2934259;10.1109/tvcg.2016.2598468;10.1109/mcg.2020.2973120;10.1109/tvcg.2011.255;10.1109/tvcg.2020.2975583;10.1109/visual.1993.398878;10.1109/tvcg.2012.244;10.1109/tvcg.2017.2744518;10.1109/tvcg.2020.3030415;10.1109/tvcg.2010.179;10.1109/infvis.2003.1249004,"Virtual tour,audio,,biological data,storytelling,illustrative visualization",,10,70,1419,,
TVCG,2022,Diagnosing Ensemble Few-Shot Classifiers,10.1109/tvcg.2022.3182488,http://dx.doi.org/10.1109/TVCG.2022.3182488,3292,3306,J,"The base learners and labeled samples (shots) in an ensemble few-shot classifier greatly affect the model performance. When the performance is not satisfactory, it is usually difficult to understand the underlying causes and make improvements. To tackle this issue, we propose a visual analysis method, FSLDiagnotor. Given a set of base learners and a collection of samples with a few shots, we consider two problems: 1) finding a subset of base learners that well predict the sample collections; and 2) replacing the low-quality shots with more representative ones to adequately represent the sample collections. We formulate both problems as sparse subset selection and develop two selection algorithms to recommend appropriate learners and shots, respectively. A matrix visualization and a scatterplot are combined to explain the recommended learners and shots in context and facilitate users in adjusting them. Based on the adjustment, the algorithm updates the recommendation results for another round of improvement. Two case studies are conducted to demonstrate that FSLDiagnotor helps build a few-shot classifier efficiently and increases the accuracy by 12% and 21%, respectively.",Weikai Yang;Xi Ye;Xingxing Zhang;Lanxi Xiao;Jiazhi Xia;Zhongyuan Wang 0006;Jun Zhu 0001;Hanspeter Pfister;Shixia Liu,Weikai Yang;Xi Ye;Xingxing Zhang;Lanxi Xiao;Jiazhi Xia;Zhongyuan Wang;Jun Zhu;Hanspeter Pfister;Shixia Liu,"School of Software, BNRist, Tsinghua University, Beijing, China;University of Texas at Austin, Austin, TX, USA;Department of Computer Science and Technology, BNRist, Tsinghua University, Beijing, China;Academy of Arts & Design, Tsinghua University, Beijing, China;Central South University, Changsha, Hunan, China;Kuaishou Technology Company Ltd., Beijing, China;Department of Computer Science and Technology, BNRist, Tsinghua University, Beijing, China;Harvard University, Cambridge, MA, USA;School of Software, BNRist, Tsinghua University, Beijing, China",0.1109/tvcg.2018.2864843;10.1109/tvcg.2018.2843369;10.1109/tvcg.2016.2598831;10.1109/tvcg.2017.2744683;10.1109/tvcg.2017.2744718;10.1109/tvcg.2017.2744938;10.1109/tvcg.2018.2864504;10.1109/vast.2017.8585721;10.1109/tvcg.2018.2865044;10.1109/tvcg.2017.2744378;10.1109/tvcg.2018.2864475;10.1109/tvcg.2020.3030354;10.1109/tvcg.2020.2973258;10.1109/vast50239.2020.00007;10.1109/tvcg.2019.2934267;10.1109/tvcg.2020.3030350;10.1109/tvcg.2012.277;10.1109/vast.2014.7042480;10.1109/vast.2012.6400492;10.1109/tvcg.2014.2331979;10.1109/vast47406.2019.8986943;10.1109/tvcg.2021.3114793;10.1109/tvcg.2012.208;10.1109/tvcg.2013.65;10.1109/tvcg.2020.3030432;10.1109/infvis.2004.60;10.1109/tvcg.2007.70515,"Few-shot learning,ensemble model,,subset selection,matrix visualization,scatterplot",,12,64,1034,,X
TVCG,2023,"When, Where and How Does it Fail? A Spatial-Temporal Visual Analytics Approach for Interpretable Object Detection in Autonomous Driving",10.1109/tvcg.2022.3201101,http://dx.doi.org/10.1109/TVCG.2022.3201101,5033,5049,J,"Arguably the most representative application of artificial intelligence, autonomous driving systems usually rely on computer vision techniques to detect the situations of the external environment. Object detection underpins the ability of scene understanding in such systems. However, existing object detection algorithms often behave as a black box, so when a model fails, no information is available on When, Where and How the failure happened. In this paper, we propose a visual analytics approach to help model developers interpret the model failures. The system includes the micro- and macro-interpreting modules to address the interpretability problem of object detection in autonomous driving. The micro-interpreting module extracts and visualizes the features of a convolutional neural network (CNN) algorithm with density maps, while the macro-interpreting module provides spatial-temporal information of an autonomous driving vehicle and its environment. With the situation awareness of the spatial, temporal and neural network information, our system facilitates the understanding of the results of object detection algorithms, and helps the model developers better understand, tune and develop the models. We use real-world autonomous driving data to perform case studies by involving domain experts in computer vision and autonomous driving to evaluate our system. The results from our interviews with them show the effectiveness of our approach.",Junhong Wang;Yun Li;Zhaoyu Zhou;Chengshun Wang;Yijie Hou;Li Zhang 0040;Xiangyang Xue;Michael Kamp;Xiaolong Luke Zhang;Siming Chen 0001,Junhong Wang;Yun Li;Zhaoyu Zhou;Chengshun Wang;Yijie Hou;Li Zhang;Xiangyang Xue;Michael Kamp;Xiaolong Luke Zhang;Siming Chen,"School of Data Science, Fudan University, Shanghai, China;School of Data Science, Fudan University, Shanghai, China;School of Data Science, Fudan University, Shanghai, China;School of Data Science, Fudan University, Shanghai, China;School of Data Science, Fudan University, Shanghai, China;School of Data Science, Fudan University, Shanghai, China;School of Data Science, Fudan University, Shanghai, China;Institute for AI in Medicine (IKIM) at UK Essen, Ruhr-University Bochum, Bochum, Germany;Pennsylvania State University, State College, PA, USA;School of Data Science, Fudan University, Shanghai, China",0.1109/tvcg.2016.2616404;10.1109/tvcg.2011.202;10.1109/tvcg.2008.149;10.1109/tvcg.2007.70574;10.1109/tvcg.2013.226;10.1109/tvcg.2020.3030350;10.1109/tvcg.2009.143;10.1109/tvcg.2021.3114855;10.1109/tvcg.2018.2843369;10.1109/tvcg.2021.3114777;10.1109/tvcg.2021.3114853;10.1109/tvcg.2017.2744938;10.1109/tvcg.2016.2598831;10.1109/vast.2017.8585721;10.1109/tvcg.2016.2520920;10.1109/tvcg.2012.213;10.1109/tvcg.2019.2934629,"Autonomous driving,spatial-temporal visual analytics,,interpretability",,9,51,835,,
TVCG,2022,Towards Better Caption Supervision for Object Detection,10.1109/tvcg.2021.3138933,http://dx.doi.org/10.1109/TVCG.2021.3138933,1941,1954,J,"As training high-performance object detectors requires expensive bounding box annotations, recent methods resort to free-available image captions. However, detectors trained on caption supervision perform poorly because captions are usually noisy and cannot provide precise location information. To tackle this issue, we present a visual analysis method, which tightly integrates caption supervision with object detection to mutually enhance each other. In particular, object labels are first extracted from captions, which are utilized to train the detectors. Then, the objects detected from images are fed into caption supervision for further improvement. To effectively loop users into the object detection process, a node-link-based set visualization supported by a multi-type relational co-clustering algorithm is developed to explain the relationships between the extracted labels and the images with detected objects. The co-clustering algorithm clusters labels and images simultaneously by utilizing both their representations and their relationships. Quantitative evaluations and a case study are conducted to demonstrate the efficiency and effectiveness of the developed method in improving the performance of object detectors.",Changjian Chen;Jing Wu 0004;Xiaohan Wang;Shouxing Xiang;Song-Hai Zhang;Qifeng Tang;Shixia Liu,Changjian Chen;Jing Wu;Xiaohan Wang;Shouxing Xiang;Song-Hai Zhang;Qifeng Tang;Shixia Liu,"School of Software, BNRist, Tsinghua University, Beijing, China;Cardiff University, Cardiff, U.K.;Zhejiang University, Zhejiang, China;School of Software, BNRist, Tsinghua University, Beijing, China;Department of Computer Science and Technology, Tsinghua University, Beijing, China;Shanghai Lianshu IoT Company Ltd., Shanghai, China;School of Software, BNRist, Tsinghua University, Beijing, China",0.1109/tvcg.2020.2969185;10.1109/tvcg.2020.3030350;10.1109/vast50239.2020.00007;10.1109/tvcg.2021.3114793;10.1109/vast47406.2019.8986917;10.1109/tvcg.2021.3084694;10.1109/tvcg.2019.2934266;10.1109/tvcg.2021.3114797;10.1109/mcg.2016.102;10.1109/tvcg.2016.2598695;10.1109/tvcg.2020.3030432;10.1109/tvcg.2017.2746018;10.1109/vast.2016.7883508;10.1109/tvcg.2018.2864843;10.1109/vast47406.2019.8986943;10.1109/tvcg.2020.2973258;10.1109/tvcg.2019.2934659;10.1109/tvcg.2016.2598831,"Machine learning,interactive visualization,,object detection,caption supervision,co-clustering",,8,56,1990,,X
TVCG,2022,NeuroConstruct: 3D Reconstruction and Visualization of Neurites in Optical Microscopy Brain Images,10.1109/tvcg.2021.3109460,http://dx.doi.org/10.1109/TVCG.2021.3109460,4951,4965,J,"We introduce NeuroConstruct, a novel end-to-end application for the segmentation, registration, and visualization of brain volumes imaged using wide-field microscopy. NeuroConstruct offers a Segmentation Toolbox with various annotation helper functions that aid experts to effectively and precisely annotate micrometer resolution neurites. It also offers an automatic neurites segmentation using convolutional neuronal networks (CNN) trained by the Toolbox annotations and somas segmentation using thresholding. To visualize neurites in a given volume, NeuroConstruct offers a hybrid rendering by combining iso-surface rendering of high-confidence classified neurites, along with real-time rendering of raw volume using a 2D transfer function for voxel classification score versus voxel intensity value. For a complete reconstruction of the 3D neurites, we introduce a Registration Toolbox that provides automatic coarse-to-fine alignment of serially sectioned samples. The quantitative and qualitative analysis show that NeuroConstruct outperforms the state-of-the-art in all design aspects. NeuroConstruct was developed as a collaboration between computer scientists and neuroscientists, with an application to the study of cholinergic neurons, which are severely affected in Alzheimer's disease.",Parmida Ghahremani;Saeed Boorboor;Pooya Mirhosseini;Chetan Gudisagar;Mala Ananth 0001;David Talmage;Lorna W. Role;Arie E. Kaufman,Parmida Ghahremani;Saeed Boorboor;Pooya Mirhosseini;Chetan Gudisagar;Mala Ananth;David Talmage;Lorna W. Role;Arie E. Kaufman,"Department of Computer Science, Stony Brook University, Stony Brook, NY, USA;Department of Computer Science, Stony Brook University, Stony Brook, NY, USA;Department of Computer Science, Stony Brook University, Stony Brook, NY, USA;Department of Computer Science, Stony Brook University, Stony Brook, NY, USA;National Institutes of Health, Bethesda, MD, USA;National Institutes of Health, Bethesda, MD, USA;National Institutes of Health, Bethesda, MD, USA;Department of Computer Science, Stony Brook University, Stony Brook, NY, USA",0.1109/tvcg.2012.240;10.1109/tvcg.2013.142;10.1109/tvcg.2018.2864852;10.1109/tvcg.2014.2346371,"Wide-field microscopy,neuron morphology,,segmentation,registration,hybrid volume rendering,CNN",,8,56,771,,
TVCG,2023,StrategyAtlas: Strategy Analysis for Machine Learning Interpretability,10.1109/tvcg.2022.3146806,http://dx.doi.org/10.1109/TVCG.2022.3146806,2996,3008,J,"Businesses in high-risk environments have been reluctant to adopt modern machine learning approaches due to their complex and uninterpretable nature. Most current solutions provide local, instance-level explanations, but this is insufficient for understanding the model as a whole. In this work, we show that strategy clusters (i.e., groups of data instances that are treated distinctly by the model) can be used to understand the global behavior of a complex ML model. To support effective exploration and understanding of these clusters, we introduce StrategyAtlas, a system designed to analyze and explain model strategies. Furthermore, it supports multiple ways to utilize these strategies for simplifying and improving the reference model. In collaboration with a large insurance company, we present a use case in automatic insurance acceptance, and show how professional data scientists were enabled to understand a complex model and improve the production model based on these insights.",Dennis Collaris;Jarke J. van Wijk,Dennis Collaris;Jarke J. van Wijk,"Department of Mathematics and Computer Science, Eindhoven University of Technology, Eindhoven, AZ, The Netherlands;Department of Mathematics and Computer Science, Eindhoven University of Technology, Eindhoven, AZ, The Netherlands",0.1109/tvcg.2017.2744683;10.1109/tvcg.2017.2744718;10.1109/vast.2017.8585721;10.1109/tvcg.2019.2934659;10.1109/tvcg.2018.2865044;10.1109/tvcg.2018.2864500;10.1109/tvcg.2018.2865230;10.1109/tvcg.2018.2865194;10.1109/tvcg.2018.2864475;10.1109/tvcg.2013.124;10.1109/tvcg.2017.2744358;10.1109/tvcg.2018.2864477;10.1109/tvcg.2018.2864812;10.1109/tvcg.2016.2598838,"Visual analytics,machine learning,,explainable AI",,9,51,1528,,
TVCG,2022,Vivern–A Virtual Environment for Multiscale Visualization and Modeling of DNA Nanostructures,10.1109/tvcg.2021.3106328,http://dx.doi.org/10.1109/TVCG.2021.3106328,4825,4838,J,"DNA nanostructures offer promising applications, particularly in the biomedical domain, as they can be used for targeted drug delivery, construction of nanorobots, or as a basis for molecular motors. One of the most prominent techniques for assembling these structures is DNA origami. Nowadays, desktop applications are used for the in silico design of such structures. However, as such structures are often spatially complex, their assembly and analysis are complicated. Since virtual reality (VR) was proven to be advantageous for such spatial-related tasks and there are no existing VR solutions focused on this domain, we propose Vivern, a VR application that allows domain experts to design and visually examine DNA origami nanostructures. Our approach presents different abstracted visual representations of the nanostructures, various color schemes, and an ability to place several DNA nanostructures and proteins in one environment, thus allowing for the detailed analysis of complex assemblies. We also present two novel examination tools, the Magic Scale Lens and the DNA Untwister, that allow the experts to visually embed different representations into local regions to preserve the context and support detailed investigation. To showcase the capabilities of our solution, prototypes of novel nanodevices conceptualized by our collaborating experts, such as DNA-protein hybrid structures and DNA origami superstructures, are presented. Finally, the results of two rounds of evaluations are summarized. They demonstrate the advantages of our solution, especially for scenarios where current desktop tools are very limited, while also presenting possible future research directions.",David Kuták;Matias Nicolás Selzer;Jan Byska;Maria Luján Ganuza;Ivan Barisic;Barbora Kozlíková;Haichao Miao,David Kuťák;Matias Nicolás Selzer;Jan Byška;María Luján Ganuza;Ivan Barišić;Barbora Kozlíková;Haichao Miao,"Masaryk University, Brno, Czech Republic;VyGLab Research Laboratory and the Institute for Computer Science and Engineering (CONICET-UNS), Bahía Blanca, Argentina;Masaryk University, Brno, Czech Republic;VyGLab Research Laboratory and the Institute for Computer Science and Engineering (CONICET-UNS), Bahía Blanca, Argentina;AIT Austrian Institute of Technology, Vienna, Austria;Masaryk University, Brno, Czech Republic;AIT Austrian Institute of Technology, Vienna, Austria",0.1109/tvcg.2014.2346331;10.1109/tvcg.2018.2864507;10.1109/visual.1998.745317;10.1109/tvcg.2019.2934334;10.1109/tvcg.2018.2850781;10.1109/tvcg.2015.2403323;10.1109/tvcg.2017.2743981;10.1109/tvcg.2017.2744278,"Virtual reality,abstraction,magic scale lens,DNA origami,nanostructures,visualization,focus+context,interaction,in silico modeling,nanotechnology,multiscale",,9,68,1130,,
TVCG,2023,Visual Exploration of Relationships and Structure in Low-Dimensional Embeddings,10.1109/tvcg.2022.3156760,http://dx.doi.org/10.1109/TVCG.2022.3156760,3312,3326,J,"In this work, we propose an interactive visual approach for the exploration and formation of structural relationships in embeddings of high-dimensional data. These structural relationships, such as item sequences, associations of items with groups, and hierarchies between groups of items, are defining properties of many real-world datasets. Nevertheless, most existing methods for the visual exploration of embeddings treat these structures as second-class citizens or do not take them into account at all. In our proposed analysis workflow, users explore enriched scatterplots of the embedding, in which relationships between items and/or groups are visually highlighted. The original high-dimensional data for single items, groups of items, or differences between connected items and groups are accessible through additional summary visualizations. We carefully tailored these summary and difference visualizations to the various data types and semantic contexts. During their exploratory analysis, users can externalize their insights by setting up additional groups and relationships between items and/or groups. We demonstrate the utility and potential impact of our approach by means of two use cases and multiple examples from various domains.",Klaus Eckelt;Andreas P. Hinterreiter;Patrick Adelberger;Conny Walchshofer;Vaishali Dhanoa;Christina Humer;Moritz Heckmann;Christian Alexander Steinparz;Marc Streit,Klaus Eckelt;Andreas Hinterreiter;Patrick Adelberger;Conny Walchshofer;Vaishali Dhanoa;Christina Humer;Moritz Heckmann;Christian Steinparz;Marc Streit,"Johannes Kepler University Linz, Linz, Austria;Johannes Kepler University Linz, Linz, Austria;Johannes Kepler University Linz, Linz, Austria;Johannes Kepler University Linz, Linz, Austria;Johannes Kepler University Linz, Linz, Austria;Johannes Kepler University Linz, Linz, Austria;Johannes Kepler University Linz, Linz, Austria;Johannes Kepler University Linz, Linz, Austria;Johannes Kepler University Linz, Linz, Austria",0.1109/tvcg.2021.3114807;10.1109/tvcg.2020.2986996;10.1109/tvcg.2016.2598446;10.1109/tvcg.2015.2467615;10.1109/tvcg.2018.2865194;10.1109/tvcg.2020.3011155;10.1109/tvcg.2016.2599030;10.1109/tvcg.2017.2744184;10.1109/tvcg.2015.2467851;10.1109/tvcg.2011.188;10.1109/vast.2018.8802454;10.1109/tvcg.2022.3148107;10.1109/tvcg.2018.2846735;10.1109/tvcg.2018.2865141;10.1109/tvcg.2021.3114870;10.1109/tvcg.2017.2745258;10.1109/tvcg.2015.2467717;10.1109/tvcg.2015.2489660,"Dimensionality reduction,projection,,visual analytics,layout enrichment,aggregation,comparison",,9,70,1183,,
TVCG,2023,Topological Simplifications of Hypergraphs,10.1109/tvcg.2022.3153895,http://dx.doi.org/10.1109/TVCG.2022.3153895,3209,3225,J,"We study hypergraph visualization via its topological simplification. We explore both vertex simplification and hyperedge simplification of hypergraphs using tools from topological data analysis. In particular, we transform a hypergraph into its graph representations, known as the line graph and clique expansion. A topological simplification of such a graph representation induces a simplification of the hypergraph. In simplifying a hypergraph, we allow vertices to be combined if they belong to almost the same set of hyperedges, and hyperedges to be merged if they share almost the same set of vertices. Our proposed approaches are general and mathematically justifiable, and put vertex simplification and hyperedge simplification in a unifying framework.",Youjia Zhou;Archit Rathore;Emilie Purvine;Bei Wang 0001,Youjia Zhou;Archit Rathore;Emilie Purvine;Bei Wang,"Scientific Computing & Imaging (SCI) Institute, University of Utah, Salt Lake City, UT, USA;Scientific Computing & Imaging (SCI) Institute, University of Utah, Salt Lake City, UT, USA;Pacific Northwest National Laboratory, Seattle, WA, USA;Scientific Computing & Imaging (SCI) Institute, University of Utah, Salt Lake City, UT, USA",0.1109/tvcg.2010.213;10.1109/tvcg.2017.2743858;10.1109/tvcg.2020.3030475;10.1109/tvcg.2019.2933196;10.1109/tvcg.2009.122;10.1109/tvcg.2011.186;10.1109/tvcg.2010.210;10.1109/tvcg.2014.2346248,"Hypergraph simplification,hypergraph visualization,,graph simplification,topological data analysis",,7,74,591,,
TVCG,2023,Finding Nano-Ötzi: Cryo-Electron Tomography Visualization Guided by Learned Segmentation,10.1109/tvcg.2022.3186146,http://dx.doi.org/10.1109/TVCG.2022.3186146,4198,4214,J,"Cryo-electron tomography (cryo-ET) is a new 3D imaging technique with unprecedented potential for resolving submicron structural details. Existing volume visualization methods, however, are not able to reveal details of interest due to low signal-to-noise ratio. In order to design more powerful transfer functions, we propose leveraging soft segmentation as an explicit component of visualization for noisy volumes. Our technical realization is based on semi-supervised learning, where we combine the advantages of two segmentation algorithms. First, the weak segmentation algorithm provides good results for propagating sparse user-provided labels to other voxels in the same volume and is used to generate dense pseudo-labels. Second, the powerful deep-learning-based segmentation algorithm learns from these pseudo-labels to generalize the segmentation to other unseen volumes, a task that the weak segmentation algorithm fails at completely. The proposed volume visualization uses deep-learning-based segmentation as a component for segmentation-aware transfer function design. Appropriate ramp parameters can be suggested automatically through frequency distribution analysis. Furthermore, our visualization uses gradient-free ambient occlusion shading to further suppress the visual presence of noise, and to give structural detail the desired prominence. The cryo-ET data studied in our technical experiments are based on the highest-quality tilted series of intact SARS-CoV-2 virions. Our technique shows the high impact in target sciences for visual data analysis of very noisy volumes that cannot be visualized with existing techniques.",Ngan Nguyen;Ciril Bohak;Dominik Engel;Peter Mindek;Ondrej Strnad;Peter Wonka;Sai Li;Timo Ropinski;Ivan Viola,Ngan Nguyen;Ciril Bohak;Dominik Engel;Peter Mindek;Ondřej Strnad;Peter Wonka;Sai Li;Timo Ropinski;Ivan Viola,"King Abdullah University of Science and Technology, Thuwal, Saudi Arabia;King Abdullah University of Science and Technology, Thuwal, Saudi Arabia;Ulm University, Ulm, Germany;Nanographics GmbH, TU Wien, Wien, Austria;King Abdullah University of Science and Technology, Thuwal, Saudi Arabia;King Abdullah University of Science and Technology, Thuwal, Saudi Arabia;School of Life Sciences, Tsinghua University, Bejing, China;Ulm University, Ulm, Germany;King Abdullah University of Science and Technology, Thuwal, Saudi Arabia",0.1109/tvcg.2018.2816059;10.1109/visual.1995.480803;10.1109/tvcg.2010.195;10.1109/tvcg.2010.208;10.1109/tvcg.2007.70518,"Volume rendering,computer graphics techniques,,machine learning techniques,scalar field data,life sciences",,6,82,1043,,
TVCG,2023,Comparative Analysis of Merge Trees Using Local Tree Edit Distance,10.1109/tvcg.2021.3122176,http://dx.doi.org/10.1109/TVCG.2021.3122176,1518,1530,J,"Comparative analysis of scalar fields is an important problem with various applications including feature-directed visualization and feature tracking in time-varying data. Comparing topological structures that are abstract and succinct representations of the scalar fields lead to faster and meaningful comparison. While there are many distance or similarity measures to compare topological structures in a global context, there are no known measures for comparing topological structures locally. While the global measures have many applications, they do not directly lend themselves to fine-grained analysis across multiple scales. We define a local variant of the tree edit distance and apply it towards local comparative analysis of merge trees with support for finer analysis. We also present experimental results on time-varying scalar fields, 3D cryo-electron microscopy data, and other synthetic data sets to show the utility of this approach in applications like symmetry detection and feature tracking.",Raghavendra Sridharamurthy;Vijay Natarajan,Raghavendra Sridharamurthy;Vijay Natarajan,"Department of Computer Science and Automation, Indian Institute of Science, Bangalore, Karnataka, India;Department of Computer Science and Automation, Indian Institute of Science, Bangalore, Karnataka, India",0.1109/tvcg.2018.2873612;10.1109/tvcg.2018.2864808;10.1109/tvcg.2019.2934368;10.1109/tvcg.2011.236;10.1109/tvcg.2013.148;10.1109/tvcg.2014.2346332;10.1109/tvcg.2017.2743938,"Merge tree,scalar field,,local distance measure,persistence,edit distance,symmetry detection,feature tracking",,6,32,259,,
TVCG,2022,DeHumor: Visual Analytics for Decomposing Humor,10.1109/tvcg.2021.3097709,http://dx.doi.org/10.1109/TVCG.2021.3097709,4609,4623,J,"Despite being a critical communication skill, grasping humor is challenging—a successful use of humor requires a mixture of both engaging content build-up and an appropriate vocal delivery (e.g., pause). Prior studies on computational humor emphasize the textual and audio features immediately next to the punchline, yet overlooking longer-term context setup. Moreover, the theories are usually too abstract for understanding each concrete humor snippet. To fill in the gap, we develop DeHumor, a visual analytical system for analyzing humorous behaviors in public speaking. To intuitively reveal the building blocks of each concrete example, DeHumor decomposes each humorous video into multimodal features and provides inline annotations of them on the video script. In particular, to better capture the build-ups, we introduce content repetition as a complement to features introduced in theories of computational humor and visualize them in a context linking graph. To help users locate the punchlines that have the desired features to learn, we summarize the content (with keywords) and humor feature statistics on an augmented time matrix. With case studies on stand-up comedy shows and TED talks, we show that DeHumor is able to highlight various building blocks of humor examples. In addition, expert interviews with communication coaches and humor researchers demonstrate the effectiveness of DeHumor for multimodal humor analysis of speech content and vocal delivery.",Xingbo Wang 0001;Yao Ming;Tongshuang Wu;Haipeng Zeng;Yong Wang 0021;Huamin Qu,Xingbo Wang;Yao Ming;Tongshuang Wu;Haipeng Zeng;Yong Wang;Huamin Qu,"Hong Kong University of Science and Technology, Hong Kong;Bloomberg LP, New York, NY, USA;University of Washington, Seattle, WA, USA;Sun Yat-sen University, Guangzhou, China;Singapore Management University, Singapore, Singapore;Hong Kong University of Science and Technology, Hong Kong",0.1109/infvis.2002.1173155,"Humor,context,,multimodal features,visualization",,6,65,847,,
TVCG,2023,NeuRegenerate: A Framework for Visualizing Neurodegeneration,10.1109/tvcg.2021.3127132,http://dx.doi.org/10.1109/TVCG.2021.3127132,1625,1637,J,"Recent advances in high-resolution microscopy have allowed scientists to better understand the underlying brain connectivity. However, due to the limitation that biological specimens can only be imaged at a single timepoint, studying changes to neural projections over time is limited to observations gathered using population analysis. In this article, we introduce NeuRegenerate, a novel end-to-end framework for the prediction and visualization of changes in neural fiber morphology within a subject across specified age-timepoints. To predict projections, we present neuReGANerator, a deep-learning network based on cycle-consistent generative adversarial network (GAN) that translates features of neuronal structures across age-timepoints for large brain microscopy volumes. We improve the reconstruction quality of the predicted neuronal structures by implementing a density multiplier and a new loss function, called the hallucination loss. Moreover, to alleviate artifacts that occur due to tiling of large input volumes, we introduce a spatial-consistency module in the training pipeline of neuReGANerator. Finally, to visualize the change in projections, predicted using neuReGANerator, NeuRegenerate offers two modes: (i) neuroCompare to simultaneously visualize the difference in the structures of the neuronal projections, from two age domains (using structural view and bounded view), and (ii) neuroMorph, a vesselness-based morphing technique to interactively visualize the transformation of the structures from one age-timepoint to the other. Our framework is designed specifically for volumes acquired using wide-field microscopy. We demonstrate our framework by visualizing the structural changes within the cholinergic system of the mouse brain between a young and old specimen.",Saeed Boorboor;Shawn Mathew;Mala Ananth 0001;David Talmage;Lorna W. Role;Arie E. Kaufman,Saeed Boorboor;Shawn Mathew;Mala Ananth;David Talmage;Lorna W. Role;Arie E. Kaufman,"Department of Computer Science, Stony Brook University, Stony Brook, NY, USA;Department of Computer Science, Stony Brook University, Stony Brook, NY, USA;National Institutes of Health, Bethesda, MD, USA;National Institutes of Health, Bethesda, MD, USA;National Institutes of Health, Bethesda, MD, USA;Department of Computer Science, Stony Brook University, Stony Brook, NY, USA",0.1109/tvcg.2014.2346312;10.1109/tvcg.2017.2744278;10.1109/tvcg.2018.2864852;10.1109/tvcg.2017.2744079;10.1109/tvcg.2016.2599042;10.1109/visual.1994.346333,"Neuron visualization,volume visualization,,volume transformation,wide-field microscopy,machine learning",,5,46,540,,
TVCG,2023,GestureLens: Visual Analysis of Gestures in Presentation Videos,10.1109/tvcg.2022.3169175,http://dx.doi.org/10.1109/TVCG.2022.3169175,3685,3697,J,"Appropriate gestures can enhance message delivery and audience engagement in both daily communication and public presentations. In this article, we contribute a visual analytic approach that assists professional public speaking coaches in improving their practice of gesture training through analyzing presentation videos. Manually checking and exploring gesture usage in the presentation videos is often tedious and time-consuming. There lacks an efficient method to help users conduct gesture exploration, which is challenging due to the intrinsically temporal evolution of gestures and their complex correlation to speech content. In this article, we propose GestureLens, a visual analytics system to facilitate gesture-based and content-based exploration of gesture usage in presentation videos. Specifically, the exploration view enables users to obtain a quick overview of the spatial and temporal distributions of gestures. The dynamic hand movements are firstly aggregated through a heatmap in the gesture space for uncovering spatial patterns, and then decomposed into two mutually perpendicular timelines for revealing temporal patterns. The relation view allows users to explicitly explore the correlation between speech content and gestures by enabling linked analysis and intuitive glyph designs. The video view and dynamic view show the context and overall dynamic movement of the selected gestures, respectively. Two usage scenarios and expert interviews with professional presentation coaches demonstrate the effectiveness and usefulness of GestureLens in facilitating gesture exploration and analysis of presentation videos.",Haipeng Zeng;Xingbo Wang 0001;Yong Wang 0021;Aoyu Wu;Ting-Chuen Pong;Huamin Qu,Haipeng Zeng;Xingbo Wang;Yong Wang;Aoyu Wu;Ting-Chuen Pong;Huamin Qu,"Sun Yat-sen University, Shenzhen, Guangdong, China;Hong Kong University of Science and Technology, Hong Kong;Singapore Management University, Singapore;Hong Kong University of Science and Technology, Hong Kong;Hong Kong University of Science and Technology, Hong Kong;Hong Kong University of Science and Technology, Hong Kong",0.1109/tvcg.2018.2889081;10.1109/tvcg.2013.178;10.1109/tvcg.2015.2468292;10.1109/tvcg.2021.3097709;10.1109/tvcg.2019.2934656;10.1109/tvcg.2021.3114794;10.1109/tvcg.2019.2963659,"Gesture,hand movements,,presentation video analysis,visual analysis",,5,51,708,,
TVCG,2023,A Predictive Visual Analytics System for Studying Neurodegenerative Disease Based on DTI Fiber Tracts,10.1109/tvcg.2021.3137174,http://dx.doi.org/10.1109/TVCG.2021.3137174,2020,2035,J,"Diffusion tensor imaging (DTI) has been used to study the effects of neurodegenerative diseases on neural pathways, which may lead to more reliable and early diagnosis of these diseases as well as a better understanding of how they affect the brain. We introduce a predictive visual analytics system for studying patient groups based on their labeled DTI fiber tract data and corresponding statistics. The system’s machine-learning-augmented interface guides the user through an organized and holistic analysis space, including the statistical feature space, the physical space, and the space of patients over different groups. We use a custom machine learning pipeline to help narrow down this large analysis space and then explore it pragmatically through a range of linked visualizations. We conduct several case studies using DTI and T1-weighted images from the research database of Parkinson’s Progression Markers Initiative.",Chaoqing Xu;Tyson Neuroth;Takanori Fujiwara;Ronghua Liang;Kwan-Liu Ma,Chaoqing Xu;Tyson Neuroth;Takanori Fujiwara;Ronghua Liang;Kwan-Liu Ma,"College of Computer Science, Zhejiang University of Technology, Hangzhou, Zhejiang, China;University of California, Davis, CA, USA;University of California, Davis, CA, USA;College of Computer Science, Zhejiang University of Technology, Hangzhou, Zhejiang, China;University of California, Davis, CA, USA",0.1109/tvcg.2015.2467435;10.1109/tvcg.2015.2403323;10.1109/tvcg.2012.142;10.1109/tvcg.2009.138;10.1109/tvcg.2009.141;10.1109/tvcg.2011.82;10.1109/mcg.2014.40;10.1109/tvcg.2019.2934547;10.1109/tvcg.2019.2934251;10.1109/tvcg.2021.3114807;10.1109/tvcg.2016.2598472;10.1109/tvcg.2018.2843369;10.1109/tvcg.2017.2743858;10.1109/tvcg.2019.2934396;10.1109/tvcg.2019.2934312,"Brain fiber tracts,neurodegenerative disease,,machine learning,predictive visual analytics,visualization",,5,94,524,,
TVCG,2023,Fitting Bell Curves to Data Distributions Using Visualization,10.1109/tvcg.2022.3210763,http://dx.doi.org/10.1109/TVCG.2022.3210763,5372,5383,J,"Idealized probability distributions, such as normal or other curves, lie at the root of confirmatory statistical tests. But how well do people understand these idealized curves? In practical terms, does the human visual system allow us to match sample data distributions with hypothesized population distributions from which those samples might have been drawn? And how do different visualization techniques impact this capability? This article shares the results of a crowdsourced experiment that tested the ability of respondents to fit normal curves to four different data distribution visualizations: bar histograms, dotplot histograms, strip plots, and boxplots. We find that the crowd can estimate the center (mean) of a distribution with some success and little bias. We also find that people generally overestimate the standard deviation—which we dub the “umbrella effect” because people tend to want to cover the whole distribution using the curve, as if sheltering it from the heavens above—and that strip plots yield the best accuracy.",Eric Newburger;Michael Correll;Niklas Elmqvist,Eric Newburger;Michael Correll;Niklas Elmqvist,"University of Maryland, College Park, MD, USA;Tableau Research, Seattle, WA, USA;University of Maryland, College Park, MD, USA",0.1109/tvcg.2016.2598862;10.1109/tvcg.2010.161;10.1109/tvcg.2018.2864907;10.1109/tvcg.2017.2785807;10.1109/tvcg.2011.185;10.1109/tvcg.2020.3030429;10.1109/tvcg.2020.3030335;10.1109/tvcg.2014.2346298;10.1109/tvcg.2017.2743898;10.1109/tvcg.2013.183,"Graphical inference,visual statistics,,statistics by eye,fitting distributions,crowdsourcing",,5,49,332,,
TVCG,2022,Effectiveness Error: Measuring and Improving RadViz Visual Effectiveness,10.1109/tvcg.2021.3104879,http://dx.doi.org/10.1109/TVCG.2021.3104879,4770,4786,J,"RadViz contributes to multidimensional analysis by using 2D points for encoding data elements and interpreting them along the original data dimensions. For these characteristics it is used in different application domains, like clustering, anomaly detection, and software visualization. However, it is likely that using the dimension arrangement that comes with the data will produce a plot that leads users to make inaccurate conclusions about points values and data distribution. This article attacks this problem without altering the original RadViz design: It defines, for both a single point and a set of points, the metric of effectiveness error, and uses it to define the objective function of a dimension arrangement strategy, arguing that minimizing it increases the overall RadViz visual quality. This article investigated the intuition that reducing the effectiveness error is beneficial for other well-known RadViz problems, like points clumping toward the center, many-to-one plotting of non-proportional points, and cluster separation. It presents an algorithm that reduces to zero the effectiveness error for a single point and a heuristic that approximates the dimension arrangement minimizing the effectiveness error for an arbitrary set of points. A set of experiments based on 21 real datasets has been performed, with the goals of analyzing the advantages of reducing the effectiveness error, comparing the proposed dimension arrangement strategy with other related proposals, and investigating the heuristic accuracy. The Effectiveness Error metric, the algorithm, and the heuristic presented in this article have been made available in a d3.js plugin at https://aware-diag-sapienza.github.io/d3-radviz.",Marco Angelini;Graziano Blasilli;Simone Lenti;Alessia Palleschi;Giuseppe Santucci,Marco Angelini;Graziano Blasilli;Simone Lenti;Alessia Palleschi;Giuseppe Santucci,"Sapienza University of Rome, Rome, Italy;Sapienza University of Rome, Rome, Italy;Sapienza University of Rome, Rome, Italy;Sapienza University of Rome, Rome, Italy;Sapienza University of Rome, Rome, Italy",0.1109/tvcg.2014.2346258;10.1109/vast.2010.5652433;10.1109/visual.1997.663916;10.1109/infvis.1998.729559;10.1109/tvcg.2008.173;10.1109/tvcg.2011.185,"Dimensionality reduction,RadViz,,dimension arrangement,visual quality metrics",,4,57,328,,
TVCG,2023,Visualizing the Scripts of Data Wrangling With Somnus,10.1109/tvcg.2022.3144975,http://dx.doi.org/10.1109/TVCG.2022.3144975,2950,2964,J,"Data workers use various scripting languages for data transformation, such as SAS, R, and Python. However, understanding intricate code pieces requires advanced programming skills, which hinders data workers from grasping the idea of data transformation at ease. Program visualization is beneficial for debugging and education and has the potential to illustrate transformations intuitively and interactively. In this article, we explore visualization design for demonstrating the semantics of code pieces in the context of data transformation. First, to depict individual data transformations, we structure a design space by two primary dimensions, i.e., key parameters to encode and possible visual channels to be mapped. Then, we derive a collection of 23 glyphs that visualize the semantics of transformations. Next, we design a pipeline, named Somnus, that provides an overview of the creation and evolution of data tables using a provenance graph. At the same time, it allows detailed investigation of individual transformations. User feedback on Somnus is positive. Our study participants achieved better accuracy with less time using Somnus, and preferred it over carefully-crafted textual description. Further, we provide two example applications to demonstrate the utility and versatility of Somnus.",Kai Xiong;Siwei Fu;Guoming Ding;Zhongsu Luo;Rong Yu;Wei Chen 0001;Hujun Bao;Yingcai Wu,Kai Xiong;Siwei Fu;Guoming Ding;Zhongsu Luo;Rong Yu;Wei Chen;Hujun Bao;Yingcai Wu,"State Key Lab of CAD&CG, Zhejiang University, Hangzhou, China;Zhejiang Lab, Hangzhou, China;State Key Lab of CAD&CG, Zhejiang University, Hangzhou, China;Zhejiang University of Technology, Hangzhou, China;Zhejiang Lab, Hangzhou, China;State Key Lab of CAD&CG, Zhejiang University, Hangzhou, China;State Key Lab of CAD&CG, Zhejiang University, Hangzhou, China;State Key Lab of CAD&CG, Zhejiang University, Hangzhou, China",0.1109/tvcg.2011.185;10.1109/tvcg.2009.111;10.1109/tvcg.2017.2745298;10.1109/mcg.2019.2941856;10.1109/vast47406.2019.8986909;10.1109/vast.2011.6102440;10.1109/tvcg.2021.3114875;10.1109/tvcg.2020.3030462;10.1109/tvcg.2021.3114830;10.1109/tvcg.2021.3114877;10.1109/tvcg.2021.3114781;10.1109/tvcg.2015.2467551,"Program understanding,data transformation,,visualization design",,7,82,570,,
TVCG,2023,Geometry-Aware Merge Tree Comparisons for Time-Varying Data With Interleaving Distances,10.1109/tvcg.2022.3163349,http://dx.doi.org/10.1109/TVCG.2022.3163349,3489,3506,J,"Merge trees, a type of topological descriptors, serve to identify and summarize the topological characteristics associated with scalar fields. They have great potential for analyzing and visualizing time-varying data. First, they give compressed and topology-preserving representations of data instances. Second, their comparisons provide a basis for studying the relations among data instances, such as their distributions, clusters, outliers, and periodicities. A number of comparative measures have been developed for merge trees. However, these measures are often computationally expensive since they implicitly consider all possible correspondences between critical points of the merge trees. In this paper, we perform geometry-aware comparisons of merge trees using labeled interleaving distances. The main idea is to decouple the computation of a comparative measure into two steps: a labeling step that generates a correspondence between the critical points of two merge trees, and a comparison step that computes distances between a pair of labeled merge trees by encoding them as matrices. We show that our approach is general, computationally efficient, and practically useful. Our framework makes it possible to integrate geometric information of the data domain in the labeling process. At the same time, the framework reduces the computational complexity since not all possible correspondences have to be considered. We demonstrate via experiments that such geometry-aware merge tree comparisons help to detect transitions, clusters, and periodicities of time-varying datasets, as well as to diagnose and highlight the topological changes between adjacent data instances.",Lin Yan 0003;Talha Bin Masood;Farhan Rasheed;Ingrid Hotz;Bei Wang 0001,Lin Yan;Talha Bin Masood;Farhan Rasheed;Ingrid Hotz;Bei Wang,"Scientific Computing & Imaging (SCI) Institute, University of Utah, Salt Lake City, UT, USA;Department of Science and Technology, Linköping University, Norrköping, Sweden;Department of Science and Technology, Linköping University, Norrköping, Sweden;Department of Science and Technology, Linköping University, Norrköping, Sweden;Scientific Computing & Imaging (SCI) Institute, University of Utah, Salt Lake City, UT, USA",0.1109/tvcg.2018.2810068;10.1109/tvcg.2011.236;10.1109/tvcg.2019.2934242;10.1109/tvcg.2018.2873612;10.1109/tvcg.2011.269;10.1109/tvcg.2011.159;10.1109/tvcg.2006.186;10.1109/tvcg.2021.3114839;10.1109/tvcg.2019.2934375;10.1109/tvcg.2010.213;10.1109/tvcg.2020.3022359,"Merge trees,merge tree metrics,,topological data analysis,topology in visualization",,5,63,349,,
TVCG,2023,Nanotilus: Generator of Immersive Guided-Tours in Crowded 3D Environments,10.1109/tvcg.2021.3133592,http://dx.doi.org/10.1109/TVCG.2021.3133592,1860,1875,J,"Immersive virtual reality environments are gaining popularity for studying and exploring crowded three-dimensional structures. When reaching very high structural densities, the natural depiction of the scene produces impenetrable clutter and requires visibility and occlusion management strategies for exploration and orientation. Strategies developed to address the crowdedness in desktop applications, however, inhibit the feeling of immersion. They result in nonimmersive, desktop-style outside-in viewing in virtual reality. This article proposes Nanotilus—a new visibility and guidance approach for very dense environments that generates an endoscopic inside-out experience instead of outside-in viewing, preserving the immersive aspect of virtual reality. The approach consists of two novel, tightly coupled mechanisms that control scene sparsification simultaneously with camera path planning. The sparsification strategy is localized around the camera and is realized as a multi-scale, multi-shell, variety-preserving technique. When Nanotilus dives into the structures to capture internal details residing on multiple scales, it guides the camera using depth-based path planning. In addition to sparsification and path planning, we complete the tour generation with an animation controller, textual annotation, and text-to-visualization conversion. We demonstrate the generated guided tours on mesoscopic biological models – SARS-CoV-2 and HIV. We evaluate the Nanotilus experience with a baseline outside-in sparsification and navigational technique in a formal user study with 29 participants. While users can maintain a better overview using the outside-in sparsification, the study confirms our hypothesis that Nanotilus leads to stronger engagement and immersion.",Ruwayda Alharbi;Ondrej Strnad;Laura Rosalia Luidolt;Manuela Waldner;David Kouril;Ciril Bohak;Tobias Klein;Eduard Gröller;Ivan Viola,Ruwayda Alharbi;Ondřej Strnad;Laura R. Luidolt;Manuela Waldner;David Kouřil;Ciril Bohak;Tobias Klein;Eduard Gröller;Ivan Viola,"King Abdullah University of Science and Technology (KAUST), Thuwal, Saudi Arabia;King Abdullah University of Science and Technology (KAUST), Thuwal, Saudi Arabia;TU Wien, Vienna, Austria;TU Wien, Vienna, Austria;Masaryk University, Brno, Czech Republic;King Abdullah University of Science and Technology (KAUST), Thuwal, Saudi Arabia;Nanographics, Vienna, Austria;TU Wien, Vienna, Austria;King Abdullah University of Science and Technology (KAUST), Thuwal, Saudi Arabia",0.1109/tvcg.2020.3030415;10.1109/tvcg.2021.3130670;10.1109/tvcg.2006.152;10.1109/tvcg.2006.124;10.1109/tvcg.2020.2975583;10.1109/tvcg.2013.123;10.1109/tvcg.2020.3030427;10.1109/tvcg.2019.2934395;10.1109/tvcg.2018.2864491;10.1109/tvcg.2017.2744518,"VR immersive,visibility management,,path planning,storytelling,visualization",,6,70,1330,,
TVCG,2024,Visual Exploration of Machine Learning Model Behavior With Hierarchical Surrogate Rule Sets,10.1109/tvcg.2022.3219232,http://dx.doi.org/10.1109/TVCG.2022.3219232,1470,1488,J,"One of the potential solutions for model interpretation is to train a surrogate model: a more transparent model that approximates the behavior of the model to be explained. Typically, classification rules or decision trees are used due to their logic-based expressions. However, decision trees can grow too deep, and rule sets can become too large to approximate a complex model. Unlike paths on a decision tree that must share ancestor nodes (conditions), rules are more flexible. However, the unstructured visual representation of rules makes it hard to make inferences across rules. In this paper, we focus on tabular data and present novel algorithmic and interactive solutions to address these issues. First, we present Hierarchical Surrogate Rules (HSR), an algorithm that generates hierarchical rules based on user-defined parameters. We also contribute SuRE, a visual analytics (VA) system that integrates HSR and an interactive surrogate rule visualization, the Feature-Aligned Tree, which depicts rules as trees while aligning features for easier comparison. We evaluate the algorithm in terms of parameter sensitivity, time performance, and comparison with surrogate decision trees and find that it scales reasonably well and overcomes the shortcomings of surrogate decision trees. We evaluate the visualization and the system through a usability study and an observational study with domain experts. Our investigation shows that the participants can use feature-aligned trees to perform non-trivial tasks with very high accuracy. We also discuss many interesting findings, including a rule analysis task characterization, that can be used for visualization design and future research.",Jun Yuan;Brian Barr;Kyle Overton;Enrico Bertini,Jun Yuan;Brian Barr;Kyle Overton;Enrico Bertini,"New York University, New York, NY, USA;Capital One, McLean, VA, USA;Capital One, McLean, VA, USA;Northeastern University, Boston, MA, USA",0.1109/vast.2011.6102453;10.1109/tvcg.2018.2864812;10.1109/tvcg.2020.3030354;10.1109/tvcg.2018.2864475;10.1109/tvcg.2016.2598829,"Visualization,rule set,,surrogate model,model understanding",,4,51,442,,
TVCG,2022,Persistence Cycles for Visual Exploration of Persistent Homology,10.1109/tvcg.2021.3110663,http://dx.doi.org/10.1109/TVCG.2021.3110663,4966,4979,J,"Persistent homology is a fundamental tool in topological data analysis used for the most diverse applications. Information captured by persistent homology is commonly visualized using scatter plots representations. Despite being widely adopted, such a visualization technique limits user understanding and is prone to misinterpretation. This article proposes a new approach for the efficient computation of persistence cycles, a geometric representation of the features captured by persistent homology. We illustrate the importance of rendering persistence cycles when analyzing scalar fields, and we discuss the advantages that our approach provides compared to other techniques in topology-based visualization. We provide an efficient implementation of our approach based on discrete Morse theory, as a new module for the Topology Toolkit. We show that our implementation has comparable performance with respect to state-of-the-art toolboxes while providing a better framework for visually analyzing persistent homology information.",Federico Iuricich,Federico Iuricich,"School of Computing, Clemson University, Clemson, SC, USA",0.1109/tvcg.2011.284;10.1109/tvcg.2017.2743938;10.1109/visual.2002.1183774;10.1109/tvcg.2020.3030353;10.1109/tvcg.2014.2346434;10.1109/tvcg.2007.70603;10.1109/tvcg.2012.209;10.1109/tvcg.2018.2864848;10.1109/tvcg.2008.110,"Persistent homology,topological data analysis,,scalar fields",,4,85,395,,
TVCG,2023,Roslingifier: Semi-Automated Storytelling for Animated Scatterplots,10.1109/tvcg.2022.3146329,http://dx.doi.org/10.1109/TVCG.2022.3146329,2980,2995,J,"We present Roslingifier, a data-driven storytelling method for animated scatterplots. Like its namesake, Hans Rosling (1948–2017), a professor of public health and a spellbinding public speaker, Roslingifier turns a sequence of entities changing over time—such as countries and continents with their demographic data—into an engaging narrative elling the story of the data. This data-driven storytelling method with an in-person presenter is a new genre of storytelling technique and has never been studied before. In this article, we aim to define a design space for this new genre—data presentation—and provide a semi-automated authoring tool for helping presenters create quality presentations. From an in-depth analysis of video clips of presentations using interactive visualizations, we derive three specific techniques to achieve this: natural language narratives, visual effects that highlight events, and temporal branching that changes playback time of the animation. Our implementation of the Roslingifier method is capable of identifying and clustering significant movements, automatically generating visual highlighting and a narrative for playback, and enabling the user to customize. From two user studies, we show that Roslingifier allows users to effectively create engaging data stories and the system features help both presenters and viewers find diverse insights.",Minjeong Shin;Joohee Kim;Yunha Han;Lexing Xie;Mitchell Whitelaw;Bum Chul Kwon;Sungahn Ko;Niklas Elmqvist,Minjeong Shin;Joohee Kim;Yunha Han;Lexing Xie;Mitchell Whitelaw;Bum Chul Kwon;Sungahn Ko;Niklas Elmqvist,"Australian National University, Canberra, ACT, Australia;Ulsan National Institute of Science and Technology, Ulsan, South Korea;Ulsan National Institute of Science and Technology, Ulsan, South Korea;Australian National University, Canberra, ACT, Australia;Australian National University, Canberra, ACT, Australia;IBM Research, Cambridge, MA, USA;Ulsan National Institute of Science and Technology, Ulsan, South Korea;University of Maryland, Maryland, MD, USA",0.1109/tvcg.2013.119;10.1109/tvcg.2017.2745085;10.1109/tvcg.2008.125;10.1109/mcg.2020.2968249;10.1109/tvcg.2018.2865232;10.1109/tvcg.2010.179;10.1109/tvcg.2011.255;10.1109/tvcg.2016.2598647;10.1109/tvcg.2019.2934398;10.1109/tvcg.2019.2934785;10.1109/tvcg.2016.2598620;10.1109/tvcg.2013.191;10.1109/tvcg.2017.2744118;10.1109/tvcg.2016.2598876;10.1109/vast.2007.4388992;10.1109/tvcg.2016.2598609;10.1109/tvcg.2018.2889054,"Data-driven storytelling,narrative visualization,,hans rosling,gapminder,trendalyzer",,3,56,918,,
TVCG,2023,Automatic Scatterplot Design Optimization for Clustering Identification,10.1109/tvcg.2022.3189883,http://dx.doi.org/10.1109/TVCG.2022.3189883,4312,4327,J,"Scatterplots are among the most widely used visualization techniques. Compelling scatterplot visualizations improve understanding of data by leveraging visual perception to boost awareness when performing specific visual analytic tasks. Design choices in scatterplots, such as graphical encodings or data aspects, can directly impact decision-making quality for low-level tasks like clustering. Hence, constructing frameworks that consider both the perceptions of the visual encodings and the task being performed enables optimizing visualizations to maximize efficacy. In this article, we propose an automatic tool to optimize the design factors of scatterplots to reveal the most salient cluster structure. Our approach leverages the merge tree data structure to identify the clusters and optimize the choice of subsampling algorithm, sampling rate, marker size, and marker opacity used to generate a scatterplot image. We validate our approach with user and case studies that show it efficiently provides high-quality scatterplot designs from a large parameter space.",Ghulam Jilani Quadri;Jennifer Adorno Nieves;Brenton M. Wiernik;Paul Rosen 0001,Ghulam Jilani Quadri;Jennifer Adorno Nieves;Brenton M. Wiernik;Paul Rosen,"Department of Computer Science, University of North Carolina, Chapel Hill, NC, USA;Department of Computer Science and Engineering, University of South Florida, Tampa, FL, USA;Department of Psychology, University of South Florida, Tampa, FL, USA;Scientific Computing and Imaging Institute, University of Utah, Salt Lake City, UT, USA",0.1109/tvcg.2013.65;10.1109/tvcg.2008.119;10.1109/tvcg.2020.3030432;10.1109/tvcg.2018.2864907;10.1109/tvcg.2020.3030365;10.1109/tvcg.2013.183;10.1109/tvcg.2014.2346979;10.1109/tvcg.2019.2934799;10.1109/infvis.2002.1173156;10.1109/tvcg.2014.2346594;10.1109/tvcg.2018.2864912;10.1109/tvcg.2017.2653106;10.1109/tvcg.2020.3030406;10.1109/tvcg.2018.2875702;10.1109/tvcg.2014.2346572;10.1109/infvis.2003.1249019;10.1109/tvcg.2017.2744359;10.1109/tvcg.2007.70535;10.1109/tvcg.2017.2744184;10.1109/tvcg.2017.2744339;10.1109/tvcg.2013.153;10.1109/infvis.2005.1532142;10.1109/tvcg.2015.2467591;10.1109/tvcg.2014.2346983;10.1109/tvcg.2021.3098240;10.1109/tvcg.2016.2598667;10.1109/tvcg.2014.2330617;10.1109/tvcg.2018.2808489;10.1109/tvcg.2017.2744378;10.1109/vast47406.2019.8986943;10.1109/tvcg.2019.2934541;10.1109/vast.2012.6400489;10.1109/tvcg.2017.2744098,"Scatterplot,overdraw,,clustering,design optimization,perception,topological data analysis",,8,110,551,,
TVCG,2024,DMT-EV: An Explainable Deep Network for Dimension Reduction,10.1109/tvcg.2022.3223399,http://dx.doi.org/10.1109/TVCG.2022.3223399,1710,1727,J,"Dimension reduction (DR) is commonly utilized to capture the intrinsic structure and transform high-dimensional data into low-dimensional space while retaining meaningful properties of the original data. It is used in various applications, such as image recognition, single-cell sequencing analysis, and biomarker discovery. However, contemporary parametric-free and parametric DR techniques suffer from several significant shortcomings, such as the inability to preserve global and local features and the poor generalisation performance. On the other hand, regarding explainability, it is crucial to comprehend the embedding process, especially the contribution of each part to the embedding process, while understanding how each feature affects the embedding results that identify critical components and help diagnose the embedding process. To address these problems, we have developed a deep neural network method called DMT-EV, which provides not only excellent performance in structural maintainability but also explainability to the DR therein. DMT-EV starts with data augmentation and a manifold-based loss function to improve embedding performance. The explanation is based on saliency maps and aims to examine the trained DMT-EV parameters and contributions of components during the embedding process. The proposed techniques are integrated with a visual interface to help the user to adjust DMT-EV to achieve better DR performance and explainability. The interactive visual interface makes it easier to illustrate the data features, compare different DR techniques, and investigate DR. An in-depth experimental comparison shows that DMT-EV consistently outperforms the state-of-the-art methods in both performance measures and explainability.",Zelin Zang;Shenghui Cheng;Hanchen Xia;Liangyu Li;Yaoting Sun;Yongjie Xu;Lei Shang;Baigui Sun;Stan Z. Li,Zelin Zang;Shenghui Cheng;Hanchen Xia;Liangyu Li;Yaoting Sun;Yongjie Xu;Lei Shang;Baigui Sun;Stan Z. Li,"AI Division, School of Engineering, Westlake University, Hangzhou, Zhejiang, China;AI Division, School of Engineering, Westlake University, Hangzhou, Zhejiang, China;AI Division, School of Engineering, Westlake University, Hangzhou, Zhejiang, China;AI Division, School of Engineering, Westlake University, Hangzhou, Zhejiang, China;AI Division, School of Engineering, Westlake University, Hangzhou, Zhejiang, China;AI Division, School of Engineering, Westlake University, Hangzhou, Zhejiang, China;Alibaba Group, Hangzhou, China;Alibaba Group, Hangzhou, China;AI Division, School of Engineering, Westlake University, Hangzhou, Zhejiang, China",0.1109/tvcg.2020.2986996;10.1109/tvcg.2015.2467552;10.1109/tvcg.2018.2865194;10.1109/tvcg.2019.2934251;10.1109/tvcg.2018.2846735;10.1109/tvcg.2017.2744358;10.1109/tvcg.2021.3114870;10.1109/tvcg.2015.2467717,"Dimension reduction,explainability of DR models,,deep learning,parametric model",,4,56,1227,,
TVCG,2023,Scientometric Analysis of Interdisciplinary Collaboration and Gender Trends in 30 Years of IEEE VIS Publications,10.1109/tvcg.2022.3158236,http://dx.doi.org/10.1109/TVCG.2022.3158236,3340,3353,J,"We present the results of a scientometric analysis of 30 years of IEEE VIS publications between 1990-2020, in which we conducted a multifaceted analysis of interdisciplinary collaboration and gender composition among authors. To this end, we curated BiblioVIS, a bibliometric dataset that contains rich metadata about IEEE VIS publications, including 3032 articles and 6113 authors. One of the main factors differentiating BiblioVIS from similar datasets is the authors’ gender and discipline data, which we inferred through iterative rounds of computational and manual processes. Our analysis shows that, by and large, inter-institutional and interdisciplinary collaboration has been steadily growing over the past 30 years. However, interdisciplinary research was mainly between a few fields, including Computer Science, Engineering and Technology, and Medicine and Health disciplines. Our analysis of gender shows steady growth in women's authorship. Despite this growth, the gender distribution is still highly skewed, with men dominating ($\approx$≈ 75%) of this space. Our predictive analysis of gender balance shows that if the current trends continue, gender parity in the visualization field will not be reached before the third quarter of the century ($\approx$≈ 2070). Our primary goal in this work is to call the visualization community's attention to the critical topics of collaboration, diversity, and gender. Our research offers critical insights through the lens of diversity and gender to help accelerate progress towards a more diverse and representative research community.",Ali Sarvghad;Rolando Franqui-Nadal;Rebecca Reznik-Zellen;Ria Chawla;Narges Mahyar,Ali Sarvghad;Rolando Franqui-Nadal;Rebecca Reznik-Zellen;Ria Chawla;Narges Mahyar,"University of Massachusetts Amherst, Amherst, MA, USA;University of Massachusetts Amherst, Amherst, MA, USA;University of Massachusetts Amherst, Amherst, MA, USA;University of Massachusetts Amherst, Amherst, MA, USA;University of Massachusetts Amherst, Amherst, MA, USA",0.1109/tvcg.2016.2615308;10.1109/tvcg.2016.2598827;10.1109/tvcg.2021.3114787;10.1109/tvcg.2015.2467621,"Co-authorship,collaboration,,gender,IEEE VIS publications,inter-institutional,interdisciplinary,scientometric",,6,93,440,,
TVCG,2023,Deep Hierarchical Super Resolution for Scientific Data,10.1109/tvcg.2022.3214420,http://dx.doi.org/10.1109/TVCG.2022.3214420,5483,5495,J,"We present a novel technique for hierarchical super resolution (SR) with neural networks (NNs), which upscales volumetric data represented with an octree data structure to a high-resolution uniform gridwith minimal seam artifacts on octree node boundaries. Our method uses existing state-of-the-art SR models and adds flexibility to upscale input data with varying levels of detail across the domain, instead of only uniform grid data that are supported in previous approaches.The key is to use a hierarchy of SR NNs, each trained to perform $2\times$2× SR between two levels of detail, with a hierarchical SR algorithm that minimizes seam artifacts by starting from the coarsest level of detail and working up.We show that our hierarchical approach outperforms baseline interpolation and hierarchical upscaling methods, and demonstrate the usefulness of our proposed approach across three use cases including data reduction using hierarchical downsampling+SR instead of uniform downsampling+SR, computation savings for hierarchical finite-time Lyapunov exponent field calculation, and super-resolving low-resolution simulation results for a high-resolution approximation visualization.",Skylar W. Wurster;Hanqi Guo 0001;Han-Wei Shen;Tom Peterka;Jiayi Xu 0001,Skylar W. Wurster;Hanqi Guo;Han-Wei Shen;Tom Peterka;Jiayi Xu,"Department of Computer Science and Engineering, The Ohio State University, Columbus, OH, USA;Department of Computer Science and Engineering, The Ohio State University, Columbus, OH, USA;Department of Computer Science and Engineering, The Ohio State University, Columbus, OH, USA;Mathematics and Computer Science Division, Argonne National Laboratory, Lemont, IL, USA;Department of Computer Science and Engineering, The Ohio State University, Columbus, OH, USA",0.1109/tvcg.2020.3032123;10.1109/tvcg.2019.2934255;10.1109/tvcg.2021.3114815;10.1109/tvcg.2007.70554;10.1109/tvcg.2020.3030381;10.1109/tvcg.2018.2864850;10.1109/tvcg.2018.2864853;10.1109/tvcg.2019.2956697;10.1109/tvcg.2020.3039340;10.1109/tvcg.2020.3028947;10.1109/tvcg.2012.240;10.1109/tvcg.2019.2934312;10.1109/tvcg.2019.2904063,"Deep learning,super-resolution,,hierarchical data",,5,66,287,,
TVCG,2022,Visualizing Graph Neural Networks With CorGIE: Corresponding a Graph to Its Embedding,10.1109/tvcg.2022.3148197,http://dx.doi.org/10.1109/TVCG.2022.3148197,2500,2516,J,"Graph neural networks (GNNs) are a class of powerful machine learning tools that model node relations for making predictions of nodes or links. GNN developers rely on quantitative metrics of the predictions to evaluate a GNN, but similar to many other neural networks, it is difficult for them to understand if the GNN truly learns characteristics of a graph as expected. We propose an approach to corresponding an input graph to its node embedding (aka latent space), a common component of GNNs that is later used for prediction. We abstract the data and tasks, and develop an interactive multi-view interface called CorGIE to instantiate the abstraction. As the key function in CorGIE, we propose the K-hop graph layout to show topological neighbors in hops and their clustering structure. To evaluate the functionality and usability of CorGIE, we present how to use CorGIE in two usage scenarios, and conduct a case study with five GNN experts. Availability: Open-source code at https://github.com/zipengliu/corgie-ui/, supplemental materials & video at https://osf.io/tr3sb/.",Zipeng Liu;Yang Wang;Jürgen Bernard;Tamara Munzner,Zipeng Liu;Yang Wang;Jürgen Bernard;Tamara Munzner,"College of Software, Beihang University, Beijing, China;Facebook Inc., Menlo Park, CA, USA;Department of Computer Science, University of Zurich, Zürich, Switzerland;Department of Computer Science, University of British Columbia, Vancouver, BC, Canada",0.1109/tvcg.2018.2846735;10.1109/tvcg.2018.2865194;10.1109/tvcg.2015.2467717;10.1109/vast.2018.8802454;10.1109/tvcg.2011.185;10.1109/tvcg.2014.2346248;10.1109/tvcg.2020.3045918;10.1109/tvcg.2008.158;10.1109/tvcg.2006.156;10.1109/tvcg.2018.2843369,"Visualization for machine learning,graph neural network,,graph layout",,5,47,1064,,X
TVCG,2023,Reinforcement Learning for Load-Balanced Parallel Particle Tracing,10.1109/tvcg.2022.3148745,http://dx.doi.org/10.1109/TVCG.2022.3148745,3052,3066,J,"We explore an online reinforcement learning (RL) paradigm to dynamically optimize parallel particle tracing performance in distributed-memory systems. Our method combines three novel components: (1) a work donation algorithm, (2) a high-order workload estimation model, and (3) a communication cost model. First, we design an RL-based work donation algorithm. Our algorithm monitors workloads of processes and creates RL agents to donate data blocks and particles from high-workload processes to low-workload processes to minimize program execution time. The agents learn the donation strategy on the fly based on reward and cost functions designed to consider processes’ workload changes and data transfer costs of donation actions. Second, we propose a workload estimation model, helping RL agents estimate the workload distribution of processes in future computations. Third, we design a communication cost model that considers both block and particle data exchange costs, helping RL agents make effective decisions with minimized communication costs. We demonstrate that our algorithm adapts to different flow behaviors in large-scale fluid dynamics, ocean, and weather simulation data. Our algorithm improves parallel particle tracing performance in terms of parallel efficiency, load balance, and costs of I/O and communication for evaluations with up to 16,384 processors.",Jiayi Xu 0001;Hanqi Guo 0001;Han-Wei Shen;Mukund Raj;Skylar W. Wurster;Tom Peterka,Jiayi Xu;Hanqi Guo;Han-Wei Shen;Mukund Raj;Skylar W. Wurster;Tom Peterka,"Department of Computer Science and Engineering, The Ohio State University, Columbus, OH, USA;Mathematics and Computer Science Division, Argonne National Laboratory, Lemont, IL, USA;Department of Computer Science and Engineering, The Ohio State University, Columbus, OH, USA;Stanley Center for Psychiatric Research, Broad Institute of MIT and Harvard, Cambridge, MA, USA;Department of Computer Science and Engineering, The Ohio State University, Columbus, OH, USA;Mathematics and Computer Science Division, Argonne National Laboratory, Lemont, IL, USA",0.1109/visual.2004.107;10.1109/tvcg.2014.2346418;10.1109/tvcg.2017.2744059;10.1109/tvcg.2010.259;10.1109/tvcg.2011.219;10.1109/tvcg.2013.144;10.1109/visual.1994.346311,"Distributed and parallel particle tracing,dynamic load balancing,,reinforcement learning",,4,78,321,,
TVCG,2023,SD2: Slicing and Dicing Scholarly Data for Interactive Evaluation of Academic Performance,10.1109/tvcg.2022.3163727,http://dx.doi.org/10.1109/TVCG.2022.3163727,3569,3585,J,"Comprehensively evaluating and comparing researchers’ academic performance is complicated due to the intrinsic complexity of scholarly data. Different scholarly evaluation tasks often require the publication and citation data to be investigated in various manners. In this article, we present an interactive visualization framework, SD$^{2}$2, to enable flexible data partition and composition to support various analysis requirements within a single system. SD$^{2}$2 features the hierarchical histogram, a novel visual representation for flexibly slicing and dicing the data, allowing different aspects of scholarly performance to be studied and compared. We also leverage the state-of-the-art set visualization technique to select individual researchers or combine multiple scholars for comprehensive visual comparison. We conduct multiple rounds of expert evaluation to study the effectiveness and usability of SD$^{2}$2 and revise the design and system implementation accordingly. The effectiveness of SD$^{2}$2 is demonstrated via multiple usage scenarios with each aiming to answer a specific, commonly raised question.",Zhichun Guo;Jun Tao 0002;Siming Chen 0001;Nitesh V. Chawla;Chaoli Wang 0001,Zhichun Guo;Jun Tao;Siming Chen;Nitesh V. Chawla;Chaoli Wang,"Visiting Scholar at Sun Yat-sen University, Guangzhou, Guangdong, China;School of Computer Science and Engineering, Sun Yat-sen University and National Supercomputer Center in Guangzhou, Guangzhou, Guangdong, China;School of Data Science, Fudan University, Shanghai, China;Department of Computer Science and Engineering, University of Notre Dame, Notre Dame, IN, USA;Department of Computer Science and Engineering, University of Notre Dame, Notre Dame, IN, USA",0.1109/tvcg.2007.70589;10.1109/tvcg.2017.2723393;10.1109/tvcg.2015.2468151;10.1109/tvcg.2009.108;10.1109/tvcg.2016.2615308;10.1109/tvcg.2015.2467621;10.1109/tvcg.2014.2346248;10.1109/tvcg.2009.202;10.1109/tvcg.2019.2934535;10.1109/vast47406.2019.8986934;10.1109/tvcg.2019.2898186;10.1109/infvis.2000.885091;10.1109/tvcg.2007.70529;10.1109/tvcg.2015.2467733;10.1109/mcg.2015.73,"Scholarly performance,publication,,citation,hierarchical histogram,visual analytics",,3,39,342,,
TVCG,2023,Geometry-Aware Planar Embedding of Treelike Structures,10.1109/tvcg.2022.3153871,http://dx.doi.org/10.1109/TVCG.2022.3153871,3182,3194,J,"The growing complexity of spatial and structural information in 3D data makes data inspection and visualization a challenging task. We describe a method to create a planar embedding of 3D treelike structures using their skeleton representations. Our method maintains the original geometry, without overlaps, to the best extent possible, allowing exploration of the topology within a single view. We present a novel camera view generation method which maximizes the visible geometric attributes (segment shape and relative placement between segments). Camera views are created for individual segments and are used to determine local bending angles at each node by projecting them to 2D. The final embedding is generated by minimizing an energy function (the weights of which are user adjustable) based on branch length and the 2D angles, while avoiding intersections. The user can also interactively modify segment placement within the 2D embedding, and the overall embedding will update accordingly. A global to local interactive exploration is provided using hierarchical camera views that are created for subtrees within the structure. We evaluate our method both qualitatively and quantitatively and demonstrate our results by constructing planar visualizations of line data (traced neurons) and volume data (CT vascular and bronchial data).",Ping Hu;Saeed Boorboor;Joseph Marino;Arie E. Kaufman,Ping Hu;Saeed Boorboor;Joseph Marino;Arie E. Kaufman,"Department of Computer Science, Stony Brook University, Stony Brook, NY, USA;Department of Computer Science, Stony Brook University, Stony Brook, NY, USA;Department of Computer Science, Stony Brook University, Stony Brook, NY, USA;Department of Computer Science, Stony Brook University, Stony Brook, NY, USA",0.1109/tvcg.2017.2744278;10.1109/tvcg.2018.2864852;10.1109/tvcg.2021.3109460;10.1109/visual.2003.1250353;10.1109/visual.2002.1183754;10.1109/tvcg.2021.3127132;10.1109/tvcg.2007.70596;10.1109/tvcg.2015.2467413;10.1109/visual.2002.1183826;10.1109/tvcg.2006.137;10.1109/visual.2001.964538;10.1109/tvcg.2011.192;10.1109/tvcg.2014.2346312;10.1109/tvcg.2013.215;10.1109/tvcg.2011.235,"Geometry-based techniques,camera view generation,,planar embedding,biomedical visualization",,3,56,335,,
TVCG,2023,Revisiting the Design Patterns of Composite Visualizations,10.1109/tvcg.2022.3213565,http://dx.doi.org/10.1109/TVCG.2022.3213565,5406,5421,J,"Composite visualization is a popular design strategy that represents complex datasets by integrating multiple visualizations in a meaningful and aesthetic layout, such as juxtaposition, overlay, and nesting. With this strategy, numerous novel designs have been proposed in visualization publications to accomplish various visual analytic tasks. However, there is a lack of understanding of design patterns of composite visualization, thus failing to provide holistic design space and concrete examples for practical use. In this article, we opted to revisit the composite visualizations in IEEE VIS publications and answered what and how visualizations of different types are composed together. To achieve this, we first constructed a corpus of composite visualizations from the publications and analyzed common practices, such as the pattern distributions and co-occurrence of visualization types. From the analysis, we obtained insights into different design patterns on the utilities and their potential pros and cons. Furthermore, we discussed usage scenarios of our taxonomy and corpus and how future research on visualization composition can be conducted on the basis of this study.",Dazhen Deng;Weiwei Cui;Xiyu Meng;Mengye Xu;Yu Liao;Haidong Zhang;Yingcai Wu,Dazhen Deng;Weiwei Cui;Xiyu Meng;Mengye Xu;Yu Liao;Haidong Zhang;Yingcai Wu,"State Key Lab of CAD&CG, Zhejiang University, Hangzhou, Zhejiang, China;Microsoft Research Asia, Beijing, China;State Key Lab of CAD&CG, Zhejiang University, Hangzhou, Zhejiang, China;State Key Lab of CAD&CG, Zhejiang University, Hangzhou, Zhejiang, China;State Key Lab of CAD&CG, Zhejiang University, Hangzhou, Zhejiang, China;Microsoft Research Asia, Beijing, China;State Key Lab of CAD&CG, Zhejiang University, Hangzhou, Zhejiang, China",0.1109/tvcg.2020.3030419;10.1109/tvcg.2020.3030338;10.1109/tvcg.2019.2934398;10.1109/tvcg.2020.3030403;10.1109/tvcg.2017.2744199;10.1109/tvcg.2016.2599030;10.1109/tvcg.2009.179;10.1109/tvcg.2021.3054916;10.1109/tvcg.2022.3155440;10.1109/tvcg.2010.183;10.1109/infvis.2000.885092;10.1109/tvcg.2013.234;10.1109/tvcg.2015.2466992;10.1109/tvcg.2017.2744098;10.1109/tvcg.2009.146;10.1109/tvcg.2017.2744378;10.1109/tvcg.2017.2745080;10.1109/tvcg.2018.2865041;10.1109/tvcg.2018.2865126;10.1109/tvcg.2017.2744683;10.1109/tvcg.2013.173;10.1109/tvcg.2009.153;10.1109/tvcg.2014.2346260;10.1109/tvcg.2018.2864884;10.1109/vast.2015.7347677;10.1109/tvcg.2014.2346454;10.1109/tvcg.2015.2467911;10.1109/vast.2010.5652478;10.1109/tvcg.2017.2744419;10.1109/tvcg.2018.2864811;10.1109/vast.2011.6102476;10.1109/vast.2014.7042484;10.1109/tvcg.2014.2346920;10.1109/tvcg.2018.2865018;10.1109/tvcg.2018.2865051;10.1109/tvcg.2006.160;10.1109/vast.2011.6102479;10.1109/vast.2011.6102451;10.1109/tvcg.2018.2864913;10.1109/vast.2009.5333420;10.1109/tvcg.2016.2598664;10.1109/tvcg.2018.2864504;10.1109/vast.2015.7347633;10.1109/tvcg.2020.3030461;10.1109/vast50239.2020.00014;10.1109/tvcg.2015.2467619;10.1109/tvcg.2011.160;10.1109/vast.2007.4388996;10.1109/tvcg.2017.2745320;10.1109/tvcg.2011.183;10.1109/vast.2017.8585721;10.1109/tvcg.2008.141;10.1109/tvcg.2013.184;10.1109/tvcg.2018.2864814;10.1109/tvcg.2018.2864475;10.1109/tvcg.2016.2535234;10.1109/tvcg.2021.3099002;10.1109/tvcg.2011.185;10.1109/tvcg.2015.2467091;10.1109/tvcg.2017.2785807;10.1109/tvcg.2013.124;10.1109/tvcg.2022.3209360;10.1109/infvis.2005.1532136;10.1109/tvcg.2018.2829750;10.1109/tvcg.2020.3030428;10.1109/tvcg.2009.122;10.1109/tvcg.2012.291;10.1109/vast.2008.4677365,"Datasets,visual analytics,,visualization specification,visualization design",,4,108,668,,
TVCG,2023,ClinicalPath: A Visualization Tool to Improve the Evaluation of Electronic Health Records in Clinical Decision-Making,10.1109/tvcg.2022.3175626,http://dx.doi.org/10.1109/TVCG.2022.3175626,4031,4046,J,"Physicians work at a very tight schedule and need decision-making support tools to help on improving and doing their work in a timely and dependable manner. Examining piles of sheets with test results and using systems with little visualization support to provide diagnostics is daunting, but that is still the usual way for the physicians’ daily procedure, especially in developing countries. Electronic Health Records systems have been designed to keep the patients’ history and reduce the time spent analyzing the patient's data. However, better tools to support decision-making are still needed. In this article, we propose ClinicalPath, a visualization tool for users to track a patient's clinical path through a series of tests and data, which can aid in treatments and diagnoses. Our proposal is focused on patient's data analysis, presenting the test results and clinical history longitudinally. Both the visualization design and the system functionality were developed in close collaboration with experts in the medical domain to ensure a right fit of the technical solutions and the real needs of the professionals. We validated the proposed visualization based on case studies and user assessments through tasks based on the physician's daily activities. Our results show that our proposed system improves the physicians’ experience in decision-making tasks, made with more confidence and better usage of the physicians’ time, allowing them to take other needed care for the patients.",Claudio D. G. Linhares;Daniel Mario de Lima;Jean R. Ponciano;Mauro M. Olivatto;Marco A. Gutierrez 0001;Jorge Poco;Caetano Traina;Agma J. M. Traina,Claudio D. G. Linhares;Daniel M. Lima;Jean R. Ponciano;Mauro M. Olivatto;Marco A. Gutierrez;Jorge Poco;Caetano Traina;Agma J. M. Traina,"Institute of Mathematics and Computer Sciences, University of São Paulo, São Carlos, Brazil;Institute of Mathematics and Computer Sciences, University of São Paulo, São Carlos, Brazil;School of Applied Mathematics, Getulio Vargas Foundation, Rio de Janeiro, Brazil;Graduate Course in Medicine, Federal University of Fronteira Sul, Chapecó, Brazil;Laboratorio de Informatica Biomedica, Instituto do Coracao, Hospital das Clinicas HCFMUSP, Faculdade de Medicina, Universidade de Sao Paulo, Sao Paulo, Brazil;School of Applied Mathematics, Getulio Vargas Foundation, Rio de Janeiro, Brazil;Institute of Mathematics and Computer Sciences, University of São Paulo, São Carlos, Brazil;Institute of Mathematics and Computer Sciences, University of São Paulo, São Carlos, Brazil",0.1109/tvcg.2021.3114810;10.1109/tvcg.2018.2864905;10.1109/tvcg.2016.2598468;10.1109/tvcg.2013.224;10.1109/tvcg.2018.2865027;10.1109/tvcg.2009.187;10.1109/vast.2009.5332595;10.1109/tvcg.2013.124;10.1109/tvcg.2018.2865119,"Information visualization,interactive visualizations,,human-computer interaction,electronic health records",,4,43,1431,,
TVCG,2023,Dynamic Mode Decomposition for Large-Scale Coherent Structure Extraction in Shear Flows,10.1109/tvcg.2021.3124729,http://dx.doi.org/10.1109/TVCG.2021.3124729,1531,1544,J,"Large-scale structures have been observed in many shear flows which are the fluid generated between two surfaces moving with different velocity. A better understanding of the physics of the structures (especially large-scale structures) in shear flows will help explain a diverse range of physical phenomena and improve our capability of modeling more complex turbulence flows. Many efforts have been made in order to capture such structures; however, conventional methods have their limitations, such as arbitrariness in parameter choice or specificity to certain setups. To address this challenge, we propose to use Multi-Resolution Dynamic Mode Decomposition (mrDMD), for large-scale structure extraction in shear flows. In particular, we show that the slow motion DMD modes are able to reveal large-scale structures in shear flows that also have slow dynamics. In most cases, we find that the slowest DMD mode and its reconstructed flow can sufficiently capture the large-scale dynamics in the shear flows, which leads to a parameter-free strategy for large-scale structure extraction. Effective visualization of the large-scale structures can then be produced with the aid of the slowest DMD mode. To speed up the computation of mrDMD, we provide a fast GPU-based implementation. We also apply our method to some non-shear flows that need not behave quasi-linearly to demonstrate the limitation of our strategy of using the slowest DMD mode. For non-shear flows, we show that multiple modes from different levels of mrDMD may be needed to sufficiently characterize the flow behavior.",Duong B. Nguyen;Panruo Wu;Rodolfo Ostilla Monico;Guoning Chen,Duong B. Nguyen;Panruo Wu;Rodolfo Ostilla Monico;Guoning Chen,"University of Houston, Houston, TX, USA;University of Houston, Houston, TX, USA;University of Houston, Houston, TX, USA;University of Houston, Houston, TX, USA",0.1109/tvcg.2018.2864817;10.1109/tvcg.2007.70551;10.1109/tvcg.2020.3028892;10.1109/tvcg.2007.70554;10.1109/tvcg.2012.274;10.1109/tvcg.2010.198,"Flow visualization,shear flows,,dynamic mode decomposition",,5,58,395,,
TVCG,2023,Team-Builder: Toward More Effective Lineup Selection in Soccer,10.1109/tvcg.2022.3207147,http://dx.doi.org/10.1109/TVCG.2022.3207147,5178,5193,J,"Lineup selection is an essential and important task in soccer matches. To win a match, coaches must consider various factors and select appropriate players for a planned formation. Computation-based tools have been proposed to help coaches on this complex task, but they are usually based on over-simplified models on player performances, do not support interactive analysis, and overlook the inputs by coaches. In this article, we propose a method for visual analytics of soccer lineup selection by tackling two challenges: characterizing essential factors involved in generating optimal lineup, and supporting coach-driven visual analytics of lineup selection. We develop a lineup selection model that integrates such important factors, such as spatial regions of player actions and defensive interactions with opponent players. A visualization system, Team-Builder, is developed to help coaches control the process of lineup generation, explanation, and comparison through multiple coordinated views. The usefulness and effectiveness of our system are demonstrated by two case studies on a real-world soccer event dataset.",Anqi Cao;Ji Lan;Xiao Xie;Hongyu Chen;Xiaolong Zhang;Hui Zhang 0051;Yingcai Wu,Anqi Cao;Ji Lan;Xiao Xie;Hongyu Chen;Xiaolong Zhang;Hui Zhang;Yingcai Wu,"State Key Lab of CAD&CG, Zhejiang University, Hangzhou, China;State Key Lab of CAD&CG, Zhejiang University, Hangzhou, China;Department of Sports Science, Zhejiang University, Hangzhou, China;State Key Lab of CAD&CG, Zhejiang University, Hangzhou, China;College of Information Sciences and Technology, Pennsylvania State University, State College, PA, USA;Department of Sports Science, Zhejiang University, Hangzhou, China;State Key Lab of CAD&CG, Zhejiang University, Hangzhou, China",0.1109/tvcg.2019.2952129;10.1109/tvcg.2018.2865041;10.1109/tvcg.2020.3030359;10.1109/mcg.2016.124;10.1109/mcg.2016.101;10.1109/vast.2014.7042478;10.1109/tvcg.2019.2934243;10.1109/tvcg.2020.3030392;10.1109/tvcg.2021.3114832;10.1109/tvcg.2012.263;10.1109/mcg.2016.100;10.1109/tvcg.2013.192;10.1109/mcg.2016.102;10.1109/tvcg.2017.2745181;10.1109/vast.2014.7042477,"Sports visualization,lineup selection,,design study",,2,61,513,,
TVCG,2022,Interpretable Anomaly Detection in Event Sequences via Sequence Matching and Visual Comparison,10.1109/tvcg.2021.3093585,http://dx.doi.org/10.1109/TVCG.2021.3093585,4531,4545,J,"Anomaly detection is a common analytical task that aims to identify rare cases that differ from the typical cases that make up the majority of a dataset. When analyzing event sequence data, the task of anomaly detection can be complex because the sequential and temporal nature of such data results in diverse definitions and flexible forms of anomalies. This, in turn, increases the difficulty in interpreting detected anomalies. In this article, we propose a visual analytic approach for detecting anomalous sequences in an event sequence dataset via an unsupervised anomaly detection algorithm based on Variational AutoEncoders. We further compare the anomalous sequences with their reconstructions and with the normal sequences through a sequence matching algorithm to identify event anomalies. A visual analytics system is developed to support interactive exploration and interpretations of anomalies through novel visualization designs that facilitate the comparison between anomalous sequences and normal sequences. Finally, we quantitatively evaluate the performance of our anomaly detection algorithm, demonstrate the effectiveness of our system through case studies, and report feedback collected from study participants.",Shunan Guo;Zhuochen Jin;Qing Chen 0001;David Gotz;Hongyuan Zha;Nan Cao 0001,Shunan Guo;Zhuochen Jin;Qing Chen;David Gotz;Hongyuan Zha;Nan Cao,"Intelligent Big Data Visualization Lab, Tongji University, Shanghai, China;Intelligent Big Data Visualization Lab, Tongji University, Shanghai, China;Intelligent Big Data Visualization Lab, Tongji University, Shanghai, China;University of North Carolina at Chapel Hill, Chapel Hill, NC, USA;East China Normal University, Shanghai, China;Intelligent Big Data Visualization Lab, Tongji University, Shanghai, China",0.1109/tvcg.2013.200;10.1109/tvcg.2014.2346922;10.1109/vast.2012.6400557;10.1109/scivis.2015.7429487;10.1109/tvcg.2017.2744419;10.1109/tvcg.2019.2934661;10.1109/tvcg.2018.2864885;10.1109/vast.2009.5332595;10.1109/tvcg.2012.110;10.1109/tvcg.2017.2745320;10.1109/tvcg.2014.2346682;10.1109/vast.2016.7883512;10.1109/tvcg.2007.70529;10.1109/tvcg.2013.122;10.1109/tvcg.2013.231,"Event sequences,visual analytics,,anomaly detection",,3,65,1111,,
TVCG,2023,GUCCI - Guided Cardiac Cohort Investigation of Blood Flow Data,10.1109/tvcg.2021.3134083,http://dx.doi.org/10.1109/TVCG.2021.3134083,1876,1892,J,"We present the framework GUCCI (Guided Cardiac Cohort Investigation), which provides a guided visual analytics workflow to analyze cohort-based measured blood flow data in the aorta. In the past, many specialized techniques have been developed for the visual exploration of such data sets for a better understanding of the influence of morphological and hemodynamic conditions on cardiovascular diseases. However, there is a lack of dedicated techniques that allow visual comparison of multiple data sets and defined cohorts, which is essential to characterize pathologies. GUCCI offers visual analytics techniques and novel visualization methods to guide the user through the comparison of predefined cohorts, such as healthy volunteers and patients with a pathologically altered aorta. The combination of overview and glyph-based depictions together with statistical cohort-specific information allows investigating differences and similarities of the time-dependent data. Our framework was evaluated in a qualitative user study with three radiologists specialized in cardiac imaging and two experts in medical blood flow visualization. They were able to discover cohort-specific characteristics, which supports the derivation of standard values as well as the assessment of pathology-related severity and the need for treatment.",Monique Meuschke;Uli Niemann;Benjamin Behrendt;Matthias Gutberlet;Bernhard Preim;Kai Lawonn,Monique Meuschke;Uli Niemann;Benjamin Behrendt;Matthias Gutberlet;Bernhard Preim;Kai Lawonn,"Department of Simulation and Graphics, University of Magdeburg, Magdeburg, Germany;University of Magdeburg, Magdeburg, Germany;University of Magdeburg, Magdeburg, Germany;University of Leipzig – Heart Centre, Leipzig, Germany;Department of Simulation and Graphics, University of Magdeburg, Magdeburg, Germany;Department of Theoretical Computer Science, University of Jena, Jena, Germany",0.1109/visual.2000.885739;10.1109/tvcg.2016.2598866;10.1109/tvcg.2018.2864509;10.1109/tvcg.2015.2467622;10.1109/tvcg.2013.224;10.1109/tvcg.2016.2598468;10.1109/tvcg.2012.110;10.1109/tvcg.2006.170,"Medical visualization,cohort analysis,,measured blood flow data,cardiac diseases",,3,59,497,,
TVCG,2023,LegalVis: Exploring and Inferring Precedent Citations in Legal Documents,10.1109/tvcg.2022.3152450,http://dx.doi.org/10.1109/TVCG.2022.3152450,3105,3120,J,"To reduce the number of pending cases and conflicting rulings in the Brazilian Judiciary, the National Congress amended the Constitution, allowing the Brazilian Supreme Court (STF) to create binding precedents (BPs), i.e., a set of understandings that both Executive and lower Judiciary branches must follow. The STF’s justices frequently cite the 58 existing BPs in their decisions, and it is of primary relevance that judicial experts could identify and analyze such citations. To assist in this problem, we propose LegalVis, a web-based visual analytics system designed to support the analysis of legal documents that cite or could potentially cite a BP. We model the problem of identifying potential citations (i.e., non-explicit) as a classification problem. However, a simple score is not enough to explain the results; that is why we use an interpretability machine learning method to explain the reason behind each identified citation. For a compelling visual exploration of documents and BPs, LegalVis comprises three interactive visual components: the first presents an overview of the data showing temporal patterns, the second allows filtering and grouping relevant documents by topic, and the last one shows a document’s text aiming to interpret the model’s output by pointing out which paragraphs are likely to mention the BP, even if not explicitly specified. We evaluated our identification model and obtained an accuracy of 96%; we also made a quantitative and qualitative analysis of the results. The usefulness and effectiveness of LegalVis were evaluated through two usage scenarios and feedback from six domain experts.",Lucas E. Resck;Jean R. Ponciano;Luis Gustavo Nonato;Jorge Poco,Lucas E. Resck;Jean R. Ponciano;Luis Gustavo Nonato;Jorge Poco,"Fundação Getulio Vargas, Rio de Janeiro, Brazil;Fundação Getulio Vargas, Rio de Janeiro, Brazil;ICMC-USP, São Carlos, Brazil;Fundação Getulio Vargas, Rio de Janeiro, Brazil",0.1109/tvcg.2020.3028975;10.1109/tvcg.2020.3030425,"Legal documents,visual analytics,,Brazilian legal system,natural language processing",,3,75,551,,
TVCG,2023,Principal Geodesic Analysis of Merge Trees (and Persistence Diagrams),10.1109/tvcg.2022.3215001,http://dx.doi.org/10.1109/TVCG.2022.3215001,1573,1589,J,"This article presents a computational framework for the Principal Geodesic Analysis of merge trees (MT-PGA), a novel adaptation of the celebrated Principal Component Analysis (PCA) framework (K. Pearson 1901) to the Wasserstein metric space of merge trees (Pont et al. 2022). We formulate MT-PGA computation as a constrained optimization problem, aiming at adjusting a basis of orthogonal geodesic axes, while minimizing a fitting energy. We introduce an efficient, iterative algorithm which exploits shared-memory parallelism, as well as an analytic expression of the fitting energy gradient, to ensure fast iterations. Our approach also trivially extends to extremum persistence diagrams. Extensive experiments on public ensembles demonstrate the efficiency of our approach – with MT-PGA computations in the orders of minutes for the largest examples. We show the utility of our contributions by extending to merge trees two typical PCA applications. First, we apply MT-PGA to data reduction and reliably compress merge trees by concisely representing them by their first coordinates in the MT-PGA basis. Second, we present a dimensionality reduction framework exploiting the first two directions of the MT-PGA basis to generate two-dimensional layouts of the ensemble. We augment these layouts with persistence correlation views, enabling global and local visual inspections of the feature variability in the ensemble. In both applications, quantitative experiments assess the relevance of our framework. Finally, we provide a C++ implementation that can be used to reproduce our results.",Mathieu Pont;Jules Vidal;Julien Tierny,Mathieu Pont;Jules Vidal;Julien Tierny,"CNRS and Sorbonne Université, Paris, France;CNRS and Sorbonne Université, Paris, France;CNRS and Sorbonne Université, Paris, France",0.1109/tvcg.2013.208;10.1109/tvcg.2018.2864505;10.1109/tvcg.2015.2467958;10.1109/tvcg.2020.3022359;10.1109/tvcg.2017.2743980;10.1109/visual.2004.96;10.1109/tvcg.2012.115;10.1109/tvcg.2018.2864432;10.1109/tvcg.2015.2467204;10.1109/tvcg.2014.2346403;10.1109/tvcg.2018.2864848;10.1109/tvcg.2007.70603;10.1109/tvcg.2015.2467432;10.1109/tvcg.2013.141;10.1109/tvcg.2011.249;10.1109/tvcg.2006.186;10.1109/tvcg.2014.2346455;10.1109/tvcg.2013.92;10.1109/tvcg.2021.3114839;10.1109/tvcg.2010.181;10.1109/tvcg.2012.249;10.1109/tvcg.2018.2873612;10.1109/tvcg.2017.2743938;10.1109/tvcg.2009.163;10.1109/tvcg.2019.2934256;10.1109/tvcg.2013.143;10.1109/tvcg.2019.2934242,"Topological data analysis,ensemble data,,merge trees,persistence diagrams",,3,123,238,,X
TVCG,2022,Influence Maximization With Visual Analytics,10.1109/tvcg.2022.3190623,http://dx.doi.org/10.1109/TVCG.2022.3190623,3428,3440,J,"In social networks, individuals’ decisions are strongly influenced by recommendations from their friends, acquaintances, and favorite renowned personalities. The popularity of online social networking platforms makes them the prime venues to advertise products and promote opinions. The Influence Maximization (IM) problem entails selecting a seed set of users that maximizes the influence spread, i.e., the expected number of users positively influenced by a stochastic diffusion process triggered by the seeds. Engineering and analyzing IM algorithms remains a difficult and demanding task due to the NP-hardness of the problem and the stochastic nature of the diffusion processes. Despite several heuristics being introduced, they often fail in providing enough information on how the network topology affects the diffusion process, precious insights that could help researchers improve their seed set selection. In this paper, we present VAIM, a visual analytics system that supports users in analyzing, evaluating, and comparing information diffusion processes determined by different IM algorithms. Furthermore, VAIM provides useful insights that the analyst can use to modify the seed set of an IM algorithm, so to improve its influence spread. We assess our system by: $(i)$(i) a qualitative evaluation based on a guided experiment with two domain experts on two different data sets; $(ii)$(ii) a quantitative estimation of the value of the proposed visualization through the ICE-T methodology by Wall et al. (IEEE TVCG - 2018). The twofold assessment indicates that VAIM effectively supports our target users in the visual analysis of the performance of IM algorithms.",Alessio Arleo;Walter Didimo;Giuseppe Liotta;Silvia Miksch;Fabrizio Montecchiani,Alessio Arleo;Walter Didimo;Giuseppe Liotta;Silvia Miksch;Fabrizio Montecchiani,"Centre for Visual Analytics Science and Technology, TU Wien, Vienna, Austria;Engineering Department, University of Perugia, Perugia, Italy;Engineering Department, University of Perugia, Perugia, Italy;Centre for Visual Analytics Science and Technology, TU Wien, Vienna, Austria;Engineering Department, University of Perugia, Perugia, Italy",0.1109/tvcg.2010.82;10.1109/tvcg.2008.141;10.1109/tvcg.2008.151;10.1109/tvcg.2016.2598468;10.1109/vast.2011.6102457;10.1109/vast.2015.7347626;10.1109/tvcg.2011.185;10.1109/tvcg.2007.70582;10.1109/tvcg.2012.291;10.1109/tvcg.2014.2346920;10.1109/tvcg.2014.2346922;10.1109/vast.2016.7883510;10.1109/tvcg.2018.2865146,"Information visualization,visualization systems and software,,influence maximization,visual analytics,information diffusion",,2,63,1234,,X
TVCG,2024,Discrete Morse Sandwich: Fast Computation of Persistence Diagrams for Scalar Data – An Algorithm and a Benchmark,10.1109/tvcg.2023.3238008,http://dx.doi.org/10.1109/TVCG.2023.3238008,1897,1915,J,"This paper introduces an efficient algorithm for persistence diagram computation, given an input piecewise linear scalar field $f$f defined on a $d$d-dimensional simplicial complex $\mathcal {K}$K, with $d \leq 3$d≤3. Our work revisits the seminal algorithm “PairSimplices” (Edelsbrunner et al. 2002), (Zomorodian, 2010) with discrete Morse theory (DMT) (Forman, 1998), (Robins et al. 2011), which greatly reduces the number of input simplices to consider. Further, we also extend to DMT and accelerate the stratification strategy described in “PairSimplices” (Edelsbrunner et al. 2002), (Zomorodian, 2010) for the fast computation of the $0^{th}$ and $(d-1)^{th}$(d-1)th diagrams, noted $\mathcal {D}_{0}(f)$D0(f) and $\mathcal {D}_{d-1}(f)$Dd-1(f). Minima-saddle persistence pairs ($\mathcal {D}_{0}(f)$D0(f)) and saddle-maximum persistence pairs ($\mathcal {D}_{d-1}(f)$Dd-1(f)) are efficiently computed by processing, with a Union-Find, the unstable sets of 1-saddles and the stable sets of $(d-1)$(d-1)-saddles. This fast pre-computation for the dimensions 0 and $(d-1)$(d-1) enables an aggressive specialization of (Bauer et al. 2014) to the 3D case, which results in a drastic reduction of the number of input simplices for the computation of $\mathcal {D}_{1}(f)$D1(f), the intermediate layer of the sandwich. Finally, we document several performance improvements via shared-memory parallelism. We provide an open-source implementation of our algorithm for reproducibility purposes. Extensive experiments indicate that our algorithm improves by two orders of magnitude the time performance of the seminal “PairSimplices” algorithm it extends. Moreover, it also improves memory footprint and time performance over a selection of 14 competing approaches, with a substantial gain over the fastest available approaches, while producing a strictly identical output.",Pierre Guillou;Jules Vidal;Julien Tierny,Pierre Guillou;Jules Vidal;Julien Tierny,"CNRS and Sorbonne Université, Paris, France;CNRS and Sorbonne Université, Paris, France;CNRS and Sorbonne Université, Paris, France",0.1109/tvcg.2017.2743980;10.1109/visual.2004.96;10.1109/tvcg.2020.3030441;10.1109/tvcg.2018.2864432;10.1109/tvcg.2014.2346403;10.1109/tvcg.2018.2864848;10.1109/tvcg.2008.110;10.1109/tvcg.2014.2346434;10.1109/tvcg.2007.70603;10.1109/tvcg.2011.249;10.1109/tvcg.2006.186;10.1109/tvcg.2020.3030353;10.1109/tvcg.2019.2934368;10.1109/tvcg.2011.284;10.1109/tvcg.2019.2934802;10.1109/tvcg.2012.228;10.1109/tvcg.2019.2934256;10.1109/tvcg.2021.3060500,"discrete Morse theory,persistence diagrams,,scalar data,Topological data analysis",,2,103,231,,X
TVCG,2023,EBBE-Text: Explaining Neural Networks by Exploring Text Classification Decision Boundaries,10.1109/tvcg.2022.3184247,http://dx.doi.org/10.1109/TVCG.2022.3184247,4154,4171,J,"While neural networks (NN) have been successfully applied to many NLP tasks, the way they function is often difficult to interpret. In this article, we focus on binary text classification via NNs and propose a new tool, which includes a visualization of the decision boundary and the distances of data elements to this boundary. This tool increases the interpretability of NN. Our approach uses two innovative views: (1) an overview of the text representation space and (2) a local view allowing data exploration around the decision boundary for various localities of this representation space. These views are integrated into a visual platform, EBBE-Text, which also contains state-of-the-art visualizations of NN representation spaces and several kinds of information obtained from the classification process. The various views are linked through numerous interactive functionalities that enable easy exploration of texts and classification results via the various complementary views. A user study shows the effectiveness of the visual encoding and a case study illustrates the benefits of using our tool for the analysis of the classifications obtained with several recent NNs and two datasets.",Alexis Delaforge;Jérôme Azé;Sandra Bringay;Caroline Mollevi;Arnaud Sallaberry;Maximilien Servajean,Alexis Delaforge;Jérôme Azé;Sandra Bringay;Caroline Mollevi;Arnaud Sallaberry;Maximilien Servajean,"LIRMM, CNRS, University of Montpellier, Montpellier, France;LIRMM, CNRS, University of Montpellier, Montpellier, France;LIRMM, AMIS research group of the Paul Valéry, CNRS, University of Montpellier, Montpellier, France;ICM, IDESP, INSERM, University of Montpellier, Montpellier, France;LIRMM, AMIS research group of the Paul Valéry, CNRS, University of Montpellier, Montpellier, France;LIRMM, AMIS research group of the Paul Valéry, CNRS, University of Montpellier, Montpellier, France",0.1109/tvcg.2018.2843369;10.1109/tvcg.2020.3028976;10.1109/tvcg.2017.2744718;10.1109/tvcg.2017.2744358;10.1109/tvcg.2018.2865044;10.1109/tvcg.2017.2744158;10.1109/tvcg.2012.277;10.1109/tvcg.2018.2864499;10.1109/tvcg.2020.3011155;10.1109/tvcg.2018.2865146,"Binary text classification,decision boundary,,deep learning,interpretability,neural networks,representation space,visual analytics",,2,73,500,,
TVCG,2023,VividGraph: Learning to Extract and Redesign Network Graphs From Visualization Images,10.1109/tvcg.2022.3153514,http://dx.doi.org/10.1109/TVCG.2022.3153514,3169,3181,J,"Network graphs are common visualization charts. They often appear in the form of bitmaps in articles, web pages, magazine prints, and designer sketches. People often want to modify graphs because of their poor design, but it is difficult to obtain their underlying data. In this article, we present VividGraph, a pipeline for automatically extracting and redesigning graphs from static images. We propose using convolutional neural networks to solve the problem of graph data extraction. Our method is robust to hand-drawn graphs, blurred graph images, and large graph images. We also present a graph classification module to make it effective for directed graphs. We propose two evaluation methods to demonstrate the effectiveness of our approach. It can be used to quickly transform designer sketches, extract underlying data from existing graphs, and interactively redesign poorly designed graphs.",Sicheng Song;Chenhui Li;Yujing Sun;Changbo Wang,Sicheng Song;Chenhui Li;Yujing Sun;Changbo Wang,"School of Computer Science and Technology, East China Normal University, Shanghai, China;School of Computer Science and Technology, East China Normal University, Shanghai, China;School of Computer Science and Technology, East China Normal University, Shanghai, China;School of Computer Science and Technology, East China Normal University, Shanghai, China",0.1109/tvcg.2011.185;10.1109/tvcg.2017.2744320;10.1109/tvcg.2018.2865138;10.1109/tvcg.2020.3030343;10.1109/infvis.2002.1173155;10.1109/tvcg.2008.118;10.1109/tvcg.2018.2875702;10.1109/mcg.2018.2881501;10.1109/tvcg.2012.229,"Information visualization,network graph,,data extraction,chart recognition,semantic segmentation,redesign",,4,57,925,,
TVCG,2023,Local Latent Representation Based on Geometric Convolution for Particle Data Feature Exploration,10.1109/tvcg.2022.3159114,http://dx.doi.org/10.1109/TVCG.2022.3159114,3354,3367,J,"Feature related particle data analysis plays an important role in many scientific applications such as fluid simulations, cosmology simulations and molecular dynamics. Compared to conventional methods that use hand-crafted feature descriptors, some recent studies focus on transforming the data into a new latent space, where features are easier to be identified, compared and extracted. However, it is challenging to transform particle data into latent representations, since the convolution neural networks used in prior studies require the data presented in regular grids. In this article, we adopt Geometric Convolution, a neural network building block designed for 3D point clouds, to create latent representations for scientific particle data. These latent representations capture both the particle positions and their physical attributes in the local neighborhood so that features can be extracted by clustering in the latent space, and tracked by applying tracking algorithms such as mean-shift. We validate the extracted features and tracking results from our approach using datasets from three applications and show that they are comparable to the methods that define hand-crafted features for each specific dataset.",Haoyu Li;Han-Wei Shen,Haoyu Li;Han-Wei Shen,"Department of Computer Science and Engineering, The Ohio State University, Columbus, OH, USA;Department of Computer Science and Engineering, The Ohio State University, Columbus, OH, USA",0.1109/tvcg.2020.3030346;10.1109/tvcg.2008.162;10.1109/tvcg.2007.70599;10.1109/tvcg.2020.3017568;10.1109/tvcg.2020.3006426;10.1109/tvcg.2018.2867488;10.1109/tvcg.2015.2467436;10.1109/tvcg.2008.167,"Data transformation,particle data,,feature extraction and tracking,deep learning",,2,52,253,,
TVCG,2023,ScrollyVis: Interactive Visual Authoring of Guided Dynamic Narratives for Scientific Scrollytelling,10.1109/tvcg.2022.3205769,http://dx.doi.org/10.1109/TVCG.2022.3205769,5165,5177,J,"Visual stories are an effective and powerful tool to convey specific information to a diverse public. Scrollytelling is a recent visual storytelling technique extensively used on the web, where content appears or changes as users scroll up or down a page. By employing the familiar gesture of scrolling as its primary interaction mechanism, it provides users with a sense of control, exploration and discoverability while still offering a simple and intuitive interface. In this article, we present a novel approach for authoring, editing, and presenting data-driven scientific narratives using scrollytelling. Our method flexibly integrates common sources such as images, text, and video, but also supports more specialized visualization techniques such as interactive maps as well as scalar field and mesh data visualizations. We show that scrolling navigation can be used to traverse dynamic narratives and demonstrate how it can be combined with interactive parameter exploration. The resulting system consists of an extensible web-based authoring tool capable of exporting stand-alone stories that can be hosted on any web server. We demonstrate the power and utility of our approach with case studies from several diverse scientific fields and with a user study including 12 participants of diverse professional backgrounds. Furthermore, an expert in creating interactive articles assessed the usefulness of our approach and the quality of the created stories.",Eric Mörth;Stefan Bruckner;Noeska N. Smit,Eric Mörth;Stefan Bruckner;Noeska N. Smit,"Department of Informatics, University of Bergen, Bergen, Norway;Department of Informatics, University of Bergen, Bergen, Norway;Department of Informatics, University of Bergen, Bergen, Norway",0.1109/tvcg.2017.2744118;10.1109/tvcg.2021.3130670;10.1109/tvcg.2021.3114849;10.1109/infvis.2003.1249004;10.1109/tvcg.2012.244;10.1109/tvcg.2020.3030412,,,2,50,1306,,
TVCG,2022,View Composition Algebra for Ad Hoc Comparison,10.1109/tvcg.2022.3152515,http://dx.doi.org/10.1109/TVCG.2022.3152515,2470,2485,J,"Comparison is a core task in visual analysis. Although there are numerous guidelines to help users design effective visualizations to aid known comparison tasks, there are few techniques available when users want to make ad hoc comparisons between marks, trends, or charts during data exploration and visual analysis. For instance, to compare voting count maps from different years, two stock trends in a line chart, or a scatterplot of country GDPs with a textual summary of the average GDP. Ideally, users can directly select the comparison targets and compare them, however what elements of a visualization should be candidate targets, which combinations of targets are safe to compare, and what comparison operations make sense? This article proposes a conceptual model that lets users compose combinations of values, marks, legend elements, and charts using a set of composition operators that summarize, compute differences, merge, and model their operands. We further define a View Composition Algebra (VCA) that is compatible with datacube-based visualizations, derive an interaction design based on this algebra that supports ad hoc visual comparisons, and illustrate its utility through several use cases.",Eugene Wu 0002,Eugene Wu,"Columbia University, New York, NY, USA",0.1109/tvcg.2017.2744198;10.1109/tvcg.2016.2598624;10.1109/tvcg.2007.70584;10.1109/tvcg.2016.2599030;10.1109/tvcg.2007.70515;10.1109/tvcg.2014.2346325;10.1109/tvcg.2007.70594;10.1109/tvcg.2018.2865240;10.1109/tvcg.2014.2346320;10.1109/tvcg.2015.2467191;10.1109/infvis.2004.12;10.1109/tvcg.2012.237;10.1109/tvcg.2017.2744199;10.1109/tvcg.2008.137;10.1109/tvcg.2020.3030338;10.1109/tvcg.2009.128,"Visualization,algebra,,comparison,databases",,2,66,264,,X
TVCG,2024,Parallel Computation of Piecewise Linear Morse-Smale Segmentations,10.1109/tvcg.2023.3261981,http://dx.doi.org/10.1109/TVCG.2023.3261981,1942,1955,J,"This article presents a well-scaling parallel algorithm for the computation of Morse-Smale (MS) segmentations, including the region separators and region boundaries. The segmentation of the domain into ascending and descending manifolds, solely defined on the vertices, improves the computational time using path compression and fully segments the border region. Region boundaries and region separators are generated using a multi-label marching tetrahedra algorithm. This enables a fast and simple solution to find optimal parameter settings in preliminary exploration steps by generating an MS complex preview. It also poses a rapid option to generate a fast visual representation of the region geometries for immediate utilization. Two experiments demonstrate the performance of our approach with speedups of over an order of magnitude in comparison to two publicly available implementations. The example section shows the similarity to the MS complex, the useability of the approach, and the benefits of this method with respect to the presented datasets. We provide our implementation with the paper.",Robin G. C. Maack;Jonas Lukasczyk;Julien Tierny;Hans Hagen;Ross Maciejewski;Christoph Garth,Robin G. C. Maack;Jonas Lukasczyk;Julien Tierny;Hans Hagen;Ross Maciejewski;Christoph Garth,"RPTU Kaiserslautern-Landau, Kaiserslautern, Germany;RPTU Kaiserslautern-Landau, Kaiserslautern, Germany;CNRS, Sorbonne Université, Paris, France;RPTU Kaiserslautern-Landau, Kaiserslautern, Germany;Arizona State University, Tempe, AZ, USA;RPTU Kaiserslautern-Landau, Kaiserslautern, Germany",0.1109/tvcg.2021.3114819;10.1109/tvcg.2006.186;10.1109/tvcg.2015.2467432;10.1109/tvcg.2018.2864848;10.1109/tvcg.2007.70552;10.1109/tvcg.2008.110;10.1109/tvcg.2011.284;10.1109/tvcg.2012.209;10.1109/tvcg.2007.70603;10.1109/tvcg.2014.2346403;10.1109/tvcg.2014.2346434;10.1109/tvcg.2020.3030353;10.1109/visual.2000.885672;10.1109/visual.1997.663887;10.1109/visual.2000.885706;10.1109/tvcg.2017.2743938,"Morse-smale complex,segmentation,,topology,visualization,watershed transformation",,2,72,363,,X
TVCG,2023,DOMINO: Visual Causal Reasoning With Time-Dependent Phenomena,10.1109/tvcg.2022.3207929,http://dx.doi.org/10.1109/TVCG.2022.3207929,5342,5356,J,"Current work on using visual analytics to determine causal relations among variables has mostly been based on the concept of counterfactuals. As such the derived static causal networks do not take into account the effect of time as an indicator. However, knowing the time delay of a causal relation can be crucial as it instructs how and when actions should be taken. Yet, similar to static causality, deriving causal relations from observational time-series data, as opposed to designed experiments, is not a straightforward process. It can greatly benefit from human insight to break ties and resolve errors. We hence propose a set of visual analytics methods that allow humans to participate in the discovery of causal relations associated with windows of time delay. Specifically, we leverage a well-established method, logic-based causality, to enable analysts to test the significance of potential causes and measure their influences toward a certain effect. Furthermore, since an effect can be a cause of other effects, we allow users to aggregate different temporal cause-effect relations found with our method into a visual flow diagram to enable the discovery of temporal causal networks. To demonstrate the effectiveness of our methods we constructed a prototype system named DOMINO and showcase it via a number of case studies using real-world datasets. Finally, we also used DOMINO to conduct several evaluations with human analysts from different science domains in order to gain feedback on the utility of our system in practical scenarios.",Jun Wang;Klaus Mueller 0001,Jun Wang;Klaus Mueller,"Computer Science Department, Visual Analytics and Imaging Lab, Stony Brook University, Stony Brook, NY, USA;Computer Science Department, Visual Analytics and Imaging Lab, Stony Brook University, Stony Brook, NY, USA",0.1109/vast.2007.4389009;10.1109/tvcg.2017.2745280;10.1109/tvcg.2014.2346682;10.1109/tvcg.2021.3100413;10.1109/tvcg.2021.3102051;10.1109/tvcg.2020.3030465;10.1109/tvcg.2009.200;10.1109/tvcg.2013.200;10.1109/tvcg.2015.2467931;10.1109/vast.2017.8585647;10.1109/tvcg.2009.187;10.1109/tvcg.2012.225;10.1109/tvcg.2020.3028957;10.1109/tvcg.2016.2598543,"Causality analysis,hypothesis generation,,hypothesis testing,time series,visual analytics",,2,47,383,,
TVCG,2022,Towards Systematic Design Considerations for Visualizing Cross-View Data Relationships,10.1109/tvcg.2021.3102966,http://dx.doi.org/10.1109/TVCG.2021.3102966,4741,4756,J,"Due to the scale of data and the complexity of analysis tasks, insight discovery often requires coordinating multiple visualizations (views), with each view displaying different parts of data or the same data from different perspectives. For example, to analyze car sales records, a marketing analyst uses a line chart to visualize the trend of car sales, a scatterplot to inspect the price and horsepower of different cars, and a matrix to compare the transaction amounts in types of deals. To explore related information across multiple views, current visual analysis tools heavily rely on brushing and linking techniques, which may require a significant amount of user effort (e.g., many trial-and-error attempts). There may be other efficient and effective ways of displaying cross-view data relationships to support data analysis with multiple views, but currently there are no guidelines to address this design challenge. In this article, we present systematic design considerations for visualizing cross-view data relationships, which leverages descriptive aspects of relationships and usable visual context of multi-view visualizations. We discuss pros and cons of different designs for showing cross-view data relationships, and provide a set of recommendations for helping practitioners make design decisions.",Maoyuan Sun;Akhil Namburi;David Koop;Jian Zhao 0010;Tianyi Li 0008;Haeyong Chung,Maoyuan Sun;Akhil Namburi;David Koop;Jian Zhao;Tianyi Li;Haeyong Chung,"Department of Computer Science, Northern Illinois University, DeKalb, IL, USA;Department of Computer Science, Northern Illinois University, DeKalb, IL, USA;Department of Computer Science, Northern Illinois University, DeKalb, IL, USA;School of Computer Science, University of Waterloo, Waterloo, ON, Canada;Department of Computer Information Technology, Purdue University, West Lafayette, IN, USA;Department of Computer Science, University of Alabama in Huntsville, Huntsville, AL, USA",0.1109/tvcg.2017.2744019;10.1109/tvcg.2014.2346293;10.1109/tvcg.2015.2467051;10.1109/infvis.2000.885094;10.1109/tvcg.2017.2723393;10.1109/tvcg.2015.2467813;10.1109/tvcg.2014.2346665;10.1109/tvcg.2015.2467552;10.1109/tvcg.2009.122;10.1109/tvcg.2010.210;10.1109/tvcg.2016.2599030;10.1109/tvcg.2013.76;10.1109/tvcg.2017.2743859;10.1109/tvcg.2013.160;10.1109/tvcg.2016.2598885;10.1109/tvcg.2014.2346260;10.1109/tvcg.2017.2744458;10.1109/tvcg.2018.2861397;10.1109/tvcg.2007.70582;10.1109/infvis.2000.885092;10.1109/infvis.1996.559213;10.1109/tvcg.2010.138;10.1109/tvcg.2011.250;10.1109/tvcg.2011.186;10.1109/tvcg.2016.2598831;10.1109/tvcg.2011.183;10.1109/infvis.2004.12;10.1109/tvcg.2007.70515;10.1109/tvcg.2014.2346249;10.1109/tvcg.2017.2785807;10.1109/vast.2015.7347628;10.1109/tvcg.2013.227;10.1109/vast.2012.6400559;10.1109/tvcg.2011.195;10.1109/tvcg.2015.2467451;10.1109/tvcg.2006.166;10.1109/tvcg.2007.70521,"Cross-view data relationship,multiple views,,visual analytics",,2,86,606,,
TVCG,2022,CosmoVis: An Interactive Visual Analysis Tool for Exploring Hydrodynamic Cosmological Simulations,10.1109/tvcg.2022.3159630,http://dx.doi.org/10.1109/TVCG.2022.3159630,2909,2925,J,"We introduce CosmoVis, an open source web-based visualization tool for the interactive analysis of massive hydrodynamic cosmological simulation data. CosmoVis was designed in close collaboration with astrophysicists to enable researchers and citizen scientists to share and explore these datasets, and to use them to investigate a range of scientific questions. CosmoVis visualizes many key gas, dark matter, and stellar attributes extracted from the source simulations, which typically consist of complex data structures multiple terabytes in size, often requiring extensive data wrangling. CosmoVis introduces a range of features to facilitate real-time analysis of these simulations, including the use of “virtual skewers,” simulated analogues of absorption line spectroscopy that act as spectral probes piercing the volume of gaseous cosmic medium. We explain how such synthetic spectra can be used to gain insight into the source datasets and to make functional comparisons with observational data. Furthermore, we identify the main analysis tasks that CosmoVis enables and present implementation details of the software interface and the client-server architecture. We conclude by providing details of three contemporary scientific use cases that were conducted by domain experts using the software and by documenting expert feedback from astrophysicists at different career levels.",David Abramov;Joseph N. Burchett;Oskar Elek;Cameron Hummels;J. Xavier Prochaska;Angus G. Forbes,David Abramov;Joseph N. Burchett;Oskar Elek;Cameron Hummels;J. Xavier Prochaska;Angus G. Forbes,"University of California, Santa Cruz, Santa Cruz, CA, USA;New Mexico State University, Las Cruces, NM, USA;University of California, Santa Cruz, Santa Cruz, CA, USA;California Institute of Technology, Pasadena, CA, USA;University of California, Santa Cruz, Santa Cruz, CA, USA;University of California, Santa Cruz, Santa Cruz, CA, USA",0.1109/tvcg.2020.3030407,"Astrovis,astrographics,,cosmological simulations,astronomy,astrophysics,virtual spectrography",,2,85,464,,X
TVCG,2024,The Risks of Ranking: Revisiting Graphical Perception to Model Individual Differences in Visualization Performance,10.1109/tvcg.2022.3226463,http://dx.doi.org/10.1109/TVCG.2022.3226463,1756,1771,J,"Graphical perception studies typically measure visualization encoding effectiveness using the error of an “average observer”, leading to canonical rankings of encodings for numerical attributes: e.g., position $>$> area $>$> angle $>$> volume. Yet different people may vary in their ability to read different visualization types, leading to variance in this ranking across individuals not captured by population-level metrics using “average observer” models. One way we can bridge this gap is by recasting classic visual perception tasks as tools for assessing individual performance, in addition to overall visualization performance. In this article we replicate and extend Cleveland and McGill's graphical comparison experiment using Bayesian multilevel regression, using these models to explore individual differences in visualization skill from multiple perspectives. The results from experiments and modeling indicate that some people show patterns of accuracy that credibly deviate from the canonical rankings of visualization effectiveness. We discuss implications of these findings, such as a need for new ways to communicate visualization effectiveness to designers, how patterns in individuals’ responses may show systematic biases and strategies in visualization judgment, and how recasting classic visual perception tasks as tools for assessing individual performance may offer new ways to quantify aspects of visualization literacy. Experiment data, source code, and analysis scripts are available at the following repository: https://osf.io/8ub7t/?view_only=9be4798797404a4397be3c6fc2a68cc0.",Russell Davis;Xiaoying Pu;Yiren Ding;Brian D. Hall;Karen Bonilla;Mi Feng;Matthew Kay 0001;Lane Harrison,Russell Davis;Xiaoying Pu;Yiren Ding;Brian D. Hall;Karen Bonilla;Mi Feng;Matthew Kay;Lane Harrison,"Worcester Polytechnic Institute, Worcester, MA, USA;University of California, Merced, CA, USA;Worcester Polytechnic Institute, Worcester, MA, USA;University of Michigan, Ann Arbor, MI, USA;Worcester Polytechnic Institute, Worcester, MA, USA;Worcester Polytechnic Institute, Worcester, MA, USA;Northwestern University, Evanston, IL, USA;Worcester Polytechnic Institute, Worcester, MA, USA",0.1109/tvcg.2018.2865240;10.1109/tvcg.2015.2467671;10.1109/tvcg.2021.3114684;10.1109/tvcg.2010.186;10.1109/vast.2010.5653587;10.1109/tvcg.2012.199;10.1109/tvcg.2015.2467758;10.1109/tvcg.2014.2346979;10.1109/tvcg.2016.2598862;10.1109/tvcg.2020.3030335;10.1109/tvcg.2021.3114874;10.1109/tvcg.2014.2346320;10.1109/tvcg.2019.2934786;10.1109/tvcg.2020.3030429;10.1109/tvcg.2016.2598920;10.1109/tvcg.2014.2346984;10.1109/tvcg.2011.255;10.1109/tvcg.2013.234;10.1109/tvcg.2018.2864909,"Visualization,graphical perception,,individual differences",,3,70,436,,
TVCG,2024,PhraseMap: Attention-Based Keyphrases Recommendation for Information Seeking,10.1109/tvcg.2022.3225114,http://dx.doi.org/10.1109/TVCG.2022.3225114,1787,1802,J,"Many Information Retrieval (IR) approaches have been proposed to extract relevant information from a large corpus. Among these methods, phrase-based retrieval methods have been proven to capture more concrete and concise information than word-based and paragraph-based methods. However, due to the complex relationship among phrases and a lack of proper visual guidance, achieving user-driven interactive information-seeking and retrieval remains challenging. In this study, we present a visual analytic approach for users to seek information from an extensive collection of documents efficiently. The main component of our approach is a PhraseMap, where nodes and edges represent the extracted keyphrases and their relationships, respectively, from a large corpus. To build the PhraseMap, we extract keyphrases from each document and link the phrases according to word attention determined using modern language models, i.e., BERT. As can be imagined, the graph is complex due to the extensive volume of information and the massive amount of relationships. Therefore, we develop a navigation algorithm to facilitate information seeking. It includes (1) a question-answering (QA) model to identify phrases related to users’ queries and (2) updating relevant phrases based on users’ feedback. To better present the PhraseMap, we introduce a resource-controlled self-organizing map (RC-SOM) to evenly and regularly display phrases on grid cells while expecting phrases with similar semantics to stay close in the visualization. To evaluate our approach, we conducted case studies with three domain experts in diverse literature. The results and feedback demonstrate its effectiveness, usability, and intelligence.",Yamei Tu;Rui Qiu;Yu-Shuen Wang;Po-Yin Yen;Han-Wei Shen,Yamei Tu;Rui Qiu;Yu-Shuen Wang;Po-Yin Yen;Han-Wei Shen,"Department of Computer Science and Engineering, The Ohio State University, Columbus, OH, USA;Department of Computer Science and Engineering, The Ohio State University, Columbus, OH, USA;National Chiao Tung University, Hsinchu, Taiwan;Washington University School of Medicine, St. Louis, MO, USA;Department of Computer Science and Engineering, The Ohio State University, Columbus, OH, USA",0.1109/tvcg.2016.2598667;10.1109/tvcg.2014.2346431;10.1109/tvcg.2013.212;10.1109/vast.2016.7883507;10.1109/tvcg.2018.2834341;10.1109/tvcg.2015.2467554;10.1109/vast.2016.7883511;10.1109/tvcg.2012.250;10.1109/vast.2016.7883510;10.1109/tvcg.2019.2934263;10.1109/tvcg.2019.2934667;10.1109/vast.2014.7042494;10.1109/tvcg.2020.2995100;10.1109/tvcg.2017.2744478;10.1109/tvcg.2016.2615308;10.1109/vast.2012.6400485,"Textual data,machine learning,,visual analytics,natural language processing,user-in-the-loop",,2,88,628,,
TVCG,2023,A Hybrid in Situ Approach for Cost Efficient Image Database Generation,10.1109/tvcg.2022.3169590,http://dx.doi.org/10.1109/TVCG.2022.3169590,3788,3798,J,"The visualization of results while the simulation is running is increasingly common in extreme scale computing environments. We present a novel approach for in situ generation of image databases to achieve cost savings on supercomputers. Our approach, a hybrid between traditional inline and in transit techniques, dynamically distributes visualization tasks between simulation nodes and visualization nodes, using probing as a basis to estimate rendering cost. Our hybrid design differs from previous works in that it creates opportunities to minimize idle time from four fundamental types of inefficiency: variability, limited scalability, overhead, and rightsizing. We demonstrate our results by comparing our method against both inline and in transit methods for a variety of configurations, including two simulation codes and a scaling study that goes above 19 K cores. Our findings show that our approach is superior in many configurations. As in situ visualization becomes increasingly ubiquitous, we believe our technique could lead to significant amounts of reclaimed cycles on supercomputers.",Valentin Bruder;Matthew Larsen;Thomas Ertl;Hank Childs;Steffen Frey,Valentin Bruder;Matthew Larsen;Thomas Ertl;Hank Childs;Steffen Frey,"Daimler Truck AG, Stuttgart, Germany;Luminary Cloud, Inc., Palo Alto, CA, USA;University of Stuttgart, Stuttgart, Germany;University of Oregon, Eugene, OR, USA;University of Groningen, Groningen, The Netherlands",0.1109/tvcg.2019.2898435;10.1109/mcg.2016.48;10.1109/tvcg.2016.2598604;10.1109/tvcg.2018.2833113;10.1109/tvcg.2015.2467411,"Visualization,High performance computing,,In situ",,2,41,314,,
TVCG,2024,Evaluating Glyph Design for Showing Large-Magnitude-Range Quantum Spins,10.1109/tvcg.2022.3232591,http://dx.doi.org/10.1109/TVCG.2022.3232591,1868,1884,J,"We present experimental results to explore a form of bivariate glyphs for representing large-magnitude-range vectors. The glyphs meet two conditions: (1) two visual dimensions are separable; and (2) one of the two visual dimensions uses a categorical representation (e.g., a categorical colormap). We evaluate how much these two conditions determine the bivariate glyphs’ effectiveness. The first experiment asks participants to perform three local tasks requiring reading no more than two glyphs. The second experiment scales up the search space in global tasks when participants must look at the entire scene of hundreds of vector glyphs to get an answer. Our results support that the first condition is necessary for local tasks when a few items are compared. But it is not enough for understanding a large amount of data. The second condition is necessary for perceiving global structures of examining very complex datasets. Participants’ comments reveal that the categorical features in the bivariate glyphs trigger emergent optimal viewers’ behaviors. This work contributes to perceptually accurate glyph representations for revealing patterns from large scientific results. We release source code, quantum physics data, training documents, participants’ answers, and statistical analyses for reproducible science at https://osf.io/4xcf5/?view_only=94123139df9c4ac984a1e0df811cd580.",Henan Zhao;Garnett W. Bryant;Wesley Griffin;Judith E. Terrill;Jian Chen 0006,Henan Zhao;Garnett W. Bryant;Wesley Griffin;Judith E. Terrill;Jian Chen,"University of Maryland, Baltimore County, Baltimore, MD, USA;National Institute of Standards and Technology, Gaithersburg, MD, USA;Stellar Science, Albuquerque, NM, USA;National Institute of Standards and Technology, Gaithersburg, MD, USA;The Ohio State University, Columbus, OH, USA",0.1109/tvcg.2016.2549018;10.1109/tvcg.2009.175;10.1109/tvcg.2016.2539949;10.1109/visual.2003.1250362;10.1109/tvcg.2015.2467759;10.1109/tvcg.2021.3114684;10.1109/tvcg.2014.2346978;10.1109/visual.2001.964510;10.1109/tvcg.2015.2467435;10.1109/tvcg.2009.126;10.1109/tvcg.2018.2865264;10.1109/tvcg.2013.234;10.1109/tvcg.2016.2598998;10.1109/tvcg.2013.120;10.1109/tvcg.2006.134,"Bivariate glyph,3D glyph,,large-magnitude-range,quantitative visualization,separable and integral dimension pairs",,1,59,316,,X
TVCG,2022,VisRecall: Quantifying Information Visualisation Recallability via Question Answering,10.1109/tvcg.2022.3198163,http://dx.doi.org/10.1109/TVCG.2022.3198163,4995,5005,J,"Despite its importance for assessing the effectiveness of communicating information visually, fine-grained recallability of information visualisations has not been studied quantitatively so far. In this work, we propose a question-answering paradigm to study visualisation recallability and present VisRecall — a novel dataset consisting of 200 visualisations that are annotated with crowd-sourced human (N = 305) recallability scores obtained from 1,000 questions of five question types. Furthermore, we present the first computational method to predict recallability of different visualisation elements, such as the title or specific data values. We report detailed analyses of our method on VisRecall and demonstrate that it outperforms several baselines in overall recallability and FE-, F-, RV-, and U-question recallability. Our work makes fundamental contributions towards a new generation of methods to assist designers in optimising visualisations.",Yao Wang;Chuhan Jiao;Mihai Bâce;Andreas Bulling,Yao Wang;Chuhan Jiao;Mihai Bâce;Andreas Bulling,"Institute for Visualisation and Interactive Systems, University of Stuttgart, Stuttgart, Germany;Aalto University, Espoo, Finland;Institute for Visualisation and Interactive Systems, University of Stuttgart, Stuttgart, Germany;Institute for Visualisation and Interactive Systems, University of Stuttgart, Stuttgart, Germany",0.1109/tvcg.2013.234;10.1109/tvcg.2015.2467732;10.1109/infvis.2005.1532136;10.1109/tvcg.2017.2743898;10.1109/tvcg.2012.197;10.1109/tvcg.2012.221;10.1109/tvcg.2020.3030396;10.1109/tvcg.2012.215;10.1109/tvcg.2017.2653106,"Information visualisation,machine learning,,memorability,recallability",,2,55,540,,X
TVCG,2023,Sensemaking Sans Power: Interactive Data Visualization Using Color-Changing Ink,10.1109/tvcg.2022.3209631,http://dx.doi.org/10.1109/TVCG.2022.3209631,5282,5293,J,"We present an approach for interactively visualizing data using color-changing inks without the need for electronic displays or computers. Color-changing inks are a family of physical inks that change their color characteristics in response to an external stimulus such as heat, UV light, water, and pressure. Visualizations created using color-changing inks can embed interactivity in printed material without external computational media. In this article, we survey current color-changing ink technology and then use these findings to derive a framework for how it can be used to construct interactive data representations. We also enumerate the interaction techniques possible using this technology. We then show some examples of how to use color-changing ink to create interactive visualizations on paper. While obviously limited in scope to situations where no power or computing is present, or as a complement to digital displays, our findings can be employed for paper, data physicalization, and embedded visualizations.",Biswaksen Patnaik;Huaishu Peng;Niklas Elmqvist,Biswaksen Patnaik;Huaishu Peng;Niklas Elmqvist,"University of Maryland, College Park, MD, USA;University of Maryland, College Park, MD, USA;University of Maryland, College Park, MD, USA",0.1109/tvcg.2018.2865119;10.1109/tvcg.2013.163;10.1109/tvcg.2007.70541;10.1109/infvis.2004.8;10.1109/tvcg.2007.70515;10.1109/tvcg.2007.70583;10.1109/tvcg.2012.264;10.1109/tvcg.2016.2598608;10.1109/tvcg.2019.2934788;10.1109/tvcg.2016.2599211,"Physical computing,color-changing inks,,design space,data physicalization,data visualization",,1,60,343,,
TVCG,2024,The Transform-and-Perform Framework: Explainable Deep Learning Beyond Classification,10.1109/tvcg.2022.3219248,http://dx.doi.org/10.1109/TVCG.2022.3219248,1502,1515,J,"In recent years, visual analytics (VA) has shown promise in alleviating the challenges of interpreting black-box deep learning (DL) models. While the focus of VA for explainable DL has been mainly on classification problems, DL is gaining popularity in high-dimensional-to-high-dimensional (H-H) problems such as image-to-image translation. In contrast to classification, H-H problems have no explicit instance groups or classes to study. Each output is continuous, high-dimensional, and changes in an unknown non-linear manner with changes in the input. These unknown relations between the input, model and output necessitate the user to analyze them in conjunction, leveraging symmetries between them. Since classification tasks do not exhibit some of these challenges, most existing VA systems and frameworks allow limited control of the components required to analyze models beyond classification. Hence, we identify the need for and present a unified conceptual framework, the Transform-and-Perform framework (T&P), to facilitate the design of VA systems for DL model analysis focusing on H-H problems. T&P provides a checklist to structure and identify workflows and analysis strategies to design new VA systems, and understand existing ones to uncover potential gaps for improvements. The goal is to aid the creation of effective VA systems that support the structuring of model understanding and identifying actionable insights for model improvements. We highlight the growing need for new frameworks like T&P with a real-world image-to-image translation application. We illustrate how T&P effectively supports the understanding and identification of potential gaps in existing VA systems.",Vidya Prasad;Ruud J. G. van Sloun;Stef van den Elzen;Anna Vilanova;Nicola Pezzotti,Vidya Prasad;Ruud J. G. van Sloun;Stef van den Elzen;Anna Vilanova;Nicola Pezzotti,"Department of Mathematics and Computer Science, Eindhoven University of Technology, AZ, Eindhoven, The Netherlands;Department of Electrical Engineering, Eindhoven University of Technology, Eindhoven, The Netherlands;Department of Mathematics and Computer Science, Eindhoven University of Technology, AZ, Eindhoven, The Netherlands;Department of Mathematics and Computer Science, Eindhoven University of Technology, AZ, Eindhoven, The Netherlands;Department of Mathematics and Computer Science, Eindhoven University of Technology, AZ, Eindhoven, The Netherlands",0.1109/tvcg.2018.2843369;10.1109/tvcg.2017.2744718;10.1109/tvcg.2021.3114855;10.1109/tvcg.2019.2934659;10.1109/tvcg.2019.2934261;10.1109/tvcg.2017.2744358;10.1109/tvcg.2020.3030461;10.1109/tvcg.2020.2973258;10.1109/tvcg.2018.2864838;10.1109/vast.2017.8585720;10.1109/tvcg.2019.2934629;10.1109/tvcg.2021.3114837;10.1109/tvcg.2016.2598838;10.1109/visual.2005.1532781;10.1109/tvcg.2020.3028888;10.1109/tvcg.2018.2865043;10.1109/tvcg.2018.2864500;10.1109/tvcg.2014.2346325;10.1109/tvcg.2019.2934619,"Visual analytics,explainable AI,,framework,deep learning,high-dimensional-to-high-dimensional translation,XAI",,1,78,583,,
TVCG,2024,DocFlow: A Visual Analytics System for Question-Based Document Retrieval and Categorization,10.1109/tvcg.2022.3219762,http://dx.doi.org/10.1109/TVCG.2022.3219762,1533,1548,J,"A systematic review (SR) is essential with up-to-date research evidence to support clinical decisions and practices. However, the growing literature volume makes it challenging for SR reviewers and clinicians to discover useful information efficiently. Many human-in-the-loop information retrieval approaches (HIR) have been proposed to rank documents semantically similar to users’ queries and provide interactive visualizations to facilitate document retrieval. Given that the queries are mainly composed of keywords and keyphrases retrieving documents that are semantically similar to a query does not necessarily respond to the clinician's need. Clinicians still have to review many documents to find the solution. The problem motivates us to develop a visual analytics system, DocFlow, to facilitate information-seeking. One of the features of our DocFlow is accepting natural language questions. The detailed description enables retrieving documents that can answer users’ questions. Additionally, clinicians often categorize documents based on their backgrounds and with different purposes (e.g., populations, treatments). Since the criteria are unknown and cannot be pre-defined in advance, existing methods can only achieve categorization by considering the entire information in documents. In contrast, by locating answers in each document, our DocFlow can intelligently categorize documents based on users’ questions. The second feature of our DocFlow is a flexible interface where users can arrange a sequence of questions to customize their rules for document retrieval and categorization. The two features of this visual analytics system support a flexible information-seeking process. The case studies and the feedback from domain experts demonstrate the usefulness and effectiveness of our DocFlow.",Rui Qiu;Yamei Tu;Yu-Shuen Wang;Po-Yin Yen;Han-Wei Shen,Rui Qiu;Yamei Tu;Yu-Shuen Wang;Po-Yin Yen;Han-Wei Shen,"Department of Computer Science and Engineering, The Ohio State University, Columbus, OH, USA;Department of Computer Science and Engineering, The Ohio State University, Columbus, OH, USA;Department of Computer Science, National Yang Ming Chiao Tung University, HsinChu, Taiwan;Institute for Informatics, Washington University School of Medicine, St. Louis, MO, USA;Department of Computer Science and Engineering, The Ohio State University, Columbus, OH, USA",0.1109/tvcg.2016.2610422;10.1109/tvcg.2016.2615308;10.1109/tvcg.2015.2467621;10.1109/tvcg.2016.2598827;10.1109/tvcg.2021.3114820;10.1109/tvcg.2010.154;10.1109/vast.2016.7883507;10.1109/tvcg.2016.2598445;10.1109/infvis.2005.1532152,"Biomedical systematic review,evidence-based-practice,,human-in-the-loop information retrieval,question-based document categorization,question-based document retrieval",,1,63,601,,
TVCG,2024,A Scalable Method for Readable Tree Layouts,10.1109/tvcg.2023.3274572,http://dx.doi.org/10.1109/TVCG.2023.3274572,1564,1578,J,"Large tree structures are ubiquitous and real-world relational datasets often have information associated with nodes (e.g., labels or other attributes) and edges (e.g., weights or distances) that need to be communicated to the viewers. Yet, scalable, easy to read tree layouts are difficult to achieve. We consider tree layouts to be readable if they meet some basic requirements: node labels should not overlap, edges should not cross, edge lengths should be preserved, and the output should be compact. There are many algorithms for drawing trees, although very few take node labels or edge lengths into account, and none optimizes all requirements above. With this in mind, we propose a new scalable method for readable tree layouts. The algorithm guarantees that the layout has no edge crossings and no label overlaps, and optimizes one of the remaining aspects: desired edge lengths and compactness. We evaluate the performance of the new algorithm by comparison with related earlier approaches using several real-world datasets, ranging from a few thousand nodes to hundreds of thousands of nodes. Tree layout algorithms can be used to visualize large general graphs, by extracting a hierarchy of progressively larger trees. We illustrate this functionality by presenting several map-like visualizations generated by the new tree layout algorithm.",Kathryn Gray;Mingwei Li;Abu Reyan Ahmed;Md. Khaledur Rahman;Ariful Azad;Stephen G. Kobourov;Katy Börner,Kathryn Gray;Mingwei Li;Reyan Ahmed;Md. Khaledur Rahman;Ariful Azad;Stephen Kobourov;Katy Börner,"Department of Computer Science, University of Arizona, Tucson, AZ, USA;Department of Computer Science, University of Arizona, Tucson, AZ, USA;Department of Computer Science, University of Arizona, Tucson, AZ, USA;Department of Computer Science, Indiana University, Bloomington, IN, USA;Department of Computer Science, Indiana University, Bloomington, IN, USA;Department of Computer Science, University of Arizona, Tucson, AZ, USA;SLIS, Indiana University, Bloomington, IN, USA",0.1109/tvcg.2011.185;10.1109/infvis.2002.1173159;10.1109/tvcg.2008.152;10.1109/infvis.2002.1173152,"Force-directed,readability,,tree layouts",,2,54,343,,X
TVCG,2023,Provectories: Embedding-Based Analysis of Interaction Provenance Data,10.1109/tvcg.2021.3135697,http://dx.doi.org/10.1109/TVCG.2021.3135697,4816,4831,J,"Understanding user behavior patterns and visual analysis strategies is a long-standing challenge. Existing approaches rely largely on time-consuming manual processes such as interviews and the analysis of observational data. While it is technically possible to capture a history of user interactions and application states, it remains difficult to extract and describe analysis strategies based on interaction provenance. In this article, we propose a novel visual approach to the meta-analysis of interaction provenance. We capture single and multiple user sessions as graphs of high-dimensional application states. Our meta-analysis is based on two different types of two-dimensional embeddings of these high-dimensional states: layouts based on (i) topology and (ii) attribute similarity. We applied these visualization approaches to synthetic and real user provenance data captured in two user studies. From our visualizations, we were able to extract patterns for data types and analytical reasoning strategies.",Conny Walchshofer;Andreas P. Hinterreiter;Kai Xu 0003;Holger Stitz;Marc Streit,Conny Walchshofer;Andreas Hinterreiter;Kai Xu;Holger Stitz;Marc Streit,"Johannes Kepler University Linz, Linz, Austria;Johannes Kepler University Linz, Linz, Austria;Middlesex University London, London, U.K.;Datavisyn GmbH, Linz, Austria;Johannes Kepler University Linz, Linz, Austria",0.1109/tvcg.2015.2467851;10.1109/vast.2016.7883520;10.1109/tvcg.2013.124;10.1109/tvcg.2014.2346575;10.1109/vast.2010.5652932;10.1109/tvcg.2022.3156760;10.1109/tvcg.2018.2865117;10.1109/tvcg.2017.2744199;10.1109/tvcg.2008.137;10.1109/tvcg.2010.177;10.1109/mcg.2019.2933419;10.1109/tvcg.2015.2467611;10.1109/tvcg.2018.2846735;10.1109/tvcg.2012.273;10.1109/tvcg.2015.2467551;10.1109/tvcg.2016.2598838;10.1109/tvcg.2018.2865024;10.1109/tvcg.2015.2468078;10.1109/vast.2012.6400494;10.1109/tvcg.2018.2864836;10.1109/tvcg.2017.2745279,"Visualization techniques,information visualization,,visual analytics,interaction provenance,sensemaking",,1,52,969,,
TVCG,2023,Rainbow Colormaps: What are They Good and Bad for?,10.1109/tvcg.2022.3214771,http://dx.doi.org/10.1109/TVCG.2022.3214771,5496,5510,J,"Guidelines for color use in quantitative visualizations have strongly discouraged the use of rainbow colormaps, arguing instead for smooth designs that do not induce visual discontinuities or implicit color categories. However, the empirical evidence behind this argument has been mixed and, at times, even contradictory. In practice, rainbow colormaps are widely used, raising questions about the true utility or dangers of such designs. We study how color categorization impacts the interpretation of scalar fields. We first introduce an approach to detect latent categories in colormaps. We hypothesize that the appearance of color categories in scalar visualizations can be beneficial in that they enhance the perception of certain features, although at the cost of rendering other features less noticeable. In three crowdsourced experiments, we show that observers are more likely to discriminate global, distributional features when viewing colorful scales that induce categorization (e.g., rainbow or diverging schemes). Conversely, when seeing the same data through a less colorful representation, observers are more likely to report localized features defined by small variations in the data. Participants showed awareness of these different affordances, and exhibited bias for exploiting the more discriminating colormap, given a particular feature type. Our results demonstrate costs and benefits for rainbows (and similarly colorful schemes), suggesting that their complementary utility for analyzing scalar data should not be dismissed. In addition to explaining potentially valid uses of rainbow, our study provides actionable guidelines, including on when such designs can be more harmful than useful. Data and materials are available at https://osf.io/xjhtf",Khairi Reda,Khairi Reda,"Indiana University–Purdue University Indianapolis, Indianapolis, IN, USA",0.1109/tvcg.2020.3035823;10.1109/tvcg.2010.161;10.1109/tvcg.2018.2855742;10.1109/tvcg.2018.2876539;10.1109/tvcg.2012.230;10.1109/tvcg.2015.2469125;10.1109/tvcg.2019.2934284;10.1109/tvcg.2017.2744359;10.1109/tvcg.2017.2743978;10.1109/tvcg.2011.192;10.1109/visual.2001.964510;10.1109/tvcg.2020.3030439;10.1109/visual.1995.480803;10.1109/tvcg.2020.3028955,"Quantitative color encoding,rainbow colormaps,,scalar fields,perception",,2,55,339,,
TVCG,2023,TopoCluster: A Localized Data Structure for Topology-Based Visualization,10.1109/tvcg.2021.3121229,http://dx.doi.org/10.1109/TVCG.2021.3121229,1506,1517,J,"Unstructured data are collections of points with irregular topology, often represented through simplicial meshes, such as triangle and tetrahedral meshes. Whenever possible such representations are avoided in visualization since they are computationally demanding if compared with regular grids. In this work, we aim at simplifying the encoding and processing of simplicial meshes. The article proposes TopoCluster, a new localized data structure for tetrahedral meshes. TopoCluster provides efficient computation of the connectivity of the mesh elements with a low memory footprint. The key idea of TopoCluster is to subdivide the simplicial mesh into clusters. Then, the connectivity information is computed locally for each cluster and discarded when it is no longer needed. We define two instances of TopoCluster. The first instance prioritizes time efficiency and provides only a modest savings in memory, while the second instance drastically reduces memory consumption up to an order of magnitude with respect to comparable data structures. Thanks to the simple interface provided by TopoCluster, we have been able to integrate both data structures into the existing Topological Toolkit (TTK) framework. As a result, users can run any plugin of TTK using TopoCluster without changing a single line of code.",Guoxi Liu;Federico Iuricich;Riccardo Fellegara;Leila De Floriani,Guoxi Liu;Federico Iuricich;Riccardo Fellegara;Leila De Floriani,"School of Computing, Clemson University, Clemson, SC, USA;School of Computing, Clemson University, Clemson, SC, USA;German Aerospace Center (DLR), Institute for Software Technology, Braunschweig, Germany;University of Maryland, College Park, MD, USA",0.1109/tvcg.2018.2864848;10.1109/tvcg.2019.2920639;10.1109/tvcg.2013.81;10.1109/tvcg.2017.2743938,"Data visualization,data structures,,topological data analysis,simplicial meshes,tetrahedral meshes",,1,33,565,,
TVCG,2023,RCMVis: A Visual Analytics System for Route Choice Modeling,10.1109/tvcg.2021.3131824,http://dx.doi.org/10.1109/TVCG.2021.3131824,1799,1817,J,"We present RCMVis, a visual analytics system to support interactive Route Choice Modeling analysis. It aims to model which characteristics of routes, such as distance and the number of traffic lights, affect travelers’ route choice behaviors and how much they affect the choice during their trips. Through close collaboration with domain experts, we designed a visual analytics framework for Route Choice Modeling. The framework supports three interactive analysis stages: exploration, modeling, and reasoning. In the exploration stage, we help analysts interactively explore trip data from multiple origin-destination (OD) pairs and choose a subset of data they want to focus on. To this end, we provide coordinated multiple OD views with different foci that allow analysts to inspect, rank, and compare OD pairs in terms of their multidimensional attributes. In the modeling stage, we integrate a $k$k-medoids clustering method and a path-size logit model into our system to enable analysts to model route choice behaviors from trips with support for feature selection, hyperparameter tuning, and model comparison. Finally, in the reasoning stage, we help analysts rationalize and refine the model by selectively inspecting the trips that strongly support the modeling result. For evaluation, we conducted a case study and interviews with domain experts. The domain experts discovered unexpected insights from numerous modeling results, allowing them to explore the hyperparameter space more effectively to gain better results. In addition, they gained OD- and road-level insights into which data mainly supported the modeling result, enabling further discussion of the model.",DongHwa Shin;Jaemin Jo;Bohyoung Kim;Hyunjoo Song;Shin-Hyung Cho;Jinwook Seo,DongHwa Shin;Jaemin Jo;Bohyoung Kim;Hyunjoo Song;Shin-Hyung Cho;Jinwook Seo,"Department of Computer Science and Engineering, Seoul National University, Seoul, South Korea;College of Computing and Informatics, Sungkyunkwan University, Suwon, Gyeonggi-do, South Korea;Division of Biomedical Engineering, Hankuk University of Foreign Studies, Seoul, South Korea;School of Computer Science and Engineering, Soongsil University, Seoul, South Korea;School of Civil and Environmental Engineering, Georgia Institute of Technology, Atlanta, GA, USA;Department of Computer Science and Engineering, Seoul National University, Seoul, South Korea",0.1109/tvcg.2013.228;10.1109/tvcg.2019.2922597;10.1109/vast.2011.6102455;10.1109/vast.2014.7042486;10.1109/tvcg.2016.2598432;10.1109/tvcg.2020.3030458;10.1109/infvis.2000.885098;10.1109/tvcg.2013.124;10.1109/tvcg.2009.122,"Route choice modeling,urban planning,,trajectory data,origin-destination,visual analytics",,2,38,1569,,
TVCG,2023,Visual Assistance in Development and Validation of Bayesian Networks for Clinical Decision Support,10.1109/tvcg.2022.3166071,http://dx.doi.org/10.1109/TVCG.2022.3166071,3602,3616,J,"The development and validation of Clinical Decision Support Models (CDSM) based on Bayesian networks (BN) is commonly done in a collaborative work between medical researchers providing the domain expertise and computer scientists developing the decision support model. Although modern tools provide facilities for data-driven model generation, domain experts are required to validate the accuracy of the learned model and to provide expert knowledge for fine-tuning it while computer scientists are needed to integrate this knowledge in the learned model (hybrid modeling approach). This generally time-expensive procedure hampers CDSM generation and updating. To address this problem, we developed a novel interactive visual approach allowing medical researchers with less knowledge in CDSM to develop and validate BNs based on domain specific data mainly independently and thus, diminishing the need for an additional computer scientist. In this context, we abstracted and simplified the common workflow in BN development as well as adjusted the workflow to medical experts’ needs. We demonstrate our visual approach with data of endometrial cancer patients and evaluated it with six medical researchers who are domain experts in the gynecological field.",Juliane Müller-Sielaff;Seyed Behnam Beladi;Stephanie W. Vrede;Monique Meuschke;Peter J. F. Lucas;Johanna M. A. Pijnenborg;Steffen Oeltze-Jafra,Juliane Müller-Sielaff;Seyed Behnam Beladi;Stephanie W. Vrede;Monique Meuschke;Peter J. F. Lucas;Johanna M. A. Pijnenborg;Steffen Oeltze-Jafra,"Department of Neurology, Otto von Guericke University Magdeburg (OVGU), Magdeburg, Germany;Department of Simulation and Graphics & Department of Neurology, OVGU, Magdeburg, Germany;Department of Obstetrics & Gynecology, Radboud university medical center, Nijmegen, GA, The Netherlands;Department of Simulation and Graphics, OVGU, Magdeburg, Germany;University of Twente, Enschede, & LIACS, Leiden University, Leiden, EZ, The Netherlands;Department of Obstetrics & Gynecology, Radboud university medical center, Nijmegen, GA, The Netherlands;Department of Neurology & the Center of Behavioral Brain Sciences, OVGU, Magdeburg, Germany",0.1109/tvcg.2011.279;10.1109/tvcg.2011.185;10.1109/tvcg.2009.111;10.1109/tvcg.2015.2467758;10.1109/tvcg.2020.3030371;10.1109/tvcg.2011.187;10.1109/tvcg.2020.3028957;10.1109/tvcg.2007.70515;10.1109/vast.2017.8585647;10.1109/tvcg.2018.2865146,"Bayesian networks,visual analysis,,clinical decision support,causal model development",,1,62,465,,
TVCG,2022,MVNet: Multi-Variate Multi-View Brain Network Comparison Over Uncertain Data,10.1109/tvcg.2021.3098123,http://dx.doi.org/10.1109/TVCG.2021.3098123,4640,4657,J,"Visually identifying effective bio-markers from human brain networks poses non-trivial challenges to the field of data visualization and analysis. Existing methods in the literature and neuroscience practice are generally limited to the study of individual connectivity features in the brain (e.g., the strength of neural connection among brain regions). Pairwise comparisons between contrasting subject groups (e.g., the diseased and the healthy controls) are normally performed. The underlying neuroimaging and brain network construction process is assumed to have 100 percent fidelity. Yet, real-world user requirements on brain network visual comparison lean against these assumptions. In this work, we present MV$^{2}$2Net, a visual analytics system that tightly integrates multi-variate multi-view visualization for brain network comparison with an interactive wrangling mechanism to deal with data uncertainty. On the analysis side, the system integrates multiple extraction methods on diffusion and geometric connectivity features of brain networks, an anomaly detection algorithm for data quality assessment, single- and multi-connection feature selection methods for bio-marker detection. On the visualization side, novel designs are introduced which optimize network comparisons among contrasting subject groups and related connectivity features. Our design provides level-of-detail comparisons, from juxtaposed and explicit-coding views for subject group comparisons, to high-order composite view for correlation of network comparisons, and to fiber tract detail view for voxel-level comparisons. The proposed techniques are inspired and evaluated in expert studies, as well as through case analyses on diffusion and geometric bio-markers of certain neurology diseases. Results in these experiments demonstrate the effectiveness and superiority of MV$^{2}$2Net over state-of-the-art approaches.",Lei Shi 0002;Junnan Hu;Zhihao Tan;Jun Tao 0002;Jiayan Ding;Yan Jin 0001;Yanjun Wu;Paul M. Thompson,Lei Shi;Junnan Hu;Zhihao Tan;Jun Tao;Jiayan Ding;Yan Jin;Yanjun Wu;Paul M. Thompson,"School of Computer Science and Engineering, Beihang University, Beijing, China;School of Data and Computer Science, and National Supercomputer Center, Sun Yat-sen University, Guangzhou, China;Chinese Academy of Sciences, Institute of Software, Beijing, China;School of Data and Computer Science, and National Supercomputer Center, Sun Yat-sen University, Guangzhou, China;College of Design and Innovation, Tongji University, Shanghai, China;Department of Radiation Oncology, The University of Texas MD Anderson Cancer Center, Houston, TX, USA;Chinese Academy of Sciences, Institute of Software, Beijing, China;Imaging Genetics Center, Mark and Mary Stevens Institute for Neuroimaging and Informatics, University of Southern California, Los Angeles, CA, USA",0.1109/tvcg.2009.143;10.1109/tvcg.2013.213;10.1109/tvcg.2015.2413774;10.1109/tvcg.2017.2744199;10.1109/tvcg.2018.2865149;10.1109/tvcg.2006.151;10.1109/tvcg.2015.2467851;10.1109/tvcg.2017.2744278;10.1109/tvcg.2014.2346312;10.1109/tvcg.2006.166;10.1109/visual.2005.1532779;10.1109/tvcg.2009.141;10.1109/tvcg.2018.2865191;10.1109/tvcg.2019.2898438;10.1109/tvcg.2009.170;10.1109/infvis.2004.1;10.1109/tvcg.2016.2598472;10.1109/tvcg.2019.2934402;10.1109/tvcg.2015.2403323;10.1109/tvcg.2009.138,"Brain network,visual comparison,,multivariate analysis",,1,81,590,,
TVCG,2023,Electromechanical Coupling in Electroactive Polymers – a Visual Analysis of a Third-Order Tensor Field,10.1109/tvcg.2022.3209328,http://dx.doi.org/10.1109/TVCG.2022.3209328,5357,5371,J,"Electroactive polymers are frequently used in engineering applications due to their ability to change their shape and properties under the influence of an electric field. This process also works vice versa, such that mechanical deformation of the material induces an electric field in the EAP device. This specific behavior makes such materials highly attractive for the construction of actuators and sensors in various application areas. The electromechanical behaviour of electroactive polymers can be described by a third-order coupling tensor, which represents the sensitivity of mechanical stresses concerning the electric field, i.e., it establishes a relation between a second-order and a first-order tensor field. Due to this coupling tensor's complexity and the lack of meaningful visualization methods for third-order tensors in general, an interpretation of the tensor is rather difficult. Thus, the central engineering research question that this contribution deals with is a deeper understanding of electromechanical coupling by analyzing the third-order coupling tensor with the help of specific visualization methods. Starting with a deviatoric decomposition of the tensor, the multipoles of each deviator are visualized, which allows a first insight into this highly complex third-order tensor. In the present contribution, four examples, including electromechanical coupling, are simulated within a finite element framework and subsequently analyzed using the tensor visualization method.",Chiara Hergl;Carina Witt;Baldwin Nsonga;Andreas Menzel;Gerik Scheuermann,Chiara Hergl;Carina Witt;Baldwin Nsonga;Andreas Menzel;Gerik Scheuermann,"Institute of Computer Science, Leipzig University, Leipzig, Germany;Institute of Mechanics, TU Dortmund, Dortmund, Germany;Institute of Computer Science, Leipzig University, Leipzig, Germany;Institute of Mechanics, TU Dortmund, Dortmund, Germany;Institute of Computer Science, Leipzig University, Leipzig, Germany",0.1109/tvcg.2010.199;10.1109/tvcg.2016.2598998;10.1109/visual.2005.1532773;10.1109/tvcg.2017.2743978;10.1109/tvcg.2019.2961674,"Tensor visualization,third-order tensor,,deviatoric decomposition,electro-active polymer",,0,48,527,,
TVCG,2023,Watertight Incremental Heightfield Tessellation,10.1109/tvcg.2022.3173081,http://dx.doi.org/10.1109/TVCG.2022.3173081,3888,3899,J,"In this article, we propose a method for the interactive visualization of medium-scale dynamic heightfields without visual artifacts. Our data fall into a category too large to be rendered directly at full resolution, but small enough to fit into GPU memory without pre-filtering and data streaming. We present the real-world use case of unfiltered flood simulation data of such medium scale that need to be visualized in real time for scientific purposes. Our solution facilitates compute shaders to maintain a guaranteed watertight triangulation in GPU memory that approximates the interpolated heightfields with view-dependent, continuous levels of detail. In each frame, the triangulation is updated incrementally by iteratively refining the cached result of the previous frame to minimize the computational effort. In particular, we minimize the number of heightfield sampling operations to make adaptive and higher-order interpolations viable options. We impose no restriction on the number of subdivisions and the achievable level of detail to allow for extreme zoom ranges required in geospatial visualization. Our method provides a stable runtime performance and can be executed with a limited time budget. We present a comparison of our method to three state-of-the-art methods, in which our method is competitive to previous non-watertight methods in terms of runtime, while outperforming them in terms of accuracy.",Daniel Cornel;Silvana Zechmeister;Eduard Gröller;Jürgen Waser,Daniel Cornel;Silvana Zechmeister;Eduard Gröller;Jürgen Waser,"VRVis Forschungs-GmbH, Vienna, Austria;VRVis Forschungs-GmbH, Vienna, Austria;TU Wien, Vienna, Austria;VRVis Forschungs-GmbH, Vienna, Austria",,"Visualization techniques and methodologies,heightfield rendering,,terrain rendering,level of detail,tessellation",,1,34,248,,
TVCG,2023,Visualizing Higher-Order 3D Tensors by Multipole Lines,10.1109/tvcg.2022.3158869,http://dx.doi.org/10.1109/TVCG.2022.3158869,3405,3418,J,"Physics, medicine, earth sciences, mechanical engineering, geo-engineering, bio-engineering and many more application areas use tensorial data. For example, tensors are used in formulating the balance equations of charge, mass, momentum, or energy as well as the constitutive relations that complement them. Some of these tensors (i.e., stiffness tensor, strain gradient, photo-elastic tensor) are of order higher than two. Currently, there are nearly no visualization techniques for such data beyond glyphs. An important reason for this is the limit of currently used tensor decomposition techniques. In this article, we propose to use the deviatoric decomposition to draw lines describing tensors of arbitrary order in three dimensions. The deviatoric decomposition splits a three-dimensional tensor of any order with any type of index symmetry into totally symmetric, traceless tensors. These tensors, called deviators, can be described by a unique set of directions (called multipoles by J. C. Maxwell) and scalars. These multipoles allow the definition of multipole lines which can be computed in a similar fashion to tensor lines and allow a line-based visualization of three-dimensional tensors of any order. We give examples for the visualization of symmetric, second-order tensor fields as well as fourth-order tensor fields. To allow an interpretation of the multipole lines, we analyze the connection between the multipoles and the eigenvectors/eigenvalues in the second-order case. For the fourth-order stiffness tensor, we prove relations between multipoles and important physical quantities such as shear moduli as well as the eigenvectors of the second-order right Cauchy-Green tensor.",Chiara Hergl;Thomas Nagel;Gerik Scheuermann,Chiara Hergl;Thomas Nagel;Gerik Scheuermann,"Faculty of Mathematics and Computer Science, Institute of Computer Science, Image and Signal Processing Group, Leipzig University, Leipzig, Germany;Chair of Soil Mechanics and Foundation Engineering, Geotechnical Institute, Technische Universität Bergakademie Freiberg, Freiberg, Germany;Faculty of Mathematics and Computer Science, Institute of Computer Science, Image and Signal Processing Group, Leipzig University, Leipzig, Germany",0.1109/tvcg.2010.199;10.1109/visual.2005.1532771;10.1109/visual.2005.1532774;10.1109/visual.2005.1532773,"Tensor algebra,higher-order tensor,,line-based,deviatoric decomposition,anisotropy",,0,33,339,,
TVCG,2023,Visual Cue Effects on a Classification Accuracy Estimation Task in Immersive Scatterplots,10.1109/tvcg.2022.3192364,http://dx.doi.org/10.1109/TVCG.2022.3192364,4858,4873,J,"Immersive visualization in virtual reality (VR) allows us to exploit visual cues for perception in 3D space, yet few existing studies have measured the effects of visual cues. Across a desktop monitor and a head-mounted display (HMD), we assessed scatterplot designs which vary their use of visual cues—motion, shading, perspective (graphical projection), and dimensionality—on two sets of data. We conducted a user study with a summary task in which 32 participants estimated the classification accuracy of an artificial neural network from the scatterplots. With Bayesian multilevel modeling, we capture the intricate visual effects and find that no cue alone explains all the variance in estimation error. Visual motion cues generally reduce participants’ estimation error; besides this motion, using other cues may increase participants’ estimation error. Using an HMD, adding visual motion cues, providing a third data dimension, or showing a more complicated dataset leads to longer response times. We speculate that most visual cues may not strongly affect perception in immersive analytics unless they change people's mental model about data. In summary, by studying participants as they interpret the output from a complicated machine learning model, we advance our understanding of how to use the visual cues in immersive analytics.",Fumeng Yang;James Tompkin 0001;Lane Harrison;David H. Laidlaw,Fumeng Yang;James Tompkin;Lane Harrison;David H. Laidlaw,"Northwestern University, Evanston, IL, USA;Department of Computer Science, Brown University, Providence, RI, USA;Department of Computer Science, Worcester Polytechnic Institute, Worcester, MA, USA;Department of Computer Science, Brown University, Providence, RI, USA",0.1109/tvcg.2017.2745941;10.1109/tvcg.2019.2934395;10.1109/tvcg.2017.2744184;10.1109/tvcg.2013.153;10.1109/tvcg.2017.2701829;10.1109/tvcg.2018.2864912;10.1109/tvcg.2019.2934803;10.1109/tvcg.2018.2865152;10.1109/tvcg.2017.2744718;10.1109/tvcg.2016.2598838;10.1109/tvcg.2016.2520921;10.1109/tvcg.2011.234;10.1109/tvcg.2020.3030427;10.1109/tvcg.2007.70596;10.1109/tvcg.2009.127;10.1109/tvcg.2018.2865192;10.1109/tvcg.2020.3030429,"Virtual reality,cluster perception,,information visualization,immersive analytics,dimension reduction,classification",,1,127,584,,
TVCG,2022,"Do You Believe Your (Social Media) Data? A Personal Story on Location Data Biases, Errors, and Plausibility as Well as Their Visualization",10.1109/tvcg.2022.3141605,http://dx.doi.org/10.1109/TVCG.2022.3141605,3277,3291,J,"We present a case study on a journey about a personal data collection of carnivorous plant species habitats, and the resulting scientific exploration of location data biases, data errors, location hiding, and data plausibility. While initially driven by personal interest, our work led to the analysis and development of various means for visualizing threats to insight from geo-tagged social media data. In the course of this endeavor we analyzed local and global geographic distributions and their inaccuracies. We also contribute Motion Plausibility Profiles—a new means for visualizing how believable a specific contributor’s location data is or if it was likely manipulated. We then compared our own repurposed social media dataset with data from a dedicated citizen science project. Compared to biases and errors in the literature on traditional citizen science data, with our visualizations we could also identify some new types or show new aspects for known ones. Moreover, we demonstrate several types of errors and biases for repurposed social media data. Please note that people with color impairments may consider our alternative paper version.",Tobias Isenberg 0001;Zujany Salazar;Rafael Blanco;Catherine Plaisant,Tobias Isenberg;Zujany Salazar;Rafael Blanco;Catherine Plaisant,"CNRS, Inria, LISN, Université Paris-Saclay, Gif-sur-Yvette, France;Télécom SudParis, Rue Charles Fourier, France;Télécom SudParis, Rue Charles Fourier, France;University of Maryland, College Park, MD, USA",0.1109/tvcg.2013.66;10.1109/tvcg.2018.2864889;10.1109/tvcg.2007.70561;10.1109/tvcg.2018.2864913;10.1109/tvcg.2015.2467619;10.1109/vast.2009.5333472,"Social media data,Flickr,,Panoramio,iNaturalist,data bias,data error,data plausibility,data obfuscation,citizen science",,0,76,843,,X
TVCG,2023,Target Netgrams: An Annulus-Constrained Stress Model for Radial Graph Visualization,10.1109/tvcg.2022.3187425,http://dx.doi.org/10.1109/TVCG.2022.3187425,4256,4268,J,"We present Target Netgrams as a visualization technique for radial layouts of graphs. Inspired by manually created target sociograms, we propose an annulus-constrained stress model that aims to position nodes onto the annuli between adjacent circles for indicating their radial hierarchy, while maintaining the network structure (clusters and neighborhoods) and improving readability as much as possible. This is achieved by having more space on the annuli than traditional layout techniques. By adapting stress majorization to this model, the layout is computed as a constrained least square optimization problem. Additional constraints (e.g., parent-child preservation, attribute-based clusters and structure-aware radii) are provided for exploring nodes, edges, and levels of interest. We demonstrate the effectiveness of our method through a comprehensive evaluation, a user study, and a case study.",Mingliang Xue;Yunhai Wang;Chang Han;Jian Zhang 0070;Zheng Wang;Kaiyi Zhang 0003;Christophe Hurter;Jian Zhao 0010;Oliver Deussen,Mingliang Xue;Yunhai Wang;Chang Han;Jian Zhang;Zheng Wang;Kaiyi Zhang;Christophe Hurter;Jian Zhao;Oliver Deussen,"Department of Computer Science, Shandong University, Qingdao, China;Department of Computer Science, Shandong University, Qingdao, China;Department of Computer Science, Shandong University, Qingdao, China;Computer Network Information Center, Chinese Academy of Sciences, Beijing, China;China Information Consulting & Designing Institute, Company, Ltd., Beijing, China;Department of Computer Science, Shandong University, Qingdao, China;ENAC, Ecole National de l'Aviation Civile, Toulouse, France;Cheriton School of Computer Science, University of Waterloo, Waterloo, ON, Canada;Computer and Information Science, University of Konstanz, Konstanz, Germany",0.1109/infvis.2003.1249009;10.1109/tvcg.2016.2615308;10.1109/tvcg.2018.2859997;10.1109/tvcg.2017.2745919;10.1109/tvcg.2010.209;10.1109/tvcg.2011.193;10.1109/tvcg.2015.2467322;10.1109/vast.2006.261438;10.1109/infvis.2000.885091;10.1109/infvis.2001.963273;10.1109/infvis.2001.963287;10.1109/visual.1997.663916;10.1109/tvcg.2018.2865361,"Radial visualization,stress model,,hierarchy constraint,graph",,1,60,410,,
TVCG,2024,MoReVis: A Visual Summary for Spatiotemporal Moving Regions,10.1109/tvcg.2023.3250166,http://dx.doi.org/10.1109/TVCG.2023.3250166,1927,1941,J,"Spatial and temporal interactions are central and fundamental in many activities in our world. A common problem faced when visualizing this type of data is how to provide an overview that helps users navigate efficiently. Traditional approaches use coordinated views or 3D metaphors like the Space-time cube to tackle this problem. However, they suffer from overplotting and often lack spatial context, hindering data exploration. More recent techniques, such as MotionRugs, propose compact temporal summaries based on 1D projection. While powerful, these techniques do not support the situation for which the spatial extent of the objects and their intersections is relevant, such as the analysis of surveillance videos or tracking weather storms. In this article, we propose MoReVis, a visual overview of spatiotemporal data that considers the objects’ spatial extent and strives to show spatial interactions among these objects by displaying spatial intersections. Like previous techniques, our method involves projecting the spatial coordinates to 1D to produce compact summaries. However, our solution's core consists of performing a layout optimization step that sets the size and positions of the visual marks on the summary to resemble the actual values on the original space. We also provide multiple interactive mechanisms to make interpreting the results more straightforward for the user. We perform an extensive experimental evaluation and usage scenarios. Moreover, we evaluated the usefulness of MoReVis in a study with 9 participants. The results point out the effectiveness and suitability of our method in representing different datasets compared to traditional techniques.",Giovani Valdrighi;Nivan Ferreira;Jorge Poco,Giovani Valdrighi;Nivan Ferreira;Jorge Poco,"Fundação Getulio Vargas, Rio de Janeiro, Brazil;Universidade Federal de Pernambuco, Recife, Brazil;Fundação Getulio Vargas, Rio de Janeiro, Brazil",0.1109/tvcg.2018.2865049;10.1109/tvcg.2013.193;10.1109/tvcg.2019.2934415;10.1109/tvcg.2012.212;10.1109/tvcg.2013.196;10.1109/tvcg.2018.2864899;10.1109/tvcg.2013.168;10.1109/tvcg.2019.2933196;10.1109/visual.1990.146402;10.1109/tvcg.2014.2346455,"Spatiotemporal visualization,spatial interactions,,spatial abstraction",,0,56,324,,X
TVCG,2023,Real-Time Visualization of Large-Scale Geological Models With Nonlinear Feature-Preserving Levels of Detail,10.1109/tvcg.2021.3120372,http://dx.doi.org/10.1109/TVCG.2021.3120372,1491,1505,J,"The rapidly growing size and complexity of 3D geological models has increased the need for level-of-detail techniques and compact encodings to facilitate interactive visualization. For large-scale hexahedral meshes, state-of-the-art approaches often employ wavelet schemes for level of detail as well as for data compression. Here, wavelet transforms serve two purposes: (1) they achieve substantial compression for data reduction; and (2) the multiresolution encoding provides levels of detail for visualization. However, in coarser detail levels, important geometric features, such as geological faults, often get too smoothed out or lost, due to linear translation-invariant filtering. The same is true for attribute features, such as discontinuities in porosity or permeability. We present a novel, integrated approach addressing both purposes above, while preserving critical data features of both model geometry and its attributes. Our first major contribution is that we completely decouple the computation of levels of detail from data compression, and perform nonlinear filtering in a high-dimensional data space jointly representing the geological model geometry with its attributes. Computing detail levels in this space enables us to jointly preserve features in both geometry and attributes. While designed in a general way, our framework specifically employs joint bilateral filters, computed efficiently on a high-dimensional permutohedral grid. For data compression, after the computation of all detail levels, each level is separately encoded with a standard wavelet transform. Our second major contribution is a compact GPU data structure for the encoded mesh and attributes that enables direct real-time GPU visualization without prior decoding.",Ronell Sicat;Mohamed Ibrahim;Amani Ageeli;Florian Mannuss;Peter Rautek;Markus Hadwiger,Ronell Sicat;Mohamed Ibrahim;Amani Ageeli;Florian Mannuss;Peter Rautek;Markus Hadwiger,"King Abdullah University of Science and Technology, Thuwal, Saudi Arabia;King Abdullah University of Science and Technology, Thuwal, Saudi Arabia;King Abdullah University of Science and Technology, Thuwal, Saudi Arabia;Saudi Aramco, Dhahran, Saudi Arabia;King Abdullah University of Science and Technology, Thuwal, Saudi Arabia;King Abdullah University of Science and Technology, Thuwal, Saudi Arabia",0.1109/visual.1999.809908;10.1109/tvcg.2014.2346324;10.1109/tvcg.2012.240;10.1109/visual.1999.809869,"Geological models,structured hexahedral meshes,,multiresolution representations,interactive visualization",,0,48,551,,
TVCG,2023,Graphical Enhancements for Effective Exemplar Identification in Contextual Data Visualizations,10.1109/tvcg.2022.3170531,http://dx.doi.org/10.1109/TVCG.2022.3170531,3775,3787,J,"An exemplar is an entity that represents a desirable instance in a multi-attribute configuration space. It offers certain strengths in some of its attributes without unduly compromising the strengths in other attributes. Exemplars are frequently sought after in real life applications, such as systems engineering, investment banking, drug advisory, product marketing and many others. We study a specific method for the visualization of multi-attribute configuration spaces, the Data Context Map (DCM), for its capacity in enabling users to identify proper exemplars. The DCM produces a 2D embedding where users can view the data objects in the context of the data attributes. We ask whether certain graphical enhancements can aid users to gain a better understanding of the attribute-wise tradeoffs and so select better exemplar sets. We conducted several user studies for three different graphical designs, namely iso-contour, value-shaded topographic rendering and terrain topographic rendering, and compare these with a baseline DCM display. As a benchmark we use an exemplar set generated via Pareto optimization which has similar goals but unlike humans can operate in the native high-dimensional data space. Our study finds that the two topographic maps are statistically superior to both the iso-contour and the DCM baseline display.",Xinyu Zhang;Shenghui Cheng;Klaus Mueller 0001,Xinyu Zhang;Shenghui Cheng;Klaus Mueller,"Department of Computer Science, Stony Brook University, NY, USA;Westlake University, Westlake Institute for Advanced Study and Research Center for the Industries of the Future, Hangzhou, China;Department of Computer Science, Stony Brook University, NY, USA",0.1109/tvcg.2015.2467552;10.1109/tvcg.2018.2808489;10.1109/tvcg.2017.2745138;10.1109/tvcg.2018.2865194;10.1109/tvcg.2013.173;10.1109/visual.1997.663916;10.1109/tvcg.2019.2895642;10.1109/tvcg.2012.65;10.1109/vast.2010.5652940;10.1109/tvcg.2016.2598589;10.1109/tvcg.2007.70596;10.1109/tvcg.2009.127;10.1109/tvcg.2007.70589;10.1109/infvis.1995.528686;10.1109/tvcg.2014.2350494,"High-dimensional data,multivariate data,,contextual displays,exemplar generation,decision support,configuration space",,0,70,644,,
