Conference,Year,Title,DOI,Link,FirstPage,LastPage,PaperType,Abstract,AuthorNames-Deduped,AuthorNames,AuthorAffiliation,InternalReferences,AuthorKeywords,AminerCitationCount,CitationCount_CrossRef,PubsCited,Award
conference_external,2014,Activity Sculptures: Exploring the Impact of Physical Visualizations on Running Activity,10.1109/TVCG.2014.2352953,http://dx.doi.org/10.1109/TVCG.2014.2352953,2201,2210,Journals,"Data sculptures are a promising type of visualizations in which data is given a physical form. In the past, they have mostly been used for artistic, communicative or educational purposes, and designers of data sculptures argue that in such situations, physical visualizations can be more enriching than pixel-based visualizations. We present the design of Activity Sculptures: data sculptures of running activity. In a three-week field study we investigated the impact of the sculptures on 14 participants' running activity, the personal and social behaviors generated by the sculptures, as well as participants' experiences when receiving these individual physical tokens generated from the specific data of their runs. The physical rewards generated curiosity and personal experimentation but also social dynamics such as discussion on runs or envy/competition. We argue that such passive (or calm) visualizations can complement nudging and other mechanisms of persuasion with a more playful and reflective look at ones' activity.",,Simon Stusak;Aurélien Tabard;Franziska Sauka;Rohit Ashok Khot;Andreas Butz,"University of Munich (LMU);Université de Lyon & CNRS, France;University of Munich (LMU);Exertion Games Lab, RMIT University;University of Munich (LMU)",,"Physical Visualizations,Activity Sculptures,,Physical Activity,Data Sculptures,Behavioral Change,,,,,",,27,,
SciVis,2014,Fast and Memory-Efficienty Topological Denoising of 2D and 3D Scalar Fields,10.1109/TVCG.2014.2346432,http://dx.doi.org/10.1109/TVCG.2014.2346432,2585,2594,Journals,"Data acquisition, numerical inaccuracies, and sampling often introduce noise in measurements and simulations. Removing this noise is often necessary for efficient analysis and visualization of this data, yet many denoising techniques change the minima and maxima of a scalar field. For example, the extrema can appear or disappear, spatially move, and change their value. This can lead to wrong interpretations of the data, e.g., when the maximum temperature over an area is falsely reported being a few degrees cooler because the denoising method is unaware of these features. Recently, a topological denoising technique based on a global energy optimization was proposed, which allows the topology-controlled denoising of 2D scalar fields. While this method preserves the minima and maxima, it is constrained by the size of the data. We extend this work to large 2D data and medium-sized 3D data by introducing a novel domain decomposition approach. It allows processing small patches of the domain independently while still avoiding the introduction of new critical points. Furthermore, we propose an iterative refinement of the solution, which decreases the optimization energy compared to the previous approach and therefore gives smoother results that are closer to the input. We illustrate our technique on synthetic and real-world 2D and 3D data sets that highlight potential applications.",,David Günther;Alec Jacobson;Jan Reininghaus;Hans-Peter Seidel;Olga Sorkine-Hornung;Tino Weinkauf,"Institut Mines-Télécom, Paris, France;Columbia University, New York, USA;IST Austria, Vienna, Austria;Max Planck Institute for Informatics, Saarbrücken, Germany;ETH Zürich, Zürich, Switzerland;Max Planck Institute for Informatics, Saarbrücken, Germany",,"Numerical optimization,topology,,scalar fields,,,,,,,",,17,,
conference_external,2014,Ranking Visualizations of Correlation Using Weber's Law,10.1109/TVCG.2014.2346979,http://dx.doi.org/10.1109/TVCG.2014.2346979,1943,1952,Journals,"Despite years of research yielding systems and guidelines to aid visualization design, practitioners still face the challenge of identifying the best visualization for a given dataset and task. One promising approach to circumvent this problem is to leverage perceptual laws to quantitatively evaluate the effectiveness of a visualization design. Following previously established methodologies, we conduct a large scale (n = 1687) crowdsourced experiment to investigate whether the perception of correlation in nine commonly used visualizations can be modeled using Weber's law. The results of this experiment contribute to our understanding of information visualization by establishing that: (1) for all tested visualizations, the precision of correlation judgment could be modeled by Weber's law, (2) correlation judgment precision showed striking variation between negatively and positively correlated data, and (3) Weber models provide a concise means to quantify, compare, and rank the perceptual precision afforded by a visualization.",,Lane Harrison;Fumeng Yang;Steven Franconeri;Remco Chang,Tufts University;Tufts University;Northwestern University;Tufts University,,"Perception,Visualization,,Evaluation,,,,,,,",,66,,
conference_external,2014,Visual Abstraction and Exploration of Multi-class Scatterplots,10.1109/TVCG.2014.2346594,http://dx.doi.org/10.1109/TVCG.2014.2346594,1683,1692,Journals,"Scatterplots are widely used to visualize scatter dataset for exploring outliers, clusters, local trends, and correlations. Depicting multi-class scattered points within a single scatterplot view, however, may suffer from heavy overdraw, making it inefficient for data analysis. This paper presents a new visual abstraction scheme that employs a hierarchical multi-class sampling technique to show a feature-preserving simplification. To enhance the density contrast, the colors of multiple classes are optimized by taking the multi-class point distributions into account. We design a visual exploration system that supports visual inspection and quantitative analysis from different perspectives. We have applied our system to several challenging datasets, and the results demonstrate the efficiency of our approach.",,Haidong Chen;Wei Chen;Honghui Mei;Zhiqi Liu;Kun Zhou;Weifeng Chen;Wentao Gu;Kwan-Liu Ma,State Key Lab of CAD&CG;State Key Lab of CAD&CG;State Key Lab of CAD&CG;State Key Lab of CAD&CG;State Key Lab of CAD&CG;Zhejiang University of Finance & Economics;Zhejiang GongShang University;University of California at Davis,,"Scatterplot,overdraw reduction,,sampling,visual abstraction,,,,,,",,56,,
conference_external,2014,A Principled Way of Assessing Visualization Literacy,10.1109/TVCG.2014.2346984,http://dx.doi.org/10.1109/TVCG.2014.2346984,1963,1972,Journals,"We describe a method for assessing the visualization literacy (VL) of a user. Assessing how well people understand visualizations has great value for research (e. g., to avoid confounds), for design (e. g., to best determine the capabilities of an audience), for teaching (e. g., to assess the level of new students), and for recruiting (e. g., to assess the level of interviewees). This paper proposes a method for assessing VL based on Item Response Theory. It describes the design and evaluation of two VL tests for line graphs, and presents the extension of the method to bar charts and scatterplots. Finally, it discusses the reimplementation of these tests for fast, effective, and scalable web-based use.",,Jeremy Boy;Ronald A. Rensink;Enrico Bertini;Jean-Daniel Fekete,"Inria, Telecom ParisTech, EnsadLab;University of British Columbia;NYU Polytechnic School of Engineering;Inria",,"Literacy,Visualization literacy,,Rasch Model,Item Response Theory,,,,,,",,52,,
conference_external,2014,Visualizing Mobility of Public Transportation System,10.1109/TVCG.2014.2346893,http://dx.doi.org/10.1109/TVCG.2014.2346893,1833,1842,Journals,"Public transportation systems (PTSs) play an important role in modern cities, providing shared/massive transportation services that are essential for the general public. However, due to their increasing complexity, designing effective methods to visualize and explore PTS is highly challenging. Most existing techniques employ network visualization methods and focus on showing the network topology across stops while ignoring various mobility-related factors such as riding time, transfer time, waiting time, and round-the-clock patterns. This work aims to visualize and explore passenger mobility in a PTS with a family of analytical tasks based on inputs from transportation researchers. After exploring different design alternatives, we come up with an integrated solution with three visualization modules: isochrone map view for geographical information, isotime flow map view for effective temporal information comparison and manipulation, and OD-pair journey view for detailed visual analysis of mobility factors along routes between specific origin-destination pairs. The isotime flow map linearizes a flow map into a parallel isoline representation, maximizing the visualization of mobility information along the horizontal time axis while presenting clear and smooth pathways from origin to destinations. Moreover, we devise several interactive visual query methods for users to easily explore the dynamics of PTS mobility over space and time. Lastly, we also construct a PTS mobility model from millions of real passenger trajectories, and evaluate our visualization techniques with assorted case studies with the transportation researchers.",,Wei Zeng;Chi-Wing Fu;Stefan Müller Arisona;Alexander Erath;Huamin Qu,"Nanyang Technological University, Singapore;Nanyang Technological University, Singapore;University of Applied Sciences;ETH Zurich;Hong Kong University of Science and Technology",,"Mobility,public transportation,,visual analytics,,,,,,,",,54,,
SciVis,2014,Visualization of Brain Microstructure Through Spherical Harmonics Illumination of High Fidelity Spatio-Angular Fields,10.1109/TVCG.2014.2346411,http://dx.doi.org/10.1109/TVCG.2014.2346411,2516,2525,Journals,"Diffusion kurtosis imaging (DKI) is gaining rapid adoption in the medical imaging community due to its ability to measure the non-Gaussian property of water diffusion in biological tissues. Compared to traditional diffusion tensor imaging (DTI), DKI can provide additional details about the underlying microstructural characteristics of the neural tissues. It has shown promising results in studies on changes in gray matter and mild traumatic brain injury where DTI is often found to be inadequate. The DKI dataset, which has high-fidelity spatio-angular fields, is difficult to visualize. Glyph-based visualization techniques are commonly used for visualization of DTI datasets; however, due to the rapid changes in orientation, lighting, and occlusion, visually analyzing the much more higher fidelity DKI data is a challenge. In this paper, we provide a systematic way to manage, analyze, and visualize high-fidelity spatio-angular fields from DKI datasets, by using spherical harmonics lighting functions to facilitate insights into the brain microstructure.",,Sujal Bista;Jiachen Zhuo;Rao P. Gullapalli;Amitabh Varshney,"University of Maryland, College Park;University of Maryland School of Medicine at Baltimore;University of Maryland School of Medicine at Baltimore;University of Maryland, College Park",,"Diffusion Kurtosis Imaging,Diffusion Tensor Imaging,,Spatio-Angular Fields,Spherical Harmonics Fields,Tensor Fields,,,,,",,10,,
SciVis,2014,Stent Maps — Comparative Visualization for the Prediction of Adverse Events of Transcatheter Aortic Valve Implantations,10.1109/TVCG.2014.2346459,http://dx.doi.org/10.1109/TVCG.2014.2346459,2704,2713,Journals,"Transcatheter aortic valve implantation (TAVI) is a minimally-invasive method for the treatment of aortic valve stenosis in patients with high surgical risk. Despite the success of TAVI, side effects such as paravalvular leakages can occur postoperatively. The goal of this project is to quantitatively analyze the co-occurrence of this complication and several potential risk factors such as stent shape after implantation, implantation height, amount and distribution of calcifications, and contact forces between stent and surrounding structure. In this paper, we present a two-dimensional visualization (stent maps), which allows (1) to comprehensively display all these aspects from CT data and mechanical simulation results and (2) to compare different datasets to identify patterns that are typical for adverse effects. The area of a stent map represents the surface area of the implanted stent - virtually straightened and uncoiled. Several properties of interest, like radial forces or stent compression, are displayed in this stent map in a heatmap-like fashion. Important anatomical landmarks and calcifications are plotted to show their spatial relation to the stent and possible correlations with the color-coded parameters. To provide comparability, the maps of different patient datasets are spatially adjusted according to a corresponding anatomical landmark. Also, stent maps summarizing the characteristics of different populations (e.g. with or without side effects) can be generated. Up to this point several interesting patterns have been observed with our technique, which remained hidden when examining the raw CT data or 3D visualizations of the same data. One example are obvious radial force maxima between the right and non-coronary valve leaflet occurring mainly in cases without leakages. These observations confirm the usefulness of our approach and give starting points for new hypotheses and further analyses. Because of its reduced dimensionality, the stent map data is an appropriate input for statistical group evaluation and machine learning methods.",,Silvia Born;Simon H. Sündermann;Christoph Russ;Raoul Hopf;Carlos E. Ruiz;Volkmar Falk;Michael Gessat,"University of Zurich, Switzerland;Division of Cardiovascular Surgery, University Hospital of Zurich, Switzerland;Swiss Federal Institute of Technology (ETH) Zurich, Switzerland;Swiss Federal Institute of Technology (ETH) Zurich, Switzerland;Structural and Congenital Heart Division, Lenox Hill Hospital;Division of Cardiovascular Surgery, University Hospital of Zurich, Switzerland;University of Zurich, Switzerland",,"Comparative visualization,medical visualization,,vessel flattening,transcatheter aortic valve implantation (TAVI),,,,,,",,8,,
conference_external,2014,Design Activity Framework for Visualization Design,10.1109/TVCG.2014.2346331,http://dx.doi.org/10.1109/TVCG.2014.2346331,2191,2200,Journals,"An important aspect in visualization design is the connection between what a designer does and the decisions the designer makes. Existing design process models, however, do not explicitly link back to models for visualization design decisions. We bridge this gap by introducing the design activity framework, a process model that explicitly connects to the nested model, a well-known visualization design decision model. The framework includes four overlapping activities that characterize the design process, with each activity explicating outcomes related to the nested model. Additionally, we describe and characterize a list of exemplar methods and how they overlap among these activities. The design activity framework is the result of reflective discussions from a collaboration on a visualization redesign project, the details of which we describe to ground the framework in a real-world design process. Lastly, from this redesign project we provide several research outcomes in the domain of cybersecurity, including an extended data abstraction and rich opportunities for future visualization research.",,Sean McKenna;Dominika Mazur;James Agutter;Miriah Meyer,"School of Computing, Salt Lake City, UT;Department of Psychology, University of Utah, Salt Lake City, UT;College of Architecture and Planning, University of Utah, Salt Lake City, UT;School of Computing, Salt Lake City, UT",,"Design,frameworks,,process,cybersecurity,nested model,decisions,models,evaluation,visualization,",,38,,
SciVis,2014,Boundary Aware Reconstruction of Scalar Fields,10.1109/TVCG.2014.2346351,http://dx.doi.org/10.1109/TVCG.2014.2346351,2447,2455,Journals,"In visualization, the combined role of data reconstruction and its classification plays a crucial role. In this paper we propose a novel approach that improves classification of different materials and their boundaries by combining information from the classifiers at the reconstruction stage. Our approach estimates the targeted materials' local support before performing multiple material-specific reconstructions that prevent much of the misclassification traditionally associated with transitional regions and transfer function (TF) design. With respect to previously published methods our approach offers a number of improvements and advantages. For one, it does not rely on TFs acting on derivative expressions, therefore it is less sensitive to noisy data and the classification of a single material does not depend on specialized TF widgets or specifying regions in a multidimensional TF. Additionally, improved classification is attained without increasing TF dimensionality, which promotes scalability to multivariate data. These aspects are also key in maintaining low interaction complexity. The results are simple-to-achieve visualizations that better comply with the user's understanding of discrete features within the studied object.",,Stefan Lindholm;Daniel Jönsson;Charles Hansen;Anders Ynnerman,"Department of Science and Technology, Linköping University;Department of Science and Technology, Linköping University;Scientific Computing and Imaging Institute, University of Utah;Department of Science and Technology, Linköping University",,"Reconstruction,signal processing,,kernel regression,volume rendering,,,,,,",,7,,
conference_external,2014,Footprints: A Visual Search Tool that Supports Discovery and Coverage Tracking,10.1109/TVCG.2014.2346743,http://dx.doi.org/10.1109/TVCG.2014.2346743,1793,1802,Journals,"Searching a large document collection to learn about a broad subject involves the iterative process of figuring out what to ask, filtering the results, identifying useful documents, and deciding when one has covered enough material to stop searching. We are calling this activity “discoverage,” discovery of relevant material and tracking coverage of that material. We built a visual analytic tool called Footprints that uses multiple coordinated visualizations to help users navigate through the discoverage process. To support discovery, Footprints displays topics extracted from documents that provide an overview of the search space and are used to construct searches visuospatially. Footprints allows users to triage their search results by assigning a status to each document (To Read, Read, Useful), and those status markings are shown on interactive histograms depicting the user's coverage through the documents across dates, sources, and topics. Coverage histograms help users notice biases in their search and fill any gaps in their analytic process. To create Footprints, we used a highly iterative, user-centered approach in which we conducted many evaluations during both the design and implementation stages and continually modified the design in response to feedback.",,Ellen Isaacs;Kelly Damico;Shane Ahern;Eugene Bart;Mudita Singhal,Palo Alto Research Center (PARC);Palo Alto Research Center (PARC);Palo Alto Research Center (PARC);Palo Alto Research Center (PARC);Palo Alto Research Center (PARC),,"discovery search visualization,visual cues,,discoverage,coverage tracking,document triage,interactive histograms,,,,",,6,,
SciVis,2014,Sparse PDF Volumes for Consistent Multi-Resolution Volume Rendering,10.1109/TVCG.2014.2346324,http://dx.doi.org/10.1109/TVCG.2014.2346324,2417,2426,Journals,"This paper presents a new multi-resolution volume representation called sparse pdf volumes, which enables consistent multi-resolution volume rendering based on probability density functions (pdfs) of voxel neighborhoods. These pdfs are defined in the 4D domain jointly comprising the 3D volume and its 1D intensity range. Crucially, the computation of sparse pdf volumes exploits data coherence in 4D, resulting in a sparse representation with surprisingly low storage requirements. At run time, we dynamically apply transfer functions to the pdfs using simple and fast convolutions. Whereas standard low-pass filtering and down-sampling incur visible differences between resolution levels, the use of pdfs facilitates consistent results independent of the resolution level used. We describe the efficient out-of-core computation of large-scale sparse pdf volumes, using a novel iterative simplification procedure of a mixture of 4D Gaussians. Finally, our data structure is optimized to facilitate interactive multi-resolution volume rendering on GPUs.",,Ronell Sicat;Jens Krüger;Torsten Möller;Markus Hadwiger,King Abdullah University of Science and Technology (KAUST);University of Duisburg-Essen;University of Vienna;King Abdullah University of Science and Technology (KAUST),,"Multi-resolution representations,sparse approximation,,pursuit algorithms,large-scale volume rendering,,,,,,",,16,,
conference_external,2014,Supporting Communication and Coordination in Collaborative Sensemaking,10.1109/TVCG.2014.2346573,http://dx.doi.org/10.1109/TVCG.2014.2346573,1633,1642,Journals,"When people work together to analyze a data set, they need to organize their findings, hypotheses, and evidence, share that information with their collaborators, and coordinate activities amongst team members. Sharing externalizations (recorded information such as notes) could increase awareness and assist with team communication and coordination. However, we currently know little about how to provide tool support for this sort of sharing. We explore how linked common work (LCW) can be employed within a `collaborative thinking space', to facilitate synchronous collaborative sensemaking activities in Visual Analytics (VA). Collaborative thinking spaces provide an environment for analysts to record, organize, share and connect externalizations. Our tool, CLIP, extends earlier thinking spaces by integrating LCW features that reveal relationships between collaborators' findings. We conducted a user study comparing CLIP to a baseline version without LCW. Results demonstrated that LCW significantly improved analytic outcomes at a collaborative intelligence task. Groups using CLIP were also able to more effectively coordinate their work, and held more discussion of their findings and hypotheses. LCW enabled them to maintain awareness of each other's activities and findings and link those findings to their own work, preventing disruptive oral awareness notifications.",,Narges Mahyar;Melanie Tory,University of Victoria;University of Victoria,,"Sensemaking,Collaboration,,Externalization,Linked common work,Collaborative thinking space,,,,,",,44,,
SciVis,2014,Multi-Charts for Comparative 3D Ensemble Visualization,10.1109/TVCG.2014.2346448,http://dx.doi.org/10.1109/TVCG.2014.2346448,2694,2703,Journals,"A comparative visualization of multiple volume data sets is challenging due to the inherent occlusion effects, yet it is important to effectively reveal uncertainties, correlations and reliable trends in 3D ensemble fields. In this paper we present bidirectional linking of multi-charts and volume visualization as a means to analyze visually 3D scalar ensemble fields at the data level. Multi-charts are an extension of conventional bar and line charts: They linearize the 3D data points along a space-filling curve and draw them as multiple charts in the same plot area. The bar charts encode statistical information on ensemble members, such as histograms and probability densities, and line charts are overlayed to allow comparing members against the ensemble. Alternative linearizations based on histogram similarities or ensemble variation allow clustering of spatial locations depending on data distribution. Multi-charts organize the data at multiple scales to quickly provide overviews and enable users to select regions exhibiting interesting behavior interactively. They are further put into a spatial context by allowing the user to brush or query value intervals and specific distributions, and to simultaneously visualize the corresponding spatial points via volume rendering. By providing a picking mechanism in 3D and instantly highlighting the corresponding data points in the chart, the user can go back and forth between the abstract and the 3D view to focus the analysis.",,Ismail Demir;Christian Dick;Rüdiger Westermann,"Computer Graphics and Visualization Group, Technische Universität München Informatik 15, Garching, Germany;Computer Graphics and Visualization Group, Technische Universität München Informatik 15, Garching, Germany;Computer Graphics and Visualization Group, Technische Universität München Informatik 15, Garching, Germany",,"Ensemble visualization,brushing and linking,,statistical analysis,,,,,,,",,40,,
conference_external,2014,Visual Reconciliation of Alternative Similarity Spaces in Climate Modeling,10.1109/TVCG.2014.2346755,http://dx.doi.org/10.1109/TVCG.2014.2346755,1923,1932,Journals,"Visual data analysis often requires grouping of data objects based on their similarity. In many application domains researchers use algorithms and techniques like clustering and multidimensional scaling to extract groupings from data. While extracting these groups using a single similarity criteria is relatively straightforward, comparing alternative criteria poses additional challenges. In this paper we define visual reconciliation as the problem of reconciling multiple alternative similarity spaces through visualization and interaction. We derive this problem from our work on model comparison in climate science where climate modelers are faced with the challenge of making sense of alternative ways to describe their models: one through the output they generate, another through the large set of properties that describe them. Ideally, they want to understand whether groups of models with similar spatio-temporal behaviors share similar sets of criteria or, conversely, whether similar criteria lead to similar behaviors. We propose a visual analytics solution based on linked views, that addresses this problem by allowing the user to dynamically create, modify and observe the interaction among groupings, thereby making the potential explanations apparent. We present case studies that demonstrate the usefulness of our technique in the area of climate science.",,Jorge Poco;Aritra Dasgupta;Yaxing Wei;William Hargrove;Christopher R. Schwalm;Deborah N. Huntzinger;Robert Cook;Enrico Bertini;Claudio T. Silva,New York University;New York University and DataONE;Oak Ridge National Laboratory;USDA Forest Service;Northern Arizona University;Northern Arizona University;Oak Ridge National Laboratory;New York University;New York University,,"Similarity,clustering,,matrix,optimization,climate model,,,,,",,13,,
SciVis,2014,Volume-Preserving Mapping and Registration for Collective Data Visualization,10.1109/TVCG.2014.2346457,http://dx.doi.org/10.1109/TVCG.2014.2346457,2664,2673,Journals,"In order to visualize and analyze complex collective data, complicated geometric structure of each data is desired to be mapped onto a canonical domain to enable map-based visual exploration. This paper proposes a novel volume-preserving mapping and registration method which facilitates effective collective data visualization. Given two 3-manifolds with the same topology, there exists a mapping between them to preserve each local volume element. Starting from an initial mapping, a volume restoring diffeomorphic flow is constructed as a compressible flow based on the volume forms at the manifold. Such a flow yields equality of each local volume element between the original manifold and the target at its final state. Furthermore, the salient features can be used to register the manifold to a reference template by an incompressible flow guided by a divergence-free vector field within the manifold. The process can retain the equality of local volume elements while registering the manifold to a template at the same time. An efficient and practical algorithm is also presented to generate a volume-preserving mapping and a salient feature registration on discrete 3D volumes which are represented with tetrahedral meshes embedded in 3D space. This method can be applied to comparative analysis and visualization of volumetric medical imaging data across subjects. We demonstrate an example application in multimodal neuroimaging data analysis and collective data visualization.",,Jiaxi Hu;Guangyu Jeff Zou;Jing Hua,"Department of Computer Science, Wayne State University, Detroit, MI;Department of Computer Science, Wayne State University, Detroit, MI;Department of Computer Science, Wayne State University, Detroit, MI",,"Volume-preserving mapping,data regularization,,data transformation,,,,,,,",,3,,
SciVis,2014,Using Topological Analysis to Support Event-Guided Exploration in Urban Data,10.1109/TVCG.2014.2346449,http://dx.doi.org/10.1109/TVCG.2014.2346449,2634,2643,Journals,"The explosion in the volume of data about urban environments has opened up opportunities to inform both policy and administration and thereby help governments improve the lives of their citizens, increase the efficiency of public services, and reduce the environmental harms of development. However, cities are complex systems and exploring the data they generate is challenging. The interaction between the various components in a city creates complex dynamics where interesting facts occur at multiple scales, requiring users to inspect a large number of data slices over time and space. Manual exploration of these slices is ineffective, time consuming, and in many cases impractical. In this paper, we propose a technique that supports event-guided exploration of large, spatio-temporal urban data. We model the data as time-varying scalar functions and use computational topology to automatically identify events in different data slices. To handle a potentially large number of events, we develop an algorithm to group and index them, thus allowing users to interactively explore and query event patterns on the fly. A visual exploration interface helps guide users towards data slices that display interesting events and trends. We demonstrate the effectiveness of our technique on two different data sets from New York City (NYC): data about taxi trips and subway service. We also report on the feedback we received from analysts at different NYC agencies.",,Harish Doraiswamy;Nivan Ferreira;Theodoros Damoulas;Juliana Freire;Cláudio T. Silva,New York University;New York University;New York University;New York University;New York University,,"Computational topology,event detection,,spatio-temporal index,urban data,visual exploration,,,,,",,36,,
conference_external,2014,Revisiting Bertin Matrices: New Interactions for Crafting Tabular Visualizations,10.1109/TVCG.2014.2346279,http://dx.doi.org/10.1109/TVCG.2014.2346279,2082,2091,Journals,"We present Bertifier, a web app for rapidly creating tabular visualizations from spreadsheets. Bertifier draws from Jacques Bertin's matrix analysis method, whose goal was to “simplify without destroying” by encoding cell values visually and grouping similar rows and columns. Although there were several attempts to bring this method to computers, no implementation exists today that is both exhaustive and accessible to a large audience. Bertifier remains faithful to Bertin's method while leveraging the power of today's interactive computers. Tables are formatted and manipulated through crossets, a new interaction technique for rapidly applying operations on rows and columns. We also introduce visual reordering, a semi-interactive reordering approach that lets users apply and tune automatic reordering algorithms in a WYSIWYG manner. Sessions with eight users from different backgrounds suggest that Bertifier has the potential to bring Bertin's method to a wider audience of both technical and non-technical users, and empower them with data analysis and communication tools that were so far only accessible to a handful of specialists.COMPUTER",,Charles Perin;Pierre Dragicevic;Jean-Daniel Fekete,INRIA;INRIA;INRIA,,"Visualization,Interaction,,Tabular Data,Bertin,Crossing,Crossets,,,,",,45,,
conference_external,2014,EvoRiver: Visual Analysis of Topic Coopetition on Social Media,10.1109/TVCG.2014.2346919,http://dx.doi.org/10.1109/TVCG.2014.2346919,1753,1762,Journals,"Cooperation and competition (jointly called “coopetition”) are two modes of interactions among a set of concurrent topics on social media. How do topics cooperate or compete with each other to gain public attention? Which topics tend to cooperate or compete with one another? Who plays the key role in coopetition-related interactions? We answer these intricate questions by proposing a visual analytics system that facilitates the in-depth analysis of topic coopetition on social media. We model the complex interactions among topics as a combination of carry-over, coopetition recruitment, and coopetition distraction effects. This model provides a close functional approximation of the coopetition process by depicting how different groups of influential users (i.e., “topic leaders”) affect coopetition. We also design EvoRiver, a time-based visualization, that allows users to explore coopetition-related interactions and to detect dynamically evolving patterns, as well as their major causes. We test our model and demonstrate the usefulness of our system based on two Twitter data sets (social topics data and business topics data).",,Guodao Sun;Yingcai Wu;Shixia Liu;Tai-Quan Peng;Jonathan J. H. Zhu;Ronghua Liang,Zhejiang University of Technology;Microsoft Research;Microsoft Research;Nanyang Technological University;City University of Hong Kong;Zhejiang University of Technology,,"Topic coopetition,information diffusion,,information propagation,time-based visualization,,,,,,",,64,,
SciVis,2014,Vivaldi: A Domain-Specific Language for Volume Processing and Visualization on Distributed Heterogeneous Systems,10.1109/TVCG.2014.2346322,http://dx.doi.org/10.1109/TVCG.2014.2346322,2407,2416,Journals,"As the size of image data from microscopes and telescopes increases, the need for high-throughput processing and visualization of large volumetric data has become more pressing. At the same time, many-core processors and GPU accelerators are commonplace, making high-performance distributed heterogeneous computing systems affordable. However, effectively utilizing GPU clusters is difficult for novice programmers, and even experienced programmers often fail to fully leverage the computing power of new parallel architectures due to their steep learning curve and programming complexity. In this paper, we propose Vivaldi, a new domain-specific language for volume processing and visualization on distributed heterogeneous computing systems. Vivaldi's Python-like grammar and parallel processing abstractions provide flexible programming tools for non-experts to easily write high-performance parallel computing code. Vivaldi provides commonly used functions and numerical operators for customized visualization and high-throughput image processing applications. We demonstrate the performance and usability of Vivaldi on several examples ranging from volume rendering to image segmentation.",,Hyungsuk Choi;Woohyuk Choi;Tran Minh Quan;David G. C. Hildebrand;Hanspeter Pfister;Won-Ki Jeong,Ulsan National Institute of Science and Technology (UNIST);Ulsan National Institute of Science and Technology (UNIST);Ulsan National Institute of Science and Technology (UNIST);Harvard University;Harvard University;Ulsan National Institute of Science and Technology (UNIST),,"Domain-specific language,volume rendering,,GPU computing,distributed heterogeneous systems,,,,,,",,18,,
conference_external,2014,PanoramicData: Data Analysis through Pen & Touch,10.1109/TVCG.2014.2346293,http://dx.doi.org/10.1109/TVCG.2014.2346293,2112,2121,Journals,"Interactively exploring multidimensional datasets requires frequent switching among a range of distinct but inter-related tasks (e.g., producing different visuals based on different column sets, calculating new variables, and observing the interactions between sets of data). Existing approaches either target specific different problem domains (e.g., data-transformation or data-presentation) or expose only limited aspects of the general exploratory process; in either case, users are forced to adopt coping strategies (e.g., arranging windows or using undo as a mechanism for comparison instead of using side-by-side displays) to compensate for the lack of an integrated suite of exploratory tools. PanoramicData (PD) addresses these problems by unifying a comprehensive set of tools for visual data exploration into a hybrid pen and touch system designed to exploit the visualization advantages of large interactive displays. PD goes beyond just familiar visualizations by including direct UI support for data transformation and aggregation, filtering and brushing. Leveraging an unbounded whiteboard metaphor, users can combine these tools like building blocks to create detailed interactive visual display networks in which each visualization can act as a filter for others. Further, by operating directly on relational-databases, PD provides an approachable visual language that exposes a broad set of the expressive power of SQL including functionally complete logic filtering, computation of aggregates and natural table joins. To understand the implications of this novel approach, we conducted a formative user study with both data and visualization experts. The results indicated that the system provided a fluid and natural user experience for probing multi-dimensional data and was able to cover the full range of queries that the users wanted to pose.",,Emanuel Zgraggen;Robert Zeleznik;Steven M. Drucker,Brown University;Brown University;Microsoft Research,,"Visual analytics,pen and touch,,user interfaces,interaction design,coordinated and multiple views,,,,,",,15,,
conference_external,2014,"Domino: Extracting, Comparing, and Manipulating Subsets Across Multiple Tabular Datasets",10.1109/TVCG.2014.2346260,http://dx.doi.org/10.1109/TVCG.2014.2346260,2023,2032,Journals,"Answering questions about complex issues often requires analysts to take into account information contained in multiple interconnected datasets. A common strategy in analyzing and visualizing large and heterogeneous data is dividing it into meaningful subsets. Interesting subsets can then be selected and the associated data and the relationships between the subsets visualized. However, neither the extraction and manipulation nor the comparison of subsets is well supported by state-of-the-art techniques. In this paper we present Domino, a novel multiform visualization technique for effectively representing subsets and the relationships between them. By providing comprehensive tools to arrange, combine, and extract subsets, Domino allows users to create both common visualization techniques and advanced visualizations tailored to specific use cases. In addition to the novel technique, we present an implementation that enables analysts to manage the wide range of options that our approach offers. Innovative interactive features such as placeholders and live previews support rapid creation of complex analysis setups. We introduce the technique and the implementation using a simple example and demonstrate scalability and effectiveness in a use case from the field of cancer genomics.",,Samuel Gratzl;Nils Gehlenborg;Alexander Lex;Hanspeter Pfister;Marc Streit,Johannes Kepler University Linz;Harvard Medical School;Harvard University;Harvard University;Johannes Kepler University Linz,,"Multiple coordinated views,visual linking,,relationships,heterogeneous data,categorical data,,,,,",,31,,
conference_external,2014,Visual Parameter Space Analysis: A Conceptual Framework,10.1109/TVCG.2014.2346321,http://dx.doi.org/10.1109/TVCG.2014.2346321,2161,2170,Journals,"Various case studies in different application domains have shown the great potential of visual parameter space analysis to support validating and using simulation models. In order to guide and systematize research endeavors in this area, we provide a conceptual framework for visual parameter space analysis problems. The framework is based on our own experience and a structured analysis of the visualization literature. It contains three major components: (1) a data flow model that helps to abstractly describe visual parameter space analysis problems independent of their application domain; (2) a set of four navigation strategies of how parameter space analysis can be supported by visualization tools; and (3) a characterization of six analysis tasks. Based on our framework, we analyze and classify the current body of literature, and identify three open research gaps in visual parameter space analysis. The framework and its discussion are meant to support visualization designers and researchers in characterizing parameter space analysis problems and to guide their design and evaluation processes.",,Michael Sedlmair;Christoph Heinzl;Stefan Bruckner;Harald Piringer;Torsten Möller,University of Vienna;University of Applied Sciences Upper Austria;University of Bergen;VRVis;University of Vienna,,"Parameter space analysis,input-output model,,simulation,task characterization,literature analysis,,,,,",,84,,
conference_external,2014,The Not-so-Staggering Effect of Staggered Animated Transitions on Visual Tracking,10.1109/TVCG.2014.2346424,http://dx.doi.org/10.1109/TVCG.2014.2346424,2241,2250,Journals,"Interactive visual applications often rely on animation to transition from one display state to another. There are multiple animation techniques to choose from, and it is not always clear which should produce the best visual correspondences between display elements. One major factor is whether the animation relies on staggering-an incremental delay in start times across the moving elements. It has been suggested that staggering may reduce occlusion, while also reducing display complexity and producing less overwhelming animations, though no empirical evidence has demonstrated these advantages. Work in perceptual psychology does show that reducing occlusion, and reducing inter-object proximity (crowding) more generally, improves performance in multiple object tracking. We ran simulations confirming that staggering can in some cases reduce crowding in animated transitions involving dot clouds (as found in, e.g., animated 2D scatterplots). We empirically evaluated the effect of two staggering techniques on tracking tasks, focusing on cases that should most favour staggering. We found that introducing staggering has a negligible, or even negative, impact on multiple object tracking performance. The potential benefits of staggering may be outweighed by strong costs: a loss of common-motion grouping information about which objects travel in similar paths, and less predictability about when any specific object would begin to move. Staggering may be beneficial in some conditions, but they have yet to be demonstrated. The present results are a significant step toward a better understanding of animation pacing, and provide direction for further research.",,Fanny Chevalier;Pierre Dragicevic;Steven Franconeri,Inria;Inria;Northwestern University,,"Animated transitions,staggered animation,,visual tracking,,,,,,,",,29,,
conference_external,2014,ConTour: Data-Driven Exploration of Multi-Relational Datasets for Drug Discovery,10.1109/TVCG.2014.2346752,http://dx.doi.org/10.1109/TVCG.2014.2346752,1883,1892,Journals,"Large scale data analysis is nowadays a crucial part of drug discovery. Biologists and chemists need to quickly explore and evaluate potentially effective yet safe compounds based on many datasets that are in relationship with each other. However, there is a lack of tools that support them in these processes. To remedy this, we developed ConTour, an interactive visual analytics technique that enables the exploration of these complex, multi-relational datasets. At its core ConTour lists all items of each dataset in a column. Relationships between the columns are revealed through interaction: selecting one or multiple items in one column highlights and re-sorts the items in other columns. Filters based on relationships enable drilling down into the large data space. To identify interesting items in the first place, ConTour employs advanced sorting strategies, including strategies based on connectivity strength and uniqueness, as well as sorting based on item attributes. ConTour also introduces interactive nesting of columns, a powerful method to show the related items of a child column for each item in the parent column. Within the columns, ConTour shows rich attribute data about the items as well as information about the connection strengths to other datasets. Finally, ConTour provides a number of detail views, which can show items from multiple datasets and their associated data at the same time. We demonstrate the utility of our system in case studies conducted with a team of chemical biologists, who investigate the effects of chemical compounds on cells and need to understand the underlying mechanisms.",,Christian Partl;Alexander Lex;Marc Streit;Hendrik Strobelt;Anne-Mai Wassermann;Hanspeter Pfister;Dieter Schmalstieg,Graz University of Technology;Harvard University;Johannes Kepler University Linz;Harvard University;Novartis Institutes for BicMedical Research;Harvard University;Graz University of Technology,,"Multi-relational data,visual data analysis,,drug discovery,,,,,,,",,15,,
SciVis,2014,Conforming Morse-Smale Complexes,10.1109/TVCG.2014.2346434,http://dx.doi.org/10.1109/TVCG.2014.2346434,2595,2603,Journals,"Morse-Smale (MS) complexes have been gaining popularity as a tool for feature-driven data analysis and visualization. However, the quality of their geometric embedding and the sole dependence on the input scalar field data can limit their applicability when expressing application-dependent features. In this paper we introduce a new combinatorial technique to compute an MS complex that conforms to both an input scalar field and an additional, prior segmentation of the domain. The segmentation constrains the MS complex computation guaranteeing that boundaries in the segmentation are captured as separatrices of the MS complex. We demonstrate the utility and versatility of our approach with two applications. First, we use streamline integration to determine numerically computed basins/mountains and use the resulting segmentation as an input to our algorithm. This strategy enables the incorporation of prior flow path knowledge, effectively resulting in an MS complex that is as geometrically accurate as the employed numerical integration. Our second use case is motivated by the observation that often the data itself does not explicitly contain features known to be present by a domain expert. We introduce edit operations for MS complexes so that a user can directly modify their features while maintaining all the advantages of a robust topology-based representation.",,Attila Gyulassy;David Günther;Joshua A. Levine;Julien Tierny;Valerio Pascucci,"SCI Institute;Institut Mines-Télécom, Télécom ParisTech, CNRS LTCI, Paris, France;School of Computing, Visual Computing Division, Clemson University, Clemson, SC, USA;Institut Mines-Télécom, Télécom ParisTech, CNRS LTCI, Paris, France;SCI Institute, University of Utah",,"Computational Topology,Morse-Smale Complex,,Data Analysis,,,,,,,",,15,,
SciVis,2014,Characterizing Molecular Interactions in Chemical Systems,10.1109/TVCG.2014.2346403,http://dx.doi.org/10.1109/TVCG.2014.2346403,2476,2485,Journals,"Interactions between atoms have a major influence on the chemical properties of molecular systems. While covalent interactions impose the structural integrity of molecules, noncovalent interactions govern more subtle phenomena such as protein folding, bonding or self assembly. The understanding of these types of interactions is necessary for the interpretation of many biological processes and chemical design tasks. While traditionally the electron density is analyzed to interpret the quantum chemistry of a molecular system, noncovalent interactions are characterized by low electron densities and only slight variations of them - challenging their extraction and characterization. Recently, the signed electron density and the reduced gradient, two scalar fields derived from the electron density, have drawn much attention in quantum chemistry since they enable a qualitative visualization of these interactions even in complex molecular systems and experimental measurements. In this work, we present the first combinatorial algorithm for the automated extraction and characterization of covalent and noncovalent interactions in molecular systems. The proposed algorithm is based on a joint topological analysis of the signed electron density and the reduced gradient. Combining the connectivity information of the critical points of these two scalar fields enables to visualize, enumerate, classify and investigate molecular interactions in a robust manner. Experiments on a variety of molecular systems, from simple dimers to proteins or DNA, demonstrate the ability of our technique to robustly extract these interactions and to reveal their structural relations to the atoms and bonds forming the molecules. For simple systems, our analysis corroborates the observations made by the chemists while it provides new visual and quantitative insights on chemical interactions for larger molecular systems.",,David Günther;Roberto A. Boto;Juila Contreras-Garcia;Jean-Philip Piquemal;Julien Tierny,"Institut-Mines-Télécom, Paris, France;Sorbonne Universités, Paris, France;Sorbonne Universités, Paris, France;Sorbonne Universités, Paris, France;CNRS LIP6, UPMC, Paris, France",,"Molecular Chemistry,Topological Data Analysis,,Morse-Smale Complex,Join Tree,,,,,,",,32,,
conference_external,2014,Visual Analytics for Complex Engineering Systems: Hybrid Visual Steering of Simulation Ensembles,10.1109/TVCG.2014.2346744,http://dx.doi.org/10.1109/TVCG.2014.2346744,1803,1812,Journals,"In this paper we propose a novel approach to hybrid visual steering of simulation ensembles. A simulation ensemble is a collection of simulation runs of the same simulation model using different sets of control parameters. Complex engineering systems have very large parameter spaces so a naïve sampling can result in prohibitively large simulation ensembles. Interactive steering of simulation ensembles provides the means to select relevant points in a multi-dimensional parameter space (design of experiment). Interactive steering efficiently reduces the number of simulation runs needed by coupling simulation and visualization and allowing a user to request new simulations on the fly. As system complexity grows, a pure interactive solution is not always sufficient. The new approach of hybrid steering combines interactive visual steering with automatic optimization. Hybrid steering allows a domain expert to interactively (in a visualization) select data points in an iterative manner, approximate the values in a continuous region of the simulation space (by regression) and automatically find the “best” points in this continuous region based on the specified constraints and objectives (by optimization). We argue that with the full spectrum of optimization options, the steering process can be improved substantially. We describe an integrated system consisting of a simulation, a visualization, and an optimization component. We also describe typical tasks and propose an interactive analysis workflow for complex engineering systems. We demonstrate our approach on a case study from automotive industry, the optimization of a hydraulic circuit in a high pressure common rail Diesel injection system.",,Kreŝimir Matković;Denis Gračanin;Rainer Splechtna;Mario Jelović;Benedikt Stehno;Helwig Hauser;Werner Purgathofer,"VRVis Research Center, Vienna, Austria;Virginia Tech, Blacksburg, VA, USA;VRVis Research Center, Vienna, Austria;AVL-AST Zagreb, Croatia;VRVis Research Center, Vienna, Austria;University of Bergen, Norway;Vienna University of Technology, Austria",,"Interactive Visual Analysis,Integrated Design Environment,,Simulation,Visual Steering,Automatic Optimization,,,,,",,16,,
conference_external,2014,Visual Methods for Analyzing Probabilistic Classification Data,10.1109/TVCG.2014.2346660,http://dx.doi.org/10.1109/TVCG.2014.2346660,1703,1712,Journals,"Multi-class classifiers often compute scores for the classification samples describing probabilities to belong to different classes. In order to improve the performance of such classifiers, machine learning experts need to analyze classification results for a large number of labeled samples to find possible reasons for incorrect classification. Confusion matrices are widely used for this purpose. However, they provide no information about classification scores and features computed for the samples. We propose a set of integrated visual methods for analyzing the performance of probabilistic classifiers. Our methods provide insight into different aspects of the classification results for a large number of samples. One visualization emphasizes at which probabilities these samples were classified and how these probabilities correlate with classification error in terms of false positives and false negatives. Another view emphasizes the features of these samples and ranks them by their separation power between selected true and false classifications. We demonstrate the insight gained using our technique in a benchmarking classification dataset, and show how it enables improving classification performance by interactively defining and evaluating post-classification rules.",,Bilal Alsallakh;Allan Hanbury;Helwig Hauser;Silvia Miksch;Andreas Rauber,Vienna University of Technology;Vienna University of Technology;University of Bergen;Vienna University of Technology;Vienna University of Technology,,"Probabilistic classification,confusion analysis,,feature evaluation and selection,visual inspection,,,,,,",,28,,
conference_external,2014,Tree Colors: Color Schemes for Tree-Structured Data,10.1109/TVCG.2014.2346277,http://dx.doi.org/10.1109/TVCG.2014.2346277,2072,2081,Journals,"We present a method to map tree structures to colors from the Hue-Chroma-Luminance color model, which is known for its well balanced perceptual properties. The Tree Colors method can be tuned with several parameters, whose effect on the resulting color schemes is discussed in detail. We provide a free and open source implementation with sensible parameter defaults. Categorical data are very common in statistical graphics, and often these categories form a classification tree. We evaluate applying Tree Colors to tree structured data with a survey on a large group of users from a national statistical institute. Our user study suggests that Tree Colors are useful, not only for improving node-link diagrams, but also for unveiling tree structure in non-hierarchical visualizations.",,Martijn Tennekes;Edwin de Jonge,Statistics Netherlands;Statistics Netherlands,,"Color schemes,statistical graphics,,hierarchical data,,,,,,,",,26,,
conference_external,2014,Visual Analysis of Public Utility Service Problems in a Metropolis,10.1109/TVCG.2014.2346898,http://dx.doi.org/10.1109/TVCG.2014.2346898,1843,1852,Journals,"Issues about city utility services reported by citizens can provide unprecedented insights into the various aspects of such services. Analysis of these issues can improve living quality through evidence-based decision making. However, these issues are complex, because of the involvement of spatial and temporal components, in addition to having multi-dimensional and multivariate natures. Consequently, exploring utility service problems and creating visual representations are difficult. To analyze these issues, we propose a visual analytics process based on the main tasks of utility service management. We also propose an aggregate method that transforms numerous issues into legible events and provide visualizations for events. In addition, we provide a set of tools and interaction techniques to explore such issues. Our approach enables administrators to make more informed decisions.",,Jiawan Zhang;E Yanli;Jing Ma;Yahui Zhao;Binghan Xu;Liting Sun;Jinyan Chen;Xiaoru Yuan,"School of Computer Science and Technology;School of Computer Science and Technology;SCS, Tianjin University;SCS, Tianjin University;SCS, Tianjin University;SCS, Tianjin University;SCS, Tianjin University;School of EECS",,"utility services,evidence-based decision making,,visual analytics,aggregate,,,,,,",,17,,
conference_external,2014,Nmap: A Novel Neighborhood Preservation Space-filling Algorithm,10.1109/TVCG.2014.2346276,http://dx.doi.org/10.1109/TVCG.2014.2346276,2063,2071,Journals,"Space-filling techniques seek to use as much as possible the visual space to represent a dataset, splitting it into regions that represent the data elements. Amongst those techniques, Treemaps have received wide attention due to its simplicity, reduced visual complexity, and compact use of the available space. Several different Treemap algorithms have been proposed, however the core idea is the same, to divide the visual space into rectangles with areas proportional to some data attribute or weight. Although pleasant layouts can be effectively produced by the existing techniques, most of them do not take into account relationships that might exist between different data elements when partitioning the visual space. This violates the distance-similarity metaphor, that is, close rectangles do not necessarily represent similar data elements. In this paper, we propose a novel approach, called Neighborhood Treemap (Nmap), that seeks to solve this limitation by employing a slice and scale strategy where the visual space is successively bisected on the horizontal or vertical directions and the bisections are scaled until one rectangle is defined per data element. Compared to the current techniques with the same similarity preservation goal, our approach presents the best results while being two to three orders of magnitude faster. The usefulness of Nmap is shown by two applications involving the organization of document collections and the construction of cartograms illustrating its effectiveness on different scenarios.",,Felipe S. L. G. Duarte;Fabio Sikansi;Francisco M. Fatore;Samuel G. Fadel;Fernando V. Paulovich,"Institute of Mathematics and Computer Science, São Carlos, Sp, Brazil;Institute of Mathematics and Computer Science, São Carlos, Sp, Brazil;Institute of Mathematics and Computer Science, São Carlos, Sp, Brazil;Institute of Mathematics and Computer Science, São Carlos, Sp, Brazil;Institute of Mathematics and Computer Science, São Carlos, Sp, Brazil",,"Space-filling techniques,treemaps,,distance-similarity preservation,,,,,,,",,17,,
conference_external,2014,DecisionFlow: Visual Analytics for High-Dimensional Temporal Event Sequence Data,10.1109/TVCG.2014.2346682,http://dx.doi.org/10.1109/TVCG.2014.2346682,1783,1792,Journals,"Temporal event sequence data is increasingly commonplace, with applications ranging from electronic medical records to financial transactions to social media activity. Previously developed techniques have focused on low-dimensional datasets (e.g., with less than 20 distinct event types). Real-world datasets are often far more complex. This paper describes DecisionFlow, a visual analysis technique designed to support the analysis of high-dimensional temporal event sequence data (e.g., thousands of event types). DecisionFlow combines a scalable and dynamic temporal event data structure with interactive multi-view visualizations and ad hoc statistical analytics. We provide a detailed review of our methods, and present the results from a 12-person user study. The study results demonstrate that DecisionFlow enables the quick and accurate completion of a range of sequence analysis tasks for datasets containing thousands of event types and millions of individual events.",,David Gotz;Harry Stavropoulos,University of North Carolina at Chapel Hill;IBM T.J. Watson Research Center,,"Information Visualization,Temporal Event Sequences,,Visual Analytics,Flow Diagrams,Medical Informatics,,,,,",,74,,
conference_external,2014,INFUSE: Interactive Feature Selection for Predictive Modeling of High Dimensional Data,10.1109/TVCG.2014.2346482,http://dx.doi.org/10.1109/TVCG.2014.2346482,1614,1623,Journals,"Predictive modeling techniques are increasingly being used by data scientists to understand the probability of predicted outcomes. However, for data that is high-dimensional, a critical step in predictive modeling is determining which features should be included in the models. Feature selection algorithms are often used to remove non-informative features from models. However, there are many different classes of feature selection algorithms. Deciding which one to use is problematic as the algorithmic output is often not amenable to user interpretation. This limits the ability for users to utilize their domain expertise during the modeling process. To improve on this limitation, we developed INFUSE, a novel visual analytics system designed to help analysts understand how predictive features are being ranked across feature selection algorithms, cross-validation folds, and classifiers. We demonstrate how our system can lead to important insights in a case study involving clinical researchers predicting patient outcomes from electronic medical records.",,Josua Krause;Adam Perer;Enrico Bertini,NYU Polytechnic School of Engineering;IBM T.J. Watson Research Center;NYU Polytechnic School of Engineering,,"Predictive modeling,feature selection,,classification,visual analytics,high-dimensional data,,,,,",,63,,
SciVis,2014,Ligand Excluded Surface: A New Type of Molecular Surface,10.1109/TVCG.2014.2346404,http://dx.doi.org/10.1109/TVCG.2014.2346404,2486,2495,Journals,"The most popular molecular surface in molecular visualization is the solvent excluded surface (SES). It provides information about the accessibility of a biomolecule for a solvent molecule that is geometrically approximated by a sphere. During a period of almost four decades, the SES has served for many purposes - including visualization, analysis of molecular interactions and the study of cavities in molecular structures. However, if one is interested in the surface that is accessible to a molecule whose shape differs significantly from a sphere, a different concept is necessary. To address this problem, we generalize the definition of the SES by replacing the probe sphere with the full geometry of the ligand defined by the arrangement of its van der Waals spheres. We call the new surface ligand excluded surface (LES) and present an efficient, grid-based algorithm for its computation. Furthermore, we show that this algorithm can also be used to compute molecular cavities that could host the ligand molecule. We provide a detailed description of its implementation on CPU and GPU. Furthermore, we present a performance and convergence analysis and compare the LES for several molecules, using as ligands either water or small organic molecules.",,Norbert Lindow;Daniel Baum;Hans-Christian Hege,Zuse Institute Berlin;Zuse Institute Berlin;Zuse Institute Berlin,,"Molecular visualization,solvent excluded surface,,ligand excluded surface,cavity analysis,,,,,,",,11,,
SciVis,2014,Visualization of Regular Maps: The Chase Continues,10.1109/TVCG.2014.2352952,http://dx.doi.org/10.1109/TVCG.2014.2352952,2614,2623,Journals,"A regular map is a symmetric tiling of a closed surface, in the sense that all faces, vertices, and edges are topologically indistinguishable. Platonic solids are prime examples, but also for surfaces with higher genus such regular maps exist. We present a new method to visualize regular maps. Space models are produced by matching regular maps with target shapes in the hyperbolic plane. The approach is an extension of our earlier work. Here a wider variety of target shapes is considered, obtained by duplicating spherical and toroidal regular maps, merging triangles, punching holes, and gluing the edges. The method produces about 45 new examples, including the genus 7 Hurwitz surface.",,Jarke J. van Wijk,Eindhoven University of Technology,,"regular maps,tiling,,tessellation,surface topology,mathematical visualization,,,,,",,1,,
conference_external,2014,VarifocalReader — In-Depth Visual Analysis of Large Text Documents,10.1109/TVCG.2014.2346677,http://dx.doi.org/10.1109/TVCG.2014.2346677,1723,1732,Journals,"Interactive visualization provides valuable support for exploring, analyzing, and understanding textual documents. Certain tasks, however, require that insights derived from visual abstractions are verified by a human expert perusing the source text. So far, this problem is typically solved by offering overview-detail techniques, which present different views with different levels of abstractions. This often leads to problems with visual continuity. Focus-context techniques, on the other hand, succeed in accentuating interesting subsections of large text documents but are normally not suited for integrating visual abstractions. With VarifocalReader we present a technique that helps to solve some of these approaches' problems by combining characteristics from both. In particular, our method simplifies working with large and potentially complex text documents by simultaneously offering abstract representations of varying detail, based on the inherent structure of the document, and access to the text itself. In addition, VarifocalReader supports intra-document exploration through advanced navigation concepts and facilitates visual analysis tasks. The approach enables users to apply machine learning techniques and search mechanisms as well as to assess and adapt these techniques. This helps to extract entities, concepts and other artifacts from texts. In combination with the automatic generation of intermediate text levels through topic segmentation for thematic orientation, users can test hypotheses or develop interesting new research questions. To illustrate the advantages of our approach, we provide usage examples from literature studies.",,Steffen Koch;Markus John;Michael Wörner;Andreas Müller;Thomas Ertl,Institute of Visualization and Interactive Systems (VIS);Institute of Visualization and Interactive Systems (VIS);Institute of Visualization and Interactive Systems (VIS);Institute for Natural Language Processing (IMS);Institute of Visualization and Interactive Systems (VIS),,"visual analytics,document analysis,,literary analysis,natural language processing,text mining,machine learning,distant reading,,,",,25,,
SciVis,2014,Decomposition and Simplification of Multivariate Data using Pareto Sets,10.1109/TVCG.2014.2346447,http://dx.doi.org/10.1109/TVCG.2014.2346447,2684,2693,Journals,"Topological and structural analysis of multivariate data is aimed at improving the understanding and usage of such data through identification of intrinsic features and structural relationships among multiple variables. We present two novel methods for simplifying so-called Pareto sets that describe such structural relationships. Such simplification is a precondition for meaningful visualization of structurally rich or noisy data. As a framework for simplification operations, we introduce a decomposition of the data domain into regions of equivalent structural behavior and the reachability graph that describes global connectivity of Pareto extrema. Simplification is then performed as a sequence of edge collapses in this graph; to determine a suitable sequence of such operations, we describe and utilize a comparison measure that reflects the changes to the data that each operation represents. We demonstrate and evaluate our methods on synthetic and real-world examples.",,Lars Huettenberger;Christian Heine;Christoph Garth,TU Kaiserslautern;ETH Zurich;TU Kaiserslautern,,"Multivariate Topology,Pareto Set,,Simplification,Decomposition,Multivariate Topology,Pareto Set,Simplification,Decomposition,,",,8,,
conference_external,2014,Visual Exploration of Sparse Traffic Trajectory Data,10.1109/TVCG.2014.2346746,http://dx.doi.org/10.1109/TVCG.2014.2346746,1813,1822,Journals,"In this paper, we present a visual analysis system to explore sparse traffic trajectory data recorded by transportation cells. Such data contains the movements of nearly all moving vehicles on the major roads of a city. Therefore it is very suitable for macro-traffic analysis. However, the vehicle movements are recorded only when they pass through the cells. The exact tracks between two consecutive cells are unknown. To deal with such uncertainties, we first design a local animation, showing the vehicle movements only in the vicinity of cells. Besides, we ignore the micro-behaviors of individual vehicles, and focus on the macro-traffic patterns. We apply existing trajectory aggregation techniques to the dataset, studying cell status pattern and inter-cell flow pattern. Beyond that, we propose to study the correlation between these two patterns with dynamic graph visualization techniques. It allows us to check how traffic congestion on one cell is correlated with traffic flows on neighbouring links, and with route selection in its neighbourhood. Case studies show the effectiveness of our system.",,Zuchao Wang;Tangzhi Ye;Min Lu;Xiaoru Yuan;Huamin Qu;Jacky Yuan;Qianliang Wu,"Peking University;Peking University;Peking University;Peking University;Hong Kong University of Science and Technology;Nanjing Intelligent Transportation Systems Co., Ltd;Nanjing Intelligent Transportation Systems Co., Ltd",,"Sparse Traffic Trajectory,Traffic Visualization,,Dynamic Graph Visualization,Traffic Congestion,,,,,,",,64,,
conference_external,2014,Axis Calibration for Improving Data Attribute Estimation in Star Coordinates Plots,10.1109/TVCG.2014.2346258,http://dx.doi.org/10.1109/TVCG.2014.2346258,2013,2022,Journals,"Star coordinates is a well-known multivariate visualization method that produces linear dimensionality reduction mappings through a set of radial axes defined by vectors in an observable space. One of its main drawbacks concerns the difficulty to recover attributes of data samples accurately, which typically lie in the [0], [1] interval, given the locations of the low-dimensional embeddings and the vectors. In this paper we show that centering the data can considerably increase attribute estimation accuracy, where data values can be read off approximately by projecting embedded points onto calibrated (i.e., labeled) axes, similarly to classical statistical biplots. In addition, this idea can be coupled with a recently developed orthonormalization process on the axis vectors that prevents unnecessary distortions. We demonstrate that the combination of both approaches not only enhances the estimates, but also provides more faithful representations of the data.",,Manuel Rubio-Sánchez;Alberto Sanchez,URJC;URJC,,"Star Coordinates,RadViz,,Biplots,Axis calibration,Attribute value estimation,Data centering,Orthographic projection,,,",,11,,
conference_external,2014,VASA: Interactive Computational Steering of Large Asynchronous Simulation Pipelines for Societal Infrastructure,10.1109/TVCG.2014.2346911,http://dx.doi.org/10.1109/TVCG.2014.2346911,1853,1862,Journals,"We present VASA, a visual analytics platform consisting of a desktop application, a component model, and a suite of distributed simulation components for modeling the impact of societal threats such as weather, food contamination, and traffic on critical infrastructure such as supply chains, road networks, and power grids. Each component encapsulates a high-fidelity simulation model that together form an asynchronous simulation pipeline: a system of systems of individual simulations with a common data and parameter exchange format. At the heart of VASA is the Workbench, a visual analytics application providing three distinct features: (1) low-fidelity approximations of the distributed simulation components using local simulation proxies to enable analysts to interactively configure a simulation run; (2) computational steering mechanisms to manage the execution of individual simulation components; and (3) spatiotemporal and interactive methods to explore the combined results of a simulation run. We showcase the utility of the platform using examples involving supply chains during a hurricane as well as food contamination in a fast food restaurant chain.",,Sungahn Ko;Jieqiong Zhao;Jing Xia;Shehzad Afzal;Xiaoyu Wang;Greg Abram;Niklas Elmqvist;Len Kne;David Van Riper;Kelly Gaither;Shaun Kennedy;William Tolone;William Ribarsky;David S. Ebert,"Purdue University in West Lafayette, IN, USA;Purdue University in West Lafayette, IN, USA;State Key Lab of CAD&CG, China;Purdue University in West Lafayette, IN, USA;University of North Carolina at Charlotte in Charlotte, NC, USA;University of Texas at Austin in Austin, TX, USA;Purdue University in West Lafayette, IN, USA;University of Minnesota in Minneapolis, MN, USA;University of Minnesota in Minneapolis, MN, USA;University of Texas at Austin in Austin, TX, USA;University of Minnesota in Minneapolis, MN, USA;University of North Carolina at Charlotte in Charlotte, NC, USA;University of North Carolina at Charlotte in Charlotte, NC, USA;Purdue University in West Lafayette, IN, USA",,"Computational steering,visual analytics,,critical infrastructure,homeland security,,,,,,",,8,,
conference_external,2014,Progressive Visual Analytics: User-Driven Visual Exploration of In-Progress Analytics,10.1109/TVCG.2014.2346574,http://dx.doi.org/10.1109/TVCG.2014.2346574,1653,1662,Journals,"As datasets grow and analytic algorithms become more complex, the typical workflow of analysts launching an analytic, waiting for it to complete, inspecting the results, and then re-Iaunching the computation with adjusted parameters is not realistic for many real-world tasks. This paper presents an alternative workflow, progressive visual analytics, which enables an analyst to inspect partial results of an algorithm as they become available and interact with the algorithm to prioritize subspaces of interest. Progressive visual analytics depends on adapting analytical algorithms to produce meaningful partial results and enable analyst intervention without sacrificing computational speed. The paradigm also depends on adapting information visualization techniques to incorporate the constantly refining results without overwhelming analysts and provide interactions to support an analyst directing the analytic. The contributions of this paper include: a description of the progressive visual analytics paradigm; design goals for both the algorithms and visualizations in progressive visual analytics systems; an example progressive visual analytics system (Progressive Insights) for analyzing common patterns in a collection of event sequences; and an evaluation of Progressive Insights and the progressive visual analytics paradigm by clinical researchers analyzing electronic medical records.",,Charles D. Stolper;Adam Perer;David Gotz,"School of Interactive Computing, Georgia Institute of Technology;IBM T.J. Watson Research Center;University of North Carolina at Chapel Hill",,"Progressive visual analytics,information visualization,,interactive machine learning,electronic medical records,,,,,,",,85,,
conference_external,2014,An Algebraic Process for Visualization Design,10.1109/TVCG.2014.2346325,http://dx.doi.org/10.1109/TVCG.2014.2346325,2181,2190,Journals,"We present a model of visualization design based on algebraic considerations of the visualization process. The model helps characterize visual encodings, guide their design, evaluate their effectiveness, and highlight their shortcomings. The model has three components: the underlying mathematical structure of the data or object being visualized, the concrete representation of the data in a computer, and (to the extent possible) a mathematical description of how humans perceive the visualization. Because we believe the value of our model lies in its practical application, we propose three general principles for good visualization design. We work through a collection of examples where our model helps explain the known properties of existing visualizations methods, both good and not-so-good, as well as suggesting some novel methods. We describe how to use the model alongside experimental user studies, since it can help frame experiment outcomes in an actionable manner. Exploring the implications and applications of our model and its design principles should provide many directions for future visualization research.",,Gordon Kindlmann;Carlos Scheidegger,University of Chicago;University of Arizona,,"Visualization Design,Symmetries,,Visualization Theory,,,,,,,",,41,,
SciVis,2014,A Robust Parity Test for Extracting Parallel Vectors in 3D,10.1109/TVCG.2014.2346412,http://dx.doi.org/10.1109/TVCG.2014.2346412,2526,2534,Journals,"Parallel vectors (PV), the loci where two vector fields are parallel, are commonly used to represent curvilinear features in 3D for data visualization. Methods for extracting PV usually operate on a 3D grid and start with detecting seed points on a cell face. We propose, to the best of our knowledge, the first provably correct test that determines the parity of the number of PV points on a cell face. The test only needs to sample along the face boundary and works for any choice of the two vector fields. A discretization of the test is described, validated, and compared with existing tests that are also based on boundary sampling. The test can guide PV-extraction algorithms to ensure closed curves wherever the input fields are continuous, which we exemplify in extracting ridges and valleys of scalar functions.",,Tao Ju;Minxin Cheng;Xu Wang;Ye Duan,Washington University in St. Louis;University of Missouri at Columbia;University of Missouri at Columbia;University of Missouri at Columbia,,"Parallel vectors,feature curve extraction,,ridges and valleys,parity test,,,,,,",,4,,
conference_external,2014,Knowledge Generation Model for Visual Analytics,10.1109/TVCG.2014.2346481,http://dx.doi.org/10.1109/TVCG.2014.2346481,1604,1613,Journals,"Visual analytics enables us to analyze huge information spaces in order to support complex decision making and data exploration. Humans play a central role in generating knowledge from the snippets of evidence emerging from visual data analysis. Although prior research provides frameworks that generalize this process, their scope is often narrowly focused so they do not encompass different perspectives at different levels. This paper proposes a knowledge generation model for visual analytics that ties together these diverse frameworks, yet retains previously developed models (e.g., KDD process) to describe individual segments of the overall visual analytic processes. To test its utility, a real world visual analytics system is compared against the model, demonstrating that the knowledge generation process model provides a useful guideline when developing and evaluating such systems. The model is used to effectively compare different data analysis systems. Furthermore, the model provides a common language and description of visual analytic processes, which can be used for communication between researchers. At the end, our model reflects areas of research that future researchers can embark on.",,Dominik Sacha;Andreas Stoffel;Florian Stoffel;Bum Chul Kwon;Geoffrey Ellis;Daniel A. Keim,"Data Analysis and Visualization Group, University of Konstanz;Data Analysis and Visualization Group, University of Konstanz;Data Analysis and Visualization Group, University of Konstanz;Data Analysis and Visualization Group, University of Konstanz;Data Analysis and Visualization Group, University of Konstanz;Data Analysis and Visualization Group, University of Konstanz",,"Visual Analytics,Knowledge Generation,,Reasoning,Visualization Taxonomies and Models,Interaction,,,,,",,125,,
SciVis,2014,Advection-Based Sparse Data Management for Visualizing Unsteady Flow,10.1109/TVCG.2014.2346418,http://dx.doi.org/10.1109/TVCG.2014.2346418,2555,2564,Journals,"When computing integral curves and integral surfaces for large-scale unsteady flow fields, a major bottleneck is the widening gap between data access demands and the available bandwidth (both I/O and in-memory). In this work, we explore a novel advection-based scheme to manage flow field data for both efficiency and scalability. The key is to first partition flow field into blocklets (e.g. cells or very fine-grained blocks of cells), and then (pre)fetch and manage blocklets on-demand using a parallel key-value store. The benefits are (1) greatly increasing the scale of local-range analysis (e.g. source-destination queries, streak surface generation) that can fit within any given limit of hardware resources; (2) improving memory and I/O bandwidth-efficiencies as well as the scalability of naive task-parallel particle advection. We demonstrate our method using a prototype system that works on workstation and also in supercomputing environments. Results show significantly reduced I/O overhead compared to accessing raw flow data, and also high scalability on a supercomputer for a variety of applications.",,Hanqi Guo;Jiang Zhang;Richen Liu;Lu Liu;Xiaoru Yuan;Jian Huang;Xiangfei Meng;Jingshan Pan,"Key Laboratory of Machine Perception (Ministry of Education), School of EECS;Key Laboratory of Machine Perception (Ministry of Education), School of EECS;Key Laboratory of Machine Perception (Ministry of Education), School of EECS;Key Laboratory of Machine Perception (Ministry of Education), School of EECS;Key Laboratory of Machine Perception (Ministry of Education), School of EECS;Department of Electrical Engineering and Computer Science, University of Tennessee, Knoxville;National Supercomputer Center in Tianjin, Binhai, Tianjin, China;National Supercomputer Center in Jinan, Shandong, China",,"Flow visualization,Data management,,High performance visualization,Key-value store,,,,,,",,12,,
SciVis,2014,ADR - Anatomy-Driven Reformation,10.1109/TVCG.2014.2346405,http://dx.doi.org/10.1109/TVCG.2014.2346405,2496,2505,Journals,"Dedicated visualization methods are among the most important tools of modern computer-aided medical applications. Reformation methods such as Multiplanar Reformation or Curved Planar Reformation have evolved as useful tools that facilitate diagnostic and therapeutic work. In this paper, we present a novel approach that can be seen as a generalization of Multiplanar Reformation to curved surfaces. The main concept is to generate reformatted medical volumes driven by the individual anatomical geometry of a specific patient. This process generates flat views of anatomical structures that facilitate many tasks such as diagnosis, navigation and annotation. Our reformation framework is based on a non-linear as-rigid-as-possible volumetric deformation scheme that uses generic triangular surface meshes as input. To manage inevitable distortions during reformation, we introduce importance maps which allow controlling the error distribution and improving the overall visual quality in areas of elevated interest. Our method seamlessly integrates with well-established concepts such as the slice-based inspection of medical datasets and we believe it can improve the overall efficiency of many medical workflows. To demonstrate this, we additionally present an integrated visualization system and discuss several use cases that substantiate its benefits.",,Jan Kretschmer;Grzegorz Soza;Christian Tietjen;Michael Suehling;Bernhard Preim;Marc Stamminger,"Department of Computer Graphics, FAU Erlangen, and Siemens Healthcare Computed Tomography, Forchheim, Germany;Siemens Healthcare Computed Tomography, Forchheim, Germany;Siemens Healthcare Computed Tomography, Forchheim, Germany;Siemens Healthcare Computed Tomography, Forchheim, Germany;Department of Simulation and Graphics, Otto-von-Guericke University of Magdeburg, Germany;Department of Computer Graphics, FAU Erlangen, Germany",,"Medical Visualization,Volume Reformation,,Viewing Algorithms,,,,,,,",,5,,
conference_external,2014,The Effects of Interactive Latency on Exploratory Visual Analysis,10.1109/TVCG.2014.2346452,http://dx.doi.org/10.1109/TVCG.2014.2346452,2122,2131,Journals,"To support effective exploration, it is often stated that interactive visualizations should provide rapid response times. However, the effects of interactive latency on the process and outcomes of exploratory visual analysis have not been systematically studied. We present an experiment measuring user behavior and knowledge discovery with interactive visualizations under varying latency conditions. We observe that an additional delay of 500ms incurs significant costs, decreasing user activity and data set coverage. Analyzing verbal data from think-aloud protocols, we find that increased latency reduces the rate at which users make observations, draw generalizations and generate hypotheses. Moreover, we note interaction effects in which initial exposure to higher latencies leads to subsequently reduced performance in a low-latency setting. Overall, increased latency causes users to shift exploration strategy, in turn affecting performance. We discuss how these results can inform the design of interactive analysis tools.",,Zhicheng Liu;Jeffrey Heer,Adobe Research;University of Washington,,"Interaction,latency,,exploratory analysis,interactive visualization,scalability,user performance,verbal analysis,,,",,101,,
conference_external,2014,GLO-STIX: Graph-Level Operations for Specifying Techniques and Interactive eXploration,10.1109/TVCG.2014.2346444,http://dx.doi.org/10.1109/TVCG.2014.2346444,2320,2328,Journals,"The field of graph visualization has produced a wealth of visualization techniques for accomplishing a variety of analysis tasks. Therefore analysts often rely on a suite of different techniques, and visual graph analysis application builders strive to provide this breadth of techniques. To provide a holistic model for specifying network visualization techniques (as opposed to considering each technique in isolation) we present the Graph-Level Operations (GLO) model. We describe a method for identifying GLOs and apply it to identify five classes of GLOs, which can be flexibly combined to re-create six canonical graph visualization techniques. We discuss advantages of the GLO model, including potentially discovering new, effective network visualization techniques and easing the engineering challenges of building multi-technique graph visualization applications. Finally, we implement the GLOs that we identified into the GLO-STIX prototype system that enables an analyst to interactively explore a graph by applying GLOs.",,Charles D. Stolper;Minsuk Kahng;Zhiyuan Lin;Florian Foerster;Aakash Goel;John Stasko;Duen Horng Chau,"College of Computing, Georgia Institute of Technology;College of Computing, Georgia Institute of Technology;College of Computing, Georgia Institute of Technology;College of Computing, Georgia Institute of Technology;College of Computing, Georgia Institute of Technology;College of Computing, Georgia Institute of Technology;College of Computing, Georgia Institute of Technology",,"Graph-level operations,graph visualization,,visualization technique specification,graph analysis,information visualization,,,,,",,8,,
conference_external,2014,The Influence of Contour on Similarity Perception of Star Glyphs,10.1109/TVCG.2014.2346426,http://dx.doi.org/10.1109/TVCG.2014.2346426,2251,2260,Journals,"We conducted three experiments to investigate the effects of contours on the detection of data similarity with star glyph variations. A star glyph is a small, compact, data graphic that represents a multi-dimensional data point. Star glyphs are often used in small-multiple settings, to represent data points in tables, on maps, or as overlays on other types of data graphics. In these settings, an important task is the visual comparison of the data points encoded in the star glyph, for example to find other similar data points or outliers. We hypothesized that for data comparisons, the overall shape of a star glyph-enhanced through contour lines-would aid the viewer in making accurate similarity judgments. To test this hypothesis, we conducted three experiments. In our first experiment, we explored how the use of contours influenced how visualization experts and trained novices chose glyphs with similar data values. Our results showed that glyphs without contours make the detection of data similarity easier. Given these results, we conducted a second study to understand intuitive notions of similarity. Star glyphs without contours most intuitively supported the detection of data similarity. In a third experiment, we tested the effect of star glyph reference structures (i.e., tickmarks and gridlines) on the detection of similarity. Surprisingly, our results show that adding reference structures does improve the correctness of similarity judgments for star glyphs with contours, but not for the standard star glyph. As a result of these experiments, we conclude that the simple star glyph without contours performs best under several criteria, reinforcing its practice and popularity in the literature. Contours seem to enhance the detection of other types of similarity, e. g., shape similarity and are distracting when data similarity has to be judged. Based on these findings we provide design considerations regarding the use of contours and reference structures on star glyphs.",,Johannes Fuchs;Petra Isenberg;Anastasia Bezerianos;Fabian Fischer;Enrico Bertini,"University of Konstanz;Inria;CNRS & Inria, Université Paris-Sud;University of Konstanz;NYU Poly",,"Glyphs,star glyphs,,contours,perception,quantitative evaluation,similarity detection,visual comparison,,,",,24,,
SciVis,2014,Fixed-Rate Compressed Floating-Point Arrays,10.1109/TVCG.2014.2346458,http://dx.doi.org/10.1109/TVCG.2014.2346458,2674,2683,Journals,"Current compression schemes for floating-point data commonly take fixed-precision values and compress them to a variable-length bit stream, complicating memory management and random access. We present a fixed-rate, near-lossless compression scheme that maps small blocks of 4d values in d dimensions to a fixed, user-specified number of bits per block, thereby allowing read and write random access to compressed floating-point data at block granularity. Our approach is inspired by fixed-rate texture compression methods widely adopted in graphics hardware, but has been tailored to the high dynamic range and precision demands of scientific applications. Our compressor is based on a new, lifted, orthogonal block transform and embedded coding, allowing each per-block bit stream to be truncated at any point if desired, thus facilitating bit rate selection using a single compression scheme. To avoid compression or decompression upon every data access, we employ a software write-back cache of uncompressed blocks. Our compressor has been designed with computational simplicity and speed in mind to allow for the possibility of a hardware implementation, and uses only a small number of fixed-point arithmetic operations per compressed value. We demonstrate the viability and benefits of lossy compression in several applications, including visualization, quantitative data analysis, and numerical simulation.",,Peter Lindstrom,"Center for Applied Scientific Computing, Lawrence Livermore National Laboratory",,"Data compression,floating-point arrays,,orthogonal block transform,embedded coding,,,,,,",,136,,
SciVis,2014,Interactive Progressive Visualization with Space-Time Error Control,10.1109/TVCG.2014.2346319,http://dx.doi.org/10.1109/TVCG.2014.2346319,2397,2406,Journals,"We present a novel scheme for progressive rendering in interactive visualization. Static settings with respect to a certain image quality or frame rate are inherently incapable of delivering both high frame rates for rapid changes and high image quality for detailed investigation. Our novel technique flexibly adapts by steering the visualization process in three major degrees of freedom: when to terminate the refinement of a frame in the background and start a new one, when to display a frame currently computed, and how much resources to consume. We base these decisions on the correlation of the errors due to insufficient sampling and response delay, which we estimate separately using fast yet expressive heuristics. To automate the configuration of the steering behavior, we employ offline video quality analysis. We provide an efficient implementation of our scheme for the application of volume raycasting, featuring integrated GPU-accelerated image reconstruction and error estimation. Our implementation performs an integral handling of the changes due to camera transforms, transfer function adaptations, as well as the progression of the data to in time. Finally, the overall technique is evaluated with an expert study.",,Steffen Frey;Filip Sadlo;Kwan-Liu Ma;Thomas Ertl,University of Stuttgart;University of Stuttgart;UC Davis;University of Stuttgart,,"Progressive visualization,error-based frame control,,interactive volume raycasting,,,,,,,",,16,,
conference_external,2014,Order of Magnitude Markers: An Empirical Study on Large Magnitude Number Detection,10.1109/TVCG.2014.2346428,http://dx.doi.org/10.1109/TVCG.2014.2346428,2261,2270,Journals,"In this paper we introduce Order of Magnitude Markers (OOMMs) as a new technique for number representation. The motivation for this work is that many data sets require the depiction and comparison of numbers that have varying orders of magnitude. Existing techniques for representation use bar charts, plots and colour on linear or logarithmic scales. These all suffer from related problems. There is a limit to the dynamic range available for plotting numbers, and so the required dynamic range of the plot can exceed that of the depiction method. When that occurs, resolving, comparing and relating values across the display becomes problematical or even impossible for the user. With this in mind, we present an empirical study in which we compare logarithmic, linear, scale-stack bars and our new markers for 11 different stimuli grouped into 4 different tasks across all 8 marker types.",,Rita Borgo;Joel Dearden;Mark W. Jones,Swansea University;Swansea University;Swansea University,,"Orders of magnitude,bar charts,,logarithmic scale,,,,,,,",,10,,
SciVis,2014,Trajectory-Based Flow Feature Tracking in Joint Particle/Volume Datasets,10.1109/TVCG.2014.2346423,http://dx.doi.org/10.1109/TVCG.2014.2346423,2565,2574,Journals,"Studying the dynamic evolution of time-varying volumetric data is essential in countless scientific endeavors. The ability to isolate and track features of interest allows domain scientists to better manage large complex datasets both in terms of visual understanding and computational efficiency. This work presents a new trajectory-based feature tracking technique for use in joint particle/volume datasets. While traditional feature tracking approaches generally require a high temporal resolution, this method utilizes the indexed trajectories of corresponding Lagrangian particle data to efficiently track features over large jumps in time. Such a technique is especially useful for situations where the volume dataset is either temporally sparse or too large to efficiently track a feature through all intermediate timesteps. In addition, this paper presents a few other applications of this approach, such as the ability to efficiently track the internal properties of volumetric features using variables from the particle data. We demonstrate the effectiveness of this technique using real world combustion and atmospheric datasets and compare it to existing tracking methods to justify its advantages and accuracy.",,Franz Sauer;Hongfeng Yu;Kwan-Liu Ma,"University of California, Davis;University of Nebraska, Lincoln;University of California, Davis",,"Feature extraction and tracking,particle data,,volume data,particle trajectories,flow visualization,,,,,",,15,,
conference_external,2014,OnSet: A Visualization Technique for Large-scale Binary Set Data,10.1109/TVCG.2014.2346249,http://dx.doi.org/10.1109/TVCG.2014.2346249,1993,2002,Journals,"Visualizing sets to reveal relationships between constituent elements is a complex representational problem. Recent research presents several automated placement and grouping techniques to highlight connections between set elements. However, these techniques do not scale well for sets with cardinality greater than one hundred elements. We present OnSet, an interactive, scalable visualization technique for representing large-scale binary set data. The visualization technique defines a single, combined domain of elements for all sets, and models each set by the elements that it both contains and does not contain. OnSet employs direct manipulation interaction and visual highlighting to support easy identification of commonalities and differences as well as membership patterns across different sets of elements. We present case studies to illustrate how the technique can be successfully applied across different domains such as bio-chemical metabolomics and task and event scheduling.",,Ramik Sadana;Timothy Major;Alistair Dove;John Stasko,Georgia Tech.;Georgia Tech.;Georgia Aquarium;Georgia Tech.,,"Set visualization,information visualization,,direct manipulation,Euler diagrams,interaction,logical operations,,,,",,31,,
conference_external,2014,How Hierarchical Topics Evolve in Large Text Corpora,10.1109/TVCG.2014.2346433,http://dx.doi.org/10.1109/TVCG.2014.2346433,2281,2290,Journals,"Using a sequence of topic trees to organize documents is a popular way to represent hierarchical and evolving topics in text corpora. However, following evolving topics in the context of topic trees remains difficult for users. To address this issue, we present an interactive visual text analysis approach to allow users to progressively explore and analyze the complex evolutionary patterns of hierarchical topics. The key idea behind our approach is to exploit a tree cut to approximate each tree and allow users to interactively modify the tree cuts based on their interests. In particular, we propose an incremental evolutionary tree cut algorithm with the goal of balancing 1) the fitness of each tree cut and the smoothness between adjacent tree cuts; 2) the historical and new information related to user interests. A time-based visualization is designed to illustrate the evolving topics over time. To preserve the mental map, we develop a stable layout algorithm. As a result, our approach can quickly guide users to progressively gain profound insights into evolving hierarchical topics. We evaluate the effectiveness of the proposed method on Amazon's Mechanical Turk and real-world news data. The results show that users are able to successfully analyze evolving topics in text data.",,Weiwei Cui;Shixia Liu;Zhuofeng Wu;Hao Wei,Microsoft Research;Microsoft Research;Nankai University;Zhejiang University,,"Hierarchical topic visualization,evolutionary tree clustering,,data transformation,,,,,,,",,66,,
conference_external,2014,LiveGantt: Interactively Visualizing a Large Manufacturing Schedule,10.1109/TVCG.2014.2346454,http://dx.doi.org/10.1109/TVCG.2014.2346454,2329,2338,Journals,"In this paper, we introduce LiveGantt as a novel interactive schedule visualization tool that helps users explore highly-concurrent large schedules from various perspectives. Although a Gantt chart is the most common approach to illustrate schedules, currently available Gantt chart visualization tools suffer from limited scalability and lack of interactions. LiveGantt is built with newly designed algorithms and interactions to improve conventional charts with better scalability, explorability, and reschedulability. It employs resource reordering and task aggregation to display the schedules in a scalable way. LiveGantt provides four coordinated views and filtering techniques to help users explore and interact with the schedules in more flexible ways. In addition, LiveGantt is equipped with an efficient rescheduler to allow users to instantaneously modify their schedules based on their scheduling experience in the fields. To assess the usefulness of the application of LiveGantt, we conducted a case study on manufacturing schedule data with four industrial engineering researchers. Participants not only grasped an overview of a schedule but also explored the schedule from multiple perspectives to make enhancements.",,Jaemin Jo;Jaeseok Huh;Jonghun Park;Bohyoung Kim;Jinwook Seo,Seoul National University;Seoul National University;Seoul National University;Seoul National University Bundang Hospital;Seoul National University,,"Schedule visualization,event sequence visualization,,simplification,exploratory interactions,simulation,,,,,",,20,,
conference_external,2014,The Spinel Explorer—Interactive Visual Analysis of Spinel Group Minerals,10.1109/TVCG.2014.2346754,http://dx.doi.org/10.1109/TVCG.2014.2346754,1913,1922,Journals,"Geologists usually deal with rocks that are up to several thousand million years old. They try to reconstruct the tectonic settings where these rocks were formed and the history of events that affected them through the geological time. The spinel group minerals provide useful information regarding the geological environment in which the host rocks were formed. They constitute excellent indicators of geological environments (tectonic settings) and are of invaluable help in the search for mineral deposits of economic interest. The current workflow requires the scientists to work with different applications to analyze spine data. They do use specific diagrams, but these are usually not interactive. The current workflow hinders domain experts to fully exploit the potentials of tediously and expensively collected data. In this paper, we introduce the Spinel Explorer-an interactive visual analysis application for spinel group minerals. The design of the Spinel Explorer and of the newly introduced interactions is a result of a careful study of geologists' tasks. The Spinel Explorer includes most of the diagrams commonly used for analyzing spinel group minerals, including 2D binary plots, ternary plots, and 3D Spinel prism plots. Besides specific plots, conventional information visualization views are also integrated in the Spinel Explorer. All views are interactive and linked. The Spinel Explorer supports conventional statistics commonly used in spinel minerals exploration. The statistics views and different data derivation techniques are fully integrated in the system. Besides the Spinel Explorer as newly proposed interactive exploration system, we also describe the identified analysis tasks, and propose a new workflow. We evaluate the Spinel Explorer using real-life data from two locations in Argentina: the Frontal Cordillera in Central Andes and Patagonia. We describe the new findings of the geologists which would have been much more difficult to achieve using the current workflow only. Very positive feedback from geologists confirms the usefulness of the Spinel Explorer.",,María Luján Ganuza;Gabriela Ferracutti;María Florencia Gargiulo;Silvia Mabel Castro;Ernesto Bjerg;Eduard Gröller;Krešimir Matković,"VyGLab Research Laboratory at the Universidad Nacional del Sur, Bahía Blanca, Argentina;Departamento de GeologíaINGEOSUR CCT CONICET, Universidad Nacional del Sur, Bahía Blanca, Argentina;Departamento de Geología, Universidad Nacional del Sur, Bahía Blanca, Argentina;VyGLab Research Laboratory at the Universidad Nacional del Sur, Bahía Blanca, Argentina;Departamento de GeologíaINGEOSUR CCT CONICET, Universidad Nacional del Sur, Bahía Blanca, Argentina;Vienna University of Technology, Austria;VRVis Research Center, Vienna, Austria",,"Interactive visual analysis,visualization in earth,,space,and environmental sciences,coordinated and multiple views,design studies,,,,",,6,,
SciVis,2014,Trend-Centric Motion Visualization: Designing and Applying a New Strategy for Analyzing Scientific Motion Collections,10.1109/TVCG.2014.2346451,http://dx.doi.org/10.1109/TVCG.2014.2346451,2644,2653,Journals,"In biomechanics studies, researchers collect, via experiments or simulations, datasets with hundreds or thousands of trials, each describing the same type of motion (e.g., a neck flexion-extension exercise) but under different conditions (e.g., different patients, different disease states, pre- and post-treatment). Analyzing similarities and differences across all of the trials in these collections is a major challenge. Visualizing a single trial at a time does not work, and the typical alternative of juxtaposing multiple trials in a single visual display leads to complex, difficult-to-interpret visualizations. We address this problem via a new strategy that organizes the analysis around motion trends rather than trials. This new strategy matches the cognitive approach that scientists would like to take when analyzing motion collections. We introduce several technical innovations making trend-centric motion visualization possible. First, an algorithm detects a motion collection's trends via time-dependent clustering. Second, a 2D graphical technique visualizes how trials leave and join trends. Third, a 3D graphical technique, using a median 3D motion plus a visual variance indicator, visualizes the biomechanics of the set of trials within each trend. These innovations are combined to create an interactive exploratory visualization tool, which we designed through an iterative process in collaboration with both domain scientists and a traditionally-trained graphic designer. We report on insights generated during this design process and demonstrate the tool's effectiveness via a validation study with synthetic data and feedback from expert musculoskeletal biomechanics researchers who used the tool to analyze the effects of disc degeneration on human spinal kinematics.",,David Schroeder;Fedor Korsakov;Carissa Mai-Ping Knipe;Lauren Thorson;Arin M. Ellingson;David Nuckley;John Carlis;Daniel F Keefe,University of Minnesota;University of Minnesota;University of Minnesota;Minneapolis College of Art and Design;University of Minnesota;Zimmer Spine;University of Minnesota;University of Minnesota,,"Design studies,focus + context techniques,,integrating spatial and non-spatial data visualization,visual design,biomedical and medical visualization,,,,,",,8,,
SciVis,2014,Low-Pass Filtered Volumetric Shadows,10.1109/TVCG.2014.2346333,http://dx.doi.org/10.1109/TVCG.2014.2346333,2437,2446,Journals,"We present a novel and efficient method to compute volumetric soft shadows for interactive direct volume visualization to improve the perception of spatial depth. By direct control of the softness of volumetric shadows, disturbing visual patterns due to hard shadows can be avoided and users can adapt the illumination to their personal and application-specific requirements. We compute the shadowing of a point in the data set by employing spatial filtering of the optical depth over a finite area patch pointing toward each light source. Conceptually, the area patch spans a volumetric region that is sampled with shadow rays; afterward, the resulting optical depth values are convolved with a low-pass filter on the patch. In the numerical computation, however, to avoid expensive shadow ray marching, we show how to align and set up summed area tables for both directional and point light sources. Once computed, the summed area tables enable efficient evaluation of soft shadows for each point in constant time without shadow ray marching and the softness of the shadows can be controlled interactively. We integrated our method in a GPU-based volume renderer with ray casting from the camera, which offers interactive control of the transfer function, light source positions, and viewpoint, for both static and time-dependent data sets. Our results demonstrate the benefit of soft shadows for visualization to achieve user-controlled illumination with many-point lighting setups for improved perception combined with high rendering speed.",,Marco Ament;Filip Sadlo;Carsten Dachsbacher;Daniel Weiskopf,"Karlsruhe Institute of Technology, Germany;University of Stuttgart, Germany;Karlsruhe Institute of Technology, Germany;University of Stuttgart, Germany",,"Direct volume rendering,volume illumination,,soft shadows,filtered shadows,summed area table,,,,,",,15,,
conference_external,2014,Genotet: An Interactive Web-based Visual Exploration Framework to Support Validation of Gene Regulatory Networks,10.1109/TVCG.2014.2346753,http://dx.doi.org/10.1109/TVCG.2014.2346753,1903,1912,Journals,"Elucidation of transcriptional regulatory networks (TRNs) is a fundamental goal in biology, and one of the most important components of TRNs are transcription factors (TFs), proteins that specifically bind to gene promoter and enhancer regions to alter target gene expression patterns. Advances in genomic technologies as well as advances in computational biology have led to multiple large regulatory network models (directed networks) each with a large corpus of supporting data and gene-annotation. There are multiple possible biological motivations for exploring large regulatory network models, including: validating TF-target gene relationships, figuring out co-regulation patterns, and exploring the coordination of cell processes in response to changes in cell state or environment. Here we focus on queries aimed at validating regulatory network models, and on coordinating visualization of primary data and directed weighted gene regulatory networks. The large size of both the network models and the primary data can make such coordinated queries cumbersome with existing tools and, in particular, inhibits the sharing of results between collaborators. In this work, we develop and demonstrate a web-based framework for coordinating visualization and exploration of expression data (RNA-seq, microarray), network models and gene-binding data (ChIP-seq). Using specialized data structures and multiple coordinated views, we design an efficient querying model to support interactive analysis of the data. Finally, we show the effectiveness of our framework through case studies for the mouse immune system (a dataset focused on a subset of key cellular functions) and a model bacteria (a small genome with high data-completeness).",,Bowen Yu;Harish Doraiswamy;Xi Chen;Emily Miraldi;Mario Luis Arrieta-Ortiz;Christoph Hafemeister;Aviv Madar;Richard Bonneau;Cláudio T. Silva,NYU Polytechnic School of Engineering;NYU Polytechnic School of Engineering;NYU Center for Genomics and Systems Biology;NYU Center for Genomics and Systems Biology;NYU Center for Genomics and Systems Biology;NYU Center for Genomics and Systems Biology;Cornell University;NYU Center for Genomics and Systems Biology;NYU Polytechnic School of Engineering,,"Web-based visualization,gene regulatory network,,,,,,,,,",,9,,
conference_external,2014,OpinionFlow: Visual Analysis of Opinion Diffusion on Social Media,10.1109/TVCG.2014.2346920,http://dx.doi.org/10.1109/TVCG.2014.2346920,1763,1772,Journals,"It is important for many different applications such as government and business intelligence to analyze and explore the diffusion of public opinions on social media. However, the rapid propagation and great diversity of public opinions on social media pose great challenges to effective analysis of opinion diffusion. In this paper, we introduce a visual analysis system called OpinionFlow to empower analysts to detect opinion propagation patterns and glean insights. Inspired by the information diffusion model and the theory of selective exposure, we develop an opinion diffusion model to approximate opinion propagation among Twitter users. Accordingly, we design an opinion flow visualization that combines a Sankey graph with a tailored density map in one view to visually convey diffusion of opinions among many users. A stacked tree is used to allow analysts to select topics of interest at different levels. The stacked tree is synchronized with the opinion flow visualization to help users examine and compare diffusion patterns across topics. Experiments and case studies on Twitter data demonstrate the effectiveness and usability of OpinionFlow.",,Yingcai Wu;Shixia Liu;Kai Yan;Mengchen Liu;Fangzhao Wu,Microsoft Research;Microsoft Research;Harbin Institute of Technology;Tsinghua University;Tsinghua University,,"Opinion visualization,opinion diffusion,,opinion flow,influence estimation,kernel density estimation,level-of-detail,,,,",,86,,
conference_external,2014,Effects of Presentation Mode and Pace Control on Performance in Image Classification,10.1109/TVCG.2014.2346437,http://dx.doi.org/10.1109/TVCG.2014.2346437,2301,2309,Journals,"A common task in visualization is to quickly find interesting items in large sets. When appropriate metadata is missing, automatic queries are impossible and users have to inspect all elements visually. We compared two fundamentally different, but obvious display modes for this task and investigated the difference with respect to effectiveness, efficiency, and satisfaction. The static mode is based on the page metaphor and presents successive pages with a static grid of items. The moving mode is based on the conveyor belt metaphor and lets a grid of items slide though the screen in a continuous flow. In our evaluation, we applied both modes to the common task of browsing images. We performed two experiments where 18 participants had to search for certain target images in a large image collection. The number of shown images per second (pace) was predefined in the first experiment, and under user control in the second one. We conclude that at a fixed pace, the mode has no significant impact on the recall. The perceived pace is generally slower for moving mode, which causes users to systematically choose for a faster real pace than in static mode at the cost of recall, keeping the average number of target images found per second equal for both modes.",,Paul van der Corput;Jarke J. van Wijk,Eindhoven University of Technology;Eindhoven University of Technology,,"RSVP,image classification,,image browsing,multimedia visualization,,,,,,",,3,,
conference_external,2014,Origin-Destination Flow Data Smoothing and Mapping,10.1109/TVCG.2014.2346271,http://dx.doi.org/10.1109/TVCG.2014.2346271,2043,2052,Journals,"This paper presents a new approach to flow mapping that extracts inherent patterns from massive geographic mobility data and constructs effective visual representations of the data for the understanding of complex flow trends. This approach involves a new method for origin-destination flow density estimation and a new method for flow map generalization, which together can remove spurious data variance, normalize flows with control population, and detect high-level patterns that are not discernable with existing approaches. The approach achieves three main objectives in addressing the challenges for analyzing and mapping massive flow data. First, it removes the effect of size differences among spatial units via kernel-based density estimation, which produces a measurement of flow volume between each pair of origin and destination. Second, it extracts major flow patterns in massive flow data through a new flow sampling method, which filters out duplicate information in the smoothed flows. Third, it enables effective flow mapping and allows intuitive perception of flow patterns among origins and destinations without bundling or altering flow paths. The approach can work with both point-based flow data (such as taxi trips with GPS locations) and area-based flow data (such as county-to-county migration). Moreover, the approach can be used to detect and compare flow patterns at different scales or in relatively sparse flow datasets, such as migration for each age group. We evaluate and demonstrate the new approach with case studies of U.S. migration data and experiments with synthetic data.",,Diansheng Guo;Xi Zhu,"Department of Geography, University of South Carolina;Department of Geography, University of South Carolina",,"flow mapping,kernel smoothing,,generalization,multi-resolution mapping,graph drawing,spatial data mining,,,,",,64,,
conference_external,2014,Constructing Visual Representations: Investigating the Use of Tangible Tokens,10.1109/TVCG.2014.2346292,http://dx.doi.org/10.1109/TVCG.2014.2346292,2102,2111,Journals,"The accessibility of infovis authoring tools to a wide audience has been identified as a major research challenge. A key task in the authoring process is the development of visual mappings. While the infovis community has long been deeply interested in finding effective visual mappings, comparatively little attention has been placed on how people construct visual mappings. In this paper, we present the results of a study designed to shed light on how people transform data into visual representations. We asked people to create, update and explain their own information visualizations using only tangible building blocks. We learned that all participants, most of whom had little experience in visualization authoring, were readily able to create and talk about their own visualizations. Based on our observations, we discuss participants' actions during the development of their visual representations and during their analytic activities. We conclude by suggesting implications for tool design to enable broader support for infovis authoring.",,Samuel Huron;Yvonne Jansen;Sheelagh Carpendale,Inria and IRI;Inria and University of Copenhagen;University of Calgary,,"Constructive visualization,Physical visualization,Visual analytics,Dynamic visualization,Empirical study,Token,Visualization authoring,Information visualization,Visual mapping,Novices,Visualization construction",,29,,
conference_external,2014,Learning Perceptual Kernels for Visualization Design,10.1109/TVCG.2014.2346978,http://dx.doi.org/10.1109/TVCG.2014.2346978,1933,1942,Journals,"Visualization design can benefit from careful consideration of perception, as different assignments of visual encoding variables such as color, shape and size affect how viewers interpret data. In this work, we introduce perceptual kernels: distance matrices derived from aggregate perceptual judgments. Perceptual kernels represent perceptual differences between and within visual variables in a reusable form that is directly applicable to visualization evaluation and automated design. We report results from crowd-sourced experiments to estimate kernels for color, shape, size and combinations thereof. We analyze kernels estimated using five different judgment types-including Likert ratings among pairs, ordinal triplet comparisons, and manual spatial arrangement-and compare them to existing perceptual models. We derive recommendations for collecting perceptual similarities, and then demonstrate how the resulting kernels can be applied to automate visualization design decisions.",,Çağatay Demiralp;Michael S. Bernstein;Jeffrey Heer,Stanford University;Stanford University;University of Washington,,"Visualization,design,,encoding,perception,model,crowdsourcing,automated visualization,visual embedding,,",,43,,
conference_external,2014,DimpVis: Exploring Time-varying Information Visualizations by Direct Manipulation,10.1109/TVCG.2014.2346250,http://dx.doi.org/10.1109/TVCG.2014.2346250,2003,2012,Journals,"We introduce a new direct manipulation technique, DimpVis, for interacting with visual items in information visualizations to enable exploration of the time dimension. DimpVis is guided by visual hint paths which indicate how a selected data item changes through the time dimension in a visualization. Temporal navigation is controlled by manipulating any data item along its hint path. All other items are updated to reflect the new time. We demonstrate how the DimpVis technique can be designed to directly manipulate position, colour, and size in familiar visualizations such as bar charts and scatter plots, as a means for temporal navigation. We present results from a comparative evaluation, showing that the DimpVis technique was subjectively preferred and quantitatively competitive with the traditional time slider, and significantly faster than small multiples for a variety of tasks.",,Brittany Kondo;Christopher Collins,University of Ontario Institute of Technology;University of Ontario Institute of Technology,,"Time navigation,direct manipulation,,information visualization,,,,,,,",,25,,
conference_external,2014,Finding Waldo: Learning about Users from their Interactions,10.1109/TVCG.2014.2346575,http://dx.doi.org/10.1109/TVCG.2014.2346575,1663,1672,Journals,"Visual analytics is inherently a collaboration between human and computer. However, in current visual analytics systems, the computer has limited means of knowing about its users and their analysis processes. While existing research has shown that a user's interactions with a system reflect a large amount of the user's reasoning process, there has been limited advancement in developing automated, real-time techniques that mine interactions to learn about the user. In this paper, we demonstrate that we can accurately predict a user's task performance and infer some user personality traits by using machine learning techniques to analyze interaction data. Specifically, we conduct an experiment in which participants perform a visual search task, and apply well-known machine learning algorithms to three encodings of the users' interaction data. We achieve, depending on algorithm and encoding, between 62% and 83% accuracy at predicting whether each user will be fast or slow at completing the task. Beyond predicting performance, we demonstrate that using the same techniques, we can infer aspects of the user's personality factors, including locus of control, extraversion, and neuroticism. Further analyses show that strong results can be attained with limited observation time: in one case 95% of the final accuracy is gained after a quarter of the average task completion time. Overall, our findings show that interactions can provide information to the computer about its human collaborator, and establish a foundation for realizing mixed-initiative visual analytics systems.",,Eli T Brown;Alvitta Ottley;Helen Zhao;Quan Lin;Richard Souvenir;Alex Endert;Remco Chang,Tufts U;Tufts U;Tufts U;Tufts U;U.N.C. Charlotte;Pacific Northwest National Lab;Tufts U,,"User Interactions,Analytic Provenance,,Visualization,Applied Machine Learning,,,,,,",,43,,
conference_external,2014,"Node, Node-Link, and Node-Link-Group Diagrams: An Evaluation",10.1109/TVCG.2014.2346422,http://dx.doi.org/10.1109/TVCG.2014.2346422,2231,2240,Journals,"Effectively showing the relationships between objects in a dataset is one of the main tasks in information visualization. Typically there is a well-defined notion of distance between pairs of objects, and traditional approaches such as principal component analysis or multi-dimensional scaling are used to place the objects as points in 2D space, so that similar objects are close to each other. In another typical setting, the dataset is visualized as a network graph, where related nodes are connected by links. More recently, datasets are also visualized as maps, where in addition to nodes and links, there is an explicit representation of groups and clusters. We consider these three Techniques, characterized by a progressive increase of the amount of encoded information: node diagrams, node-link diagrams and node-link-group diagrams. We assess these three types of diagrams with a controlled experiment that covers nine different tasks falling broadly in three categories: node-based tasks, network-based tasks and group-based tasks. Our findings indicate that adding links, or links and group representations, does not negatively impact performance (time and accuracy) of node-based tasks. Similarly, adding group representations does not negatively impact the performance of network-based tasks. Node-link-group diagrams outperform the others on group-based tasks. These conclusions contradict results in other studies, in similar but subtly different settings. Taken together, however, such results can have significant implications for the design of standard and domain snecific visualizations tools.",,Bahador Saket;Paolo Simonetto;Stephen Kobourov;Katy Börner,University of Arizona;University of Arizona;University of Arizona;Indiana University,,"graphs,networks,,maps,scatter plots,,,,,,",,22,,
SciVis,2014,ViSlang: A System for Interpreted Domain-Specific Languages for Scientific Visualization,10.1109/TVCG.2014.2346318,http://dx.doi.org/10.1109/TVCG.2014.2346318,2388,2396,Journals,"Researchers from many domains use scientific visualization in their daily practice. Existing implementations of algorithms usually come with a graphical user interface (high-level interface), or as software library or source code (low-level interface). In this paper we present a system that integrates domain-specific languages (DSLs) and facilitates the creation of new DSLs. DSLs provide an effective interface for domain scientists avoiding the difficulties involved with low-level interfaces and at the same time offering more flexibility than high-level interfaces. We describe the design and implementation of ViSlang, an interpreted language specifically tailored for scientific visualization. A major contribution of our design is the extensibility of the ViSlang language. Novel DSLs that are tailored to the problems of the domain can be created and integrated into ViSlang. We show that our approach can be added to existing user interfaces to increase the flexibility for expert users on demand, but at the same time does not interfere with the user experience of novice users. To demonstrate the flexibility of our approach we present new DSLs for volume processing, querying and visualization. We report the implementation effort for new DSLs and compare our approach with Matlab and Python implementations in terms of run-time performance.",,Peter Rautek;Stefan Bruckner;M. Eduard Gröller;Markus Hadwiger,KAUST;University of Bergen;Vienna University of Technology;KAUST,,"Domain-specific languages,Volume visualization,,Volume visualization framework,,,,,,,",,14,,
conference_external,2014,Stenomaps: Shorthand for shapes,10.1109/TVCG.2014.2346274,http://dx.doi.org/10.1109/TVCG.2014.2346274,2053,2062,Journals,"We address some of the challenges in representing spatial data with a novel form of geometric abstraction-the stenomap. The stenomap comprises a series of smoothly curving linear glyphs that each represent both the boundary and the area of a polygon. We present an efficient algorithm to automatically generate these open, C1-continuous splines from a set of input polygons. Feature points of the input polygons are detected using the medial axis to maintain important shape properties. We use dynamic programming to compute a planar non-intersecting spline representing each polygon's base shape. The results are stylised glyphs whose appearance may be parameterised and that offer new possibilities in the 'cartographic design space'. We compare our glyphs with existing forms of geometric schematisation and discuss their relative merits and shortcomings. We describe several use cases including the depiction of uncertain model data in the form of hurricane track forecasting; minimal ink thematic mapping; and the depiction of continuous statistical data.",,Arthur van Goethem;Andreas Reimer;Bettina Speckmann;Jo Wood,TU Eindhoven;Universität Heidelberg;TU Eindhoven;City University London,,"Schematisation,Maps,,Algorithm,Design,,,,,,",,0,,
conference_external,2014,Attribute Signatures: Dynamic Visual Summaries for Analyzing Multivariate Geographical Data,10.1109/TVCG.2014.2346265,http://dx.doi.org/10.1109/TVCG.2014.2346265,2033,2042,Journals,"The visual analysis of geographically referenced datasets with a large number of attributes is challenging due to the fact that the characteristics of the attributes are highly dependent upon the locations at which they are focussed, and the scale and time at which they are measured. Specialized interactive visual methods are required to help analysts in understanding the characteristics of the attributes when these multiple aspects are considered concurrently. Here, we develop attribute signatures-interactively crafted graphics that show the geographic variability of statistics of attributes through which the extent of dependency between the attributes and geography can be visually explored. We compute a number of statistical measures, which can also account for variations in time and scale, and use them as a basis for our visualizations. We then employ different graphical configurations to show and compare both continuous and discrete variation of location and scale. Our methods allow variation in multiple statistical summaries of multiple attributes to be considered concurrently and geographically, as evidenced by examples in which the census geography of London and the wider UK are explored.",,Cagatay Turkay;Aidan Slingsby;Helwig Hauser;Jo Wood;Jason Dykes,"Dep. of Computer Science at City University London, UK;Dep. of Computer Science at City University London, UK;Department of Informatics at University of Bergen, Bergen, Norway;Dep. of Computer Science at City University London, UK;Dep. of Computer Science at City University London, UK",,"Visual analytics,multi-variate data,,geographic information,geovisualization,interactive data analysis,,,,,",,20,,
conference_external,2014,Error Bars Considered Harmful: Exploring Alternate Encodings for Mean and Error,10.1109/TVCG.2014.2346298,http://dx.doi.org/10.1109/TVCG.2014.2346298,2142,2151,Journals,"When making an inference or comparison with uncertain, noisy, or incomplete data, measurement error and confidence intervals can be as important for judgment as the actual mean values of different groups. These often misunderstood statistical quantities are frequently represented by bar charts with error bars. This paper investigates drawbacks with this standard encoding, and considers a set of alternatives designed to more effectively communicate the implications of mean and error data to a general audience, drawing from lessons learned from the use of visual statistics in the information visualization community. We present a series of crowd-sourced experiments that confirm that the encoding of mean and error significantly changes how viewers make decisions about uncertain data. Careful consideration of design tradeoffs in the visual presentation of data results in human reasoning that is more consistently aligned with statistical inferences. We suggest the use of gradient plots (which use transparency to encode uncertainty) and violin plots (which use width) as better alternatives for inferential tasks than bar charts with error bars.",,Michael Correll;Michael Gleicher,"Department of Computer Sciences, University of Wisconsin-Madison;Department of Computer Sciences, University of Wisconsin-Madison",,"Visual statistics,information visualization,,crowd-sourcing,empirical evaluation,,,,,,",,72,,
conference_external,2014,LoyalTracker: Visualizing Loyalty Dynamics in Search Engines,10.1109/TVCG.2014.2346912,http://dx.doi.org/10.1109/TVCG.2014.2346912,1733,1742,Journals,"The huge amount of user log data collected by search engine providers creates new opportunities to understand user loyalty and defection behavior at an unprecedented scale. However, this also poses a great challenge to analyze the behavior and glean insights into the complex, large data. In this paper, we introduce LoyalTracker, a visual analytics system to track user loyalty and switching behavior towards multiple search engines from the vast amount of user log data. We propose a new interactive visualization technique (flow view) based on a flow metaphor, which conveys a proper visual summary of the dynamics of user loyalty of thousands of users over time. Two other visualization techniques, a density map and a word cloud, are integrated to enable analysts to gain further insights into the patterns identified by the flow view. Case studies and the interview with domain experts are conducted to demonstrate the usefulness of our technique in understanding user loyalty and switching behavior in search engines.",,Conglei Shi;Yingcai Wu;Shixia Liu;Hong Zhou;Huamin Qu,Hong Kong University of Science and Technology;Microsoft Research Asia;Microsoft Research Asia;Shenzhen University;Hong Kong University of Science and Technology,,"Time-series visualization,stacked graphs,,log data visualization,text visualization,,,,,,",,18,,
conference_external,2014,iVisDesigner: Expressive Interactive Design of Information Visualizations,10.1109/TVCG.2014.2346291,http://dx.doi.org/10.1109/TVCG.2014.2346291,2092,2101,Journals,"We present the design, implementation and evaluation of iVisDesigner, a web-based system that enables users to design information visualizations for complex datasets interactively, without the need for textual programming. Our system achieves high interactive expressiveness through conceptual modularity, covering a broad information visualization design space. iVisDesigner supports the interactive design of interactive visualizations, such as provisioning for responsive graph layouts and different types of brushing and linking interactions. We present the system design and implementation, exemplify it through a variety of illustrative visualization designs and discuss its limitations. A performance analysis and an informal user study are presented to evaluate the system.",,Donghao Ren;Tobias Höllerer;Xiaoru Yuan,"Department of Computer Science, University of California, Santa Barbara;Department of Computer Science, University of California, Santa Barbara;Key Laboratory of Machine Perception (Ministry of Education), School of EECS",,"Visualization design,Interactive Design,,Interaction,Expressiveness,Web-based visualization,,,,,",,42,,
SciVis,2014,City Forensics: Using Visual Elements to Predict Non-Visual City Attributes,10.1109/TVCG.2014.2346446,http://dx.doi.org/10.1109/TVCG.2014.2346446,2624,2633,Journals,"We present a method for automatically identifying and validating predictive relationships between the visual appearance of a city and its non-visual attributes (e.g. crime statistics, housing prices, population density etc.). Given a set of street-level images and (location, city-attribute-value) pairs of measurements, we first identify visual elements in the images that are discriminative of the attribute. We then train a predictor by learning a set of weights over these elements using non-linear Support Vector Regression. To perform these operations efficiently, we implement a scalable distributed processing framework that speeds up the main computational bottleneck (extracting visual elements) by an order of magnitude. This speedup allows us to investigate a variety of city attributes across 6 different American cities. We find that indeed there is a predictive relationship between visual elements and a number of city attributes including violent crime rates, theft rates, housing prices, population density, tree presence, graffiti presence, and the perception of danger. We also test human performance for predicting theft based on street-level images and show that our predictor outperforms this baseline with 33% higher accuracy on average. Finally, we present three prototype applications that use our system to (1) define the visual boundary of city neighborhoods, (2) generate walking directions that avoid or seek out exposure to city attributes, and (3) validate user-specified visual elements for prediction.",,Sean M. Arietta;Alexei A. Efros;Ravi Ramamoorthi;Maneesh Agrawala,"EECS Department, University of California, Berkeley;EECS Department, University of California, Berkeley;CSE Department, University of California, San Diego;EECS Department, University of California, Berkeley",,"Data mining,big data,,computational geography,visual processing,,,,,,",,51,,
conference_external,2014,Combing the Communication Hairball: Visualizing Parallel Execution Traces using Logical Time,10.1109/TVCG.2014.2346456,http://dx.doi.org/10.1109/TVCG.2014.2346456,2349,2358,Journals,"With the continuous rise in complexity of modern supercomputers, optimizing the performance of large-scale parallel programs is becoming increasingly challenging. Simultaneously, the growth in scale magnifies the impact of even minor inefficiencies - potentially millions of compute hours and megawatts in power consumption can be wasted on avoidable mistakes or sub-optimal algorithms. This makes performance analysis and optimization critical elements in the software development process. One of the most common forms of performance analysis is to study execution traces, which record a history of per-process events and interprocess messages in a parallel application. Trace visualizations allow users to browse this event history and search for insights into the observed performance behavior. However, current visualizations are difficult to understand even for small process counts and do not scale gracefully beyond a few hundred processes. Organizing events in time leads to a virtually unintelligible conglomerate of interleaved events and moderately high process counts overtax even the largest display. As an alternative, we present a new trace visualization approach based on transforming the event history into logical time inferred directly from happened-before relationships. This emphasizes the code's structural behavior, which is much more familiar to the application developer. The original timing data, or other information, is then encoded through color, leading to a more intuitive visualization. Furthermore, we use the discrete nature of logical timelines to cluster processes according to their local behavior leading to a scalable visualization of even long traces on large process counts. We demonstrate our system using two case studies on large-scale parallel codes.",,Katherine E. Isaacs;Peer-Timo Bremer;Ilir Jusufi;Todd Gamblin;Abhinav Bhatele;Martin Schulz;Bernd Hamann,"University of California, Davis;Lawrence Livermore National Laboratory;University of California, Davis;Lawrence Livermore National Laboratory;Lawrence Livermore National Laboratory;Lawrence Livermore National Laboratory;University of California, Davis",,"Information visualization,software visualization,,timelines,traces,performance analysis,,,,,",,22,,
conference_external,2014,"The relation between visualization size, grouping, and user performance",10.1109/TVCG.2014.2346983,http://dx.doi.org/10.1109/TVCG.2014.2346983,1953,1962,Journals,"In this paper we make the following contributions: (1) we describe how the grouping, quantity, and size of visual marks affects search time based on the results from two experiments; (2) we report how search performance relates to self-reported difficulty in finding the target for different display types; and (3) we present design guidelines based on our findings to facilitate the design of effective visualizations. Both Experiment 1 and 2 asked participants to search for a unique target in colored visualizations to test how the grouping, quantity, and size of marks affects user performance. In Experiment 1, the target square was embedded in a grid of squares and in Experiment 2 the target was a point in a scatterplot. Search performance was faster when colors were spatially grouped than when they were randomly arranged. The quantity of marks had little effect on search time for grouped displays (“pop-out”), but increasing the quantity of marks slowed reaction time for random displays. Regardless of color layout (grouped vs. random), response times were slowest for the smallest mark size and decreased as mark size increased to a point, after which response times plateaued. In addition to these two experiments we also include potential application areas, as well as results from a small case study where we report preliminary findings that size may affect how users infer how visualizations should be used. We conclude with a list of design guidelines that focus on how to best create visualizations based on grouping, quantity, and size of visual marks.",,Connor C. Gramazio;Karen B. Schloss;David H. Laidlaw,"Department of Computer Science, Brown University;Department of Cognitive, Linguistic, Psychological Sciences at Brown University;Department of Computer Science, Brown University",,"information visualization,graphical perception,,size,layout,,,,,,",,12,,
SciVis,2014,Vortex Cores of Inertial Particles,10.1109/TVCG.2014.2346415,http://dx.doi.org/10.1109/TVCG.2014.2346415,2535,2544,Journals,"The cores of massless, swirling particle motion are an indicator for vortex-like behavior in vector fields and to this end, a number of coreline extractors have been proposed in the literature. Though, many practical applications go beyond the study of the vector field. Instead, engineers seek to understand the behavior of inertial particles moving therein, for instance in sediment transport, helicopter brownout and pulverized coal combustion. In this paper, we present two strategies for the extraction of the corelines that inertial particles swirl around, which depend on particle density, particle diameter, fluid viscosity and gravity. The first is to deduce the local swirling behavior from the autonomous inertial motion ODE, which eventually reduces to a parallel vectors operation. For the second strategy, we use a particle density estimation to locate inertial attractors. With this, we are able to extract the cores of swirling inertial particle motion for both steady and unsteady 3D vector fields. We demonstrate our techniques in a number of benchmark data sets, and elaborate on the relation to traditional massless corelines.",,Tobias Günther;Holger Theisel,Visual Computing Group at the University of Magdeburg;Visual Computing Group at the University of Magdeburg,,"Inertial particles,flow visualization,,vortex cores,,,,,,,",,12,,
conference_external,2014,Exploring the Placement and Design of Word-Scale Visualizations,10.1109/TVCG.2014.2346435,http://dx.doi.org/10.1109/TVCG.2014.2346435,2291,2300,Journals,"We present an exploration and a design space that characterize the usage and placement of word-scale visualizations within text documents. Word-scale visualizations are a more general version of sparklines-small, word-sized data graphics that allow meta-information to be visually presented in-line with document text. In accordance with Edward Tufte's definition, sparklines are traditionally placed directly before or after words in the text. We describe alternative placements that permit a wider range of word-scale graphics and more flexible integration with text layouts. These alternative placements include positioning visualizations between lines, within additional vertical and horizontal space in the document, and as interactive overlays on top of the text. Each strategy changes the dimensions of the space available to display the visualizations, as well as the degree to which the text must be adjusted or reflowed to accommodate them. We provide an illustrated design space of placement options for word-scale visualizations and identify six important variables that control the placement of the graphics and the level of disruption of the source text. We also contribute a quantitative analysis that highlights the effect of different placements on readability and text disruption. Finally, we use this analysis to propose guidelines to support the design and placement of word-scale visualizations.",,Pascal Goffin;Wesley Willett;Jean-Daniel Fekete;Petra Isenberg,Inria;Inria;Inria;Inria,,"Information visualization,text visualization,,sparklines,glyphs,design space,word-scale visualizations,,,,",,22,,
conference_external,2014,TenniVis: Visualization for Tennis Match Analysis,10.1109/TVCG.2014.2346445,http://dx.doi.org/10.1109/TVCG.2014.2346445,2339,2348,Journals,"Existing research efforts into tennis visualization have primarily focused on using ball and player tracking data to enhance professional tennis broadcasts and to aid coaches in helping their students. Gathering and analyzing this data typically requires the use of an array of synchronized cameras, which are expensive for non-professional tennis matches. In this paper, we propose TenniVis, a novel tennis match visualization system that relies entirely on data that can be easily collected, such as score, point outcomes, point lengths, service information, and match videos that can be captured by one consumer-level camera. It provides two new visualizations to allow tennis coaches and players to quickly gain insights into match performance. It also provides rich interactions to support ad hoc hypothesis development and testing. We first demonstrate the usefulness of the system by analyzing the 2007 Australian Open men's singles final. We then validate its usability by two pilot user studies where two college tennis coaches analyzed the matches of their own players. The results indicate that useful insights can quickly be discovered and ad hoc hypotheses based on these insights can conveniently be tested through linked match videos.",,Tom Polk;Jing Yang;Yueqi Hu;Ye Zhao,University of North Carolina at Charlotte;University of North Carolina at Charlotte;University of North Carolina at Charlotte;Kent State University,,"Visual knowledge discovery,sports analytics,,tennis visualization,,,,,,,",,34,,
SciVis,2014,FLDA: Latent Dirichlet Allocation Based Unsteady Flow Analysis,10.1109/TVCG.2014.2346416,http://dx.doi.org/10.1109/TVCG.2014.2346416,2545,2554,Journals,"In this paper, we present a novel feature extraction approach called FLDA for unsteady flow fields based on Latent Dirichlet allocation (LDA) model. Analogous to topic modeling in text analysis, in our approach, pathlines and features in a given flow field are defined as documents and words respectively. Flow topics are then extracted based on Latent Dirichlet allocation. Different from other feature extraction methods, our approach clusters pathlines with probabilistic assignment, and aggregates features to meaningful topics at the same time. We build a prototype system to support exploration of unsteady flow field with our proposed LDA-based method. Interactive techniques are also developed to explore the extracted topics and to gain insight from the data. We conduct case studies to demonstrate the effectiveness of our proposed approach.",,Fan Hong;Chufan Lai;Hanqi Guo;Enya Shen;Xiaoru Yuan;Sikun Li,"Key Laboratory of Machine Perception (Ministry of Education), School of EECS;Key Laboratory of Machine Perception (Ministry of Education), School of EECS;Key Laboratory of Machine Perception (Ministry of Education), School of EECS;School of Computer Science, National University of Defense Technology, Changsha, China;Key Laboratory of Machine Perception (Ministry of Education), School of EECS;School of Computer Science, National University of Defense Technology, Changsha, China",,"Flow visualization,Topic model,,Latent Dirichlet allocation (LDA),,,,,,,",,12,,
conference_external,2014,Reinforcing Visual Grouping Cues to Communicate Complex Informational Structure,10.1109/TVCG.2014.2346998,http://dx.doi.org/10.1109/TVCG.2014.2346998,1973,1982,Journals,"In his book Multimedia Learning [7], Richard Mayer asserts that viewers learn best from imagery that provides them with cues to help them organize new information into the correct knowledge structures. Designers have long been exploiting the Gestalt laws of visual grouping to deliver viewers those cues using visual hierarchy, often communicating structures much more complex than the simple organizations studied in psychological research. Unfortunately, designers are largely practical in their work, and have not paused to build a complex theory of structural communication. If we are to build a tool to help novices create effective and well structured visuals, we need a better understanding of how to create them. Our work takes a first step toward addressing this lack, studying how five of the many grouping cues (proximity, color similarity, common region, connectivity, and alignment) can be effectively combined to communicate structured text and imagery from real world examples. To measure the effectiveness of this structural communication, we applied a digital version of card sorting, a method widely used in anthropology and cognitive science to extract cognitive structures. We then used tree edit distance to measure the difference between perceived and communicated structures. Our most significant findings are: 1) with careful design, complex structure can be communicated clearly; 2) communicating complex structure is best done with multiple reinforcing grouping cues; 3) common region (use of containers such as boxes) is particularly effective at communicating structure; and 4) alignment is a weak structural communicator.",,Juhee Bae;Benjamin Watson,North Carolina State University;North Carolina State University,,"Visual grouping,visual hierarchy,,gestalt principles,perception,visual communication,,,,,",,7,,
conference_external,2014,Visual Analytics for Comparison of Ocean Model Output with Reference Data: Detecting and Analyzing Geophysical Processes Using Clustering Ensembles,10.1109/TVCG.2014.2346751,http://dx.doi.org/10.1109/TVCG.2014.2346751,1893,1902,Journals,"Researchers assess the quality of an ocean model by comparing its output to that of a previous model version or to observations. One objective of the comparison is to detect and to analyze differences and similarities between both data sets regarding geophysical processes, such as particular ocean currents. This task involves the analysis of thousands or hundreds of thousands of geographically referenced temporal profiles in the data. To cope with the amount of data, modelers combine aggregation of temporal profiles to single statistical values with visual comparison. Although this strategy is based on experience and a well-grounded body of expert knowledge, our discussions with domain experts have shown that it has two limitations: (1) using a single statistical measure results in a rather limited scope of the comparison and in significant loss of information, and (2) the decisions modelers have to make in the process may lead to important aspects being overlooked.",,Patrick Köthur;Mike Sips;Henryk Dobslaw;Doris Dransch,"GFZ German Research Centre for Geosciences, Potsdam, Germany;GFZ German Research Centre for Geosciences, Potsdam, Germany;GFZ German Research Centre for Geosciences, Potsdam, Germany;GFZ German Research Centre for Geosciences, Potsdam, Germany",,"Ocean modeling,model assessment,,geospatial time,series,cluster ensembles,visual comparison,visual analytics,,,",,17,,
conference_external,2014,Opening the Black Box: Strategies for Increased User Involvement in Existing Algorithm Implementations,10.1109/TVCG.2014.2346578,http://dx.doi.org/10.1109/TVCG.2014.2346578,1643,1652,Journals,"An increasing number of interactive visualization tools stress the integration with computational software like MATLAB and R to access a variety of proven algorithms. In many cases, however, the algorithms are used as black boxes that run to completion in isolation which contradicts the needs of interactive data exploration. This paper structures, formalizes, and discusses possibilities to enable user involvement in ongoing computations. Based on a structured characterization of needs regarding intermediate feedback and control, the main contribution is a formalization and comparison of strategies for achieving user involvement for algorithms with different characteristics. In the context of integration, we describe considerations for implementing these strategies either as part of the visualization tool or as part of the algorithm, and we identify requirements and guidelines for the design of algorithmic APIs. To assess the practical applicability, we provide a survey of frequently used algorithm implementations within R regarding the fulfillment of these guidelines. While echoing previous calls for analysis modules which support data exploration more directly, we conclude that a range of pragmatic options for enabling user involvement in ongoing computations exists on both the visualization and algorithm side and should be used.",,Thomas Mühlbacher;Harald Piringer;Samuel Gratzl;Michael Sedlmair;Marc Streit,"VRVis Research Center, Vienna, Austria;VRVis Research Center, Vienna, Austria;Johannes Kepler University, Linz, Austria;University of Vienna, Austria;Johannes Kepler University, Linz, Austria",,"Visual analytics infrastructures,integration,,interactive algorithms,user involvement,problem subdivision,,,,,",,60,,
conference_external,2014,DIA2: Web-based Cyberinfrastructure for Visual Analysis of Funding Portfolios,10.1109/TVCG.2014.2346747,http://dx.doi.org/10.1109/TVCG.2014.2346747,1823,1832,Journals,"We present a design study of the Deep Insights Anywhere, Anytime (DIA2) platform, a web-based visual analytics system that allows program managers and academic staff at the U.S. National Science Foundation to search, view, and analyze their research funding portfolio. The goal of this system is to facilitate users' understanding of both past and currently active research awards in order to make more informed decisions of their future funding. This user group is characterized by high domain expertise yet not necessarily high literacy in visualization and visual analytics-they are essentially casual experts-and thus require careful visual and information design, including adhering to user experience standards, providing a self-instructive interface, and progressively refining visualizations to minimize complexity. We discuss the challenges of designing a system for casual experts and highlight how we addressed this issue by modeling the organizational structure and workflows of the NSF within our system. We discuss each stage of the design process, starting with formative interviews, prototypes, and finally live deployments and evaluation with stakeholders.",,Krishna Madhavan;Niklas Elmqvist;Mihaela Vorvoreanu;Xin Chen;Yuetling Wong;Hanjun Xian;Zhihua Dong;Aditya Johri,Purdue University;Purdue University;Purdue University;Purdue University;Purdue University;Microsoft Corporation;Microsoft Corporation;George Mason University,,"visual analytics,portfolio mining,,web-based visualization,casual visualization,design study,,,,,",,15,,
conference_external,2014,MovExp: A Versatile Visualization Tool for Human-Computer Interaction Studies with 3D Performance and Biomechanical Data,10.1109/TVCG.2014.2346311,http://dx.doi.org/10.1109/TVCG.2014.2346311,2359,2368,Journals,"In Human-Computer Interaction (HCI), experts seek to evaluate and compare the performance and ergonomics of user interfaces. Recently, a novel cost-efficient method for estimating physical ergonomics and performance has been introduced to HCI. It is based on optical motion capture and biomechanical simulation. It provides a rich source for analyzing human movements summarized in a multidimensional data set. Existing visualization tools do not sufficiently support the HCI experts in analyzing this data. We identified two shortcomings. First, appropriate visual encodings are missing particularly for the biomechanical aspects of the data. Second, the physical setup of the user interface cannot be incorporated explicitly into existing tools. We present MovExp, a versatile visualization tool that supports the evaluation of user interfaces. In particular, it can be easily adapted by the HCI experts to include the physical setup that is being evaluated, and visualize the data on top of it. Furthermore, it provides a variety of visual encodings to communicate muscular loads, movement directions, and other specifics of HCI studies that employ motion capture and biomechanical simulation. In this design study, we follow a problem-driven research approach. Based on a formalization of the visualization needs and the data structure, we formulate technical requirements for the visualization tool and present novel solutions to the analysis needs of the HCI experts. We show the utility of our tool with four case studies from the daily work of our HCI experts.",,Gregorio Palmas;Myroslav Bachynskyi;Antti Oulasvirta;Hans-Peter Seidel;Tina Weinkauf,Max Planck Institute for Informatics;Max Planck Institute for Informatics;Max Planck Institute for Informatics;Max Planck Institute for Informatics;Max Planck Institute for Informatics,,"Information visualization,Design study,,Human-Computer Interaction,,,,,,,",,11,,
conference_external,2014,Cupid: Cluster-Based Exploration of Geometry Generators with Parallel Coordinates and Radial Trees,10.1109/TVCG.2014.2346626,http://dx.doi.org/10.1109/TVCG.2014.2346626,1693,1702,Journals,"Geometry generators are commonly used in video games and evaluation systems for computer vision to create geometric shapes such as terrains, vegetation or airplanes. The parameters of the generator are often sampled automatically which can lead to many similar or unwanted geometric shapes. In this paper, we propose a novel visual exploration approach that combines the abstract parameter space of the geometry generator with the resulting 3D shapes in a composite visualization. Similar geometric shapes are first grouped using hierarchical clustering and then nested within an illustrative parallel coordinates visualization. This helps the user to study the sensitivity of the generator with respect to its parameter space and to identify invalid parameter settings. Starting from a compact overview representation, the user can iteratively drill-down into local shape differences by clicking on the respective clusters. Additionally, a linked radial tree gives an overview of the cluster hierarchy and enables the user to manually split or merge clusters. We evaluate our approach by exploring the parameter space of a cup generator and provide feedback from domain experts.",,Michael Beham;Wolfgang Herzner;M. Eduard Gröller;Johannes Kehrer,Vienna University of Technology;Austrian Institute of Technology;Vienna University of Technology;Vienna University of Technology,,"Composite visualization,hierarchical clustering,,illustrative parallel coordinates,radial trees,3D shape analysis,,,,,",,18,,
SciVis,2014,Escape Maps,10.1109/TVCG.2014.2346442,http://dx.doi.org/10.1109/TVCG.2014.2346442,2604,2613,Journals,"We present a technique to visualize the streamline-based mapping between the boundary of a simply-connected subregion of arbitrary 3D vector fields. While the streamlines are seeded on one part of the boundary, the remaining part serves as escape border. Hence, the seeding part of the boundary represents a map of streamline behavior, indicating if streamlines reach the escape border or not. Since the resulting maps typically exhibit a very fine and complex structure and are thus not amenable to direct sampling, our approach instead aims at topologically consistent extraction of their boundary. We show that isocline surfaces of the projected vector field provide a robust basis for stream-surface-based extraction of these boundaries. The utility of our technique is demonstrated in the context of transport processes using vector field data from different domains.",,Gustavo Machado;Filip Sadlo;Thomas Müller;Thomas Ertl,"University of Stuttgart, Germany;University of Stuttgart, Germany;University of Stuttgart, Germany;University of Stuttgart, Germany",,"Streamline behavior,vector field topology,,isocline surfaces,coronal hole extraction,,,,,,",,1,,
conference_external,2014,Interactive Visual Analysis of Image-Centric Cohort Study Data,10.1109/TVCG.2014.2346591,http://dx.doi.org/10.1109/TVCG.2014.2346591,1673,1682,Journals,"Epidemiological population studies impose information about a set of subjects (a cohort) to characterize disease-specific risk factors. Cohort studies comprise heterogenous variables describing the medical condition as well as demographic and lifestyle factors and, more recently, medical image data. We propose an Interactive Visual Analysis (IVA) approach that enables epidemiologists to rapidly investigate the entire data pool for hypothesis validation and generation. We incorporate image data, which involves shape-based object detection and the derivation of attributes describing the object shape. The concurrent investigation of image-based and non-image data is realized in a web-based multiple coordinated view system, comprising standard views from information visualization and epidemiological data representations such as pivot tables. The views are equipped with brushing facilities and augmented by 3D shape renderings of the segmented objects, e.g., each bar in a histogram is overlaid with a mean shape of the associated subgroup of the cohort. We integrate an overview visualization, clustering of variables and object shape for data-driven subgroup definition and statistical key figures for measuring the association between variables. We demonstrate the IVA approach by validating and generating hypotheses related to lower back pain as part of a qualitative evaluation.",,Paul Klemm;Steffen Oeltze-Jafra;Kai Lawonn;Katrin Hegenscheid;Henry Völzke;Bernhard Preim,"Otto-von-Guericke University Magdeburg, Germany;Otto-von-Guericke University Magdeburg, Germany;Otto-von-Guericke University Magdeburg, Germany;Ernst-Moritz-Arndt University Greifswald, Germany;Ernst-Moritz-Arndt University Greifswald, Germany;Otto-von-Guericke University Magdeburg, Germany",,"Interactive Visual Analysis,Epidemiology,,Spine,,,,,,,",,23,,
conference_external,2014,#FluxFlow: Visual Analysis of Anomalous Information Spreading on Social Media,10.1109/TVCG.2014.2346922,http://dx.doi.org/10.1109/TVCG.2014.2346922,1773,1782,Journals,"We present FluxFlow, an interactive visual analysis system for revealing and analyzing anomalous information spreading in social media. Everyday, millions of messages are created, commented, and shared by people on social media websites, such as Twitter and Facebook. This provides valuable data for researchers and practitioners in many application domains, such as marketing, to inform decision-making. Distilling valuable social signals from the huge crowd's messages, however, is challenging, due to the heterogeneous and dynamic crowd behaviors. The challenge is rooted in data analysts' capability of discerning the anomalous information behaviors, such as the spreading of rumors or misinformation, from the rest that are more conventional patterns, such as popular topics and newsworthy events, in a timely fashion. FluxFlow incorporates advanced machine learning algorithms to detect anomalies, and offers a set of novel visualization designs for presenting the detected threads for deeper analysis. We evaluated FluxFlow with real datasets containing the Twitter feeds captured during significant events such as Hurricane Sandy. Through quantitative measurements of the algorithmic performance and qualitative interviews with domain experts, the results show that the back-end anomaly detection model is effective in identifying anomalous retweeting threads, and its front-end interactive visualizations are intuitive and useful for analysts to discover insights in data and comprehend the underlying analytical model.",,Jian Zhao;Nan Cao;Zhen Wen;Yale Song;Yu-Ru Lin;Christopher Collins,University of Toronto;MIT;MIT;IBM J. Watson Research Center;University of Pittsburgh;UOIT,,"Retweeting threads,anomaly detection,,social media,visual analytics,machine learning,information visualization,,,,",,80,,
SciVis,2014,Curve Boxplot: Generalization of Boxplot for Ensembles of Curves,10.1109/TVCG.2014.2346455,http://dx.doi.org/10.1109/TVCG.2014.2346455,2654,2663,Journals,"In simulation science, computational scientists often study the behavior of their simulations by repeated solutions with variations in parameters and/or boundary values or initial conditions. Through such simulation ensembles, one can try to understand or quantify the variability or uncertainty in a solution as a function of the various inputs or model assumptions. In response to a growing interest in simulation ensembles, the visualization community has developed a suite of methods for allowing users to observe and understand the properties of these ensembles in an efficient and effective manner. An important aspect of visualizing simulations is the analysis of derived features, often represented as points, surfaces, or curves. In this paper, we present a novel, nonparametric method for summarizing ensembles of 2D and 3D curves. We propose an extension of a method from descriptive statistics, data depth, to curves. We also demonstrate a set of rendering and visualization strategies for showing rank statistics of an ensemble of curves, which is a generalization of traditional whisker plots or boxplots to multidimensional curves. Results are presented for applications in neuroimaging, hurricane forecasting and fluid dynamics.",,Mahsa Mirzargar;Ross T. Whitaker;Robert M. Kirby,"Scientific Computing and Imaging Institute, University of Utah, Salt Lake City, UT;Scientific Computing and Imaging Institute, Salt Lake City, UT;Scientific Computing and Imaging Institute, Salt Lake City, UT",,"Uncertainty visualization,boxplots,,ensemble visualization,order statistics,data depth,nonparametric statistic,functional data,parametric curves,,",,80,,
conference_external,2014,VAET: A Visual Analytics Approach for E-Transactions Time-Series,10.1109/TVCG.2014.2346913,http://dx.doi.org/10.1109/TVCG.2014.2346913,1743,1752,Journals,"Previous studies on E-transaction time-series have mainly focused on finding temporal trends of transaction behavior. Interesting transactions that are time-stamped and situation-relevant may easily be obscured in a large amount of information. This paper proposes a visual analytics system, Visual Analysis of E-transaction Time-Series (VAET), that allows the analysts to interactively explore large transaction datasets for insights about time-varying transactions. With a set of analyst-determined training samples, VAET automatically estimates the saliency of each transaction in a large time-series using a probabilistic decision tree learner. It provides an effective time-of-saliency (TOS) map where the analysts can explore a large number of transactions at different time granularities. Interesting transactions are further encoded with KnotLines, a compact visual representation that captures both the temporal variations and the contextual connection of transactions. The analysts can thus explore, select, and investigate knotlines of interest. A case study and user study with a real E-transactions dataset (26 million records) demonstrate the effectiveness of VAET.",,Cong Xie;Wei Chen;Xinxin Huang;Yueqi Hu;Scott Barlowe;Jing Yang,"State Key Lab of CAD&CG, Zhejiang University;State Key Lab of CAD&CG, Zhejiang University;State Key Lab of CAD&CG, Zhejiang University;Dept. of Computer Science, University of North Carolina, Charlotte;Western Carolina University;Dept. of Computer Science, University of North Carolina, Charlotte",,"Time-Series,Visual Analytics,,E-transaction,,,,,,,",,35,,
conference_external,2014,Transforming Scagnostics to Reveal Hidden Features,10.1109/TVCG.2014.2346572,http://dx.doi.org/10.1109/TVCG.2014.2346572,1624,1632,Journals,"Scagnostics (Scatterplot Diagnostics) were developed by Wilkinson et al. based on an idea of Paul and John Tukey, in order to discern meaningful patterns in large collections of scatterplots. The Tukeys' original idea was intended to overcome the impediments involved in examining large scatterplot matrices (multiplicity of plots and lack of detail). Wilkinson's implementation enabled for the first time scagnostics computations on many points as well as many plots. Unfortunately, scagnostics are sensitive to scale transformations. We illustrate the extent of this sensitivity and show how it is possible to pair statistical transformations with scagnostics to enable discovery of hidden structures in data that are not discernible in untransformed visualizations.",,Tuan Nhon Dang;Leland Wilkinson,"Department of Computer Science, University of Illinois at Chicago;Department of Computer Science, Skytree Software Inc.",,"Scagnostics,Scatterplot matrix,,Transformation,High-Dimensional Visual Analytics,,,,,,",,16,,
conference_external,2014,Visualizing Statistical Mix Effects and Simpson's Paradox,10.1109/TVCG.2014.2346297,http://dx.doi.org/10.1109/TVCG.2014.2346297,2132,2141,Journals,"We discuss how “mix effects” can surprise users of visualizations and potentially lead them to incorrect conclusions. This statistical issue (also known as “omitted variable bias” or, in extreme cases, as “Simpson's paradox”) is widespread and can affect any visualization in which the quantity of interest is an aggregated value such as a weighted sum or average. Our first contribution is to document how mix effects can be a serious issue for visualizations, and we analyze how mix effects can cause problems in a variety of popular visualization techniques, from bar charts to treemaps. Our second contribution is a new technique, the “comet chart,” that is meant to ameliorate some of these issues.",,Zan Armstrong;Martin Wattenberg,"Google at the time of research, currently unaffiliated;Google",,"Mix effects,Omitted variable bias,,Simpson's paradox,Statistics,,,,,,",,5,,
SciVis,2014,Design and Evaluation of Interactive Proofreading Tools for Connectomics,10.1109/TVCG.2014.2346371,http://dx.doi.org/10.1109/TVCG.2014.2346371,2466,2475,Journals,"Proofreading refers to the manual correction of automatic segmentations of image data. In connectomics, electron microscopy data is acquired at nanometer-scale resolution and results in very large image volumes of brain tissue that require fully automatic segmentation algorithms to identify cell boundaries. However, these algorithms require hundreds of corrections per cubic micron of tissue. Even though this task is time consuming, it is fairly easy for humans to perform corrections through splitting, merging, and adjusting segments during proofreading. In this paper we present the design and implementation of Mojo, a fully-featured single-user desktop application for proofreading, and Dojo, a multi-user web-based application for collaborative proofreading. We evaluate the accuracy and speed of Mojo, Dojo, and Raveler, a proofreading tool from Janelia Farm, through a quantitative user study. We designed a between-subjects experiment and asked non-experts to proofread neurons in a publicly available connectomics dataset. Our results show a significant improvement of corrections using web-based Dojo, when given the same amount of time. In addition, all participants using Dojo reported better usability. We discuss our findings and provide an analysis of requirements for designing visual proofreading software.",,Daniel Haehn;Seymour Knowles-Barley;Mike Roberts;Johanna Beyer;Narayanan Kasthuri;Jeff W. Lichtman;Hanspeter Pfister,School of Engineering and Applied Sciences at Harvard University;Center for Brain Science at Harvard University;Computer Graphics Laboratory at Stanford University;School of Engineering and Applied Sciences at Harvard University;Center for Brain Science at Harvard University;Center for Brain Science at Harvard University;School of Engineering and Applied Sciences at Harvard University,,"Proofreading,Segmentation,,Connectomics,Quantitative Evaluation,,,,,,",,27,,
conference_external,2014,Moving beyond sequential design: Reflections on a rich multi-channel approach to data visualization,10.1109/TVCG.2014.2346323,http://dx.doi.org/10.1109/TVCG.2014.2346323,2171,2180,Journals,"We reflect on a four-year engagement with transport authorities and others involving a large dataset describing the use of a public bicycle-sharing scheme. We describe the role visualization of these data played in fostering engagement with policy makers, transport operators, the transport research community, the museum and gallery sector and the general public. We identify each of these as `channels'-evolving relationships between producers and consumers of visualization-where traditional roles of the visualization expert and domain expert are blurred. In each case, we identify the different design decisions that were required to support each of these channels and the role played by the visualization process. Using chauffeured interaction with a flexible visual analytics system we demonstrate how insight was gained by policy makers into gendered spatio-temporal cycle behaviors, how this led to further insight into workplace commuting activity, group cycling behavior and explanations for street navigation choice. We demonstrate how this supported, and was supported by, the seemingly unrelated development of narrative-driven visualization via TEDx, of the creation and the setting of an art installation and the curating of digital and physical artefacts. We assert that existing models of visualization design, of tool/technique development and of insight generation do not adequately capture the richness of parallel engagement via these multiple channels of communication. We argue that developing multiple channels in parallel opens up opportunities for visualization design and analysis by building trust and authority and supporting creativity. This rich, non-sequential approach to visualization design is likely to foster serendipity, deepen insight and increase impact.",,Jo Wood;Roger Beecham;Jason Dykes,"giCentre, City University London;giCentre, City University London;giCentre, City University London",,"Movement visualization,visual analytics,,bikeshare,impact,visualization models,design study,,,,",,17,,
conference_external,2014,Proactive Spatiotemporal Resource Allocation and Predictive Visual Analytics for Community Policing and Law Enforcement,10.1109/TVCG.2014.2346926,http://dx.doi.org/10.1109/TVCG.2014.2346926,1863,1872,Journals,"In this paper, we present a visual analytics approach that provides decision makers with a proactive and predictive environment in order to assist them in making effective resource allocation and deployment decisions. The challenges involved with such predictive analytics processes include end-users' understanding, and the application of the underlying statistical algorithms at the right spatiotemporal granularity levels so that good prediction estimates can be established. In our approach, we provide analysts with a suite of natural scale templates and methods that enable them to focus and drill down to appropriate geospatial and temporal resolution levels. Our forecasting technique is based on the Seasonal Trend decomposition based on Loess (STL) method, which we apply in a spatiotemporal visual analytics context to provide analysts with predicted levels of future activity. We also present a novel kernel density estimation technique we have developed, in which the prediction process is influenced by the spatial correlation of recent incidents at nearby locations. We demonstrate our techniques by applying our methodology to Criminal, Traffic and Civil (CTC) incident datasets.",,Abish Malik;Ross Maciejewski;Sherry Towers;Sean McCullough;David S. Ebert,Purdue University;Arizona State University;Arizona State University;Purdue University;Purdue University,,"Visual Analytics,Natural Scales,,Seasonal Trend decomposition based on Loess (STL),Law Enforcement,,,,,,",,37,,
conference_external,2014,UpSet: Visualization of Intersecting Sets,10.1109/TVCG.2014.2346248,http://dx.doi.org/10.1109/TVCG.2014.2346248,1983,1992,Journals,"Understanding relationships between sets is an important analysis task that has received widespread attention in the visualization community. The major challenge in this context is the combinatorial explosion of the number of set intersections if the number of sets exceeds a trivial threshold. In this paper we introduce UpSet, a novel visualization technique for the quantitative analysis of sets, their intersections, and aggregates of intersections. UpSet is focused on creating task-driven aggregates, communicating the size and properties of aggregates and intersections, and a duality between the visualization of the elements in a dataset and their set membership. UpSet visualizes set intersections in a matrix layout and introduces aggregates based on groupings and queries. The matrix layout enables the effective representation of associated data, such as the number of elements in the aggregates and intersections, as well as additional summary statistics derived from subset or element attributes. Sorting according to various measures enables a task-driven analysis of relevant intersections and aggregates. The elements represented in the sets and their associated attributes are visualized in a separate view. Queries based on containment in specific intersections, aggregates or driven by attribute filters are propagated between both views. We also introduce several advanced visual encodings and interaction methods to overcome the problems of varying scales and to address scalability. UpSet is web-based and open source. We demonstrate its general utility in multiple use cases from various domains.",,Alexander Lex;Nils Gehlenborg;Hendrik Strobelt;Romain Vuillemot;Hanspeter Pfister,Hendrik Strobelt and Hanspeter Pfister are with Harvard University.;Harvard Medical School;Hendrik Strobelt and Hanspeter Pfister are with Harvard University.;Romain Vuillemot is with Harvard University;Hendrik Strobelt and Hanspeter Pfister are with Harvard University.,,"Sets,set visualization,,sets intersections,set attributes,set relationships,multidimensional data,,,,",,537,,
conference_external,2014,Four Experiments on the Perception of Bar Charts,10.1109/TVCG.2014.2346320,http://dx.doi.org/10.1109/TVCG.2014.2346320,2152,2160,Journals,"Bar charts are one of the most common visualization types. In a classic graphical perception paper, Cleveland & McGill studied how different bar chart designs impact the accuracy with which viewers can complete simple perceptual tasks. They found that people perform substantially worse on stacked bar charts than on aligned bar charts, and that comparisons between adjacent bars are more accurate than between widely separated bars. However, the study did not explore why these differences occur. In this paper, we describe a series of follow-up experiments to further explore and explain their results. While our results generally confirm Cleveland & McGill's ranking of various bar chart configurations, we provide additional insight into the bar chart reading task and the sources of participants' errors. We use our results to propose new hypotheses on the perception of bar charts.",,Justin Talbot;Vidya Setlur;Anushka Anand,Tableau Research;Tableau Research;Tableau Research,,"Graphical perception,bar charts,,Graphical perception,bar charts,,,,,,",,30,,
conference_external,2014,Comparative Eye Tracking Study on Node-Link Visualizations of Trajectories,10.1109/TVCG.2014.2346420,http://dx.doi.org/10.1109/TVCG.2014.2346420,2221,2230,Journals,"We present the results of an eye tracking study that compares different visualization methods for long, dense, complex, and piecewise linear spatial trajectories. Typical sources of such data are from temporally discrete measurements of the positions of moving objects, for example, recorded GPS tracks of animals in movement ecology. In the repeated-measures within-subjects user study, four variants of node-link visualization techniques are compared, with the following representations of directed links: standard arrow, tapered, equidistant arrows, and equidistant comets. In addition, we investigate the effect of rendering order for the halo visualization of those links as well as the usefulness of node splatting. All combinations of link visualization techniques are tested for different trajectory density levels. We used three types of tasks: tracing of paths, identification of longest links, and estimation of the density of trajectory clusters. Results are presented in the form of the statistical evaluation of task completion time, task solution accuracy, and two eye tracking metrics. These objective results are complemented by a summary of subjective feedback from the participants. The main result of our study is that tapered links perform very well. However, we discuss that equidistant comets and equidistant arrows are a good option to perceive direction information independent of zoom-level of the display.",,Rudolf Netzel;Michel Burch;Daniel Weiskopf,VISUS;VISUS;VISUS,,"User study,eye tracking,,evaluation,trajectory visualization,node-link visualization,direction encoding,node splatting,halo rendering,,",,18,,
conference_external,2014,Multivariate Network Exploration and Presentation: From Detail to Overview via Selections and Aggregations,10.1109/TVCG.2014.2346441,http://dx.doi.org/10.1109/TVCG.2014.2346441,2310,2319,Journals,"Network data is ubiquitous; e-mail traffic between persons, telecommunication, transport and financial networks are some examples. Often these networks are large and multivariate, besides the topological structure of the network, multivariate data on the nodes and links is available. Currently, exploration and analysis methods are focused on a single aspect; the network topology or the multivariate data. In addition, tools and techniques are highly domain specific and require expert knowledge. We focus on the non-expert user and propose a novel solution for multivariate network exploration and analysis that tightly couples structural and multivariate analysis. In short, we go from Detail to Overview via Selections and Aggregations (DOSA): users are enabled to gain insights through the creation of selections of interest (manually or automatically), and producing high-level, infographic-style overviews simultaneously. Finally, we present example explorations on real-world datasets that demonstrate the effectiveness of our method for the exploration and understanding of multivariate networks where presentation of findings comes for free.",,Stef van den Elzen;Jarke J. van Wijk,"Department of Mathematic and Computer Science, Eindhoven University of Technology, The Netherlands;Department of Mathematic and Computer Science, Eindhoven University of Technology, The Netherlands",,"Multivariate networks,Selections of interest,,Interaction,Direct manipulation,,,,,,",,61,,
SciVis,2014,Attractive Flicker — Guiding Attention in Dynamic Narrative Visualizations,10.1109/TVCG.2014.2346352,http://dx.doi.org/10.1109/TVCG.2014.2346352,2456,2465,Journals,"Focus-context techniques provide visual guidance in visualizations by giving strong visual prominence to elements of interest while the context is suppressed. However, finding a visual feature to enhance for the focus to pop out from its context in a large dynamic scene, while leading to minimal visual deformation and subjective disturbance, is challenging. This paper proposes Attractive Flicker, a novel technique for visual guidance in dynamic narrative visualizations. We first show that flicker is a strong visual attractor in the entire visual field, without distorting, suppressing, or adding any scene elements. The novel aspect of our Attractive Flicker technique is that it consists of two signal stages: The first “orientation stage” is a short but intensive flicker stimulus to attract the attention to elements of interest. Subsequently, the intensive flicker is reduced to a minimally disturbing luminance oscillation (“engagement stage”) as visual support to keep track of the focus elements. To find a good trade-off between attraction effectiveness and subjective annoyance caused by flicker, we conducted two perceptual studies to find suitable signal parameters. We showcase Attractive Flicker with the parameters obtained from the perceptual statistics in a study of molecular interactions. With Attractive Flicker, users were able to easily follow the narrative of the visualization on a large display, while the flickering of focus elements was not disturbing when observing the context.",,Manuela Waldner;Mathieu Le Muzic;Matthias Bernhard;Werner Purgathofer;Ivan Viola,Vienna University of Technology;Vienna University of Technology;Vienna University of Technology;Vienna University of Technology;Vienna University of Technology,,"Visual attention,flicker,,narrative visualization,,,,,,,",,12,,
conference_external,2014,"Overview: The Design, Adoption, and Analysis of a Visual Document Mining Tool for Investigative Journalists",10.1109/TVCG.2014.2346431,http://dx.doi.org/10.1109/TVCG.2014.2346431,2271,2280,Journals,"For an investigative journalist, a large collection of documents obtained from a Freedom of Information Act request or a leak is both a blessing and a curse: such material may contain multiple newsworthy stories, but it can be difficult and time consuming to find relevant documents. Standard text search is useful, but even if the search target is known it may not be possible to formulate an effective query. In addition, summarization is an important non-search task. We present Overview, an application for the systematic analysis of large document collections based on document clustering, visualization, and tagging. This work contributes to the small set of design studies which evaluate a visualization system “in the wild”, and we report on six case studies where Overview was voluntarily used by self-initiated journalists to produce published stories. We find that the frequently-used language of “exploring” a document collection is both too vague and too narrow to capture how journalists actually used our application. Our iterative process, including multiple rounds of deployment and observations of real world usage, led to a much more specific characterization of tasks. We analyze and justify the visual encoding and interaction techniques used in Overview's design with respect to our final task abstractions, and propose generalizable lessons for visualization design methodology.",,Matthew Brehmer;Stephen Ingram;Jonathan Stray;Tamara Munzner,University of British Columbia;University of British Columbia;Columbia Journalism School and the Associated Press;University of British Columbia,,"Design study,investigative journalism,,task and requirements analysis,text and document data,text analysis,,,,,",,27,,
SciVis,2014,Combined Visualization of Wall Thickness and Wall Shear Stress for the Evaluation of Aneurysms,10.1109/TVCG.2014.2346406,http://dx.doi.org/10.1109/TVCG.2014.2346406,2506,2515,Journals,"For an individual rupture risk assessment of aneurysms, the aneurysm's wall morphology and hemodynamics provide valuable information. Hemodynamic information is usually extracted via computational fluid dynamic (CFD) simulation on a previously extracted 3D aneurysm surface mesh or directly measured with 4D phase-contrast magnetic resonance imaging. In contrast, a noninvasive imaging technique that depicts the aneurysm wall in vivo is still not available. Our approach comprises an experiment, where intravascular ultrasound (IVUS) is employed to probe a dissected saccular aneurysm phantom, which we modeled from a porcine kidney artery. Then, we extracted a 3D surface mesh to gain the vessel wall thickness and hemodynamic information from a CFD simulation. Building on this, we developed a framework that depicts the inner and outer aneurysm wall with dedicated information about local thickness via distance ribbons. For both walls, a shading is adapted such that the inner wall as well as its distance to the outer wall is always perceivable. The exploration of the wall is further improved by combining it with hemodynamic information from the CFD simulation. Hence, the visual analysis comprises a brushing and linking concept for individual highlighting of pathologic areas. Also, a surface clustering is integrated to provide an automatic division of different aneurysm parts combined with a risk score depending on wall thickness and hemodynamic information. In general, our approach can be employed for vessel visualization purposes where an inner and outer wall has to be adequately represented.",,Sylvia Glaßer;Kai Lawonn;Thomas Hoffmann;Martin Skalej;Bernhard Preim,"Department for Simulation and Graphics, University of Magdeburg, Germany;Department for Simulation and Graphics, University of Magdeburg, Germany;Neuroradiology Department, University hospital of Magdeburg, Germany;Neuroradiology Department, University hospital of Magdeburg, Germany;Department for Simulation and Graphics, University of Magdeburg, Germany",,"Aneurysm,IVUS,,Wall Thickness,Wall Shear Stress,Brushing and Linking,Focus + Context,,,,",,11,,
conference_external,2014,The Persuasive Power of Data Visualization,10.1109/TVCG.2014.2346419,http://dx.doi.org/10.1109/TVCG.2014.2346419,2211,2220,Journals,"Data visualization has been used extensively to inform users. However, little research has been done to examine the effects of data visualization in influencing users or in making a message more persuasive. In this study, we present experimental research to fill this gap and present an evidence-based analysis of persuasive visualization. We built on persuasion research from psychology and user interfaces literature in order to explore the persuasive effects of visualization. In this experimental study we define the circumstances under which data visualization can make a message more persuasive, propose hypotheses, and perform quantitative and qualitative analyses on studies conducted to test these hypotheses. We compare visual treatments with data presented through barcharts and linecharts on the one hand, treatments with data presented through tables on the other, and then evaluate their persuasiveness. The findings represent a first step in exploring the effectiveness of persuasive visualization.",,Anshul Vikram Pandey;Anjali Manivannan;Oded Nov;Margaret Satterthwaite;Enrico Bertini,New York University;New York University;New York University;New York University;New York University,,"Persuasive visualization,elaboration likelihood model,,evaluation,,,,,,,",,43,,
conference_external,2014,NeuroLines: A Subway Map Metaphor for Visualizing Nanoscale Neuronal Connectivity,10.1109/TVCG.2014.2346312,http://dx.doi.org/10.1109/TVCG.2014.2346312,2369,2378,Journals,"We present NeuroLines, a novel visualization technique designed for scalable detailed analysis of neuronal connectivity at the nanoscale level. The topology of 3D brain tissue data is abstracted into a multi-scale, relative distance-preserving subway map visualization that allows domain scientists to conduct an interactive analysis of neurons and their connectivity. Nanoscale connectomics aims at reverse-engineering the wiring of the brain. Reconstructing and analyzing the detailed connectivity of neurons and neurites (axons, dendrites) will be crucial for understanding the brain and its development and diseases. However, the enormous scale and complexity of nanoscale neuronal connectivity pose big challenges to existing visualization techniques in terms of scalability. NeuroLines offers a scalable visualization framework that can interactively render thousands of neurites, and that supports the detailed analysis of neuronal structures and their connectivity. We describe and analyze the design of NeuroLines based on two real-world use-cases of our collaborators in developmental neuroscience, and investigate its scalability to large-scale neuronal connectivity data.",,Ali K. Al-Awami;Johanna Beyer;Hendrik Strobelt;Narayanan Kasthuri;Jeff W. Lichtman;Hanspeter Pfister;Markus Hadwiger,King Abdullah University of Science and Technology (KAUST);School of Engineering and Applied Sciences at Harvard University;School of Engineering and Applied Sciences at Harvard University;Center for Brain Science at Harvard University;Center for Brain Science at Harvard University;School of Engineering and Applied Sciences at Harvard University;King Abdullah University of Science and Technology (KAUST),,"Connectomics,Neuroscience,,Data Abstraction,Multi-Trees,Focus+Context,,,,,",,20,,
conference_external,2014,A Five-Level Design Framework for Bicluster Visualizations,10.1109/TVCG.2014.2346665,http://dx.doi.org/10.1109/TVCG.2014.2346665,1713,1722,Journals,"Analysts often need to explore and identify coordinated relationships (e.g., four people who visited the same five cities on the same set of days) within some large datasets for sensemaking. Biclusters provide a potential solution to ease this process, because each computed bicluster bundles individual relationships into coordinated sets. By understanding such computed, structural, relations within biclusters, analysts can leverage their domain knowledge and intuition to determine the importance and relevance of the extracted relationships for making hypotheses. However, due to the lack of systematic design guidelines, it is still a challenge to design effective and usable visualizations of biclusters to enhance their perceptibility and interactivity for exploring coordinated relationships. In this paper, we present a five-level design framework for bicluster visualizations, with a survey of the state-of-the-art design considerations and applications that are related or that can be applied to bicluster visualizations. We summarize pros and cons of these design options to support user tasks at each of the five-level relationships. Finally, we discuss future research challenges for bicluster visualizations and their incorporation into visual analytics tools.",,Maoyuan Sun;Chris North;Naren Ramakrishnan,"Department of Computer Science, Discovery Analytics Center, Virginia Tech;Department of Computer Science, Discovery Analytics Center, Virginia Tech;Department of Computer Science, Discovery Analytics Center, Virginia Tech",,"Biclusters,interactive visual analytics,,coordinated relationships,design framework,,,,,,",,19,,
conference_external,2014,Run Watchers: Automatic Simulation-Based Decision Support in Flood Management,10.1109/TVCG.2014.2346930,http://dx.doi.org/10.1109/TVCG.2014.2346930,1873,1882,Journals,"In this paper, we introduce a simulation-based approach to design protection plans for flood events. Existing solutions require a lot of computation time for an exhaustive search, or demand for a time-consuming expert supervision and steering. We present a faster alternative based on the automated control of multiple parallel simulation runs. Run Watchers are dedicated system components authorized to monitor simulation runs, terminate them, and start new runs originating from existing ones according to domain-specific rules. This approach allows for a more efficient traversal of the search space and overall performance improvements due to a re-use of simulated states and early termination of failed runs. In the course of search, Run Watchers generate large and complex decision trees. We visualize the entire set of decisions made by Run Watchers using interactive, clustered timelines. In addition, we present visualizations to explain the resulting response plans. Run Watchers automatically generate storyboards to convey plan details and to justify the underlying decisions, including those which leave particular buildings unprotected. We evaluate our solution with domain experts.",,Artem Konev;Jürgen Waser;Bernhard Sadransky;Daniel Cornel;Rui A.P. Perdigão;Zsolt Horváth;M. Eduard Gröller,VRVis Vienna;VRVis Vienna;VRVis Vienna;VRVis Vienna;TU Vienna;TU Vienna;TU Vienna,,"Disaster management,simulation control,,decision making,visual evidence,storytelling,,,,,",,6,,
SciVis,2014,Multiscale Symmetry Detection in Scalar Fields by Clustering Contours,10.1109/TVCG.2014.2346332,http://dx.doi.org/10.1109/TVCG.2014.2346332,2427,2436,Journals,"The complexity in visualizing volumetric data often limits the scope of direct exploration of scalar fields. Isocontour extraction is a popular method for exploring scalar fields because of its simplicity in presenting features in the data. In this paper, we present a novel representation of contours with the aim of studying the similarity relationship between the contours. The representation maps contours to points in a high-dimensional transformation-invariant descriptor space. We leverage the power of this representation to design a clustering based algorithm for detecting symmetric regions in a scalar field. Symmetry detection is a challenging problem because it demands both segmentation of the data and identification of transformation invariant segments. While the former task can be addressed using topological analysis of scalar fields, the latter requires geometry based solutions. Our approach combines the two by utilizing the contour tree for segmenting the data and the descriptor space for determining transformation invariance. We discuss two applications, query driven exploration and asymmetry visualization, that demonstrate the effectiveness of the approach.",,Dilip Mathew Thomas;Vijay Natarajan,"Department of Computer Science and Automation, Indian Institute of Science, Bangalore, India;Department of Computer Science and Automation and Supercomputer Education Research Centre, Indian Institute of Science, Bangalore, India",,"Scalar field visualization,symmetry detection,,contour tree,data exploration,,,,,,",,25,,
SciVis,2014,Visualizing 2-dimensional Manifolds with Curve Handles in 4D,10.1109/TVCG.2014.2346425,http://dx.doi.org/10.1109/TVCG.2014.2346425,2575,2584,Journals,"In this paper, we present a mathematical visualization paradigm for exploring curves embedded in 3D and surfaces in 4D mathematical world. The basic problem is that, 3D figures of 4D mathematical entities often twist, turn, and fold back on themselves, leaving important properties behind the surface sheets. We propose an interactive system to visualize the topological features of the original 4D surface by slicing its 3D figure into a series of feature diagram. A novel 4D visualization interface is designed to allow users to control 4D topological shapes via the collection of diagram handles using the established curve manipulation mechanism. Our system can support rich mathematical interaction of 4D mathematical objects which is very difficult with any existing approach. We further demonstrate the effectiveness of the proposed visualization tool using various experimental results and cases studies.",,Hui Zhang;Jianguang Weng;Guangchen Ruan,"Pervasive Technology Institute, Indiana University;Zhejiang University of Media and Communication;School of Informatics and Computing, Indiana University",,"math visualization,4D,,deformation,Reidemeister theorem,,,,,,",,4,,
SciVis,2014,Predicate-Based Focus-and-Context Visualization for 3D Ultrasound,10.1109/TVCG.2014.2346317,http://dx.doi.org/10.1109/TVCG.2014.2346317,2379,2387,Journals,"Direct volume visualization techniques offer powerful insight into volumetric medical images and are part of the clinical routine for many applications. Up to now, however, their use is mostly limited to tomographic imaging modalities such as CT or MRI. With very few exceptions, such as fetal ultrasound, classic volume rendering using one-dimensional intensity-based transfer functions fails to yield satisfying results in case of ultrasound volumes. This is particularly due its gradient-like nature, a high amount of noise and speckle, and the fact that individual tissue types are rather characterized by a similar texture than by similar intensity values. Therefore, clinicians still prefer to look at 2D slices extracted from the ultrasound volume. In this work, we present an entirely novel approach to the classification and compositing stage of the volume rendering pipeline, specifically designed for use with ultrasonic images. We introduce point predicates as a generic formulation for integrating the evaluation of not only low-level information like local intensity or gradient, but also of high-level information, such as non-local image features or even anatomical models. Thus, we can successfully filter clinically relevant from non-relevant information. In order to effectively reduce the potentially high dimensionality of the predicate configuration space, we propose the predicate histogram as an intuitive user interface. This is augmented by a scribble technique to provide a comfortable metaphor for selecting predicates of interest. Assigning importance factors to the predicates allows for focus-and-context visualization that ensures to always show important (focus) regions of the data while maintaining as much context information as possible. Our method naturally integrates into standard ray casting algorithms and yields superior results in comparison to traditional methods in terms of visualizing a specific target anatomy in ultrasound volumes.",,Christian Schulte zu Berge;Maximilian Baust;Ankur Kapoor;Nassir Navab,"Chair for Computer Aided Medical Procedures, Technische Universität, München, Germany;Chair for Computer Aided Medical Procedures, Technische Universität, München, Germany;Imaging and Computer Vision, Siemens Corporation, Corporate Technology, Princeton, NJ, USA;Chair for Computer Aided Medical Procedures, Technische Universität, München, Germany",,"Direct Volume Rendering,Ultrasound,,Classification,Predicate Function,User Interface,,,,,",,4,,
conference_external,2014,VIS Steering and Executive Committees,10.1109/TVCG.2014.2346666,http://dx.doi.org/10.1109/TVCG.2014.2346666,xix,xix,Journals,Provides a listing of current committee members and society officers.,,,,,",,,,,,,,,,",,0,,
conference_external,2014,IEEE Visualization and Graphics Technical Committee (VGTC),10.1109/TVCG.2014.2346662,http://dx.doi.org/10.1109/TVCG.2014.2346662,xv,xv,Journals,Provides a listing of current committee members and society officers.,,,,,",,,,,,,,,,",,0,,
conference_external,2014,Message from the Editor-in-Chief,10.1109/TVCG.2014.2346658,http://dx.doi.org/10.1109/TVCG.2014.2346658,x,x,Journals,"I am pleased to introduce the December 2014 issue of the IEEE Transactions on Visualization and Computer Graphics (TVCG). With mixed emotions, I am writing my last editorial for IEEE VIS and ending my tenure as the EIC of IEEE TVCG. Selected from a record high number of 480 submissions, this special issue contains 111 papers presented at the 2014 IEEE VIS, including the IEEE Conference on Visual Analytics Science and Technolgy (VAST), the IEEE Information Visualization Conference (InfoVis), and the IEEE Scientific Visualization Conference (SciVis) in Paris, France from 9-14 November 2014. These papers that were recommended for acceptance by the program committees of these three conferences, after having undergone a rigorous two-round review process, are published in this issue.",,,,,",,,,,,,,,,",,0,,
conference_external,2014,VIS International Program Committees,10.1109/TVCG.2014.2346664,http://dx.doi.org/10.1109/TVCG.2014.2346664,xvii,xviii,Journals,Provides a listing of current committee members and society officers.,,,,,",,,,,,,,,,",,0,,
conference_external,2014,VIS Conference Committee,10.1109/TVCG.2014.2346663,http://dx.doi.org/10.1109/TVCG.2014.2346663,xvi,xvi,Journals,Provides a listing of current committee members and society officers.,,,,,",,,,,,,,,,",,0,,
conference_external,2014,Message from the VIS Paper Chairs and Guest Editors,10.1109/TVCG.2014.2346661,http://dx.doi.org/10.1109/TVCG.2014.2346661,xi,xiv,Journals,"The papers in this special issue were presented at the Proceedings of IEEE VIS 2014, held during November 9-14, 2014, in Paris, France. VIS consists of three conferences, held concurrently: the IEEE Visual Analytics Science and Technology Conference (VAST 2014), the IEEE Information Visualization Conference (InfoVis 2014), and the IEEE Scientific Visualization Conference (SciVis 2014). Visualization continues to develop rapidly as a research discipline and the three conferences are maintaining their positions as the leading annual events for researchers and practitioners to share the most innovative and impactful results of an increasingly diverse and influential community.",,,,,",,,,,,,,,,",,0,,
conference_external,2014,2014 Index IEEE Transactions on Visualization and Computer Graphics Vol. 20,10.1109/TVCG.2014.2359173,http://dx.doi.org/10.1109/TVCG.2014.2359173,xxvi,xxvii,Journals,"This index covers all technical items - papers, correspondence, reviews, etc. - that appeared in this periodical during the year, and items from previous years that were commented upon or corrected in this year. Departments and other items may also be covered if they have been judged to have archival value. The Author Index contains the primary entry for each item, listed under the first author's name. The primary entry includes the co-authors' names, the title of the paper or other item, and its location, specified by the publication abbreviation, year, month, and inclusive pagination. The Subject Index contains entries describing the item under all appropriate subject headings, plus the first author's name, the publication abbreviation, month, and year, and inclusive pages. Note that the item title is found only under the primary entry in the Author Index.",,,,,",,,,,,,,,,",,0,,
conference_external,2014,The 2014 Visualization Technical Achievement Award: Claudio T. Silva,10.1109/TVCG.2014.2346672,http://dx.doi.org/10.1109/TVCG.2014.2346672,xxv,xxv,Journals,"The 2014 Visualization Technical Achievement Award goes to Claudio T. Silva, New York University Polytechnic School of Engineering, in recognition of seminal advances in geometric computing for visualization and for contributions to the development of the VisTrails data exploration system. Claudio has made seminal contributions to many areas of visualization and graphics, including point-based modeling, surface reconstruction, isosurface generation, out-of-core and streaming visualization techniques, and unstructured volume rendering. Having participated in interdisciplinary projects, his contributions have had impact in multiple scientific domains. He has also developed widely-used visualization and analysis tools, including the open-source VisTrails system. The IEEE Visualization & Graphics Technical Community (VGTC) is pleased to award Claudio T. Silva the 2014 Visualization Technical Achievement Award. A biography of the award winner is included.",,,,,",,,,,,,,,,",,0,,
conference_external,2014,VIS reviewers,10.1109/TVCG.2014.2346668,http://dx.doi.org/10.1109/TVCG.2014.2346668,xx,xxiii,Journals,The conference offers a note of thanks and lists its reviewers.,,,,,",,,,,,,,,,",,0,,
conference_external,2014,The 2014 Visualization Technical Achievement Award: Ken Joy,10.1109/TVCG.2014.2346669,http://dx.doi.org/10.1109/TVCG.2014.2346669,xxiv,xxiv,Journals,"The 2014 Visualization Technical Achievement Award goes to Ken Joy, University of California at Davis, in recognition of foundational research in the mathematical representation of data for visualization and for service to the community. The IEEE Visualization & Graphics Technical Community (VGTC) is pleased to award Ken Joy the 2014 Visualization Career Award. A biography of the award winner is included.",,,,,",,,,,,,,,,",,0,,
conference_external,2014,[Front cover],10.1109/TVCG.2014.2346976,http://dx.doi.org/10.1109/TVCG.2014.2346976,i,Bii,Journals,Presents the front cover for this issue of the publication.,,,,,",,,,,,,,,,",,0,,
conference_external,2014,Table of contents,10.1109/TVCG.2014.2346974,http://dx.doi.org/10.1109/TVCG.2014.2346974,iii,xi,Journals,Presents the table of contents for this issue of the periodical.,,,,,",,,,,,,,,,",,0,,
