Conference,Year,Title,DOI,Link,FirstPage,LastPage,PaperType,Abstract,AuthorNames-Deduped,AuthorNames,AuthorAffiliation,InternalReferences,AuthorKeywords,AminerCitationCount,CitationCount_CrossRef,PubsCited,Award
conference_external,2017,MC3 - A Web-Based Interactive Image Explorer for Temporal Analysis of Satellite Images (Honorable Mention - Good Interactive Image Explorer),10.1109/VAST.2017.8585425,https://doi.org/10.1109/VAST.2017.8585425,207,208,Conferences,"Our Web-based image analysis tool for the VAST 2017 Mini-Challenge 3 combines small multiple views of satellite images, linked semantic zooming and image intensity histograms, along with filter controls. The resulting tool allow users to interactively analyze spatio-temporal changes in the preserve area.",,Vijayraj Mahida;Bartosz Kupiec;Andrew Burks;Timothy Luciani;G.Elisabeta Marai,"Electronic Visualization Laboratory, University of Illinois at Chicago;Electronic Visualization Laboratory, University of Illinois at Chicago;Electronic Visualization Laboratory, University of Illinois at Chicago;Electronic Visualization Laboratory, University of Illinois at Chicago;Electronic Visualization Laboratory, University of Illinois at Chicago",,",,,,,,,,",,1,,
conference_external,2017,iDVL Visualizes Patterns of Traffic,10.1109/VAST.2017.8585709,https://doi.org/10.1109/VAST.2017.8585709,213,214,Conferences,"Presenting patterns of life with novel visualizations and reasoning cause of reduction of local birds via hypotheses are interested for Vast Challenge. Linked views, quick navigation buttons and choice of visualizations contributed to creating ways for ornithologist better finding normal and abnormal patterns of vehicles that may result in bird reduction.",,Long Nguyen;Tommy Dang,Texas Tech University;Texas Tech University,,"H.1.2 [Models and Principles]: User/Machine Systems—Human information processing,H.5.2 [Information Systems]: Information Interfaces and Presentation—User Interfaces,,,,,,,",,0,,
conference_external,2017,VAST Mini-Challenge 1,10.1109/VAST.2017.8585677,https://doi.org/10.1109/VAST.2017.8585677,221,222,Conferences,"We propose an interactive visual analytics system for exploring spatio-temporal data in VAST 2017 Mini-Challenge-1. As part of this challenge, we are expected to determine repeating, seasonal and unusual cars' movements in Lekagul park dataset. We use varied visualizations such as heatmap, sequential sunburst and line plots. Further, we have developed a web deployable ad-hoc system for displaying spatio-temporal information on geographical map.",,Ayushi Gupta;Veera Raghavendra Chikka;Kamalakar Karlapalem,"International Institute of Information and Technology Hyderabad, India;International Institute of Information and Technology Hyderabad, India;International Institute of Information and Technology Hyderabad, India",,",,,,,,,,",,0,,
conference_external,2017,Interactive and Collaborative Visual Analysis on Traffic Sensor Data,10.1109/VAST.2017.8585432,https://doi.org/10.1109/VAST.2017.8585432,187,188,Conferences,"In VAST Challenge 2017, we propose an interactive and collaborative visual analytic system for the analysis of traffic sensor data. Our system fully incorporates the power of spatial-temporal visualization, sequence mining techniques and collaborative analysis. It allows users to conduct multi-facet and interactive data analysis in a highly efficient way. We discuss technical details in this report, and demonstrate the effectiveness of our system via convincing cases.",,Chufan Lai;Qiangqiang Liu;Lu Feng;Chenglei Yue;Xi Chen;Yang Hu;Zhanyi Wang;Pengju Teng;Xiaoru Yuan,"Key Laboratory of Machine Perception (Ministry of Education), and School of EECS, Peking University;Key Laboratory of Machine Perception (Ministry of Education), and School of EECS, Peking University;Key Laboratory of Machine Perception (Ministry of Education), and School of EECS, Peking University;Key Laboratory of Machine Perception (Ministry of Education), and School of EECS, Peking University;Key Laboratory of Machine Perception (Ministry of Education), and School of EECS, Peking University;Key Laboratory of Machine Perception (Ministry of Education), and School of EECS, Peking University;Qihoo 360 Enterprise Security Group;Qihoo 360 Enterprise Security Group;Beijing Engineering Technology Research Center of Virtual Simulation and Visualization, Peking University",,",,,,,,,,",,0,,
conference_external,2017,Visual Analysis to Explore Mystery at Wildlife Preserve,10.1109/VAST.2017.8585648,https://doi.org/10.1109/VAST.2017.8585648,211,212,Conferences,"We conducted visual analytics to find out possible reasons of the decreasing of Rose-Crested Blue Pipit, a popular local bird in a wildlife Preserve at Midford. Given two large scale and multidimensional datasets on chemical release and meteorological information, we utilized Tableau visualization toolset to reveal the patterns of monitor observation and chemical release. Additionally, we developed a prediction method to connect the wind direction with the chemical release, which eventually suggests the release origins from surrounding manufactories.",,Bo Sun;Rumeel Jessamy;Sungsoo Ha;Wei Xu,Rowan University;Lincoln University;Brookhaven National Lab;Brookhaven National Lab,,"Visualization,Visual Analytics,Tableau,,,,,,",,0,,
conference_external,2017,"PreserVis, a Visual Analytic System for Traffic and Pollution Patterns - Multi-Challenge Award for Compelling Synthesis of Information",10.1109/VAST.2017.8585719,https://doi.org/10.1109/VAST.2017.8585719,183,184,Conferences,"In this report, we propose PreserVis, a data visualization system for inspecting the pattern of the transportation and pollutant release in Boonsong Lekagul Nature Preserve in VAST Challenge 2017. Intuitive clustering and novel visualization methods are used to discover the patterns hidden in the datasets.",,Qiao GU;Hang YIN;Lian CHEN;Haotian LI;Chengzhong LIU;Xuanwu YUE;Huamin QU,The Hong Kong University of Science and Technology;The Hong Kong University of Science and Technology;The Hong Kong University of Science and Technology;The Hong Kong University of Science and Technology;The Hong Kong University of Science and Technology;The Hong Kong University of Science and Technology;The Hong Kong University of Science and Technology,,"PreserVis,VAST Challenge,data visualization,,,,,,",,0,,
conference_external,2017,Visualizing chemicals detection VAST 2017 Mini Challenge 2,10.1109/VAST.2017.8585723,https://doi.org/10.1109/VAST.2017.8585723,241,242,Conferences,"Analysis of sensor data is currently a popular topic in visual analytics, as visual representations can efficiently uncover insights in huge and noisy datasets.",,Jiaqi Zhang;Xintian Liu;Hongjun Qian;Tin Seong Kam,"School of Information Systems, Singapore Management University;School of Information Systems, Singapore Management University;School of Information Systems, Singapore Management University;School of Information Systems, Singapore Management University",,",,,,,,,,",,0,,
conference_external,2017,Visual Integration of Meteorological and Sensor Data for Identifying Suspicious Company Behavior,10.1109/VAST.2017.8585436,https://doi.org/10.1109/VAST.2017.8585436,225,226,Conferences,"We present an approach developed in course of the VAST 2017 Mini-Challenge 2. To help the ornithologist Mitch to investigate the noxious gases emitted by the four companies south of the nature preserve, we employ a combination of interactive visualizations that allow for an exploration of the data. In this paper, we present our visual-interactive approach for analyzing suspicious patterns in the data. By taking the wind data into consideration, as well, our approach allows the retrieval of patterns in the chemical releases and identify key polluters.",,Daniel Seebacher;Bruno Schneider;Michael Behrisch,University of Konstanz;University of Konstanz;Harvard University,,",,,,,,,,",,0,,
conference_external,2017,MC2 — Spatio-Temporal Provenance Data Aggregation for Visual Analysis,10.1109/VAST.2017.8585615,https://doi.org/10.1109/VAST.2017.8585615,229,230,Conferences,"We describe our approach to the analysis of 2017 VAST Challenge Mini-Challenge 2 data. The challenge deals with readings from air sampler stations. To answer the main question, the provenance of the chemicals measured at the sampler stations, we extend the provided data set by aggregated spatio-temporal provenance data. This data is generated from the provided meteorological data and locations map by using it as input for a particle tracer which calculates the provenance of the particles arriving from the emitters (factories) at the collectors (the locations of sampler stations). We use ComVis [3], a coordinated multiple views (CMV) system, to analyze the whole data set (the provided and generated data) by applying a sensor centric data model.",,Rainer Splechtna;Silvana Podaras;Michael Beham;Denis Gračanin;Krešimir Matković,"VRVis Research Center, Vienna, Austria;VRVis Research Center, Vienna, Austria;VRVis Research Center, Vienna, Austria;Virginia Tech, Blacksburg, VA, USA;VRVis Research Center, Vienna, Austria",,"I.3.8 [Computing Methodologies]: Computer Graphics—Applications,,,,,,,,",,0,,
conference_external,2017,Temporal and Spatial Analysis of VAST 2017’s Mini-Challenge 1,10.1109/VAST.2017.8585475,https://doi.org/10.1109/VAST.2017.8585475,215,216,Conferences,"This paper summarizes the approach and tools used by our team to analyze the dataset for Mini-Challenge 1 of the 2017 VAST Challenge. The goal of the mini-challenge was to find patterns of traffic activity within the park that may be associated with declining numbers of nesting bird pairs. We developed a custom, web-based application using Python and JavaScript to visualize and analyze the data to solve the mini-challenge.",,Chris Muller;Kevin McGurgan;Stephanie Kane,Charles River Analytics;Charles River Analytics;Charles River Analytics,,",,,,,,,,",,0,,
conference_external,2017,MC1 --- Iterative Analysis of Spatio-temporal Data by Textual Queries and Visualizations,10.1109/VAST.2017.8585513,https://doi.org/10.1109/VAST.2017.8585513,227,228,Conferences,"Visualizing monitored traffic over a long period of time is a difficult problem. The trajectories of many traffic participants have to be taken into account to find regular patterns and unusual behavior. We introduce a novel system for visual analysis of spatio-temporal tracking data. This system, developed as response to VAST 2017 Mini-Challenge 1, enables iterative analysis steps by combining textual queries and linking and brushing interactive visualizations in ComVis tool.",,Michael Beham;Silvana Podaras;Rainer Splechtna;Denis GraČanin;Krešimir Matković,"VRVis Research Center, Vienna, Austria;VRVis Research Center, Vienna, Austria;VRVis Research Center, Vienna, Austria;Virginia Tech, Blacksburg, VA, USA;VRVis Research Center, Vienna, Austria",,"Information Search and Retrieval,,,,,,,,",,0,,
conference_external,2017,VIS Keynote Address: Analytics Inspired Visualization: a Holistic In-situ Scientific Workflow at Extreme Scale,10.1109/VAST.2017.8585481,https://doi.org/10.1109/VAST.2017.8585481,1,1,Conferences,"Summary form only given, as follows. The complete presentation was not made available for publication as part of the conference proceedings. Combustion and turbulence simulations involve highly intermittent localized phenomena that generate high volumes of spatially and temporally varying field and particle data. The current paradigm of posthoc analysis and visualization will become increasingly infeasible as data volumes continue to increase. In the exascale era this problem will be further exacerbated by the difficulty of moving large volumes of data through deep complex memory hierarchies and across the machine network to hard disks on a heterogeneous supercomputer. I will discuss recent advances in in situ massively parallel volume and particle visualization algorithms coupled with analytics - e.g., topological feature segmentation/tracking, distance field construction, multi-variate statistics and eigensolutions of the reaction rate Jacobian - as an integral part of a scientific discovery from high-fidelity combustion simulations. The role of asynchronous task based programming models and runtimes to facilitate an extensible, performance portable computational science workflow at extreme scale will also be discussed in the context of recent turbulent ignition simulations.",,Jacqueline H. Chen,Sandia National Laboratories,,",,,,,,,,",,0,,
conference_external,2017,Temporal Pattern Analysis and Source Detection through Visual Analysis on Multi-Dimensional Time Series Data,10.1109/VAST.2017.8585548,https://doi.org/10.1109/VAST.2017.8585548,189,190,Conferences,"In VAST Challenge 2017, we developed a visual exploration system for detection of sensor anomaly, pattern of chemical distribution and responsible factory for each release of chemical. In this report, we discuss details of our data preprocessing, design, implementation and how we found our answer.",,Ruike Jiang;Wei Huang;Nan Ma;Fan Hong;Ying Zhao;Xiaoru Yuan,"Key Laboratory of Machine Perception (Ministry of Education), and School of EECS, Peking University;QIHOO 360;Key Laboratory of Machine Perception (Ministry of Education), and School of EECS, Peking University;Key Laboratory of Machine Perception (Ministry of Education), and School of EECS, Peking University;School of Information Science and Engineering, Central South University;Beijing Engineering Technology Research Center of Virtual Simulation and Visualization, Peking University",,",,,,,,,,",,0,,
conference_external,2017,Visual Analysis for Wildlife Preserve based on Muti-systems,10.1109/VAST.2017.8585552,https://doi.org/10.1109/VAST.2017.8585552,247,248,Conferences,"In the Grand Challenge of IEEE VAST Challenge 2017, we explore the systems in each mini-challenge, and combine the discoveries logically to provide a comprehensive story happened in the wildlife preserve. In this report, we present technical details for the systems, in order to discuss how to discover the events, and how to combine them to construct an overall picture considering the additional information, newsletter, in the Grand Challenge.",,Lijing Lin;Min Lu;Guozheng Li;Shuai Chen;Chufan Lai;Ruike Jiang;Qiangqiang Liu;Xiaoru Yuan,"Key Laboratory of Machine Perception (Ministry of Education), and School of EECS, Peking University;Key Laboratory of Machine Perception (Ministry of Education), and School of EECS, Peking University;Key Laboratory of Machine Perception (Ministry of Education), and School of EECS, Peking University;Key Laboratory of Machine Perception (Ministry of Education), and School of EECS, Peking University, Beijing, Beijing, CN;Key Laboratory of Machine Perception (Ministry of Education), and School of EECS, Peking University;Key Laboratory of Machine Perception (Ministry of Education), and School of EECS, Peking University;Key Laboratory of Machine Perception (Ministry of Education), and School of EECS, Peking University;Beijing Engineering Technology Research Center of Virtual Simulation and Visualization, Peking University",,",,,,,,,,",,0,,
conference_external,2017,"Exploring Lekagul Sensor Events using Rules, Aggregations, and Selections",10.1109/VAST.2017.8585619,https://doi.org/10.1109/VAST.2017.8585619,193,194,Conferences,"In this paper we demonstrate how we can study multivariate event sequences in the VAST Mini Challenge 1 data set using our system Eventpad, a notepad editor for event data. We illustrate the effectiveness of multivariate regular expressions, pattern aggregations, and selections to define custom events of interest, discover patterns within sequences, and study differences between sequences. Finally, we discuss our analysis process and summarize some patterns and anomalies we discovered in the data set.",,Bram C.M. Cappers,Eindhoven University of Technology,,"Event Visualization,Multivariate Events,Regular Expressions,Sequence Alignment,Interaction,,,,",,0,,
conference_external,2017,Visual Statistical Analysis of Environmental Sensor Data,10.1109/VAST.2017.8585515,https://doi.org/10.1109/VAST.2017.8585515,245,246,Conferences,We attempted the VAST MC2 challenge following a statistical modelling approach along with interactive visualizations to analyse and extract insights from the data. We use Bayesian networks to model dependencies between given and derived data attributes along with visual analytics techniques to answer the questions posed by the challenge.,,Bindu Gupta;Kaushal Paneri;Gunjan Sehgal;Karamjit Singh;Geetika Sharma;Gautam Shroff,"Tata Consultancy Services Research, Gurugram, India;Tata Consultancy Services Research, Gurugram, India;Tata Consultancy Services Research, Gurugram, India;Tata Consultancy Services Research, Gurugram, India;Tata Consultancy Services Research, Gurugram, India;Tata Consultancy Services Research, Gurugram, India",,",,,,,,,,",,0,,
conference_external,2017,Interactive Visual Analysis of Traffic Patterns: Ecological Impact within a Nature Preserve (VAST Challenge 2017),10.1109/VAST.2017.8585729,https://doi.org/10.1109/VAST.2017.8585729,237,238,Conferences,"As part of the Visual Analytics Science and Technology Challenge 2017, teams were tasked to hypothesize whether or not the traffic within the Boonsong Lekagul Nature Preserve is affecting the nesting Rose-Crested Blue Pipit. With exploratory data analysis, variable generation, and visual analytic techniques, our team worked to uncover patterns within the preserve. Potentially harmful park activity was uncovered through our analysis.",,Allison Montroy;Tyler Witter;Christopher Banas;Walter Bennette,AFRL RIEA;AFRL RIEA;AFRL RIEA;AFRL RIEA,,"visual analysis,interactive,traffic patterns,pattern of life,,,,,",,0,,
conference_external,2017,WindNebula: Vectorial-Temporal Analysis for Environmental Assessment : VAST Challenge MC2 Award: Multi-challenge Award for Aesthetic Design,10.1109/VAST.2017.8585631,https://doi.org/10.1109/VAST.2017.8585631,181,182,Conferences,"WindNebula joins two datasets, sensor data and meteorological data, to combine wind directions with sensor readings to reveal implicit relations among locations of factories and sensors, pollution intensity, wind direction, and sensor problems. The two major views, vectorial view and temporal view, blend key information of different variables from the IEEE VAST 2017 Mini Challenge 2 dataset. This paper introduces the composition of the WindNebula system, exhibits the components of both views, and discusses the benefits of using this system to gain insights of the dataset.",,Hui Tang;Wenjie Wu;Zheng Zhou;Sijin Wang;Aijun Huang;Yafeng Niu;Yingjie Victor Chen;Zhenyu Cheryl Qian,"Department of Computer Graphics Technology, Purdue University, West Lafayette, Indiana, USA;Department of Computer Graphics Technology, Purdue University, West Lafayette, Indiana, USA;Department of Computer Graphics Technology, Purdue University, West Lafayette, Indiana, USA;Department of Computer Graphics Technology, Purdue University, West Lafayette, Indiana, USA;Department of Industrial and Interaction Design, Purdue University, West Lafayette, Indiana, USA;Schoool of Mechanical Engineering, Southeast University, China;Department of Computer Graphics Technology, Purdue University, West Lafayette, Indiana, USA;Department of Industrial and Interaction Design, Purdue University, West Lafayette, Indiana, USA",,"[Human-centered computing]-Visual analytics,Information visualization,User interface design,[Information systems]-Spatial-temporal systems,,,,,",,0,,
conference_external,2017,MC2 - Mining Factory Pollution Data through a Spatial-Nonspatial Flow Approach (Honorable Mention for Clarity in Visual Communication),10.1109/VAST.2017.8585491,https://doi.org/10.1109/VAST.2017.8585491,203,204,Conferences,"Mini Challenge 2 of the VAST Challenge 2017 focused on a small industrial area south of the fictional Mistford preserve, specifically around four manufacturing factories. Our main goal was to develop a visual analytics tool to explore the spatio-temporal chemical readings and wind data. Specifically, we wanted to determine which factories were responsible for emitting which chemicals and to determine the performance of the nine sensors in the area. In order to help achieve this goal, we developed a web-based application that utilizes interactive visualizations and path line analysis for revealing sensor errors and chemical reading spikes, along with pinpointing the possible sources of chemical reading spikes.",,Joshua Castor;Joseph Borowicz;Andrew Burks;Manu Thomas;Timothy Luciani;G. Elisabeta Marai,"Electronic Visualization Laboratory, University of Illinois at Chicago;Electronic Visualization Laboratory, University of Illinois at Chicago;Electronic Visualization Laboratory, University of Illinois at Chicago;Electronic Visualization Laboratory, University of Illinois at Chicago;Electronic Visualization Laboratory, University of Illinois at Chicago;Electronic Visualization Laboratory, University of Illinois at Chicago",,",,,,,,,,",,0,,
conference_external,2017,Spatiotemporal identification of anomalies in a wildlife preserve VAST Grand Challenge 2017 Award: Clear Presentation of Hypotheses and Supporting Evidence,10.1109/VAST.2017.8585493,https://doi.org/10.1109/VAST.2017.8585493,185,186,Conferences,"The datasets released for the VAST Challenge 2017 comprise vehicle movement data captured with RFID sensors, chemical emission data from factories captured by gas sensors, and image attributes of the wildlife plant health obtained from satellites, all pertaining to a fictional wildlife preserve. Using visual analytics, a compelling hypothesis is established to link the spatiotemporal datasets to the phenomenon, where the count of a bird specimen is found to decline over a given year. Anomalies in vehicle traffic patterns are linked to proximal factory emissions, and further associated with satellite imagery that show proof of degradation in plant quality in the preserve. The evidences are supported with visualizations created in Tableau, R, QGIS & SAS-JMP. Raster image analysis is also done to identify other key features in the preserve, such as the existence of a lake. This is achieved by using NDVI and NDMI measures, which also help understand the change in climate over the years.",,Bharadwaj S Kishan;Ong Guan Jie Jason;Zhang Yanrong;Kam Tin Seong,Singapore Management University;Singapore Management University;Singapore Management University;Singapore Management University,,"Spatiotemporal analysis,Geo-spatial analytics,Visual analytics,Traffic pattern detection,Raster image processing,NDVI,,,",,0,,
conference_external,2017,Multilab: Multispectral image analysis in Matlab,10.1109/VAST.2017.8585672,https://doi.org/10.1109/VAST.2017.8585672,223,224,Conferences,"In this paper we describe our approach to the VAST Challenge Mini Challenge 3 which provided time-series multispectral image for visualization and analysis. We used Matlab for rapid prototyping, interface design and implementation of the final software. The resulting application, Multilab, allowed us to interactively explore the collection of multispectral images, generate and test hypotheses, and answer quantitative questions about the images.",,Tim McGraw;Aijun Huang;Sijin Wang,Purdue University;Purdue University;Purdue University,,"I.4.9 [Computing Methodologies]: Image Processing and Computer Vision—Applications,D.2.2 [Software]: Software Engineering–Design Tools and Techniques,,,,,,,",,0,,
conference_external,2017,Interactive Visual Analytics Application for Spatiotemporal Movement Data VAST Challenge 2017 Mini-Challenge 1: Award for Actionable and Detailed Analysis,10.1109/VAST.2017.8585564,https://doi.org/10.1109/VAST.2017.8585564,195,196,Conferences,"The Visual Analytics Science and Technology (VAST) Challenge 2017 Mini-Challenge 1 dataset mirrored the challenging scenarios in analysing large spatiotemporal movement tracking datasets. The datasets provided contains a 13-month movement data generated by five types of sensors, for six types of vehicles passing through the Boonsong Lekagul Nature Preserve. We present an application developed with the market leading visualisation software Tableau to provide an interactive visual analysis of the multi-dimensional spatiotemporal datasets. Our interactive application allows the user to perform an interactive analysis to observe movement patterns, study vehicle trajectories and identify movement anomalies while allowing them to customise the preferred visualisation configurations.",,Guan Yifei;Kam Tin Seong,Singapore Management University;Singapore Management University,,"Spatiotemporal visualisation,Movement Analysis,User interaction,Tableau,,,,,",,0,,
conference_external,2017,Visual Analysis for Multi-Spectral Images Comparisons,10.1109/VAST.2017.8585456,https://doi.org/10.1109/VAST.2017.8585456,191,192,Conferences,"The analysis for images helps people to gain insights by extracting the inner features and variances between them. However, it is hard to analyze the underlying events further without users participation. We proposes a visual analytic system based on collaborative tagging techniques to allow users to identify features and changes from multi-spectral images. We evaluate our system with mini challenge 3 of VAST Challenge 2017. The exploration results validate the efficiency and effectiveness of our system.",,Guozheng Li;Shuai Chen;Qiusheng Li;Zhibang Jiang;Yuening Shi;Qiangqiang Liu;Xi Liu;Xiaoru Yuan,"Key Laboratory of Machine Perception (Ministry of Education), and School of EECS, Peking University;Key Laboratory of Machine Perception (Ministry of Education), and School of EECS, Peking University;Qihoo 360 Technology Co. Ltd.;Key Laboratory of Machine Perception (Ministry of Education), and School of EECS, Peking University;Key Laboratory of Machine Perception (Ministry of Education), and School of EECS, Peking University;Key Laboratory of Machine Perception (Ministry of Education), and School of EECS, Peking University;Qihoo 360 Technology Co. Ltd.;Key Laboratory of Machine Perception (Ministry of Education), and School of EECS, Peking University",,",,,,,,,,",,0,,
conference_external,2017,A Visual Explorer for Analyzing Trajectory Patterns,10.1109/VAST.2017.8585462,https://doi.org/10.1109/VAST.2017.8585462,199,200,Conferences,"In this paper, we propose a web-based interactive visual analytic system effective for revealing the trajectory patterns. We describe the analysis approach with the data of MC1 of the VAST challenge 2017.",,Wooil Kim;Changbeom Shim;Ilhyun Suh;Yon Dohn Chung,Korea University;Korea University;Korea University;Korea University,,"Visual analytics,Information visualization,,,,,,,",,0,,
conference_external,2017,Data Aggregation and Visualization Technique for Traffic Sensor Data,10.1109/VAST.2017.8585568,https://doi.org/10.1109/VAST.2017.8585568,239,240,Conferences,"A wealth of information is captured by traffic sensors but extracting and representing the said information is a challenge. We developed a data processing tool in Apache Spark to aggregate the data points recorded by the sensors and enrich it with geographical information as well. We also developed a tool in Processing to aid the visual analysis of this data set. It plots the paths identified in the transformed data as a subway map, while still preserving the relative locations of each sensor. The transformed data is also suitable for further analysis using existing tools such as Tableau. We use all three of these tools in conjunction to solve the VAST challenge 2017 - mini challenge 1.",,Anwesh Tuladhar;Sulav Malla;Ghulam Jilani Quadri;Paul Rosen,Department of Computer Science and Engineering;Department of Computer Science and Engineering;Department of Computer Science and Engineering;Department of Computer Science and Engineering,,",,,,,,,,",,0,,
conference_external,2017,SIZE: Satellite Image Zooming and Exploration,10.1109/VAST.2017.8585639,https://doi.org/10.1109/VAST.2017.8585639,219,220,Conferences,"The VAST Challenge 2017 presents the case of the ornithologist Mitch, who wants to understand the vanishing of the Rose-crested Blue Pipit in the Boonsong Lekagul Nature preserve. To help the ornithologist to answer the challenge questions, we propose the Satellite Image Zooming and Exploration (SIZE) application that implements a framework to interactively zoom and explore satellite images of the preserve area provided by the VAST Mini Challenge 3. SIZE enables the experts to generate hypothesis through zooming and exploration, which he can further verify using different satellite images and Tableau. Two major hypothesis to help Mitch solving the poor development of the bird species are developed. One being the destruction of the habitat of the birds and the other being a heavy pollution of a lake in the preserve area.",,Udo Schlegel;Alexandra Diehl;Daniel A. Keim,University of Konstanz;University of Konstanz;University of Konstanz,,"VAST Challenge 2017,Mini Challenge 3,Visual Analytics,,,,,,",,0,,
conference_external,2017,Visual Analytic Design for Characterizing Air-Sampling Sensor Performance and Operation,10.1109/VAST.2017.8585678,https://doi.org/10.1109/VAST.2017.8585678,217,218,Conferences,"Analysis and exploration of similar continuous data for various air-sampler sensor have been performed by developing a processing tool. The analysis and design for characterizing sensor data have been stated and described. Continuous 24X7 sensor data and metrological data leads the layout choices for the analytical design. Such design choices are helpful to understand the pattern of similar reading for various devices at a time. In this paper, we describe the use of the mentioned design choices for to identify pattern, unusual behavior. We used this tool and design choice to solve VAST 2017 mini challenge 2.",,Ghulam Jilani Quadri;Anwesh Tuladhar;Sulav Malla;Paul Rosen,"Department of Computer Engineering, University of South Florida, Tampa, FL;Department of Computer Engineering, University of South Florida, Tampa, FL;Department of Computer Engineering, University of South Florida, Tampa, FL;Department of Computer Engineering, University of South Florida, Tampa, FL",,"Air-sampler,vector dot-product,multi-label data,multi-variate data,,,,,",,0,,
conference_external,2017,ODIX: A Rapid Hypotheses Testing System for Origin-Destination Data IEEE VAST Challenge Award for Excellence in Spatio-temporal Graph Analytics,10.1109/VAST.2017.8585686,https://doi.org/10.1109/VAST.2017.8585686,197,198,Conferences,"In this paper, we present our solution to the VAST Challenge 2017 Mini Challenge 1. We discuss challenges posed by data set and tasks and introduce ODIX, a custom rapid hypotheses testing system tailored to origin-destination data as provided by the challenge. We show findings made with ODIX and illustrate how we apply sequential pattern mining to explore common traffic patterns.",,Juri Buchmüller;Wolfgang Jentner;Dirk Streeb;Daniel A. Keim,Universität Konstanz;Universität Konstanz;Universität Konstanz;Universität Konstanz,,"H.4.0 [Information Systems],Information Systems Applications—General,,,,,,,",,0,,
conference_external,2017,GC --- Holistic Analysis of Heterogeneous Datasets,10.1109/VAST.2017.8585435,https://doi.org/10.1109/VAST.2017.8585435,233,234,Conferences,"The 2017 VAST Challenge is set in a fictional natural preserve surrounded by a small industrial area with four companies and a mid-size city. In this area, the population of a local bird, the Rose-Crested Blue Pipit, is decreasing. The task of the Grand Challenge was to combine findings of the three Mini-Challenges and additional textual data and build a hypothesis about what (and who) could impact the birds population.",,Silvana Podaras;Michael Beham;Rainer Splechtna;Denis Gračanin;Krešimir Matković,"VRVis Research Center, Vienna, Austria;VRVis Research Center, Vienna, Austria;VRVis Research Center, Vienna, Austria;Virginia Tech, Blacksburg, VA, USA;VRVis Research Center, Vienna, Austria",,"Computer Graphics,Scene Analysis,,,,,,,",,0,,
conference_external,2017,ClockPetals: Interactive Sequential Analysis of Traffic Patterns VAST Challenge MC1 Award: Multi-Challenge Award for Aesthetic Design,10.1109/VAST.2017.8585620,https://doi.org/10.1109/VAST.2017.8585620,179,180,Conferences,"The visual analytics system ClockPetals aims to reveal the spatio-temporal and sequential patterns of a large traffic record dataset. The system features appealing interactive web graphics that fast illustrate traffic patterns and allow users to locate unusual, anomalous traffic events from multiple demographical and temporal dimensions. ClockPetals also provides the interactive exploration of different vehicle batches via common sequential characteristic clustering. This paper presents the system's architecture and the benefits of its adoption.",,Zheng Zhou;Sijin Wang;Wenjie Wu;Aijun Huang;Yafeng Niu;Hui Tang;Yingjie Victor Chen;Zhenyu Cheryl Qian,"Department of Computer Graphics Technology, Purdue University, West Lafayette, IN;Department of Computer Graphics Technology, Purdue University, West Lafayette, IN;Department of Computer Graphics Technology, Purdue University, West Lafayette, IN;Department of Industrial and Interaction Design, Purdue University, West Lafayette, IN, USA;Schoool of Mechanical Engineering, Southeast University, China;Department of Computer Graphics Technology, Purdue University, West Lafayette, IN;Department of Computer Graphics Technology, Purdue University, West Lafayette, IN;Department of Industrial and Interaction Design, Purdue University, West Lafayette, IN, USA",,"[Human-centered computing]—Visual analytics, Information visualization, User interface design,[Information systems]—Spatial-temporal systems,,,,,,,",,0,,
conference_external,2017,MC3 — Modified Frame Differencing of Satellite Images to Detect Temporal Changes in a Natural Preserve,10.1109/VAST.2017.8585476,https://doi.org/10.1109/VAST.2017.8585476,231,232,Conferences,"Multi spectral imaging from a satellite enables to analyze the health of an natural environment over time. However, low resolution of the satellite images, and a lack of information of human activity and geological information makes it difficult to find and understand all temporal changes. We present an approach to analyze the change over time using satellite images of a natural preserve. We create a map, which contains all changes between two time steps, by using frame differencing. We then exclude uninteresting natural phenomena like clouds. The resulting map is than used to find all changes. Each of the changes is then analyzed in detail by using state of the art algorithm like false-colored images and ratio transformations.",,Michael Beham;Rainer Splechtna;Silvana Podaras;Denis Gračanin;Krešimir Matković,"VRVis Research Center, Vienna, Austria;VRVis Research Center, Vienna, Austria;VRVis Research Center, Vienna, Austria;Virginia Tech, Blacksburg, VA, USA;VRVis Research Center, Vienna, Austria",,"I.3.8 [Computing Methodologies]: Computer Graphics—Applications,I.4.8 [Image Processing and Computer Vision]: Scene Analysis—Time-varying imagery,,,,,,,",,0,,
conference_external,2017,Multi-Spectral Satellite Image Analysis for Feature Identification and Change Detection VAST Challenge 2017: Honorable Mention for Good Facilitation of Single Image Analysis,10.1109/VAST.2017.8585482,https://doi.org/10.1109/VAST.2017.8585482,205,206,Conferences,"Satellite images are helpful in remote sensing of land features. However, such multi-spectral images cannot be displayed using readily available imaging tools. We developed a tool in Processing that is able to read in multi-spectral images and display each band as a grayscale image. This tool also allows for mapping of any of the bands to red, green or blue channel of the displayed image. In this paper, we describe how such tool can be used in identifying land features as well as assist in finding changes over time. We used our tool to successfully solve the VAST challenge 2017 mini-challenge 3.",,Sulav Malla;Anwesh Tuladhar;Ghulam Jilani Quadri;Paul Rosen,"Department of Computer Science and Engineering, University of South Florida, Tampa, Florida;Department of Computer Science and Engineering, University of South Florida, Tampa, Florida;Department of Computer Science and Engineering, University of South Florida, Tampa, Florida;Department of Computer Science and Engineering, University of South Florida, Tampa, Florida",,"H.5.2 [Information Interfaces and Presentation]: User Interfaces—,Graphical User Interfaces (GUI),H.1.2 [Models and Principles]: User/Machine Systems—,Visual Analytics,,,,,",,0,,
conference_external,2017,Uncovering the Mistford Toxic Conspiracy,10.1109/VAST.2017.8585661,https://doi.org/10.1109/VAST.2017.8585661,243,244,Conferences,"To help ornithologist Mitch in understanding the poor development of the Rose-crested Blue Pipit in terms of the VAST Challenge 2017 Grand Challenge, we apply a diverse set of custom specialized tools and out-of-the-box data analysis systems to a rich data set consisting of satellite images, gas sensor measurements, movement traces and newsletter issues. Following the Visual Analytics approach, we implement a collaborative analysis loop and are able to combine data and gain insights into the current situation of the Boonsong Lekagul Nature Preserve. Finally, we come up with a hypothesis that combines suspect observations to a coherent story of illegal disposal of toxic waste involving two companies located in the reserve's vicinity.",,Dirk Streeb;Juri Buchmuller;Udo Schlegel;Wolfgang Jentner;Michael Behrisch;Bruno Schneider;Daniel Seebacher,Universität Konstanz;Universität Konstanz;Universität Konstanz;Universität Konstanz;Harvard University;Universität Konstanz;Universität Konstanz,,",,,,,,,,",,0,,
conference_external,2017,MC1: A Bespoke Analysis Tool for Spatio-temporal Park Traffic Data,10.1109/VAST.2017.8585624,https://doi.org/10.1109/VAST.2017.8585624,235,236,Conferences,"This paper describes a web-based traffic data analysis tool developed for the VAST 2017 Mini Challenge 1. The tool consists of two linked heat maps which allow for the inspection of daily activity for vehicles, as well as a histogram which allows for the analysis of total time spent by vehicles in the park. Combined, these views allow for the analysis of both spatial and temporal patterns in the park preserve.",,Dimitar Kirilov;Isabel Lindmae;Andrew Burks;Chihua Ma;G. Elisabeta Marai,"Electronic Visualization Laboratory, University of Illinois at Chicago;Electronic Visualization Laboratory, University of Illinois at Chicago;Electronic Visualization Laboratory, University of Illinois at Chicago;Electronic Visualization Laboratory, University of Illinois at Chicago;Electronic Visualization Laboratory, University of Illinois at Chicago",,",,,,,,,,",,0,,
conference_external,2017,Visual Analytic Design for Detecting Airborne Pollution Sources VAST Challenge 2017 Award: Comprehensive Mini-Challenge 2 Answer,10.1109/VAST.2017.8585588,https://doi.org/10.1109/VAST.2017.8585588,201,202,Conferences,"Using the VAST Challenge 2017 dataset as illustration, the design choices of a visual analytic system for predicting the source of air pollution is described. Probabilistic Source Cones are visual symbols representing the probability of source direction of a pollution event. Using transparency to indicate probability, multiple cones may be overlaid in order to provide a fuzzy triangulation of likely sources. This enabled the correct prediction and elimination of pollution sources at a precision far in excess of the spatial density of the sensors themselves.",,Jo Wood,"giCentre (http://gicentre.org), City, University of London",,",,,,,,,,",,0,,
conference_external,2017,Detecting Vehicular Patterns Using a Graph-Based Approach,10.1109/VAST.2017.8585667,https://doi.org/10.1109/VAST.2017.8585667,209,210,Conferences,"In the VAST 2017 competition, one of the challenges is to discover vehicular traffic patterns for understanding the reasons behind a decrease in the number of nesting pairs of Rose-Crested Blue Pipit. In this work, we present a graph-based approach that analyzes the data for structural patterns in the data. Our approach first reports the normative patterns in the data, and then discovers any anomalous patterns associated with the previously discovered patterns.",,Sirisha Velampalli;Lenin Mookiah;William Eberle,Jawaharlal Nehru Technological University;Tennessee Tech University;Tennessee Tech University,,"knowledge,graph-based knowledge discovery,graph based anomaly detection,,,,,,",,0,,
conference_external,2017,VAST Challenge 2017: Mini-challenge 1,10.1109/VAST.2017.8585461,https://doi.org/10.1109/VAST.2017.8585461,249,250,Conferences,"In this paper, we addressed the mini-challenge I. To efficiently identify odd behaviors and general patterns, visual analytics was used to parse trajectory data of vehicles and support spatial analyses. Firstly, the adjacent relations among spatial objects were extracted and then simplified as a topological graph. Base on the topological representation, cluster methods and spatio-temporal visualization were utilized to conduct a comprehensive analysis. Through visual analytics on the topological graph, we found general and regular behavior patterns of passages in the preserve and recognize outliers that reflected odd behaviors.",,Shu Zhang;Danhuai Guo;Yingqiu Zhu;Deqiang Wang,"University of Chinese Academy of Sciences and the Computer Network Information Center, Chinese Academy of Sciences;University of Chinese Academy of Sciences and the Computer Network Information Center, Chinese Academy of Sciences;University of Chinese Academy of Sciences and the Computer Network Information Center, Chinese Academy of Sciences;University of Chinese Academy of Sciences and the Computer Network Information Center, Chinese Academy of Sciences",,"Topology,spatio-temporal visualization,,,,,,,",,0,,
VAST-conf,2017,Understanding Hidden Memories of Recurrent Neural Networks,10.1109/VAST.2017.8585721,https://doi.org/10.1109/VAST.2017.8585721,13,24,Conferences,"Recurrent neural networks (RNNs) have been successfully applied to various natural language processing (NLP) tasks and achieved better results than conventional methods. However, the lack of understanding of the mechanisms behind their effectiveness limits further improvements on their architectures. In this paper, we present a visual analytics method for understanding and comparing RNN models for NLP tasks. We propose a technique to explain the function of individual hidden state units based on their expected response to input texts. We then co-cluster hidden state units and words based on the expected response and visualize co-clustering results as memory chips and word clouds to provide more structured knowledge on RNNs’ hidden states. We also propose a glyph-based sequence visualization based on aggregate information to analyze the behavior of an RNN’s hidden state at the sentence-level. The usability and effectiveness of our method are demonstrated through case studies and reviews from domain experts.",,Yao Ming;Shaozu Cao;Ruixiang Zhang;Zhen Li;Yuanzhe Chen;Yangqiu Song;Huamin Qu,Hong Kong University of Science and Technology;Hong Kong University of Science and Technology;Hong Kong University of Science and Technology;Hong Kong University of Science and Technology;Hong Kong University of Science and Technology;Hong Kong University of Science and Technology;Hong Kong University of Science and Technology,,"recurrent neural networks,visual analytics,understanding neural model,co-clustering,,,,,",,87,,
VAST-conf,2017,"Warning, Bias May Occur: A Proposed Approach to Detecting Cognitive Bias in Interactive Visual Analytics",10.1109/VAST.2017.8585669,https://doi.org/10.1109/VAST.2017.8585669,104,115,Conferences,"Visual analytic tools combine the complementary strengths of humans and machines in human-in-the-loop systems. Humans provide invaluable domain expertise and sensemaking capabilities to this discourse with analytic models; however, little consideration has yet been given to the ways inherent human biases might shape the visual analytic process. In this paper, we establish a conceptual framework for considering bias assessment through human-in-the-loop systems and lay the theoretical foundations for bias measurement. We propose six preliminary metrics to systematically detect and quantify bias from user interactions and demonstrate how the metrics might be implemented in an existing visual analytic system, InterAxis. We discuss how our proposed metrics could be used by visual analytic systems to mitigate the negative effects of cognitive biases by making users aware of biased processes throughout their analyses.",,Emily Wall;Leslie M. Blaha;Lyndsey Franklin;Alex Endert,Georgia Tech;Pacific Northwest National Laboratory;Pacific Northwest National Laboratory;Georgia Tech,,"cognitive bias,visual analytics,human-in-the-loop,mixed initiative,user interaction,H.5.0 [Information Systems]: Human-Computer Interaction-General,,,",,66,,
VAST-conf,2017,The Anchoring Effect in Decision-Making with Visual Analytics,10.1109/VAST.2017.8585665,https://doi.org/10.1109/VAST.2017.8585665,116,126,Conferences,"Anchoring effect is the tendency to focus too heavily on one piece of information when making decisions. In this paper, we present a novel, systematic study and resulting analyses that investigate the effects of anchoring effect on human decision-making using visual analytic systems. Visual analytics interfaces typically contain multiple views that present various aspects of information such as spatial, temporal, and categorical. These views are designed to present complex, heterogeneous data in accessible forms that aid decision-making. However, human decision-making is often hindered by the use of heuristics, or cognitive biases, such as anchoring effect. Anchoring effect can be triggered by the order in which information is presented or the magnitude of information presented. Through carefully designed laboratory experiments, we present evidence of anchoring effect in analysis with visual analytics interfaces when users are primed by representation of different pieces of information. We also describe detailed analyses of users’ interaction logs which reveal the impact of anchoring bias on the visual representation preferred and paths of analysis. We discuss implications for future research to possibly detect and alleviate anchoring bias.",,Isaac Cho;Ryan Wesslen;Alireza Karduni;Sashank Santhanam;Samira Shaikh;Wenwen Dou,University of North Carolina at Charlotte;University of North Carolina at Charlotte;University of North Carolina at Charlotte;University of North Carolina at Charlotte;University of North Carolina at Charlotte;University of North Carolina at Charlotte,,"Visual Analytics,Anchoring Effect,Sense Making,Cognitive Bias,Interaction Log Analysis,K.6.1 [Management of Computing and Information Systems]: Project and People Management-Life Cycle,K.7.m [The Computing Profession]: Miscellaneous-Ethics,,",,38,,
VAST-conf,2017,A Workflow for Visual Diagnostics of Binary Classifiers using Instance-Level Explanations,10.1109/VAST.2017.8585720,https://doi.org/10.1109/VAST.2017.8585720,162,172,Conferences,"Human-in-the-loop data analysis applications necessitate greater transparency in machine learning models for experts to understand and trust their decisions. To this end, we propose a visual analytics workflow to help data scientists and domain experts explore, diagnose, and understand the decisions made by a binary classifier. The approach leverages “instance-level explanations”, measures of local feature relevance that explain single instances, and uses them to build a set of visual representations that guide the users in their investigation. The workflow is based on three main visual representations and steps: one based on aggregate statistics to see how data distributes across correct / incorrect decisions; one based on explanations to understand which features are used to make these decisions; and one based on raw data, to derive insights on potential root causes for the observed patterns. The workflow is derived from a long-term collaboration with a group of machine learning and healthcare professionals who used our method to make sense of machine learning models they developed. The case study from this collaboration demonstrates that the proposed workflow helps experts derive useful knowledge about the model and the phenomena it describes, thus experts can generate useful hypotheses on how a model can be improved.",,Josua Krause;Aritra Dasgupta;Jordan Swartz;Yindalon Aphinyanaphongs;Enrico Bertini,NYU Tandon School of Engineering;Pacific Northwest National Laboratory;NYU School of Medicine;NYU School of Medicine;NYU Tandon School of Engineering,,"Machine Learning,Interpretation,Visual Analytics,,,,,,",,36,,
VAST-conf,2017,The Role of Explicit Knowledge: A Conceptual Model of Knowledge-Assisted Visual Analytics,10.1109/VAST.2017.8585498,https://doi.org/10.1109/VAST.2017.8585498,92,103,Conferences,"Visual Analytics (VA) aims to combine the strengths of humans and computers for effective data analysis. In this endeavor, humans' tacit knowledge from prior experience is an important asset that can be leveraged by both human and computer to improve the analytic process. While VA environments are starting to include features to formalize, store, and utilize such knowledge, the mechanisms and degree in which these environments integrate explicit knowledge varies widely. Additionally, this important class of VA environments has never been elaborated on by existing work on VA theory. This paper proposes a conceptual model of Knowledge-assisted VA conceptually grounded on the visualization model by van Wijk. We apply the model to describe various examples of knowledge-assisted VA from the literature and elaborate on three of them in finer detail. Moreover, we illustrate the utilization of the model to compare different design alternatives and to evaluate existing approaches with respect to their use of knowledge. Finally, the model can inspire designers to generate novel VA environments using explicit knowledge effectively.",,Paolo Federico;Markus Wagner;Alexander Rind;Albert Amor-Amorós;Silvia Miksch;Wolfgang Aigner,"TU Wien, Austria;St. Poelten University of Applied Sciences, Austria and TU Wien, Austria;St. Poelten University of Applied Sciences, Austria and TU Wien, Austria;TU Wien, Austria;TU Wien, Austria;TU Wien, Austria",,"Automated analysis,tacit knowledge,explicit knowledge,visual analytics,information visualization,theory and model,,,",,27,,
VAST-conf,2017,Visual Causality Analysis Made Practical,10.1109/VAST.2017.8585647,https://doi.org/10.1109/VAST.2017.8585647,151,161,Conferences,"Deriving the exact casual model that governs the relations between variables in a multidimensional dataset is difficult in practice. It is because causal inference algorithms by themselves typically cannot encode an adequate amount of domain knowledge to break all ties. Visual analytic approaches are considered a feasible alternative to fully automated methods. However, their application in real-world scenarios can be tedious. This paper focuses on these practical aspects of visual causality analysis. The most imperative of these aspects is posed by Simpson' Paradox. It implies the existence of multiple causal models differing in both structure and parameter depending on how the data is subdivided. We propose a comprehensive interface that engages human experts in identifying these subdivisions and allowing them to establish the corresponding causal models via a rich set of interactive facilities. Other features of our interface include: (1) a new causal network visualization that emphasizes the flow of causal dependencies, (2) a model scoring mechanism with visual hints for interactive model refinement, and (3) flexible approaches for handling heterogeneous data. Various real-world data examples are given.",,Jun Wang;Klaus Mueller,"Visual Analytics and Imaging Lab, Stony Brook University;Visual Analytics and Imaging Lab, Stony Brook University",,"Visual knowledge discovery,Causality,Hypothesis testing,Visual evidence,High-dimensional data,,,,",,23,,
VAST-conf,2017,E-Map: A Visual Analytics Approach for Exploring Significant Event Evolutions in Social Media,10.1109/VAST.2017.8585638,https://doi.org/10.1109/VAST.2017.8585638,36,47,Conferences,"Significant events are often discussed and spread through social media, involving many people. Reposting activities and opinions expressed in social media offer good opportunities to understand the evolution of events. However, the dynamics of reposting activities and the diversity of user comments pose challenges to understand event-related social media data. We propose E-Map, a visual analytics approach that uses map-like visualization tools to help multi-faceted analysis of social media data on a significant event and in-depth understanding of the development of the event. E-Map transforms extracted keywords, messages, and reposting behaviors into map features such as cities, towns, and rivers to build a structured and semantic space for users to explore. It also visualizes complex posting and reposting behaviors as simple trajectories and connections that can be easily followed. By supporting multi-level spatial temporal exploration, E-Map helps to reveal the patterns of event development and key players in an event, disclosing the ways they shape and affect the development of the event. Two cases analysing real-world events confirm the capacities of E-Map in facilitating the analysis of event evolution with social media data.",,Siming Chen;Shuai Chen;Lijing Lin;Xiaoru Yuan;Jie Liang;Xiaolong Zhang,"Key Laboratory of Machine Perception (Ministry of Education) and School of EECS, Peking University, China;Key Laboratory of Machine Perception (Ministry of Education) and School of EECS, Peking University, China;Key Laboratory of Machine Perception (Ministry of Education) and School of EECS, Peking University, China;Key Laboratory of Machine Perception (Ministry of Education) and School of EECS, Peking University, China;Faculty of Engineer and Information Technology, The University of Technology, Sydney, Australia;College of Information Sciences and Technology, Pennsylvania State University, USA",,"Social Media,Event Analysis,Map-like Visual Metaphor,Spatial Temporal Visual Analytics,,,,,",,17,,
VAST-conf,2017,CrystalBall: A Visual Analytic System for Future Event Discovery and Analysis from Social Media Data,10.1109/VAST.2017.8585658,https://doi.org/10.1109/VAST.2017.8585658,25,35,Conferences,"Social media data bear valuable insights regarding events that occur around the world. Events are inherently temporal and spatial. Existing visual text analysis systems have focused on detecting and analyzing past and ongoing events. Few have leveraged social media information to look for events that may occur in the future. In this paper, we present an interactive visual analytic system, CrystalBall, that automatically identifies and ranks future events from Twitter streams. CrystalBall integrates new methods to discover events with interactive visualizations that permit sensemaking of the identified future events. Our computational methods integrate seven different measures to identify and characterize future events, leveraging information regarding time, location, social networks, and the informativeness of the messages. A visual interface is tightly coupled with the computational methods to present a concise summary of the possible future events. A novel connection graph and glyphs are designed to visualize the characteristics of the future events. To demonstrate the efficacy of CrystalBall in identifying future events and supporting interactive analysis, we present multiple case studies and validation studies on analyzing events derived from Twitter data.",,Isaac Cho;Ryan Wesslen;Svitlana Volkova;William Ribarsky;Wenwen Dou,University of North Carolina at Charlotte;University of North Carolina at Charlotte;Pacific Northwest National Laboratory;University of North Carolina at Charlotte;University of North Carolina at Charlotte,,"Social media analysis,Event detection and analysis,visual analytics,,,,,,",,11,,
VAST-conf,2017,Visualizing Real-Time Strategy Games: The Example of StarCraft II,10.1109/VAST.2017.8585594,https://doi.org/10.1109/VAST.2017.8585594,71,80,Conferences,"We present a visualization system for users to examine real-time strategy games, which have become very popular globally in recent years. Unlike previous systems that focus on showing statistics and build order, our system can depict the most important part - battles in the games. Specifically, we visualize detailed movements of armies belonging to respective nations on a map and enable users to examine battles from a global view to a local view. In the global view, battles are depicted by curved arrows revealing how the armies enter and escape from the battlefield. By observing the arrows and the height map, users can make sense of offensive and defensive strategies easily. In the local view, units of each type are rendered on the map, and their movements are represented by animation. We also render an attack line between a pair of units if one of them can attack the other to help users analyze the advantages and disadvantages of a particular formation. Accordingly, users can utilize our system to discover statistics, build order, and battles, and learn strategies from games played by professionals.",,Yen-Ting Kuan;Yu-Shuen Wang;Jung-Hong Chuang,National Chiao Tung University;National Chiao Tung University;National Chiao Tung University,,"real-time strategy games,StarCraft,game visualization,trajectories,,,,,",,10,,
VAST-conf,2017,Interactive Visual Alignment of Medieval Text Versions,10.1109/VAST.2017.8585505,https://doi.org/10.1109/VAST.2017.8585505,127,138,Conferences,"Textual criticism consists of the identification and analysis of variant readings among different versions of a text. Being a relatively simple task for modern languages, the collation of medieval text traditions ranges from the complex to the virtually impossible depending on the degree of instability of textual transmission. We present a visual analytics environment that supports computationally aligning such complex textual differences typical of orally inflected medieval poetry. For the purpose of analyzing alignment, we provide interactive visualizations for different text hierarchy levels, specifically, a meso reading view to support investigating repetition and variance at the line level across text segments. In addition to outlining important aspects of our interdisciplinary collaboration, we emphasize the utility of the proposed system by various usage scenarios in medieval French literature.",,Stefan Jänicke;David Joseph Wrisley,"Image and Signal Processing Group, Institute for Computer Science, Leipzig University, Germany;Digital Humanities, New York University Abu Dhabi, United Arab Emirates",,",,,,,,,,",,8,,
VAST-conf,2017,A Visual Analytics System for Optimizing Communications in Massively Parallel Applications,10.1109/VAST.2017.8585646,https://doi.org/10.1109/VAST.2017.8585646,59,70,Conferences,"Current and future supercomputers have tens of thousands of compute nodes interconnected with high-dimensional networks and complex network topologies for improved performance. Application developers are required to write scalable parallel programs in order to achieve high throughput on these machines. Application performance is largely determined by efficient inter-process communication. A common way to analyze and optimize performance is through profiling parallel codes to identify communication bottlenecks. However, understanding gigabytes of profiled at a is not a trivial task. In this paper, we present a visual analytics system for identifying the scalability bottlenecks and improving the communication efficiency of massively parallel applications. Visualization methods used in this system are designed to comprehend large-scale and varied communication patterns on thousands of nodes in complex networks such as the 5D torus and the dragonfly. We also present efficient rerouting and remapping algorithms that can be coupled with our interactive visual analytics design for performance optimization. We demonstrate the utility of our system with several case studies using three benchmark applications on two leading supercomputers. The mapping suggestion from our system led to 38% improvement in hop-bytes for Mini AMR application on 4,096 MPI processes.",,Takanori Fujiwara;Preeti Malakar;Khairi Reda;Venkatram Vishwanath;Michael E. Papka;Kwan-Liu Ma,"University of California, Davis;Argonne National Laboratory;Indiana University-Purdue University Indianapolis;Argonne National Laboratory;Argonne National Laboratory, Northern Illinois University;University of California, Davis",,"Supercomputing,parallel communications,performance analysis,visual analytics,communication visualization,,,,",,7,,
VAST-conf,2017,Pattern Trails: Visual Analysis of Pattern Transitions in Subspaces,10.1109/VAST.2017.8585613,https://doi.org/10.1109/VAST.2017.8585613,1,12,Conferences,"Subspace analysis methods have gained interest for identifying patterns in subspaces of high-dimensional data. Existing techniques allow to visualize and compare patterns in subspaces. However, many subspace analysis methods produce an abundant amount of patterns, which often remain redundant and are difficult to relate. Creating effective layouts for comparison of subspace patterns remains challenging. We introduce Pattern Trails, a novel approach for visually ordering and comparing subspace patterns. Central to our approach is the notion of pattern transitions as an interpretable structure imposed to order and compare patterns between subspaces. The basic idea is to visualize projections of subspaces side-by-side, and indicate changes between adjacent patterns in the subspaces by a linked representation, hence introducing pattern transitions. Our contributions comprise a systematization for how pairs of subspace patterns can be compared, and how changes can be interpreted in terms of pattern transitions. We also contribute a technique for visual subspace analysis based on a data-driven similarity measure between subspace representations. This measure is useful to order the patterns, and interactively group subspaces to reduce redundancy. We demonstrate the usefulness of our approach by application to several use cases, indicating that data can be meaningfully ordered and interpreted in terms of pattern transitions.",,Dominik Jäckle;Michael Hund;Michael Behrisch;Daniel A. Keim;Tobias Schreck,University of Konstanz;University of Konstanz;University of Konstanz;University of Konstanz;TU Graz,,"H.5.2 [Information Interfaces and Presentation],user Interfaces—Graphical User Interfaces,Interaction Styles,,,,,,",,7,,
conference_external,2017,"The “y” of it Matters, Even for Storyline Visualization",10.1109/VAST.2017.8585487,https://doi.org/10.1109/VAST.2017.8585487,81,91,Conferences,"Storylines are adept at communicating complex change by encoding time on the x-axis and using the proximity of lines in the y direction to represent interaction between entities. The original definition of a storyline visualization requires data defined in terms of explicit interaction groups. Relaxing this definition allows storyline visualization to be applied more generally, but this creates questions about how the y-coordinate should encode interactions when this is tied to a particular place or state. To answer this question, we conducted a design study where we considered two layout algorithm design alternatives within a geo-temporal analysis tool written to solve part of the VAST Challenge 2014. We measured the performance of users at overview and detail oriented tasks between two storyline layout algorithms. To the best of our knowledge, this paper is the first work to question the design principles for storyline visualization, and what we found surprised us. For overview tasks with the alternative layout, which has a consistent encoding for the y-coordinate, users performed moderately better (p <; .05) than the storyline layout based on existing design constraints and aesthetic criteria. Our empirical findings were also supported by first-hand accounts taken from interviews with multiple expert analysts, who suggested that the inconsistent meaning of the y-axis was misleading. These findings led us to design a new storyline layout algorithm that is a “best of both” where the y-axis has a consistent meaning but aesthetic criteria (e.g., line crossings) are considered.",,Dustin Arendt;Meg Pirrung,Pacific Northwest National Laboratory;Pacific Northwest National Laboratory,,"Storyline visualization,layout algorithms,interaction context,geospatial analysis,VAST Challenge,,,,",,4,,
VAST-conf,2017,CRICTO: Supporting Sensemaking through Crowdsourced Information Schematization,10.1109/VAST.2017.8585484,https://doi.org/10.1109/VAST.2017.8585484,139,150,Conferences,"We present CRICTO, a new crowdsourcing visual analytics environment for making sense of and analyzing text data, whereby multiple crowdworkers are able to parallelize the simple information schematization tasks of relating and connecting entities across documents. The diverse links from these schematization tasks are then automatically combined and the system visualizes them based on the semantic types of the linkages. CRICTO also includes several tools that allow analysts to interactively explore and refine crowdworkers' results to better support their own sensemaking processes. We evaluated CRICTO's techniques and analysis workflow with deployments of CRICTO using Amazon Mechanical Turk and a user study that assess the effect of crowdsourced schematization in sensemaking tasks. The results of our evaluation show that CRICTO's crowdsourcing approaches and workflow help analysts explore diverse aspects of datasets, and uncover more accurate hidden stories embedded in the text datasets.",,Haeyong Chung;Sai Prashanth Dasari;Santhosh Nandhakumar;Christopher Andrews,University of Alabama in Huntsville;University of Alabama in Huntsville;University of Alabama in Huntsville;Middlebury College,,"Visual text analytics,sensemaking,crowdsourcing,,,,,,",,4,,
conference_external,2017,VAST Challenge 2017: Mystery at the Wildlife Preserve,10.1109/VAST.2017.8585503,https://doi.org/10.1109/VAST.2017.8585503,173,178,Conferences,"The VAST Challenge 2017 offered three mini-challenges and a grand challenge dealing with environmental problems potentially caused by human patterns of life and potentially harmful chemically laden effluent plumes being emitted from factory smokestacks. The data provided included traffic patterns, sensor data though a Preserve, information about the Preserve, multispectral imagery and a map to help an ornithology graduate student particularly concerned with the population decrease of the Rose-Crested Blue Pipit determine who and what might be responsible. Mini-Challenge 1 focused on analysis of vehicles passing through the Preserve over time. Mini-Challenge 2 looked at data collected by air sampling monitors surrounding nearby factories, along with meteorological readings, to understand potential impacts they may be having on the Pipit. Mini-Challenge 3 required investigation into several months of multi-spectral imagery over the area to understand the Preserve's general health. The Grand Challenge asked participants to synthesize across all three mini-challenges to create hypotheses of what is happening and what sensible next steps could be. This year's challenge received 58 submissions and recorded over 1100 unique downloads from 20 countries prior to the submission deadline.",,Mark A. Whiting;Kris Cook;R. Jordan Crouser;John Fallon;Georges Grinstein;Jereme Haack;Cindy Henderson;Kristen Liggett;Diane Staheli;Jana Strasburg;Jerry Tagestad;Carrie Varley,Pacific Northwest National Laboratory;Pacific Northwest National Laboratory;Smith College;University of Mass Amherst;University of Mass Amherst;Pacific Northwest National Laboratory;Pacific Northwest National Laboratory;Air Force Research Laboratory;MIT Lincoln Laboratory;Pacific Northwest National Laboratory;Pacific Northwest National Laboratory;Pacific Northwest National Laboratory,,"Visual analytics,human information interaction,patterns of life,short events analytics,multi-spectral imagery,evaluation,contest,,",,2,,
VAST-conf,2017,QSAnglyzer: Visual Analytics for Prismatic Analysis of Question Answering System Evaluations,10.1109/VAST.2017.8585733,https://doi.org/10.1109/VAST.2017.8585733,48,58,Conferences,"Developing sophisticated artificial intelligence (AI) systems requires AI researchers to experiment with different designs and analyze results from evaluations (we refer this task as evaluation analysis). In this paper, we tackle the challenges of evaluation analysis in the domain of question-answering (QA) systems. Through in-depth studies with QA researchers, we identify tasks and goals of evaluation analysis and derive a set of design rationales, based on which we propose a novel approach termed prismatic analysis. Prismatic analysis examines data through multiple ways of categorization (referred as angles). Categories in each angle are measured by aggregate metrics to enable diverse comparison scenarios. To facilitate prismatic analysis of QA evaluations, we design and implement the Question Space Anglyzer (QSAnglyzer), a visual analytics (VA) tool. In QSAnglyzer, the high-dimensional space formed by questions is divided into categories based on several angles (e.g., topic and question type). Each category is aggregated by accuracy, the number of questions, and accuracy variance across evaluations. QSAnglyzer visualizes these angles so that QA researchers can examine and compare evaluations from various aspects both individually and collectively. Furthermore, QA researchers filter questions based on any angle by clicking to construct complex queries. We validate QSAnglyzer through controlled experiments and by expert reviews. The results indicate that when using QSAnglyzer, users perform analysis tasks faster (p <; 0.01) and more accurately (p <; 0.05), and are quick to gain new insight. We discuss how prismatic analysis and QSAnglyzer scaffold evaluation analysis, and provide directions for future research.",,Nan-Chen Chen;Been Kim,University of Washington;Allen Institute for Artificial Intelligence,,"visual analytics,visualization,interactive visualization,question answering,multi-experiment analysis,visual comparison,visual exploration,prismatic analysis,H.5.2 [Information Interfaces and Presentation]: User Interfaces—",,0,,
conference_external,2017,VIS Capstone Address Data Humanism: The Revolution will be Visualized,10.1109/VAST.2017.8585625,https://doi.org/10.1109/VAST.2017.8585625,1,1,Conferences,"It's time to change our minds about data. Data is often perceived as inevitably cold, but instead it can be more than numbers, it can represent real life and it can be a snapshot of the world in the same way that a picture catches small moments in time. The more ubiquitous data becomes, the more we need to experiment with how to make it unique, contextual, intimate; and the way we visualize it is crucial as it is the key to translating numbers into concepts we can relate to. In an aspirational talk, Giorgia will discuss how to see this moment as an opportunity to jumpstart a new renaissance, where we can question the impersonality of a merely technical approach to data, where we are ready to reconnect numbers to what they really stand for: which are more and more our lives.",,Giorgia Lupi,Accurat,,",,,,,,,,",,4,,
conference_external,2017,VAST 2017 Conference Committee,10.1109/VAST.2017.8585430,https://doi.org/10.1109/VAST.2017.8585430,i,i,Conferences,Provides a listing of current committee members and society officers.,,,,,",,,,,,,,",,0,,
conference_external,2017,Preface,10.1109/VAST.2017.8585465,https://doi.org/10.1109/VAST.2017.8585465,i,i,Conferences,The following topics are dealt with: data visualisation; data analysis; environmental science computing; zoology; data mining; geophysical image processing; interactive systems; pattern clustering; traffic engineering computing; biology computing.,,,,,",,,,,,,,",,0,,
conference_external,2017,VAST 2017 International Program Committee,10.1109/VAST.2017.8585727,https://doi.org/10.1109/VAST.2017.8585727,i,iii,Conferences,Provides a listing of current committee members and society officers.,,,,,",,,,,,,,",,0,,
conference_external,2017,VAST 2017 Preface,10.1109/VAST.2017.8585437,https://doi.org/10.1109/VAST.2017.8585437,i,i,Conferences,Presents the introductory welcome message from the conference proceedings. May include the conference officers' congratulations to all involved with the conference event and publication of the proceedings record.,,,,,",,,,,,,,",,0,,
conference_external,2017,[Title page],10.1109/VAST.2017.8585581,https://doi.org/10.1109/VAST.2017.8585581,i,i,Conferences,Presents the title page of the proceedings record.,,,,,",,,,,,,,",,0,,
conference_external,2017,[Copyright notice],10.1109/VAST.2017.8585676,https://doi.org/10.1109/VAST.2017.8585676,i,i,Conferences,Presents the copyright information for the conference. May include reprint permission information.,,,,,",,,,,,,,",,0,,
conference_external,2017,Table of Contents,10.1109/VAST.2017.8585558,https://doi.org/10.1109/VAST.2017.8585558,i,iv,Conferences,Presents the table of contents/splash page of the proceedings record.,,,,,",,,,,,,,",,0,,
