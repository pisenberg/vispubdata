Conference,Year,Title,DOI,Link,FirstPage,LastPage,PaperType,Abstract,AuthorNames-Deduped,AuthorNames,AuthorAffiliation,InternalReferences,AuthorKeywords,AminerCitationCount,CitationCount_CrossRef,PubsCited,Award
SciVis-conf,2015,Multiresolution visualization of digital earth data via hexagonal box-spline wavelets,10.1109/SciVis.2015.7429508,http://dx.doi.org/10.1109/SciVis.2015.7429508,151,152,Conferences,"Multiresolution analysis is an important tool for exploring large-scale data sets. Such analysis provides facilities to visualize data at different levels of detail while providing the advantages of efficient data compression and transmission. In this work, an approach is presented to apply multiresolution analysis to digital Earth data where each resolution describes data at a specific level of detail. Geospatial data at a fine level is taken as the input and a hierarchy of approximation and detail coefficients is built by applying a hexagonal discrete wavelet transform. Multiresolution filters are designed for hexagonal cells based on the three directional linear box spline which is natively supported by modern GPUs.",,Mohammad Imrul Jubair;Usman Alim;Niklas Roeber;John Clyne;Ali Mahdavi-Amiri;Faramarz Samavati,University of Calgary;University of Calgary;German Climate Computing Centre;University Corporation for Atmospheric Research;University of Calgary;University of Calgary,,"Multiresolution analysis,digital earth data,linear box-spline,hexagonal grid,,",,2,,
SciVis-conf,2015,PathlinesExplorer - Image-based exploration of large-scale pathline fields,10.1109/SciVis.2015.7429512,http://dx.doi.org/10.1109/SciVis.2015.7429512,159,160,Conferences,"PathlinesExplorer is a novel image-based tool, which has been designed to visualize large scale pathline fields on a single computer [7]. PathlinesExplorer integrates explorable images (EI) technique [4] with order-independent transparency (OIT) method [2]. What makes this method different is that it allows users to handle large data on a single workstation. Although it is a view-dependent method, PathlinesExplorer combines both exploration and modification of visual aspects without re-accessing the original huge data. Our approach is based on constructing a per-pixel linked list data structure in which each pixel contains a list of pathline segments. With this view-dependent method, it is possible to filter, color-code, and explore large-scale flow data in real-time. In addition, optimization techniques such as early-ray termination and deferred shading are applied, which further improves the performance and scalability of our approach.",,Omniah H. Nagoor;Markus Hadwiger;Madhusudhanan Srinivasan,KAUST;KAUST;KAUST,,"Image-based rendering,per-pixel linked list,pathline fields,explorable images,deferred shading,early-ray termination",,0,,
SciVis-conf,2015,"Inviwo - An extensible, multi-purpose visualization framework",10.1109/SciVis.2015.7429514,http://dx.doi.org/10.1109/SciVis.2015.7429514,163,164,Conferences,"To enable visualization research impacting other scientific domains, the availability of easy-to-use visualization frameworks is essential. Nevertheless, an easy-to-use system also has to be adapted to the capabilities of modern hardware architectures, as only this allows for realizing interactive visualizations. With this trade-off in mind, we have designed and realized the cross-platform Inviwo (Interactive Visualization Workshop) visualization framework, that supports both interactive visualization research as well as efficient visualization application development and deployment. In this poster we give an overview of the architecture behind Inviwo, and show how its design enables us and other researchers to realize their visualization ideas efficiently. Inviwo consists of a modern and lightweight, graphics independent core, which is extended by optional modules that encapsulate visualization algorithms, well-known utility libraries and commonly used parallel-processing APIs (such as OpenGL and OpenCL). The core enables a simplistic structure for creating bridges between the different modules regarding data transfer across architecture and devices with an easy-to-use screen graph and minimalistic programming. Making the base structures in a modern way while providing intuitive methods of extending the functionality and creating modules based on other modules, we hope that Inviwo can help the visualization community to perform research through a rapid-prototyping design and GUI, while at the same time allowing users to take advantage of the results implemented in the system in any way they desire later on. Inviwo is publicly available at www.inviwo.org, and can be used freely by anyone under a permissive free software license (Simplified BSD).",,Erik Sunden;Peter Steneteg;Sathish Kottravel;Daniel Jonsson;Rickard Englund;Martin Falk;Timo Ropinski,Linkoping University;Linkoping University;Linkoping University;Linkoping University;Linkoping University;Linkoping University;Ulm University,,"Inviwo,Interactive Visualization Workshop,Rapid Prototyping,Open Source Software,,",,10,,
conference_external,2015,Visualising the dark sky IEEE SciVis contest 2015,10.1109/SciVis.2015.7429496,http://dx.doi.org/10.1109/SciVis.2015.7429496,79,86,Conferences,"Cosmological simulations are a cornerstone of our understanding of the Universe during its 13.7 billion year progression from small fluctuations that we see in the cosmic microwave background to today, where we are surrounded by galaxies and clusters of galaxies interconnected by a vast cosmic web. In this paper, we present our results on the 2015 IEEE Scientific Visualization Contest, which pertains to datasets derived from the Dark Sky Simulations [10]. We ingest, process and visualise cosmological data of particle clouds and halo formations in terms of positions and shed light on various properties of scientific interest including graviational potential, velocity and spin.",,Theodoros Christoudias;Christos Kallidonis;Loizos Koutsantonis;Christos Lemesios;Lefteris Markou;Constantinos Sophocleous,Computational Science and Technology Research Center (CaSToRC) Cyprus Institute;Computational Science and Technology Research Center (CaSToRC) Cyprus Institute;Computational Science and Technology Research Center (CaSToRC) Cyprus Institute;Computational Science and Technology Research Center (CaSToRC) Cyprus Institute;Computational Science and Technology Research Center (CaSToRC) Cyprus Institute;Computational Science and Technology Research Center (CaSToRC) Cyprus Institute,,",,,,,",,0,,
conference_external,2015,Visualizing the life and anatomy of dark matter,10.1109/SciVis.2015.7429498,http://dx.doi.org/10.1109/SciVis.2015.7429498,101,106,Conferences,"We provide a visualization based answer to understanding the evolution and structure of dark matter halos by addressing the tasks assigned in 2015 IEEE Scientific Visualization Contest. The data released this year is a Cosmological Simulation dataset generated from the Dark Sky Simulation experiments. Out of the assigned tasks we are addressing the following: data integration and browsing, halo identification and visualization and diving deep into halo substructure.",,Subhashis Hazarika;Tzu-Hsuan Wei;Rajaditya Mukherjee;Alexandru Barbur,The Ohio State University;The Ohio State University;The Ohio State University;The Ohio State University,,"[Scientific Visualization],[Dark Matter Halo],[Particle Data],,,",,0,,
SciVis-conf,2015,OpenSpace: Public dissemination of space mission profiles,10.1109/SciVis.2015.7429503,http://dx.doi.org/10.1109/SciVis.2015.7429503,141,142,Conferences,This work presents a visualization system and its application to space missions. The system allows the public to disseminate the scientific findings of space craft and gain a greater understanding thereof. Instruments' field-of-views and their measurements are embedded in an accurate 3 dimensional rendering of the solar system to provide context to past measurements or the planning of future events. We tested our system with NASA's New Horizons at the Pluto Pallooza event in New York and will expose it to the greater public on the upcoming July 14th Pluto flyby.,,Alexander Bock;Michal Marcinkowski;Joakim Kilby;Carter Emmart;Anders Ynnerman,"Linköping University;American Museum of Natural History, Linköping University;Linköping University;American Museum of Natural History;Linköping University",,",,,,,",,4,,
SciVis-conf,2015,Real-time interactive time correction on the GPU,10.1109/SciVis.2015.7429505,http://dx.doi.org/10.1109/SciVis.2015.7429505,145,146,Conferences,"The study of physical phenomena and their dynamic evolution is supported by the analysis and visualization of time-enabled data. In many applications, available data are sparsely distributed in the space-time domain, which leads to incomprehensible visualizations. We present an interactive approach for the dynamic tracking and visualization of measured data particles through advection in a simulated flow. We introduce a fully GPU-based technique for efficient spatio-temporal interpolation, using a kd-tree forest for acceleration. As the user interacts with the system using a time slider, particle positions are reconstructed for the time selected by the user. Our results show that the proposed technique achieves highly accurate parallel tracking for thousands of particles. The rendering performance is mainly affected by the size of the query set.",,Mai Elshehaly;Denis Gračanin;Mohamed Gad;Junpeng Wang;Hicham G. Elmongui,Virginia Tech;Virginia Tech;Ain Shams University;Virginia Tech;Alexandria University,,"I.3.8 [COMPUTER GRAPHICS],Applications,,,,",,0,,
SciVis-conf,2015,An evaluation of three methods for visualizing uncertainty in architecture and archaeology,10.1109/SciVis.2015.7429507,http://dx.doi.org/10.1109/SciVis.2015.7429507,149,150,Conferences,"This project explores the representation of uncertainty in visualizations for archaeological research and provides insights obtained from user feedback. Our 3D models brought together information from standing architecture and excavated remains, surveyed plans, ground penetrating radar (GPR) data from the Carthusian monastery of Bourgfontaine in northern France. We also included information from comparative Carthusian sites and a bird's eye representation of the site in an early modern painting. Each source was assigned a certainty value which was then mapped to a color or texture for the model. Certainty values between one and zero were assigned by one subject matter expert and should be considered qualitative. Students and faculty from the fields of architectural history and archaeology at two institutions interacted with the models and answered a short survey with four questions about each. We discovered equal preference for color and transparency and a strong dislike for the texture model. Discoveries during model building also led to changes of the excavation plans for summer 2015.",,Scott Houde;Sheila Bonde;David H. Laidlaw,Brown University;Brown University;Brown University,,"uncertainty visualization,3D models,architectural history,archaeology,Bourgfontaine,qualitative data",,0,,
SciVis-conf,2015,A proposed multivariate visualization taxonomy from user data,10.1109/SciVis.2015.7429511,http://dx.doi.org/10.1109/SciVis.2015.7429511,157,158,Conferences,"We revisited past user study data on multivariate visualizations, looking at whether image processing measures offer any insight into user performance. While we find statistically significant correlations, some of the greatest insights into user performance came from variables that have strong ties to two key properties of multivariate representations. We discuss our analysis and propose a taxonomy of multivariate visualizations that arises.",,Mark A. Livingston;Jonathan W. Decker;Zhuming Ai,;;,,"H.5.2 [Information Interfaces and Presentation]: User Interfaces — Evaluation/methodology,H.5.2 [Information Interfaces and Presentation],User Interfaces — Screen design,,,",,0,,
SciVis-conf,2015,Automated visualization workflow for simulation experiments,10.1109/SciVis.2015.7429509,http://dx.doi.org/10.1109/SciVis.2015.7429509,153,154,Conferences,"Modeling and simulation is often used to predict future events and plan accordingly. Experiments in this domain often produce thousands of results from individual simulations, based on slightly varying input parameters. Geo-spatial visualizations can be a powerful tool to help health researchers and decision-makers to take measures during catastrophic and epidemic events such as Ebola outbreaks. The work produced a web-based geo-visualization tool to visualize and compare the spread of Ebola in the West African countries Ivory Coast and Senegal based on multiple simulation results. The visualization is not Ebola specific and may visualize any time-varying frequencies for given geo-locations.",,Jonathan P. Leidig;Santhosh Dharmapuri,"School of Computing and Information Systems, Grand Valley State University;School of Computing and Information Systems, Grand Valley State University",,"Modeling and simulation,geo-spatial,,,,",,1,,
SciVis-conf,2015,Visualizing 3D flow through cutting planes,10.1109/SciVis.2015.7429513,http://dx.doi.org/10.1109/SciVis.2015.7429513,161,162,Conferences,Studies have found conflicting results regarding the effectiveness of tube-like structures for representing 3D flow data. This paper presents the findings of a small-scale pilot study contrasting static monoscopic depth cues to ascertain their importance in perceiving the orientation of a three-dimensional glyph with respect to a cutting plane. A simple striped texture and shading were found to reduce judgement errors when used with a 3D tube glyph as compared to plain or shaded line glyphs. A discussion of considerations for a full-scale study and possible future work follows.,,Colin Ware;Andrew H. Stevens,University of New Hampshire;University of New Hampshire,,"Cutting plane,depth cues,flow visualization,,,",,0,,
SciVis-conf,2015,High performance flow field visualization with high-order access dependencies,10.1109/SciVis.2015.7429515,http://dx.doi.org/10.1109/SciVis.2015.7429515,165,166,Conferences,"We present a novel model based on high-order access dependencies for high performance pathline computation in flow field. The high-order access dependencies are defined as transition probabilities from one data block to other blocks based on a few historical data accesses. Compared with existing methods which employed first-order access dependencies, our approach takes the advantages of high order access dependencies with higher accuracy and reliability in data access prediction. In our work, high-order access dependencies are calculated by tracing densely-seeded pathlines. The efficiency of our proposed approach is demonstrated through a parallel particle tracing framework with high-order data prefetching. Results show that our method can achieve higher data locality than the first-order access dependencies based method, thereby reducing the I/O requests and improving the efficiency of pathline computation in various applications.",,Jiang Zhang;Hanqi Guo;Xiaoru Yuan,"Key Laboratory of Machine Perception (Ministry of Education), and School of EECS, Peking University;Argonne National Laboratory;Key Laboratory of Machine Perception (Ministry of Education), and School of EECS, Peking University",,"Flow visualization,High-Order,Data prefetching,,,",,0,,
conference_external,2015,Halos in a dark sky: Interactively exploring the structure of dark matter halo merger trees,10.1109/SciVis.2015.7429495,http://dx.doi.org/10.1109/SciVis.2015.7429495,73,77,Conferences,"This paper presents a novel application that visualizes dark matter halo merger trees and their evolution through space and time. Our application enables users to interact with individual halos within these trees in order to perform a range of visual analysis tasks, including: identifying the substructure and superstructure of the halos; observing the movement of halos across a custom range of time steps; and comparing the branching attributes of multiple trees. Central to our application is the ability to navigate the halos by interactively ""jumping"" from tree to tree. By clearly marking halos that have ""tributaries"" — that is, that split off into multiple halos or merge with one or more halos — we make it easy for the user to traverse the complex structure of the universe. Our application is publicly available1 online and runs at interactive rates on the browser using hardware-accelerated graphics.",,Kyle R. Almryde;Angus G. Forbes,University of Illinois at Chicago;University of Illinois at Chicago,,",,,,,",,3,,
conference_external,2015,Cavern Halos: Exploring spatial and nonspatial cosmological data in an immersive virtual environment,10.1109/SciVis.2015.7429497,http://dx.doi.org/10.1109/SciVis.2015.7429497,87,99,Conferences,"We present the design and implementation of an immersive visual mining and analysis tool for cosmological data. The tool consists of an immersive linked multiview display which allows domain experts to interact with visual representations of spatial and nonspatial cosmology data. Nonspatial data is represented as time-aligned merger trees, and through a pixel-based heatmap. Spatial data is represented through GPU-accelerated point clouds and geometric primitives. The user can select a halo and visualize a 3D representation of the raw particles, as well as of the halos at the particular time stamp. We have demonstrated the tool to a senior staff member of the Adler Planetarium and report their feedback. The tool can assist researchers in the interaction navigation and mining of large scale cosmological simulation data.",,Peter Hanula;Kamil Piekutowski;Carlos Uribe;Kyle Almryde;Arthur Nishimoto;Julieta Aguilera;G. Elisabeta Marai,"Electronic Visualization Laboratory University of Illinois at Chicago;Electronic Visualization Laboratory University of Illinois at Chicago;Electronic Visualization Laboratory University of Illinois at Chicago;Electronic Visualization Laboratory University of Illinois at Chicago;Electronic Visualization Laboratory University of Illinois at Chicago;Adler Planetarium, Chicago, IL;Electronic Visualization Laboratory University of Illinois at Chicago",,",,,,,",,3,,
conference_external,2015,Integrated explorer for cosmological evolution,10.1109/SciVis.2015.7429499,http://dx.doi.org/10.1109/SciVis.2015.7429499,107,114,Conferences,"Our system design is motivated by the need to simultaneously observe multiple data modalities. The main output from the cosmological simulation is a set of particle data, where each particle represents a dark matter parcel which coalesces into larger structures over time. Next, the data is run through a halo finding algorithm (Rockstar [1]), which detects groups of gravitationally bound particles and identifies them as halos. Lastly, a merger tree generation tool (Consistent Trees [2]) analyzes the hierarchical evolution of halos as they continue to merge into larger structures. Although each of these data modalities are generated through an iterative process, an understanding of their interplay is essential. Since information about the raw particle data and the extracted halos inform one another, we designed a multi-view exploration tool and enhance these views with both qualitative and quantitative information. Because of the scale of the data and the multitude of features, we aim to provide capability to both locate and focus analysis on specific features of interest.",,Annie Preston;Franz Sauer;Ramyar Ghods;Nick Leaf;Jinrong Xie;Kwan-Liu Ma,"University of California at Davis, CA, USA;University of California at Davis, CA, USA;University of California at Davis, CA, USA;University of California at Davis, CA, USA;University of California at Davis, CA, USA;University of California at Davis, CA, USA",,",,,,,",,0,,
SciVis-conf,2015,Correlation analysis in multidimensional multivariate time-varying datasets,10.1109/SciVis.2015.7429502,http://dx.doi.org/10.1109/SciVis.2015.7429502,139,140,Conferences,"One of the most vital challenges for weather forecasters is the correlation between two geographical phenomena that are distributed continuously in multidimensional multivariate time-varying datasets. In this research, we have visualized the correlation between Pressure and Temperature in the climate datasets. Pearson correlation is used in this study to measure the major linear relationship between two variables in the dataset. Using glyphs in the spatial location, we highlighted the significant association between variables. Based on the positive or negative slope of correlation lines, we can conclude how much they are correlated. The principal of this research is visualizing the local trend of variables versus each other in multidimensional multivariate time-varying datasets, which needs to be visualized with their spatial locations in meteorological datasets. Using glyphs, not only can we visualize the correlation between two variables in the coordinate system, but we can also discern whether any of these variables is separately increasing or decreasing. Moreover, we can visualize the background color as another variable and see the correlation lines around of a particular zone such as storm area.",,Najmeh Abedzadeh,Mississippi State University,,",,,,,",,0,,
SciVis-conf,2015,3D superquadric glyphs for visualizing myocardial motion,10.1109/SciVis.2015.7429504,http://dx.doi.org/10.1109/SciVis.2015.7429504,143,144,Conferences,"Various cardiac diseases can be diagnosed by the analysis of myocardial motion. Relevant biomarkers are radial, longitudinal, and rotational velocities of the cardiac muscle computed locally from MR images. We designed a visual encoding that maps these three attributes to glyph shapes according to a barycentric space formed by 3D superquadric glyphs. The glyphs show aggregated myocardial motion information following the AHA model and are displayed in a respective 3D layout.",,Teodora Chitiboi;Mathias Neugebauer;Susanne Schnell;Michael Markl;Lars Linsen,"FraunhoferMEVIS, Jacobs University Bremen;Fraunhofer MEVIS;Northwestern University;Northwestern University;Jacobs University Bremen",,",,,,,",,2,,
SciVis-conf,2015,Visualizing crossing probabilistic tracts,10.1109/SciVis.2015.7429506,http://dx.doi.org/10.1109/SciVis.2015.7429506,147,148,Conferences,"Diffusion weighted magnetic resonance imaging (dMRI) together with tractography algorithms allow to probe for principal white matter tracts in the living human brain. Specifically, probabilistic tractography quantifies the existence of physical connections to a given seed region as a 3D scalar map of confidence scores. Fiber-Stippling is a visualization for probabilistic tracts that effectively communicates the diffusion pattern, connectivity score, and anatomical context. Unfortunately, it cannot handle multiple diffusion orientations per voxel, which exist in high angular resolution diffusion imaging (HARDI) data. Such data is needed to resolve tracts in complex configurations, such as crossings. In this work, we suggest a visualization based on Fiber-Stippling but sensible to multiple diffusion orientations from HARDI-based diffusion models. With such a technique, it is now possible to visualize probabilistic tracts from HARDI-based tractography algorithms. This implies that tract crossings may now be visualized as crossing stipples, which is an essential step towards an accurate visualization of the neuroanatomy, as crossing tracts are widespread phenomena in the brain.",,Mathias Goldau;André Reichenbach;Mario Hlawitschka,Leipzig University;Leipzig University;Leipzig University,,"I.3.3 [Computer Graphics],Picture/Image Generation — Line and curve generation,,,,",,0,,
SciVis-conf,2015,A bottom-up scheme for user-defined feature exploration in vector field ensembles,10.1109/SciVis.2015.7429510,http://dx.doi.org/10.1109/SciVis.2015.7429510,155,156,Conferences,"Most of the existing approaches to visualize vector field ensembles are achieved by visualizing the uncertainty of individual variables from different simulation runs. However, the comparison of the derived feature or user-defined feature, such as the vortex in ensemble flow is also of vital significance since they often make more sense according to the domain knowledge. In this work, we present a framework to extract user-defined feature from different simulation runs. Specially, we use a bottom-up searching scheme to help to extract vortex with a user-defined shape, and further compute the geometry information including the size, and the geo-spatial location of the extracted vortex. Finally we design some linked views to compare the feature between different runs.",,Richen Liu;Hanqi Guo;Xiaoru Yuan,"Key Laboratory of Machine Perception (Ministry of Education), and School of EECS, Peking University;Argonne National Laboratory;Key Laboratory of Machine Perception (Ministry of Education), and School of EECS, Peking University",,",,,,,",,1,,
SciVis-conf,2015,Using maximum topology matching to explore differences in species distribution models,10.1109/SciVis.2015.7429486,http://dx.doi.org/10.1109/SciVis.2015.7429486,9,16,Conferences,"Species distribution models (SDM) are used to help understand what drives the distribution of various plant and animal species. These models are typically high dimensional scalar functions, where the dimensions of the domain correspond to predictor variables of the model algorithm. Understanding and exploring the differences between models help ecologists understand areas where their data or understanding of the system is incomplete and will help guide further investigation in these regions. These differences can also indicate an important source of model to model uncertainty. However, it is cumbersome and often impractical to perform this analysis using existing tools, which allows for manual exploration of the models usually as 1-dimensional curves. In this paper, we propose a topology-based framework to help ecologists explore the differences in various SDMs directly in the high dimensional domain. In order to accomplish this, we introduce the concept of maximum topology matching that computes a locality-aware correspondence between similar extrema of two scalar functions. The matching is then used to compute the similarity between two functions. We also design a visualization interface that allows ecologists to explore SDMs using their topological features and to study the differences between pairs of models found using maximum topological matching. We demonstrate the utility of the proposed framework through several use cases using different data sets and report the feedback obtained from ecologists.",,Jorge Poco;Harish Doraiswamy;Marian Talbert;Jeffrey Morisette;Cláudio T. Silva,New York University;New York University;U.S. Geological Survey;U.S. Geological Survey;New York University,,"Function similarity,computational topology,species distribution models,persistence,high dimensional visualization,",,1,,
SciVis-conf,2015,Explicit frequency control for high-quality texture-based flow visualization,10.1109/SciVis.2015.7429490,http://dx.doi.org/10.1109/SciVis.2015.7429490,41,48,Conferences,"In this work we propose an effective method for frequency-controlled dense flow visualization derived from a generalization of the Line Integral Convolution (LIC) technique. Our approach consists in considering the spectral properties of the dense flow visualization process as an integral operator defined in a local curvilinear coordinate system aligned with the flow. Exploring LIC from this point of view, we suggest a systematic way to design a flow visualization process with particular local spatial frequency properties of the resulting image. Our method is efficient, intuitive, and based on a long-standing model developed as a result of numerous perception studies. The method can be described as an iterative application of line integral convolution, followed by a one-dimensional Gabor filtering orthogonal to the flow. To demonstrate the utility of the technique, we generated novel adaptive multi-frequency flow visualizations, that according to our evaluation, feature a higher level of frequency control and higher quality scores than traditional approaches in texture-based flow visualization.",,Victor Matvienko;Jens Krüger,Saarland University;University Duisburg-Essen,,"flow visualization,texture-based visualization,LIC,Gabor filter,spatial frequency,image contrast",,1,,
SciVis-conf,2015,A visual voting framework for weather forecast calibration,10.1109/SciVis.2015.7429488,http://dx.doi.org/10.1109/SciVis.2015.7429488,25,32,Conferences,"Numerical weather predictions have been widely used for weather forecasting. Many large meteorological centers are producing highly accurate ensemble forecasts routinely to provide effective weather forecast services. However, biases frequently exist in forecast products because of various reasons, such as the imperfection of the weather forecast models. Failure to identify and neutralize the biases would result in unreliable forecast products that might mislead analysts; consequently, unreliable weather predictions are produced. The analog method has been commonly used to overcome the biases. Nevertheless, this method has some serious limitations including the difficulties in finding effective similar past forecasts, the large search space for proper parameters and the lack of support for interactive, real-time analysis. In this study, we develop a visual analytics system based on a novel voting framework to circumvent the problems. The framework adopts the idea of majority voting to combine judiciously the different variants of analog methods towards effective retrieval of the proper analogs for calibration. The system seamlessly integrates the analog methods into an interactive visualization pipeline with a set of coordinated views that characterizes the different methods. Instant visual hints are provided in the views to guide users in finding and refining analogs. We have worked closely with the domain experts in the meteorological research to develop the system. The effectiveness of the system is demonstrated using two case studies. An informal evaluation with the experts proves the usability and usefulness of the system.",,Hongsen Liao;Yingcai Wu;Li Chen;Thomas M. Hamill;Yunhai Wang;Kan Dai;Hui Zhang;Wei Chen,"School of Software, Tsinghua National Laboratory for Information Science and Technology, Tsinghua University;State Key Lab of CAD & CG, Zhejiang University;School of Software, Tsinghua National Laboratory for Information Science and Technology, Tsinghua University;NOAA Earth System Research Lab, Physical Sciences Division;Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences;National Meteorological Center of CMA;School of Software, Tsinghua National Laboratory for Information Science and Technology, Tsinghua University;State Key Lab of CAD & CG, Zhejiang University",,"Weather forecast,analog method,calibration,majority voting,visual analytics,",,5,,
SciVis-conf,2015,CPU ray tracing large particle data with balanced P-k-d trees,10.1109/SciVis.2015.7429492,http://dx.doi.org/10.1109/SciVis.2015.7429492,57,64,Conferences,"We present a novel approach to rendering large particle data sets from molecular dynamics, astrophysics and other sources. We employ a new data structure adapted from the original balanced k-d tree, which allows for representation of data with trivial or no overhead. In the OSPRay visualization framework, we have developed an efficient CPU algorithm for traversing, classifying and ray tracing these data. Our approach is able to render up to billions of particles on a typical workstation, purely on the CPU, without any approximations or level-of-detail techniques, and optionally with attribute-based color mapping, dynamic range query, and advanced lighting models such as ambient occlusion and path tracing.",,Ingo Wald;Aaron Knoll;Gregory P. Johnson;Will Usher;Valerio Pascucci;Michael E. Papka,"Intel Corporation;SCI Institute, University of Utah;Intel Corporation;SCI Institute, University of Utah;SCI Institute, University of Utah;Argonne National Laboratory, Northern Illinois University",,"Ray tracing,Visualization,Particle Data,k-d Trees,,",,14,,
SciVis-conf,2015,A classification of user tasks in visual analysis of volume data,10.1109/SciVis.2015.7429485,http://dx.doi.org/10.1109/SciVis.2015.7429485,1,8,Conferences,"Empirical findings from studies in one scientific domain have very limited applicability to other domains, unless we formally establish deeper insights on the generalizability of task types. We present a domain-independent classification of visual analysis tasks with volume visualizations. This taxonomy will help researchers design experiments, ensure coverage, and generate hypotheses in empirical studies with volume datasets. To develop our taxonomy, we first interviewed scientists working with spatial data in disparate domains. We then ran a survey to evaluate the design participants in which were scientists and professionals from around the world, working with volume data in various scientific domains. Respondents agreed substantially with our taxonomy design, but also suggested important refinements. We report the results in the form of a goal-based generic categorization of visual analysis tasks with volume visualizations. Our taxonomy covers tasks performed with a wide variety of volume datasets.",,Bireswar Laha;Doug A. Bowman;David H. Laidlaw;John J. Socha,Stanford University;Virginia Tech;Brown University;Virginia Tech,,"Task Taxonomy,Empirical Evaluation,Volume Visualization,Scientific Visualization,Virtual Reality,3D Interaction",,6,,
SciVis-conf,2015,Visual verification of space weather ensemble simulations,10.1109/SciVis.2015.7429487,http://dx.doi.org/10.1109/SciVis.2015.7429487,17,24,Conferences,"We propose a system to analyze and contextualize simulations of coronal mass ejections. As current simulation techniques require manual input, uncertainty is introduced into the simulation pipeline leading to inaccurate predictions that can be mitigated through ensemble simulations. We provide the space weather analyst with a multi-view system providing visualizations to: 1. compare ensemble members against ground truth measurements, 2. inspect time-dependent information derived from optical flow analysis of satellite images, and 3. combine satellite images with a volumetric rendering of the simulations. This three-tier workflow provides experts with tools to discover correlations between errors in predictions and simulation parameters, thus increasing knowledge about the evolution and propagation of coronal mass ejections that pose a danger to Earth and interplanetary travel.",,Alexander Bock;Asher Pembroke;M. Leila Mays;Lutz Rastaetter;Timo Ropinski;Anders Ynnerman,Linkoping University;NASA Goddard Space Flight Center;NASA Goddard Space Flight Center;NASA Goddard Space Flight Center;Ulm University;Linköping University,,"Visual Verification,Space Weather,Coronal Mass Ejections,Ensemble,,",,8,,
SciVis-conf,2015,Feature-based tensor field visualization for fiber reinforced polymers,10.1109/SciVis.2015.7429491,http://dx.doi.org/10.1109/SciVis.2015.7429491,49,56,Conferences,"Virtual testing is an integral part of modern product development in mechanical engineering. Numerical structure simulations allow the computation of local stresses which are given as tensor fields. For homogeneous materials, the tensor information is usually reduced to a scalar field like the von Mises stress. A material-dependent threshold defines the material failure answering the key question of engineers. This leads to a rather simple feature-based visualisation. For composite materials like short fiber reinforced polymers, the situation is much more complex. The material property is determined by the fiber distribution at every position, often described as fiber orientation tensor field. Essentially, the material's ability to cope with stress becomes anisotropic and inhomogeneous. We show how to combine the stress field and the fiber orientation field in such cases, leading to a feature-based visualization of tensor fields for composite materials. The resulting features inform the engineer about potential improvements in the product development.",,Valentin Zobel;Markus Stommel;Gerik Scheuermann,Leipzig University;TU Dortmund University;Leipzig University,,"tensor visualization,feature-based visualisation,composite materials,structural mechanics,,",,3,,
SciVis-conf,2015,Real-time uncertainty visualization for B-mode ultrasound,10.1109/SciVis.2015.7429489,http://dx.doi.org/10.1109/SciVis.2015.7429489,33,40,Conferences,"B-mode ultrasound is a very well established imaging modality and is widely used in many of today's clinical routines. However, acquiring good images and interpreting them correctly is a challenging task due to the complex ultrasound image formation process depending on a large number of parameters. To facilitate ultrasound acquisitions, we introduce a novel framework for real-time uncertainty visualization in B-mode images. We compute real-time per-pixel ultrasound Confidence Maps, which we fuse with the original ultrasound image in order to provide the user with an interactive feedback on the quality and credibility of the image. In addition to a standard color overlay mode, primarily intended for educational purposes, we propose two perceptional visualization schemes to be used in clinical practice. Our mapping of uncertainty to chroma uses the perceptionally uniform L*a*b* color space to ensure that the perceived brightness of B-mode ultrasound remains the same. The alternative mapping of uncertainty to fuzziness keeps the B-mode image in its original grayscale domain and locally blurs or sharpens the image based on the uncertainty distribution. An elaborate evaluation of our system and user studies on both medical students and expert sonographers demonstrate the usefulness of our proposed technique. In particular for ultrasound novices, such as medical students, our technique yields powerful visual cues to evaluate the image quality and thereby learn the ultrasound image formation process. Furthermore, seeing the distribution of uncertainty adjust to the transducer positioning in real-time, provides also expert clinicians with a strong visual feedback on their actions. This helps them to optimize the acoustic window and can improve the general clinical value of ultrasound.",,Christian Schulte Zu Berge;Denis Declara;Christoph Hennersperger;Maximilian Baust;Nassir Navab,;;;;,,"Ultrasound,Uncertainty Visualization,Confidence Maps,Real-time,,",,1,,
SciVis-conf,2015,Auto-calibration of multi-projector displays with a single handheld camera,10.1109/SciVis.2015.7429493,http://dx.doi.org/10.1109/SciVis.2015.7429493,65,72,Conferences,"We present a novel approach that utilizes a simple handheld camera to automatically calibrate multi-projector displays. Most existing studies adopt active structured light patterns to verify the relationship between the camera and the projectors. The utilized camera is typically expensive and requires an elaborate installation process depending on the scalability of its applications. Moreover, the observation of the entire area by the camera is almost impossible for a small space surrounded by walls as there is not enough distance for the camera to capture the entire scene. We tackle these issues by requiring only a portion of the walls to be visible to a handheld camera that is widely used these days. This becomes possible by the introduction of our new structured light pattern scheme based on a perfect submap and a geometric calibration that successfully utilizes the geometric information of multi-planar environments. We demonstrate that immersive display in a small space such as an ordinary room can be effectively created using images captured by a handheld camera.",,Sanghun Park;Hyunggoog Seo;Seunghoon Cha;Junyong Noh,KAIST;KAIST;KAIST;KAIST,,"I.3.3 [Computer Graphics]: Picture/Image Generation — Display algorithms,I.4.1 [Image Processing and Computer Vision]: Digitization and Image Capture — Imaging geometry,I.4.1 [Image Processing and Computer Vision]: Digitization and Image Capture — Camera calibration,I.3.3 [Hardware],Input/Output Devices — Image display,",,3,,
conference_external,2015,Visualize the universe: Interactive exploration of cosmological dark matter simulation data,10.1109/SciVis.2015.7429500,http://dx.doi.org/10.1109/SciVis.2015.7429500,115,135,Conferences,"We propose a unified visualization tool for cosmological data resulting from dark matter simulations. Our system comprises both established and novel visualization approaches for the dark matter tracer particles and halo structures to allow interactive exploration of the data in 3D and 2D as well as tracking the evolution of the data over time using multiple views. Due to our scalable volume rendering approach, properties of the particle data such as the distribution of dark matter can be visualized at interactive frame rates even for large-scale data after a one-time pre-processing conversion step.",,Aaron Scherzinger;Tobias Brix;Dominik Drees;Andreas Volker;Kiril Radkov;Niko Santalidis;Alexander Fieguth;Klaus Hinrichs,University of Munster;University of Munster;University of Munster;University of Munster;University of Munster;University of Munster;University of Munster;University of Munster,,",,,,,",,0,,
conference_external,2015,SciVis international program committee,10.1109/SciVis.2015.7429480,http://dx.doi.org/10.1109/SciVis.2015.7429480,1,1,Conferences,Provides a listing of current committee members and society officers.,,,,,",,,,,",,0,,
conference_external,2015,IEEE visualization and graphics technical committee (VGTC),10.1109/SciVis.2015.7429478,http://dx.doi.org/10.1109/SciVis.2015.7429478,1,1,Conferences,Provides a listing of current committee members and society officers.,,,,,",,,,,",,0,,
conference_external,2015,Preface,10.1109/SciVis.2015.7429477,http://dx.doi.org/10.1109/SciVis.2015.7429477,1,2,Conferences,Presents the introductory welcome message from the conference proceedings. May include the conference officers' congratulations to all involved with the conference event and publication of the proceedings record.,,,,,",,,,,",,0,,
conference_external,2015,VIS conference committee,10.1109/SciVis.2015.7429479,http://dx.doi.org/10.1109/SciVis.2015.7429479,1,1,Conferences,Provides a listing of current committee members and society officers.,,,,,",,,,,",,0,,
conference_external,2015,[Title page],10.1109/SciVis.2015.7429474,http://dx.doi.org/10.1109/SciVis.2015.7429474,1,1,Conferences,The following topics are dealt with: visual analysis; data visualization; 3D flow visualization; trees.,,,,,",,,,,",,0,,
conference_external,2015,Conference papers,10.1109/SciVis.2015.7429476,http://dx.doi.org/10.1109/SciVis.2015.7429476,1,2,Conferences,Presents the table of contents/splash page of the 2015 IEEE Scientific Visualization Conference (SciVis) proceedings record.,,,,,",,,,,",,0,,
conference_external,2015,Papers,10.1109/SciVis.2015.7429484,http://dx.doi.org/10.1109/SciVis.2015.7429484,1,2,Conferences,Start of the above-titled section of the conference proceedings record.,,,,,",,,,,",,0,,
conference_external,2015,Contest,10.1109/SciVis.2015.7429494,http://dx.doi.org/10.1109/SciVis.2015.7429494,1,2,Conferences,Start of the above-titled section of the conference proceedings record.,,,,,",,,,,",,0,,
conference_external,2015,Posters,10.1109/SciVis.2015.7429501,http://dx.doi.org/10.1109/SciVis.2015.7429501,1,2,Conferences,Start of the above-titled section of the conference proceedings record.,,,,,",,,,,",,0,,
conference_external,2015,[Copyright notice],10.1109/SciVis.2015.7429475,http://dx.doi.org/10.1109/SciVis.2015.7429475,1,1,Conferences,Presents the copyright information for the conference. May include reprint permission information.,,,,,",,,,,",,0,,
conference_external,2015,SciVis paper reviewers,10.1109/SciVis.2015.7429481,http://dx.doi.org/10.1109/SciVis.2015.7429481,1,1,Conferences,The conference offers a note of thanks and lists its reviewers.,,,,,",,,,,",,0,,
conference_external,2015,VIS capstone address: Architectures physical and digital,10.1109/SciVis.2015.7429483,http://dx.doi.org/10.1109/SciVis.2015.7429483,1,1,Conferences,"How do computer architectures and physical architectures inform each other? This talk will explore the interconnection of data and visualization through an architectural and computational lens over the last 50 years, including the work of Steven Coons, Christopher Alexander, Richard Saul Wurman and others.",,Molly Wright Steenson,Carnegie Mellon,,",,,,,",,0,,
conference_external,2015,VIS keynote address: An evolving visual language,10.1109/SciVis.2015.7429482,http://dx.doi.org/10.1109/SciVis.2015.7429482,1,1,Conferences,"Visualization of all types of data is a highly effective tool used by researchers to gain insight into natural phenomena and to communicate their findings. It is also an increasingly popular means of presenting large scientific datasets to the general public in informal educational settings such as museums and planetaria. Visualization has appeared in many forms and in many cultures throughout digital history and contributes to the evolving visual language of science. Dr. Donna Cox and the Advanced Visualization Laboratory team at the National Center for Supercomputing Applications, University of Illinois, collaborate with science teams, writers, producers, educators, and media distribution professionals on content designed to engage a wide range of audiences. In the past 8 years alone, her collaborative educational and outreach projects have produced science narratives featuring data visualizations that have been viewed by more than 45 million people worldwide. Cox leads an NSF-funded project to create scientific visualizations and then test audiences' understanding of the phenomenon that is being presented. Large-scale computational data present unique visualization challenges for producers of high-resolution, production-quality 3D IMAX movies; feature films; and museum fulldomes. In this keynote, Cox will provide a visual feast of major projects, including new digital fulldome museum shows and award-winning IMAX films.",,Donna J. Cox,"University of Illinois, Chicago",,",,,,,",,0,,
