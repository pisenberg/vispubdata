Conference,Year,Title,DOI,Link,FirstPage,LastPage,PaperType,Abstract,AuthorNames-Deduped,AuthorNames,AuthorAffiliation,InternalReferences,AuthorKeywords,AminerCitationCount,CitationCount_CrossRef,PubsCited,Award
conference_external,2018,MTDES: Multi-dimensional Temporal Data Exploration System,10.1109/VAST.2018.8802440,https://doi.org/10.1109/VAST.2018.8802440,100,101,Conferences,"This work proposes a visual analytic solution which is well-designed to provide investigative functions with fluent interactions to analyze multi-dimensional temporal data. The solution allows users to view different dimensions of the data at different levels of details with a well-designed mixture of different visualizations and smooth interactions. At the general/overview level, various aggregation strategies are used to reduce data to be visualized, and different sorting procedures are used to cluster correlated data together to help discover patterns. Detail views are provided to explore and confirm/reject the identified patterns. Interaction and smooth transition between views are implemented to enable natural actions while performing analysis tasks. This work also presents the result of applying the solution to the VAST 2018 - Mini-Challenge (MC) 2 dataset, which led to the Strong Support for Exploratory Analysis award for the challenge.",,Vung V. Pham;Tommy Dang,"Computer Science Department, Texas Tech University;Computer Science Department, Texas Tech University",,"Multi-dimensional,temporal data analysis—Heat-map—Line-graph—Interaction Design,,,,,,VAST Challenge 2018—Mini-Challenge 2—Award:Strong Support for Exploratory Analysis—,,,,,,,",,4,,
conference_external,2018,"TimeMatrix: Visual Representation for Temporal Pattern Detection in Dynamic Networks, VAST 2018 Mini-Challenge 3",10.1109/VAST.2018.8802457,https://doi.org/10.1109/VAST.2018.8802457,108,109,Conferences,"This work proposes a visual analytic technique for visualizing temporal pattern detection in networks. The force-directed layout is a popular way to highlight structures of a network however it does not allow to present the dynamic features (how communities change over time). We target this problem by forcing nodes to display vertically and using the horizontal space for representing the timeline of entities. To show the connection between nodes, the edges are drawn vertically to avoid edge-crossings. This work also presents the result of applying the solution to the VAST 2018 - Mini Challenge 3 dataset, which led to the Honorable Mention: Representation of Small-Scale Temporal Patterns for the challenge.",,Tommy Dang;Vung V. Pham,"Computer Science Department, Texas Tech University;Computer Science Department, Texas Tech University",,",,,,,,,,,,,,,,",,1,,
conference_external,2018,Visual Bird Watcher: Interactive Visual Analysis on Bird Distribution and Migration,10.1109/VAST.2018.8802447,https://doi.org/10.1109/VAST.2018.8802447,94,95,Conferences,"VAST Challenge 2018 Mini Challenge 1 presents a challenge to analyze some patterns under the given spatio-temporal data. However, sometimes it is difficult to acquire the underlying ones. Hence we propose an interactive visual analytic system to allow users to get some useful information more efficiently from the data. We manage to meet the challenge using our system to discover the hidden information.",,Chuyue Ye;Sihang Li;Gang Li;Liang Tang;Dengfeng Zhang;Xinyue Luan;Zhuo Zhang;Xiaoru Yuan,"Key Laboratory of Machine Perception (Ministry of Education), School of EECS, Peking University;Key Laboratory of Machine Perception (Ministry of Education), School of EECS, Peking University;Sky Eye Lab, 360 Enterprise Security Corp., Endpoint Security, Inc;Sky Eye Lab, 360 Enterprise Security Corp., Endpoint Security, Inc;Sky Eye Lab, 360 Enterprise Security Corp., Endpoint Security, Inc;Sky Eye Lab, 360 Enterprise Security Corp., Endpoint Security, Inc;Sky Eye Lab, 360 Enterprise Security Corp., Endpoint Security, Inc;Key Laboratory of Machine Perception (Ministry of Education), School of EECS, Peking University",,",,,,,,,,,,,,,,",,1,,
conference_external,2018,A Unified Approach For Sampling And Measurement Joint Analysis,10.1109/VAST.2018.8802453,https://doi.org/10.1109/VAST.2018.8802453,118,120,Conferences,"In this paper we show an alternative approach to the standard data mining tools for detecting outliers both in sampling rates and in the measurements derived from those samples. Our interactive tool fits in the context of the VAST Mini Challenge 2, regarding the alleged chemical dumpings in the Boonsong Lekagul Wildlife Preserve. The approach developed comprises an interactive dashboard built in R using mainly the Plotly and Shiny packages that allows the user to choose the summary statistics for the sample sizes and to select which measurements (e.g. locations, chemicals) to analyse.",,Pablo Santoro;Rubén Flecha;Juan Pablo Pilorget,University of Buenos Aires;University of Buenos Aires;University of Buenos Aires,,"Multivariate Analysis,Statistical Analysis,,,,,,R,Interactive Visualization,,,,,,",,0,,
conference_external,2018,Visual Analysis for Subgroups in a Dynamic Network,10.1109/VAST.2018.8802392,https://doi.org/10.1109/VAST.2018.8802392,106,107,Conferences,"The VAST 2018 company communication dataset reflects current challenges in analyzing specific sub-group within a large dynamic network. We apply multiple visual analytic techniques. This also includes a traceability system, a custom visualization tool enable tracing a focused group on multivariate dynamic networks. We manage to tackle the tasks of abstracting group structural features and discovering other groups tied closely.",,Qi Ma;Xueshi Wei;Liwenhan Xie;Zhiyi Yin;Yiping Liu;Chuanming Huang;Xiaoru Yuan,"Sky Eye Lab, 360 Enterprise Security Corp., Endpoint Security, Inc.;Sky Eye Lab, 360 Enterprise Security Corp., Endpoint Security, Inc.;Key Laboratory of Machine Perception (Ministry of Education), and School of EECS, Peking University;Key Laboratory of Machine Perception (Ministry of Education), and School of EECS, Peking University;Sky Eye Lab, 360 Enterprise Security Corp., Endpoint Security, Inc.;Sky Eye Lab, 360 Enterprise Security Corp., Endpoint Security, Inc.;Key Laboratory of Machine Perception (Ministry of Education), and School of EECS, Peking University",,"Human-centered computing,Visualization,,,,,,Visualization application domains,Visual analytics,,,,,,",,0,,
conference_external,2018,A Visualization Study on Visual Analysis to Explore the Organizational Structure of the Group Within a Factory,10.1109/VAST.2018.8802426,https://doi.org/10.1109/VAST.2018.8802426,129,130,Conferences,"We conducted visual analytics to find out the organizational structure of the group within Kasios Factory. Given nine large scale datasets on communication and purchase information between employees, we utilized Tableau visualization toolset to determine company growth and potiental suspicious employees. Additionaly, we created communication network graphs in R to present interactions between those suspicious employees.",,Bo Sun;Ce Pang,"Department of Computer Science, Rowan University, NJ, USA;Department of Computer Science, Rowan University, NJ, USA",,"Visualization,Visual Analytics,,,,,,Tableau,R,,,,,,",,0,,
conference_external,2018,Using Tableau to Discover the Effect of Chemical Release at Wildlife Preserve,10.1109/VAST.2018.8802430,https://doi.org/10.1109/VAST.2018.8802430,121,122,Conferences,"We viewed visual datasets from chemical testing in the Boonsong Lekagul Wildlife Preserve waterways to determine if any of the chemical readings would prove harmful to the environment. With the amount of data provided, we utilized Tableau to visualize these findings to better understand the trends and anomalies that came with it. We also developed a prediction to what direction the rivers flow, and how each location is related to one another.",,Bo Sun;Benjamin Weidner;Simon Su,"Rowan University, NJ, USA;Rowan University, NJ, USA;U.S. Army Research Lab",,"Visual Analytics,Data Visualization,,,,,,,,,,,,,",,0,,
conference_external,2018,VAST Challenge 2018: Mini-Challenge 1 Award: Applied Visual Data Science,10.1109/VAST.2018.8802505,https://doi.org/10.1109/VAST.2018.8802505,90,91,Conferences,"Effectively combining machine learning techniques and visual analytics to support inferred results is an area of great importance. In this paper, we use the audio collection data provided as part of the 2018 VAST Challenge, which takes place in a fictitious natural preserve where a bird species has been claimed to be endangered by a polluting company. The goal of the mini challenge is to find evidence to support or refute the company's claim that the Rose-Crested Blue Pipit (RCBP) is thriving across the Preserve. This required to characterize the patterns of all the bird species in the Preserve and classify newly collected audio recordings into their corresponding species. Our solution implements multiple visual analysis for spatiotemporal pattern discovery and to support results obtained through a machine learning model.",,Andrei Rukavina;Sergio Banchero,"Master in Data Mining and Knowledge Discovery, Universidad de Buenos Aires;Master in Data Mining and Knowledge Discovery, Universidad de Buenos Aires",,"VAST Challenge,visual analytics,,,,,,audio classification,[Human-centered computing]: Visualization-Visualization systems and tools,,,,,,",,0,,
conference_external,2018,Phoenixmap: Spatio-Temporal Distribution Analysis With Deep Learning Classifications,10.1109/VAST.2018.8802513,https://doi.org/10.1109/VAST.2018.8802513,114,115,Conferences,"In this paper, we introduce PhoenixMap, a visual analytics system to help analysts understand spatiotemporal distribution patterns and anomalies of many objects. It focuses on solving two VA challenges. First, visualizing the spatial distribution of many points under different categories especially when these points partially overlap with each other; Second, employing visual means to classify bird calls using deep learning CNN method. This PhoenixMap system can successfully help us understand the change and patterns of birds regions over many years.",,Junhan Zhao;xiang Liu;Ryan Guan;Josephine Zhang;Baijian Yang;Zhenyu Qian;Yingjie Chen,Purdue University;Purdue University;Naperville North High School;Adlai E.Stevenson High School;Purdue University;Purdue University;Purdue University,,"Human-centered computing,Visualization,,,,,,Visualization design and evaluation methods,,,,,,,",,0,,
conference_external,2018,Interactive Webtool for Tempospatial Data and Visual Audio Analysis : VAST Challenge 2018: Honorable Mention for Interactive Analytic Tool,10.1109/VAST.2018.8802517,https://doi.org/10.1109/VAST.2018.8802517,96,97,Conferences,"To solve VAST Mini Challenge 1, we build an interactive visualization tool that allows hypothesis testing and exploratory analysis of the data. The tool contains different visualizations for metadata and audio data analysis. To analyze the recorded bird calls, we trained a Gradient Boosting-classifier to distinguish different bird species. Our tool integrates these results and visualizes them in combination with additional data allowing the user to get context information and confirm the results.",,Benedikt Bäumle;Ina Boesecke;Raphael Buchmüller;Yannick Metz;Juri Buchmüller;Eren Cakmak;Wolfgang Jentner;Daniel A. Keim,"IEEE Conference on Visual Analytics, Science and Technology (VAST), 21-26 October 2018, University of Konstanz, Berlin, Germany;IEEE Conference on Visual Analytics, Science and Technology (VAST), 21-26 October 2018, University of Konstanz, Berlin, Germany;IEEE Conference on Visual Analytics, Science and Technology (VAST), 21-26 October 2018, University of Konstanz, Berlin, Germany;IEEE Conference on Visual Analytics, Science and Technology (VAST), 21-26 October 2018, University of Konstanz, Berlin, Germany;IEEE Conference on Visual Analytics, Science and Technology (VAST), 21-26 October 2018, University of Konstanz, Berlin, Germany;IEEE Conference on Visual Analytics, Science and Technology (VAST), 21-26 October 2018, University of Konstanz, Berlin, Germany;IEEE Conference on Visual Analytics, Science and Technology (VAST), 21-26 October 2018, University of Konstanz, Berlin, Germany;IEEE Conference on Visual Analytics, Science and Technology (VAST), 21-26 October 2018, University of Konstanz, Berlin, Germany",,"Visual Analytics,Visualization,,,,,,Visualization techniques,,,,,,,",,0,,
conference_external,2018,River-water Quality Exploration,10.1109/VAST.2018.8802460,https://doi.org/10.1109/VAST.2018.8802460,123,124,Conferences,"We describe our analysis of VAST Challenge 2018 Mini-Challenge 2 data set using a collection of visualization tools. We used the tools for better user interaction and to introduce new views in support of visual analytics. We answer some of the challenge questions and plan further research on data exploration and analysis based on the newly introduced data model, interaction, and views.",,Michael Beham;Rainer Splechtna;Denis Gračanin;Elena Ginina;Krešimir Matković,VRVis Research Center;VRVis Research Center;Virginia Tech;VRVis Research Center;VRVis Research Center,,"Human-centered computing,Visualization,,,,,,Visualization Techniques,,,,,,,",,0,,
conference_external,2018,Interactive Classification Using Spectrograms and Audio Glyphs,10.1109/VAST.2018.8802500,https://doi.org/10.1109/VAST.2018.8802500,110,111,Conferences,"Figure 1.(A) Interactive spectrogram and (B) audio glyph - both views (A) and (B) show the same preprocessed supposed audio sample of a pipit call. (A) shows an interactive spectrogram and (B) an audio glyph that maps the spectral roll-off of the audio sample to a global linear color scale. three different bird calls (1-3) are visible in the spectrogram and the audio glyph.The VAST Challenge 2018 aims to clarify the situation of the Rose-Crested Blue Pipit's population in the Boonsong Lekagul Wildlife Preserve. We propose an interactive spectrogram and a representative novel audio glyph to support the classification of bird calls. The second visualization of our system helps to identify spatio-temporal patterns of bird species in the preserve. Using the system, we are able to solve the Mini Challenge 1 (MC1) tasks to classify claimed pipit calls and detect multiple spatio-temporal migratory patterns in the preserve. We find evidence that the pipit population is declining, but we can not identify any clear evidence that the accused company is responsible for the decrease of the pipit population.",,Eren Cakmak;Udo Schlegel;Matthias Miller;Juri Buchmüller;Wolfgang Jentner;Daniel A. Keim,"Data Analysis and Visualization Group, University of Konstanz;Data Analysis and Visualization Group, University of Konstanz;Data Analysis and Visualization Group, University of Konstanz;Data Analysis and Visualization Group, University of Konstanz;Data Analysis and Visualization Group, University of Konstanz;Data Analysis and Visualization Group, University of Konstanz",,"Human-centered computing,Visualization,,,,,,Visualization application domains,Visual Analytics,,,,,,",,0,,
conference_external,2018,VIS Keynote Address : When Visualization Met Augmented Reality,10.1109/VAST.2018.8802427,https://doi.org/10.1109/VAST.2018.8802427,1,1,Conferences,"In the past year, Augmented Reality (AR) has been introduced in several products of premier technology companies, addressing billions of mobile computing users. In particular, a new breed of AR games is engaging and visually appealing. In contrast, non-entertainment applications of AR generally tend to lack sophisticated content. This can be related to the fact that AR developers are only learning how to effectively use the new medium. But it also has to do with the lack of overlap in AR research and visualization research. While AR research has mostly been driven by computer vision with minimal consideration of the visual output, VIS is the field where the perceptual and cognitive foundations of visual information are studied. AR needs VIS! As AR matures, it will be vital to bring the two fields together. VIS needs to address the new medium AR, embracing its two key aspects: mobility and mixed real+virtual perception. AR poses new challenges for VIS, as the visual information needs to adapt to reality rather than shaping the entire visual domain. This talk will discuss fundamental properties of AR visualization and present examples of previous, current and future work.",,Dieter Schmalstieg,"Technische Universitat Graz, Graz, Steiermark, AT",,",,,,,,,,,,,,,,",,0,,
conference_external,2018,Time Series Projection to Highlight Trends and Outliers,10.1109/VAST.2018.8802502,https://doi.org/10.1109/VAST.2018.8802502,104,105,Conferences,"The goal of the VAST Challenge 2018 Mini Challenge 2 (MC 2) was to unveil the possible causes and effects of environmental pollution in the Boonsong Lekagul Wildlife Preserve. We propose the ViCCEx (Visual Chemical Contamination Explorer) system that enables to interactively explore the sparse multivariate river network sensor reading dataset to identify characteristics, trends, and outliers of the different sensor reading locations over time. The ViCCEx system uses a t-SNE projection to display an overview visualization, a sampling strategy view to highlight the overall sampling strategies of different chemical measurements at each sensor location, and various extracted statistics to highlight the evolution of chemical measurements. The three views are connected via linking and brushing, which enables to explore and identify possible pollution causes and effects in the preserve.",,Eren Cakmak;Daniel Seebacher;Juri Buchmüller;Daniel A. Keim,"Data Analysis and Visualization Group, University of Konstanz;Data Analysis and Visualization Group, University of Konstanz;Data Analysis and Visualization Group, University of Konstanz;Data Analysis and Visualization Group, University of Konstanz",,"Human-centered computing,Visualization,,,,,,Visualization application domains,Visual Analytics,,,,,,",,0,,
conference_external,2018,Identifying Patterns and Anomalies within Spatiotemporal Water Sampling Data,10.1109/VAST.2018.8802466,https://doi.org/10.1109/VAST.2018.8802466,98,99,Conferences,"This paper presents our solution to the Mini Challenge 2 (MC2) of the VAST Challenge 2018. We will analyze the provided data set and introduce our visualization tool, which was implemented and tailored to the tasks given by MC2. The tool combines the power of stream graphs, innovative glyph visualizations, box plots, sparklines, heat maps and cross-filter strategies. It allows identifying patterns and anomalies within the provided data set.",,Isabel Piljek;Giuliana Dehn;Jannik Frauendorf;Ziad Salem;Yerzhan Niyazbayev;Juri Buchmüller;Eren Cakmak;Wolfgang Jentner;Florian Stoffel;Daniel A. Keim,"IEEE Conference on Visual Analytics Science and Technology (VAST) 21-26 October 2018, University of Konstanz, Berlin, Germany;IEEE Conference on Visual Analytics Science and Technology (VAST) 21-26 October 2018, University of Konstanz, Berlin, Germany;IEEE Conference on Visual Analytics Science and Technology (VAST) 21-26 October 2018, University of Konstanz, Berlin, Germany;IEEE Conference on Visual Analytics Science and Technology (VAST) 21-26 October 2018, University of Konstanz, Berlin, Germany;IEEE Conference on Visual Analytics Science and Technology (VAST) 21-26 October 2018, University of Konstanz, Berlin, Germany;IEEE Conference on Visual Analytics Science and Technology (VAST) 21-26 October 2018, University of Konstanz, Berlin, Germany;IEEE Conference on Visual Analytics Science and Technology (VAST) 21-26 October 2018, University of Konstanz, Berlin, Germany;IEEE Conference on Visual Analytics Science and Technology (VAST) 21-26 October 2018, University of Konstanz, Berlin, Germany;IEEE Conference on Visual Analytics Science and Technology (VAST) 21-26 October 2018, University of Konstanz, Berlin, Germany;IEEE Conference on Visual Analytics Science and Technology (VAST) 21-26 October 2018, University of Konstanz, Berlin, Germany",,",,,,,,,,,,,,,,",,0,,
conference_external,2018,They do Move! Visual Analytics of Rose-Crested Blue Pipit Habitat,10.1109/VAST.2018.8802397,https://doi.org/10.1109/VAST.2018.8802397,112,113,Conferences,"Figure 1.Analysis workflow: we combine automatic and interactive approach in order to analyze complex data. Neither approach alone would have been sufficient for the analysis.We describe our analysis of VAST Challenge 2018 Mini-Challenge 1. Our approach combines automatic analysis and interactive exploration. We improve user interaction and introduce new views to support analysis. At the same time, we design a convolutional neural network in order to compute a classifier of bird-singing audio files. The classifier and the interactive exploration tool are used to answer some of the challenge questions. Our analysis suggest that the audio files are most probably not of Pipits and, moreover, if there are Pipits among them, they are represented in minority. This finding indicates a need for further investigation.",,Elena Ginina;Michael Beham;Denis Gračanin;Rainer Splechtna;Krešimir Matković,VRVis Research Center;VRVis Research Center;Virginia Tech;VRVis Research Center;VRVis Research Center,,"Human-centered computing,Visualization,,,,,,Visualization Techniques,,,,,,,",,0,,
conference_external,2018,Unearthing the X-Streams: Visualizing Water Contamination : VAST Mini-Challenge 2 Honorable Mention: Clarity of Narrative,10.1109/VAST.2018.8802504,https://doi.org/10.1109/VAST.2018.8802504,102,103,Conferences,"The datasets released for VAST 2018 Mini Challenge 2 pertain to sensor readings capturing chemical concentrations and physical properties from water bodies in the Boonsong Lekagul wildlife preserve. This challenge is in continuation to the VAST 2017 Challenge, where the company Kasios was identified as the culprit in dumping the chemical - Methylosmoline. In the absence of actual chemical measurements in the soil, challenge participants need to visualize chemical contamination based on the proximal water bodies to identify trends of interest. A horizon plot developed helps to narrow down the complete list of 106 chemicals provided to only 7, from where control charts are used to identify change points and periods of abnormal activity. In addition, a sequential sampling strategy to capture differences in chemical patterns along the flow of the river is recommended using a sunburst diagram.",,Akangsha Bandalkul;Angad Srivastava;Kishan Bharadwaj Shridhar;Ong Guan Jie Jason;Zhang Yanrong,Singapore Management University;Singapore Management University;Singapore Management University;Singapore Management University;Singapore Management University,,"Hydrology,Spatiotemporal analysis,,,,,,Horizon plot,Sunburst diagram,,,,,,",,0,,
conference_external,2018,Audio Explorer - VAST Challenge 2018 MC1 (Awarded “Excellent Comprehensive Submission”),10.1109/VAST.2018.8802399,https://doi.org/10.1109/VAST.2018.8802399,92,93,Conferences,"The 2018 VAST Challenge Mini-challenge 1 poses a multifaceted data analysis problem requiring specialized insight into several fields of computing and visual analytics. In this paper we present our tool, Audio Explorer, that combines deep learning classification of audio files with geospatial and auditory visualization techniques in a user-friendly interface designed to promote information discovery.",,Colin Scruggs;Cameron Henkel;Charles D. Stolper,Southwestern University;Southwestern University;Southwestern University,,"Human-centered computing,Visualization,,,,,,Visualization design and evaluation methods,Machine learning,Machine learning approaches,Classification and regression trees,Neural networks,,,",,0,,
conference_external,2018,Contourmap: Contour Based Visualization Of Water Chemical Data,10.1109/VAST.2018.8802508,https://doi.org/10.1109/VAST.2018.8802508,125,126,Conferences,"This paper introduces a novel visual analytics tool to analyze water contamination data. Bar charts and contour maps are used to inspect the data on an aggregate level. In order to identify both spatial and temporal patterns across all areas, we created a series of contour maps and used isolines to aggregate the readings. We also encoded the contours with color such that newer data were on the warmer spectrum (red/orange) and the older data were on the cooler spectrum (blue/green). Through panning, selecting, brushing, and filtering time scale, the user is able to identify patterns of interest in the data sets and highlight problem areas in the Preserve.",,Chen Guo;Ryan Guan;Josephine Zhang;Yingjie Victor Chen;Zhenyu Cheryl Qian,James Madison University;Naperville North High School;Adlai E. Stevenson High School;Purdue University;Purdue University,,"spatiotemporal visualization,visual analytics,,,,,,contour map,small multiples,,,,,,",,0,,
conference_external,2018,Multilevel Visual Clustering Exploration for Incomplete Time-Series in Water Samples,10.1109/VAST.2018.8802480,https://doi.org/10.1109/VAST.2018.8802480,116,117,Conferences,"The VAST 2018 contest provided an opportunity to explore solutions in the pattern identification of 811 incomplete time-series in water samples. In this paper, we present two multilevel approaches (sorted clusters and MCLEAN) to explore and identify trends. Sorted clusters is a combination of clustering with multidimensional scaling to safeguard the similarity in the visualisation of clusters. MCLEAN transforms a multi-dimensional dataset into a network so that it can be investigated at different levels of details.",,Daniel Alcaide;Jan Aerts,"Faculty of Engineering, ESAT/STADIUS, KU Leuven, Belgium;Faculty of Engineering, ESAT/STADIUS, KU Leuven, Belgium",,",,,,,,,,,,,,,,",,0,,
conference_external,2018,VIS Capstone Address: Can I believe what I see?-Information theoretic algorithm validation,10.1109/VAST.2018.8802482,https://doi.org/10.1109/VAST.2018.8802482,1,1,Conferences,"Data Science promises us a methodology and algorithms to gain insights in ubiquitous Big Data. Sophisticated algorithmic techniques seek to identify and visualize non-accidental patterns that may be (causally) linked to mechanisms in the natural sciences, but also in the social sciences, medicine, technology, and governance. When we use machine learning algorithms to inspect the often high-dimensional, uncertain, and high-volume data to filter out and visualize relevant information, we aim to abstract from accidental factors in our experiments and thereby generalize over data fluctuations. Doing this, we often rely on highly nonlinear algorithms. This talk presents arguments advocating an information theoretic framework for algorithm analysis, where an algorithm is characterized as a computational evolution of a posterior distribution on the output space with a quantitative stopping criterion. The method allows us to investigate complex data analysis pipelines, such as those found in computational neuroscience, neurology, and molecular biology. I will demonstrate this concept for the validation of algorithms using the example of a statistical analysis of diffusion tensor imaging data. In addition, on the example of gene expression data, I will demonstrate how different spectral clustering methods can be validated by showing their robustness to data fluctuations and yet sufficient sensitivity to changes in the data. All in all, an information-theoretical method is presented for validating data analysis algorithms, offering the potential of more trustful results in Visual Analytics.",,Joachim M. Buhmann,"Eidgenossische Technische Hochschule Zurich, Zurich, ZH, CH",,",,,,,,,,,,,,,,",,0,,
VAST-conf,2018,Analyzing the Noise Robustness of Deep Neural Networks,10.1109/VAST.2018.8802509,https://doi.org/10.1109/VAST.2018.8802509,60,71,Conferences,"Deep neural networks (DNNs) are vulnerable to maliciously generated adversarial examples. These examples are intentionally designed by making imperceptible perturbations and often mislead a DNN into making an incorrect prediction. This phenomenon means that there is significant risk in applying DNNs to safety-critical applications, such as driverless cars. To address this issue, we present a visual analytics approach to explain the primary cause of the wrong predictions introduced by adversarial examples. The key is to analyze the datapaths of the adversarial examples and compare them with those of the normal examples. A datapath is a group of critical neurons and their connections. To this end, we formulate the datapath extraction as a subset selection problem and approximately solve it based on back-propagation. A multi-level visualization consisting of a segmented DAG (layer level), an Euler diagram (feature map level), and a heat map (neuron level), has been designed to help experts investigate datapaths from the high-level layers to the detailed neuron activations. Two case studies are conducted that demonstrate the promise of our approach in support of explaining the working mechanism of adversarial examples.",,Mengchen Liu;Shixia Liu;Hang Su;Kelei Cao;Jun Zhu,"School of Software, Tsinghua University;School of Software, Tsinghua University;Dept.of Comp.Sci.Tech., Tsinghua University;School of Software, Tsinghua University;Dept.of Comp.Sci.Tech., Tsinghua University",,"Deep neural networks,robustness,,,,,,adversarial examples,back propagation,multi-level visualization.,,,,,",,27,,
VAST-conf,2018,EmbeddingVis: A Visual Analytics Approach to Comparative Network Embedding Inspection,10.1109/VAST.2018.8802454,https://doi.org/10.1109/VAST.2018.8802454,48,59,Conferences,"Constructing latent vector representation for nodes in a network through embedding models has shown its practicality in many graph analysis applications, such as node classification, clustering, and link prediction. However, despite the high efficiency and accuracy of learning an embedding model, people have little clue of what information about the original network is preserved in the embedding vectors. The abstractness of low-dimensional vector representation, stochastic nature of the construction process, and non-transparent hyper-parameters all obscure understanding of network embedding results. Visualization techniques have been introduced to facilitate embedding vector inspection, usually by projecting the embedding space to a two-dimensional display. Although the existing visualization methods allow simple examination of the structure of embedding space, they cannot support in-depth exploration of the embedding vectors. In this paper, we design an exploratory visual analytics system that supports the comparative visual interpretation of embedding vectors at the cluster, instance, and structural levels. To be more specific, it facilitates comparison of what and how node metrics are preserved across different embedding models and investigation of relationships between node metrics and selected embedding vectors. Several case studies confirm the efficacy of our system. Experts' feedback suggests that our approach indeed helps them better embrace the understanding of network embedding models.",,Quan Li;Kristanto Sean Njotoprawiro;Hammad Haleem;Qiaoan Chen;Chris Yi;Xiaojuan Ma,"Department of Computer Science and Engineering, The Hong Kong University of Science and Technology, Hong Kong;Department of Computer Science and Engineering, The Hong Kong University of Science and Technology, Hong Kong;Department of Computer Science and Engineering, The Hong Kong University of Science and Technology, Hong Kong;WeChat, Tencent Technology (Shenzhen) Co., Ltd., Shenzhen, China;WeChat, Tencent Technology (Shenzhen) Co., Ltd., Shenzhen, China;Department of Computer Science and Engineering, The Hong Kong University of Science and Technology, Hong Kong",,"Human-centered computing,Visualization,,,,,,Visualization application domains,Visual analytics,Human-centered computing,Visualization,Visualization design and evaluation methods,,,",,23,,
VAST-conf,2018,The Effect of Semantic Interaction on Foraging in Text Analysis,10.1109/VAST.2018.8802424,https://doi.org/10.1109/VAST.2018.8802424,13,24,Conferences,"Completing text analysis tasks is a continuous sensemaking loop of foraging for information and incrementally synthesizing it into hypotheses. Past research has shown the advantages of using spatial workspaces as a means for synthesizing information through externalizing hypotheses and creating spatial schemas. However, spatializing the entirety of datasets becomes prohibitive as the number of documents available to the analysts grows, particularly when only a small subset are relevant to the task at hand. StarSPIRE is a visual analytics tool designed to explore collections of documents, leveraging users' semantic interactions to steer (1) a synthesis model that aids in document layout, and (2) a foraging model to automatically retrieve new relevant information. In contrast to traditional keyword search foraging (KSF), “semantic interaction foraging” (SIF) occurs as a result of the user's synthesis actions. To quantify the value of semantic interaction foraging, we use StarSPIRE to evaluate its utility for an intelligence analysis sensemaking task. Semantic interaction foraging accounted for 26% of useful documents found, and it also resulted in increased synthesis interactions and improved sensemaking task performance by users in comparison to only using keyword search.",,John Wenskovitch;Lauren Bradel;Michelle Dowling;Leanna House;Chris North,Virginia Tech Computer Science;Department of Defense;Virginia Tech Computer Science;Virginia Tech Statistics;Virginia Tech Computer Science,,"Human-centered computing,Visualization,,,,,,Empirical studies in visualization,Human-centered computing,Visualization,Visual analytics,,,,",,8,,
VAST-conf,2018,VUSphere: Visual Analysis of Video Utilization in Online Distance Education,10.1109/VAST.2018.8802383,https://doi.org/10.1109/VAST.2018.8802383,25,35,Conferences,"Online Distance Education (ODE) provides massive course videos of various specialties for students across the country to learn professional knowledge anytime and anywhere. Analyzing the utilization of these videos from user log data can help academics better understand the learning process of students, evaluate the quality of service provided by regional learning centers, and improve the quality of program curriculum in the future. However, due to the lack of comparable indicators, it is a great challenge to discover the utilization patterns of massive videos and analyze the learning process of large-scale student population from learning log data. In this paper, we introduce a visual analytics system, called VUSphere, to explore the video utilization from multiple perspectives with two proposed indicators. This system offers three coordinated views: a spherical layout overview to depict the overall utilization distribution of videos, courses, and students; a detailed statistics view with four panels to present video utilization statistics of each element from multiple perspectives; and a comparison view to examine the differences in individual elements. Based on the real dataset from our ODE school, several patterns related to video utilization and enrollment are found in the case study with our domain experts.",,Huan He;Oinghua Zheng;Bo Dong,"School of Electronic and Information Engineering, Xi’an Jiaotong University;School of Electronic and Information Engineering, Xi’an Jiaotong University;National Engineering Lab for Big Data Analytics, Xi’an Jiaotong University",,"Video utilization pattern,online distance education,,,,,,visual analytics,,,,,,,",,7,,
VAST-conf,2018,SMARTexplore: Simplifying High-Dimensional Data Analysis through a Table-Based Visual Analytics Approach,10.1109/VAST.2018.8802486,https://doi.org/10.1109/VAST.2018.8802486,36,47,Conferences,"We present SMARTEXPLORE, a novel visual analytics technique that simplifies the identification and understanding of clusters, correlations, and complex patterns in high-dimensional data. The analysis is integrated into an interactive table-based visualization that maintains a consistent and familiar representation throughout the analysis. The visualization is tightly coupled with pattern matching, subspace analysis, reordering, and layout algorithms. To increase the analyst's trust in the revealed patterns, SMARTEXPLORE automatically selects and computes statistical measures based on dimension and data properties. While existing approaches to analyzing high-dimensional data (e.g., planar projections and Parallel coordinates) have proven effective, they typically have steep learning curves for non-visualization experts. Our evaluation, based on three expert case studies, confirms that non-visualization experts successfully reveal patterns in high-dimensional data when using SMARTEXPLORE.",,Michael Blumenschein;Michael Behrisch;Stefanie Schmid;Simon Butscher;Deborah R. Wahl;Karoline Villinger;Britta Renner;Harald Reiterer;Daniel A. Keim,"University of Konstanz, Germany;Harvard University, USA;University of Konstanz, Germany;University of Konstanz, Germany;University of Konstanz, Germany;University of Konstanz, Germany;University of Konstanz, Germany;University of Konstanz, Germany;University of Konstanz, Germany",,"High-dimensional data,visual exploration,,,,,,pattern-driven analysis,tabular visualization,subspace,aggregation,,,,",,4,,
VAST-conf,2018,Segue: Overviewing Evolution Patterns of Egocentric Networks by Interactive Construction of Spatial Layouts,10.1109/VAST.2018.8802415,https://doi.org/10.1109/VAST.2018.8802415,72,83,Conferences,"Getting the overall picture of how a large number of ego-networks evolve is a common yet challenging task. Existing techniques often require analysts to inspect the evolution patterns of ego-networks one after another. In this study, we explore an approach that allows analysts to interactively create spatial layouts in which each dot is a dynamic ego-network. These spatial layouts provide overviews of the evolution patterns of ego-networks, thereby revealing different global patterns such as trends, clusters and outliers in evolution patterns. To let analysts interactively construct interpretable spatial layouts, we propose a data transformation pipeline, with which analysts can adjust the spatial layouts and convert dynamic ego-networks into event sequences to aid interpretations of the spatial positions. Based on this transformation pipeline, we develop Segue, a visual analysis system that supports thorough exploration of the evolution patterns of ego-networks. Through two usage scenarios, we demonstrate how analysts can gain insights into the overall evolution patterns of a large collection of ego-networks by interactively creating different spatial layouts.",,Po-Ming Law;Yanhong Wu;Rahul C. Basole,Georgia Institute of Technology;Visa Research;Georgia Institute of Technology,,"Human-centered computing,Visualization,,,,,,Visualization techniques,Graph drawings,,,,,,",,3,,
conference_external,2018,VAST Challenge 2018: Suspense at the Wildlife Preserve,10.1109/VAST.2018.8802465,https://doi.org/10.1109/VAST.2018.8802465,84,89,Conferences,"The 2018 VAST Challenge returns to the (fictional) city of Mistford and the Boonsong Lekagul Wildlife Preserve to pose three MiniChallenges surrounding the nefarious Kasios Furniture Company and the fate of the Rose-Crested Blue Pipit. For Mini-Challenge 1, participants performed classification on a collection of bird song recordings to help experts understand the changing population dynamics within the preserve. Mini-Challenge 2 introduced new hydrology evidence in a spatiotemporal challenge, asking participants to trace the transmission of various chemicals through the preserve's waterways. In Mini-Challenge 3, participants took their analysis global, examining suspicious connections in Kasios' international business dealings in a massive graph challenge.",,R. Jordan Crouser;Kristin Cook;John Fallon;Jereme Haack;Kristen Liggett;Mark Whiting;Diane Staheli,Smith College;Pacific Northwest National Laboratory;University of Massachusetts Amherst;Pacific Northwest National Laboratory;Air Force Research Laboratory;Pacific Northwest National Laboratory;MIT Lincoln Laboratory,,",,,,,,,,,,,,,,",,1,,
VAST-conf,2018,The Effect of Proximity in Social Data Charts on Perceived Unity,10.1109/VAST.2018.8802449,https://doi.org/10.1109/VAST.2018.8802449,1,12,Conferences,"Social data charts - visual presentations of quantitative data about peer behaviors - may offer new means to motivate individuals to participate in group goals. However, to do so these charts need to create a semantic response of `unity' among the chart viewers in order to overcome the problems of social loafing where people act selfishly and undervalue the group's goal. In this paper, we focus on two properties of social data charts that may affect a viewer's perceptions of unity: (1) The skewness in the data structure - the statistical distribution of the social data, and (2) the proximity in the visual structure of the chart - the spatial organization of the data points. We performed a controlled perceptual experiment to examine the effect of proximity and skewness on four different semantic facets of perceived group unity: similarity, entitativity, rapport, and centrality. We exposed 179 participants on Amazon Mechanical Turk to different group charts using a 2 x 2 factorial design, varying both proximity and skewness. Our two-way ANCOVA analyses reveal three important findings: (1) Across all conditions, proximity has a strong positive effect on perceived group unity and conveys a social meaning of group entitativity, as well as, member similarity and rapport; (2) Skewness and proximity interact in a non-linear way, suggesting that skewness creates a negative force that modifies the semantic responses to high proximity; and (3) The perceptual responses to proximity have different semantic facets that are either stable or sensitive to skewness. These findings contribute to perceptual as well as social InfoVis literature.",,Marlen Promann;Sabine Brunswicker,Purdue University;Purdue University,,"Social visualization,information visualization,Human-centered computing,Empirical studies in HCI,Displays and imagers,Social engineering (social sciences),Visualization theory, concepts and paradigms,Gestalt theory,controlled experiment,data density,data spread,perception,group identity,unity,priming",,0,,
conference_external,2018,VAST 2018 Preface,10.1109/VAST.2018.8802371,https://doi.org/10.1109/VAST.2018.8802371,i,i,Conferences,Presents the introductory welcome message from the conference proceedings. May include the conference officers' congratulations to all involved with the conference event and publication of the proceedings record.,,,,,",,,,,,,,,,,,,,",,0,,
conference_external,2018,VAST 2018 Steering Committee,10.1109/VAST.2018.8802410,https://doi.org/10.1109/VAST.2018.8802410,i,i,Conferences,Provides a listing of current committee members and society officers.,,,,,",,,,,,,,,,,,,,",,0,,
conference_external,2018,VAST 2018 IEEE Visualization and Graphics Technical Committee,10.1109/VAST.2018.8802442,https://doi.org/10.1109/VAST.2018.8802442,i,i,Conferences,Provides a listing of current committee members and society officers.,,,,,",,,,,,,,,,,,,,",,0,,
conference_external,2018,VAST 2018 International Program Committee,10.1109/VAST.2018.8802411,https://doi.org/10.1109/VAST.2018.8802411,i,i,Conferences,Provides a listing of current committee members and society officers.,,,,,",,,,,,,,,,,,,,",,0,,
conference_external,2018,VAST 2018 VIS Conference Committee,10.1109/VAST.2018.8802439,https://doi.org/10.1109/VAST.2018.8802439,i,i,Conferences,Provides a listing of current committee members and society officers.,,,,,",,,,,,,,,,,,,,",,0,,
conference_external,2018,[VAST 2018 Title page],10.1109/VAST.2018.8802497,https://doi.org/10.1109/VAST.2018.8802497,i,i,Conferences,Presents the title page of the proceedings record.,,,,,",,,,,,,,,,,,,,",,0,,
conference_external,2018,[Copyright notice],10.1109/VAST.2018.8802404,https://doi.org/10.1109/VAST.2018.8802404,i,i,Conferences,Presents the copyright information for the conference. May include reprint permission information.,,,,,",,,,,,,,,,,,,,",,0,,
conference_external,2018,VAST 2018 Paper Reviewers,10.1109/VAST.2018.8802373,https://doi.org/10.1109/VAST.2018.8802373,i,i,Conferences,The conference offers a note of thanks and lists its reviewers.,,,,,",,,,,,,,,,,,,,",,0,,
conference_external,2018,Table of contents,10.1109/VAST.2018.8802372,https://doi.org/10.1109/VAST.2018.8802372,i,iii,Conferences,Presents the table of contents/splash page of the proceedings record.,,,,,",,,,,,,,,,,,,,",,0,,
