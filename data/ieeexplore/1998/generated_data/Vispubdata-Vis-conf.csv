Conference,Year,Title,DOI,Link,FirstPage,LastPage,PaperType,Abstract,AuthorNames-Deduped,AuthorNames,AuthorAffiliation,InternalReferences,AuthorKeywords,AminerCitationCount,CitationCount_CrossRef,PubsCited,Award
Vis-conf,1998,Smooth view-dependent level-of-detail control and its application to terrain rendering,10.1109/VISUAL.1998.745282,https://doi.org/10.1109/VISUAL.1998.745282,35,42,Conferences,"The key to real-time rendering of large-scale surfaces is to locally adapt surface geometric complexity to changing view parameters. Several schemes have been developed to address this problem of view-dependent level-of-detail control. Among these, the view-dependent progressive mesh (VDPM) framework represents an arbitrary triangle mesh as a hierarchy of geometrically optimized refinement transformations, from which accurate approximating meshes can be efficiently retrieved. In this paper we extend the general VDPM framework to provide temporal coherence through the run-time creation of geomorphs. These geomorphs eliminate ""popping"" artifacts by smoothly interpolating geometry. Their implementation requires new output-sensitive data structures, which have the added benefit of reducing memory use. We specialize the VDPM framework to the important case of terrain rendering. To handle huge terrain grids, we introduce a block-based simplification scheme that constructs a progressive mesh as a hierarchy of block refinements. We demonstrate the need for an accurate approximation metric during simplification. Our contributions are highlighted in a real-time flyover of a large, rugged terrain. Notably, the use of geomorphs results in visually smooth rendering even at 72 frames/sec on a graphics workstation.",,H. Hoppe,"Microsoft Research, USA",,,,192,,
Vis-conf,1998,Fast and memory efficient polygonal simplification,10.1109/VISUAL.1998.745314,https://doi.org/10.1109/VISUAL.1998.745314,279,286,Conferences,"Conventional wisdom says that in order to produce high-quality simplified polygonal models, one must retain and use information about the original model during the simplification process. We demonstrate that excellent simplified models can be produced without the need to compare against information from the original geometry while performing local changes to the model. We use edge collapses to perform simplification, as do a number of other methods. We select the position of the new vertex so that the original volume of the model is maintained and we minimize the per-triangle change in volume of the tetrahedra swept out by those triangles that are moved. We also maintain surface area near boundaries and minimize the per-triangle area changes. Calculating the edge collapse priorities and the positions of the new vertices requires only the face connectivity and the the vertex locations in the intermediate model. This approach is memory efficient, allowing the simplification of very large polygonal models, and it is also fast. Moreover, simplified models created using this technique compare favorably to a number of other published simplification methods in terms of mean geometric error.",,P. Lindstrom;G. Turk,"Georgia Institute of Technology, USA;Georgia Institute of Technology, USA",,,,121,,
Vis-conf,1998,Interactive ray tracing for isosurface rendering,10.1109/VISUAL.1998.745713,https://doi.org/10.1109/VISUAL.1998.745713,233,238,Conferences,"We show that it is feasible to perform interactive isosurfacing of very large rectilinear datasets with brute-force ray tracing on a conventional (distributed) shared-memory multiprocessor machine. Rather than generate geometry representing the isosurface and render with a z-buffer, for each pixel we trace a ray through a volume and do an analytic isosurface intersection computation. Although this method has a high intrinsic computational cost, its simplicity and scalability make it ideal for large datasets on current high-end systems. Incorporating simple optimizations, such as volume bricking and a shallow hierarchy, enables interactive rendering (i.e. 10 frames per second) of the 1 GByte full resolution Visible Woman dataset on an SGI Reality Monster. The graphics capabilities of the Reality Monster are used only for display of the final color image.",,S. Parker;P. Shirley;Y. Livnat;C. Hansen;P.-P. Sloan,"Computer Science Department, University of Utah, USA;Computer Science Department, University of Utah, USA;Computer Science Department, University of Utah, USA;Computer Science Department, University of Utah, USA;Computer Science Department, University of Utah, USA",,,,117,,
Vis-conf,1998,Visualizing diffusion tensor images of the mouse spinal cord,10.1109/VISUAL.1998.745294,https://doi.org/10.1109/VISUAL.1998.745294,127,134,Conferences,"Within biological systems, water molecules undergo continuous stochastic Brownian motion. The diffusion rate can give clues to the structure of the underlying tissues. In some tissues, the rate is anisotropic. Diffusion-rate images can be calculated from diffusion-weighted MRI. A 2D diffusion tensor image (DTI) and an associated anatomical scalar field define seven values at each spatial location. We present two new methods for visually representing DTIs. The first method displays an array of ellipsoids, where the shape of each ellipsoid represents one tensor value. The ellipsoids are all normalized to approximately the same size so that they can be displayed simultaneously in context. The second method uses concepts from oil painting to represent the seven-valued data with multiple layers of varying brush strokes. Both methods successfully display most or all of the information in DTIs and provide exploratory methods for understanding them. The ellipsoid method has a simpler interpretation and explanation than the painting-motivated method; the painting-motivated method displays more of the information and is easier to read quantatively. We demonstrate the methods on images of the mouse spinal cord. The visualizations show significant differences between spinal cords from mice suffering from experimental allergic encephalomyelitis and spinal cords from wild-type mice. The differences are consistent with differences shown histologically and suggest that our new non-invasive imaging methodology and visualization of the results could have early diagnostic value for neurodegenerative diseases.",,D.H. Laidlaw;E.T. Ahrens;D. Kremers;M.J. Avalos;R.E. Jacobs;C. Readhead,"California Institute of Technology, Pasadena, CA, USA;California Institute of Technology, Pasadena, CA, USA;California Institute of Technology, Pasadena, CA, USA;California Institute of Technology, Pasadena, CA, USA;California Institute of Technology, Pasadena, CA, USA;Cedars Sinai Medical Center, Los Angeles, CA, USA",,,,64,,
Vis-conf,1998,Interactive out-of-core isosurface extraction,10.1109/VISUAL.1998.745299,https://doi.org/10.1109/VISUAL.1998.745299,167,174,Conferences,"We present a novel out-of-core technique for the interactive computation of isosurfaces from volume data. Our algorithm minimizes the main memory and disk space requirements on the visualization workstation, while speeding up isosurface extraction queries. Our overall approach is a two-level indexing scheme. First, by our meta-cell technique, we partition the original dataset into clusters of cells, called meta-cells. Secondly, we produce meta-intervals associated with the meta-cells, and build an indexing data structure on the meta-intervals. We separate the cell information, kept only in meta-cells on disk, from the indexing structure, which is also on disk and only contains pointers to meta-cells. Our meta-cell technique is an I/O-efficient approach for computing a k-d-tree-like partition of the dataset. Our indexing data structure, the binary blocked I/O interval tree, is a new I/O-optimal data structure to perform stabbing queries that report from a set of meta-intervals (or intervals) those containing a query value q. Our tree is simpler to implement, and is also more space-efficient in practice than existing structures. To perform an isosurface query, we first query the indexing structure, and then use the reported meta-cell pointers to read from disk the active meta-cells intersected by the isosurface. The isosurface itself can then be generated from active meta-cells. Rather than being a single cost indexing approach, our technique exhibits a smooth trade-off between query time and disk space.",,Y.-J. Chiang;C.T. Silva;W.J. Schroeder,"Polytechnic University, USA;IBM Thomas J. Watson Research Center, USA;Kitware Inc.orporate",,,,53,,
Vis-conf,1998,High quality rendering of attributed volume data,10.1109/VISUAL.1998.745311,https://doi.org/10.1109/VISUAL.1998.745311,255,262,Conferences,"For high quality rendering of objects segmented from tomographic volume data the precise location of the boundaries of adjacent objects in subvoxel resolution is required. We describe a new method that determines the membership of a given sample point to an object by reclassifying the sample point using interpolation of the original intensity values and searching for the best fitting object in the neighbourhood. Using a ray-casting approach we then compute the surface location between successive sample points along the viewing-ray by interpolation or bisection. The accurate calculation of the object boundary enables a much more precise computation of the gray-level-gradient yielding the surface normal. Our new approach significantly improves the quality of reconstructed and shaded surfaces and reduces aliasing artifacts for animations and magnified views. We illustrate the results on different cases including the Visible-Human-Data, where we achieve nearly photo-realistic images.",,U. Tiede;T. Schiemann;K.H. Hohne,"Institute of Mathematics and Computer Science in Medicine, University Hospital Eppendorf, Hamburg, Germany;Institute of Mathematics and Computer Science in Medicine, University Hospital Eppendorf, Hamburg, Germany;Institute of Mathematics and Computer Science in Medicine, University Hospital Eppendorf, Hamburg, Germany",,,,44,,
Vis-conf,1998,Progressive tetrahedralizations,10.1109/VISUAL.1998.745329,https://doi.org/10.1109/VISUAL.1998.745329,397,402,Conferences,"The paper describes some fundamental issues for robust implementations of progressively refined tetrahedralizations generated through sequences of edge collapses. We address the definition of appropriate cost functions and explain on various tests which are necessary to preserve the consistency of the mesh when collapsing edges. Although considered a special case of progressive simplicial complexes (J. Popovic and H. Hoppe, 1997), the results of our method are of high practical importance and can be used in many different applications, such as finite element meshing, scattered data interpolation, or rendering of unstructured volume data.",,O.G. Staadt;M.H. Gross,"Computer Graphics Research Group, Department of Computer Science, Swiss Federal Institute of Technology, Zurich, Switzerland;Computer Graphics Research Group, Department of Computer Science, Swiss Federal Institute of Technology, Zurich, Switzerland",,,,44,,
Vis-conf,1998,View dependent isosurface extraction,10.1109/VISUAL.1998.745300,https://doi.org/10.1109/VISUAL.1998.745300,175,180,Conferences,"We propose a new approach to polygonal isosurface extraction that is based on extracting only the visible portion of the isosurface. The visibility tests are done in two phases. First, coarse visibility tests are performed in software to determine the visible cells. These tests are based on hierarchical tiles and shear-warp factorization. The second phase resolves the visible portions of the extracted triangles and is accomplished by the graphics hardware. While the latest isosurface extraction methods have effectively eliminated the search phase bottleneck, the cost of constructing and rendering the isosurface remains high. Many of today's large datasets contain very large and complex isosurfaces that can easily overwhelm even state-of-the-art graphics hardware. The proposed approach is output sensitive and is thus well suited for remote visualization applications where the extraction and rendering phases are done on a separate machines.",,Y. Livnat;C. Hansen,"University of Utah, USA;University of Utah, USA",,,,43,,
Vis-conf,1998,Efficient implementation of multi-triangulations,10.1109/VISUAL.1998.745283,https://doi.org/10.1109/VISUAL.1998.745283,43,50,Conferences,"Multi-triangulation (MT) is a general framework for managing the level-of-detail in large triangle meshes, which we have introduced in our previous work. In this paper, we describe an efficient implementation of an MT based on vertex decimation. We present general techniques for querying an MT, which are independent of a specific application, and which can be applied for solving problems, such as selective refinement, windowing, point location, and other spatial interference queries. We describe alternative data structures for encoding an MT, which achieve different trade-offs between space and performance. Experimental results are discussed.",,L. De Floriani;P. Magillo;E. Puppo,"Dipartimento di Informatica e Scienze dellInformazione, Universita di Genova, Genoa, Italy;Dipartimento di Informatica e Scienze dellInformazione, Universita di Genova, Genoa, Italy;Istituto per la Matematica Applicata, Consiglio Nationale delle Ricerche, Genoa, Italy",,,,37,,
Vis-conf,1998,Surface reconstruction with anisotropic density-scaled alpha shapes,10.1109/VISUAL.1998.745286,https://doi.org/10.1109/VISUAL.1998.745286,67,72,Conferences,"Generation of a three-dimensional model from an unorganized set of points is an active area of research in computer graphics. Alpha shapes can be employed to construct a surface which most closely reflects the object described by the points. However, no /spl alpha/-shape, for any value of /spl alpha/, can properly detail discontinuous regions of a model. We introduce herein two methods of improving the results of reconstruction using /spl alpha/-shapes: density-scaling, which modulates the value of a depending on the density of points in a region; and anisotropic shaping, which modulates the form of the /spl alpha/-ball based on point normals. We give experimental results that show the successes and limitations of our method.",,M. Teichmann;M. Capps,"Laboratory for Computer Science, Massachusetts Institute of Technology, USA;Laboratory for Computer Science, Massachusetts Institute of Technology, USA",,,,33,,
Vis-conf,1998,Selective visualization of vortices in hydrodynamic flows,10.1109/VISUAL.1998.745333,https://doi.org/10.1109/VISUAL.1998.745333,419,422,Conferences,"Vortices are important features in many research and engineering fields. Visualization is an important step in gaining more understanding and control of vortices. Vortex detection criteria fall into two categories: point based scalar quantities, calculated at single points, and curve based geometric criteria, calculated for, e.g., streamlines. The first category is easy to compute, but does not work in all cases. The second category is more intuitive and should work in all cases, but currently only works in 2D (or 3D projected) flows. We show applications of both approaches in hydrodynamic flows.",,I.A. Sadarjoen;F.H. Post;Bing Ma;D.C. Banks;H.-G. Pagendarm,"Department of Computer Science, Delft University of Technnology, Delft, Netherlands;Department of Computer Science, Delft University of Technnology, Delft, Netherlands;Laboratory for Aero and Hydrodynamics,Delft University of Technology, Tsinghua University, Beijing, China;Department of Computer Science, Mississippi State University, USA;DLR: Deutsches Zentrum für Luft-und Raumfahrt, German Aerospace Center, Germany",,,,29,,
Vis-conf,1998,Image-based transfer function design for data exploration in volume visualization,10.1109/VISUAL.1998.745319,https://doi.org/10.1109/VISUAL.1998.745319,319,326,Conferences,"Transfer function design is an integrated component in volume visualization and data exploration. The common trial-and-error approach for transfer function searching is a very difficult and time consuming process. A goal oriented and parameterized transfer function model is therefore crucial in guiding the transfer function searching process for better and more meaningful visualization results. The paper presents an image based transfer function model that integrates 3D image processing tools into the volume visualization pipeline to facilitate the search for an image based transfer function in volume data visualization and exploration. The model defines a transfer function as a sequence of 3D image processing procedures, and allows the users to adjust a set of qualitative and descriptive parameters to achieve their subjective visualization goals. 3D image enhancement and boundary detection tools, and their integration methods with volume visualization algorithms are described. The application of this approach for 3D microscopy data exploration and analysis is also discussed.",,Shiaofen Fang;T. Biddlecome;M. Tuceryan,"Department of Computer and Information Science, Indiana University-Purdue University Indianapolis, USA;Department of Computer and Information Science, Indiana University-Purdue University Indianapolis, USA;Department of Computer and Information Science, Indiana University-Purdue University Indianapolis, USA",,,,27,,
Vis-conf,1998,Feature comparisons of vector fields using Earth mover's distance,10.1109/VISUAL.1998.745291,https://doi.org/10.1109/VISUAL.1998.745291,103,109,Conferences,"A novel approach is introduced to define a quantitative measure of closeness between vector fields. The usefulness of this measurement can be seen when comparing computational and experimental flow fields under the same conditions. Furthermore, its applicability can be extended to more cumbersome tasks, such as navigating through a large database, searching for similar topologies. This new measure relies on the use of critical points, which are a key feature in vector field topology. In order to characterize critical points, /spl alpha/ and /spl beta/ parameters are introduced. They are used to form a closed set of eight unique patterns for simple critical points. These patterns are also basic building blocks for higher-order nonlinear vector fields. In order to study and compare a given set of vector fields, a measure of distance between different patterns of critical points is introduced. The basic patterns of critical points are mapped onto a unit circle in /spl alpha/-/spl beta/ space. The concept of the ""Earth mover's distance"" is used to compute the closeness between various pairs of vector fields, and a nearest-neighbor query is thus produced to illustrate the relationship between the given set of vector fields. This approach quantitatively measures the similarity and dissimilarity between vector fields. It is ideal for data compression of a large flow field, since only the number and types of critical points along with their corresponding /spl alpha/ and /spl beta/ parameters are necessary to reconstruct the whole field. It can also be used to better quantify the changes in time-varying data sets.",,Y. Lavin;R. Batra;L. Hesselink,"Department of Physics, University of Stanford, Stanford, CA, USA;Department of Aeronautics and Astronautics, University of Stanford, Stanford, CA, USA;Department of Electrical Engineering, University of Stanford, Stanford, CA, USA",,,,27,,
Vis-conf,1998,A general method for preserving attribute values on simplified meshes,10.1109/VISUAL.1998.745285,https://doi.org/10.1109/VISUAL.1998.745285,59,66,Conferences,"Many sophisticated solutions have been proposed to reduce the geometric complexity of 3D meshes. A problem studied less often is how to preserve on a simplified mesh the detail (e.g., color, high frequency shape detail, scalar fields, etc.) which is encoded in the original mesh. We present a general approach for preserving detail on simplified meshes. The detail (or high frequency information) lost after simplification is encoded through texture or bump maps. The original contribution is that preservation is performed after simplification, by building set of triangular texture patches that are then packed in a single texture map. Each simplified mesh face is sampled to build the associated triangular texture patch; a new method for storing this set of texture patches into a standard rectangular texture is presented and discussed. Our detail preserving approach makes no assumptions about the simplification process adopted to reduce mesh complexity and allows highly efficient rendering. The solution is very general, allowing preservation of any attribute value defined on the high resolution mesh. We also describe an alternative application: the conversion of 3D models with 3D static procedural textures into standard 3D models with 2D textures.",,P. Cignoni;C. Montani;C. Rocchini;R. Scopigno,"Istituto di Elaborazione dell'Informazione, Consiglio Nationale delle Ricerche, Italy;Istituto di Elaborazione dell'Informazione, Consiglio Nationale delle Ricerche, Italy;Istituto di Elaborazione dell'Informazione, Consiglio Nationale delle Ricerche, Italy;Istituto di Elaborazione dell'Informazione, Consiglio Nationale delle Ricerche, Italy",,,,26,,
Vis-conf,1998,Isosurface extraction in time-varying fields using a temporal hierarchical index tree,10.1109/VISUAL.1998.745298,https://doi.org/10.1109/VISUAL.1998.745298,159,166,Conferences,"Many high-performance isosurface extraction algorithms have been proposed in the past several years as a result of intensive research efforts. When applying these algorithms to large-scale time-varying fields, the storage overhead incurred from storing the search index often becomes overwhelming. This paper proposes an algorithm for locating isosurface cells in time-varying fields. We devise a new data structure, called the temporal hierarchical index tree, which utilizes the temporal coherence that exists in a time-varying field and adaptively coalesces the cells' extreme values over time; the resulting extreme values are then used to create the isosurface cell search index. For a typical time-varying scalar data set, not only does this temporal hierarchical index tree require much less storage space, but also the amount of I/O required to access the indices from the disk at different time steps is substantially reduced. We illustrate the utility and speed of our algorithm with data from several large-scale time-varying CFD simulations. Our algorithm can achieve more than 80% of disk-space savings when compared with the existing techniques, while the isosurface extraction time is nearly optimal.",,H.-W. Shen,"MRJ Technology Solutions, Moffett Field, CA, USA",,,,25,,
Vis-conf,1998,Continuous cartogram construction,10.1109/VISUAL.1998.745303,https://doi.org/10.1109/VISUAL.1998.745303,197,204,Conferences,"Area cartograms are used for visualizing geographically distributed data by attaching measurements to regions of a map and scaling the regions such that their areas are proportional to the measured quantities. A continuous area cartogram is a cartogram that is constructed without changing the underlying map topology. We present a new algorithm for the construction of continuous area cartograms that was developed by viewing their construction as a constrained optimization problem. The algorithm uses a relaxation method that exploits hierarchical resolution, constrained dynamics, and a scheme that alternates goals of achieving correct region areas and adjusting region shapes. It is compared favorably to existing methods in its ability to preserve region shape recognition cues, while still achieving high accuracy.",,D.H. House;C.J. Kocmoud,"Visualization Lab., Texas A&M Univ., College Station, TX, USA;Texas Engineering Experiment Station, College Station, TX, USA",,,,25,,
Vis-conf,1998,Simplification of tetrahedral meshes,10.1109/VISUAL.1998.745315,https://doi.org/10.1109/VISUAL.1998.745315,287,295,Conferences,"We present a method for the construction of multiple levels of tetrahedral meshes approximating a trivariate function at different levels of detail. Starting with an initial, high-resolution triangulation of a three-dimensional region, we construct coarser representation levels by collapsing tetrahedra. Each triangulation defines a linear spline function, where the function values associated with the vertices are the spline coefficients. Based on predicted errors, we collapse tetrahedron in the grid that do not cause the maximum error to exceed a use-specified threshold. Bounds are stored for individual tetrahedra and are updated as the mesh is simplified. We continue the simplification process until a certain error is reached. The result is a hierarchical data description suited for the efficient visualization of large data sets at varying levels of detail.",,I.J. Trotts;B. Hamann;K.I. Joy;D.F. Wiley,"Center for Image Processing and Integrated Computing, Department of Computer Science, University of California, Davis, USA;Center for Image Processing and Integrated Computing, Department of Computer Science, University of California, Davis, USA;Center for Image Processing and Integrated Computing, Department of Computer Science, University of California, Davis, USA;Center for Image Processing and Integrated Computing, Department of Computer Science, University of California, Davis, USA",,,,25,,
Vis-conf,1998,Real-time techniques for 3D flow visualization,10.1109/VISUAL.1998.745317,https://doi.org/10.1109/VISUAL.1998.745317,305,312,Conferences,"Visualization of three-dimensional steady flow has to overcome a lot of problems to be effective. Among them are occlusion of distant details, lack of directional and depth hints and occlusion. We present methods which address these problems for real-time graphic representations applicable in virtual environments. We use dashtubes, i.e., animated, opacity-mapped streamlines, as a visualization icon for 3D-flow visualization. We present a texture mapping technique to keep the level of texture detail along a streamline nearly constant even when the velocity of the flow varies considerably. An algorithm is described which distributes the dashtubes evenly in space. We apply magic lenses and magic boxes as interaction techniques for investigating densely filled areas without overwhelming the observer with visual detail. Implementation details of these methods and their integration in our virtual environment conclude the paper.",,A. Fuhrmann;E. Groller,"Universitat Wien, Wien, Wien, AT;",,,,25,,
Vis-conf,1998,Image-guided streamline placement on curvilinear grid surfaces,10.1109/VISUAL.1998.745295,https://doi.org/10.1109/VISUAL.1998.745295,135,142,Conferences,"The success of using a streamline technique for visualizing a vector field usually depends largely on the choice of adequate seed points. G. Turk and D. Banks (1996) developed an elegant technique for automatically placing seed points to achieve a uniform distribution of streamlines on a 2D vector field. Their method uses an energy function calculated from the low-pass filtered streamline image to guide the optimization process of the streamline distribution. This paper proposes a new technique for creating evenly distributed streamlines on 3D parametric surfaces found in curvilinear grids. We make use of Turk and Banks's 2D algorithm by first mapping the vectors on a 3D surface into the computational space of the curvilinear grid. To take into the consideration the mapping distortion caused by the uneven grid density in a curvilinear grid, a new energy function is designed and used for guiding the placement of streamlines in the computational space with desired local densities.",,X. Mao;Y. Hatanaka;H. Higashida;A. Imamiya,"Department of Computer and Media Engineering, Yamanashi University, Kofu, Yamanashi, Japan;Department of Computer and Media Engineering, Yamanashi University, Kofu, Yamanashi, Japan;Department of Computer and Media Engineering, Yamanashi University, Kofu, Yamanashi, Japan;Department of Computer and Media Engineering, Yamanashi University, Kofu, Yamanashi, Japan",,,,23,,
Vis-conf,1998,Visualization of scalar topology for structural enhancement,10.1109/VISUAL.1998.745284,https://doi.org/10.1109/VISUAL.1998.745284,51,58,Conferences,"Scalar fields arise in every scientific application. Existing scalar visualization techniques require that the user infers the global scalar structure from what is frequently an insufficient display of information. We present a visualization technique which numerically detects the structure at all scales, removing from the user the responsibility of extracting information implicit in the data, and presenting the structure explicitly for analysis. We further demonstrate how scalar topology detection proves useful for correct visualization and image processing applications such as image co-registration, isocontouring, and mesh compression.",,C.L. Bajaj;V. Pascucci;D.R. Schikore,"Department of Computer Sciences and TICAM, University of Technology, Austin, TX, USA;Department of Computer Sciences and TICAM, University of Technology, Austin, TX, USA;Lawrence Livermore National Laboratory, Center for Applied Scientific Computing, Livermore, CA, USA",,,,22,,
Vis-conf,1998,Interactive virtual angioscopy,10.1109/VISUAL.1998.745337,https://doi.org/10.1109/VISUAL.1998.745337,435,438,Conferences,"Virtual angioscopy is a non invasive medical procedure for exploring parts of the human vascular system. We have developed an interactive tool that takes as input, data acquired with standard medical imaging modalities and regards it as a virtual environment to be interactively inspected. The system supports real time navigation with stereoscopic direct volume rendering and dynamic endoscopic camera control, interactive tissue classification, and interactive point picking for morphological feature measurement. We provide an overview of the system, discuss the techniques used in our prototype, and present experimental results on human data sets.",,E. Gobbetti;P. Pili;A. Zorcolo;M. Tuveri,"Center for Advanced Studies, CRS4, Research and Development in Sardinia, Cagliari, Italy;Center for Advanced Studies, CRS4, Research and Development in Sardinia, Cagliari, Italy;Center for Advanced Studies, CRS4, Research and Development in Sardinia, Cagliari, Italy;",,,,19,,
Vis-conf,1998,Efficient warping for architectural walkthroughs using layered depth images,10.1109/VISUAL.1998.745305,https://doi.org/10.1109/VISUAL.1998.745305,211,215,Conferences,"This paper presents efficient image-based rendering techniques used in the context of an architectural walkthrough system. Portals (doors and windows) are rendered by warping layered depth images (LDIs). In a preprocessing phase, for every portal, a number of pre-rendered images are combined into an LDI. The resulting LDI stores, exactly once, all surfaces visible in at least one of the images used in the construction, so most of the exposure errors are efficiently eliminated. The LDI can be warped in the McMillan occlusion compatible ordering. A substantial increase in performance is obtained by warping in parallel. Our parallelization scheme achieves good load balancing, scales with the number of processors, and preserves the occlusion compatible ordering. A fast, conservative reference-image-space clipping algorithm also reduces the warping effort.",,V. Popescu;A. Lastra;D. Aliaga;M. de Oliveira Neto,"University of North Carolina, Chapel Hill, USA;University of North Carolina, Chapel Hill, USA;University of North Carolina, Chapel Hill, USA;University of North Carolina, Chapel Hill, USA",,,,18,,
Vis-conf,1998,Feature detection in linked derived spaces,10.1109/VISUAL.1998.745289,https://doi.org/10.1109/VISUAL.1998.745289,87,94,Conferences,"This paper describes by example a strategy for plotting and interacting with data in multiple metric spaces. The example system was designed for use with time-varying computational fluid dynamics (CFD) data sets, but the methodology is directly applicable to other types of field data. The central objects embodied by the tool are portraits, which show the data in various coordinate systems, while preserving their spatial connectivity and temporal variability. The coordinates are derived in various ways from the field data, and an important feature is that new and derived portraits can be created interactively. The primary operations supported by the tool are brushing and linking: the user can select a subset of a given portrait, and this subset is highlighted in all portraits. The user can combine highlighted subsets from an arbitrary number of portraits with the usual logical operators, thereby indicating where an arbitrarily complex set of conditions holds. The system is useful for exploratory visualization and feature detection in multivariate data.",,C. Henze,"M/S T27A-1, NASA Ames Research Center, Moffett Field, CA, USA",,,,18,,
Vis-conf,1998,Converting sets of polygons to manifold surfaces by cutting and stitching,10.1109/VISUAL.1998.745327,https://doi.org/10.1109/VISUAL.1998.745327,383,390,Conferences,"Many real world polygonal surfaces contain topological singularities that represent a challenge for processes such as simplification, compression, smoothing, etc. We present an algorithm for removing such singularities, thus converting non manifold sets of polygons to manifold polygonal surfaces (orientable if necessary). We identify singular vertices and edges, multiply singular vertices, and cut through singular edges. In an optional stitching phase, we join surface boundary edges that were cut, or whose endpoints are sufficiently close, while guaranteeing that the surface is a manifold. We study two different stitching strategies called ""edge pinching"" and ""edge snapping""; when snapping, special care is required to avoid re-creating singularities. The algorithm manipulates the polygon vertex indices (surface topology) and essentially ignores vertex coordinates (surface geometry). Except for the optional stitching, the algorithm has a linear complexity in the number of vertices edges and faces, and require no floating point operation.",,A. Gueziec;G. Taubin;F. Lazarus;W. Horn,"IBM Thomas J. Watson Research Center, Yorktown Heights, NY, USA;IBM Thomas J. Watson Research Center, Yorktown Heights, NY, USA;IRCOM-SIC (UMR CNRS 6615), France;IBM Thomas J. Watson Research Center, Yorktown Heights, NY, USA",,,,15,,
Vis-conf,1998,Accelerated ray-casting for curvilinear volumes,10.1109/VISUAL.1998.745310,https://doi.org/10.1109/VISUAL.1998.745310,247,253,Conferences,"We present an efficient and robust ray-casting algorithm for directly rendering a curvilinear volume of arbitrarily-shaped cells. We designed the algorithm to alleviate the consumption of CPU power and memory space. By incorporating the essence of the projection paradigm into the ray-casting process, we have successfully accelerated the ray traversal through the grid and data interpolations at sample points. Our algorithm also overcomes the conventional limitation requiring the cells to be convex. Application of this algorithm to several commonly-used curvilinear data sets has produced a favorable performance when compared with recently reported algorithms.",,L. Hong;A. Kaufman,"Software Production Research Department, Cardiac Investigation Unit St Vincents Hospital, Naperville, IL, USA;Center for Visual Computing (CVC) and Department of Computer Science, State University of New York, Stony Brook, Stony Brook, NY, USA",,,,13,,
Vis-conf,1998,Interactive deformations from tensor fields,10.1109/VISUAL.1998.745316,https://doi.org/10.1109/VISUAL.1998.745316,297,304,Conferences,"This paper presents techniques for interactively visualizing tensor fields using deformations. The conceptual idea behind this approach is to allow the tensor field to manifest its influence on idealized objects placed within the tensor field. This is similar, though not exactly the same, to surfaces deforming under load in order to relieve built up stress and strain. We illustrate the effectiveness of the Deviator-Isotropic tensor decomposition in deformation visualizations of CFD strain rate. We also investigate how directional flow techniques can be extended to distinguish between regions of tensile versus compressive forces.",,E. Boring;A. Pang,"Computer Science Department, University of California, Santa Cruz, CA, USA;Computer Science Department, University of California, Santa Cruz, CA, USA",,,,12,,
Vis-conf,1998,Comparing LIC and spot noise,10.1109/VISUAL.1998.745324,https://doi.org/10.1109/VISUAL.1998.745324,359,365,Conferences,Spot noise and line integral convolution (LIC) are two texture synthesis techniques for vector field visualization. The two techniques are compared. Continuous directional convolution is used as a common basis for comparing the techniques. It is shown that the techniques are based on the same mathematical concept. Comparisons of the visual appearance of the output and performance of the algorithms are made.,,W. de Leeuw;R. van Liere,"Center for Mathematics and Computer Science, CWI, Mexico;Department of Software Engineering, CWI, Amsterdam, Netherlands",,,,11,,
Vis-conf,1998,Building perceptual textures to visualize multidimensional datasets,10.1109/VISUAL.1998.745292,https://doi.org/10.1109/VISUAL.1998.745292,111,118,Conferences,"Presents a new method for using texture to visualize multi-dimensional data elements arranged on an underlying 3D height field. We hope to use simple texture patterns in combination with other visual features like hue and intensity to increase the number of attribute values we can display simultaneously. Our technique builds perceptual texture elements (or pexels) to represent each data element. Attribute values encoded in the data element are used to vary the appearance of a corresponding pexel. Texture patterns that form when the pexels are displayed can be used to rapidly and accurately explore the dataset. Our pexels are built by controlling three separate texture dimensions: height, density and regularity. Results from computer graphics, computer vision and cognitive psychology have identified these dimensions as important for the formation of perceptual texture patterns. We conducted a set of controlled experiments to measure the effectiveness of these dimensions, and to identify any visual interference that may occur when all three are displayed simultaneously at the same spatial location. Results from our experiments show that these dimensions can be used in specific combinations to form perceptual textures for visualizing multidimensional datasets. We demonstrate the effectiveness of our technique by applying it to two real-world visualization environments: tracking typhoon activity in southeast Asia, and analyzing ocean conditions in the northern Pacific.",,C.G. Healey;J.T. Enns,"North Carolina State University, University of British Columbia, USA;North Carolina State University, University of British Columbia, USA",,,,11,,
Vis-conf,1998,Data level comparison of wind tunnel and computational fluid dynamics data,10.1109/VISUAL.1998.745332,https://doi.org/10.1109/VISUAL.1998.745332,415,418,Conferences,"The paper describes the architecture of a data level comparative visualization system and experiences using it to study computational fluid dynamics data and experimental wind tunnel data. We illustrate how the system can be used to compare data sets from different sources, data sets with different resolutions and data sets computed using different mathematical models of fluid flow. Suggested improvements to the system based on user feedback are also discussed.",,Q. Shen;A. Pang;S. Uselton,"Computer Science Department, University of California, Santa Cruz, USA;Computer Science Department, University of California, Santa Cruz, USA;MRJ Technology Solutions, Inc., USA",,,,11,,
Vis-conf,1998,Production visualization for the ASCI One TeraFLOPS machine,10.1109/VISUAL.1998.745343,https://doi.org/10.1109/VISUAL.1998.745343,459,462,Conferences,"The delivery of the first one tera-operations/sec computer has significantly impacted production data visualization, affecting data transfer, post processing, and rendering. Terascale computing has motivated a need to consider the entire data visualization system; improving a single algorithm is not sufficient. This paper presents a systems approach to decrease by a factor of four the time required to prepare large data sets for visualization. For daily production use, all stages in the processing pipeline from physics simulation code to pixels on a screen, must be balanced to yield good overall performance. Performance of the initial visualization system is compared with recent improvements. ""Lessons learned"" from the coordinated deployment of improved algorithms also are discussed, including the need for 64 bit addressing and a fully parallel data visualization pipeline.",,P.D. Heermann,"Sandia National Laboratories, USA",,,,10,,
Vis-conf,1998,Acoustic imaging and visualization of plumes discharging from black smoker vents on the deep seafloor,10.1109/VISUAL.1998.745347,https://doi.org/10.1109/VISUAL.1998.745347,475,478,Conferences,"Visualization and quantification methods are being developed to analyze our acoustic images of thermal plumes containing metallic mineral particles that discharge from hot springs on the deep seafloor. The acoustic images record intensity of backscattering from the particulate matter suspended in the plumes. The visualization methods extract, classify, visualize, measure and track reconstructions of the plumes, depicted by isointensity surfaces as 3D volume objects and 2D slices. The parameters measured, including plume volume, cross sectional area, centerline location (trajectory), surface area and isosurfaces at percentages of maximum backscatter intensity, are being used to derive elements of plume behavior including expansion with height, dilution, and mechanisms of entrainment of surrounding seawater. Our aim is to compare the observational data with predictions of plume theory to test and advance models of the behavior of hydrothermal plumes through the use of multiple representations.",,P. Rona;K. Bemis;D. Kenchammana-Hosekote;D. Silver,"Institute of Marine and Coastal Sciences, Rutgers University, New Brunswick, NJ, USA;Institute of Marine and Coastal Sciences, Rutgers University, New Brunswick, NJ, USA;Electrical and Computer Engineering and CAIP, Rutgers University, Piscataway, NJ, USA;Institute of Marine and Coastal Sciences, Rutgers University, New Brunswick, NJ, USA",,,,7,,
Vis-conf,1998,Extremal feature extraction from 3-D vector and noisy scalar fields,10.1109/VISUAL.1998.745290,https://doi.org/10.1109/VISUAL.1998.745290,95,102,Conferences,"We are interested in feature extraction from volume data in terms of coherent surfaces and 3D space curves. The input can be an inaccurate scalar or vector field, sampled densely or sparsely on a regular 3D grid, in which poor resolution and the presence of spurious noisy samples make traditional iso-surface techniques inappropriate. In this paper, we present a general-purpose methodology to extract surfaces or curves from a digital 3D potential vector field {(s,v~)}, in which each voxel holds a scalar s designating the strength and a vector v~ indicating the direction. For scalar, sparse or low-resolution data, we ""vectorize"" and ""densify"" the volume by tensor voting to produce dense vector fields that are suitable as input to our algorithms, the extremal surface and curve algorithms. Both algorithms extract, with sub-voxel precision, coherent features representing local extrema in the given vector field. These coherent features are a hole-free triangulation mesh (in the surface case), and a set of connected, oriented and non-intersecting polyline segments (in the curve case). We demonstrate the general usefulness of both extremal algorithms on a variety of real data by properly extracting their inherent extremal properties, such as (a) shock waves induced by abrupt velocity or direction changes in a flow field, (b) interacting vortex cores and vorticity lines in a velocity field, (c) crest-lines and ridges implicit in a digital terrain map, and (d) grooves, anatomical lines and complex surfaces from noisy dental data.",,C.-K. Tang;G. Medioni,"University of Southern California, USA;Institute for Robotics and Intelligent Systems, University of Southern California, Los Angeles, USA",,,,7,,
Vis-conf,1998,Contour interpolation and surface reconstruction of smooth terrain models,10.1109/VISUAL.1998.745281,https://doi.org/10.1109/VISUAL.1998.745281,27,33,Conferences,"Interpolating contours and reconstructing a rational surface from a contour map are two essential problems in terrain modeling. They are often met in the field of computer graphics and CAD systems based on geographic information systems. Although many approaches have been developed for these two problems, one difficulty still remains. That is how to ensure that the reconstructed surface is both smooth globally and coincides with the given contours exactly simultaneously. In this paper we solve the two problems in a unified framework. We use gradient controlled partial differential equation (PDE) surfaces to express terrain surfaces, in which the surface shapes can be globally determined by the contours, their locations, height and gradient values. The surface generated by this method is accurate in the sense of exactly coinciding with the original contours and smooth with C/sup 1/ continuity everywhere. The method can reveal smooth saddle shapes caused by surface branching of one to more and can make rational interpolated sub-contours between two or more neighboring contours.",,J. Chai;T. Miyoshi;E. Nakamae,"Sanei Company Limited, Japan;Hiroshima Institute of Technology, Hiroshima, Japan;Hiroshima Institute of Technology, Hiroshima, Japan",,,,7,,
Vis-conf,1998,Seabed visualization,10.1109/VISUAL.1998.745348,https://doi.org/10.1109/VISUAL.1998.745348,479,481,Conferences,"The development of a high speed multi-frequency continuous scan sonar at Sonar Research & Development Ltd has resulted in the acquisition of extremely accurate, high resolution bathymetric data. This rich underwater data provides new challenges and possibilities within the field of seabed visualization. This paper introduces the reader to seabed visualization by describing two example case studies which use the Seabed Visualization System developed at SRD. Both case studies, harbour wall and shipwreck visualization, are implemented using real survey data. The high resolution of the data obtained means slight changes in the seabed topography are easily distinguishable. Annual survey inspections in both case studies enable comparisons to be made between the data sets making the visualization system an important tool for management and planning.",,P. Chapman;P. Stevens;D. Wills;G. Brookes,"Department of Computer Science, University of Hull, UK;Department of Computer Science, University of Hull, UK;Department of Computer Science, University of Hull, UK;Department of Computer Science, University of Hull, UK",,,,7,,
Vis-conf,1998,Visualization for multiparameter aircraft designs,10.1109/VISUAL.1998.745351,https://doi.org/10.1109/VISUAL.1998.745351,491,494,Conferences,"We describe an aircraft design problem in high dimensional space, with D typically being 10 to 30. In some respects this is a classic optimization problem, where the goal is to find the point that minimizes an objective function while satisfying a set of constraints. However, evaluating an individual point is expensive, and the high dimensionality makes many approaches to solving the problem infeasible. The difficulty of the problem means that aircraft designers would benefit from any insights that can be provided. We discuss how simple visualizations have already proved beneficial, and then describe how visualization might be of further help in the future.",,C.A. Shaffer;D.L. Knill;L.T. Watson,"Computer Science, Virginia Technology, Blacksburg, VA, USA;Aeronautics and Astronautics, University of Washington, Seattle, WA, USA;Computer Science and Mathematics, Virginia Polytechnic Institute and State University, Blacksburg, VA, USA",,,,6,,
Vis-conf,1998,Constrained optimal framings of curves and surfaces using quaternion Gauss maps,10.1109/VISUAL.1998.745326,https://doi.org/10.1109/VISUAL.1998.745326,375,382,Conferences,"We propose a general paradigm for computing optimal coordinate frame fields that may be exploited to visualize curves and surfaces. Parallel transport framings, which work well for open curves, generally fail to have desirable properties for cyclic curves and for surfaces. We suggest that minimal quaternion measure provides an appropriate heuristic generalization of parallel transport. Our approach differs from minimal tangential acceleration approaches due to the addition of ""sliding ring"" constraints that fix one frame axis, but allow an axial rotational freedom whose value is varied in the optimization process. Our fundamental tool is the quaternion Gauss map, a generalization to quaternion space of the tangent map for curves and of the Gauss map for surfaces. The quaternion Gauss map takes 3D coordinate frame fields for curves and surfaces into corresponding curves and surfaces constrained to the space of possible orientations in quaternion space. Standard optimization tools provide application specific means of choosing optimal, e.g., length- or area-minimizing, quaternion frame fields in this constrained space.",,A.J. Hanson,"Computer Science Department, Indiana University, Bloomington, IN, USA",,,,6,,
Vis-conf,1998,"Intent, perception, and out-of-core visualization applied to terrain",10.1109/VISUAL.1998.745342,https://doi.org/10.1109/VISUAL.1998.745342,455,458,Conferences,"This paper considers how out-of-core visualization applies to terrain datasets, which are among the largest now presented for interactive visualization and can range to sizes of 20 GB and more. It is found that a combination of out-of-core visualization, which tends to focus on 3D data, and visual simulation, which places an emphasis on visual perception and real-time display of multiresolution data, results in interactive terrain visualization with significantly improved data access and quality of presentation. Further, the visual simulation approach provides qualities that are useful for general data, not just terrain.",,D. Davis;T.Y. Jiang;W. Ribarsky;N. Faust,"Graphics, Visualization,and Usability Center, Georgia Institute of Technology, USA;Graphics, Visualization,and Usability Center, Georgia Institute of Technology, USA;Graphics, Visualization,and Usability Center, Georgia Institute of Technology, USA;Graphics, Visualization,and Usability Center, Georgia Institute of Technology, USA",,,,6,,
Vis-conf,1998,A distributed blackboard architecture for interactive data visualization,10.1109/VISUAL.1998.745307,https://doi.org/10.1109/VISUAL.1998.745307,225,231,Conferences,"In this paper the motivation, design and application of a distributed blackboard architecture for interactive data visualization is discussed. The main advantages of the architecture are twofold. First, it allows visualization tools to be tightly integrated with simulations. Second, it allows qualitative and quantitative analysis to be combined during the visualization process.",,R. van Liere;J. Harkes;W. de Leeuw,"Center for Mathematics and Computer Science, CWI, Netherlands;Center for Mathematics and Computer Science, CWI, Netherlands;Department of Software Engineering, CWI, Amsterdam, Netherlands",,,,6,,
Vis-conf,1998,POPTEX: Interactive ocean model visualization using texture mapping hardware,10.1109/VISUAL.1998.745346,https://doi.org/10.1109/VISUAL.1998.745346,471,474,Conferences,"Global circulation models are used to gain an understanding of the processes that affect the Earth's climate and may ultimately be used to assess the impact of humanity's activities on it. The POP ocean model developed at Los Alamos is an example of such a global circulation model that is being used to investigate the role of the ocean in the climate system. Data output from POP has traditionally been visualized using video technology which precludes rapid modification of visualization parameters and techniques. This paper describes a visualization system that leverages high speed graphics hardware, specifically texture mapping hardware, to accelerate data exploration to interactive rates. We describe the design of the system, the specific hardware features used, and provide examples of its use. The system is capable of viewing ocean circulation simulation results at up to 60 frames per second while loading texture memory at approximately 72 million texels per second.",,A. McPherson;M. Maltrud,"Advanced Computing Laboratory, Los Alamos National Laboratory, USA;Theoretical Division, Los Alamos National Laboratory, USA",,,,6,,
Vis-conf,1998,Hierarchical volume analysis and visualization based on morphological operators,10.1109/VISUAL.1998.745321,https://doi.org/10.1109/VISUAL.1998.745321,335,341,Conferences,"One common problem in the practical application of volume visualization is the proper choice of transfer functions in order to color different parts of the volume meaningfully. This interactive process can be very complicated and time consuming. An alternative to the adjustment of transfer functions is the application of segmentation algorithms. These algorithms are often dedicated to a limited range of data sets and tend to be very compute intensive. We propose a morphology based hierarchical analysis to estimate the optical properties of the volume to be rendered. This approach requires fewer parameters and incorporates also spatial information, but it is far less compute intensive than most of the segmentation methods. The hierarchical analysis is constructed in analogy to the wavelet analysis, except for the fact, that nonlinear filters are used in our case. These morphological operators have a lower distortional influence on the analyzed structures than the usual linear filters. A special decomposition of the morphological operators is discussed, which leads to an efficient implementation of this approach. This technique reduces the three dimensional analysis to a one dimensional computation, as it is done in tensor product based linear filters. The resulting decomposition may also be parallelized easily. We demonstrate the usefulness of the proposed technique by applying it to medical and technical data sets.",,C. Lurig;T. Ertl,"Computer Graphics Group, Universität Erlangen Nürnberg, Germany;Computer Graphics Group, Universität Erlangen Nürnberg, Germany",,,,6,,
Vis-conf,1998,Multi-Source Data Analysis Challenges,10.1109/VISUAL.1998.745353,https://doi.org/10.1109/VISUAL.1998.745353,501,504,Conferences,,,S. Uselton;J. Ahrens;W. Bethel;L. Treinish;A. State,University of North Carolina at Chapel Hill;;;;,,,,5,,
Vis-conf,1998,Visualizing Hilbert curves,10.1109/VISUAL.1998.745340,https://doi.org/10.1109/VISUAL.1998.745340,447,450,Conferences,"A computer animated movie was produced, illustrating both 2D and 3D Hilbert curves, and showing the transition from 2D to 3D with the help of volume rendering.",,N. Max,"Lawrence Livemore National Laboratory, USA",,,,5,,
Vis-conf,1998,Three-dimensional visualization of microstructures,10.1109/VISUAL.1998.745350,https://doi.org/10.1109/VISUAL.1998.745350,487,490,Conferences,"This case study describes a technique for the three-dimensional analysis of the internal microscopic structure (microstructure) of materials. This technique consists of incrementally polishing through a thin layer (approximately 0.2 /spl mu/m) of material, chemically etching the polished surface, applying reference marks, and performing optical or scanning electron microscopy on selected areas. The series of images are then processed employing AVS and other visualization software to obtain a 3D reconstruction of the material. We describe how we applied this technique to an alloy steel to study the morphology, connectivity, and distribution of cementite precipitates formed during thermal processing. The results showed microstructural features not previously identified with traditional 2D techniques.",,M. Lanzagorta;M.V. Kral;J.E. Swan;G. Spanos;R. Rosenberg;E. Kuo,"Scientific Visualization Laboratory# contractor from Scientific and Engineering Solutions, Naval Research Laboratory, Inc., Washington D.C., DC, USA;;Virtual Reality Laboratory, Naval Research Laboratory, Inc., Washington D.C., DC, USA;Materials Science and Technology Division, Naval Research Laboratory, Inc., Washington D.C., DC, USA;Scientific Visualization Laboratory, Naval Research Laboratory, Inc., Washington D.C., DC, USA;Virtual Reality Laboratory, Naval Research Laboratory, Inc., Washington D.C., DC, USA",,,,5,,
Vis-conf,1998,Pixel masks for screen-door transparency,10.1109/VISUAL.1998.745323,https://doi.org/10.1109/VISUAL.1998.745323,351,358,Conferences,"Rendering objects transparently gives additional insight in complex and overlapping structures. However, traditional techniques for the rendering of transparent objects such as alpha blending are not very well suited for the rendering of multiple transparent objects in dynamic scenes. Screen door transparency is a technique to render transparent objects in a simple and efficient way: no sorting is required and intersecting polygons can be handled without further preprocessing. With this technique, polygons are rendered through a mask: only where the mask is present, pixels are set. However, artifacts such as incorrect opacities and distracting patterns can easily occur if the masks are not carefully designed. The requirements on the masks are considered. Next, three algorithms are presented for the generation of pixel masks. One algorithm is designed for the creation of small (e.g. 4/spl times/4) masks. The other two algorithms can be used for the creation of larger masks (e.g. 32/spl times/32). For each of these algorithms, results are presented and discussed.",,J.D. Mulder;F.C.A. Groen;J.J. van Wijk,"Center of Mathematics and Computer Science, Amsterdam, Netherlands;Faculty of Mathematics, Computer Science, Physics, and Astronomy, University of Amsterdam, Netherlands;Faculty of Mathematics and Computer Science, Eindhovan University of Technology, Netherlands",,,,5,,
Vis-conf,1998,Image-based rendering with occlusions via cubist images,10.1109/VISUAL.1998.745320,https://doi.org/10.1109/VISUAL.1998.745320,327,334,Conferences,"We attack the problem of image based rendering with occlusions and general camera motions by using distorted multiperspective images; such images provide multiple viewpoint photometry similar to the paintings of cubist artists. We take scene geometry, in contrast, to be embodied in mappings of viewing rays from their original 3D intercepts into the warped multiperspective image space. This approach allows us to render approximations of scenes with occlusions using time dense and spatially sparse sequences of camera rays, which is a significant improvement over the storage requirements of an equivalent animation sequence. Additional data compression can be achieved using sparse time keyframes as well. Interpolating the paths of sparse time key rays correctly in image space requires singular interpolation functions with spatial discontinuities. While there are many technical questions yet to be resolved, the employment of these singular interpolation functions in the multiperspective image space appears to be of potential interest for generating general viewpoint scene renderings with minimal data storage.",,A.J. Hanson;E.A. Wernert,"Computer Science Department, Indiana University, Bloomington, IN, USA;Computer Science Department, Indiana University, Bloomington, IN, USA",,,,3,,
Vis-conf,1998,Wavelets over curvilinear grids,10.1109/VISUAL.1998.745318,https://doi.org/10.1109/VISUAL.1998.745318,313,317,Conferences,"We develop multiresolution models for analyzing and visualizing two-dimensional flows over curvilinear grids. Our models are based upon nested spaces of piecewise defined functions defined over nested curvilinear grid domains. The nested domains are selected so as to maintain the original geometry of the inner boundary. We first give the refinement and decomposition equations for Haar wavelets over these domains. Next, using lifting techniques we develop and show examples of piecewise linear wavelets over curvilinear grids.",,G.M. Nielson;Il.-H. Jung;J. Sung,"Department of Computer Science and Engineering, Arizona State University, Tempe, AZ, USA;Department of Computer Science and Engineering, Arizona State University, Tempe, AZ, USA;Department of Computer Science and Engineering, Arizona State University, Tempe, AZ, USA",,,,3,,
Vis-conf,1998,Visual presentation of magnetic resonance images,10.1109/VISUAL.1998.745334,https://doi.org/10.1109/VISUAL.1998.745334,423,426,Conferences,"Medical image analysis is shifting from current film oriented light screen environments to computer environments that involve viewing and analyzing large sets of images on a computer screen. Magnetic resonance imaging (MRI) studies, in particular, can involve many images. The paper examines how best to meet the needs of radiologists in a computational environment. To this end, a field study was conducted to observe radiologists' interactions during MRI analysis in the traditional light screen environment. Key issues uncovered involve control over focus and context, dynamic grouping of images and retrieval of images and image groups. To address the problem of focus and context, existing layout adjustment and magnification techniques are explored to provide the most appropriate solution. Our interest is in combining the methodologies of human computer interaction studies with computational presentation possibilities to design a visual environment for the crucial field of medical image analysis.",,J.E. van der Heyden;M.S.T. Carpendale;K. Inkpen;M.S. Atkins,"School of Computing Science, Simon Fraser University, Burnaby, BC, Canada;School of Computing Science, Simon Fraser University, Burnaby, BC, Canada;School of Computing Science, Simon Fraser University, Burnaby, BC, Canada;School of Computing Science, Simon Fraser University, Burnaby, BC, Canada",,,,3,,
Vis-conf,1998,A case study using the virtual environment for reconstructive surgery,10.1109/VISUAL.1998.745336,https://doi.org/10.1109/VISUAL.1998.745336,431,434,Conferences,"The paper details the use of a Virtual Environment for Reconstructive Surgery (VERS) in the case of a 17 year-old boy with a severe facial defect, arising from the removal of a soft tissue tumor. Computed tomography (CT) scans were taken of the patient, the data were segmented, a mesh was generated, and this patient-specific mesh was used in a virtual environment by the surgeons for preoperative visualization of the defect, planning of the surgery, and production of a custom surgical template to aid in repairing the defect. The paper details the case of this patient, provides a background on the virtual environment technology used, discusses the difficulties encountered, and describes the lessons learned.",,K. Montgomery;M. Stephanides;S. Schendel;M. Ross,"National Biocomputation Center, University of Stanford, Stanford, CA, USA;National Biocomputation Center, University of Stanford, Stanford, CA, USA;National Biocomputation Center, University of Stanford, Stanford, CA, USA;NASA Ames Research Center, Moffett Field, CA, USA",,,,3,,
Vis-conf,1998,Rear-projecting virtual data onto physical terrain: an exercise in two senses being better than one,10.1109/VISUAL.1998.745341,https://doi.org/10.1109/VISUAL.1998.745341,451,454,Conferences,"This paper describes a project that combined physical model fabrication and virtual computer-based data display to create a unique visualization presentation. USGS terrain information on Prince of Wales Island, Alaska was used to create a physical prototype in SDSC's TeleManufacturing Facility. This model was then used as a mold to create a translucent plate of the terrain. Finally, deforestation data from the island was color mapped and rear-projected onto the translucent plate within a light box. The result is a very compelling display in which both the senses of sight and touch are used to make relationships between terrain features and the data more readily apparent.",,D. Clark;R. Marciano;R. McKeon;M. Bailey,"San Diego Supercomputer Center, University of California, San Diego, USA;San Diego Supercomputer Center, University of California, San Diego, USA;San Diego Supercomputer Center, University of California, San Diego, USA;San Diego Supercomputer Center, University of California, San Diego, San Diego, CA, USA",,,,2,,
Vis-conf,1998,Scientific visualization and data modeling of scattered sediment contaminant data in New York/New Jersey estuaries,10.1109/VISUAL.1998.745345,https://doi.org/10.1109/VISUAL.1998.745345,467,470,Conferences,"Sediments in many parts of the New York and New Jersey estuary system are contaminated with toxic organic and inorganic compounds by different sources. Because of the potential environmental consequences, detailed information on the spatial distribution of sediment contaminants is essential in order to carry out routine shipping channel dredging in an environmentally responsible way, and to remediate hot spots cost-effectively and safely. Scientific visualization and scatter data modeling techniques have been successfully applied in analyzing the sparse sampling data of sediment contaminants in New York and New Jersey estuaries, the underlying spatial characteristics of which are otherwise difficult to comprehend. Continuous realizations of contaminant concentrations in the region were obtained by using a spectral domain-decomposition scattered data model and IBM Data Explorer which is a software package for scientific data visualization.",,H. Ma;K.W. Jones;E.A. Stern,"Brockhaven National Laboratory, Upton, NY, USA;Brockhaven National Laboratory, Upton, NY, USA;U.S. Enviromental Protection Agency, New York, NY, USA",,,,2,,
Vis-conf,1998,Volumetric modeling of acoustic fields in CNMAT's sound spatialization theatre,10.1109/VISUAL.1998.745338,https://doi.org/10.1109/VISUAL.1998.745338,439,442,Conferences,"A new tool for real time visualization of acoustic sound fields has been developed for a new sound spatialization theatre. The theatre is described and several applications of the acoustic and volumetric modeling software are presented. The visualization system described is a valuable tool for spatial sound researchers, sound engineers and composers using CNMAT's sound spatialization theatre. Further work is in progress on the adaptation of better acoustic simulation methods (M. Monks et al., 1996) for more accurate display of the quality of the reverberant field. The room database will be automatically extracted from a model built with 3D modeling software. Volume visualization strategies are being explored to display sounds in spectral and impulse response form.",,S. Khoury;A. Freed;D. Wessel,"Center for New Music and Audio Technologies, Berkeley, CA, USA;Center for New Music and Audio Technologies, Berkeley, CA, USA;Center for New Music and Audio Technologies, Berkeley, CA, USA",,,,2,,
Vis-conf,1998,A unified approach for simplifying polygonal and spline models,10.1109/VISUAL.1998.745313,https://doi.org/10.1109/VISUAL.1998.745313,271,278,Conferences,"We present a new approach for simplifying models composed of polygons or spline patches. Given an input model, the algorithm computes a new representation of the model in terms of triangular Bezier patches. It performs a series of geometric operations, consisting of patch merging and swapping diagonals, and makes use of batch connectivity information to generate C-LODs (curved levels-of-detail). Each C-LOD is represented using cubic triangular Bezier patches. The C-LODs provide a compact representation for storing the model. The algorithm tries to minimize the surface deviation error and maintains continuity at patch boundaries. Given the CLODs, the algorithm can generate their polygonal approximations using static and dynamic tessellation schemes. It has been implemented and we highlight its performance on a number of polygonal and spline models.",,M. Gopi;D. Manocha,"Department of Computer Science, University of North Carolina, Chapel Hill, USA;Department of Computer Science, University of North Carolina, Chapel Hill, USA",,,,2,,
Vis-conf,1998,Key Problems and Thorny Issues in Multidimensional Visualization,10.1109/VISUAL.1998.745354,https://doi.org/10.1109/VISUAL.1998.745354,505,506,Conferences,,,G. Grinstein;A. Inselberg;S. Laskowski,University of Massachusetts Lowell;;,,,,2,,
Vis-conf,1998,Efficient co-triangulation of large data sets,10.1109/VISUAL.1998.745293,https://doi.org/10.1109/VISUAL.1998.745293,119,126,Conferences,"Presents an efficient algorithm for the reconstruction of a multivariate function from multiple sets of scattered data. Given N sets of scattered data representing N distinct dependent variables that have been sampled independently over a common domain and N error tolerance values, the algorithm constructs a triangulation of the domain of the data and associates multivariate values with the vertices of the triangulation. The resulting linear interpolation of these multivariate values yields a multivariate function, called a co-triangulation, that represents all of the dependent data up to the given error tolerance. A simple iterative algorithm for the construction of a co-triangulation from any number of data sets is presented and analyzed. The main contribution of this paper lies in the description of a highly efficient framework for the realization of this approximation algorithm. While the asymptotic time complexity of the algorithm certainly remains within the theoretical bounds, we demonstrate that it is possible to achieve running times that depend only linearly on the number of data even for very large problems with more than two million samples. This efficient realization of the algorithm uses adapted dynamic data structures and careful caching in an integrated framework.",,H. Weimer;J. Warren;J. Troutner;W. Wiggins;J. Shrout,"Department of Computer Science, Rice University, Houston, TX, USA;Department of Computer Science, Rice University, Houston, TX, USA;Western Geophysical, Houston, TX, USA;Western Geophysical, Houston, TX, USA;Western Geophysical, Houston, TX, USA",,,,2,,
Vis-conf,1998,Development of a multi-source visualization prototype,10.1109/VISUAL.1998.745331,https://doi.org/10.1109/VISUAL.1998.745331,411,414,Conferences,"This case study describes the design and development of VISOR (Visual Integration of Simulated and Observed Results), a tool which supports the visualization and analysis of a wide variety of data relevant to aerospace engineering design. Integrating data from such disparate sources is challenging; overcoming the obstacles results in a powerful tool. The process has also been valuable in exposing requirements for the libraries of reusable software tools for visualization and data analysis being developed at NASA Ames.",,L. Keely;S. Uselton,"MRJ Technology Solutions, NASA Ames Research Center, USA;MRJ Technology Solutions, NASA Ames Research Center, USA",,,,2,,
Vis-conf,1998,Configuration space visualization for mechanical design,10.1109/VISUAL.1998.745349,https://doi.org/10.1109/VISUAL.1998.745349,483,486,Conferences,"We are studying difficult geometric problems in computer-aided mechanical design where visualization plays a key role. The research addresses the fundamental design task of contact analysis: deriving the part contacts and the ensuing motion constraints in a mechanical system. We have automated contact analysis of general planar systems via configuration space computation. Configuration space is a geometric representation of rigid-body interaction that encodes quantitative information, such as part motion paths, and qualitative information, such as system failure modes. The configuration space dimension equals the number of degrees of freedom in the system. Three-dimensional spaces are most important, but higher-dimensions are often useful. The qualitative aspects, which relate to the topology of the configuration space, are best understood by visualization. We explain what configuration space is, how it encodes contact information, and what research challenges it poses for visualization.",,E. Sacks;L. Joskowicz,"Purdue University, West Lafayette, IN, USA;Institute of Computer Science, Hebrew University of Jerusalem, Jerusalem, Israel",,,,1,,
Vis-conf,1998,Art and Visualization: Oil and Water?,10.1109/VISUAL.1998.745355,https://doi.org/10.1109/VISUAL.1998.745355,507,509,Conferences,,,D. Laidlaw;D. Kremers;V. Interrante;F. Frankel;T. Banchoff,University of Minnesota Computer Scientist;;;;,,,,1,,
Vis-conf,1998,Level of detail visualization of scalar data sets on irregular surface meshes,10.1109/VISUAL.1998.745287,https://doi.org/10.1109/VISUAL.1998.745287,73,77,Conferences,"In this article, we build a multi-resolution framework intended to be used for the visualization of continuous piecewise linear functions defined over triangular planar or spherical meshes. In particular, the data set can be viewed at different level of detail, that's to say as a piecewise linear function defined over any simplification of the base mesh. In his multi-resolution form, the function requires strictly the same volume of data than the original input: It is then possible to go through consecutive levels by the use of so-called detail coefficients, with exact reconstruction if desired. We also show how to choose a decimation sequence that leads to a good compromise between the resulting approximation error and the number of removed vertices. The theoretical tools used here are inspired from wavelet-based techniques and extended in the sense that they can handle non-nested approximation spaces.",,G.-P. Bonneau;A. Gerussi,"LMC-CNRS, Grenoble, France;LMC-CNRS, France",,,,1,,
Vis-conf,1998,Visualization in corneal topography,10.1109/VISUAL.1998.745335,https://doi.org/10.1109/VISUAL.1998.745335,427,430,Conferences,"The anterior surface of the eye ('cornea') is extremely important for good sight. Instruments measuring corneal shape conventionally visualize the surface characteristics by mapping the instantaneous radius of curvature onto a rainbow colour scale. This technique is known to have important drawbacks. Firstly, not corneal shape itself is visualized, but rather second order surface properties. Secondly, the type of colouring produces well documented artifacts. We discuss visualization techniques for a more direct representation of the data. In a three part display, shape deviations are presented as a height surface in one window, height lines superimposed over the input image in another, and a colour mapped representation of the mean normal radius of curvature in a third. With the aid of some typical examples, it is shown that these visualizations are easy to interpret by the physician and overcome the limitations of the conventional techniques.",,F.M. Vos;H.J.W. Spoelder,"Delft University of Technnology, Netherlands;Vrije Universiteit Amsterdam, Netherlands",,,,1,,
Vis-conf,1998,"Supporting detail-in-context for the DNA representation, H-curves",10.1109/VISUAL.1998.745339,https://doi.org/10.1109/VISUAL.1998.745339,443,446,Conferences,"This paper presents a tool for the visual exploration of DNA sequences represented as H-curves. Although very long sequences can be plotted using H-curves, micro-features are lost as sequences get longer. We present a new three-dimensional distortion algorithm to allow the magnification of a sub-segment of an H-curve while preserving a global view of the curve. This is particularly appropriate for H-curves as they provide useful visual information at several resolutions. Our approach also extends the current possibilities of detail-in-context viewing in 3D. It provides a non-occluding, orthogonal technique that preserves uniform scaling within regions and maintains geometric continuity between regions.",,M.L. Lantin;M.S.T. Carpendale,"School of Computing Science, Simon Fraser University, Canada;School of Computing Science, Simon Fraser University, Canada",,,,0,,
Vis-conf,1998,Why is Real-Time Volume Rendering No Longer a Year Away?,10.1109/VISUAL.1998.745352,https://doi.org/10.1109/VISUAL.1998.745352,497,499,Conferences,,,A. Kaufman;M. Brady;B. Lorensen;F. Kitson;H. Pfister,"State University of New York, Stony Brook, USA;Intel Corporation, USA;;Hewlett Packard Laboratories, USA;A Mitsubishi Electric Research Lab, MERL",,,,0,,
Vis-conf,1998,Simplifying surfaces with color and texture using quadric error metrics,10.1109/VISUAL.1998.745312,https://doi.org/10.1109/VISUAL.1998.745312,263,269,Conferences,"There are a variety of application areas in which there is a need for simplifying complex polygonal surface models. These models often have material properties such as colors, textures, and surface normals. Our surface simplification algorithm, based on iterative edge contraction and quadric error metrics, can rapidly produce high quality approximations of such models. We present a natural extension of our original error metric that can account for a wide range of vertex attributes.",,M. Garland;P.S. Heckbert,"Computer Science Department, Carnegie Mellon University, Pittsburgh, USA;Carnegie Mellon University, USA",,,,169,,
Vis-conf,1998,Large scale terrain visualization using the restricted quadtree triangulation,10.1109/VISUAL.1998.745280,https://doi.org/10.1109/VISUAL.1998.745280,19,26,Conferences,"Real-time rendering of triangulated surfaces has attracted growing interest in the last few years. However, interactive visualization of very large scale grid digital elevation models is still difficult. The graphics load must be controlled by adaptive surface triangulation and by taking advantage of different levels of detail. Furthermore, management of the visible scene requires efficient access to the terrain database. We describe an all-in-one visualization system which integrates adaptive triangulation, dynamic scene management and spatial data handling. The triangulation model is based on the restricted quadtree triangulation. Furthermore, we present new algorithms of restricted quadtree triangulation. These include among others exact error approximation, progressive meshing, performance enhancements and spatial access.",,R. Pajarola,"ETH, Zurich, Switzerland",,,,106,,
Vis-conf,1998,A higher-order method for finding vortex core lines,10.1109/VISUAL.1998.745296,https://doi.org/10.1109/VISUAL.1998.745296,143,150,Conferences,"This paper presents a novel method to extract vortical structures from 3D CFD (computational fluid dynamics) vector fields automatically. It discusses the underlying theory and some aspects of the implementation. Making use of higher-order derivatives, the method is able to locate bent vortices. In order to structure the recognition procedure, we distinguish locating the core line from calculating attributes of strength and quality. Results are presented on several flow fields from the field of turbomachinery.",,M. Roth;R. Peikert,"ETH Zurich, Swiss Center for Scientific Computing, Switzerland;ETH Zurich, Swiss Center for Scientific Computing, Switzerland",,,,66,,
Vis-conf,1998,Automatic detection of open and closed separation and attachment lines,10.1109/VISUAL.1998.745297,https://doi.org/10.1109/VISUAL.1998.745297,151,158,Conferences,"A fully automatic feature detection algorithm is presented that locates and distinguishes lines of flow separation and attachment on surfaces in 3D numerical flow fields. The algorithm is based on concepts from 2D phase-plane analysis of linear vector fields. Unlike prior visualization techniques based on particle tracing or flow topology, the phase-plane algorithm detects separation using local analytic tests. The results show that it not only detects the standard closed separation lines but also the illusive open separation lines which are not captured by flow topology methods.",,D.N. Kenwright,"NASA Ames Research Center, Moffett Field, CA, USA",,,,38,,
Vis-conf,1998,Tracking scalar features in unstructured data sets,10.1109/VISUAL.1998.745288,https://doi.org/10.1109/VISUAL.1998.745288,79,86,Conferences,"3D time-varying unstructured and structured data sets are difficult to visualize and analyze because of the immense amount of data involved. These data sets contain many evolving amorphous regions, and standard visualization techniques provide no facilities to aid the scientist to follow regions of interest. In this paper, we present a basic framework for the visualization of time-varying data sets, and a new algorithm and data structure to track volume features in unstructured scalar data sets. The algorithm and data structure are general and can be used for structured, curvilinear, adaptive and hybrid grids as well. The features tracked can be any type of connected regions. Examples are shown from ongoing research.",,D. Silver;X. Wang,"Department of Electrical and Computer Engineering and CAIP Center, Rutgers University, Piscataway, NJ, USA;Department of Electrical and Computer Engineering and CAIP Center, Rutgers University, Piscataway, NJ, USA",,,,34,,
Vis-conf,1998,TOPIC ISLANDS/sup TM/-a wavelet-based text visualization system,10.1109/VISUAL.1998.745302,https://doi.org/10.1109/VISUAL.1998.745302,189,196,Conferences,"We present a novel approach to visualize and explore unstructured text. The underlying technology, called TOPIC-O-GRAPHY/sup TM/, applies wavelet transforms to a custom digital signal constructed from words within a document. The resultant multiresolution wavelet energy is used to analyze the characteristics of the narrative flow in the frequency domain, such as theme changes, which is then related to the overall thematic content of the text document using statistical methods. The thematic characteristics of a document can be analyzed at varying degrees of detail, ranging from section-sized text partitions to partitions consisting of a few words. Using this technology, we are developing a visualization system prototype known as TOPIC ISLANDS to browse a document, generate fuzzy document outlines, summarize text by levels of detail and according to user interests, define meaningful subdocuments, query text content, and provide summaries of topic evolution.",,N.E. Miller;P.C. Wong;M. Brewster;H. Foote,"Pacific Northwest Lab., Richland, WA, USA;;Los Alamos National Laboratory, USA;",,,,34,,
Vis-conf,1998,Eliminating popping artifacts in sheet buffer-based splatting,10.1109/VISUAL.1998.745309,https://doi.org/10.1109/VISUAL.1998.745309,239,245,Conferences,"Splatting is a fast volume rendering algorithm which achieves its speed by projecting voxels in the form of pre-integrated interpolation kernels, or splats. Presently, two main variants of the splatting algorithm exist: (i) the original method, in which all splats are composited back-to-front, and (ii) the sheet-buffer method, in which the splats are added in cache-sheets, aligned with the volume face most parallel to the image plane, which are subsequently composited back-to-front. The former method is prone to cause bleeding artifacts from hidden objects, while the latter method reduces bleeding, but causes very visible color popping artifacts when the orientation of the compositing sheets changes suddenly as the image screen becomes more parallel to another volume face. We present a new variant of the splatting algorithm in which the compositing sheets are always parallel to the image plane, eliminating the condition for popping, while maintaining the insensitivity to color bleeding. This enables pleasing animated viewing of volumetric objects without temporal color and lighting discontinuities. The method uses a hierarchy of partial splats and employs an efficient list-based volume traversal scheme for fast splat access. It also offers more accuracy for perspective splatting as the decomposition of the individual splats facilitates a better approximation to the diverging nature of the rays that traverse the splatting kernels.",,K. Mueller;R. Crawfis,"Department of Computer and Information Science, Ohio State Uinversity, Columbus, OH, USA;Department of Computer and Information Science, Ohio State Uinversity, Columbus, OH, USA",,,,28,,
Vis-conf,1998,The Gridfit algorithm: an efficient and effective approach to visualizing large amounts of spatial data,10.1109/VISUAL.1998.745301,https://doi.org/10.1109/VISUAL.1998.745301,181,188,Conferences,"In a large number of applications, data is collected and referenced by their spatial locations. Visualizing large amounts of spatially referenced data on a limited-size screen display often results in poor visualizations due to the high degree of overplotting of neighboring datapoints. We introduce a new approach to visualizing large amounts of spatially referenced data. The basic idea is to intelligently use the unoccupied pixels of the display instead of overplotting data points. After formally describing the problem, we present two solutions which are based on: placing overlapping data points on the nearest unoccupied pixel; and shifting data points along a screen-filling curve (e.g., Hilbert-curve). We then develop a more sophisticated approach called Gridfit, which is based on a hierarchical partitioning of the data space. We evaluate all three approaches with respect to their efficiency and effectiveness and show the superiority of the Gridfit approach. For measuring the effectiveness, we not only present the resulting visualizations but also introduce mathematical effectiveness criteria measuring properties of the generated visualizations with respect to the original data such as distance- and position-preservation.",,D.A. Keim;A. Herrmann,"Institute for Computer Science, University of Halle-Wittenberg, Halle, Germany;Institute for Computer Science, University of Halle-Wittenberg, Halle, Germany",,,,27,,
Vis-conf,1998,Interactive display of very large textures,10.1109/VISUAL.1998.745322,https://doi.org/10.1109/VISUAL.1998.745322,343,350,Conferences,"Large textures cause bottlenecks in real time applications that often lead to a loss of interactivity. These performance bottlenecks occur because of disk and network transfer, texture translation, and memory swapping. We present a software solution that alleviates the problems associated with large textures by treating texture as a bandwidth limited resource rather than a finite resource. As a result the display of large textures is reduced to a caching problem in which texture memory serves as the primary cache for texture data, main memory the secondary cache, and local disk the tertiary cache. By using this cache hierarchy, applications are able to maintain real time performance while displaying textures hundreds of times larger than can fit into texture memory.",,D. Cline;P.K. Egbert,"Computer Science Department, Brigham Young University, USA;Computer Science Department, Brigham Young University, USA",,,,18,,
Vis-conf,1998,Battlefield visualization on the responsive workbench,10.1109/VISUAL.1998.745344,https://doi.org/10.1109/VISUAL.1998.745344,463,466,Conferences,"In this paper we describe a battlefield visualization system, called Dragon, which we have implemented on a virtual reality responsive workbench. The Dragon system has been successfully deployed as part of two large military exercises: the Hunter Warrior advanced warfighting experiment, in March 1997, and the Joint Counter Mine advanced concept tactical demonstration, in August and September 1997. We describe battlefield visualization, the Dragon system, and the workbench, and we describe our experiences as part of these two real-world deployments, with an emphasis on lessons learned and needed future work.",,J. Durbin;J.E. Swan;B. Colbert;J. Crowe;R. King;T. King;C. Scannell;Z. Wartell;T. Welsh,"Naval Research Laboratory, Inc., Washington D.C., DC, USA;Naval Research Laboratory, Inc., Washington D.C., DC, USA;Naval Research Laboratory, Inc., Washington D.C., DC, USA;Naval Research Laboratory, Inc., Washington D.C., DC, USA;Naval Research Laboratory, Inc., Washington D.C., DC, USA;;Naval Research Laboratory, Inc., Washington D.C., DC, USA;Naval Research Laboratory, Inc., Washington D.C., DC, USA;",,,,18,,
Vis-conf,1998,Visualizing differences in movies of cortical activity,10.1109/VISUAL.1998.745306,https://doi.org/10.1109/VISUAL.1998.745306,217,224,Conferences,"This paper discusses techniques for visualizing structure in video data and other data sets that represent time snapshots of physical phenomena. Individual frames of a movie are treated as vectors and projected onto a low-dimensional subspace spanned by principal components. Movies can be compared and their differences visualized by analyzing the nature of the subspace and the projections of multiple movies onto the same subspace. The approach is demonstrated on an application in neurobiology in which the electrical response of a visual cortex to optical stimulation is imaged onto a high-speed photodiode array to produce a cortical movie. Techniques for sampling movies over a single trial and multiple trials are discussed. The approach provides the traditional benefits of principal component analysis (compression, noise reduction and classification) and also allows the visual separation of spatial and temporal behavior.",,K.A. Robbins;D.M. Senseman,"Division of Computer Science, University of Texas, San Antonio, San Antonio, TX, USA;Division of Life Sciences, University of Texas, San Antonio, San Antonio, TX, USA",,,,11,,
Vis-conf,1998,Task-specific visualization design: a case study in operational weather forecasting,10.1109/VISUAL.1998.745330,https://doi.org/10.1109/VISUAL.1998.745330,405,409,Conferences,"Efforts to create highly generic visualizations, both content and interface, often when applied to non research oriented or operational activities are composed of several goals. Although these goals may appear to be related, they are often composed of distinct tasks. Generic solutions, even if domain-specific, may lack sufficient focus to be effective for such purposes. The design of different visualization tools matched to a set of tasks but built on top of a common framework with a similar approach to content is a promising alternative. This hypothesis is tested in detail by application to a demanding problem-operational weather forecasting.",,L.A. Treinish,"IBM Thomas J. Watson Research Center, Yorktown Heights, NY, USA",,,,10,,
Vis-conf,1998,A concept for virtual reality tools for design reviews,10.1109/VISUAL.1998.745304,https://doi.org/10.1109/VISUAL.1998.745304,205,210,Conferences,"The paper discusses a concept for virtual reality tools for use in design reviews of mechanical products. In this discussion, the special requirements of a virtual environment are given consideration. The focus of this paper is on suggestions for the visualization and arrangement of a product, its structure, its components and their alternatives together in one environment. The realization of these concepts results in a 3D-interface that allows users, especially engineers, to evaluate different configurations of a product and gives them direct access to the product structure. By applying various visualization techniques, product components and their attributes, e.g., their price, can be brought together into one visualization. Thus, in contrast to state-of-the-art software, the product structure, three-dimensional, real-sized components, and attribute values can be combined together in 3D-visualizations. This research was done in cooperation with Christoph Brandt, member of the Heinz Nixdorf Institute's virtual reality group.",,K. Kremer,"Heinz Nixdorf Inst., Paderborn Univ., Germany",,,,4,,
Vis-conf,1998,Interpolation of triangle hierarchies,10.1109/VISUAL.1998.745328,https://doi.org/10.1109/VISUAL.1998.745328,391,396,Conferences,"We consider interpolation between keyframe hierarchies. We impose a set of weak constraints that allows smooth interpolation between two keyframe hierarchies in an animation or, more generally, allows the interpolation in an n-parameter family of hierarchies. We use hierarchical triangulations obtained by the Rivara element bisection algorithm (M. Rivara, 1984) and impose a weak compatibility constraint on the set of root elements of all keyframe hierarchies. We show that the introduced constraints are rather weak. The strength of our approach is that the interpolation works in the class of conforming triangulations and simplifies the task of finding the intermediate hierarchy, which is the union of the two (or more) keyframe hierarchies involved in the interpolation process. This allows for an efficient generation of the intermediate connectivity and additionally ensures that the intermediate hierarchy is again a conforming hierarchy satisfying the same constraints.",,A. Friedrich;K. Polthier;M. Schmies,"Technical University Berlin, Germany;Technical University Berlin, Germany;Technical University Berlin, Germany",,,,4,,
Vis-conf,1998,Size preserving pattern mapping,10.1109/VISUAL.1998.745325,https://doi.org/10.1109/VISUAL.1998.745325,367,373,Conferences,"We introduce a new approach for mapping texture on volumetric iso-surfaces and parametric surfaces. Our approach maps 2D images on surfaces while maintaining continuity and preserving the size of the mapped images on the models. Our approach is fully automatic. It eliminates the need for manual mapping of texture maps. We use the curvature of a surface at a point in order to continuously vary the scale of the mapped image. This makes our approach dependent only on local attributes of a point (position, normal and its derivatives) and independent of the global shape and topology of an object. Our method can map high resolution images on low resolution volumes, hence enhancing the visual appearance of rendered volume data. We describe a general framework useful for all surface types that have a C/sup 1/ continuous normal. We demonstrate the new method for painting volume data and for mapping cavities on volume data.",,Y. Kurzion;T. Moller;R. Yagel,"Ohio State University, Columbus, OH, US;;Ohio State University, Columbus, OH, US",,,,4,,
conference_external,1998,Proceedings Visualization '98 (Cat. No.98CB36276),10.1109/VISUAL.1998.745279,https://doi.org/10.1109/VISUAL.1998.745279,3,,Conferences,,,,,,,,0,,
conference_external,1998,Author index,10.1109/VISUAL.1998.745356,https://doi.org/10.1109/VISUAL.1998.745356,510,510,Conferences,The author index contains an entry for each author and coauthor included in the proceedings record.,,,,,,,0,,
