Conference,Year,Title,DOI,Link,FirstPage,LastPage,PaperType,Abstract,AuthorNames-Deduped,AuthorNames,AuthorAffiliation,InternalReferences,AuthorKeywords,AminerCitationCount,CitationCount_CrossRef,PubsCited,Award
Vis-conf,2005,The application of GPU particle tracing to diffusion tensor field visualization,10.1109/VISUAL.2005.1532780,https://doi.org/10.1109/VISUAL.2005.1532780,73,78,Conferences,"In this paper we introduce GPU particle tracing for the visualization of 3D diffusion tensor fields. For about half a million particles, reconstruction of diffusion directions from the tensor field, time integration and rendering can be done at interactive rates. Different visualization options like oriented particles of diffusion-dependent shape, stream lines or stream tubes facilitate the use of particle tracing for diffusion tensor visualization. The proposed methods provide efficient and intuitive means to show the dynamics in diffusion tensor fields, and they accommodate the exploration of the diffusion properties of biological tissue.",,P. Kondratieva;J. Kruger;R. Westermann,"Computer Graphics and Visualization Group, Technische Universität München, Germany;Computer Graphics and Visualization Group, Technische Universität München, Germany;Computer Graphics and Visualization Group, Technische Universität München",,",,,,",,11,,
Vis-conf,2005,Teniae coli guided navigation and registration for virtual colonoscopy,10.1109/VISUAL.2005.1532806,https://doi.org/10.1109/VISUAL.2005.1532806,279,285,Conferences,"We present a new method for guiding virtual colonoscopic navigation and registration by using teniae coli as anatomical landmarks. As most existing protocols require a patient to be scanned in both supine and prone positions to increase sensitivity in detecting colonic polyps, reference and registration between scans are necessary. However, the conventional centerline approach, generating only the longitudinal distance along the colon, lacks the necessary orientation information to synchronize the virtual navigation cameras in both scanned positions. In this paper we describe a semi-automatic method to detect teniae coli from a colonic surface model reconstructed from CT colonography. Teniae coli are three bands of longitudinal smooth muscle on the surface of the colon. They form a triple helix structure from the appendix to the sigmoid colon and are ideal references for virtual navigation. Our method was applied to 3 patients resulting in 6 data sets (supine and prone scans). The detected teniae coli matched well with our visual inspection. In addition, we demonstrate that polyps visible on both scans can be located and matched more efficiently with the aid of a teniae coli guided navigation implementation.",,A. Huang;D. Roy;M. Franaszek;R.M. Summers,"Diagnostic Radiology Department, Warren Grant Magnuson Clinical Center, National Institutes of Health DHHS, Bethesda, MD, USA;Diagnostic Radiology Department, Warren Grant Magnuson Clinical Center, National Institutes of Health DHHS, Bethesda, MD, USA;Diagnostic Radiology Department, National Institutes of Health, Bethesda, MD;Diagnostic Radiology Department, Warren Grant Magnuson Clinical Center, National Institutes of Health DHHS, Bethesda, MD, USA",,",,,,",,7,,
Vis-conf,2005,Marching diamonds for unstructured meshes,10.1109/VISUAL.2005.1532825,https://doi.org/10.1109/VISUAL.2005.1532825,423,429,Conferences,"We present a higher-order approach to the extraction of isosurfaces from unstructured meshes. Existing methods use linear interpolation along each mesh edge to find isosurface intersections. In contrast, our method determines intersections by performing barycentric interpolation over diamonds formed by the tetrahedra incident to each edge. Our method produces smoother, more accurate isosurfaces. Additionally, interpolating over diamonds, rather than linearly interpolating edge endpoints. enables us to identify up to two isosurface intersections per edge. This paper details how our new technique extracts isopoints, and presents a simple connection strategy for forming a triangle mesh isosurface.",,J.C. Anderson;J.C. Bennett;K.I. Joy,"Institute for Data Analysis and Visualization, Computer Science Department, University of California, Davis, USA;Institute for Data Analysis and Visualization, Computer Science Department, University of California, Davis, USA;Institute for Data Analysis and Visualization, Computer Science Department, University of California, Davis, USA",,",,,,",,1,,
Vis-conf,2005,The value of visualization,10.1109/VISUAL.2005.1532781,https://doi.org/10.1109/VISUAL.2005.1532781,79,86,Conferences,"The field of visualization is getting mature. Many problems have been solved, and new directions are sought for. In order to make good choices, an understanding of the purpose and meaning of visualization is needed. Especially, it would be nice if we could assess what a good visualization is. In this paper an attempt is made to determine the value of visualization. A technological viewpoint is adopted, where the value of visualization is measured based on effectiveness and efficiency. An economic model of visualization is presented, and benefits and costs are established. Next, consequences (brand limitations of visualization are discussed (including the use of alternative methods, high initial costs, subjective/less, and the role of interaction), as well as examples of the use of the model for the judgement of existing classes of methods and understanding why they are or are not used in practice. Furthermore, two alternative views on visualization are presented and discussed: viewing visualization as an art or as a scientific discipline. Implications and future directions are identified.",,J.J. van Wijk,"Department Mathematics and Computer Science, Technische Universiteit Eindhoven, Netherlands",,",,,,",,84,,
Vis-conf,2005,Evolutionary morphing,10.1109/VISUAL.2005.1532826,https://doi.org/10.1109/VISUAL.2005.1532826,431,438,Conferences,"We introduce a technique to visualize the gradual evolutionary change of the shapes of living things as a morph between known three-dimensional shapes. Given geometric computer models of anatomical shapes for some collection of specimens - here the skulls of the some of the extant members of a family of monkeys - an evolutionary tree for the group implies a hypothesis about the way in which the shape changed through time. We use a statistical model which expresses the value of some continuous variable at an internal point in the tree as a weighted average of the values at the leaves. The framework of geometric morphometrics can then be used to define a shape-space, based on the correspondences of landmark points on the surfaces, within which these weighted averages can be realized as actual surfaces. Our software provides tools for performing and visualizing such an analysis in three dimensions. Beginning with laser range scans of crania, we use our landmark editor to interactively place landmark points on the surface. We use these to compute a ""tree-morph"" that smoothly interpolates the shapes across the tree. Each intermediate shape in the morph is a linear combination of all of the input surfaces. We create a surface model for an intermediate shape by warping all the input meshes towards the correct shape and then blending them together. To do the blending, we compute a weighted average of their associated trivariate distance functions and then extract a surface from the resulting function. We implement this idea using the squared distance function, rather than the usual signed distance function, in a novel way.",,D.F. Wiley;N. Amenta;D.A. Alcantara;D. Ghosh;Y.J. Kil;E. Delson;W. Harcourt-Smith;F.J. Rohlf;K. St John;B. Hamann,"Institute for Data Analysis and Visualization and Department of Computer Science, University of California, Davis, USA;Institute for Data Analysis and Visualization and Department of Computer Science, University of California, Davis, USA;Institute for Data Analysis and Visualization and Department of Computer Science, University of California, Davis, USA;Institute for Data Analysis and Visualization and Department of Computer Science, University of California, Davis, USA;Institute for Data Analysis and Visualization and Department of Computer Science, University of California, Davis, USA;American Museum of Natural, University of New York, UK;American Museum of Natural, University of New York, UK;Department of Ecology and Evolution, State University of New York, Stony Brook, USA;American Museum of Natural, University of New York, UK;Institute for Data Analysis and Visualization and Department of Computer Science, University of California, Davis, USA",,",,,,",,72,,
Vis-conf,2005,VisTrails: enabling interactive multiple-view visualizations,10.1109/VISUAL.2005.1532788,https://doi.org/10.1109/VISUAL.2005.1532788,135,142,Conferences,"VisTrails is a new system that enables interactive multiple-view visualizations by simplifying the creation and maintenance of visualization pipelines, and by optimizing their execution. It provides a general infrastructure that can be combined with existing visualization systems and libraries. A key component of VisTrails is the visualization trail (vistrail), a formal specification of a pipeline. Unlike existing dataflow-based systems, in VisTrails there is a clear separation between the specification of a pipeline and its execution instances. This separation enables powerful scripting capabilities and provides a scalable mechanism for generating a large number of visualizations. VisTrails also leverages the vistrail specification to identify and avoid redundant operations. This optimization is especially useful while exploring multiple visualizations. When variations of the same pipeline need to be executed, substantial speedups can be obtained by caching the results of overlapping subsequences of the pipelines. In this paper, we describe the design and implementation of VisTrails, and show its effectiveness in different application scenarios.",,L. Bavoil;S.P. Callahan;P.J. Crossno;J. Freire;C.E. Scheidegger;C.T. Silva;H.T. Vo,"Scientific Computing and Imaging Institute, University of Utah, USA;Scientific Computing and Imaging Institute, University of Utah, USA;Sandia National Laboratories, USA;School of Computing, University of Utah, USA;Scientific Computing and Imaging Institute, University of Utah, USA;Scientific Computing and Imaging Institute, University of Utah, USA;Scientific Computing and Imaging Institute, University of Utah, USA",,",,,,",,66,,
Vis-conf,2005,Evaluation of fiber clustering methods for diffusion tensor imaging,10.1109/VISUAL.2005.1532779,https://doi.org/10.1109/VISUAL.2005.1532779,65,72,Conferences,"Fiber tracking is a standard approach for the visualization of the results of diffusion tensor imaging (DTI). If fibers are reconstructed and visualized individually through the complete white matter, the display gets easily cluttered making it difficult to get insight in the data. Various clustering techniques have been proposed to automatically obtain bundles that should represent anatomical structures, but it is unclear which clustering methods and parameter settings give the best results. We propose a framework to validate clustering methods for white-matter fibers. Clusters are compared with a manual classification which is used as a ground truth. For the quantitative evaluation of the methods, we developed a new measure to assess the difference between the ground truth and the clusterings. The measure was validated and calibrated by presenting different clusterings to physicians and asking them for their judgement. We found that the values of our new measure for different clusterings match well with the opinions of physicians. Using this framework, we have evaluated different clustering algorithms, including shared nearest neighbor clustering, which has not been used before for this purpose. We found that the use of hierarchical clustering using single-link and a fiber similarity measure based on the mean distance between fibers gave the best results.",,B. Moberts;A. Vilanova;J.J. van Wijk,"Department of Mathematics and Computer Science, Technische Universiteit Eindhoven, Eindhoven, Netherlands;Department of Biomedical Engineering, Technische Universiteit Eindhoven, Eindhoven, Netherlands;Department of Mathematics and Computer Science, Technische Universiteit Eindhoven, Eindhoven, Netherlands",,",,,,",,58,,
Vis-conf,2005,VolumeShop: an interactive system for direct volume illustration,10.1109/VISUAL.2005.1532856,https://doi.org/10.1109/VISUAL.2005.1532856,671,678,Conferences,"Illustrations play a major role in the education process. Whether used to teach a surgical or radiologic procedure, to illustrate normal or aberrant anatomy, or to explain the functioning of a technical device, illustration significantly impacts learning. Although many specimens are readily available as volumetric data sets, particularly in medicine, illustrations are commonly produced manually as static images in a time-consuming process. Our goal is to create a fully dynamic three-dimensional illustration environment which directly operates on volume data. Single images have the aesthetic appeal of traditional illustrations, but can be interactively altered and explored. In this paper we present methods to realize such a system which combines artistic visual styles and expressive visualization techniques. We introduce a novel concept for direct multi-object volume visualization which allows control of the appearance of inter-penetrating objects via two-dimensional transfer functions. Furthermore, a unifying approach to efficiently integrate many non-photorealistic rendering models is presented. We discuss several illustrative concepts which can be realized by combining cutaways, ghosting, and selective deformation. Finally, we also propose a simple interface to specify objects of interest through three-dimensional volumetric painting. All presented methods are integrated into VolumeShop, an interactive hardware-accelerated application for direct volume illustration.",,S. Bruckner;M.E. Groller,"Institute of Computer Graphics and Algorithms, University of Technology, Vienna, Austria;Institute of Computer Graphics and Algorithms, University of Technology, Vienna, Austria",,",,,,",,51,,
Vis-conf,2005,View selection for volume rendering,10.1109/VISUAL.2005.1532833,https://doi.org/10.1109/VISUAL.2005.1532833,487,494,Conferences,"In a visualization of a three-dimensional dataset, the insights gained are dependent on what is occluded and what is not. Suggestion of interesting viewpoints can improve both the speed and efficiency of data understanding. This paper presents a view selection method designed for volume rendering. It can be used to find informative views for a given scene, or to find a minimal set of representative views which capture the entire scene. It becomes particularly useful when the visualization process is non-interactive - for example, when visualizing large datasets or time-varying sequences. We introduce a viewpoint ""goodness"" measure based on the formulation of entropy from information theory. The measure takes into account the transfer function, the data distribution and the visibility of the voxels. Combined with viewpoint properties like view-likelihood and view-stability, this technique can be used as a guide, which suggests ""interesting"" viewpoints for further exploration. Domain knowledge is incorporated into the algorithm via an importance transfer function or volume. This allows users to obtain view selection behaviors tailored to their specific situations. We generate a view space partitioning, and select one representative view for each partition. Together, this set of views encapsulates the ""interesting"" and distinct views of the data. Viewpoints in this set can be used as starting points for interactive exploration of the data, thus reducing the human effort in visualization. In non-interactive situations, such a set can be used as a representative visualization of the dataset from all directions.",,U.D. Bordoloi;H.-W. Shen,"Ohio State Uinversity, USA;Ohio State Uinversity, USA",,",,,,",,51,,
Vis-conf,2005,A contract based system for large data visualization,10.1109/VISUAL.2005.1532795,https://doi.org/10.1109/VISUAL.2005.1532795,191,198,Conferences,"VisIt is a richly featured visualization tool that is used to visualize some of the largest simulations ever run. The scale of these simulations requires that optimizations are incorporated into every operation VisIt performs. But the set of applicable optimizations that VisIt can perform is dependent on the types of operations being done. Complicating the issue, VisIt has a plugin capability that allows new, unforeseen components to be added, making it even harder to determine which optimizations can be applied. We introduce the concept of a contract to the standard data flow network design. This contract enables each component of the data flow network to modify the set of optimizations used. In addition, the contract allows for new components to be accommodated gracefully within VisIt's data flow network system.",,H. Childs;E. Brugger;K. Bonnell;J. Meredith;M. Miller;B. Whitlock;N. Max,"Lawrence Livermore National Laboratory, University of California, Davis, USA;Lawrence Livemore National Laboratory, USA;Lawrence Livemore National Laboratory, USA;Lawrence Livemore National Laboratory, USA;Lawrence Livemore National Laboratory, USA;Lawrence Livemore National Laboratory, USA;University of California, Davis, USA",,",,,,",,46,,
Vis-conf,2005,Streaming meshes,10.1109/VISUAL.2005.1532800,https://doi.org/10.1109/VISUAL.2005.1532800,231,238,Conferences,"Recent years have seen an immense increase in the complexity of geometric data sets. Today's gigabyte-sized polygon models can no longer be completely loaded into the main memory of common desktop PCs. Unfortunately, current mesh formats, which were designed years ago when meshes were orders of magnitudes smaller, do not account for this. Using such formats to store large meshes is inefficient and complicates all subsequent processing. We describe a streaming format for polygon meshes that is simple enough to replace current offline mesh formats and is more suitable for representing large data sets. Furthermore, it is an ideal input and output format for I/O-efficient out-of-core algorithms that process meshes in a streaming, possibly pipelined, fashion. This paper chiefly concerns the underlying theory and the practical aspects of creating and working with this new representation. In particular, we describe desirable qualities for streaming meshes and methods for converting meshes from a traditional to a streaming format. A central theme of this paper is the issue of coherent and compatible layouts of the mesh vertices and polygons. We present metrics and diagrams that characterize the coherence of a mesh layout and suggest appropriate strategies for improving its ""streamability"". To this end, we outline several out-of-core algorithms for reordering meshes with poor coherence, and present results for a menagerie of well known and generally incoherent surface meshes.",,M. Isenburg;P. Lindstrom,"North Carolina State University, Chapel Hill, USA;Lawrence Livermore, National Laboratory, USA",,",,,,",,33,,
Vis-conf,2005,A feature-driven approach to locating optimal viewpoints for volume visualization,10.1109/VISUAL.2005.1532834,https://doi.org/10.1109/VISUAL.2005.1532834,495,502,Conferences,"Optimal viewpoint selection is an important task because it considerably influences the amount of information contained in the 2D projected images of 3D objects, and thus dominates their first impressions from a psychological point of view. Although several methods have been proposed that calculate the optimal positions of viewpoints especially for 3D surface meshes, none has been done for solid objects such as volumes. This paper presents a new method of locating such optimal viewpoints when visualizing volumes using direct volume rendering. The major idea behind our method is to decompose an entire volume into a set of feature components, and then find a globally optimal viewpoint by finding a compromise between locally optimal viewpoints for the components. As the feature components, the method employs interval volumes and their combinations that characterize the topological transitions of isosurfaces according to the scalar field. Furthermore, opacity transfer functions are also utilized to assign different weights to the decomposed components so that users can emphasize features of specific interest in the volumes. Several examples of volume datasets together with their optimal positions of viewpoints are exhibited in order to demonstrate that the method can effectively guide naive users to find optimal projections of volumes.",,S. Takahashi;I. Fujishiro;Y. Takeshima;T. Nishita,"University of Tokyo, Japan;University of Tohoku, Japan;Tohoku University;University of Tokyo, Japan",,",,,,",,32,,
Vis-conf,2005,Illuminated lines revisited,10.1109/VISUAL.2005.1532772,https://doi.org/10.1109/VISUAL.2005.1532772,19,26,Conferences,"For the rendering of vector and tensor fields, several texture-based volumetric rendering methods were presented in recent years. While they have indisputable merits, the classical vertex-based rendering of integral curves has the advantage of better zooming capabilities as it is not bound to a fixed resolution. It has been shown that lighting can improve spatial perception of lines significantly, especially if lines appear in bundles. Although OpenGL does not directly support lighting of lines, fast rendering of illuminated lines can be achieved by using basic texture mapping. This existing technique is based on a maximum principle which gives a good approximation of specular reflection. Diffuse reflection however is essentially limited to bidirectional lights at infinity. We show how the realism can be further increased by improving diffuse reflection. We present simplified expressions for the Phong/Blinn lighting of infinitesimally thin cylindrical tubes. Based on these, we propose a fast rendering technique with diffuse and specular reflection for orthographic and perspective views and for multiple local and infinite lights. The method requires commonly available programmable vertex and fragment shaders and only two-dimensional lookup textures.",,O. Mallo;R. Peikert;C. Sigg;F. Sadlo,"ETH Zürich, Switzerland;ETH Zürich, Switzerland;ETH Zürich, Switzerland;ETH Zürich, Switzerland",,"Field lines,illumination,vector field visualization,texture mapping,graphics hardware",,31,,
Vis-conf,2005,The magic volume lens: an interactive focus+context technique for volume rendering,10.1109/VISUAL.2005.1532818,https://doi.org/10.1109/VISUAL.2005.1532818,367,374,Conferences,"The size and resolution of volume datasets in science and medicine are increasing at a rate much greater than the resolution of the screens used to view them. This limits the amount of data that can be viewed simultaneously, potentially leading to a loss of overall context of the data when the user views or zooms into a particular area of interest. We propose a focus+context framework that uses various standard and advanced magnification lens rendering techniques to magnify the features of interest, while compressing the remaining volume regions without clipping them away completely. Some of these lenses can be interactively configured by the user to specify the desired magnification patterns, while others are feature-adaptive. All our lenses are accelerated on the GPU. They allow the user to interactively manage the available screen area, dedicating more area to the more resolution-important features.",,L. Wang;Y. Zhao;K. Mueller;A. Kaufman,"Center for Visual Computing, Computer Science, Stony Brook University, USA;Center for Visual Computing, Computer Science, Stony Brook University, USA;Center for Visual Computing, Computer Science, Stony Brook University, USA;Center for Visual Computing, Computer Science, Stony Brook University, USA",,",,,,",,30,,
Vis-conf,2005,Visualization with stylized line primitives,10.1109/VISUAL.2005.1532859,https://doi.org/10.1109/VISUAL.2005.1532859,695,702,Conferences,"Line primitives are a very powerful visual attribute used for scientific visualization and in particular for 3D vector-field visualization. We extend the basic line primitives with additional visual attributes including color, line width, texture and orientation. To implement the visual attributes we represent the stylized line primitives as generalized cylinders. One important contribution of our work is an efficient rendering algorithm for stylized lines, which is hybrid in the sense that it uses both CPU and GPU based rendering. We improve the depth perception with a shadow algorithm. We present several applications for the visualization with stylized lines among which are the visualizations of 3D vector fields and molecular structures.",,C. Stoll;S. Gumhold;H.-P. Seidel,"Max Planck Institut fuer Informatik, Saarbruecken, Germany;Max Planck Institut fuer Informatik, Saarbruecken, Germany;Max Planck Institut fuer Informatik, Saarbruecken, Germany",,",,,,",,28,,
Vis-conf,2005,Statistically quantitative volume visualization,10.1109/VISUAL.2005.1532807,https://doi.org/10.1109/VISUAL.2005.1532807,287,294,Conferences,"Visualization users are increasingly in need of techniques for assessing quantitative uncertainty and error in the images produced. Statistical segmentation algorithms compute these quantitative results, yet volume rendering tools typically produce only qualitative imagery via transfer function-based classification. This paper presents a visualization technique that allows users to interactively explore the uncertainty, risk, and probabilistic decision of surface boundaries. Our approach makes it possible to directly visualize the combined ""fuzzy"" classification results from multiple segmentations by combining these data into a unified probabilistic data space. We represent this unified space, the combination of scalar volumes from numerous segmentations, using a novel graph-based dimensionality reduction scheme. The scheme both dramatically reduces the dataset size and is suitable for efficient, high quality, quantitative visualization. Lastly, we show that the statistical risk arising from overlapping segmentations is a robust measure for visualizing features and assigning optical properties.",,J.M. Kniss;R. Van Uitert;A. Stephens;G.-S. Li;T. Tasdizen;C. Hansen,"University of Utah, USA;National Institutes of Health DHHS, USA;University of Utah, USA;University of Utah, USA;University of Utah, USA;University of Utah, USA",,",,,,",,28,,
Vis-conf,2005,Farthest point seeding for efficient placement of streamlines,10.1109/VISUAL.2005.1532832,https://doi.org/10.1109/VISUAL.2005.1532832,479,486,Conferences,"We propose a novel algorithm for placement of streamlines from two-dimensional steady vector or direction fields. Our method consists of placing one streamline at a time by numerical integration starting at the furthest away from all previously placed streamlines. Such a farthest point seeding strategy leads to high quality placements by favoring long streamlines, while retaining uniformity with the increasing density. Our greedy approach generates placements of comparable quality with respect to the optimization approach from Turk and Banks, while being 200 times faster. Simplicity, robustness as well as efficiency is achieved through the use of a Delaunay triangulation to model the streamlines, address proximity queries and determine the biggest voids by exploiting the empty circle property. Our method handles variable density and extends to multiresolution.",,A. Mebarki;P. Alliez;O. Devillers,"I.N.R.I.A. Sophia Antipolis, France;I.N.R.I.A. Sophia Antipolis, France;I.N.R.I.A. Sophia Antipolis, France",,",,,,",,27,,
Vis-conf,2005,Query-driven visualization of large data sets,10.1109/VISUAL.2005.1532792,https://doi.org/10.1109/VISUAL.2005.1532792,167,174,Conferences,"We present a practical and general-purpose approach to large and complex visual data analysis where visualization processing, rendering and subsequent human interpretation is constrained to the subset of data deemed interesting by the user. In many scientific data analysis applications, ""interesting"" data can be defined by compound Boolean range queries of the form (temperature>1000) AND (70<pressure<90). As data sizes grow larger, a central challenge is to answer such queries as efficiently as possible. Prior work in the visualization community has focused on answering range queries for scalar fields within the context of accelerating the search phase of isosurface algorithms. In contrast, our work describes an approach that leverages state-of-the-art indexing technology from the scientific data management community called ""bitmap indexing"". Our implementation, which we call ""DEX"" (short for dextrous data explorer), uses bitmap indexing to efficiently answer multivariate, multidimensional data queries to provide input to a visualization pipeline. We present an analysis overview and benchmark results that show bitmap indexing offers significant storage and performance improvements when compared to previous approaches for accelerating the search phase of isosurface algorithms. More importantly, since bitmap indexing supports complex multidimensional, multivariate range queries, it is more generally applicable to scientific data visualization and analysis problems. In addition to benchmark performance and analysis, we apply DEX to a typical scientific visualization problem encountered in combustion simulation data analysis.",,K. Stockinger;J. Shalf;K. Wu;E.W. Bethel,"Computational Res. Div., Lawrence Berkeley Lab., CA, USA;Computational Res. Div., Lawrence Berkeley Lab., CA, USA;Computational Res. Div., Lawrence Berkeley Lab., CA, USA;Computational Res. Div., Lawrence Berkeley Lab., CA, USA",,",,,,",,25,,
Vis-conf,2005,Topology-based simplification for feature extraction from 3D scalar fields,10.1109/VISUAL.2005.1532839,https://doi.org/10.1109/VISUAL.2005.1532839,535,542,Conferences,"In this paper, we present a topological approach for simplifying continuous functions defined on volumetric domains. We introduce two atomic operations that remove pairs of critical points of the function and design a combinatorial algorithm that simplifies the Morse-Smale complex by repeated application of these operations. The Morse-Smale complex is a topological data structure that provides a compact representation of gradient flow between critical points of a function. Critical points paired by the Morse-Smale complex identify topological features and their importance. The simplification procedure leaves important critical points untouched, and is therefore useful for extracting desirable features. We also present a visualization of the simplified topology.",,A. Gyulassy;Vijay Natarajan,"Institute for Data Analysis and Visualization, University of California, Davis;Institute for Data Analysis and Visualization, University of California, Davis",,",,,,",,24,,
Vis-conf,2005,Visual analysis and exploration of fluid flow in a cooling jacket,10.1109/VISUAL.2005.1532850,https://doi.org/10.1109/VISUAL.2005.1532850,623,630,Conferences,"We present a visual analysis and exploration of fluid flow through a cooling jacket. Engineers invest a large amount of time and serious effort to optimize the flow through this engine component because of its important role in transferring heat away from the engine block. In this study we examine the design goals that engineers apply in order to construct an ideal-as-possible cooling jacket geometry and use a broad range of visualization tools in order to analyze, explore, and present the results. We systematically employ direct, geometric, and texture-based flow visualization techniques as well as automatic feature extraction and interactive feature-based methodology. And we discuss the relative advantages and disadvantages of these approaches as well as the challenges, both technical and perceptual with this application. The result is a feature-rich state-of-the-art flow visualization analysis applied to an important and complex data set from real-world computational fluid dynamics simulations.",,R.S. Laramee;C. Garth;H. Doleisch;J. Schneider;H. Hauser;H. Hagen,"VRVis Research Center, Vienna, Austria;Department of Computer Science, University of Kaiserslautern, Germany;VRVis Research Center, Vienna, Austria;Department of Advanced Simulation Technologies (AST), AVL, Graz, Austria;VRVis Research Center, Vienna, Austria;Department of Computer Science, University of Kaiserslautern, Germany",,",,,,",,24,,
Vis-conf,2005,Effectively visualizing large networks through sampling,10.1109/VISUAL.2005.1532819,https://doi.org/10.1109/VISUAL.2005.1532819,375,382,Conferences,"We study the problem of visualizing large networks and develop techniques for effectively abstracting a network and reducing the size to a level that can be clearly viewed. Our size reduction techniques are based on sampling, where only a sample instead of the full network is visualized. We propose a randomized notion of ""focus"" that specifies a part of the network and the degree to which it needs to be magnified. Visualizing a sample allows our method to overcome the scalability issues inherent in visualizing massive networks. We report some characteristics that frequently occur in large networks and the conditions under which they are preserved when sampling from a network. This can be useful in selecting a proper sampling scheme that yields a sample with similar characteristics as the original network. Our method is built on top of a relational database, thus it can be easily and efficiently implemented using any off-the-shelf database software. As a proof of concept, we implement our methods and report some of our experiments over the movie database and the connectivity graph of the Web.",,D. Rafiei,"Computing Science Department, University of Alberta",,",,,,",,22,,
Vis-conf,2005,Understanding visualization through spatial ability differences,10.1109/VISUAL.2005.1532836,https://doi.org/10.1109/VISUAL.2005.1532836,511,518,Conferences,"Little is known about the cognitive abilities which influence the comprehension of scientific and information visualizations and what properties of the visualization affect comprehension. Our goal in this paper is to understand what makes visualizations difficult. We address this goal by examining the spatial ability differences in a diverse population selected for spatial ability variance. For example, how is, spatial ability related to visualization comprehension? What makes a particular visualization difficult or time intensive for specific groups of subjects? In this paper, we present the results of an experiment designed to answer these questions. Fifty-six subjects were tested on a basic visualization task and given standard paper tests of spatial abilities. An equal number of males and females were recruited in this study in order to increase spatial ability variance. Our results show that high spatial ability is correlated with accuracy on our three-dimensional visualization test, but not with time. High spatial ability subjects also had less difficulty with object complexity and the hidden properties of an object.",,M.C. Velez;D. Silver;M. Tremaine,"Center for Advanced Information Processing Rutgers, State University of New Jersey, USA;Center for Advanced Information Processing Rutgers, State University of New Jersey, USA;Center for Advanced Information Processing Rutgers, State University of New Jersey, USA",,",,,,",,21,,
Vis-conf,2005,Curve-skeleton applications,10.1109/VISUAL.2005.1532783,https://doi.org/10.1109/VISUAL.2005.1532783,95,102,Conferences,"Curve-skeletons are a 1D subset of the medial surface of a 3D object and are useful for many visualization tasks including virtual navigation, reduced-model formulation, visualization improvement, mesh repair, animation, etc. There are many algorithms in the literature describing extraction methodologies for different applications; however, it is unclear how general and robust they are. In this paper, we provide an overview of many curve-skeleton applications and compile a set of desired properties of such representations. We also give a taxonomy of methods and analyze the advantages and drawbacks of each class of algorithms.",,N.D. Cornea;D. Silver;P. Min,"Rutgers University, NJ, USA;Rutgers University, NJ, USA;John Cabot University, Rome, Italy",,",,,,",,21,,
Vis-conf,2005,Opening the black box - data driven visualization of neural networks,10.1109/VISUAL.2005.1532820,https://doi.org/10.1109/VISUAL.2005.1532820,383,390,Conferences,"Artificial neural networks are computer software or hardware models inspired by the structure and behavior of neurons in the human nervous system. As a powerful learning tool, increasingly neural networks have been adopted by many large-scale information processing applications but there is no a set of well defined criteria for choosing a neural network. The user mostly treats a neural network as a black box and cannot explain how learning from input data was done nor how performance can be consistently ensured. We have experimented with several information visualization designs aiming to open the black box to possibly uncover underlying dependencies between the input data and the output data of a neural network. In this paper, we present our designs and show that the visualizations not only help us design more efficient neural networks, but also assist us in the process of using neural networks for problem solving such as performing a classification task.",,F.-Y. Tzeng;K.-L. Ma,"Department of Computer Science, University of California, Davis, USA;Dept. of Comput. Sci., California Univ., Davis, CA, USA",,",,,,",,20,,
Vis-conf,2005,Strategy for seeding 3D streamlines,10.1109/VISUAL.2005.1532831,https://doi.org/10.1109/VISUAL.2005.1532831,471,478,Conferences,"This paper presents a strategy for seeding streamlines in 3D flow fields. Its main goal is to capture the essential flow patterns and to provide sufficient coverage in the field while reducing clutter. First, critical points of the flow field are extracted to identify regions with important flow patterns that need to be presented. Different seeding templates are then used around the vicinity of the different critical points. Because there is significant variability in the flow pattern even for the same type of critical point, our template can change shape depending on how far the critical point is from transitioning into another type of critical point. To accomplish this, we introduce the /spl alpha/-/spl beta/ map of 3D critical points. Next, we use Poisson seeding to populate the empty regions. Finally, we filter the streamlines based on their geometric and spatial properties. Altogether, this multi-step strategy reduces clutter and yet captures the important 3D flow features.",,Xiangong Ye;D. Kao;A. Pang,"Computer Science Department, University of California, Santa Cruz, USA;NASA Ames Research Center, USA;Computer Science Department, University of California, Santa Cruz, USA",,",,,,",,19,,
Vis-conf,2005,Extraction of parallel vector surfaces in 3D time-dependent fields and application to vortex core line tracking,10.1109/VISUAL.2005.1532851,https://doi.org/10.1109/VISUAL.2005.1532851,631,638,Conferences,"We introduce an approach to tracking vortex core lines in time-dependent 3D flow fields which are defined by the parallel vectors approach. They build surface structures in the 4D space-time domain. To extract them, we introduce two 4D vector fields which act as feature flow fields, i.e., their integration gives the vortex core structures. As part of this approach, we extract and classify local bifurcations of vortex core lines in space-time. Based on a 4D stream surface integration, we provide an algorithm to extract the complete vortex core structure. We apply our technique to a number of test data sets.",,H. Theisel;J. Sahner;T. Weinkauf;H.-C. Hege;H.-P. Seidel,"MPI Saarbrücken;ZIB, Berlin, Germany;ZIB, Berlin, Germany;ZIB, Berlin, Germany;MPI Saarbrücken, Germany",,",,,,",,17,,
Vis-conf,2005,Visualizing data with motion,10.1109/VISUAL.2005.1532838,https://doi.org/10.1109/VISUAL.2005.1532838,527,534,Conferences,"This paper describes an experimental study of three perceptual properties of motion: flicker, direction, and velocity. Our goal is to understand how to apply these properties to represent data in a visualization environment. Results from our experiments show that all three properties can encode multiple data values, but that minimum visual differences are needed to ensure rapid and accurate target detection: flicker must be coherent and must have a cycle length of 120 milliseconds or greater, direction must differ by at least 20/spl deg/, and velocity must differ by at least 0.43/spl deg/ of subtended visual angle. We conclude with an overview of how we are applying our results to real-world data, and then discuss future work we plan to pursue.",,D.E. Huber;C.G. Healey,"Northrop Grumman Corporation, USA;North Carolina State University, USA",,",,,,",,17,,
Vis-conf,2005,Illustration and photography inspired visualization of flows and volumes,10.1109/VISUAL.2005.1532858,https://doi.org/10.1109/VISUAL.2005.1532858,687,694,Conferences,"Understanding and analyzing complex volumetrically varying data is a difficult problem. Many computational visualization techniques have had only limited success in succinctly portraying the structure of three-dimensional turbulent flow. Motivated by both the extensive history and success of illustration and photographic flow visualization techniques, we have developed a new interactive volume rendering and visualization system for flows and volumes that simulates and enhances traditional illustration, experimental advection, and photographic flow visualization techniques. Our system uses a combination of varying focal and contextual illustrative styles, new advanced two-dimensional transfer functions, enhanced Schlieren and shadowgraphy shaders, and novel oriented structure enhancement techniques to allow interactive visualization, exploration, and comparative analysis of scalar, vector, and time-varying volume datasets. Both traditional illustration techniques and photographic flow visualization techniques effectively reduce visual clutter by using compact oriented structure information to convey three-dimensional structures. Therefore, a key to the effectiveness of our system is using one-dimensional (Schlieren and shadowgraphy) and two-dimensional (silhouette) oriented structural information to reduce visual clutter, while still providing enough three-dimensional structural information for the user's visual system to understand complex three-dimensional flow data. By combining these oriented feature visualization techniques with flexible transfer function controls, we can visualize scalar and vector data, allow comparative visualization of flow properties in a succinct, informative manner, and provide continuity for visualizing time-varying datasets.",,N.A. Svakhine;Y. Jang;D. Ebert;K. Gaither,"Purdue University, USA;Purdue University, USA;Purdue University, USA;University of Technology, Austin, USA",,",,,,",,17,,
Vis-conf,2005,Extracting higher order critical points and topological simplification of 3D vector fields,10.1109/VISUAL.2005.1532842,https://doi.org/10.1109/VISUAL.2005.1532842,559,566,Conferences,"This paper presents an approach to extracting and classifying higher order critical points of 3D vector fields. To do so, we place a closed convex surface s around the area of interest. Then we show that the complete 3D classification of a critical point into areas of different flow behavior is equivalent to extracting the topological skeleton of an appropriate 2D vector field on s, if each critical point is equipped with an additional bit of information. Out of this skeleton, we create an icon which replaces the complete topological structure inside s for the visualization. We apply our method to find a simplified visual representation of clusters of critical points, leading to expressive visualizations of topologically complex 3D vector fields.",,T. Weinkauf;H. Theisel;K. Shi;H.-C. Hege;H.-P. Seidel,"ZIB Berlin, Germany;MPI Saarbrücken, Germany;MPI Saarbrücken, Germany;ZIB Berlin, Germany;MPI Saarbrücken, Germany",,",,,,",,16,,
Vis-conf,2005,Texture-based visualization of uncertainty in flow fields,10.1109/VISUAL.2005.1532853,https://doi.org/10.1109/VISUAL.2005.1532853,647,654,Conferences,"In this paper, we present two novel texture-based techniques to visualize uncertainty in time-dependent 2D flow fields. Both methods use semi-Lagrangian texture advection to show flow direction by streaklines and convey uncertainty by blurring these streaklines. The first approach applies a cross advection perpendicular to the flow direction. The second method employs isotropic diffusion that can be implemented by Gaussian filtering. Both methods are derived from a generic filtering process that is incorporated into the traditional texture advection pipeline. Our visualization methods allow for a continuous change of the density of flow representation by adapting the density of particle injection. All methods can be mapped to efficient GPU implementations. Therefore, the user can interactively control all important characteristics of the system like particle density, error influence, or dye injection to create meaningful illustrations of the underlying uncertainty. Even though there are many sources of uncertainties, we focus on uncertainty that occurs during data acquisition. We demonstrate the usefulness of our methods for the example of real-world fluid flow data measured with the particle image velocimetry (PIV) technique. Furthermore, we compare these techniques with an adapted multi-frequency noise approach.",,R.P. Botchen;D. Weiskopf;T. Ertl,"University of Stuttgart, Germany;University of Stuttgart, Germany;University of Stuttgart, Germany",,",,,,",,15,,
Vis-conf,2005,Illustration-inspired techniques for visualizing time-varying data,10.1109/VISUAL.2005.1532857,https://doi.org/10.1109/VISUAL.2005.1532857,679,686,Conferences,"Traditionally, time-varying data has been visualized using snapshots of the individual time steps or an animation of the snapshots shown in a sequential manner. For larger datasets with many time-varying features, animation can be limited in its use, as an observer can only track a limited number of features over the last few frames. Visually inspecting each snapshot is not practical either for a large number of time-steps. We propose new techniques inspired from the illustration literature to convey change over time more effectively in a time-varying dataset. Speedlines are used extensively by cartoonists to convey motion, speed, or change over different panels. Flow ribbons are another technique used by cartoonists to depict motion in a single frame. Strobe silhouettes are used to depict previous positions of an object to convey the previous positions of the object to the user. These illustration-inspired techniques can be used in conjunction with animation to convey change over time.",,A. Joshi;P. Rheingans,"University of Maryland, Baltimore, USA;University of Maryland, Baltimore, USA",,",,,,",,14,,
Vis-conf,2005,HOT-lines: tracking lines in higher order tensor fields,10.1109/VISUAL.2005.1532773,https://doi.org/10.1109/VISUAL.2005.1532773,27,34,Conferences,"Tensors occur in many areas of science and engineering. Especially, they are used to describe charge, mass and energy transport (i.e. electrical conductivity tensor, diffusion tensor, thermal conduction tensor resp.) If the locale transport pattern is complicated, usual second order tensor representation is not sufficient. So far, there are no appropriate visualization methods for this case. We point out similarities of symmetric higher order tensors and spherical harmonics. A spherical harmonic representation is used to improve tensor glyphs. This paper unites the definition of streamlines and tensor lines and generalizes tensor lines to those applications where second order tensors representations fail. The algorithm is tested on the tractography problem in diffusion tensor magnetic resonance imaging (DT-MRI) and improved for this special application.",,M. Hlawitschka;G. Scheuermann,"Institute for Computer Sciences, University of Leipzig, Leipzig, Germany;Institute for Computer Sciences, University of Leipzig, Leipzig, Germany",,",,,,",,14,,
Vis-conf,2005,COTS cluster-based sort-last rendering: performance evaluation and pipelined implementation,10.1109/VISUAL.2005.1532785,https://doi.org/10.1109/VISUAL.2005.1532785,111,118,Conferences,"Sort-last parallel rendering is an efficient technique to visualize huge datasets on COTS clusters. The dataset is subdivided and distributed across the cluster nodes. For every frame, each node renders a full resolution image of its data using its local GPU, and the images are composited together using a parallel image compositing algorithm. In this paper, we present a performance evaluation of standard sort-last parallel rendering methods and of the different improvements proposed in the literature. This evaluation is based on a detailed analysis of the different hardware and software components. We present a new implementation of sort-last rendering that fully overlaps CPU(s), GPU and network usage all along the algorithm. We present experiments on a 3 years old 32-node PC cluster and on a 1.5 years old 5-node PC cluster, both with Gigabit interconnect, showing volume rendering at respectively 13 and 31 frames per second and polygon rendering at respectively 8 and 17 frames per second on a 1024 x 768 render area, and we show that our implementation outperforms or equals many other implementations and specialized visualization clusters.",,X. Cavin;C. Mion;A. Filbois,"Inria Lorraine;Inria Lorraine, France;Inria Lorraine",,",,,,",,14,,
Vis-conf,2005,Fast and reproducible fiber bundle selection in DTI visualization,10.1109/VISUAL.2005.1532778,https://doi.org/10.1109/VISUAL.2005.1532778,59,64,Conferences,"Diffusion tensor imaging (DTI) is an MRI-based technique for quantifying water diffusion in living tissue. In the white matter of the brain, water diffuses more rapidly along the neuronal axons than in the perpendicular direction. By exploiting this phenomenon, DTI can be used to determine trajectories of fiber bundles, or neuronal connections between regions, in the brain. The resulting bundles can be visualized. However, the resulting visualizations can be complex and difficult to interpret. An effective approach is to pre-determine trajectories from a large number of positions throughout the white matter (full brain fiber tracking) and to offer facilities to aid the user in selecting fiber bundles of interest. Two factors are crucial for the use and acceptance of this technique in clinical studies: firstly, the selection of the bundles by brain experts should be interactive, supported by real-time visualization of the trajectories registered with anatomical MRI scans. Secondly, the fiber selections should be reproducible, so that different experts will achieve the same results. In this paper we present a practical technique for the interactive selection of fiber-bundles using multiple convex objects that is an order of magnitude faster than similar techniques published earlier. We also present the results of a clinical study with ten subjects that show that our selection approach is highly reproducible for fractional anisotropy (FA) calculated over the selected fiber bundles.",,J. Blaas;C.P. Botha;B. Peters;F.M. Vos;F.H. Post,"Data Visualization Group, Delft University of Technnology, Netherlands;Data Visualization Group, Delft University of Technnology, Netherlands;Psychiatric Centre, Academic Medical Center, Amsterdam, Netherlands;Quantitative Imaging Group, Delft University of Technnology, Netherlands;Data Visualization Group, Delft University of Technnology, Netherlands",,",,,,",,13,,
Vis-conf,2005,Phonon tracing for auralization and visualization of sound,10.1109/VISUAL.2005.1532790,https://doi.org/10.1109/VISUAL.2005.1532790,151,158,Conferences,"We present a new particle tracing approach for the simulation of mid- and high-frequency sound. Inspired by the photorealism obtained by methods like photon mapping, we develop a similar method for the physical simulation of sound within rooms. For given source and listener positions, our method computes a finite-response filter accounting for the different reflections at various surfaces with frequency-dependent absorption coefficients. Convoluting this filter with an anechoic input signal reproduces a realistic aural impression of the simulated room. We do not consider diffraction effects due to low frequencies, since these can be better computed by finite elements. Our method allows the visualization of a wave front propagation using color-coded blobs traversing the paths of individual phonons.",,M. Bertram;E. Deines;J. Mohring;J. Jegorovs;H. Hagen,"Technical University of Kaiserslautern, Germany;Technical University of Kaiserslautern, Germany;ITWM Kaiserslautern;ITWM Kaiserslautern;Technical University of Kaiserslautern, Germany",,",,,,",,13,,
Vis-conf,2005,Opening the can of worms: an exploration tool for vortical flows,10.1109/VISUAL.2005.1532830,https://doi.org/10.1109/VISUAL.2005.1532830,463,470,Conferences,"Gaining a comprehensive understanding of turbulent flows still poses one of the great challenges in fluid dynamics. A well-established approach to advance this research is the analysis of the vortex structures contained in the flow. In order to be able to perform this analysis efficiently, supporting visualization tools with clearly defined requirements are needed. In this paper, we present a visualization system which matches these requirements to a large extent. The system consists of two components. The first component analyzes the flow by means of a novel combination of vortex core line detection and the /spl lambda//sub 2/ method. The second component is a vortex browser which allows for an interactive exploration and manipulation of the vortices detected and separated during the first phase. Our system improves the reliability and applicability of existing vortex detection methods and allows for a more efficient study of vortical flows which is demonstrated in an evaluation performed by experts.",,S. Stegmaier;U. Rist;T. Ertl,"Institute for Visualization and Interactive Systems, University of Stuttgart, Germany;Institute for Aerodynamics and Gasdynamics, University of Stuttgart, Germany;Institute for Visualization and Interactive Systems, University of Stuttgart, Germany",,",,,,",,13,,
Vis-conf,2005,Reflection nebula visualization,10.1109/VISUAL.2005.1532803,https://doi.org/10.1109/VISUAL.2005.1532803,255,262,Conferences,"Stars form in dense clouds of interstellar gas and dust. The residual dust surrounding a young star scatters and diffuses its light, making the star's ""cocoon"" of dust observable from Earth. The resulting structures, called reflection nebulae, are commonly very colorful in appearance due to wavelength-dependent effects in the scattering and extinction of light. The intricate interplay of scattering and extinction cause the color hues, brightness distributions, and the apparent shapes of such nebulae to vary greatly with viewpoint. We describe an interactive visualization tool for realistically rendering the appearance of arbitrary 3D dust distributions surrounding one or more illuminating stars. Our rendering algorithm is based on the physical models used in astrophysics research. The tool can be used to create virtual fly-throughs of reflection nebulae for interactive desktop visualizations, or to produce scientifically accurate animations for educational purposes, e.g., in planetarium shows. The algorithm is also applicable to investigate on-the-fly the visual effects of physical parameter variations, exploiting visualization technology to help gain a deeper and more intuitive understanding of the complex interaction of light and dust in real astrophysical settings.",,M.A. Magnor;K. Hildebrand;A. Lintu;A.J. Hanson,"MPI Informatik, Germany;MPI Informatik, Germany;MPI Informatik, Germany;Indiana University, USA",,",,,,",,12,,
Vis-conf,2005,Visualization of white matter tracts with wrapped streamlines,10.1109/VISUAL.2005.1532777,https://doi.org/10.1109/VISUAL.2005.1532777,51,58,Conferences,"Diffusion tensor imaging is a magnetic resonance imaging method which has gained increasing importance in neuroscience and especially in neurosurgery. It acquires diffusion properties represented by a symmetric 2nd order tensor for each voxel in the gathered dataset. From the medical point of view, the data is of special interest due lo different diffusion characteristics of varying brain tissue allowing conclusions about the underlying structures such as while matter tracts. An obvious way to visualize this data is to focus on the anisotropic areas using the major eigenvector for tractography and rendering lines for visualization of the simulation results. Our approach extends this technique to avoid line representation since lines lead 10 very complex illustrations and furthermore are mistakable. Instead, we generate surfaces wrapping bundles of lines. Thereby, a more intuitive representation of different tracts is achieved.",,F. Enders;N. Sauber;D. Merhof;P. Hastreiter;C. Nimsky;M. Stamminger,"Neurocenter, Department of Neurosurgery, Computer Graphics Group, University of Erlangen Nuremberg, Germany;Computer Graphics Group, University of Erlangen Nuremberg, Germany;Neurocenter, Department of Neurosurgery, Computer Graphics Group, University of Erlangen Nuremberg, Germany;Neurocenter, Department of Neurosurgery, Computer Graphics Group, University of Erlangen Nuremberg, Germany;Christopher Nimsky, University of Erlangen Nuremberg, Germany;Computer Graphics Group, University of Erlangen Nuremberg, Germany",,",,,,",,12,,
Vis-conf,2005,Build-by-number: rearranging the real world to visualize novel architectural spaces,10.1109/VISUAL.2005.1532789,https://doi.org/10.1109/VISUAL.2005.1532789,143,150,Conferences,"We present build-by-number, a technique for quickly designing architectural structures that can be rendered photorealistically at interactive rates. We combine image-based capturing and rendering with procedural modeling techniques to allow the creation of novel structures in the style of real-world structures. Starting with a simple model recovered from a sparse image set, the model is divided into feature regions, such as doorways, windows, and brick. These feature regions essentially comprise a mapping from model space to image space, and can be recombined to texture a novel model. Procedural rules for the growth and reorganization of the model are automatically derived to allow for very fast editing and design. Further, the redundancies marked by the feature labeling can be used to perform automatic occlusion replacement and color equalization in the finished scene, which is rendered using view-dependent texture mapping on standard graphics hardware. Results using four captured scenes show that a great variety of novel structures can be created very quickly once a captured scene is available, and rendered with a degree of realism comparable to the original scene.",,D. Bekins;D.G. Aliaga,"Department of Computer Science at Purdue University, Purdue University System, West Lafayette, IN, US;Department of Computer Science at Purdue University, Purdue University System, West Lafayette, IN, US",,",,,,",,11,,
Vis-conf,2005,Batched multi triangulation,10.1109/VISUAL.2005.1532797,https://doi.org/10.1109/VISUAL.2005.1532797,207,214,Conferences,"The multi triangulation framework (MT) is a very general approach for managing adaptive resolution in triangle meshes. The key idea is arranging mesh fragments at different resolution in a directed acyclic graph (DAG) which encodes the dependencies between fragments, thereby encompassing a wide class of multiresolution approaches that use hierarchies or DAGs with predefined topology. On current architectures, the classic MT is however unfit for real-time rendering, since DAG traversal costs vastly dominate raw rendering costs. In this paper, we redesign the MT framework in a GPU friendly fashion, moving its granularity from triangles to precomputed optimized triangle patches. The patches can be conveniently tri-stripped and stored in secondary memory to be loaded on demand, ready to be sent to the GPU using preferential paths. In this manner, central memory only contains the DAG structure and CPU workload becomes negligible. The major contributions of this work are: a new out-of-core multiresolution framework, that, just like the MT, encompasses a wide class of multiresolution structures; a robust and elegant way to build a well conditioned MT DAG by introducing the concept of V-partitions, that can encompass various state of the art multiresolution algorithms; an efficient multithreaded rendering engine and a general subsystem for the external memory processing and simplification of huge meshes.",,P. Cignoni;F. Ganovelli;E. Gobbetti;F. Marton;F. Ponchio;R. Scopigno,"ISTI-CNR, Pisa, Italy;ISTI-CNR, Pisa, Italy;CRS4, Pula, Italy;CRS4, Italy;ISTI-CNR;ISTI-CNR",,",,,,",,11,,
Vis-conf,2005,Topological structures of 3D tensor fields,10.1109/VISUAL.2005.1532841,https://doi.org/10.1109/VISUAL.2005.1532841,551,558,Conferences,"Tensor topology is useful in providing a simplified and yet detailed representation of a tensor field. Recently the field of 3D tensor topology is advanced by the discovery that degenerate tensors usually form lines in their most basic configurations. These lines form the backbone for further topological analysis. A number of ways for extracting and tracing the degenerate tensor lines have also been proposed. In this paper, we complete the previous work by studying the behavior and extracting the separating surfaces emanating from these degenerate lines. First, we show that analysis of eigenvectors around a 3D degenerate tensor can be reduced to 2D. That is, in most instances, the 3D separating surfaces are just the trajectory of the individual 2D separatrices which includes trisectors and wedges. But the proof is by no means trivial since it is closely related to perturbation theory around a pair of singular slate. Such analysis naturally breaks down at the tangential points where the degenerate lines pass through the plane spanned by the eigenvectors associated with the repeated eigenvalues. Second, we show that the separatrices along a degenerate line may switch types (e.g. trisectors to wedges) exactly at the points where the eigenplane is tangential to the degenerate curve. This property leads to interesting and yet complicated configuration of surfaces around such transition points. Finally, we apply the technique to several common data sets to verify its correctness.",,X. Zheng;B. Parlett;A. Pang,"Computer Science Department, University of California, Santa Cruz, USA;Department of Mathematics and Graduate School, UCB;Computer Science Department, University of California, Santa Cruz, USA",,",,,,",,11,,
Vis-conf,2005,Distributed data management for large volume visualization,10.1109/VISUAL.2005.1532794,https://doi.org/10.1109/VISUAL.2005.1532794,183,189,Conferences,"We propose a distributed data management scheme for large data visualization that emphasizes efficient data sharing and access. To minimize data access time and support users with a variety of local computing capabilities, we introduce an adaptive data selection method based on an ""enhanced time-space partitioning"" (ETSP) tree that assists with effective visibility culling, as well as multiresolution data selection. By traversing the tree, our data management algorithm can quickly identify the visible regions of data, and, for each region, adaptively choose the lowest resolution satisfying user-specified error tolerances. Only necessary data elements are accessed and sent to the visualization pipeline. To further address the issue of sharing large-scale data among geographically distributed collaborative teams, we have designed an infrastructure for integrating our data management technique with a distributed data storage system provided by logistical networking (LoN). Data sets at different resolutions are generated and uploaded to LoN for wide-area access. We describe a parallel volume rendering system that verifies the effectiveness of our data storage, selection and access scheme.",,J. Gao;J. Huang;C.R. Johnson;S. Atchley,Oak Ridge National Lab;The Univ. of Tennessee;The Univ. of Tennessee;The Univ. of Tennessee,,",,,,",,10,,
Vis-conf,2005,Prefiltered Gaussian reconstruction for high-quality rendering of volumetric data sampled on a body-centered cubic grid,10.1109/VISUAL.2005.1532810,https://doi.org/10.1109/VISUAL.2005.1532810,311,318,Conferences,"In this paper a novel high-quality reconstruction scheme is presented. Although our method is mainly proposed to reconstruct volumetric data sampled on an optimal body-centered cubic (BCC) grid, it can be easily adapted lo the conventional regular rectilinear grid as well. The reconstruction process is decomposed into two steps. The first step, which is considered to be a preprocessing, is a discrete Gaussian deconvolution performed only once in the frequency domain. Afterwards, the second step is a spatial-domain convolution with a truncated Gaussian kernel, which is used to interpolate arbitrary samples for ray casting. Since the preprocessing is actually a discrete prefiltering, we call our technique prefiltered Gaussian reconstruction (PGR). It is shown that the impulse response of PGR well approximates the ideal reconstruction kernel. Therefore the quality of PGR is much higher than that of previous reconstruction techniques proposed for optimally sampled data, which are based on linear and cubic box splines adapted to the BCC grid. Concerning the performance, PGR is slower than linear box-spline reconstruction but significantly faster than cubic box-spline reconstruction.",,B. Csebfalvi,"Department of Control Engineering and Information Technology, Budapest University슠of슠Technology슠and슠Economics, Hungary",,",,,,",,9,,
Vis-conf,2005,High dynamic range volume visualization,10.1109/VISUAL.2005.1532812,https://doi.org/10.1109/VISUAL.2005.1532812,327,334,Conferences,"High resolution volumes require high precision compositing to preserve detailed structures. This is even more desirable for volumes with high dynamic range values. After the high precision intermediate image has been computed, simply rounding up pixel values to regular display scales loses the computed details. In this paper, we present a novel high dynamic range volume visualization method for rendering volume data with both high spatial and intensity resolutions. Our method performs high precision volume rendering followed by dynamic tone mapping to preserve details on regular display devices. By leveraging available high dynamic range image display algorithms, this dynamic tone mapping can be automatically adjusted to enhance selected features for the final display. We also present a novel transfer function design interface with nonlinear magnification of the density range and logarithmic scaling of the color/opacity range to facilitate high dynamic range volume visualization. By leveraging modern commodity graphics hardware and out-of-core acceleration, our system can produce an effective visualization of huge volume data.",,X. Yuan;M.Z. Nguyen;B. Chen;D.H. Porter,"Department of Computer Science and Engineering, University of Minnesota, Twin city, USA;Department of Computer Science and Engineering, University of Minnesota, Twin city, USA;Department of Computer Science and Engineering, University of Minnesota, Twin city, USA;The Laboratory for Computational Science and Engineering, University of Minnesota, Twin city, USA",,",,,,",,9,,
Vis-conf,2005,View-dependent rendering of multiresolution texture-atlases,10.1109/VISUAL.2005.1532798,https://doi.org/10.1109/VISUAL.2005.1532798,215,222,Conferences,"Real-time rendering of massively textured 3D scenes usually involves two major problems: Large numbers of texture switches are a well-known performance bottleneck and the set of simultaneously visible textures is limited by the graphics memory. This paper presents a level-of-detail texturing technique that overcomes both problems. In a preprocessing step, the technique creates a hierarchical data structure for all textures used by scene objects, and it derives texture atlases at different resolutions. At runtime, our texturing technique requires only a small set of these texture atlases, which represent scene textures in an appropriate size depending on the current camera position and screen resolution. Independent of the number and total size of all simultaneously visible textures, the achieved frame rates are similar to that of rendering the scene without any texture switches. Since the approach includes dynamic texture loading, the total size of the textures is only limited by the hard disk capacity. The technique is applicable for any 3D scenes whose scene objects are primarily distributed in a plane, such as in the case of 3D city models or outdoor scenes in computer games. Our approach has been successfully applied to massively textured, large-scale 3D city models.",,H. Buchholz;J. Dollner,"Hasso-Plattner Institute, University of Potsdam, Germany;Hasso-Plattner Institute, University of Potsdam, Germany",,",,,,",,8,,
Vis-conf,2005,Dataset traversal with motion-controlled transfer functions,10.1109/VISUAL.2005.1532817,https://doi.org/10.1109/VISUAL.2005.1532817,359,366,Conferences,"In this paper, we describe a methodology and implementation for interactive dataset traversal using motion-controlled transfer functions. Dataset traversal here refers lo the process of translating a transfer function along a specific path. In scientific visualization, it is often necessary to manipulate transfer functions in order to visualize datasets more effectively. This manipulation of transfer functions is usually performed globally, i.e., a new transfer function is applied to the entire dataset. Our approach allows one to locally manipulate transfer functions while controling its movement along a traversal path. The method we propose allows the user to select a traversal path within the dataset, based on the shape of the volumetric model and manipulate a transfer function along this path. Examples of dataset traversal include the animation of transfer functions along a pre-defined path, the simulation of flow in vascular structures, and the visualization of convoluted shapes. For example, this type of traversal is often used in medical illustration to highlight flow in blood vessels. We present an interactive implementation of our method using graphics hardware, based on the decomposition of the volume. We show examples of our approach using a variety of volumetric datasets, and we also demonstrate that with our novel decomposition, the rendering process is faster.",,C.D. Correa;D. Silver,"Department of Electrical and Computer Engineering Rutgers, State University of New Jersey, Piscataway, NJ, USA;Department of Electrical and Computer Engineering Rutgers, State University of New Jersey, Piscataway, NJ, USA",,",,,,",,8,,
Vis-conf,2005,Eyegaze analysis of displays with combined 2D and 3D views,10.1109/VISUAL.2005.1532837,https://doi.org/10.1109/VISUAL.2005.1532837,519,526,Conferences,"Displays combining both 2D and 3D views have been shown to support higher performance on certain visualization tasks. However, it is not clear how best to arrange a combination of 2D and 3D views spatially in a display. In this study, we analyzed the eyegaze strategies of participants using two arrangements of 2D and 3D views to estimate the relative position of objects in a 3D scene. Our results show that the 3D view was used significantly more often than individual 2D views in both displays, indicating the importance of the 3D view for successful task completion. However, viewing patterns were significantly different between the two displays: transitions through centrally-placed views were always more frequent, and users avoided saccades between views that were far apart. Although the change in viewing strategy did not result in significant performance differences, error analysis indicates that a 3D overview in the center may reduce the number of serious errors compared to a 3D overview placed off to the side.",,M. Tory;M.S. Atkins;A.E. Kirkpatrick;M. Nicolaou;G.-Z. Yang,"Department of Computer, Science University of British, Columbia, USA;School of Computing Science, Simon Fraser University, Canada;School of Computing Science, Simon Fraser University, Canada;Department of Computing, Imperial College London, UK;Department of Computing, Imperial College London, UK",,",,,,",,8,,
Vis-conf,2005,VolQD: direct volume rendering of multi-million atom quantum dot simulations,10.1109/VISUAL.2005.1532811,https://doi.org/10.1109/VISUAL.2005.1532811,319,326,Conferences,"In this work we present a hardware-accelerated direct volume rendering system for visualizing multivariate wave functions in semiconducting quantum dot (QD) simulations. The simulation data contains the probability density values of multiple electron orbitals for up to tens of millions of atoms, computed by the NEMO3-D quantum device simulator software run on large-scale cluster architectures. These atoms form two interpenetrating crystalline face centered cubic lattices (FCC), where each FCC cell comprises the eight corners of a cubic cell and six additional face centers. We have developed compact representation techniques for the FCC lattice within PC graphics hardware texture memory, hardware-accelerated linear and cubic reconstruction schemes, and new multi-field rendering techniques utilizing logarithmic scale transfer functions. Our system also enables the user to drill down through the simulation data and execute statistical queries using general-purpose computing on the GPU (GPGPU).",,W. Qiao;D.S. Ebert;A. Entezari;M. Korkusinski;G. Klimeck,"Purdue University, USA;Purdue University, USA;Simon Fraser University, Canada;Purdue University, USA;Purdue University, USA",,",,,,",,7,,
Vis-conf,2005,A handheld flexible display system,10.1109/VISUAL.2005.1532846,https://doi.org/10.1109/VISUAL.2005.1532846,591,597,Conferences,"A new close range virtual reality system is introduced that allows intuitive and immersive user interaction with computer generated objects. A projector with a special spherical lens is combined with a flexible, tracked rear projection screen that users hold in their hands. Unlike normal projectors, the spherical lens allows for a 180 degree field of view and nearly infinite depth of focus. This allows the user to move the screen around the environment and use it as a virtual ""slice"" to examine the interior of 3D volumes. This provides a concrete correspondence between the virtual representation of the 3D volume and how that volume would actually appear if its real counterpart was sliced open. The screen can also be used as a ""magic window"" to view the mesh of the volume from different angles prior to taking cross sections of it. Real time rendering of the desired 3D volume or mesh is accomplished using current graphics hardware. Additional applications of the system are also discussed.",,J. Konieczny;C. Shimizu;G. Meyer;D. Colucci,"Digital Technology Center, University of Minnesota, USA;Digital Technology Center, University of Minnesota, USA;Digital Technology Center, University of Minnesota, USA;Digital Technology Center, University of Minnesota, USA",,",,,,",,7,,
Vis-conf,2005,Particle and texture based spatiotemporal visualization of time-dependent vector fields,10.1109/VISUAL.2005.1532852,https://doi.org/10.1109/VISUAL.2005.1532852,639,646,Conferences,"We propose a hybrid particle and texture based approach for the visualization of time-dependent vector fields. The underlying space-time framework builds a dense vector field representation in a two-step process: 1) particle-based forward integration of trajectories in spacetime for temporal coherence, and 2) texture-based convolution along another set of paths through the spacetime for spatially correlated patterns. Particle density is controlled by stochastically injecting and removing particles, taking into account the divergence of the vector field. Alternatively, a uniform density can be maintained by placing exactly one particle in each cell of a uniform grid, which leads to particle-in-cell forward advection. Moreover, we discuss strategies of previous visualization methods for unsteady flow and show how they address issues of spatiotemporal coherence and dense visual representations. We demonstrate how our framework is capable of realizing several of these strategies. Finally, we present an efficient GPU implementation that facilitates an interactive visualization of unsteady 2D flow on Shader Model 3 compliant graphics hardware.",,D. Weiskopf;F. Schramm;G. Erlebacher;T. Ertl,"Institute of Visualization and Interactive Systems, University of Stuttgart, Germany;Institute of Visualization and Interactive Systems, University of Stuttgart, Germany;School of Computational Science and Information Technology, Florida State University, USA;Institute of Visualization and Interactive Systems, University of Stuttgart, Germany",,",,,,",,7,,
Vis-conf,2005,On the optimization of visualizations of complex phenomena,10.1109/VISUAL.2005.1532782,https://doi.org/10.1109/VISUAL.2005.1532782,87,94,Conferences,"The problem of perceptually optimizing complex visualizations is a difficult one, involving perceptual as well as aesthetic issues. In our experience, controlled experiments are quite limited in their ability to uncover interrelationships among visualization parameters, and thus may not be the most useful way to develop rules-of-thumb or theory to guide the production of high-quality visualizations. In this paper, we propose a new experimental approach to optimizing visualization quality that integrates some of the strong points of controlled experiments with methods more suited to investigating complex highly-coupled phenomena. We use human-in-the-loop experiments to search through visualization parameter space, generating large databases of rated visualization solutions. This is followed by data mining to extract results such as exemplar visualizations, guidelines for producing visualizations, and hypotheses about strategies leading to strong visualizations. The approach can easily address both perceptual and aesthetic concerns, and can handle complex parameter interactions. We suggest a genetic algorithm as a valuable way of guiding the human-in-the-loop search through visualization parameter space. We describe our methods for using clustering, histogramming, principal component analysis, and neural networks for data mining. The experimental approach is illustrated with a study of the problem of optimal texturing for viewing layered surfaces so that both surfaces are maximally observable.",,D. House;A. Bair;C. Ware,"Texas A and M University, USA;Texas A and M University, USA;University of New Hampshire, USA",,",,,,",,6,,
Vis-conf,2005,OpenGL multipipe SDK: a toolkit for scalable parallel rendering,10.1109/VISUAL.2005.1532786,https://doi.org/10.1109/VISUAL.2005.1532786,119,126,Conferences,"We describe OpenGL multipipe SDK (MPK), a toolkit for scalable parallel rendering based on OpenGL. MPK provides a uniform application programming interface (API) to manage scalable graphics applications across many different graphics subsystems. MPK-based applications run seamlessly from single-processor, single-pipe desktop systems to large multi-processor, multipipe scalable graphics systems. The application is oblivious of the system configuration, which can be specified through a configuration file at run time. To scale application performance, MPK uses a decomposition system that supports different modes for task partitioning and implements optimized CPU-based composition algorithms. MPK also provides a customizable image composition interface, which can be used to apply post-processing algorithms on raw pixel data obtained from executing sub-tasks on multiple graphics pipes in parallel. This can be used to implement parallel versions of any CPU-based algorithm, not necessarily used for rendering. In this paper, we motivate the need for a scalable graphics API and discuss the architecture of MPK. We present MPK's graphics configuration interface, introduce the notion of compound-based decomposition schemes and describe our implementation. We present some results from our work on a couple of target system architectures and conclude with future directions of research in this area.",,Praveen Bhaniramka;P.C.D. Robert;S. Eilemann,"Silicon Graphics, Inc.;University of Bern, Switzerland;University of Zurich, Switzerland",,",,,,",,6,,
Vis-conf,2005,Stream-processing points,10.1109/VISUAL.2005.1532801,https://doi.org/10.1109/VISUAL.2005.1532801,239,246,Conferences,"With the growing size of captured 3D models it has become increasingly important to provide basic efficient processing methods for large unorganized raw surface-sample point data sets. In this paper we introduce a novel stream-based (and out-of-core) point processing framework. The proposed approach processes points in an orderly sequential way by sorting them and sweeping along a spatial dimension. The major advantages of this new concept are: (1) support of extensible and concatenate local operators called stream operators, (2) low main-memory usage and (3) applicability to process very large data sets out-of-core.",,R. Pajarola,"Visualization and MultiMedia Lab, Department of Informatics, University of Zürich, Switzerland",,",,,,",,6,,
Vis-conf,2005,Topology-driven surface mappings with robust feature alignment,10.1109/VISUAL.2005.1532840,https://doi.org/10.1109/VISUAL.2005.1532840,543,550,Conferences,"Topological concepts and techniques have been broadly applied in computer graphics and geometric modeling. However, the homotopy type of a mapping between two surfaces has not been addressed before. In this paper, we present a novel solution to the problem of computing continuous maps with different homotopy types between two arbitrary triangle meshes with the same topology. Inspired by the rich theory of topology as well as the existing body of work on surface mapping, our newly-developed mapping techniques are both fundamental and unique, offering many attractive advantages. First, our method allows the user to change the homotopy type or global structure of the mapping with minimal intervention. Moreover, to locally affect shape correspondence, we articulate a new technique that robustly satisfies hard feature constraints, without the use of heuristics to ensure validity. In addition to acting as a useful tool for computer graphics applications, our method can be used as a rigorous and practical mechanism for the visualization of abstract topological concepts such as homotopy type of surface mappings, homology basis, fundamental domain, and universal covering space. At the core of our algorithm is a procedure for computing the canonical homology basis and using it as a common cut graph for any surface with the same topology. We demonstrate our results by applying our algorithm to shape morphing in this paper.",,C. Garner;M. Jin;X. Gu;H. Qin,"Stony Brook University;Stony Brook University, USA;Stony Brook University, USA;Stony Brook University, USA",,",,,,",,6,,
Vis-conf,2005,Rendering tetrahedral meshes with higher-order attenuation functions for digital radiograph reconstruction,10.1109/VISUAL.2005.1532809,https://doi.org/10.1109/VISUAL.2005.1532809,303,310,Conferences,"This paper presents a novel method for computing simulated x-ray images, or DRRs (digitally reconstructed radiographs), of tetrahedral meshes with higher-order attenuation functions. DRRs are commonly used in computer assisted surgery (CAS), with the attenuation function consisting of a voxelized CT study, which is viewed from different directions. Our application of DRRs is in intra-operative ""2D-3D"" registration, i.e., finding the pose of the CT dataset given a small number of patient radiographs. We register 2D patient images with a statistical tetrahedral model, which encodes the CT intensity numbers as Bernstein polynomials, and includes knowledge about typical shape variation modes. The unstructured grid is more suitable for applying deformations than a rectilinear grid, and the higher-order polynomials provide a better approximation of the actual density than constant or linear models. The infra-operative environment demands a fast method for creating the DRRs, which we present here. We demonstrate this application through the creation and use of a deformable atlas of human pelvis bones. Compared with other works on rendering unstructured grids, the main contributions of this work are: 1) Simple and perspective-correct interpolation of the thickness of a tetrahedral cell. 2) Simple and perspective-correct interpolation of front and back barycentric coordinates with respect to the cell. 3) Computing line integrals of higher-order functions. 4) Capability of applying shape deformations and variations in the attenuation function without significant performance loss. The method does not depend on for pre-integration, and does not require depth-sorting of the visualized cells. We present imaging and timing results of implementing the algorithm, and discuss the impact of using higher-order functions on the quality of the result and the performance.",,C. Sadowsky;J.D. Cohen;R.H. Taylor,"Johns Hopkins University, USA;Johns Hopkins University, USA;Johns Hopkins University, USA",,",,,,",,6,,
Vis-conf,2005,Hardware-accelerated simulated radiography,10.1109/VISUAL.2005.1532815,https://doi.org/10.1109/VISUAL.2005.1532815,343,350,Conferences,"We present the application of hardware accelerated volume rendering algorithms to the simulation of radiographs as an aid to scientists designing experiments, validating simulation codes, and understanding experimental data. The techniques presented take advantage of 32-bit floating point texture capabilities to obtain solutions to the radiative transport equation for X-rays. The hardware accelerated solutions are accurate enough to enable scientists to explore the experimental design space with greater efficiency than the methods currently in use. An unsorted hexahedron projection algorithm is presented for curvilinear hexahedral meshes that produces simulated radiographs in the absorption-only regime. A sorted tetrahedral projection algorithm is presented that simulates radiographs of emissive materials. We apply the tetrahedral projection algorithm to the simulation of experimental diagnostics for inertial confinement fusion experiments on a laser at the University of Rochester.",,D. Laney;S.P. Callahan;N. Max;C.T. Silva;S. Langer;R. Frank,"Lawrence Livemore National Laboratory, USA;University of Utah, USA;Lawrence Livemore National Laboratory, USA;University of Utah, USA;Lawrence Livemore National Laboratory, USA;Computational Engineering International",,",,,,",,6,,
Vis-conf,2005,Example-based volume illustrations,10.1109/VISUAL.2005.1532854,https://doi.org/10.1109/VISUAL.2005.1532854,655,662,Conferences,"Scientific illustrations use accepted conventions and methodologies to effectively convey object properties and improve our understanding. We present a method to illustrate volume datasets by emulating example illustrations. As with technical illustrations, our volume illustrations more clearly delineate objects, enrich details, and artistically visualize volume datasets. For both color and scalar 3D volumes, we have developed an automatic color transfer method based on the clustering and similarities in the example illustrations and volume sources. As an extension to 2D Wang tiles, we provide a new, general texture synthesis method for Wang cubes that solves the edge discontinuity problem. We have developed a 2D illustrative slice viewer and a GPU-based direct volume rendering system that uses these non-periodic 3D textures to generate illustrative results similar to the 2D examples. Both applications simulate scientific illustrations to provide more information than the original data and visualize objects more effectively, while only requiring simple user interaction.",,A. Lu;D.S. Ebert,"UNC Charlotte, Purdue University;Purdue University, USA",,",,,,",,6,,
Vis-conf,2005,Interactive visual analysis and exploration of injection systems simulations,10.1109/VISUAL.2005.1532821,https://doi.org/10.1109/VISUAL.2005.1532821,391,398,Conferences,"Simulations often generate large amounts of data that require use of SciVis techniques for effective exploration of simulation results. In some cases, like 1D theory of fluid dynamics, conventional SciVis techniques are not very useful. One such example is a simulation of injection systems that is becoming more and more important due to an increasingly restrictive emission regulations. There are many parameters and correlations among them that influence the simulation results. We describe how basic information visualization techniques can help in visualizing, understanding and analyzing this kind of data. The Com Vis tool is developed and used to analyze and explore the data. Com Vis supports multiple linked views and common information visualization displays such as 2D and 3D scatter-plot, histogram, parallel coordinates, pie-chart, etc. A diesel common rail injector with 2/2 way valve is used for a case study. Data sets were generated using a commercially available AVL HYDSIM simulation tool for dynamic analysis of hydraulic and hydro-mechanical systems, with the main application area in the simulation of fuel injection systems.",,K. Matkovic;M. Jelovic;J. Juric;Z. Konyha;D. Gracanin,"VRVis Research Center, Vienna, Austria;;;;",,",,,,",,6,,
Vis-conf,2005,Surface reconstruction via contour metamorphosis: an Eulerian approach with Lagrangian particle tracking,10.1109/VISUAL.2005.1532823,https://doi.org/10.1109/VISUAL.2005.1532823,407,414,Conferences,"We present a robust method for 3D reconstruction of closed surfaces from sparsely sampled parallel contours. A solution to this problem is especially important for medical segmentation, where manual contouring of 2D imaging scans is still extensively used. Our proposed method is based on a morphing process applied to neighboring contours that sweeps out a 3D surface. Our method is guaranteed to produce closed surfaces that exactly pass through the input contours, regardless of the topology of the reconstruction. Our general approach consecutively morphs between sets of input contours using an Eulerian formulation (i.e. fixed grid) augmented with Lagrangian particles (i.e. interface tracking). This is numerically accomplished by propagating the input contours as 2D level sets with carefully constructed continuous speed functions. Specifically this involves particle advection to estimate distances between the contours, monotonicity constrained spline interpolation to compute continuous speed functions without overshooting, and state-of-the-art numerical techniques for solving the level set equations. We demonstrate the robustness of our method on a variety of medical, topographic and synthetic data sets.",,O. Nilsson;D. Breen;K. Museth,"Linköping University, Sweden;Drexel University, USA;Linköping University, Sweden",,",,,,",,6,,
Vis-conf,2005,A shader-based parallel rendering framework,10.1109/VISUAL.2005.1532787,https://doi.org/10.1109/VISUAL.2005.1532787,127,134,Conferences,"Existing parallel or remote rendering solutions rely on communicating pixels, OpenGL commands, scene-graph changes or application-specific data. We propose an intermediate solution based on a set of independent graphics primitives that use hardware shaders to specify their visual appearance. Compared to an OpenGL based approach, it reduces the complexity of the model by eliminating most fixed function parameters while giving access to the latest functionalities of graphics cards. It also suppresses the OpenGL state machine that creates data dependencies making primitive re-scheduling difficult. Using a retained-mode communication protocol transmitting changes between each frame, combined with the possibility to use shaders to implement interactive data processing operations instead of sending final colors and geometry, we are able to optimize the network load. High level information such as bounding volumes is used to setup advanced schemes where primitives are issued in parallel, routed according to their visibility, merged and re-ordered when received for rendering. Different optimization algorithms can be efficiently implemented, saving network bandwidth or reducing texture switches for instance. We present performance results based on two VTK applications, a parallel iso-surface extraction and a parallel volume renderer. We compare our approach with Chromium. Results show that our approach leads to significantly better performance and scalability, while offering easy access to hardware accelerated rendering algorithms.",,J. Allard;B. Raffin,"CNRS/INPG/INRIA/UJF, ID-IMAG, Grenoble, France;CNRS/INPG/INRIA/UJF, ID-IMAG, Grenoble, France",,",,,,",,6,,
Vis-conf,2005,2D asymmetric tensor analysis,10.1109/VISUAL.2005.1532770,https://doi.org/10.1109/VISUAL.2005.1532770,3,10,Conferences,"Analysis of degenerate tensors is a fundamental step in finding the topological structures and separatrices in tensor fields. Previous work in this area have been limited to analyzing symmetric second order tensor fields. In this paper, we extend the topological analysis to 2D general (asymmetric) second order tensor fields. We show that it is not sufficient to define degeneracies based on eigenvalues alone, but one must also include the eigenvectors in the analysis. We also study the behavior of these eigenvectors as they cross from one topological region into another.",,X. Zheng;A. Pang,"Computer Science Department, University of California, Santa Cruz, CA, USA;Computer Science Department, University of California, Santa Cruz, CA, USA",,",,,,",,6,,
Vis-conf,2005,Illustrative display of hidden iso-surface structures,10.1109/VISUAL.2005.1532855,https://doi.org/10.1109/VISUAL.2005.1532855,663,670,Conferences,"Indirect volume rendering is a widespread method for the display of volume datasets. It is based on the extraction of polygonal iso-surfaces from volumetric data, which are then rendered using conventional rasterization methods. Whereas this rendering approach is fast and relatively easy to implement, it cannot easily provide an understandable display of structures occluded by the directly visible iso-surface. Simple approaches like alpha-blending for transparency when drawing the iso-surface often generate a visually complex output, which is difficult to interpret. Moreover, such methods can significantly increase the computational complexity of the rendering process. In this paper, we therefore propose a new approach for the illustrative indirect rendering of volume data in real-time. This algorithm emphasizes the silhouette of objects represented by the iso-surface. Additionally, shading intensities on objects are reproduced with a monochrome hatching technique. Using a specially designed two-pass rendering process, structures behind the front layer of the iso-surface are automatically extracted with a depth peeling method. The shapes of these hidden structures are also displayed as silhouette outlines. As an additional option, the geometry of explicitly specified inner objects can be displayed with constant translucency. Although these inner objects always remain visible, a specific shading and depth attenuation method is used to convey the depth relationships. We describe the implementation of the algorithm, which exploits the programmability of state-of-the-art graphics processing units (GPUs). The algorithm described in this paper does not require any preprocessing of the input data or a manual definition of inner structures. Since the presented method works on iso-surfaces, which are stored as polygonal datasets, it can also be applied to other types of polygonal models.",,J. Fischer;D. Bartz;W. Strasser,"Visual Computing for Medicine, University of Tübingen, Germany;Visual Computing for Medicine, University of Tübingen, Germany;WSI/GRIS, University of Tübingen",,",,,,",,5,,
Vis-conf,2005,Interactive rendering of large unstructured grids using dynamic level-of-detail,10.1109/VISUAL.2005.1532796,https://doi.org/10.1109/VISUAL.2005.1532796,199,206,Conferences,"We describe a new dynamic level-of-detail (LOD) technique that allows real-time rendering of large tetrahedral meshes. Unlike approaches that require hierarchies of tetrahedra, our approach uses a subset of the faces that compose the mesh. No connectivity is used for these faces so our technique eliminates the need for topological information and hierarchical data structures. By operating on a simple set of triangular faces, our algorithm allows a robust and straightforward graphics hardware (GPU) implementation. Because the subset of faces processed can be constrained to arbitrary size, interactive rendering is possible for a wide range of data sets and hardware configurations.",,S.P. Callahan;J.L.D. Comba;P. Shirley;C.T. Silva,"Scientific Computing and Imaging Institute, University of Utah, USA;UFRGS, Brazil;School of Computing, University of Utah, USA;School of Computing, University of Utah, USA",,",,,,",,5,,
Vis-conf,2005,Visualizing intersecting surfaces with nested-surface techniques,10.1109/VISUAL.2005.1532835,https://doi.org/10.1109/VISUAL.2005.1532835,503,510,Conferences,"This paper describes the adaptation and evaluation of existing nested-surface visualization techniques for the problem of displaying intersecting surfaces. For this work, we collaborated with a neurosurgeon who is comparing multiple tumor segmentations with the goal of increasing the segmentation accuracy and reliability. A second collaborator, a physicist, aims to validate geometric models of specimens against atomic-force microscope images of actual specimens. These collaborators are interested in comparing both surface shape and inter-surface distances. Many commonly employed techniques for visually comparing multiple surfaces (side-by-side, wireframe, colormaps, uniform translucence) do not simultaneously convey inter-surface distance and the shapes of two or more surfaces. This paper describes a simple geometric partitioning of intersecting surfaces that enables the application of existing nested-surface techniques, such as texture-modulated translucent rendering of exteriors, to a broader range of visualization problems. Three user studies investigate the performance of existing techniques and a new shadow-casting glyph technique. The results of the first user study show that texture glyphs on partitioned, intersecting surfaces can convey inter-surface distance better than directly mapping distance to a red-gray-blue color scale on a single surface. The results of the second study show similar results for conveying local surface orientation. The results of the third user study show that adding cast shadows to texture glyphs can increase the understanding of inter-surface distance in static images, but can be overpowered by the shape cues from a simple rocking motion.",,C. Weigle;R.M. Taylor,"Department of Computer Science, North Carolina State University, Chapel Hill, USA;Department of Computer Science, North Carolina State University, Chapel Hill, USA",,",,,,",,5,,
Vis-conf,2005,Exploiting frame-to-frame coherence for accelerating high-quality volume raycasting on graphics hardware,10.1109/VISUAL.2005.1532799,https://doi.org/10.1109/VISUAL.2005.1532799,223,230,Conferences,GPU-based raycasting offers an interesting alternative to conventional slice-based volume rendering due to the inherent flexibility and the high quality of the generated images. Recent advances in graphics hardware allow for the ray traversal and volume sampling to be executed on a per-fragment level completely on the GPU leading to interactive framerates. In this work we present optimization techniques that improve the performance and quality of GPU-based volume raycasting. We apply a hybrid image/object space approach to accelerate the ray traversal in animation sequences that works for both isosurface rendering and semi-transparent volume rendering. An empty-space-leaping technique that exploits the spatial coherence between consecutively rendered images is used to estimate the optimal initial ray sampling point for each image pixel. These can double the rendering performance for typical volumetric data sets without sacrificing image quality. The achieved speed-up allows for further improvements of image quality. We demonstrate an object space antialiasing technique based on selective super-sampling at sharp creases and silhouette edges which also benefits from exploiting frame-to-frame coherence.,,T. Klein;M. Strengert;S. Stegmaier;T. Ertl,"Institute for Visualization and Interactive Systems, University of Stuttgart, Germany;Institute for Visualization and Interactive Systems, University of Stuttgart, Germany;Institute for Visualization and Interactive Systems, University of Stuttgart, Germany;Institute for Visualization and Interactive Systems, University of Stuttgart, Germany",,",,,,",,5,,
Vis-conf,2005,Multimodal exploration of the fourth dimension,10.1109/VISUAL.2005.1532804,https://doi.org/10.1109/VISUAL.2005.1532804,263,270,Conferences,"We present a multimodal paradigm for exploring topological surfaces embedded in four dimensions; we exploit haptic methods in particular to overcome the intrinsic limitations of 3D graphics images and 3D physical models. The basic problem is that, just as 2D shadows of 3D curves lose structure where lines cross, 3D graphics projections of smooth 4D topological surfaces are interrupted where one surface intersects another. Furthermore, if one attempts to trace real knotted ropes or a plastic models of self-intersecting surfaces with a fingertip, one inevitably collides with parts of the physical artifact. In this work, we exploit the free motion of a computer-based haptic probe to support a continuous motion that follows the local continuity of the object being explored. For our principal test case of 4D-embedded surfaces projected to 3D, this permits us to follow the full local continuity of the surface as though in fact we were touching an actual 4D object. We exploit additional sensory cues to provide supplementary or redundant information. For example, we can use audio tags to note the relative 4D depth of illusory 3D surface intersections produced by projection from 4D, as well as providing automated refinement of the tactile exploration path to eliminate jitter and snagging, resulting in a much cleaner exploratory motion than a bare uncorrected motion. Visual enhancements provide still further improvement to the feedback: by opening a view-direction-defined cutaway into the interior of the 3D surface projection, we allow the viewer to keep the haptic probe continuously in view as it traverses any touchable part of the object. Finally, we extend the static tactile exploration framework using a dynamic mode that links each stylus motion to a change in orientation that creates at each instant a maximal-area screen projection of a neighborhood of the current point of interest. This minimizes 4D distortion and permits true metric sizes to be deduced locally at any point. All these methods combine to reveal the full richness of the complex spatial relationships of the target shapes, and to overcome many expected perceptual limitations in 4D visualization.",,A.J. Hanson;H. Zhang,"Computer Science Department, Indiana University, USA;Computer Science Department, Indiana University, USA",,",,,,",,5,,
Vis-conf,2005,Visualization of the genus of knots,10.1109/VISUAL.2005.1532843,https://doi.org/10.1109/VISUAL.2005.1532843,567,574,Conferences,"The genus of a knot or link can be defined via Seifert surfaces. A Seifert surface of a knot or link is an oriented surface whose boundary coincides with that, knot or link. Schematic images of these surfaces are shown in every text book on knot theory, but from these it is hard to understand their shape and structure. In this paper the visualization of such surfaces is discussed. A method is presented to produce different styles of surfaces for knots and links, starting from the so-called braid representation. Also, it is shown how closed oriented surfaces can be generated in which the knot is embedded, such that the knot subdivides the surface into two parts. These closed surfaces provide a direct visualization of the genus of a knot.",,J.J. van Wijk;A.M. Cohen,"Department Mathematics and Computer Science, Technische Universiteit Eindhoven, Netherlands;Department Mathematics and Computer Science, Technische Universiteit Eindhoven, Netherlands",,",,,,",,4,,
Vis-conf,2005,Profile Flags: a novel metaphor for probing of T/sub 2/ maps,10.1109/VISUAL.2005.1532847,https://doi.org/10.1109/VISUAL.2005.1532847,599,606,Conferences,"This paper describes a tool for the visualization of T/sub 2/ maps of knee cartilage. Given the anatomical scan, and the T/sub 2/ map of the cartilage, we combine the information on the shape and the quality of the cartilage in a single image. The Profile Flag is an intuitive 3D glyph for probing and annotating of the underlying data. It comprises a bulletin board pin-like shape with a small flag on top of it. While moving the glyph along the reconstructed surface of an object, the curve data measured along the pin's needle and in its neighborhood are shown on the flag. The application area of the Profile Flag is manifold, enabling the visualization of profile data of dense but in-homogeneous objects. Furthermore, it extracts the essential part of the data without removing or even reducing the context information. By sticking Profile Flags into the investigated structure, one or more significant locations can be annotated by showing the local characteristics of the data at that locations. In this paper we are demonstrating the properties of the tool by visualizing T/sub 2/ maps of knee cartilage.",,M. Mlejnek;P. Ermest;A. Vilanova;R. van der Rijt;H. van den Bosch;F. Gerritsen;M.E. Groller,"Institute of Computer Graphics and Algorithms, University of Technology, Vienna, Austria;;Deorlrtment of Biomedical Engineering, Technische Universiteit, Eindhoven, Netherlands;Catharina Hospital, Eindhovn, Netherlands;Catharina Hospital, Eindhovn, Netherlands;Philips Medical Systems, Best, Netherlands;Institute of Computer Graphics and Algorithms, University of Technology, Vienna, Austria",,",,,,",,4,,
Vis-conf,2005,Quality mesh generation for molecular skin surfaces using restricted union of balls,10.1109/VISUAL.2005.1532822,https://doi.org/10.1109/VISUAL.2005.1532822,399,405,Conferences,"Quality surface meshes for molecular models are desirable in the studies of protein shapes and functionalities. However, there is still no robust software that is capable to generate such meshes with good quality. In this paper, we present a Delaunay-based surface triangulation algorithm generating quality surface meshes for the molecular skin model. We expand the restricted union of balls along the surface and generate an /spl epsiv/-sampling of the skin surface incrementally. At the same time, a quality surface mesh is extracted from the Delaunay triangulation of the sample points. The algorithm supports robust and efficient implementation and guarantees the mesh quality and topology as well. Our results facilitate molecular visualization and have made a contribution towards generating quality volumetric tetrahedral meshes for the macromolecules.",,H.-L. Cheng;X. Shi,"School of Computing, National University of Singapore, Singapore;School of Computing, National University of Singapore, Singapore",,",,,,",,4,,
Vis-conf,2005,Differential protein expression analysis via liquid-chromatography/mass-spectrometry data visualization,10.1109/VISUAL.2005.1532828,https://doi.org/10.1109/VISUAL.2005.1532828,447,454,Conferences,"Differential protein expression analysis is one of the main challenges in proteomics. It denotes the search for proteins, whose encoding genes are differentially expressed under a given experimental setup. An important task in this context is to identify the differentially expressed proteins or, more generally, all proteins present in the sample. One of the most promising and recently widely used approaches for protein identification is to cleave proteins into peptides, separate the peptides using liquid chromatography, and determine the masses of the separated peptides using mass spectrometry. The resulting data needs to be analyzed and matched against protein sequence databases. The analysis step is typically done by searching for intensity peaks in a large number of 2D graphs. We present an interactive visualization tool for the exploration of liquid-chromatography/mass-spectrometry data in a 3D space, which allows for the understanding of the data in its entirety and a detailed analysis of regions of interest. We compute differential expression over the liquid-chromatography/mass-spectrometry domain and embed it visually in our system. Our exploration tool can treat single liquid-chromatography/mass-spectrometry data sets as well as data acquired using multi-dimensional protein identification technology. For efficiency purposes we perform a peak-preserving data resampling and multiresolution hierarchy generation prior to visualization.",,L. Linsen;J. Locherbach;M. Berth;J. Bernhardt;D. Becher,"Department of Mathematics and Computer Science, Ernst Moritz Arndt University슠of Greifswald, Greifswald, Germany;Department of Mathematics and Computer Science, Ernst Moritz Arndt University슠of Greifswald, Greifswald, Germany;DECODON GmbH, Greifswald, Germany;Department of Microbiology, Ernst Moritz Arndt University슠of Greifswald, Greifswald, Germany;Department of Microbiology, Ernst Moritz Arndt University슠of Greifswald, Greifswald, Germany",,",,,,",,4,,
Vis-conf,2005,VolumeExplorer: roaming large volumes to couple visualization and data processing for oil and gas exploration,10.1109/VISUAL.2005.1532802,https://doi.org/10.1109/VISUAL.2005.1532802,247,254,Conferences,"In this paper, we present a volume roaming system dedicated to oil and gas exploration. Our system combines probe-based volume rendering with data processing and computing. The daily oil production and the estimation of the world proven-reserves directly affect the barrel price and have a strong impact on the economy. Among others, production and correct estimation are linked to the accuracy of the sub-surface model used for predicting oil reservoirs shape and size. Geoscientists build this model from the interpretation of seismic data, i.e. 3D images of the subsurface obtained from geophysical surveys. Our system couples visualization and data processing for the interpretation of seismic data. It is based on volume roaming along with efficient volume paging to manipulate the multi-gigabyte data sets commonly acquired during seismic surveys. Our volume rendering lenses implement high quality pre-integrated volume rendering with accurate lighting. They use a generic multi-modal volume rendering system that blends several volumes in the spirit of the ""stencil"" paradigm used in 2D painting programs. In addition, our system can interactively display non-polygonal isosurfaces painted with an attribute. Beside the visualization algorithms, automatic extraction of local features of the subsurface model also take full advantage of the volume paging.",,L. Castanie;B. Levy;F. Bosquet,"Earth Decision Sciences, Gocad Research Group;Project ALICE, INRIA Lorraine, France;Earth Decision Sciences",,",,,,",,4,,
Vis-conf,2005,Visualization in the Einstein Year 2005: a case study on explanatory and illustrative visualization of relativity and astrophysics,10.1109/VISUAL.2005.1532845,https://doi.org/10.1109/VISUAL.2005.1532845,583,590,Conferences,"In this application paper, we report on over fifteen years of experience with relativistic and astrophysical visualization, which has been culminating in a substantial engagement for visualization in the Einstein Year 2005 - the 100/sup th/ anniversary of Einstein's publications on special relativity, the photoelectric effect, and Brownian motion. This paper focuses on explanatory and illustrative visualizations used to communicate aspects of the difficult theories of special and general relativity, their geometric structure, and of the related fields of cosmology and astrophysics. We discuss visualization strategies, motivated by physics education and didactics of mathematics, and describe what kind of visualization methods have proven to be useful for different types of media, such as still images in popular-science magazines, film contributions to TV shows, oral presentations, or interactive museum installations. Although our visualization tools build upon existing methods and implementations, these techniques have been improved by several novel technical contributions like image-based special relativistic rendering on GPUs, an extension of general relativistic ray tracing to manifolds described by multiple charts, GPU-based interactive visualization of gravitational light deflection, as well as planetary terrain rendering. The usefulness and effectiveness of our visualizations are demonstrated by reporting on experiences with, and feedback from, recipients of visualizations and collaborators.",,D. Weiskopf;M. Borchers;T. Ertl;M. Falk;O. Fechtig;R. Frank;F. Grave;A. King;U. Kraus;T. Muller;H.-P. Nollert;I.R. Mendez;H. Ruder;T. Schafhitzel;S. Schar;C. Zahn;M. Zatloukal,"Visualization and Interactive Systems, University of Stuttgart, Germany;Astronomy and Astrophysics, University of Tübingen, Germany;Visualization and Interactive Systems, University of Stuttgart, Germany;Visualization and Interactive Systems, University of Stuttgart, Germany;Astronomy and Astrophysics, University of Tübingen, Germany;Astronomy and Astrophysics, University of Tübingen, Germany;Astronomy and Astrophysics, University of Tübingen, Germany;Astronomy and Astrophysics, University of Tübingen, Germany;Astronomy and Astrophysics, University of Tübingen, Germany;Astronomy and Astrophysics, University of Tübingen, Germany;Astronomy and Astrophysics, University of Tübingen, Germany;Astronomy and Astrophysics, University of Tübingen, Germany;Astronomy and Astrophysics, University of Tübingen, Germany;Visualization and Interactive Systems, University of Stuttgart, Germany;Historisches Museum Bern, Bern, Switzerland;Astronomy and Astrophysics, University of Tübingen, Germany;Astronomy and Astrophysics, University of Tübingen, Germany",,",,,,",,3,,
Vis-conf,2005,Framework for visualizing higher-order basis functions,10.1109/VISUAL.2005.1532776,https://doi.org/10.1109/VISUAL.2005.1532776,43,50,Conferences,"Techniques in numerical simulation such as the finite element method depend on basis functions for approximating the geometry and variation of the solution over discrete regions of a domain. Existing visualization systems can visualize these basis functions if they are linear, or for a small set of simple non-linear bases. However, newer numerical approaches often use basis functions of elevated and mixed order or complex form; hence existing visualization systems cannot directly process them. In this paper we describe an approach that supports automatic, adaptive tessellation of general basis functions using a flexible and extensible software architecture in conjunction with an on demand, edge-based recursive subdivision algorithm. The framework supports the use of functions implemented in external simulation packages, eliminating the need to reimplement the bases within the visualization system. We demonstrate our method on several examples, and have implemented the framework in the open-source visualization system VTK.",,W.J. Schroeder;F. Bertel;M. Malaterre;D. Thompson;P.P. Pebay;R. O'Barall;Saurabh Tendulkar,"Kitware;Kitware;Kitware;Sandia;Sandia, UK;;Simmetrix, South Korea",,",,,,",,3,,
Vis-conf,2005,Sort-middle multi-projector immediate-mode rendering in Chromium,10.1109/VISUAL.2005.1532784,https://doi.org/10.1109/VISUAL.2005.1532784,103,110,Conferences,"Traditionally, sort-middle is a technique that has been difficult to attain on clusters because of the tight coupling of geometry and rasterization processes on commodity graphics hardware. In this paper, we describe the implementation of a new sort-middle approach for performing immediate-mode rendering in Chromium. The Chromium Rendering System is used extensively to drive multi-projector displays on PC clusters with inexpensive commodity graphics components. By default, Chromium uses a sort-first approach to distribute rendering work to individual nodes in a PC cluster. While this sort-first approach works effectively in retained-mode rendering, it suffers from various network bottlenecks when rendering in immediate-mode. Current techniques avoid these bottlenecks by sorting vertex data as a pre-processing step and grouping vertices into specific bounding boxes, using Chromium's bounding box extension. These steps may be expensive, especially if the dataset is dynamic. In our approach, we utilize standard programmable graphics hardware and extend standard APIs to achieve a separation in the rendering pipeline. The pre-processing of vertex data or the grouping of vertices into bounding boxes are not required. Additionally, the amount of OpenGL state commands transmitted through the network are reduced. Our results indicate that the approach can attain twice the frame rates as compared to Chromium's sort-first approach when rendering in immediate-mode.",,J.L. Williams;R.E. Hiromoto,"Department of Computer Science, University of Idaho, USA;Department of Computer Science, University of Idaho, USA",,",,,,",,3,,
Vis-conf,2005,Visualizing the tightening of knots,10.1109/VISUAL.2005.1532844,https://doi.org/10.1109/VISUAL.2005.1532844,575,582,Conferences,"The study of physical models for knots has recently received much interest in the mathematics community. In this paper, we consider the ropelength model, which considers knots tied in an idealized rope. This model is interesting in pure mathematics, and has been applied to the study of a variety of problems in the natural sciences as well. Modeling and visualizing the tightening of knots in this idealized rope poses some interesting challenges in computer graphics. In particular, self-contact in a deformable rope model is a difficult problem which cannot be handled by standard techniques. In this paper, we describe a solution based on reformulating the contact problem and using constrained-gradient techniques from nonlinear optimization. The resulting animations reveal new properties of the tightening flow and provide new insights into the geometric structure of tight knots and links.",,J. Cantarella;M. Piatek;E. Rawdon,"University of Georgia, USA;University of Washington, USA;Duquesne University",,",,,,",,3,,
Vis-conf,2005,Hardware-accelerated 3D visualization of mass spectrometry data,10.1109/VISUAL.2005.1532827,https://doi.org/10.1109/VISUAL.2005.1532827,439,446,Conferences,"We present a system for three-dimensional visualization of complex liquid chromatography-mass spectrometry (LCMS) data. Every LCMS data point has three attributes: time, mass, and intensity. Instead of the traditional visualization of two-dimensional subsets of the data, we visualize it as a height field or terrain in 3D. Unlike traditional terrains, LCMS data has non-linear sampling and consists mainly of tall needle-like features. We adapt the level-of-detail techniques of geometry clipmaps for hardware-accelerated rendering of LCMS data. The data is cached in video memory as a set of nested rectilinear grids centered about the view frustum. We introduce a simple compression scheme and dynamically stream data from the CPU to the GPU as the viewpoint moves. Our system allows interactive investigation of complex LCMS data with close to one billion data points at up to 130 frames per second, depending on the view conditions.",,J. de Corral;H. Pfister,Waters Corporation;Mitsubishi Electric Research Laboratories,,",,,,",,3,,
Vis-conf,2005,Scale-invariant volume rendering,10.1109/VISUAL.2005.1532808,https://doi.org/10.1109/VISUAL.2005.1532808,295,302,Conferences,"As standard volume rendering is based on an integral in physical space (or ""coordinate space""), it is inherently dependent on the scaling of this space. Although this dependency is appropriate for the realistic rendering of semitransparent volumetric objects, it has several unpleasant consequences for volume visualization. In order to overcome these disadvantages, a new variant of the volume rendering integral is proposed, which is defined in data space instead of physical space. Apart from achieving scale invariance, this new method supports the rendering of isosurfaces of uniform opacity and color, independently of the local gradient or"" the visualized scalar field. Moreover, it reveals certain structures in scalar fields even with constant transfer functions. Furthermore, it can be defined as the limit of infinitely many semitransparent isosurfaces, and is therefore based on an intuitive and at the same time precise definition. In addition to the discussion of these features of scale-invariant volume rendering, efficient adaptations of existing volume rendering algorithms and extensions for silhouette enhancement and local illumination by transmitted light are presented.",,M. Kraus,,,",,,,",,2,,
Vis-conf,2005,Exploring 2D tensor fields using stress nets,10.1109/VISUAL.2005.1532771,https://doi.org/10.1109/VISUAL.2005.1532771,11,18,Conferences,"In this article we describe stress nets, a technique for exploring 2D tensor fields. Our method allows a user to examine simultaneously the tensors' eigenvectors (both major and minor) as well as scalar-valued tensor invariants. By avoiding noise-advection techniques, we are able to display both principal directions of the tensor field as well as the derived scalars without cluttering the display. We present a CPU-only implementation of stress nets as well as a hybrid CPU/GPU approach and discuss the relative strengths and weaknesses of each. Stress nets have been used as part of an investigation into crack propagation. They were used to display the directions of maximum shear in a slab of material under tension as well as the magnitude of the shear forces acting on each point. Our methods allowed users to find new features in the data that were not visible on standard plots of tensor invariants. These features disagree with commonly accepted analytical crack propagation solutions and have sparked renewed investigation. Though developed for a materials mechanics problem, our method applies equally well to any 2D tensor field having unique characteristic directions.",,A. Wilson;R. Brannon,"Sandia National Laboratories, Albuquerque, NM, USA;Sandia National Laboratories, Albuquerque, NM, USA",,",,,,",,2,,
Vis-conf,2005,Volume rendering of smoke propagation CFD data,10.1109/VISUAL.2005.1532813,https://doi.org/10.1109/VISUAL.2005.1532813,335,341,Conferences,"The evacuation of buildings in the event of a fire requires careful planning of ventilation and evacuation routes during early architectural design stages. Different designs are evaluated by simulating smoke propagation using computational fluid dynamics (CFD). Visibility plays a decisive role in finding the nearest fire exit. This paper presents real-time volume rendering of transient smoke propagation conforming to standardized visibility distances. We visualize time dependent smoke particle concentration on unstructured tetrahedral meshes using a direct volume rendering approach. Due to the linear transfer function of the optical model commonly used in fire protection engineering, accurate pre-integration of diffuse color across tetrahedra can be carried out with a single 2D texture lookup. We reduce rounding errors during frame buffer blending by applying randomized dithering if high accuracy frame buffers are unavailable on the target platform. A simple absorption-based lighting model is evaluated in a preprocessing step using the same rendering approach. Back-illuminated exit signs are commonly used to indicate the escape route. As light emitting objects are visible further than reflective objects, the transfer function in front of illuminated exit signs must be adjusted with a deferred rendering pass.",,O. Staubli;C. Sigg;R. Peikert;D. Gubler;M. Gross,"ETH Zürich, Switzerland;ETH Zürich, Switzerland;ETH Zürich, Switzerland;Air Flow Consulting;ETH Zürich, Switzerland",,",,,,",,2,,
Vis-conf,2005,Visualizing tensor fields in geomechanics,10.1109/VISUAL.2005.1532774,https://doi.org/10.1109/VISUAL.2005.1532774,35,42,Conferences,"The study of stress and strains in soils and structures (solids) help us gain a better understanding of events such as failure of bridges, dams and buildings, or accumulated stresses and strains in geological subduction zones that could trigger earthquakes and subsequently tsunamis. In such domains, the key feature of interest is the location and orientation of maximal shearing planes. This paper describes a method that highlights this feature in stress tensor fields. It uses a plane-in-a-box glyph which provides a global perspective of shearing planes based on local analysis of tensors. The analysis can be performed over the entire domain, or the user can interactively specify where to introduce these glyphs. Alternatively, they can also be placed depending on the threshold level of several physical relevant parameters such as double couple and compensated linear vector dipole. Both methods are tested on stress tensor fields from geomechanics.",,A. Neeman;B. Jeremic;A. Pang,"Computer Science Department, University of California, Santa Cruz, USA;Department of Civil and Environmental Engineering, Davis, USA;Computer Science Department, University of California, Santa Cruz, USA",,",,,,",,1,,
Vis-conf,2005,Interpolation and visualization for advected scalar fields,10.1109/VISUAL.2005.1532849,https://doi.org/10.1109/VISUAL.2005.1532849,615,622,Conferences,"Doppler radars are useful facilities for weather forecasting. The data sampled by using Doppler radars are used to measure the distributions and densities of rain drops, snow crystals, hail stones, or even insects in the atmosphere. In this paper, we propose to build up a graphics-based software system for visualizing Doppler radar data. In the system, the reflectivity data gathered by using Doppler radars are post-processed to generate virtual cloud images which reveal the densities of precipitation in the air. An optical flow based method is adopted to compute the velocities of clouds, advected by winds. Therefore, the movement of clouds is depicted. The cloud velocities are also used to interpolate reflectivities for arbitrary time steps. Therefore, the reflectivities at any time can be produced. Our system composes of three stages. At the first stage, the raw radar data are re-sampled and filtered to create a multiple resolution data structure, based on a pyramid structure. At the second stage, a numeric method is employed to compute cloud velocities in the air and to interpolate radar reflectivity data at given time steps. The radar reflectivity data and cloud velocities are displayed at the last stage. The reflectivities are rendered by using splatting methods to produce semi-transparent cloud images. Two kinds of media are created for analyzing the reflectivity data. The first kind media consists of a group of still images of clouds which displays the distribution and density of water in the air. The second type media is a short animation of cloud images to show the formation and movement of the clouds. To show the advection of clouds, the cloud velocities are displayed by using two dimensional images. In these images, the velocities are represented by arrows and superimposed on cloud images. To enhance image quality, gradients and diffusion of the radar data are computed and used in the rendering process. Therefore the cloud structures are better portrayed. In order to achieve interactive visualization, our system is also comprised with a view-dependent visualization module. The radar data at far distance are rendered in lower resolutions, while the data closer to the eye position is rendered in details.",,Shyh-Kuang Ueng;Sheng-Chuan Wang,"Department of Computer Science, National Taiwan Ocean University, Keelung, Taiwan;Department of Computer Science, National Taiwan Ocean University, Keelung, Taiwan",,",,,,",,1,,
Vis-conf,2005,Reconstructing manifold and non-manifold surfaces from point clouds,10.1109/VISUAL.2005.1532824,https://doi.org/10.1109/VISUAL.2005.1532824,415,422,Conferences,"This paper presents a novel approach for surface reconstruction from point clouds. The proposed technique is general in the sense that it naturally handles both manifold and non-manifold surfaces, providing a consistent way for reconstructing closed surfaces as well as surfaces with boundaries. It is also robust in the presence of noise, irregular sampling and surface gaps. Furthermore, it is fast, parallelizable and easy to implement because it is based on simple local operations. In this approach, surface reconstruction consists of three major steps: first, the space containing the point cloud is subdivided, creating a voxel representation. Then, a voxel surface is computed using gap filling and topological thinning operations. Finally, the resulting voxel surface is converted into a polygonal mesh. We demonstrate the effectiveness of our approach by reconstructing polygonal models from range scans of real objects as well as from synthetic data.",,J. Wang;M.M. Oliveira;A.E. Kaufman,"CVC, Computer Science, Stony Brook University, USA;Instituto de Informática, UFRGS, Brazil;CVC, Computer Science, Stony Brook University, USA",,",,,,",,1,,
Vis-conf,2005,High performance volume splatting for visualization of neurovascular data,10.1109/VISUAL.2005.1532805,https://doi.org/10.1109/VISUAL.2005.1532805,271,278,Conferences,"A new technique is presented to increase the performance of volume splatting by using hardware accelerated point sprites. This allows creating screen aligned elliptical splats for high quality volume splatting at very low cost on the GPU. Only one vertex per splat is stored on the graphics card. GPU generated point sprite texture coordinates are used for computing splats and per-fragment 3D-texture coordinates on the fly. Thus, only 6 bytes per splat are stored on the GPU and vertex shader load is 25% in comparison to applying textured quads. For eight predefined viewing directions, depth-sorting of the splats is performed in a pre-processing step where the resulting indices are stored on the GPU. Thereby, there is no data transfer between CPU and GPU during rendering. Post-classificative two dimensional transfer functions with lighting for scalar data and tagged volumes were implemented. Thereby, we focused on the visualization of neurovascular structures, where typically no more than 2% of the voxels contribute to the resulting 3D-representation. A comparison with a 3D-texture-based slicing algorithm showed frame rates up to 11 times higher for the presented approach on current CPUs. The presented technique was evaluated with a broad medical database and its value for highly sparse volume visualization is shown.",,F. Vega-Higuera;P. Hastreiter;R. Fahlbusch;G. Greiner,"Neurocenter, Department of Neurosurgery and Computer Graphics Group, University of Erlangen, Germany;Neurocenter, Department of Neurosurgery and Computer Graphics Group, University of Erlangen, Germany;Neurocenter, Department of Neurosurgery and Computer Graphics Group, University of Erlangen, Germany;Dept. of Neurosurg. & Comput. Graphics Group, Univ. of Erlangen, Germany",,",,,,",,1,,
Vis-conf,2005,Eyelet particle tracing - steady visualization of unsteady flow,10.1109/VISUAL.2005.1532848,https://doi.org/10.1109/VISUAL.2005.1532848,607,614,Conferences,"It is a challenging task to visualize the behavior of time-dependent 3D vector fields. Most of the time an overview of unsteady fields is provided via animations, but, unfortunately, animations provide only transient impressions of momentary flow. In this paper we present two approaches to visualize time varying fields with fixed geometry. Path lines and streak lines represent such a steady visualization of unsteady vector fields, but because of occlusion and visual clutter it is useless to draw them all over the spatial domain. A selection is needed. We show how bundles of streak lines and path lines, running at different times through one point in space, like through an eyelet, yield an insightful visualization of flow structure (""eyelet lines""). To provide a more intuitive and appealing visualization we also explain how to construct a surface from these lines. As second approach, we use a simple measurement of local changes of a field over time to determine regions with strong changes. We visualize these regions with isosurfaces to give an overview of the activity in the dataset. Finally we use the regions as a guide for placing eyelets.",,A. Wiebel;G. Scheuermann,"Image and Signal Processing Group, Department of Computer Science, University of Leipzig, Germany;Image and Signal Processing Group, Department of Computer Science, University of Leipzig, Greece",,",,,,",,1,,
Vis-conf,2005,The visible radio: process visualization of a software-defined radio,10.1109/VISUAL.2005.1532791,https://doi.org/10.1109/VISUAL.2005.1532791,159,165,Conferences,"In this case study, a data-oriented approach is used to visualize a complex digital signal processing pipeline. The pipeline implements a frequency modulated (FM) software-defined radio (SDR). SDR is an emerging technology where portions of the radio hardware, such as filtering and modulation, are replaced by software components. We discuss how an SDR implementation is instrumented to illustrate the processes involved in FM transmission and reception. By using audio-encoded images, we illustrate the processes involved in radio, such as how filters are used to reduce noise, the nature of a carrier wave, and how frequency modulation acts on a signal. The visualization approach used in this work is very effective in demonstrating advanced topics in digital signal processing and is a useful tool for experimenting with the software radio design.",,M. Hall;A. Betts;D. Cox;D. Pointer;V. Kindratenko,"National Center for Supercomputing Applications, University of Illinois, Champaign, USA;National Center for Supercomputing Applications, University of Illinois, Champaign, USA;National Center for Supercomputing Applications, University of Illinois, Champaign, USA;National Center for Supercomputing Applications, University of Illinois, Champaign, USA;National Center for Supercomputing Applications, University of Illinois, Champaign, USA",,",,,,",,1,,
Vis-conf,2005,Visualization of time-dependent remote adaptive mesh refinement data,10.1109/VISUAL.2005.1532793,https://doi.org/10.1109/VISUAL.2005.1532793,175,182,Conferences,"Analysis of phenomena that simultaneously occur on different spatial and temporal scales requires adaptive, hierarchical schemes to reduce computational and storage demands. Adaptive mesh refinement (AMR) schemes support both refinement in space that results in a time-dependent grid topology, as well as refinement in time that results in updates at higher rates for refined levels. Visualization of AMR data requires generating data for absent refinement levels at specific time steps. We describe a solution starting from a given set of ""key frames"" with potentially different grid topologies. The presented work was developed in a project involving several research institutes that collaborate in the field of cosmology and numerical relativity. AMR data results from simulations that are run on dedicated compute machines and is thus stored centrally, whereas the analysis of the data is performed on the local computers of the scientists. We built a distributed solution using remote procedure calls (RPC). To keep the application responsive, we split the bulk data transfer from the RPC response and deliver it asynchronously as a binary stream. The number of network round-trips is minimized by using high level operations. In summary, we provide an application for exploratory visualization of remotely stored AMR data.",,R. Kaehler;S. Prohaska;A. Hutanu;H.-C. Hege,"MPI for Gravitational Physics, Zuse Institute Berlin, Germany;Zuse Institute Berlin, Germany;Louisiana State University, USA;Zuse Institute Berlin, Germany",,",,,,",,1,,
Vis-conf,2005,Fast visualization by shear-warp on quadratic super-spline models using wavelet data decompositions,10.1109/VISUAL.2005.1532816,https://doi.org/10.1109/VISUAL.2005.1532816,351,358,Conferences,"We develop the first approach Tor interactive volume visualization based on a sophisticated rendering method of shear-warp type, wavelet data encoding techniques, and a trivariate spline model, which has been introduced recently. As a first step of our algorithm, we apply standard wavelet expansions to represent and decimate the given gridded three-dimensional data. Based on this data encoding, we give a sophisticated version of the shear-warp based volume rendering method. Our new algorithm visits each voxel only once taking advantage of the particular data organization of octrees. In addition, the hierarchies of the data guide the local (re)construction of the quadratic super-spline models, which we apply as a pure visualization tool. The low total degree of the polynomial pieces allows to numerically approximate the volume rendering integral efficiently. Since the coefficients of the splines are almost immediately available from the given data, Bernstein-Bezier techniques can be fully employed in our algorithms. In this way, we demonstrate that these models can be successfully applied to full volume rendering of hierarchically organized data. Our computational results show that (even when hierarchical approximations are used) the new approach leads to almost artifact-free visualizations of high quality for complicated and noise-contaminated volume data sets, while the computational effort is considerable low, i.e. our current implementation yields 1-2 frames per second for parallel perspective rendering a 2563 volume data set (using simple opacity transfer functions) in a 5122 view-port.",,G. Schlosser;J. Hesser;F. Zeilfelder;C. Rossl;G. Nurnberger;H.-P. Seidel;R. Manner,"ICM, Universitäten Mannheim und Heidelberg, Mannheim, Germany;ICM, Universitäten Mannheim und Heidelberg, Mannheim, Germany;Institut für Mathematik, Universität Mannheim, Mannheim, Germany;;;;",,",,,,",,0,,
Vis-conf,2005,The software interface to the 3D-force microscope,10.1109/VISUAL.2005.1532829,https://doi.org/10.1109/VISUAL.2005.1532829,455,462,Conferences,"We have developed a real-time experiment-control and data-display system for a novel microscope, the 3D-force microscope (3DFM), which is designed for nanometer-scale and nanoNewton-force biophysical experiments. The 3DFM software suite synthesizes the several data sources from the 3DFM into a coherent view and provides control over data collection and specimen manipulation. Herein, we describe the system architecture designed to handle the several feedback loops and data flows present in the microscope and its control system. We describe the visualization techniques used in the 3DFM software suite, where used, and on which types of data. We present feedback from our scientist-users regarding the usefulness of these techniques, and we also present lessons learned from our successive implementations.",,D. Marshburn;C. Weigle;B.G. Wilde;R.M. Taylor;K. Desai;J.K. Fisher;J. Cribb;E.T. O'Brien;R. Superfine,"Department of Computer Science, North Carolina State University, Chapel Hill, USA;Department of Computer Science, North Carolina State University, Chapel Hill, USA;Department of Computer Science, North Carolina State University, Chapel Hill, USA;Department of Computer Science, North Carolina State University, Chapel Hill, USA;Department of Biomedical Engineering, North Carolina State University, Chapel Hill, USA;Department of Computer Science, North Carolina State University, Chapel Hill, USA;Department of Computer Science, North Carolina State University, Chapel Hill, USA;Dept. of Physics and Astronomy, University of North Carolina at Chapel Hill;Department of Physics and Astronomy, North Carolina State University, Chapel Hill, USA",,",,,,",,0,,
conference_external,2005,[Blank page],10.1109/VISUAL.2005.1532814,https://doi.org/10.1109/VISUAL.2005.1532814,342,342,Conferences,This page or pages intentionally left blank.,,,,,",,,,",,0,,
conference_external,2005,Design and evaluation in visualization research,10.1109/VISUAL.2005.1532860,https://doi.org/10.1109/VISUAL.2005.1532860,705,708,Conferences,"This panel brings together researchers who have been pioneering quite different approaches to visualization research by integrating evaluation and knowledge of visual design into their work. The panelists will present their views and experiences in using user studies for quantitative evaluation of methods, in integrating the expertise of visually trained designers into the development of methods, and in exploring the parameter space of visualization possibilities using ""human-in-the-loop"" experiments. A goal of the panel is to encourage a lively and stimulating discussion by presenting challenging but highly contrasting ideas. The panel will follow the usual pattern of short position presentations, taking care to leave ample time for audience interaction, questions, and comments.",,Donald House;Victoria Interrante;David Laidlaw;Russell Taylor;Colin Ware,"Texas A and M University, USA;University of Minnesota, USA;Brown University, USA;North Carolina State University, USA;University of New Hampshire, USA",,"visualization evaluation,visualization design,,,",,4,,
conference_external,2005,Illustrative rendering techniques for visualization: Future of visualization or just another technique?,10.1109/VISUAL.2005.1532863,https://doi.org/10.1109/VISUAL.2005.1532863,715,718,Conferences,"Illustrative rendering, often also depicted as non-photorealistic rendering1 or stylized rendering, employs abstraction techniques to convey the relevant information, and de-emphasize less important details. The question remains how this abstraction process is guided and in particular how can we ensure that relevant information is maintained. Consequently, research on illustrative rendering needs to address how the information is perceived by the human observer, next to the investigation of algorithmic aspects. In this panel, we discuss various aspects on this topic. Kwan-Liu Ma discusses how illustrative rendering can be used in scientifc visualization, and Bernhard Preim explores its use for the visualization in the medical imaging domain. Perception aspects are presented by Victoria Interrante. A different perspective, if illustrative rendering is useful for typical visualization problems, is added by Hans Hagen.",,D. Bartz;H. Hagen;V. Interrante;Kwan-Liu Ma;B. Preim,;;;;,,",,,,",,2,,
conference_external,2005,End users' perspectives on volume rendering in medical imaging: A job well done or not over yet?,10.1109/VISUAL.2005.1532862,https://doi.org/10.1109/VISUAL.2005.1532862,711,713,Conferences,"The objective of this panel is to reflect on the advances that volume rendering has brought to the medical community and, even more important, to discuss its current short-comings and future needs. This direct feedback from the medical community will hopefully inspire the IEEE Visualization audience and help to focus on new research areas that will further advance the state of the art in medical visualization. The panel assembles end-users from well-known medical facilities and research institutions who have a background in visualization but primarily are experts using this technology for practical diagnostic applications.",,M. Meissner;K. Zuiderveld;G. Harris;J.R. Lesser;A. Persson;M. Vannier,;;;;;,,",,,,",,1,,
conference_external,2005,The Visualization Process: The Path from Data to Insight,10.1109/VISUAL.2005.1532861,https://doi.org/10.1109/VISUAL.2005.1532861,709,710,Conferences,"While previous Visualization panels have focused on different methods for scientific visualization, this panel focuses on the process of transforming data into insight. The overarching goal for visualization is to transform data into information or knowledge. This goal, however, can be somewhat elusive and difficult to achieve. The purpose of this panel is to discuss a variety of approaches that range from traditional to those that are new and emerging. Each of the given panelists is keenly interested in extracting relevant knowledge and information from a given set of data. However, each panelist takes a very different approach, and each has a different process by which visualization bears insight. David Ebert is inspired by the effectiveness of illustration and experimental photography techniques to convey knowledge. Kelly Gaither is keenly rooted in the physical meaning behind the data and uses this knowledge to guide the choice and style of visual representation. Pat Hanrahan is interested in self-illustrating phenomena and new approaches to visualizing streams of data such as network flows, migrations of birds and people, and flow of goods and traffic. Daniel Weiskopf is exploring the impact of color, motion, and interactivity on the visualization process. His approaches are traditional in nature but incorporate advances in graphics hardware.",,K. Gaither;D. Ebert;D. Weiskopf;P. Hanrahan,"University of Technology, Austin, USA;Purdue University, USA;Simon Fraser University, Canada;University of Stanford, USA",,",,,,",,0,,
