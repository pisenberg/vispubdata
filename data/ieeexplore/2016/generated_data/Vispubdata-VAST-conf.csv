Conference,Year,Title,DOI,Link,FirstPage,LastPage,PaperType,Abstract,AuthorNames-Deduped,AuthorNames,AuthorAffiliation,InternalReferences,AuthorKeywords,AminerCitationCount,CitationCount_CrossRef,PubsCited,Award
VAST-conf,2016,EventAction: Visual analytics for temporal event sequence recommendation,10.1109/VAST.2016.7883512,https://doi.org/10.1109/VAST.2016.7883512,61,70,Conferences,"Recommender systems are being widely used to assist people in making decisions, for example, recommending films to watch or books to buy. Despite its ubiquity, the problem of presenting the recommendations of temporal event sequences has not been studied. We propose EventAction, which to our knowledge, is the first attempt at a prescriptive analytics interface designed to present and explain recommendations of temporal event sequences. EventAction provides a visual analytics approach to (1) identify similar records, (2) explore potential outcomes, (3) review recommended temporal event sequences that might help achieve the users' goals, and (4) interactively assist users as they define a personalized action plan associated with a probability of success. Following the design study framework, we designed and deployed EventAction in the context of student advising and reported on the evaluation with a student review manager and three graduate students.",,Fan Du;Catherine Plaisant;Neil Spring;Ben Shneiderman,University of Maryland;University of Maryland;University of Maryland;University of Maryland,,"Temporal event sequences,recommender systems,prescriptive analytics,visual analytics,,,,",,45,,
VAST-conf,2016,DropoutSeer: Visualizing learning patterns in Massive Open Online Courses for dropout reasoning and prediction,10.1109/VAST.2016.7883517,https://doi.org/10.1109/VAST.2016.7883517,111,120,Conferences,"Aiming at massive participation and open access education, Massive Open Online Courses (MOOCs) have attracted millions of learners over the past few years. However, the high dropout rate of learners is considered to be one of the most crucial factors that may hinder the development of MOOCs. To tackle this problem, statistical models have been developed to predict dropout behavior based on learner activity logs. Although predictive models can foresee the dropout behavior, it is still difficult for users to understand the reasons behind the predicted results and further design interventions to prevent dropout. In addition, with a better understanding of dropout, researchers in the area of predictive modeling in turn can improve the models. In this paper, we introduce DropoutSeer, a visual analytics system which not only helps instructors and education experts understand the reasons for dropout, but also allows researchers to identify crucial features which can further improve the performance of the models. Both the heterogeneous data extracted from three different kinds of learner activity logs (i.e., clickstream, forum posts and assignment records) and the predicted results are visualized in the proposed system. Case studies and expert interviews have been conducted to demonstrate the usefulness and effectiveness of DropoutSeer.",,Yuanzhe Chen;Qing Chen;Mingqian Zhao;Sebastien Boyer;Kalyan Veeramachaneni;Huamin Qu,Hong Kong University of Science and Technology;Hong Kong University of Science and Technology;Hong Kong University of Science and Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology;Hong Kong University of Science and Technology,,"Visualization in education,machine learning,time series data,design studies,,,,",,33,,
VAST-conf,2016,D-Map: Visual analysis of ego-centric information diffusion patterns in social media,10.1109/VAST.2016.7883510,https://doi.org/10.1109/VAST.2016.7883510,41,50,Conferences,"Popular social media platforms could rapidly propagate vital information over social networks among a significant number of people. In this work we present D-Map (Diffusion Map), a novel visualization method to support exploration and analysis of social behaviors during such information diffusion and propagation on typical social media through a map metaphor. In D-Map, users who participated in reposting (i.e., resending a message initially posted by others) one central user's posts (i.e., a series of original tweets) are collected and mapped to a hexagonal grid based on their behavior similarities and in chronological order of the repostings. With additional interaction and linking, D-Map is capable of providing visual portraits of the influential users and describing their social behaviors. A comprehensive visual analysis system is developed to support interactive exploration with D-Map. We evaluate our work with real world social media data and find interesting patterns among users. Key players, important information diffusion paths, and interactions among social communities can be identified.",,Siming Chen;Shuai Chen;Zhenhuang Wang;Jie Liang;Xiaoru Yuan;Nan Cao;Yadong Wu,"Key Laboratory of Machine Perception (Ministry of Education), and School of EECS, Peking University, China;Key Laboratory of Machine Perception (Ministry of Education), and School of EECS, Peking University, China;Key Laboratory of Machine Perception (Ministry of Education), and School of EECS, Peking University, China;Faculty of Engineer and Information Technology, The University of Technology, Sydney, Australia;Key Laboratory of Machine Perception (Ministry of Education), and School of EECS, Peking University, China;New York University, Shanghai, China;Southwest University of Science and Technology, China",,"Social Media,Map,Information Diffusion,,,,,",,31,,
VAST-conf,2016,How ideas flow across multiple social groups,10.1109/VAST.2016.7883511,https://doi.org/10.1109/VAST.2016.7883511,51,60,Conferences,"Tracking how correlated ideas flow within and across multiple social groups facilitates the understanding of the transfer of information, opinions, and thoughts on social media. In this paper, we present IdeaFlow, a visual analytics system for analyzing the lead-lag changes within and across pre-defined social groups regarding a specific set of correlated ideas, each of which is described by a set of words. To model idea flows accurately, we develop a random-walk-based correlation model and integrate it with Bayesian conditional cointegration and a tensor-based technique. To convey complex lead-lag relationships over time, IdeaFlow combines the strengths of a bubble tree, a flow map, and a timeline. In particular, we develop a Voronoi-treemap-based bubble tree to help users get an overview of a set of ideas quickly. A correlated-clustering-based layout algorithm is used to simultaneously generate multiple flow maps with less ambiguity. We also introduce a focus+context timeline to explore huge amounts of temporal data at different levels of time granularity. Quantitative evaluation and case studies demonstrate the accuracy and effectiveness of IdeaFlow.",,Xiting Wang;Shixia Liu;Yang Chen;Tai-Quan Peng;Jing Su;Jing Yang;Baining Guo,"School of Software, Tsinghua University;School of Software, Tsinghua University;School of Software, Tsinghua University;Michigan State University;Tsinghua University;UNCC;Microsoft Research",,"Idea flow,lead-lag,focus+context,correlated clustering,flow map,,,",,23,,
VAST-conf,2016,The semantics of sketch: Flexibility in visual query systems for time series data,10.1109/VAST.2016.7883519,https://doi.org/10.1109/VAST.2016.7883519,131,140,Conferences,"Sketching allows analysts to specify complex and free-form patterns of interest. Visual query systems can make use of sketches to locate these patterns of interest in large datasets. However, sketching is ambiguous: the same drawing could represent a multitude of potential queries. In this work, we investigate these ambiguities as they apply to visual query systems for time series data. We define a class of “invariants” - the properties of a time series that the analyst wishes to ignore when performing a sketch-based query. We present the results of a crowd-sourced study, showing that these invariants are key components of how people rate the strength of match between sketch and target. We adapt a number of algorithms for time series matching to support invariants in sketches. Lastly, we present a web-deployed prototype sketch-based visual query system that relies on these invariants. We apply the prototype to data from finance, the digital humanities, and political science.",,Michael Correll;Michael Gleicher,University of Washington;University of Wisconsin-Madison,,",,,,,,,",,23,,
VAST-conf,2016,DocuCompass: Effective exploration of document landscapes,10.1109/VAST.2016.7883507,https://doi.org/10.1109/VAST.2016.7883507,11,20,Conferences,"The creation of interactive visualization to analyze text documents has gained an impressive momentum in recent years. This is not surprising in the light of massive and still increasing amounts of available digitized texts. Websites, social media, news wire, and digital libraries are just few examples of the diverse text sources whose visual analysis and exploration offers new opportunities to effectively mine and manage the information and knowledge hidden within them. A popular visualization method for large text collections is to represent each document by a glyph in 2D space. These landscapes can be the result of optimizing pairwise distances in 2D to represent document similarities, or they are provided directly as meta data, such as geo-locations. For well-defined information needs, suitable interaction methods are available for these spatializations. However, free exploration and navigation on a level of abstraction between a labeled document spatialization and reading single documents is largely unsupported. As a result, vital foraging steps for task-tailored actions, such as selecting subgroups of documents for detailed inspection, or subsequent sense-making steps are hampered. To fill in this gap, we propose DocuCompass, a focus+context approach based on the lens metaphor. It comprises multiple methods to characterize local groups of documents, and to efficiently guide exploration based on users' requirements. DocuCompass thus allows for effective interactive exploration of document landscapes without disrupting the mental map of users by changing the layout itself. We discuss the suitability of multiple navigation and characterization methods for different spatializations and texts. Finally, we provide insights generated through user feedback and discuss the effectiveness of our approach.",,Florian Heimerl;Markus John;Qi Han;Steffen Koch;Thomas Ertl,"SAP Innovation Center, Singapore;SAP Innovation Center, Singapore;;;",,"interaction techniques,document visualization,text mining,visual analytics,focus+context,,,",,18,,
VAST-conf,2016,SenseMap: Supporting browser-based online sensemaking through analytic provenance,10.1109/VAST.2016.7883515,https://doi.org/10.1109/VAST.2016.7883515,91,100,Conferences,"Sensemaking is described as the process in which people collect, organize and create representations of information, all centered around some problem they need to understand. People often get lost when solving complicated tasks using big datasets over long periods of exploration and analysis. They may forget what they have done, are unaware of where they are in the context of the overall task, and are unsure where to continue. In this paper, we introduce a tool, SenseMap, to address these issues in the context of browser-based online sensemaking. We conducted a semi-structured interview with nine participants to explore their behaviors in online sensemaking with existing browser functionality. A simplified sensemaking model based on Pirolli and Card's model is derived to better represent the behaviors we found: users iteratively collect information sources relevant to the task, curate them in a way that makes sense, and finally communicate their findings to others. SenseMap automatically captures provenance of user sensemaking actions and provides multi-linked views to visualize the collected information and enable users to curate and communicate their findings. To explore how SenseMap is used, we conducted a user study in a naturalistic work setting with five participants completing the same sensemaking task related to their daily work activities. All participants found the visual representation and interaction of the tool intuitive to use. Three of them engaged with the tool and produced successful outcomes. It helped them to organize information sources, to quickly find and navigate to the sources they wanted, and to effectively communicate their findings.",,Phong H. Nguyen;Kai Xu;Andy Bardill;Betul Salman;Kate Herd;B.L. William Wong,"Middlesex University, London, UK;Middlesex University, London, UK;Middlesex University, London, UK;Middlesex University, London, UK;Middlesex University, London, UK;Middlesex University, London, UK",,"Sensemaking,browser-based online sensemaking,analytic provenance,visual analytics,visualization,design study,,",,17,,
VAST-conf,2016,Supporting visual exploration for multiple users in large display environments,10.1109/VAST.2016.7883506,https://doi.org/10.1109/VAST.2016.7883506,1,10,Conferences,"We present a design space exploration of interaction techniques for supporting multiple collaborators exploring data on a shared large display. Our proposed solution is based on users controlling individual lenses using both explicit gestures as well as proxemics: the spatial relations between people and physical artifacts such as their distance, orientation, and movement. We discuss different design considerations for implicit and explicit interactions through the lens, and evaluate the user experience to find a balance between the implicit and explicit interaction styles. Our findings indicate that users favor implicit interaction through proxemics for navigation and collaboration, but prefer using explicit mid-air gestures to perform actions that are perceived to be direct, such as terminating a lens composition. Based on these results, we propose a hybrid technique utilizing both proxemics and mid-air gestures, along with examples applying this technique to other datasets. Finally, we performed a usability evaluation of the hybrid technique and observed user performance improvements in the presence of both implicit and explicit interaction styles.",,Sriram Karthik Badam;Fereshteh Amini;Niklas Elmqvist;Pourang Irani,"University of Maryland, College Park, MD, USA;University of Manitoba, Winnipeg, MB, Canada;University of Maryland, College Park, MD, USA;University of Manitoba, Winnipeg, MB, Canada",,"Proxemics,gestures,visual exploration,collaborative sensemaking,user study,large displays,orientation,position",,14,,
VAST-conf,2016,Visual analysis and coding of data-rich user behavior,10.1109/VAST.2016.7883520,https://doi.org/10.1109/VAST.2016.7883520,141,150,Conferences,"Investigating user behavior involves abstracting low-level events to higher-level concepts. This requires an analyst to study individual user activities, assign codes which categorize behavior, and develop a consistent classification scheme. To better support this reasoning process of an analyst, we suggest a novel visual analytics approach which integrates rich user data including transcripts, videos, eye movement data, and interaction logs. Word-sized visualizations embedded into a tabular representation provide a space-efficient and detailed overview of user activities. An analyst assigns codes, grouped into code categories, as part of an interactive process. Filtering and searching helps to select specific activities and focus an analysis. A comparison visualization summarizes results of coding and reveals relationships between codes. Editing features support efficient assignment, refinement, and aggregation of codes. We demonstrate the practical applicability and usefulness of our approach in a case study and describe expert feedback.",,Tanja Blascheck;Fabian Beck;Sebastian Baltes;Thomas Ertl;Daniel Weiskopf,"University of Stuttgart, Germany;University of Stuttgart, Germany;University of Trier, Germany;University of Stuttgart, Germany;University of Stuttgart, Germany",,"I.3.6 [Methodology and Techniques]: Interaction techniques—,H.5.2 [User Interfaces]: Evaluation/Methodology—,,,,,,",,11,,
VAST-conf,2016,SocialBrands: Visual analysis of public perceptions of brands on social media,10.1109/VAST.2016.7883513,https://doi.org/10.1109/VAST.2016.7883513,71,80,Conferences,"Public perceptions of a brand is critical to its performance. While social media has demonstrated a huge potential to shape public perceptions of brands, existing tools are not intuitive and explanatory for domain users to use as they fail to provide a comprehensive analysis framework for perceptions of brands. In this paper, we present SocialBrands, a novel visual analysis tool for brand managers to understand public perceptions of brands on social media. Social-Brands leverages brand personality framework in marketing literature and social computing approaches to compute the personality of brands from three driving factors (user imagery, employee imagery, and official announcement) on social media, and construct an evidence network explaining the association between brand personality and driving factors. These computational results are then integrated with new interactive visualizations to help brand managers understand personality traits and their driving factors. We demonstrate the usefulness and effectiveness of SocialBrands through a series of user studies with brand managers in an enterprise context. Design lessons are also derived from our studies.",,Xiaotong Liu;Anbang Xu;Liang Gou;Haibin Liu;Rama Akkiraju;Han-Wei Shen,Visa Research;IBM Research;Ohio State University;IBM Research;IBM Research;Visa Research,,",,,,,,,",,9,,
VAST-conf,2016,PorosityAnalyzer: Visual analysis and evaluation of segmentation pipelines to determine the porosity in fiber-reinforced polymers,10.1109/VAST.2016.7883516,https://doi.org/10.1109/VAST.2016.7883516,101,110,Conferences,"In this paper we present PorosityAnalyzer, a novel tool for detailed evaluation and visual analysis of pore segmentation pipelines to determine the porosity in fiber-reinforced polymers (FRPs). The presented tool consists of two modules: the computation module and the analysis module. The computation module enables a convenient setup and execution of distributed off-line-computations on industrial 3D X-ray computed tomography datasets. It allows the user to assemble individual segmentation pipelines in the form of single pipeline steps, and to specify the parameter ranges as well as the sampling of the parameter-space of each pipeline segment. The result of a single segmentation run consists of the input parameters, the calculated 3D binary-segmentation mask, the resulting porosity value, and other derived results (e.g., segmentation pipeline run-time). The analysis module presents the data at different levels of detail by drill-down filtering in order to determine accurate and robust segmentation pipelines. Overview visualizations allow to initially compare and evaluate the segmentation pipelines. With a scatter plot matrix (SPLOM), the segmentation pipelines are examined in more detail based on their input and output parameters. Individual segmentation-pipeline runs are selected in the SPLOM and visually examined and compared in 2D slice views and 3D renderings by using aggregated segmentation masks and statistical contour renderings. PorosityAnalyzer has been thoroughly evaluated with the help of twelve domain experts. Two case studies demonstrate the applicability of our proposed concepts and visualization techniques, and show that our tool helps domain experts to gain new insights and improve their workflow efficiency.",,Johannes Weissenböck;Artem Amirkhanov;Eduard Gröller;Johann Kastner;Christoph Heinzl,"University of Applied Sciences, Wels, Upper Austria, Austria;University of Applied Sciences, Wels, Upper Austria, Austria;VrVis Research Center, Austria;University of Applied Sciences, Wels, Upper Austria, Austria;University of Applied Sciences, Wels, Upper Austria, Austria",,"I.3.6 [Computer Graphics]: Methodology and Techniques—Interaction techniques,,,,,,,",,9,,
VAST-conf,2016,Shape grammar extraction for efficient query-by-sketch pattern matching in long time series,10.1109/VAST.2016.7883518,https://doi.org/10.1109/VAST.2016.7883518,121,130,Conferences,"Long time-series, involving thousands or even millions of time steps, are common in many application domains but remain very difficult to explore interactively. Often the analytical task in such data is to identify specific patterns, but this is a very complex and computationally difficult problem and so focusing the search in order to only identify interesting patterns is a common solution. We propose an efficient method for exploring user-sketched patterns, incorporating the domain expert's knowledge, in time series data through a shape grammar based approach. The shape grammar is extracted from the time series by considering the data as a combination of basic elementary shapes positioned across different amplitudes. We represent these basic shapes using a ratio value, perform binning on ratio values and apply a symbolic approximation. Our proposed method for pattern matching is amplitude-, scale- and translation-invariant and, since the pattern search and pattern constraint relaxation happen at the symbolic level, is very efficient permitting its use in a real-time/online system. We demonstrate the effectiveness of our method in a case study on stock market data although it is applicable to any numeric time series data.",,Prithiviraj K. Muthumanickam;Katerina Vrotsou;Matthew Cooper;Jimmy Johansson,"Linköping University, Sweden;Linköping University, Sweden;Linköping University, Sweden;Linköping University, Sweden",,"User-queries,Sketching,Time Series,Symbolic approximation,Regular Expression,Shape Grammar,,",,8,,
VAST-conf,2016,C2A: Crowd consensus analytics for virtual colonoscopy,10.1109/VAST.2016.7883508,https://doi.org/10.1109/VAST.2016.7883508,21,30,Conferences,"We present a medical crowdsourcing visual analytics platform called C2A to visualize, classify and filter crowdsourced clinical data. More specifically, C2A is used to build consensus on a clinical diagnosis by visualizing crowd responses and filtering out anomalous activity. Crowdsourcing medical applications have recently shown promise where the non-expert users (the crowd) were able to achieve accuracy similar to the medical experts. This has the potential to reduce interpretation/reading time and possibly improve accuracy by building a consensus on the findings beforehand and letting the medical experts make the final diagnosis. In this paper, we focus on a virtual colonoscopy (VC) application with the clinical technicians as our target users, and the radiologists acting as consultants and classifying segments as benign or malignant. In particular, C2A is used to analyze and explore crowd responses on video segments, created from fly-throughs in the virtual colon. C2A provides several interactive visualization components to build crowd consensus on video segments, to detect anomalies in the crowd data and in the VC video segments, and finally, to improve the non-expert user's work quality and performance by A/B testing for the optimal crowdsourcing platform and application-specific parameters. Case studies and domain experts feedback demonstrate the effectiveness of our framework in improving workers' output quality, the potential to reduce the radiologists' interpretation time, and hence, the potential to improve the traditional clinical workflow by marking the majority of the video segments as benign based on the crowd consensus.",,Ji Hwan Park;Saad Nadeem;Seyedkoosha Mirhosseini;Arie Kaufman,Stony Brook University;Stony Brook University;Stony Brook University;Stony Brook University,,"Crowdsourcing,virtual colonoscopy,visual analytics,biomedical applications,,,,",,6,,
VAST-conf,2016,DimScanner: A relation-based visual exploration approach towards data dimension inspection,10.1109/VAST.2016.7883514,https://doi.org/10.1109/VAST.2016.7883514,81,90,Conferences,"Exploring multi-dimensional datasets can be cumbersome if data analysts have little knowledge about the data. Various dimension relation inspection tools and dimension exploration tools have been proposed for efficient data examining and understanding. However, the needed workload varies largely with respect to data complexity and user expertise, which can only be reduced with rich background knowledge over the data. In this paper we address the workload challenge with a data structuring and exploration scheme that affords dimension relation detection and that serves as the background knowledge for further investigation. We contribute a novel data structuring scheme that leverages an information-theoretic view structuring algorithm to uncover information-aware relations among different data views, and thereby discloses redundancy and other relation patterns among dimensions. The integrated system, DimScanner, empowers analysts with rich user controls and assistance widgets to interactively detect the relations of multi-dimensional data.",,Jing Xia;Wei Chen;Yumeng Hou;Wanqi Hu;Xinxin Huang;David S. Ebertk,"State Key Lab of CAD&CG, Zhejiang University;State Key Lab of CAD&CG, Zhejiang University;State Key Lab of CAD&CG, Zhejiang University;State Key Lab of CAD&CG, Zhejiang University;State Key Lab of CAD&CG, Zhejiang University;Purdue University System, West Lafayette, IN, US",,"High-dimensional data visualization,information-aware relation,data exploration,,,,,",,6,,
VAST-conf,2016,The DataSpace for HIV vaccine studies,10.1109/VAST.2016.7883509,https://doi.org/10.1109/VAST.2016.7883509,31,40,Conferences,"The DataSpace for HIV vaccine studies is a discovery tool available on the web to hundreds of investigators. We designed it to help them better understand activity in the field and explore new ideas latent in completed research. The DataSpace harmonizes immunoassay results and study metadata so that a broader research community can pursue more flexible discovery than the typical centrally planned analyses. Insights from human-centered design and beta evaluation suggest strong potential for visual analytics that may also apply to other efforts in open science. The contribution of this paper is to elucidate key domain challenges and demonstrate an application that addresses them. We made several changes to familiar visualizations to support key tasks such as identifying and filtering to a cohort of interest, making meaningful comparisons of time series data from multiple studies that have different plans, and preserving analytic context when making data transformations and comparisons that would normally exclude some data.",,David McColgin;Paul Hoover;Mark Igra,Artefact;Artefact;Independent,,"Hypothesis forming,Time series visualization,Visual knowledge discovery,Vaccines,Public health,,,",,1,,
conference_external,2016,VIS capstone address,10.1109/VAST.2016.7883505,https://doi.org/10.1109/VAST.2016.7883505,xiii,xiii,Conferences,"Useful as each of them can be, a large body of tips and tricks is impossible to remember, at least in a practical, usable way, unless it is structured into a balanced, meaningful hierarchy. This talk proposes and illustrates three simple yet solid ideas that lead to more effective communication and that underpin every other guideline: easy to remember, readily applicable, and always relevant—in short, valuable for the rest of your life.",,Jean-luc Doumont,"Louvain, Belgium",,",,,,,,,",,0,,
conference_external,2016,VIS keynote address,10.1109/VAST.2016.7883504,https://doi.org/10.1109/VAST.2016.7883504,xii,xii,Conferences,Recent theories of the wealth and poverty of nations put the accent on the accumulation of collective know how. The fundamental difference between rich and poor countries is not in the average level of individual skills of their citizens but in the kinds of things that can be done collectively. This creates an important visualization problem: how to measure and represent the differential levels of collective know how between countries and regions? How to visualize its evolution in time? How to identify more feasible and effective paths for progress? How can visualization help orient the efforts of the public and private sectors in enhancing progress?,,Ricardo Hausmann,"Center for International Development, Harvard University, United States of America",,",,,,,,,",,0,,
conference_external,2016,IEEE Visualization and Graphics Technical Committee (VGTC),10.1109/VAST.2016.7883498,https://doi.org/10.1109/VAST.2016.7883498,vi,vi,Conferences,Provides a listing of current committee members and society officers.,,,,,",,,,,,,",,0,,
conference_external,2016,Preface,10.1109/VAST.2016.7883497,https://doi.org/10.1109/VAST.2016.7883497,v,v,Conferences,"The IEEE Visual Analytics Science and Technology (VAST) Conference is now in its eleventh year, and its seventh year as an IEEE Conference. It remains the primary venue for the rapidly growing feld of visual analytics. Visual analytics is the science of analytical reasoning supported by highly interactive visual interfaces, and seeks to integrate computational analytics with human cognitive processes. Visual analytics requires interdisciplinary science, going beyond traditional visualization to include statistics, mathematics, knowledge representation, management and discovery technologies, cognitive and perceptual sciences, decision sciences, and more.",,Gennady Andrienko;Shixia Liu;John Stasko,"Fraunhofer IAIS & City University London, United Kingdom;Tsinghua University, China;Georgia Institute of Technology, United States of America",,",,,,,,,",,0,,
conference_external,2016,VAST international program committee,10.1109/VAST.2016.7883500,https://doi.org/10.1109/VAST.2016.7883500,viii,viii,Conferences,Provides a listing of current committee members and society officers.,,,,,",,,,,,,",,0,,
conference_external,2016,VIS conference committee,10.1109/VAST.2016.7883499,https://doi.org/10.1109/VAST.2016.7883499,vii,vii,Conferences,Provides a listing of current committee members and society officers.,,,,,",,,,,,,",,0,,
conference_external,2016,[Title page],10.1109/VAST.2016.7883494,https://doi.org/10.1109/VAST.2016.7883494,i,i,Conferences,Presents the title page of the proceedings record.,,,,,",,,,,,,",,0,,
conference_external,2016,Table of contents,10.1109/VAST.2016.7883496,https://doi.org/10.1109/VAST.2016.7883496,iii,iv,Conferences,The following topics are dealt with: biomedical visualization; social media; data visual and algorithmic analysis; visual knowledge discovery; sense-making; time-series data; education and computer games.,,,,,",,,,,,,",,0,,
conference_external,2016,VAST paper reviewers,10.1109/VAST.2016.7883501,https://doi.org/10.1109/VAST.2016.7883501,ix,ix,Conferences,The publication offers a note of thanks and lists its reviewers.,,,,,",,,,,,,",,0,,
conference_external,2016,[Copyright notice],10.1109/VAST.2016.7883495,https://doi.org/10.1109/VAST.2016.7883495,ii,ii,Conferences,Presents the copyright information for the conference. May include reprint permission information.,,,,,",,,,,,,",,0,,
conference_external,2016,The 2016 Visualization Technical Achievement Award,10.1109/VAST.2016.7883503,https://doi.org/10.1109/VAST.2016.7883503,xi,xi,Conferences,"The 2016 Visualization Technical Achievement Award goes to David Ebert in recognition of foundational work in visual analytics, both through development of fundamental predictive techniques and as Director of the Purdue/DHS Visual Analytics Center of Excellence.",,David Ebert,"Purdue University, United States of America",,",,,,,,,",,0,,
conference_external,2016,The 2016 Visualization Career Award,10.1109/VAST.2016.7883502,https://doi.org/10.1109/VAST.2016.7883502,x,x,Conferences,"The 2016 Visualization Career Award goes to John Dill in recognition of major industrial and academic research advances spanning CAE/CAD, HCI, and data visualization as well as organizational leadership that helped develop the field of visual analytics.",,John Dill,"Simon Fraser University, Canada",,",,,,,,,",,0,,
