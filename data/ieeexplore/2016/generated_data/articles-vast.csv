"articles_abstract","articles_abstract_url","articles_access_type","articles_article_number","articles_authors_authors_0_affiliation","articles_authors_authors_0_authorUrl","articles_authors_authors_0_author_order","articles_authors_authors_0_full_name","articles_authors_authors_0_id","articles_authors_authors_1_affiliation","articles_authors_authors_1_authorUrl","articles_authors_authors_1_author_order","articles_authors_authors_1_full_name","articles_authors_authors_1_id","articles_authors_authors_2_affiliation","articles_authors_authors_2_authorUrl","articles_authors_authors_2_author_order","articles_authors_authors_2_full_name","articles_authors_authors_2_id","articles_authors_authors_3_affiliation","articles_authors_authors_3_authorUrl","articles_authors_authors_3_author_order","articles_authors_authors_3_full_name","articles_authors_authors_3_id","articles_authors_authors_4_affiliation","articles_authors_authors_4_authorUrl","articles_authors_authors_4_author_order","articles_authors_authors_4_full_name","articles_authors_authors_4_id","articles_authors_authors_5_affiliation","articles_authors_authors_5_authorUrl","articles_authors_authors_5_author_order","articles_authors_authors_5_full_name","articles_authors_authors_5_id","articles_authors_authors_6_affiliation","articles_authors_authors_6_authorUrl","articles_authors_authors_6_author_order","articles_authors_authors_6_full_name","articles_authors_authors_6_id","articles_citing_paper_count","articles_citing_patent_count","articles_conference_dates","articles_conference_location","articles_content_type","articles_doi","articles_end_page","articles_html_url","articles_index_terms_author_terms_terms_0","articles_index_terms_author_terms_terms_1","articles_index_terms_author_terms_terms_2","articles_index_terms_author_terms_terms_3","articles_index_terms_author_terms_terms_4","articles_index_terms_author_terms_terms_5","articles_index_terms_author_terms_terms_6","articles_index_terms_author_terms_terms_7","articles_index_terms_ieee_terms_terms_0","articles_index_terms_ieee_terms_terms_1","articles_index_terms_ieee_terms_terms_2","articles_index_terms_ieee_terms_terms_3","articles_index_terms_ieee_terms_terms_4","articles_index_terms_ieee_terms_terms_5","articles_index_terms_ieee_terms_terms_6","articles_is_number","articles_isbn","articles_isbn_formats_isbns_0_format","articles_isbn_formats_isbns_0_isbnType","articles_isbn_formats_isbns_0_value","articles_isbn_formats_isbns_1_format","articles_isbn_formats_isbns_1_isbnType","articles_isbn_formats_isbns_1_value","articles_pdf_url","articles_publication_date","articles_publication_number","articles_publication_title","articles_publication_year","articles_publisher","articles_rank","articles_start_page","articles_title"
"The creation of interactive visualization to analyze text documents has gained an impressive momentum in recent years. This is not surprising in the light of massive and still increasing amounts of available digitized texts. Websites, social media, news wire, and digital libraries are just few examples of the diverse text sources whose visual analysis and exploration offers new opportunities to effectively mine and manage the information and knowledge hidden within them. A popular visualization method for large text collections is to represent each document by a glyph in 2D space. These landscapes can be the result of optimizing pairwise distances in 2D to represent document similarities, or they are provided directly as meta data, such as geo-locations. For well-defined information needs, suitable interaction methods are available for these spatializations. However, free exploration and navigation on a level of abstraction between a labeled document spatialization and reading single documents is largely unsupported. As a result, vital foraging steps for task-tailored actions, such as selecting subgroups of documents for detailed inspection, or subsequent sense-making steps are hampered. To fill in this gap, we propose DocuCompass, a focus+context approach based on the lens metaphor. It comprises multiple methods to characterize local groups of documents, and to efficiently guide exploration based on users' requirements. DocuCompass thus allows for effective interactive exploration of document landscapes without disrupting the mental map of users by changing the layout itself. We discuss the suitability of multiple navigation and characterization methods for different spatializations and texts. Finally, we provide insights generated through user feedback and discuss the effectiveness of our approach.","https://ieeexplore.ieee.org/document/7883507/","LOCKED","7883507","","https://ieeexplore.ieee.org/author/38490630000","1","Florian Heimerl","38490630000","","https://ieeexplore.ieee.org/author/37085484719","2","Markus John","37085484719","","https://ieeexplore.ieee.org/author/37085447519","3","Qi Han","37085447519","","https://ieeexplore.ieee.org/author/37593029700","4","Steffen Koch","37593029700","","https://ieeexplore.ieee.org/author/37268023800","5","Thomas Ertl","37268023800","","","","","","","","","","","10","0","23-28 Oct. 2016","Baltimore, MD","Conferences","10.1109/VAST.2016.7883507","20","https://ieeexplore.ieee.org/document/7883507/","interaction techniques","document visualization","text mining","visual analytics","focus+context","","","","Lenses","Visualization","Two dimensional displays","Layout","Metadata","Text analysis","Navigation","7883493","978-1-5090-5662-0","Print on Demand(PoD) ISBN","New-2005","978-1-5090-5662-0","Electronic ISBN","New-2005","978-1-5090-5661-3","https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7883507","23-28 Oct. 2016","7867613","2016 IEEE Conference on Visual Analytics Science and Technology (VAST)","2016","IEEE","1","11","DocuCompass: Effective exploration of document landscapes"
"Tracking how correlated ideas flow within and across multiple social groups facilitates the understanding of the transfer of information, opinions, and thoughts on social media. In this paper, we present IdeaFlow, a visual analytics system for analyzing the lead-lag changes within and across pre-defined social groups regarding a specific set of correlated ideas, each of which is described by a set of words. To model idea flows accurately, we develop a random-walk-based correlation model and integrate it with Bayesian conditional cointegration and a tensor-based technique. To convey complex lead-lag relationships over time, IdeaFlow combines the strengths of a bubble tree, a flow map, and a timeline. In particular, we develop a Voronoi-treemap-based bubble tree to help users get an overview of a set of ideas quickly. A correlated-clustering-based layout algorithm is used to simultaneously generate multiple flow maps with less ambiguity. We also introduce a focus+context timeline to explore huge amounts of temporal data at different levels of time granularity. Quantitative evaluation and case studies demonstrate the accuracy and effectiveness of IdeaFlow.","https://ieeexplore.ieee.org/document/7883511/","LOCKED","7883511","School of Software, Tsinghua University, China","https://ieeexplore.ieee.org/author/37086058835","1","Xiting Wang","37086058835","School of Software, Tsinghua University, China","https://ieeexplore.ieee.org/author/37406039100","2","Shixia Liu","37406039100","School of Software, Tsinghua University, China","https://ieeexplore.ieee.org/author/37086049610","3","Yang Chen","37086049610","Michigan State University, United States of America","https://ieeexplore.ieee.org/author/37086057575","4","Tai-Quan Peng","37086057575","Tsinghua University, China","https://ieeexplore.ieee.org/author/37086047572","5","Jing Su","37086047572","UNCC, United States of America","https://ieeexplore.ieee.org/author/37086058663","6","Jing Yang","37086058663","Microsoft Research, United States of America","https://ieeexplore.ieee.org/author/37275929500","7","Baining Guo","37275929500","19","0","23-28 Oct. 2016","Baltimore, MD","Conferences","10.1109/VAST.2016.7883511","60","https://ieeexplore.ieee.org/document/7883511/","Idea flow","lead-lag","focus+context","correlated clustering","flow map","","","","Lead","Correlation","Time series analysis","Social groups","Social network services","Visual analytics","","7883493","978-1-5090-5662-0","Print on Demand(PoD) ISBN","New-2005","978-1-5090-5662-0","Electronic ISBN","New-2005","978-1-5090-5661-3","https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7883511","23-28 Oct. 2016","7867613","2016 IEEE Conference on Visual Analytics Science and Technology (VAST)","2016","IEEE","2","51","How ideas flow across multiple social groups"
"The DataSpace for HIV vaccine studies is a discovery tool available on the web to hundreds of investigators. We designed it to help them better understand activity in the field and explore new ideas latent in completed research. The DataSpace harmonizes immunoassay results and study metadata so that a broader research community can pursue more flexible discovery than the typical centrally planned analyses. Insights from human-centered design and beta evaluation suggest strong potential for visual analytics that may also apply to other efforts in open science. The contribution of this paper is to elucidate key domain challenges and demonstrate an application that addresses them. We made several changes to familiar visualizations to support key tasks such as identifying and filtering to a cohort of interest, making meaningful comparisons of time series data from multiple studies that have different plans, and preserving analytic context when making data transformations and comparisons that would normally exclude some data.","https://ieeexplore.ieee.org/document/7883509/","LOCKED","7883509","LabKey Software, United States of America","https://ieeexplore.ieee.org/author/37938647900","1","David McColgin","37938647900","LabKey Software, United States of America","https://ieeexplore.ieee.org/author/37086006520","2","Paul Hoover","37086006520","LabKey Software, United States of America","https://ieeexplore.ieee.org/author/37086015221","3","Mark Igra","37086015221","","","","","","","","","","","","","","","","","","","","","1","0","23-28 Oct. 2016","Baltimore, MD","Conferences","10.1109/VAST.2016.7883509","40","https://ieeexplore.ieee.org/document/7883509/","Hypothesis forming","Time series visualization","Visual knowledge discovery","Vaccines","Public health","","","","Vaccines","Human immunodeficiency virus","Immune system","Visual analytics","Data visualization","Timing","Software","7883493","978-1-5090-5662-0","Print on Demand(PoD) ISBN","New-2005","978-1-5090-5662-0","Electronic ISBN","New-2005","978-1-5090-5661-3","https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7883509","23-28 Oct. 2016","7867613","2016 IEEE Conference on Visual Analytics Science and Technology (VAST)","2016","IEEE","3","31","The DataSpace for HIV vaccine studies"
"Public perceptions of a brand is critical to its performance. While social media has demonstrated a huge potential to shape public perceptions of brands, existing tools are not intuitive and explanatory for domain users to use as they fail to provide a comprehensive analysis framework for perceptions of brands. In this paper, we present SocialBrands, a novel visual analysis tool for brand managers to understand public perceptions of brands on social media. Social-Brands leverages brand personality framework in marketing literature and social computing approaches to compute the personality of brands from three driving factors (user imagery, employee imagery, and official announcement) on social media, and construct an evidence network explaining the association between brand personality and driving factors. These computational results are then integrated with new interactive visualizations to help brand managers understand personality traits and their driving factors. We demonstrate the usefulness and effectiveness of SocialBrands through a series of user studies with brand managers in an enterprise context. Design lessons are also derived from our studies.","https://ieeexplore.ieee.org/document/7883513/","LOCKED","7883513","Ohio State University, United States of America","https://ieeexplore.ieee.org/author/37086031835","1","Xiaotong Liu","37086031835","IBM Research, United States of America","https://ieeexplore.ieee.org/author/37086030660","2","Anbang Xu","37086030660","Visa Research, United States of America","https://ieeexplore.ieee.org/author/37075500200","3","Liang Gou","37075500200","IBM Research, United States of America","https://ieeexplore.ieee.org/author/37086038298","4","Haibin Liu","37086038298","IBM Research, United States of America","https://ieeexplore.ieee.org/author/37283362000","5","Rama Akkiraju","37283362000","Ohio State University, United States of America","https://ieeexplore.ieee.org/author/37086034271","6","Han-Wei Shen","37086034271","","","","","","3","0","23-28 Oct. 2016","Baltimore, MD","Conferences","10.1109/VAST.2016.7883513","80","https://ieeexplore.ieee.org/document/7883513/","","","","","","","","","Data visualization","Electronic mail","Companies","Twitter","Visual analytics","","","7883493","978-1-5090-5662-0","Print on Demand(PoD) ISBN","New-2005","978-1-5090-5662-0","Electronic ISBN","New-2005","978-1-5090-5661-3","https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7883513","23-28 Oct. 2016","7867613","2016 IEEE Conference on Visual Analytics Science and Technology (VAST)","2016","IEEE","4","71","SocialBrands: Visual analysis of public perceptions of brands on social media"
"Sensemaking is described as the process in which people collect, organize and create representations of information, all centered around some problem they need to understand. People often get lost when solving complicated tasks using big datasets over long periods of exploration and analysis. They may forget what they have done, are unaware of where they are in the context of the overall task, and are unsure where to continue. In this paper, we introduce a tool, SenseMap, to address these issues in the context of browser-based online sensemaking. We conducted a semi-structured interview with nine participants to explore their behaviors in online sensemaking with existing browser functionality. A simplified sensemaking model based on Pirolli and Card's model is derived to better represent the behaviors we found: users iteratively collect information sources relevant to the task, curate them in a way that makes sense, and finally communicate their findings to others. SenseMap automatically captures provenance of user sensemaking actions and provides multi-linked views to visualize the collected information and enable users to curate and communicate their findings. To explore how SenseMap is used, we conducted a user study in a naturalistic work setting with five participants completing the same sensemaking task related to their daily work activities. All participants found the visual representation and interaction of the tool intuitive to use. Three of them engaged with the tool and produced successful outcomes. It helped them to organize information sources, to quickly find and navigate to the sources they wanted, and to effectively communicate their findings.","https://ieeexplore.ieee.org/document/7883515/","LOCKED","7883515","Middlesex University, London, UK","https://ieeexplore.ieee.org/author/38490354300","1","Phong H. Nguyen","38490354300","Middlesex University, London, UK","https://ieeexplore.ieee.org/author/37273812200","2","Kai Xu","37273812200","Middlesex University, London, UK","https://ieeexplore.ieee.org/author/37422447600","3","Andy Bardill","37422447600","Middlesex University, London, UK","https://ieeexplore.ieee.org/author/37086135817","4","Betul Salman","37086135817","Middlesex University, London, UK","https://ieeexplore.ieee.org/author/37086135749","5","Kate Herd","37086135749","Middlesex University, London, UK","https://ieeexplore.ieee.org/author/37549700100","6","B.L. William Wong","37549700100","","","","","","7","0","23-28 Oct. 2016","Baltimore, MD","Conferences","10.1109/VAST.2016.7883515","100","https://ieeexplore.ieee.org/document/7883515/","Sensemaking","browser-based online sensemaking","analytic provenance","visual analytics","visualization","design study","","","Browsers","History","Interviews","Visualization","Data visualization","Conferences","Web pages","7883493","978-1-5090-5662-0","Print on Demand(PoD) ISBN","New-2005","978-1-5090-5662-0","Electronic ISBN","New-2005","978-1-5090-5661-3","https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7883515","23-28 Oct. 2016","7867613","2016 IEEE Conference on Visual Analytics Science and Technology (VAST)","2016","IEEE","5","91","SenseMap: Supporting browser-based online sensemaking through analytic provenance"
"Aiming at massive participation and open access education, Massive Open Online Courses (MOOCs) have attracted millions of learners over the past few years. However, the high dropout rate of learners is considered to be one of the most crucial factors that may hinder the development of MOOCs. To tackle this problem, statistical models have been developed to predict dropout behavior based on learner activity logs. Although predictive models can foresee the dropout behavior, it is still difficult for users to understand the reasons behind the predicted results and further design interventions to prevent dropout. In addition, with a better understanding of dropout, researchers in the area of predictive modeling in turn can improve the models. In this paper, we introduce DropoutSeer, a visual analytics system which not only helps instructors and education experts understand the reasons for dropout, but also allows researchers to identify crucial features which can further improve the performance of the models. Both the heterogeneous data extracted from three different kinds of learner activity logs (i.e., clickstream, forum posts and assignment records) and the predicted results are visualized in the proposed system. Case studies and expert interviews have been conducted to demonstrate the usefulness and effectiveness of DropoutSeer.","https://ieeexplore.ieee.org/document/7883517/","LOCKED","7883517","Hong Kong University of Science and Technology, China","https://ieeexplore.ieee.org/author/37086092806","1","Yuanzhe Chen","37086092806","Hong Kong University of Science and Technology, China","https://ieeexplore.ieee.org/author/37085471103","2","Qing Chen","37085471103","Hong Kong University of Science and Technology, China","https://ieeexplore.ieee.org/author/37086091957","3","Mingqian Zhao","37086091957","Massachusetts Institute of Technology, United States of America","https://ieeexplore.ieee.org/author/37085638999","4","Sebastien Boyer","37085638999","Massachusetts Institute of Technology, United States of America","https://ieeexplore.ieee.org/author/37085648060","5","Kalyan Veeramachaneni","37085648060","Hong Kong University of Science and Technology, China","https://ieeexplore.ieee.org/author/37272637300","6","Huamin Qu","37272637300","","","","","","15","0","23-28 Oct. 2016","Baltimore, MD","Conferences","10.1109/VAST.2016.7883517","120","https://ieeexplore.ieee.org/document/7883517/","Visualization in education","machine learning","time series data","design studies","","","","","Data visualization","Predictive models","Data models","Feature extraction","Education","Visual analytics","","7883493","978-1-5090-5662-0","Print on Demand(PoD) ISBN","New-2005","978-1-5090-5662-0","Electronic ISBN","New-2005","978-1-5090-5661-3","https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7883517","23-28 Oct. 2016","7867613","2016 IEEE Conference on Visual Analytics Science and Technology (VAST)","2016","IEEE","6","111","DropoutSeer: Visualizing learning patterns in Massive Open Online Courses for dropout reasoning and prediction"
"Sketching allows analysts to specify complex and free-form patterns of interest. Visual query systems can make use of sketches to locate these patterns of interest in large datasets. However, sketching is ambiguous: the same drawing could represent a multitude of potential queries. In this work, we investigate these ambiguities as they apply to visual query systems for time series data. We define a class of “invariants” - the properties of a time series that the analyst wishes to ignore when performing a sketch-based query. We present the results of a crowd-sourced study, showing that these invariants are key components of how people rate the strength of match between sketch and target. We adapt a number of algorithms for time series matching to support invariants in sketches. Lastly, we present a web-deployed prototype sketch-based visual query system that relies on these invariants. We apply the prototype to data from finance, the digital humanities, and political science.","https://ieeexplore.ieee.org/document/7883519/","LOCKED","7883519","University of Washington, United States of America","https://ieeexplore.ieee.org/author/38230607000","1","Michael Correll","38230607000","University of Wisconsin-Madison, United States of America","https://ieeexplore.ieee.org/author/37282585700","2","Michael Gleicher","37282585700","","","","","","","","","","","","","","","","","","","","","","","","","","12","0","23-28 Oct. 2016","Baltimore, MD","Conferences","10.1109/VAST.2016.7883519","140","https://ieeexplore.ieee.org/document/7883519/","","","","","","","","","Visualization","Time series analysis","Prototypes","Shape","Semantics","Algorithm design and analysis","Signal processing algorithms","7883493","978-1-5090-5662-0","Print on Demand(PoD) ISBN","New-2005","978-1-5090-5662-0","Electronic ISBN","New-2005","978-1-5090-5661-3","https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7883519","23-28 Oct. 2016","7867613","2016 IEEE Conference on Visual Analytics Science and Technology (VAST)","2016","IEEE","7","131","The semantics of sketch: Flexibility in visual query systems for time series data"
"We present a design space exploration of interaction techniques for supporting multiple collaborators exploring data on a shared large display. Our proposed solution is based on users controlling individual lenses using both explicit gestures as well as proxemics: the spatial relations between people and physical artifacts such as their distance, orientation, and movement. We discuss different design considerations for implicit and explicit interactions through the lens, and evaluate the user experience to find a balance between the implicit and explicit interaction styles. Our findings indicate that users favor implicit interaction through proxemics for navigation and collaboration, but prefer using explicit mid-air gestures to perform actions that are perceived to be direct, such as terminating a lens composition. Based on these results, we propose a hybrid technique utilizing both proxemics and mid-air gestures, along with examples applying this technique to other datasets. Finally, we performed a usability evaluation of the hybrid technique and observed user performance improvements in the presence of both implicit and explicit interaction styles.","https://ieeexplore.ieee.org/document/7883506/","LOCKED","7883506","University of Maryland, College Park, USA","https://ieeexplore.ieee.org/author/37085388100","1","Sriram Karthik Badam","37085388100","University of Manitoba, Winnipeg, Canada","https://ieeexplore.ieee.org/author/37701811900","2","Fereshteh Amini","37701811900","University of Maryland, College Park, USA","https://ieeexplore.ieee.org/author/37295438200","3","Niklas Elmqvist","37295438200","University of Manitoba, Winnipeg, Canada","https://ieeexplore.ieee.org/author/37283481700","4","Pourang Irani","37283481700","","","","","","","","","","","","","","","","6","0","23-28 Oct. 2016","Baltimore, MD","Conferences","10.1109/VAST.2016.7883506","10","https://ieeexplore.ieee.org/document/7883506/","Proxemics","gestures","visual exploration","collaborative sensemaking","user study","large displays","orientation","position","Visualization","Lenses","Collaboration","Navigation","Aerospace electronics","Computers","Mice","7883493","978-1-5090-5662-0","Print on Demand(PoD) ISBN","New-2005","978-1-5090-5662-0","Electronic ISBN","New-2005","978-1-5090-5661-3","https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7883506","23-28 Oct. 2016","7867613","2016 IEEE Conference on Visual Analytics Science and Technology (VAST)","2016","IEEE","8","1","Supporting visual exploration for multiple users in large display environments"
"Popular social media platforms could rapidly propagate vital information over social networks among a significant number of people. In this work we present D-Map (Diffusion Map), a novel visualization method to support exploration and analysis of social behaviors during such information diffusion and propagation on typical social media through a map metaphor. In D-Map, users who participated in reposting (i.e., resending a message initially posted by others) one central user's posts (i.e., a series of original tweets) are collected and mapped to a hexagonal grid based on their behavior similarities and in chronological order of the repostings. With additional interaction and linking, D-Map is capable of providing visual portraits of the influential users and describing their social behaviors. A comprehensive visual analysis system is developed to support interactive exploration with D-Map. We evaluate our work with real world social media data and find interesting patterns among users. Key players, important information diffusion paths, and interactions among social communities can be identified.","https://ieeexplore.ieee.org/document/7883510/","LOCKED","7883510","Key Laboratory of Machine Perception (Ministry of Education), Peking University, China","https://ieeexplore.ieee.org/author/37085387892","1","Siming Chen","37085387892","Key Laboratory of Machine Perception (Ministry of Education), Peking University, China","https://ieeexplore.ieee.org/author/37086146756","2","Shuai Chen","37086146756","Key Laboratory of Machine Perception (Ministry of Education), Peking University, China","https://ieeexplore.ieee.org/author/37085375437","3","Zhenhuang Wang","37085375437","Faculty of Engineer and Information Technology, The University of Technology, Sydney, Australia","https://ieeexplore.ieee.org/author/37085343774","4","Jie Liang","37085343774","Key Laboratory of Machine Perception (Ministry of Education), Peking University, China","https://ieeexplore.ieee.org/author/37403856700","5","Xiaoru Yuan","37403856700","New York University, Shanghai, China","https://ieeexplore.ieee.org/author/37085734033","6","Nan Cao","37085734033","Southwest University of Science and Technology, China","https://ieeexplore.ieee.org/author/37086142212","7","Yadong Wu","37086142212","22","0","23-28 Oct. 2016","Baltimore, MD, USA","Conferences","10.1109/VAST.2016.7883510","50","https://ieeexplore.ieee.org/document/7883510/","Social Media","Map","Information Diffusion","","","","","","Data visualization","Diffusion processes","Visualization","Twitter","Clutter","Radar","","7883493","978-1-5090-5662-0","Print on Demand(PoD) ISBN","New-2005","978-1-5090-5662-0","Electronic ISBN","New-2005","978-1-5090-5661-3","https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7883510","23-28 Oct. 2016","7867613","2016 IEEE Conference on Visual Analytics Science and Technology (VAST)","2016","IEEE","9","41","D-Map: Visual analysis of ego-centric information diffusion patterns in social media"
"We present a medical crowdsourcing visual analytics platform called C2A to visualize, classify and filter crowdsourced clinical data. More specifically, C2A is used to build consensus on a clinical diagnosis by visualizing crowd responses and filtering out anomalous activity. Crowdsourcing medical applications have recently shown promise where the non-expert users (the crowd) were able to achieve accuracy similar to the medical experts. This has the potential to reduce interpretation/reading time and possibly improve accuracy by building a consensus on the findings beforehand and letting the medical experts make the final diagnosis. In this paper, we focus on a virtual colonoscopy (VC) application with the clinical technicians as our target users, and the radiologists acting as consultants and classifying segments as benign or malignant. In particular, C2A is used to analyze and explore crowd responses on video segments, created from fly-throughs in the virtual colon. C2A provides several interactive visualization components to build crowd consensus on video segments, to detect anomalies in the crowd data and in the VC video segments, and finally, to improve the non-expert user's work quality and performance by A/B testing for the optimal crowdsourcing platform and application-specific parameters. Case studies and domain experts feedback demonstrate the effectiveness of our framework in improving workers' output quality, the potential to reduce the radiologists' interpretation time, and hence, the potential to improve the traditional clinical workflow by marking the majority of the video segments as benign based on the crowd consensus.","https://ieeexplore.ieee.org/document/7883508/","LOCKED","7883508","Stony Brook University, United States of America","https://ieeexplore.ieee.org/author/37085387879","1","Ji Hwan Park","37085387879","Stony Brook University, United States of America","https://ieeexplore.ieee.org/author/37085891693","2","Saad Nadeem","37085891693","Stony Brook University, United States of America","https://ieeexplore.ieee.org/author/37085396011","3","Seyedkoosha Mirhosseini","37085396011","Stony Brook University, United States of America","https://ieeexplore.ieee.org/author/37268052800","4","Arie Kaufman","37268052800","","","","","","","","","","","","","","","","1","0","23-28 Oct. 2016","Baltimore, MD","Conferences","10.1109/VAST.2016.7883508","30","https://ieeexplore.ieee.org/document/7883508/","Crowdsourcing","virtual colonoscopy","visual analytics","biomedical applications","","","","","Crowdsourcing","Colon","Visual analytics","Hospitals","Virtual colonoscopy","Medical diagnostic imaging","","7883493","978-1-5090-5662-0","Print on Demand(PoD) ISBN","New-2005","978-1-5090-5662-0","Electronic ISBN","New-2005","978-1-5090-5661-3","https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7883508","23-28 Oct. 2016","7867613","2016 IEEE Conference on Visual Analytics Science and Technology (VAST)","2016","IEEE","10","21","C2A: Crowd consensus analytics for virtual colonoscopy"
"Recommender systems are being widely used to assist people in making decisions, for example, recommending films to watch or books to buy. Despite its ubiquity, the problem of presenting the recommendations of temporal event sequences has not been studied. We propose EventAction, which to our knowledge, is the first attempt at a prescriptive analytics interface designed to present and explain recommendations of temporal event sequences. EventAction provides a visual analytics approach to (1) identify similar records, (2) explore potential outcomes, (3) review recommended temporal event sequences that might help achieve the users' goals, and (4) interactively assist users as they define a personalized action plan associated with a probability of success. Following the design study framework, we designed and deployed EventAction in the context of student advising and reported on the evaluation with a student review manager and three graduate students.","https://ieeexplore.ieee.org/document/7883512/","LOCKED","7883512","University of Maryland, United States of America","https://ieeexplore.ieee.org/author/37085829363","1","Fan Du","37085829363","University of Maryland, United States of America","https://ieeexplore.ieee.org/author/37283026800","2","Catherine Plaisant","37283026800","University of Maryland, United States of America","https://ieeexplore.ieee.org/author/37322104700","3","Neil Spring","37322104700","University of Maryland, United States of America","https://ieeexplore.ieee.org/author/37283016400","4","Ben Shneiderman","37283016400","","","","","","","","","","","","","","","","26","0","23-28 Oct. 2016","Baltimore, MD","Conferences","10.1109/VAST.2016.7883512","70","https://ieeexplore.ieee.org/document/7883512/","Temporal event sequences","recommender systems","prescriptive analytics","visual analytics","","","","","Recommender systems","Visual analytics","Medical services","History","Timing","Prototypes","","7883493","978-1-5090-5662-0","Print on Demand(PoD) ISBN","New-2005","978-1-5090-5662-0","Electronic ISBN","New-2005","978-1-5090-5661-3","https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7883512","23-28 Oct. 2016","7867613","2016 IEEE Conference on Visual Analytics Science and Technology (VAST)","2016","IEEE","11","61","EventAction: Visual analytics for temporal event sequence recommendation"
"Exploring multi-dimensional datasets can be cumbersome if data analysts have little knowledge about the data. Various dimension relation inspection tools and dimension exploration tools have been proposed for efficient data examining and understanding. However, the needed workload varies largely with respect to data complexity and user expertise, which can only be reduced with rich background knowledge over the data. In this paper we address the workload challenge with a data structuring and exploration scheme that affords dimension relation detection and that serves as the background knowledge for further investigation. We contribute a novel data structuring scheme that leverages an information-theoretic view structuring algorithm to uncover information-aware relations among different data views, and thereby discloses redundancy and other relation patterns among dimensions. The integrated system, DimScanner, empowers analysts with rich user controls and assistance widgets to interactively detect the relations of multi-dimensional data.","https://ieeexplore.ieee.org/document/7883514/","LOCKED","7883514","State Key Lab of CAD&CG, Zhejiang University, China","https://ieeexplore.ieee.org/author/37085405113","1","Jing Xia","37085405113","State Key Lab of CAD&CG, Zhejiang University, China","https://ieeexplore.ieee.org/author/37291847800","2","Wei Chen","37291847800","State Key Lab of CAD&CG, Zhejiang University, China","https://ieeexplore.ieee.org/author/37086043190","3","Yumeng Hou","37086043190","State Key Lab of CAD&CG, Zhejiang University, China","https://ieeexplore.ieee.org/author/37085880497","4","Wanqi Hu","37085880497","State Key Lab of CAD&CG, Zhejiang University, China","https://ieeexplore.ieee.org/author/37085386143","5","Xinxin Huang","37085386143","Purdue University, United States of America","","6","David S. Ebertk","","","","","","","4","0","23-28 Oct. 2016","Baltimore, MD","Conferences","10.1109/VAST.2016.7883514","90","https://ieeexplore.ieee.org/document/7883514/","High-dimensional data visualization","information-aware relation","data exploration","","","","","","Data visualization","Measurement","Two dimensional displays","Correlation","Layout","Visualization","Inspection","7883493","978-1-5090-5662-0","Print on Demand(PoD) ISBN","New-2005","978-1-5090-5662-0","Electronic ISBN","New-2005","978-1-5090-5661-3","https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7883514","23-28 Oct. 2016","7867613","2016 IEEE Conference on Visual Analytics Science and Technology (VAST)","2016","IEEE","12","81","DimScanner: A relation-based visual exploration approach towards data dimension inspection"
"In this paper we present PorosityAnalyzer, a novel tool for detailed evaluation and visual analysis of pore segmentation pipelines to determine the porosity in fiber-reinforced polymers (FRPs). The presented tool consists of two modules: the computation module and the analysis module. The computation module enables a convenient setup and execution of distributed off-line-computations on industrial 3D X-ray computed tomography datasets. It allows the user to assemble individual segmentation pipelines in the form of single pipeline steps, and to specify the parameter ranges as well as the sampling of the parameter-space of each pipeline segment. The result of a single segmentation run consists of the input parameters, the calculated 3D binary-segmentation mask, the resulting porosity value, and other derived results (e.g., segmentation pipeline run-time). The analysis module presents the data at different levels of detail by drill-down filtering in order to determine accurate and robust segmentation pipelines. Overview visualizations allow to initially compare and evaluate the segmentation pipelines. With a scatter plot matrix (SPLOM), the segmentation pipelines are examined in more detail based on their input and output parameters. Individual segmentation-pipeline runs are selected in the SPLOM and visually examined and compared in 2D slice views and 3D renderings by using aggregated segmentation masks and statistical contour renderings. PorosityAnalyzer has been thoroughly evaluated with the help of twelve domain experts. Two case studies demonstrate the applicability of our proposed concepts and visualization techniques, and show that our tool helps domain experts to gain new insights and improve their workflow efficiency.","https://ieeexplore.ieee.org/document/7883516/","LOCKED","7883516","University of Applied Sciences, Upper Austria, Wels, Austria","https://ieeexplore.ieee.org/author/37086017815","1","Johannes Weissenböck","37086017815","University of Applied Sciences, Upper Austria, Wels, Austria","https://ieeexplore.ieee.org/author/37590979900","2","Artem Amirkhanov","37590979900","TU Wien, Vienna, Austria","https://ieeexplore.ieee.org/author/37284271200","3","Eduard Gröller","37284271200","University of Applied Sciences, Upper Austria, Wels, Austria","https://ieeexplore.ieee.org/author/37947609000","4","Johann Kastner","37947609000","University of Applied Sciences, Upper Austria, Wels, Austria","https://ieeexplore.ieee.org/author/37400391300","5","Christoph Heinzl","37400391300","","","","","","","","","","","6","0","23-28 Oct. 2016","Baltimore, MD","Conferences","10.1109/VAST.2016.7883516","110","https://ieeexplore.ieee.org/document/7883516/","I.3.6 [Computer Graphics]: Methodology and Techniques—Interaction techniques","","","","","","","","Pipelines","Visualization","Data visualization","Image segmentation","Three-dimensional displays","Electronic mail","Analytical models","7883493","978-1-5090-5662-0","Print on Demand(PoD) ISBN","New-2005","978-1-5090-5662-0","Electronic ISBN","New-2005","978-1-5090-5661-3","https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7883516","23-28 Oct. 2016","7867613","2016 IEEE Conference on Visual Analytics Science and Technology (VAST)","2016","IEEE","13","101","PorosityAnalyzer: Visual analysis and evaluation of segmentation pipelines to determine the porosity in fiber-reinforced polymers"
"Investigating user behavior involves abstracting low-level events to higher-level concepts. This requires an analyst to study individual user activities, assign codes which categorize behavior, and develop a consistent classification scheme. To better support this reasoning process of an analyst, we suggest a novel visual analytics approach which integrates rich user data including transcripts, videos, eye movement data, and interaction logs. Word-sized visualizations embedded into a tabular representation provide a space-efficient and detailed overview of user activities. An analyst assigns codes, grouped into code categories, as part of an interactive process. Filtering and searching helps to select specific activities and focus an analysis. A comparison visualization summarizes results of coding and reveals relationships between codes. Editing features support efficient assignment, refinement, and aggregation of codes. We demonstrate the practical applicability and usefulness of our approach in a case study and describe expert feedback.","https://ieeexplore.ieee.org/document/7883520/","LOCKED","7883520","University of Stuttgart, Germany","https://ieeexplore.ieee.org/author/37085671312","1","Tanja Blascheck","37085671312","University of Stuttgart, Germany","https://ieeexplore.ieee.org/author/37586060300","2","Fabian Beck","37586060300","University of Trier, Germany","https://ieeexplore.ieee.org/author/37085486113","3","Sebastian Baltes","37085486113","University of Stuttgart, Germany","https://ieeexplore.ieee.org/author/37268023800","4","Thomas Ertl","37268023800","University of Stuttgart, Germany","https://ieeexplore.ieee.org/author/37268045000","5","Daniel Weiskopf","37268045000","","","","","","","","","","","7","0","23-28 Oct. 2016","Baltimore, MD","Conferences","10.1109/VAST.2016.7883520","150","https://ieeexplore.ieee.org/document/7883520/","I.3.6 [Methodology and Techniques]: Interaction techniques—","H.5.2 [User Interfaces]: Evaluation/Methodology—","","","","","","","Encoding","Data visualization","Cognition","Visual analytics","Tag clouds","","","7883493","978-1-5090-5662-0","Print on Demand(PoD) ISBN","New-2005","978-1-5090-5662-0","Electronic ISBN","New-2005","978-1-5090-5661-3","https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7883520","23-28 Oct. 2016","7867613","2016 IEEE Conference on Visual Analytics Science and Technology (VAST)","2016","IEEE","14","141","Visual analysis and coding of data-rich user behavior"
"Long time-series, involving thousands or even millions of time steps, are common in many application domains but remain very difficult to explore interactively. Often the analytical task in such data is to identify specific patterns, but this is a very complex and computationally difficult problem and so focusing the search in order to only identify interesting patterns is a common solution. We propose an efficient method for exploring user-sketched patterns, incorporating the domain expert's knowledge, in time series data through a shape grammar based approach. The shape grammar is extracted from the time series by considering the data as a combination of basic elementary shapes positioned across different amplitudes. We represent these basic shapes using a ratio value, perform binning on ratio values and apply a symbolic approximation. Our proposed method for pattern matching is amplitude-, scale- and translation-invariant and, since the pattern search and pattern constraint relaxation happen at the symbolic level, is very efficient permitting its use in a real-time/online system. We demonstrate the effectiveness of our method in a case study on stock market data although it is applicable to any numeric time series data.","https://ieeexplore.ieee.org/document/7883518/","LOCKED","7883518","Linköping University, Sweden","https://ieeexplore.ieee.org/author/37086071126","1","Prithiviraj K. Muthumanickam","37086071126","Linköping University, Sweden","https://ieeexplore.ieee.org/author/37939017400","2","Katerina Vrotsou","37939017400","Linköping University, Sweden","https://ieeexplore.ieee.org/author/37268765000","3","Matthew Cooper","37268765000","Linköping University, Sweden","https://ieeexplore.ieee.org/author/37273045500","4","Jimmy Johansson","37273045500","","","","","","","","","","","","","","","","2","0","23-28 Oct. 2016","Baltimore, MD","Conferences","10.1109/VAST.2016.7883518","130","https://ieeexplore.ieee.org/document/7883518/","User-queries","Sketching","Time Series","Symbolic approximation","Regular Expression","Shape Grammar","","","Time series analysis","Shape","Grammar","Pattern matching","Search problems","Approximation algorithms","Market research","7883493","978-1-5090-5662-0","Print on Demand(PoD) ISBN","New-2005","978-1-5090-5662-0","Electronic ISBN","New-2005","978-1-5090-5661-3","https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7883518","23-28 Oct. 2016","7867613","2016 IEEE Conference on Visual Analytics Science and Technology (VAST)","2016","IEEE","15","121","Shape grammar extraction for efficient query-by-sketch pattern matching in long time series"
"Provides a listing of current committee members and society officers.","https://ieeexplore.ieee.org/document/7883498/","EPHEMERA","7883498","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","0","0","23-28 Oct. 2016","Baltimore, MD","Conferences","10.1109/VAST.2016.7883498","vi","","","","","","","","","","","","","","","","","7883493","978-1-5090-5662-0","Print on Demand(PoD) ISBN","New-2005","978-1-5090-5662-0","Electronic ISBN","New-2005","978-1-5090-5661-3","https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7883498","23-28 Oct. 2016","7867613","2016 IEEE Conference on Visual Analytics Science and Technology (VAST)","2016","IEEE","16","vi","IEEE Visualization and Graphics Technical Committee (VGTC)"
"The IEEE Visual Analytics Science and Technology (VAST) Conference is now in its eleventh year, and its seventh year as an IEEE Conference. It remains the primary venue for the rapidly growing feld of visual analytics. Visual analytics is the science of analytical reasoning supported by highly interactive visual interfaces, and seeks to integrate computational analytics with human cognitive processes. Visual analytics requires interdisciplinary science, going beyond traditional visualization to include statistics, mathematics, knowledge representation, management and discovery technologies, cognitive and perceptual sciences, decision sciences, and more.","https://ieeexplore.ieee.org/document/7883497/","EPHEMERA","7883497","Fraunhofer IAIS & City University London, United Kingdom","","1","Gennady Andrienko","","Tsinghua University, China","","2","Shixia Liu","","Georgia Institute of Technology, United States of America","","3","John Stasko","","","","","","","","","","","","","","","","","","","","","","0","0","23-28 Oct. 2016","Baltimore, MD","Conferences","10.1109/VAST.2016.7883497","v","","","","","","","","","","","","","","","","","7883493","978-1-5090-5662-0","Print on Demand(PoD) ISBN","New-2005","978-1-5090-5662-0","Electronic ISBN","New-2005","978-1-5090-5661-3","https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7883497","23-28 Oct. 2016","7867613","2016 IEEE Conference on Visual Analytics Science and Technology (VAST)","2016","IEEE","17","v","Preface"
"Provides a listing of current committee members and society officers.","https://ieeexplore.ieee.org/document/7883500/","EPHEMERA","7883500","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","0","0","23-28 Oct. 2016","Baltimore, MD","Conferences","10.1109/VAST.2016.7883500","viii","","","","","","","","","","","","","","","","","7883493","978-1-5090-5662-0","Print on Demand(PoD) ISBN","New-2005","978-1-5090-5662-0","Electronic ISBN","New-2005","978-1-5090-5661-3","https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7883500","23-28 Oct. 2016","7867613","2016 IEEE Conference on Visual Analytics Science and Technology (VAST)","2016","IEEE","18","viii","VAST international program committee"
"Provides a listing of current committee members and society officers.","https://ieeexplore.ieee.org/document/7883499/","EPHEMERA","7883499","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","0","0","23-28 Oct. 2016","Baltimore, MD","Conferences","10.1109/VAST.2016.7883499","vii","","","","","","","","","","","","","","","","","7883493","978-1-5090-5662-0","Print on Demand(PoD) ISBN","New-2005","978-1-5090-5662-0","Electronic ISBN","New-2005","978-1-5090-5661-3","https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7883499","23-28 Oct. 2016","7867613","2016 IEEE Conference on Visual Analytics Science and Technology (VAST)","2016","IEEE","19","vii","VIS conference committee"
"Presents the title page of the proceedings record.","","EPHEMERA","7883494","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","0","0","23-28 Oct. 2016","Baltimore, MD","Conferences","10.1109/VAST.2016.7883494","i","","","","","","","","","","","","","","","","","7883493","978-1-5090-5662-0","Print on Demand(PoD) ISBN","New-2005","978-1-5090-5662-0","Electronic ISBN","New-2005","978-1-5090-5661-3","https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7883494","23-28 Oct. 2016","7867613","2016 IEEE Conference on Visual Analytics Science and Technology (VAST)","2016","IEEE","20","i","[Title page]"
"The following topics are dealt with: biomedical visualization; social media; data visual and algorithmic analysis; visual knowledge discovery; sense-making; time-series data; education and computer games.","","EPHEMERA","7883496","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","0","0","23-28 Oct. 2016","Baltimore, MD","Conferences","10.1109/VAST.2016.7883496","iv","","","","","","","","","","","","","","","","","7883493","978-1-5090-5662-0","Print on Demand(PoD) ISBN","New-2005","978-1-5090-5662-0","Electronic ISBN","New-2005","978-1-5090-5661-3","https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7883496","23-28 Oct. 2016","7867613","2016 IEEE Conference on Visual Analytics Science and Technology (VAST)","2016","IEEE","21","iii","Table of contents"
"The publication offers a note of thanks and lists its reviewers.","","EPHEMERA","7883501","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","0","0","23-28 Oct. 2016","Baltimore, MD","Conferences","10.1109/VAST.2016.7883501","ix","","","","","","","","","","","","","","","","","7883493","978-1-5090-5662-0","Print on Demand(PoD) ISBN","New-2005","978-1-5090-5662-0","Electronic ISBN","New-2005","978-1-5090-5661-3","https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7883501","23-28 Oct. 2016","7867613","2016 IEEE Conference on Visual Analytics Science and Technology (VAST)","2016","IEEE","22","ix","VAST paper reviewers"
"Useful as each of them can be, a large body of tips and tricks is impossible to remember, at least in a practical, usable way, unless it is structured into a balanced, meaningful hierarchy. This talk proposes and illustrates three simple yet solid ideas that lead to more effective communication and that underpin every other guideline: easy to remember, readily applicable, and always relevant—in short, valuable for the rest of your life.","","EPHEMERA","7883505","Louvain, Belgium","","1","Jean-luc Doumont","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","0","0","23-28 Oct. 2016","Baltimore, MD","Conferences","10.1109/VAST.2016.7883505","xiii","","","","","","","","","","","","","","","","","7883493","978-1-5090-5662-0","Print on Demand(PoD) ISBN","New-2005","978-1-5090-5662-0","Electronic ISBN","New-2005","978-1-5090-5661-3","https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7883505","23-28 Oct. 2016","7867613","2016 IEEE Conference on Visual Analytics Science and Technology (VAST)","2016","IEEE","23","xiii","VIS capstone address"
"Presents the copyright information for the conference. May include reprint permission information.","","EPHEMERA","7883495","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","0","0","23-28 Oct. 2016","Baltimore, MD","Conferences","10.1109/VAST.2016.7883495","ii","","","","","","","","","","","","","","","","","7883493","978-1-5090-5662-0","Print on Demand(PoD) ISBN","New-2005","978-1-5090-5662-0","Electronic ISBN","New-2005","978-1-5090-5661-3","https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7883495","23-28 Oct. 2016","7867613","2016 IEEE Conference on Visual Analytics Science and Technology (VAST)","2016","IEEE","24","ii","[Copyright notice]"
"Recent theories of the wealth and poverty of nations put the accent on the accumulation of collective know how. The fundamental difference between rich and poor countries is not in the average level of individual skills of their citizens but in the kinds of things that can be done collectively. This creates an important visualization problem: how to measure and represent the differential levels of collective know how between countries and regions? How to visualize its evolution in time? How to identify more feasible and effective paths for progress? How can visualization help orient the efforts of the public and private sectors in enhancing progress?","","EPHEMERA","7883504","Center for International Development, Harvard University, United States of America","","1","Ricardo Hausmann","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","0","0","23-28 Oct. 2016","Baltimore, MD","Conferences","10.1109/VAST.2016.7883504","xii","","","","","","","","","","","","","","","","","7883493","978-1-5090-5662-0","Print on Demand(PoD) ISBN","New-2005","978-1-5090-5662-0","Electronic ISBN","New-2005","978-1-5090-5661-3","https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7883504","23-28 Oct. 2016","7867613","2016 IEEE Conference on Visual Analytics Science and Technology (VAST)","2016","IEEE","25","xii","VIS keynote address"
"The 2016 Visualization Technical Achievement Award goes to David Ebert in recognition of foundational work in visual analytics, both through development of fundamental predictive techniques and as Director of the Purdue/DHS Visual Analytics Center of Excellence.","","EPHEMERA","7883503","Purdue University, United States of America","","1","David Ebert","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","0","0","23-28 Oct. 2016","Baltimore, MD","Conferences","10.1109/VAST.2016.7883503","xi","","","","","","","","","","","","","","","","","7883493","978-1-5090-5662-0","Print on Demand(PoD) ISBN","New-2005","978-1-5090-5662-0","Electronic ISBN","New-2005","978-1-5090-5661-3","https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7883503","23-28 Oct. 2016","7867613","2016 IEEE Conference on Visual Analytics Science and Technology (VAST)","2016","IEEE","26","xi","The 2016 Visualization Technical Achievement Award"
"The 2016 Visualization Career Award goes to John Dill in recognition of major industrial and academic research advances spanning CAE/CAD, HCI, and data visualization as well as organizational leadership that helped develop the field of visual analytics.","","EPHEMERA","7883502","Simon Fraser University, Canada","","1","John Dill","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","0","0","23-28 Oct. 2016","Baltimore, MD","Conferences","10.1109/VAST.2016.7883502","x","","","","","","","","","","","","","","","","","7883493","978-1-5090-5662-0","Print on Demand(PoD) ISBN","New-2005","978-1-5090-5662-0","Electronic ISBN","New-2005","978-1-5090-5661-3","https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7883502","23-28 Oct. 2016","7867613","2016 IEEE Conference on Visual Analytics Science and Technology (VAST)","2016","IEEE","27","x","The 2016 Visualization Career Award"
