Conference,Year,Title,DOI,Link,FirstPage,LastPage,PaperType,Abstract,AuthorNames-Deduped,AuthorNames,AuthorAffiliation,InternalReferences,AuthorKeywords,AminerCitationCount,CitationCount_CrossRef,PubsCited,Award
Vis-conf,2001,An immersive virtual environment for DT-MRI volume visualization applications: a case study,10.1109/VISUAL.2001.964545,https://doi.org/10.1109/VISUAL.2001.964545,437,584,Conferences,"We describe a virtual reality environment for visualizing tensor-valued volumetric datasets acquired with diffusion tensor magnetic resonance imaging (DT-MRI). We have prototyped a virtual environment that displays geometric representations of the volumetric second-order diffusion tensor data and are developing interaction and visualization techniques for two application areas: studying changes in white-matter structures after gamma-knife capsulotomy and pre-operative planning for brain tumor surgery. Our feedback shows that compared to desktop displays, our system helps the user better interpret the large and complex geometric models, and facilitates communication among a group of users.",,S. Zhang;C. Demiralp;D.F. Keefe;M. DaSilva;D.H. Laidlaw;B.D. Greenberg;P.J. Basser;C. Pierpaoli;E.A. Chiocca;T.S. Deisboeck,"Brown University, USA;Brown University, USA;Brown University, USA;Brown University, USA;Brown University, USA;Brown University, USA;National Institutes of Health DHHS, USA;National Institutes of Health DHHS, USA;Massachusetts General Hospital, USA;Massachusetts General Hospital, USA",,,,42,,
Vis-conf,2001,"Archaeological data visualization in VR: analysis of lamp finds at the Great Temple of Petra, a case study",10.1109/VISUAL.2001.964560,https://doi.org/10.1109/VISUAL.2001.964560,493,597,Conferences,"Presents the results of an evaluation of the ARCHAVE (ARCHAeological Virtual Environment) system, an immersive virtual reality (VR) environment for archaeological research. ARCHAVE is implemented in a Cave. The evaluation studied researchers analyzing lamp and coin finds throughout the excavation trenches at the Petra Great Temple site in Jordan. Experienced archaeologists used our system to study excavation data, confirming existing hypotheses and postulating new theories they had not been able to discover without the system. ARCHAVE provided access to the excavation database, and researchers were able to examine the data in the context of a life-size representation of the present-day architectural ruins of the temple. They also had access to a miniature model for site-wide analysis. Because users quickly became comfortable with the interface, they concentrated their efforts on examining the data being retrieved and displayed. The immersive VR visualization of the recovered information gave them the opportunity to explore it in a new and dynamic way and, in several cases, enabled them to make discoveries that opened new lines of investigation about the excavation.",,D. Acevedo;E. Vote;D.H. Laidlaw;M.S. Joukowsky,"Department of Computer Science, Brown University, Providence, RI;Department of Computer Science, Brown University, Providence, RI;Department of Computer Science, Brown University, Providence, RI;Department of Anthropology, Brown University",,,,26,,
Vis-conf,2001,Virtual temporal bone dissection: a case study,10.1109/VISUAL.2001.964561,https://doi.org/10.1109/VISUAL.2001.964561,497,598,Conferences,"The Temporal Bone Dissection Simulator is an ongoing research project for the construction of a synthetic environment suitable for virtual dissection of human temporal bone and related anatomy. Funded by the National Institute on Deafness and Other Communication Disorders (NIDCD), the primary goal of this project is to provide a safe, robust, and cost-effective virtual environment for learning the anatomy and surgical procedures associated with the temporal bone. Direct volume visualization has been indispensable for the necessary level of realism and interactivity that is vital to the success of this project. This work is being conducted by the Ohio Supercomputer Center in conjunction with the Department of Otolaryngology at the Ohio State University, and NIDCD.",,J. Bryan;D. Stredney;G. Wiet;D. Sessanna,"Department of Computer and Information Science, The Ohio State University;Ohio Supercomputer Center;Department of Otolaryngology, The Ohio State University;Ohio Supercomputer Center",,,,25,,
Vis-conf,2001,Salient iso-surface detection with model-independent statistical signatures,10.1109/VISUAL.2001.964516,https://doi.org/10.1109/VISUAL.2001.964516,231,238,Conferences,"Volume graphics has not been accepted for widespread use. One of the inhibiting reasons is the lack of general methods for data-analysis and simple interfaces for data exploration. An error-and-trial iterative procedure is often used to select a desirable transfer function or mine the dataset for salient iso-values. New semi-automatic methods that are also data-centric have shown much promise. However, general and robust methods are still needed for data-exploration and analysis. In this paper, we propose general model-independent statistical methods based on central moments of data. Using these techniques we show how salient iso-surfaces at material boundaries can be determined. We provide examples from the medical and computational domain to demonstrate the effectiveness of our methods.",,S. Tenginakai;Jinho Lee;R. Machiraju,"Computer and Information Science, Ohio State Uinversity, USA;Computer and Information Science, Ohio State Uinversity, USA;Computer and Information Science, Ohio State Uinversity, USA",,,,24,,
Vis-conf,2001,Visualizing 2D probability distributions from EOS satellite image-derived data sets: a case study,10.1109/VISUAL.2001.964550,https://doi.org/10.1109/VISUAL.2001.964550,457,589,Conferences,"Maps of biophysical and geophysical variables using Earth Observing System (EOS) satellite image data are an important component of Earth science. These maps have a single value derived at every grid cell and standard techniques are used to visualize them. Current tools fall short, however, when it is necessary to describe a distribution of values at each grid cell. Distributions may represent a frequency of occurrence over time, frequency of occurrence from multiple runs of an ensemble forecast or possible values from an uncertainty model. We identify these ""distribution data sets"" and present a case study to visualize such 2D distributions. Distribution data sets are different from multivariate data sets in the sense that the values are for a single variable instead of multiple variables. Data for this case study consists of multiple realizations of percent forest cover, generated using a geostatistical technique that combines ground measurements and satellite imagery to model uncertainty about forest cover. We present two general approaches for analyzing and visualizing such data sets. The first is a pixel-wise analysis of the probability density functions for the 2D image while the second is an analysis of features identified within the image. Such pixel-wise and feature-wise views will give Earth scientists a more complete understanding of distribution data sets. See www.cse.ucsc.edu/research/avis/nasa is for additional information.",,D. Kao;J.L. Dungan;A. Pang,"Ames Research Center, NASA, USA;Ames Research Center, NASA, USA;Computer Science Department, University of California, Santa Cruz, USA",,,,21,,
Vis-conf,2001,Computed tomography angiography: a case study of peripheral vessel investigation,10.1109/VISUAL.2001.964555,https://doi.org/10.1109/VISUAL.2001.964555,477,593,Conferences,This paper deals with vessel exploration based on computed tomography angiography. Large image sequences of the lower extremities are investigated in a clinical environment. Two different approaches for peripheral vessel diagnosis dealing with stenosis and calcification detection are introduced. The paper presents an automated vessel-tracking tool for curved planar reformation. An interactive segmentation tool for bone removal is proposed.,,A. Kanitsar;D. Fleischmann;R. Wegenkittl;D. Sandner;P. Felkel;E. Groller,"Institute of Computer Graphics and Algorithms, University of Technology, Vienna, Austria;TIANI Medgraph, Austria;VRVis Center Vienna, Austria;Department of Radiology, University of Technology, Vienna, Austria;Department of Radiology, University of Technology, Vienna, Austria;Institute of Computer Graphics and Algorithms, University of Technology, Vienna, Austria",,,,19,,
Vis-conf,2001,4D space-time techniques: a medical imaging case study,10.1109/VISUAL.2001.964554,https://doi.org/10.1109/VISUAL.2001.964554,473,592,Conferences,"We present the problem of visualizing time-varying medical data. Two medical imaging modalities are compared-MRI and dynamic SPECT. For each modality, we examine several derived scalar and vector quantities such as the change in intensity over time, the spatial gradient, and the change of the gradient over time. We compare several methods for presenting the data, including isosurfaces, direct volume rendering, and vector visualization using glyphs. These techniques may provide more information and context than methods currently used in practice; thus it is easier to discover temporal changes and abnormalities in a data set.",,M. Tory;N. Rober;T. Moller;A. Celler;M.S. Atkins,"School Of Computing Science, Simon Fraser University, Canada;School Of Computer Science, Otto-von-Guericke University of Magdeburg, Germany;School Of Computing Science, Simon Fraser University, Canada;Nuclear Medicine, Vancouver Hospital and Health Sciences Center, Canada;School Of Computing Science, Simon Fraser University",,,,10,,
Vis-conf,2001,The perspective shear-warp algorithm in a virtual environment,10.1109/VISUAL.2001.964513,https://doi.org/10.1109/VISUAL.2001.964513,207,213,Conferences,"Since the original paper of Lacroute and Levoy (1994), where the shear-warp factorization was also shown for perspective projections, a lot of work has been carried out using the shear-warp factorization with parallel projections. However, none of it has proved or improved the algorithm for the perspective projection. Also in Lacroute's Volpack library, the perspective shear-warp volume rendering algorithm is missing. This paper reports on an implementation of the perspective shear-warp algorithm, which includes enhancements for its application in immersive virtual environments. Furthermore, a mathematical proof for the correctness of the permutation of projection and warp is provided, so far a basic assumption of the shear-warp perspective projection.",,R.P. Schulze;R. Niemeier;U. Lang,"High Performance Computing Center Stuttgart (HLRS), Stuttgart, Germany;Science computing ag, Tubingen, Germany;High Performance Computing Center Stuttgart (HLRS), Stuttgart, Germany",,,,8,,
Vis-conf,2001,Surgical simulator for hysteroscopy: a case study of visualization in surgical training,10.1109/VISUAL.2001.964548,https://doi.org/10.1109/VISUAL.2001.964548,449,587,Conferences,"Computer-based surgical simulation promises to provide a broader scope of clinical training through the introduction of anatomic variation, simulation of untoward events, and collection of performance data. We present a haptically-enabled surgical simulator for the most common techniques in diagnostic and operative hysteroscopy-cervical dilation, endometrial resection and ablation, and lesion excision. Engineering tradeoffs in developing a real-time, haptic-rate simulator are discussed.",,K. Montgomery;L.R. Heinrichs;C. Bruyns;S. Wildermuth;C. Hasser;S. Ozenne;D. Bailey,"National Biocomputation Center, University of Stanford, USA;University of Stanford, USA;National Biocomputation Center, University of Stanford, USA;National Biocomputation Center, University of Stanford, USA;Immersion Corporation, USA;Immersion Corporation, USA;Immersion Corporation, USA",,,,7,,
Vis-conf,2001,Enridged contour maps,10.1109/VISUAL.2001.964495,https://doi.org/10.1109/VISUAL.2001.964495,69,543,Conferences,"The visualization of scalar functions of two variables is a classic and ubiquitous application. We present a new method to visualize such data. The method is based on a nonlinear mapping of the function to a height field, followed by visualization as a shaded mountain landscape. The method is easy to implement and efficient, and leads to intriguing and insightful images: The visualization is enriched by adding ridges. Three types of applications are discussed: visualization of iso-levels, clusters (multivariate data visualization), and dense contours (flow visualization).",,J.J. van Wijk;A. Telea,"Dept. of Mathematics and Computer Science, Eindhoven University of Technology, Eindhoven, MB, The Netherlands;Dept. of Mathematics and Computer Science, Eindhoven University of Technology, Eindhoven, MB, The Netherlands",,,,6,,
Vis-conf,2001,The MetVR case study: meteorological visualization in an immersive virtual environment,10.1109/VISUAL.2001.964559,https://doi.org/10.1109/VISUAL.2001.964559,489,596,Conferences,"Traditional methods for displaying weather products are generally two-dimensional (2D) plots or just text format. It is hard for forecasters to get the entire picture of the atmosphere using these methods. The problems apparent in 2D with comparing and correlating multiple layers are overcome simply by adding a dimension. This is important because pertinent features in the data sets may lie in multiple layers and span several time steps. However, simply using a three-dimensional (3D) approach is not enough. The capacity for analysis of small-scale, but important, features in 2D are lost when transitioning to 3D. We propose that 3D's advantages can be incorporated with 2D's small-scale analysis by using an immersive virtual environment. In this case study, we evaluate our current standing with the project: have we met our goals, and how should we proceed from this point? To evaluate our application, we invited meteorologists to use the application to explore a data set. Then we presented our goals and asked which ones had we met, from a meteorologist's perspective. The results qualitatively reflected that our application was effective and further research would be worthwhile.",,S. Ziegeler;R.J. Moorhead;P.J. Croft;Duanjun Lu,"NSF Engineering Research Center, Mississippi State University, MS, USA;NSF Engineering Research Center, Mississippi State University, MS, USA;Department of Physics, Atmospheric, and General Sciences, Jackson State University, Jackson, MS, USA;Department of Physics, Atmospheric, and General Sciences, Jackson State University, Jackson, MS, USA",,,,5,,
Vis-conf,2001,Case study: application of feature tracking to analysis of autoignition simulation data,10.1109/VISUAL.2001.964551,https://doi.org/10.1109/VISUAL.2001.964551,461,464,Conferences,The focus of this paper is to evaluate the usefulness of some basic feature tracking algorithms as analysis tools for combustion datasets by application to a dataset modeling autoignition. Features defined as areas of high intermediate concentrations were examined to explore the initial phases in the autoignition process.,,W.S. Koegler,"Sandia National Laboratories, Livermore, CA, USA",,,,5,,
Vis-conf,2001,Case study: visualization of particle track data,10.1109/VISUAL.2001.964552,https://doi.org/10.1109/VISUAL.2001.964552,465,590,Conferences,"The Relativistic Heavy Ion Collider (RHIC) experiment at the Brookhaven National Lab is designed to study how the universe came into being. It is believed that after the Big Bang, the universe expanded and cooled, consisting of a soup of quarks, gluons, electrons and neutrinos. As the temperature lowered, electrons combined with protons and formed neutral atoms. Later, clouds of atoms contracted into stars. In this paper, we describe how techniques of volume rendering and information visualization are used to visualize the large particle track data set generated from this high energy physics experiment. The system, called TrackVis, is based on our earlier work of VolVis - Volume Visualization software. Example images of real particle collision data are shown, which are helpful to physicists in investigating the behavior of strongly interacting matter at high energy density.",,Xiaoming Wei;A.E. Kaufman;T.J. Hallman,"Department of Computer Science, State University of New York, Stony Brook, Stony Brook, NY, USA;Department of Computer Science, State University of New York, Stony Brook, Stony Brook, NY, USA;Physics Department, RHIC, Brockhaven National Laboratory, Upton, NY, USA",,,,4,,
Vis-conf,2001,A virtual environment for simulated rat dissection: a case study of visualization for astronaut training,10.1109/VISUAL.2001.964564,https://doi.org/10.1109/VISUAL.2001.964564,509,601,Conferences,"Animal dissection for the scientific examination of organ subsystems is a delicate procedure. Performing this procedure under the complex environment of microgravity presents additional challenges because of the limited training opportunities available that can recreate the altered gravity environment. Traditional astronaut crew training often occurs several months in advance of experimentation, provides limited realism, and involves complicated logistics. We have developed an interactive virtual environment that can simulate several common tasks performed during animal dissection. In this paper, we describe the imaging modality used to reconstruct the rat, provide an overview of the simulation environment and briefly discuss some of the techniques used to manipulate the virtual rat.",,K. Montgomery;C. Bruyns;S. Wildermuth,"National Biocomputation Center, University of Stanford, USA;Center for BioInformatics, NASA Ames Research Center, USA;Center for BioInformatics, NASA Ames Research Center, USA",,,,4,,
Vis-conf,2001,Wind tunnel data fusion and immersive visualization: a case study,10.1109/VISUAL.2001.964563,https://doi.org/10.1109/VISUAL.2001.964563,505,600,Conferences,"This case study describes the process of fusing the data from several wind tunnel experiments into a single coherent visualization. Each experiment was conducted independently and was designed to explore different flow features around airplane landing gear. In the past, it would have been very difficult to correlate results from the different experiments. However, with a single 3-D visualization representing the fusion of the three experiments, significant insight into the composite flowfield was observed that would have been extremely difficult to obtain by studying its component parts. The results are even more compelling when viewed in an immersive environment.",,K. Severance;P. Brewster;B. Lazos;D. Keefe,NASA Langley Research Center;NASA Langley Research Center;NASA Langley Research Center;Brown University,,,,3,,
Vis-conf,2001,Chromatin decondensation: case study of tracking features in confocal data,10.1109/VISUAL.2001.964546,https://doi.org/10.1109/VISUAL.2001.964546,441,585,Conferences,"In this case study we discuss an interactive feature tracking system and its use for the analysis of chromatin decondensation. Features are described as points in a multidimensional attribute space. Distances between points are used as a measure for feature correspondence. Users can interactively experiment with the correspondence measure in order to gain insight in chromatin movement. In addition, by defining time as an attribute, tracking problems related to noisy confocal data can be circumvented.",,W. de Leeuw;R. van Liere,"Center of Mathematics and Computer Science, Amsterdam, Netherlands;Center of Mathematics and Computer Science, Amsterdam, Netherlands",,,,3,,
Vis-conf,2001,"Semi-immersive space mission design and visualization: case study of the ""Terrestrial Planet Finder"" mission",10.1109/VISUAL.2001.964562,https://doi.org/10.1109/VISUAL.2001.964562,501,599,Conferences,"The paper addresses visualization issues of the Terrestrial Planet Finder Mission (C.A. Beichman et al., 1999). The goal of this mission is to search for chemical signatures of life in distant solar systems using five satellites flying in formation to simulate a large telescope. To design and visually verify such a delicate mission, one has to analyze and interact with many different 3D spacecraft trajectories, which is often difficult in 2D. We employ a novel trajectory design approach using invariant manifold theory, which is best understood and utilized in an immersive setting. The visualization also addresses multi-scale issues related to the vast differences in distance, velocity, and time at different phases of the mission. Additionally, the parameterization and coordinate frames used for numerical simulations may not be suitable for direct visualization. Relative motion presents a more serious problem where the patterns of the trajectories can only be viewed in particular rotating frames. Some of these problems are greatly relieved by using interactive, animated stereo 3D visualization in a semi-immersive environment such as a Responsive Workbench. Others were solved using standard techniques such as a stratify approach with multiple windows to address the multiscale issues, re-parameterizations of trajectories and associated 2D manifolds and relative motion of the camera to ""evoke"" the desired patterns.",,K. Museth;A. Barr;M.W. Lo,"Computer Science Department, California Institute of Technology, Pasadena, CA, USA;Computer Science Department, California Institute of Technology, Pasadena, CA, USA;Jet Propulsion Laboratory",,,,3,,
Vis-conf,2001,PingTV: a case study in visual network monitoring,10.1109/VISUAL.2001.964541,https://doi.org/10.1109/VISUAL.2001.964541,421,580,Conferences,"PingTV generates a logical map of a network that is used as an overlay on a physical geographical image of the location from the user perspective (buildings, floors within buildings, etc.). PingTV is used at Illinois State University as a visualization tool to communicate real-time network conditions to the university community via a dedicated channel on the campus cable TV system. Colored symbols allow students and staff to discern high-congestion ""rush hours"" and understand why their specific Internet connectivity is ""broken"" from the wide range of potential causes. Lessons learned include the use of color to visually convey confidence intervals using color shading and the visualization of cyclical network traffic patterns. Our implementation is general and flexible with potential for application for other domains.",,A. Gubin;W. Yurcik;L. Brumbaugh,"Lucent Technologies Network Systems, Naperville, IL, USA;Dept. of Applied Computer Science, Illinois State University, Normal, IL, USA;Dept. of Applied Computer Science, Illinois State University, Normal, IL, USA",,,,3,,
Vis-conf,2001,Case study: visual debugging of cluster hardware,10.1109/VISUAL.2001.964543,https://doi.org/10.1109/VISUAL.2001.964543,429,582,Conferences,"This paper presents a novel use of visualization applied to debugging the Cplant/sup TM/ cluster hardware at Sandia National Laboratories. As commodity cluster systems grow in popularity and grow in size, tracking component failures within the hardware will become more and more difficult. We have developed a tool that facilitates visual debugging of errors within the switches and cables connecting the processors. Combining an abstract system model with color-coding for both error and job information enables failing components to be identified.",,P. Crossno;R. Haynes,"Sandia National Laboratories, Albuquerque, NM, USA;Sandia National Laboratories, Albuquerque, NM, USA",,,,3,,
Vis-conf,2001,"Case study: reconstruction, visualization and quantification of neuronal fiber pathways",10.1109/VISUAL.2001.964549,https://doi.org/10.1109/VISUAL.2001.964549,453,588,Conferences,"It is of significant interest for neurological studies to determine and visualize neuronal fiber pathways in the human brain. By exploiting the capability of diffusion tensor magnetic resonance imaging to detect local orientations of neuronal fibers, we have developed a system of algorithms to reconstruct, visualize and quantify neuronal fiber pathways in vivo. Illustrative results show that the system is a promising tool for visual analysis of fiber connectivity and quantitative studies of neuronal fibers.",,Zhaohua Ding;J.C. Gore;A.W. Anderson,"Department of Diagnostic Radiology, Yale University School of Medicine, USA;Department of Diagnostic Radiology, Yale University School of Medicine, USA;Department of Diagnostic Radiology, Yale University School of Medicine, USA",,,,3,,
Vis-conf,2001,Case study: interacting with cortical flat maps of the human brain,10.1109/VISUAL.2001.964553,https://doi.org/10.1109/VISUAL.2001.964553,469,591,Conferences,"The complex geometry of the human brain contains many folds and fissures, making it impossible to view the entire surface at once. Since most of the cortical activity occurs on these folds, it is desirable to be able to view the entire surface of the brain in a single view. This can be achieved using quasi-conformal flat maps of the cortical surface. Computational and visualization tools are now needed to be able to interact with these flat maps of the brain to gain information about spatial and functional relationships that might not otherwise be apparent. Such information can contribute to earlier diagnostic tools for diseases and improved treatment. Our group is developing visualization and analysis tools that will help elucidate new information about the human brain through the interaction between a cortical surface and its corresponding quasiconformal flat map.",,M.K. Hurdal;K.W. Kurtz;D.C. Banks,"Department of Mathematics and CSIT, Florida State University, USA;Department of Mathematics and CSIT, Florida State University, USA;Department of Mathematics and CSIT, Florida State University, USA",,,,2,,
Vis-conf,2001,Case study: medical Web service for the automatic 3D documentation for neuroradiological diagnosis,10.1109/VISUAL.2001.964542,https://doi.org/10.1109/VISUAL.2001.964542,425,581,Conferences,"The case study presents a medical Web service for the automatic analysis of CTA (computer tomography angiography) datasets. It aims at the detection and evaluation of intracranial aneurysms which are malformations of cerebral blood vessels. To obtain a standardized 3D visualization, digital videos are automatically generated. The time-consuming video production caused by the manual delineation of structures, software based volume rendering, and the interactive definition of an optimized camera path is considerably improved with a fully automatic strategy. Therefore, a previously suggested approach (C. Rezk-Salama, 2000) is applied which uses an optimized transfer function as a template and automatically adapts it to an individual dataset. Furthermore, we introduce hardware-accelerated morphologic filtering in order to detect the location of mid-size and giant aneurysms. The actual generation of the video is finally integrated into a hardware accelerated off-screen rendering process based on 3D texture mapping, ensuring fast visualization of high quality. Overall, clinical routine can be considerably assisted by providing a Web based service combining automatic detection and standardized visualization.",,S. Iserhardt-Bauer;P. Hastreiter;T. Ertl;K. Eberhardt;B. Tomandl,"Visualization and Interactive Systems Group, University of Stuttgart, Germany;Neurocenter, University of Erlangen Nuremberg, Germany;Visualization and Interactive Systems Group, University of Stuttgart, Germany;Division of Neuroradiology, University of Erlangen Nuremberg, Germany;Division of Neuroradiology, University of Erlangen Nuremberg, Germany",,,,1,,
Vis-conf,2001,A case study on interactive exploration and guidance aids for visualizing historical data,10.1109/VISUAL.2001.964557,https://doi.org/10.1109/VISUAL.2001.964557,485,595,Conferences,"In this paper, we address the problem of historical data visualization. We describe the data acquisition, preparation, and visualization. Since the data contain four dimensions, the standard 3D exploration techniques have to be extended or appropriately adapted in order to enable interactive exploration. We discuss in detail two interaction concepts: (1) navigation with one fixed dimension, and (2) quasi 4D navigation allowing to simultaneously explore the four-dimensional space. In addition, we also present a picture-in-picture display mode, enabling the user to interactively view the data, while ""flying with"" a particular event, tracking its motion in time and space. Finally, we present a technique for guided exploration and animation generation, allowing for a vivid gain of insight into the historical data.",,S.L. Stoev;W. Strasser,"WSI/GRIS, University of Tübingen, Tubingen, Germany;WSI/GRIS, University of Tübingen, Tubingen, Germany",,,,1,,
Vis-conf,2001,Case study on real-time visualization of virtual Tubingen on commodity PC hardware,10.1109/VISUAL.2001.964544,https://doi.org/10.1109/VISUAL.2001.964544,433,583,Conferences,"For psychophysical studies in spatial cognition a virtual model of the picturesque old town of Tubingen has been constructed. In order to perform psychophysical experiments in highly realistic virtual environments the model is based on high quality texture maps adding up to several hundreds of MBytes. To accomplish the required real-time frame updates, view frustum and occlusion culling without visibility pre-processing, levels of detail, and texture compression are applied in an interleaved manner. Shared memory communication and a standard PC with two commodity graphics cards is used to enable the powerful combination of those techniques because this combination is not yet available on a single graphics card.",,M. Meissner;J. Orman;S.J. Braun,"WSI/GRIS, University of Tübingen, Tübingen, Germany;WSI/GRIS, University of Tübingen, Tübingen, Germany;Max Planck Institute for Biological Cybernetics, Tübingen, Germany",,,,0,,
Vis-conf,2001,Graphical strategies to convey functional relationships in the human brain: a case study,10.1109/VISUAL.2001.964556,https://doi.org/10.1109/VISUAL.2001.964556,481,594,Conferences,"Brain imaging methods used in experimental brain research such as Positron Emission Tomography (PET) and Functional Magnetic Resonance (fMRI) require the analysis of large amounts of data. Exploratory statistical methods can be used to generate new hypotheses and to provide a reliable measure of a given effect. Typically, researchers report their findings by listing those regions which show significant statistical activity in a group of subjects under some experimental condition or task. A number of methods create statistical parametric maps (SPMs) of the brain on a voxel-basis. In our approach statistics are computed not on individual voxels but on predefined anatomical regions-of-interest (ROIs). A correlation coefficient is used to quantify similarity in response for various regions during an experimental setting. Since the functional inter-relationships can become rather complex and spatially widespread, they are best understood in the context of the underlying 3-D brain anatomy. However despite the power of the 3-D model, the relative location of ROIs in 3-D can be obscured due the inherent problem of presenting 3-D spatial information on a 2-D screen. In order to address this problem, we have explored a number of visualization techniques to aid the brain researcher in exploring the spatial relationships of brain activity. In this paper we present a novel 3-D interface that allows the interactive exploration of correlation datasets.",,T. Welsh;K. Mueller;Wei Zhu;N. Volkow;J. Meade,"Brookhaven National Laboratory, State University of New York, Stony Brook, USA;Brookhaven National Laboratory, State University of New York, Stony Brook, USA;Brookhaven National Laboratory, State University of New York, Stony Brook, USA;Brookhaven National Laboratory, State University of New York, Stony Brook, USA;Brookhaven National Laboratory, State University of New York, Stony Brook, USA",,,,0,,
Vis-conf,2001,Point set surfaces,10.1109/VISUAL.2001.964489,https://doi.org/10.1109/VISUAL.2001.964489,21,"29, 537",Conferences,"We advocate the use of point sets to represent shapes. We provide a definition of a smooth manifold surface from a set of points close to the original surface. The definition is based on local maps from differential geometry, which are approximated by the method of moving least squares (MLS). We present tools to increase or decrease the density of the points, thus, allowing an adjustment of the spacing among the points to control the fidelity of the representation. To display the point set surface, we introduce a novel point rendering technique. The idea is to evaluate the local maps according to the image resolution. This results in high quality shading effects and smooth silhouettes at interactive frame rates.",,M. Alexa;J. Behr;D. Cohen-Or;S. Fleishman;D. Levin;C.T. Silva,"Technical University of Darmstadt, Germany;ZGDV Darmstadt, Germany;Tel-Aviv University, Israel;Tel-Aviv University, Israel;Tel-Aviv University, Israel;AT and T Laboratories, USA",,,,264,,
Vis-conf,2001,Interactive volume rendering using multi-dimensional transfer functions and direct manipulation widgets,10.1109/VISUAL.2001.964519,https://doi.org/10.1109/VISUAL.2001.964519,255,562,Conferences,"Most direct volume renderings produced today employ one-dimensional transfer functions, which assign color and opacity to the volume based solely on the single scalar quantity which comprises the dataset. Though they have not received widespread attention, multi-dimensional transfer functions are a very effective way to extract specific material boundaries and convey subtle surface properties. However, identifying good transfer functions is difficult enough in one dimension, let alone two or three dimensions. This paper demonstrates an important class of three-dimensional transfer functions for scalar data (based on data value, gradient magnitude, and a second directional derivative), and describes a set of direct manipulation widgets which make specifying such transfer functions intuitive and convenient. We also describe how to use modem graphics hardware to interactively render with multi-dimensional transfer functions. The transfer functions, widgets, and hardware combine to form a powerful system for interactive volume exploration.",,J. Kniss;G. Kindlmann;C. Hansen,"Scientific Computing and Imaging Institute, School of Computing, University of Utah, USA;Scientific Computing and Imaging Institute, School of Computing, University of Utah, USA;Scientific Computing and Imaging Institute, School of Computing, University of Utah, USA",,,,146,,
Vis-conf,2001,Visualization of large terrains made easy,10.1109/VISUAL.2001.964533,https://doi.org/10.1109/VISUAL.2001.964533,363,574,Conferences,"We present an elegant and simple to implement framework for performing out-of-core visualization and view-dependent refinement of large terrain surfaces. Contrary to the trend of increasingly elaborate algorithms for large-scale terrain visualization, our algorithms and data structures have been designed with the primary goal of simplicity and efficiency of implementation. Our approach to managing large terrain data also departs from more conventional strategies based on data tiling. Rather than emphasizing how to segment and efficiently bring data in and out of memory, we focus on the manner in which the data is laid out to achieve good memory coherency for data accesses made in a top-down (coarse-to-fine) refinement of the terrain. We present and compare the results of using several different data indexing schemes, and propose a simple to compute index that yields substantial improvements in locality and speed over more commonly used data layouts. Our second contribution is a new and simple, yet easy to generalize method for view-dependent refinement. Similar to several published methods in this area, we use longest edge bisection in a top-down traversal of the mesh hierarchy to produce a continuous surface with subdivision connectivity. In tandem with the refinement, we perform view frustum culling and triangle stripping. These three components are done together in a single pass over the mesh. We show how this framework supports virtually any error metric, while still being highly memory and compute efficient.",,P. Lindstrom;V. Pascucci,"Center for Applied Scientific Computing, Lawrence Livemore National Laboratory, USA;Center for Applied Scientific Computing, Lawrence Livemore National Laboratory, USA",,,,83,,
Vis-conf,2001,Efficient adaptive simplification of massive meshes,10.1109/VISUAL.2001.964503,https://doi.org/10.1109/VISUAL.2001.964503,127,551,Conferences,"The growing availability of massive polygonal models, and the inability of most existing visualization tools to work with such data, has created a pressing need for memory-efficient methods capable of simplifying very large meshes. In this paper, we present a method for performing adaptive simplification of polygonal meshes that are too large to fit in-core. Our algorithm performs two passes over an input mesh. In the first pass, the model is quantized using a uniform grid, and surface information is accumulated in the form of quadrics and dual quadrics. This sampling is then used to construct a BSP-tree in which the partitioning planes are determined by the dual quadrics. In the final pass, the original vertices are clustered using the BSP-tree, yielding an adaptive approximation of the original mesh. The BSP-tree describes a natural simplification hierarchy, making it possible to generate a progressive transmission and construct level-of-detail representations. In this way, the algorithm provides some of the features associated with more expensive edge contraction methods while maintaining greater computational efficiency. In addition to performing adaptive simplification, our algorithm exhibits output-sensitive memory requirements and allows fine control over the size of the simplified mesh.",,E. Shaffer;M. Garland,"Department of Computer Science, University of Illinois, Urbana, IL;University of Illinois at Urbana-Champaign",,,,61,,
Vis-conf,2001,Continuous topology simplification of planar vector fields,10.1109/VISUAL.2001.964507,https://doi.org/10.1109/VISUAL.2001.964507,159,166,Conferences,"Vector fields can present complex structural behavior, especially in turbulent computational fluid dynamics. The topological analysis of these data sets reduces the information, but one is usually still left with too many details for interpretation. In this paper, we present a simplification approach that removes pairs of critical points from the data set, based on relevance measures. In contrast to earlier methods, no grid changes are necessary, since the whole method uses small local changes of the vector values defining the vector field. An interpretation in terms of bifurcations underlines the continuous, natural flavor of the algorithm.",,X. Tricoche;G. Scheuermann;H. Hagen,"Computer Science Department, University of Kaiserslautern, Kaiserslautern, Germany;Computer Science Department, University of Kaiserslautern, Kaiserslautern, Germany;Computer Science Department, University of Kaiserslautern, Kaiserslautern, Germany",,,,58,,
Vis-conf,2001,Fitting subdivision surfaces,10.1109/VISUAL.2001.964527,https://doi.org/10.1109/VISUAL.2001.964527,319,568,Conferences,"We introduce a new algorithm for fitting a Catmull-Clark subdivision surface to a given shape within a prescribed tolerance, based on the method of quasi-interpolation. The fitting algorithm is fast, local and scales well since it does not require the solution of linear systems. Its convergence rate is optimal for regular meshes and our experiments show that it behaves very well for irregular meshes. We demonstrate the power and versatility of our method with examples from interactive modeling, surface fitting, and scientific visualization.",,N. Litke;A. Levin;P. Schroder,Caltech;Tel Aviv University;Caltech,,,,56,,
Vis-conf,2001,Visualization and interaction techniques for the exploration of vascular structures,10.1109/VISUAL.2001.964538,https://doi.org/10.1109/VISUAL.2001.964538,395,578,Conferences,"We describe a pipeline of image processing steps for deriving symbolic models of vascular structures from radiological data which reflect the branching pattern and diameter of vessels. For the visualization of these symbolic models, concatenated truncated cones are smoothly blended at branching points. We put emphasis on the quality of the visualizations which is achieved by anti-aliasing operations in different stages of the visualization. The methods presented are referred to as HQVV (high quality vessel visualization). Scalable techniques are provided to explore vascular structures of different orders of magnitude. The hierarchy as well as the diameter of the branches of vascular systems are used to restrict visualizations to relevant subtrees and to emphasize parts of vascular systems. Our research is inspired by clear visualizations in textbooks and is targeted toward medical education and therapy planning. We describe the application of vessel visualization techniques for liver surgery planning. For this application it is crucial to recognize the morphology and branching pattern of vascular systems as well as the basic spatial relations between vessels and other anatomic structures.",,H.K. Hahn;B. Preim;D. Selle;H.-O. Peitgen,"MeVis Center for Medical Diagnostic Systems and Visualization, Bremen, Germany;MeVis Center for Medical Diagnostic Systems and Visualization, Bremen, Germany;MeVis Center for Medical Diagnostic Systems and Visualization, Bremen, Germany;MeVis Center for Medical Diagnostic Systems and Visualization, Bremen, Germany",,,,50,,
Vis-conf,2001,A memory insensitive technique for large model simplification,10.1109/VISUAL.2001.964502,https://doi.org/10.1109/VISUAL.2001.964502,121,550,Conferences,"The authors propose three simple, but significant improvements to the OoCS (Out-of-Core Simplification) algorithm of P. Lindstrom (2000) which increase the quality of approximations and extend the applicability of the algorithm to an even larger class of compute systems. The original OoCS algorithm has memory complexity that depends on the size of the output mesh, but no dependency on the size of the input mesh. That is, it can be used to simplify meshes of arbitrarily large size, but the complexity of the output mesh is limited by the amount of memory available. Our first contribution is a version of OoCS that removes the dependency of having enough memory to hold (even) the simplified mesh. With our new algorithm, the whole process is made essentially independent of the available memory on the host computer. Our new technique uses disk instead of main memory, but it is carefully designed to avoid costly random accesses. Our two other contributions improve the quality of the approximations generated by OoCS. We propose a scheme for preserving surface boundaries which does not use connectivity information, and a scheme for constraining the position of the ""representative vertex"" of a grid cell to an optimal position inside the cell.",,P. Lindstrom;C.T. Silva,"LLNL, USA;AT and T, USA",,,,42,,
Vis-conf,2001,PixelFlex: a reconfigurable multi-projector display system,10.1109/VISUAL.2001.964508,https://doi.org/10.1109/VISUAL.2001.964508,167,554,Conferences,"This paper presents PixelFlex - a spatially reconfigurable multi-projector display system. The PixelFlex system is composed of ceiling-mounted projectors, each with computer-controlled pan, tilt, zoom and focus; and a camera for closed-loop calibration. Working collectively, these controllable projectors function as a single logical display capable of being easily modified into a variety of spatial formats of differing pixel density, size and shape. New layouts are automatically calibrated within minutes to generate the accurate warping and blending functions needed to produce seamless imagery across planar display surfaces, thus giving the user the flexibility to quickly create, save and restore multiple screen configurations. Overall, PixelFlex provides a new level of automatic reconfigurability and usage, departing from the static, one-size-fits-all design of traditional large-format displays. As a front-projection system, PixelFlex can be installed in most environments with space constraints and requires little or no post-installation mechanical maintenance because of the closed-loop calibration.",,Ruigang Yang;D. Gotz;J. Hensley;H. Towles;M.S. Brown,"Department of Computer Science, University of North Carolina, Chapel Hill, USA;Department of Computer Science, University of North Carolina, Chapel Hill, USA;Department of Computer Science, University of North Carolina, Chapel Hill, USA;Department of Computer Science, University of North Carolina, Chapel Hill, USA;Department of Computer Science, University of Kentucky, USA",,,,42,,
Vis-conf,2001,Texture hardware assisted rendering of time-varying volume data,10.1109/VISUAL.2001.964520,https://doi.org/10.1109/VISUAL.2001.964520,263,563,Conferences,"In this paper we present a hardware-assisted rendering technique coupled with a compression scheme for the interactive visual exploration of time-varying scalar volume data. A palette-based decoding technique and an adaptive bit allocation scheme are developed to fully utilize the texturing capability of a commodity 3-D graphics card. Using a single PC equipped with a modest amount of memory, a texture capable graphics card, and an inexpensive disk array, we are able to render hundreds of time steps of regularly gridded volume data (up to 45 millions voxels each time step) at interactive rates, permitting the visual exploration of large scientific data sets in both the temporal and spatial domain.",,E.B. Lum;Kwan-Liu Ma;J. Clyne,"CIPIC & Department of Computer Science, University of California, Davis;CIPIC & Department of Computer Science, University of California, Davis;National Center for Atmospheric Research",,,,42,,
Vis-conf,2001,Multiresolution feature extraction for unstructured meshes,10.1109/VISUAL.2001.964523,https://doi.org/10.1109/VISUAL.2001.964523,287,294,Conferences,"We present a framework to extract mesh features from unstructured two-manifold surfaces. Our method computes a collection of piecewise linear curves describing the salient features of surfaces, such as edges and ridge lines. We extend these basic techniques to a multiresolution setting which improves the quality of the results and accelerates the extraction process. The extraction process is semi-automatic, that is, the user is required to input a few control parameters and to select the operators to be applied to the input surface. Our mesh feature extraction algorithm can be used as a preprocessor for a variety of applications in geometric modeling including mesh fairing, subdivision and simplification.",,A. Hubeli;M. Gross,"Department of Computer Science, ETH, Zurich, Switzerland;Department of Computer Science, ETH, Zurich, Switzerland",,,,37,,
Vis-conf,2001,EWA volume splatting,10.1109/VISUAL.2001.964490,https://doi.org/10.1109/VISUAL.2001.964490,29,538,Conferences,"In this paper we present a novel framework for direct volume rendering using a splatting approach based on elliptical Gaussian kernels. To avoid aliasing artifacts, we introduce the concept of a resampling filter combining a reconstruction with a low-pass kernel. Because of the similarity to Heckbert's EWA (elliptical weighted average) filter for texture mapping we call our technique EWA volume splatting. It provides high image quality without aliasing artifacts or excessive blurring even with non-spherical kernels. Hence it is suitable for regular, rectilinear, and irregular volume data sets. Moreover, our framework introduces a novel approach to compute the footprint function. It facilitates efficient perspective projection of arbitrary elliptical kernels at very little additional cost. Finally, we show that EWA volume reconstruction kernels can be reduced to surface reconstruction kernels. This makes our splat primitive universal in reconstructing surface and volume data.",,M. Zwicker;H. Pfister;J. van Baar;M. Gross,"ETH Zürich, Switzerland;MERL, Cambridge, MA, USA;MERL, Cambridge, MA, USA;ETH Zürich, Switzerland",,,,37,,
Vis-conf,2001,Real-time decompression and visualization of animated volume data,10.1109/VISUAL.2001.964531,https://doi.org/10.1109/VISUAL.2001.964531,349,572,Conferences,"Interactive exploration of animated volume data is required by many application, but the huge amount of computational time and storage space needed for rendering does not yet allow the visualization of animated volumes. In this paper, we introduce an algorithm running at interactive frame rates using 3D wavelet transforms that allows for any wavelet, motion compensation techniques and various encoding schemes of the resulting wavelet coefficients to be used. We analyze different families and orders of wavelets for compression ratio and the introduced error. We use a quantization that has been optimized for the visual impression of the reconstructed volume, independent of the viewing algorithm. This enables us to achieve very high compression ratios while still being able to reconstruct the volume with as few visual artifacts as possible. A further improvement of the compression ratio has been achieved by applying a motion compensation scheme to exploit temporal coherency. Using these schemes, we are able to decompress each volume of our animation at interactive frame rates, while visualizing these decompressed volumes on a single PC. We also present a number of improved visualization algorithms for high-quality display using OpenGL hardware running at interactive frame rates on a standard PC.",,S. Guthe;W. Strasser,"WSI/GRIS University of Tübingen, Germany;WSI/GRIS University of Tübingen",,,,36,,
Vis-conf,2001,"The ""Which Blair project"": a quick visual method for evaluating perceptual color maps",10.1109/VISUAL.2001.964510,https://doi.org/10.1109/VISUAL.2001.964510,183,556,Conferences,"We have developed a fast, perceptual method for selecting color scales for data visualization that takes advantage of our sensitivity to luminance variations in human faces. To do so, we conducted experiments in which we mapped various color scales onto the intensity values of a digitized photograph of a face and asked observers to rate each image. We found a very strong correlation between the perceived naturalness of the images and the degree to which the underlying color scales increased monotonically in luminance. Color scales that did not include a monotonically increasing luminance component produced no positive rating scores. Since color scales with monotonic luminance profiles are widely recommended for visualizing continuous scalar data, a purely visual technique for identifying such color scales could be very useful, especially in situations where color calibration is not integrated into the visualization environment, such as over the Internet.",,B.E. Rogowitz;A.D. Kalvin,"Visual Analysis Group, IBM Thomas J. Watson Research Center, Hawthorne, NY, USA;Visual Analysis Group, IBM Thomas J. Watson Research Center, Hawthorne, NY, USA",,,,32,,
Vis-conf,2001,"Visualization of sports using motion trajectories: providing insights into performance, style, and strategy",10.1109/VISUAL.2001.964496,https://doi.org/10.1109/VISUAL.2001.964496,75,544,Conferences,"Remote experience of sporting events has thus far been limited mostly to watching video and the scores and statistics associated with the sport. However, a fast-developing trend is the use of visualization techniques to give new insights into performance, style, and strategy of the players. Automated techniques can extract accurate information from video about player performance that not even the most skilled observer is able to discern. When presented as static images or as a three-dimensional virtual replay, this information makes viewing a game an entirely new and exciting experience. This paper presents one such sports visualization system called LucentVision, which has been developed for the sport of tennis. LucentVision uses real-time video analysis to obtain motion trajectories of players and the ball, and offers a rich set of visualization options based on this trajectory data. The system has been used extensively in the broadcast of international tennis tournaments, both on television and the Internet.",,G. Pingali;A. Opalach;Y. Jean;I. Carlbom,"IBM T. J. Watson Research Center, NY, USA;Bell Labs, Lucent Technologies, NJ, USA;Avaya Labs Research, NY, USA;Bell Labs, Lucent Technologies, NJ, USA",,,,31,,
Vis-conf,2001,Hybrid simplification: combining multi-resolution polygon and point rendering,10.1109/VISUAL.2001.964491,https://doi.org/10.1109/VISUAL.2001.964491,37,539,Conferences,"Multi-resolution hierarchies of polygons and more recently of points are familiar and useful tools for achieving interactive rendering rates. We present an algorithm for tightly integrating the two into a single hierarchical data structure. The trade-off between rendering portions of a model with points or with polygons is made automatically. Our approach to this problem is to apply a bottom-up simplification process involving not only polygon simplification operations, but point replacement and point simplification operations as well. Given one or more surface meshes, our algorithm produces a hybrid hierarchy comprising both polygon and point primitives. This hierarchy may be optimized according to the relative performance characteristics of these primitive types on the intended rendering platform. We also provide a range of aggressiveness for performing point replacement operations. The most conservative approach produces a hierarchy that is better than a purely polygonal hierarchy in some places, and roughly equal in others. A less conservative approach can trade reduced complexity at the far viewing ranges for some increased complexity at the near viewing ranges. We demonstrate our approach on a number of input models, achieving primitive counts that are 1.3 to 4.7 times smaller than those of triangle-only simplification.",,J.D. Cohen;D.G. Aliaga;Weiqiang Zhang,"Johns Hopkins University, USA;Lucent Technologies, Bell Laboratories Innovations, USA;Johns Hopkins University, USA",,,,29,,
Vis-conf,2001,Fast detection of meaningful isosurfaces for volume data visualization,10.1109/VISUAL.2001.964515,https://doi.org/10.1109/VISUAL.2001.964515,223,230,Conferences,"Automatic detection of meaningful isosurfaces is important for producing informative visualizations of volume data, especially when no information about the data origin and imaging protocol is available. We propose a computationally efficient method for the automated detection of intensity transitions in volume data. In this approach, the dominant transitions correspond to clear maxima in cumulative Laplacian-weighted gray value histograms. Only one pass through the data volume is required to compute the histogram. Several other features which may be useful for exploration of data of unknown origin can be efficiently computed in a similar manner. The detected intensity transitions can be used for setting of visualization parameters for surface rendering, as well as for direct volume rendering of 3D datasets. When using surface rendering, the detected dominant intensity transition values correspond to the optimal surface isovalues for extraction of boundaries of the objects of interest. In direct volume rendering, such transitions are important for generation of the transfer functions, which are used to assign visualization properties to data voxels and determine the appearance of the rendered image. The proposed method is illustrated by examples with synthetic data as well as real biomedical datasets.",,V. Pekar;R. Wiemker;D. Hempel,"Philips Research Laboratories, Hamburg, Germany;Philips Research Laboratories, Hamburg, Germany;Philips Research Laboratories, Hamburg, Germany",,,,28,,
Vis-conf,2001,Lagrangian-Eulerian advection for unsteady flow visualization,10.1109/VISUAL.2001.964493,https://doi.org/10.1109/VISUAL.2001.964493,53,541,Conferences,"In this paper, we propose a new technique to visualize dense representations of time-dependent vector fields based on a Lagrangian-Eulerian Advection (LEA) scheme. The algorithm produces animations with high spatio-temporal correlation at interactive rates. With this technique, every still frame depicts the instantaneous structure of the flow, whereas an animated sequence of frames reveals the motion a dense collection of particles would take when released into the flow. The simplicity of both the resulting data structures and the implementation suggest that LEA could become a useful component of any scientific visualization toolkit concerned with the display of unsteady flows.",,B. Jobard;G. Erlebacher;M. Yousuff Hussaini,"School of Computational Science and Information Technology, Florida State University, USA;School of Computational Science and Information Technology, Florida State University, USA;School of Computational Science and Information Technology, Florida State University, USA",,,,28,,
Vis-conf,2001,A tetrahedra-based stream surface algorithm,10.1109/VISUAL.2001.964506,https://doi.org/10.1109/VISUAL.2001.964506,151,553,Conferences,"This paper presents a new algorithm for the calculation of stream surfaces for tetrahedral grids. It propagates the surface through the tetrahedra, one at a time, calculating the intersections with the tetrahedral faces. The method allows us to incorporate topological information from the cells, e.g. critical points. The calculations are based on barycentric coordinates, since this simplifies the theory and the algorithm. The stream surfaces are ruled surfaces inside each cell, and their construction starts with line segments on the faces. Our method supports the analysis of velocity fields resulting from computational fluid dynamics (CFD) simulations.",,G. Scheuermann;T. Bobach;H. Hagen;K. Mahrous;B. Hamann;K.I. Joy;W. Kollmann,"Computer Science Department, University of Kaiserslautern, Kaiserslautern, Germany;Computer Science Department, University of Kaiserslautern, Kaiserslautern, Germany;Computer Science Department, University of Kaiserslautern, Kaiserslautern, Germany;Center for image Processing and Integrated Computing (CIPIC), Department of Computer Science, University of California, Davis, CA;Center for image Processing and Integrated Computing (CIPIC), Department of Computer Science, University of California, Davis, CA;Center for image Processing and Integrated Computing (CIPIC), Department of Computer Science, University of California, Davis, CA;Department of mechanaical and Aeronanutical Engineering, University of California, Davis, CA",,,,25,,
Vis-conf,2001,Dynamic shadow removal from front projection displays,10.1109/VISUAL.2001.964509,https://doi.org/10.1109/VISUAL.2001.964509,175,555,Conferences,"Front-projection display environments suffer from a fundamental problem: users and other objects in the environment can easily and inadvertently block projectors, creating shadows on the displayed image. We introduce a technique that detects and corrects transient shadows in a multi-projector display. Our approach is to minimize the difference between predicted (generated) and observed (camera) images by continuous modification of the projected image values for each display device. We speculate that the general predictive monitoring framework introduced here is capable of addressing more general radiometric consistency problems. Using an automatically-derived relative position of cameras and projectors in the display environment and a straightforward color correction scheme, the system renders an expected image for each camera location. Cameras observe the displayed image, which is compared with the expected image to detect shadowed regions. These regions are transformed to the appropriate projector frames, where corresponding pixel values are increased. In display regions where more than one projector contributes to the image, shadow regions are eliminated. We demonstrate an implementation of the technique in a multiprojector system.",,C. Jaynes;S. Webb;R.M. Steele;M. Brown;W.B. Seales,"Dept. of Computer Science, University of Kentucky;Dept. of Computer Science, University of Kentucky;Dept. of Comput. Sci., Kentucky Univ., Lexington, KY, USA;Dept. of Computer Science, University of Kentucky;Dept. of Comput. Sci., Kentucky Univ., Lexington, KY, USA",,,,22,,
Vis-conf,2001,POP: a hybrid point and polygon rendering system for large data,10.1109/VISUAL.2001.964492,https://doi.org/10.1109/VISUAL.2001.964492,45,540,Conferences,"We introduce a simple but effective extension to the existing pure point rendering systems. Rather than using only points, we use both points and polygons to represent and render large mesh models. We start from triangles as leaf nodes and build up a hierarchical tree structure with intermediate nodes as points. During the rendering, the system determines whether to use a point (of a certain intermediate level node) or a triangle (of a leaf node) for display depending on the screen contribution of each node. While points are used to speedup the rendering of distant objects, triangles are used to ensure the quality of close objects. Our method can accelerate the rendering of large models, compromising little in image quality.",,Baoquan Chen;Minh Xuan Nguyen,"Department of Computer Science and Engineering, University of Minnesota at Twin Cities;Department of Computer Science and Engineering, University of Minnesota at Twin Cities",,,,21,,
Vis-conf,2001,Accelerated volume ray-casting using texture mapping,10.1109/VISUAL.2001.964521,https://doi.org/10.1109/VISUAL.2001.964521,271,278,Conferences,"Acceleration techniques for volume ray-casting are primarily based on pre-computed data structures that allow one to efficiently traverse empty or homogeneous regions. In order to display volume data that successively undergoes color lookups, however, the data structures have to be re-built continuously. In this paper we propose a technique that circumvents this drawback using hardware accelerated texture mapping. In a first rendering pass we employ graphics hardware to interactively determine for each ray where the material is hit. In a second pass ray-casting is performed, but ray traversal starts right in front of the previously determined regions. The algorithm enables interactive classification and it considerably accelerates the view dependent display of selected materials and surfaces from volume data. In contrast to other techniques that are solely based on texture mapping our approach requires less memory and accurately performs the composition of material contributions along the ray.",,R. Westermann;B. Sevenich,"Scientific Visualization & Imaging Group, RWTH Aachen University of Technology, Aachen, Germany;Scientific Visualization & Imaging Group, RWTH Aachen University of Technology, Aachen, Germany",,,,18,,
Vis-conf,2001,Connectivity shapes,10.1109/VISUAL.2001.964504,https://doi.org/10.1109/VISUAL.2001.964504,135,552,Conferences,"We describe a method to visualize the connectivity graph of a mesh using a natural embedding in 3D space. This uses a 3D shape representation that is based solely on mesh connectivity: the connectivity shape. Given a connectivity, we define its natural geometry as a smooth embedding in space with uniform edge lengths and describe efficient techniques to compute it. Our main contribution is to demonstrate that a surprising amount of geometric information is implicit in the connectivity. We also show how to generate connectivity shapes that approximate given 3D shapes. Potential applications of connectivity shapes to modeling and mesh coding are described.",,M. Isenburg;S. Gumhold;C. Gotsman,"University of North Carolina, Chapel Hill, USA;University of Tübingen, Germany;Technion-Israel Institute of Technology, Israel",,,,18,,
Vis-conf,2001,Smooth approximation and rendering of large scattered data sets,10.1109/VISUAL.2001.964530,https://doi.org/10.1109/VISUAL.2001.964530,341,571,Conferences,"Presents an efficient method to automatically compute a smooth approximation of large functional scattered data sets given over arbitrarily shaped planar domains. Our approach is based on the construction of a C/sup 1/-continuous bivariate cubic spline and our method offers optimal approximation order. Both local variation and nonuniform distribution of the data are taken into account by using local polynomial least squares approximations of varying degree. Since we only need to solve small linear systems and no triangulation of the scattered data points is required, the overall complexity of the algorithm is linear in the total number of points. Numerical examples dealing with several real-world scattered data sets with up to millions of points demonstrate the efficiency of our method. The resulting spline surface is of high visual quality and can be efficiently evaluated for rendering and modeling. In our implementation we achieve real-time frame rates for typical fly-through sequences and interactive frame rates for recomputing and rendering a locally modified spline surface.",,J. Haber;F. Zeilfelder;O. Davydov;H.-P. Seidel,"Max Planck Institut für Informatik, Saarbruecken, Germany;Max Planck Institut für Informatik, Saarbruecken, Germany;Justus-Liebig-Universität Giessen, Giessen, Germany;Max Planck Institut für Informatik, Saarbruecken, Germany",,,,17,,
Vis-conf,2001,Optimal regular volume sampling,10.1109/VISUAL.2001.964498,https://doi.org/10.1109/VISUAL.2001.964498,91,546,Conferences,"The classification of volumetric data sets as well as their rendering algorithms are typically based on the representation of the underlying grid. Grid structures based on a Cartesian lattice are the de-facto standard for regular representations of volumetric data. In this paper we introduce a more general concept of regular grids for the representation of volumetric data. We demonstrate that a specific type of regular lattice-the so-called body-centered cubic-is able to represent the same data set as a Cartesian grid to the same accuracy but with 29.3% fewer samples. This speeds up traditional volume rendering algorithms by the same ratio, which we demonstrate by adopting a splatting implementation for these new lattices. We investigate different filtering methods required for computing the normals on this lattice. The lattice representation results also in lossless compression ratios that are better than previously reported. Although other regular grid structures achieve the same sample efficiency, the body-centered cubic is particularly easy to use. The only assumption necessary is that the underlying volume is isotropic and band-limited-an assumption that is valid for most practical data sets.",,T. Theussl;T. Moller;M.E. Groller,"Institute of Computer Graphics and Algorithms, Vienna University of Technology;Graphics, Usability, and Visualization Lab, Simon Fraser University, Canada;Institute of Computer Graphics and Algorithms, Vienna University of Technology, Austria",,,,16,,
Vis-conf,2001,Nonlinear virtual colon unfolding,10.1109/VISUAL.2001.964540,https://doi.org/10.1109/VISUAL.2001.964540,411,579,Conferences,"The majority of virtual endoscopy techniques tries to simulate a real endoscopy. A real endoscopy does not always give the optimal information due to the physical limitations it is subject to. In this paper, we deal with the unfolding of the surface of the colon as a possible visualization technique for diagnosis and polyp detection. A new two-step technique is presented which deals with the problems of double appearance of polyps and nonuniform sampling that other colon unfolding techniques suffer from. In the first step, a distance map from a central path induces nonlinear rays for unambiguous parameterization of the surface. The second step compensates for locally varying distortions of the unfolded surface. A technique similar to magnification fields in information visualization is hereby applied. The technique produces a single view of a complete, virtually dissected colon.",,A.V. Vilanova Bartroli;R. Wegenkittl;A. Konig;E. Groller,"Institute of Computer Graphics and Algorithms, University of Technology, Vienna, Austria;Tiani Medgraph, Austria;Institute of Computer Graphics and Algorithms, University of Technology, Vienna, Austria;Institute of Computer Graphics and Algorithms, University of Technology, Vienna, Austria",,,,16,,
Vis-conf,2001,Quantitative comparative evaluation of 2D vector field visualization methods,10.1109/VISUAL.2001.964505,https://doi.org/10.1109/VISUAL.2001.964505,143,150,Conferences,"Presents results from a user study that compared six visualization methods for 2D vector data. Two methods used different distributions of short arrows, two used different distributions of integral curves, one used wedges located to suggest flow lines, and the final one was line-integral convolution (LIC). We defined three simple but representative tasks for users to perform using visualizations from each method: (1) locating all critical points in an image, (2) identifying critical point types, and (3) advecting a particle. The results show different strengths and weaknesses for each method. We found that users performed better with methods that: (1) showed the sign of vectors within the vector field, (2) visually represented integral curves, and (3) visually represented the locations of critical points. These results provide quantitative support for some of the anecdotal evidence concerning visualization methods. The tasks and testing framework also provide a basis for comparing other visualization methods, for creating more effective methods and for defining additional tasks to further understand tradeoffs among methods. They may also be useful for evaluating 2D vectors on 2D surfaces embedded in 3D and for defining analogous tasks for 3D visualization methods.",,D.H. Laidlaw;R.M. Kirby;J.S. Davidson;T.S. Miller;M. da Silva;W.H. Warren;M. Tarr,"Department of Computer Science, Brown University, Providence, RI, USA;Division of Applied Mathematics, Brown University, Providence, RI;Department of Computer Science, Brown University, Providence, RI, USA;Department of Computer Science, Brown University, Providence, RI, USA;Department of Computer Science, Brown University, Providence, RI, USA;Department of Cognitive and Linguistic Sciences, Brown University, Providence, RI, USA;Department of Cognitive and Linguistic Sciences, Brown University, Providence, RI, USA",,,,16,,
Vis-conf,2001,Integrating occlusion culling with view-dependent rendering,10.1109/VISUAL.2001.964534,https://doi.org/10.1109/VISUAL.2001.964534,371,575,Conferences,"We present an approach that integrates occlusion culling within the view-dependent rendering framework. View-dependent rendering provides the ability to change level of detail over the surface seamlessly and smoothly in real-time. The exclusive use of view-parameters to perform level-of-detail selection causes even occluded regions to be rendered in high level of detail. To overcome this serious drawback we have integrated occlusion culling into the level selection mechanism. Because computing exact visibility is expensive and it is currently not possible to perform this computation in real time, we use a visibility estimation technique instead. Our approach reduces dramatically the resolution at occluded regions.",,J. El-Sana;N. Sokolovsky;C.T. Silva,"Department of Computer Science, Ben-Gurion University of the Negev, Beersheba, Israel;Department of Computer Science, Ben-Gurion University of the Negev, Beersheba, Israel;AT and T Research Laboratories, Florham Park, NJ, USA",,,,15,,
Vis-conf,2001,Compressing large polygonal models,10.1109/VISUAL.2001.964532,https://doi.org/10.1109/VISUAL.2001.964532,357,573,Conferences,"Presents an algorithm that uses partitioning and gluing to compress large triangular meshes which are too complex to fit in main memory. The algorithm is based largely on the existing mesh compression algorithms, most of which require an 'in-core' representation of the input mesh. Our solution is to partition the mesh into smaller submeshes and compress these submeshes separately using existing mesh compression techniques. Since a direct partition of the input mesh is out of question, instead we partition a simplified mesh and use the partition on the simplified model to obtain a partition on the original model. In order to recover the full connectivity, we present a simple scheme for encoding/decoding the resulting boundary structure from the mesh partition. When compressing large models with few singular vertices, a negligible portion of the compressed output is devoted to gluing information. On desktop computers, we have run experiments on models with millions of vertices, which could not be compressed using standard compression software packages, and have observed compression ratios as high as 17 to 1 using our technique.",,J. Ho;Kuang-Chih Lee;D. Kriegman,"Beckman Institute, University of Illinois at Urbana-Champaign, Urbana, IL, USA;Beckman Institute, University of Illinois at Urbana-Champaign, Urbana, IL;Beckman Institute, University of Illinois at Urbana-Champaign, Urbana, IL, USA",,,,14,,
Vis-conf,2001,Normal bounds for subdivision-surface interference detection,10.1109/VISUAL.2001.964529,https://doi.org/10.1109/VISUAL.2001.964529,333,570,Conferences,"Subdivision surfaces are an attractive representation when modeling arbitrary-topology free-form surfaces and show great promise for applications in engineering design and computer animation. Interference detection is a critical tool in many of these applications. In this paper, we derive normal bounds for subdivision surfaces and use these to develop an efficient algorithm for (self-) interference detection.",,E. Grinspun;P. Schroder,"Caltech, USA;Caltech, USA",,,,12,,
Vis-conf,2001,Distance-field based skeletons for virtual navigation,10.1109/VISUAL.2001.964517,https://doi.org/10.1109/VISUAL.2001.964517,239,560,Conferences,"We present a generic method for rapid flight planning, virtual navigation and effective camera control in a volumetric environment. Directly derived from an accurate distance from boundary (DFB) field, our automatic path planning algorithm rapidly generates centered flight paths, a skeleton, in the navigable region of the virtual environment. Based on precomputed flight paths and the DFB field, our dual-mode physically based camera control model supports a smooth, safe, and sticking-free virtual navigation with six degrees of freedom. By using these techniques, combined with accelerated volume rendering, we have successfully developed a real-time virtual colonoscopy system on low-cost PCs and confirmed the high speed, high accuracy and robustness of our techniques on more than 40 patient datasets.",,Ming Wan;F. Dachille;A. Kaufman,"Boeing Company, Seattle, WA, USA;Department of Computer Science, State University of New York, Stony Brook, Stony Brook, NY, USA;Department of Computer Science, State University of New York, Stony Brook, Stony Brook, NY, USA",,,,11,,
Vis-conf,2001,Simplicial subdivisions and sampling artifacts,10.1109/VISUAL.2001.964499,https://doi.org/10.1109/VISUAL.2001.964499,99,547,Conferences,"We review several schemes for dividing cubical cells into simplices (tetrahedra) in 3-D for interpolating from sampled data to R/sup 3/ or for computing isosurfaces by barycentric interpolation. We present test data that reveal the geometric artifacts that these subdivision schemes generate, and discuss how these artifacts relate to the filter kernels that correspond to the subdivision schemes.",,H. Carr;T. Moller;J. Snoeyink,"Department of Computer Science, University of British Columbia, Canada;Dept. of Computer Science, Simon Fraser University;Dept. of Computer Science, University of North Carolina, Chapel Hill",,,,11,,
Vis-conf,2001,Cell-projection of cyclic meshes,10.1109/VISUAL.2001.964514,https://doi.org/10.1109/VISUAL.2001.964514,215,559,Conferences,"We present the first algorithm that employs hardware-accelerated cell-projection for direct volume rendering of cyclic meshes, i.e., meshes with visibility cycles. The visibility sorting of a cyclic mesh is performed by an extended topological sorting, which computes and isolates visibility cycles. Measured sorting times are comparable to previously published algorithms, which are, however, restricted to acyclic meshes. In practice, our algorithm is also useful for acyclic meshes as numerical instabilities can lead to false visibility cycles. Our method includes a simple, hardware-assisted algorithm based on image compositing that renders visibility cycles correctly. For tetrahedral meshes this algorithm allows us to render each tetrahedral cell (whether it is part of a cycle or not) by hardware-accelerated cell-projection. In its basic form our method applies only to convex cyclic meshes; however, we present an exact and a simpler but inexact extension of our method for nonconvex meshes.",,M. Kraus;T. Ertl,"Visualization and Interactive Systems Group, Universitat Stuttgart, Germany;Visualization and Interactive Systems Group, Universitat Stuttgart, Germany",,,,11,,
Vis-conf,2001,User-centric viewpoint computation for haptic exploration and manipulation,10.1109/VISUAL.2001.964526,https://doi.org/10.1109/VISUAL.2001.964526,311,567,Conferences,"We present several techniques for user-centric viewing of the virtual objects or datasets under haptic exploration and manipulation. Depending on the type of tasks performed by the user, our algorithms compute automatic placement of the user viewpoint to navigate through the scene, to display the near-optimal views, and to reposition the viewpoint for haptic visualization. This is accomplished by conjecturing the user's intent based on the user's actions, the object geometry, and intra- and inter-object occlusion relationships. These algorithms have been implemented and interfaced with both a 3-DOF and a 6-DOF PHANToM arms. We demonstrate their application on haptic exploration and visualization of a complex structure, as well as multiresolution modeling and 3D painting with a haptic interface.",,M.A. Otaduy;M.C. Lin,"Department of Computer Science, University of North Carolina, Chapel Hill, USA;Department of Computer Science, University of North Carolina, Chapel Hill, USA",,,,10,,
Vis-conf,2001,A complete distance field representation,10.1109/VISUAL.2001.964518,https://doi.org/10.1109/VISUAL.2001.964518,247,561,Conferences,"Distance fields are an important volume representation. A high quality distance field facilitates accurate surface characterization and gradient estimation. However, due to Nyquist's law, no existing volumetric methods based on the linear sampling theory can fully capture surface details, such as comers and edges, in 3D space. We propose a novel complete distance field representation (CDFR) that does not rely on Nyquist's sampling theory. To accomplish this, we construct a volume where each voxel has a complete description of all portions of surface that affect the local distance field. For any desired distance, we are able to extract a surface contour in true Euclidean distance, at any level of accuracy, from the same CDFR representation. Such point-based iso-distance contours have faithful per-point gradients and can be interactively visualized using splatting, providing per-point shaded image quality. We also demonstrate applying CDFR to a cutting edge design for manufacturing application involving high-complexity parts at unprecedented accuracy using only commonly available computational resources.",,Jian Huang;Yan Li;R. Crawfis;Shao-Chiung Lu;Shuh-Yuan Liou,"Computer and Information Science, Ohio State Uinversity, Columbus, OH, USA;Electrical Engineering, Ohio State Uinversity, Columbus, OH, USA;Computer and Information Science, Ohio State Uinversity, Columbus, OH, USA;Visteon, Inc., Dearborn, MI, USA;Ford Motor Company Limited, Dearborn, MI, USA",,,,10,,
Vis-conf,2001,A simple algorithm for surface denoising,10.1109/VISUAL.2001.964500,https://doi.org/10.1109/VISUAL.2001.964500,107,548,Conferences,"We present a simple denoising technique for geometric data represented as a semiregular mesh, based on locally adaptive Wiener filtering. The degree of denoising is controlled by a single parameter (an estimate of the relative noise level) and the time required for denoising is independent of the magnitude of the estimate. The performance of the algorithm is sufficiently fast to allow interactive local denoising.",,Jianbo Peng;V. Strela;D. Zorin,"New York University, USA;New York University, USA;NYU MRL, New York, NY, USA",,,,9,,
Vis-conf,2001,Fast extraction of adaptive multiresolution meshes with guaranteed properties from volumetric data,10.1109/VISUAL.2001.964524,https://doi.org/10.1109/VISUAL.2001.964524,295,565,Conferences,"We present a new algorithm for extracting adaptive multiresolution triangle meshes from volume datasets. The algorithm guarantees that the topological genus of the generated mesh is the same as the genus of the surface embedded in the volume dataset at all levels of detail. In addition to this ""hard constraint"" on the genus of the mesh, the user can choose to specify some number of soft geometric constraints, such as triangle aspect ratio, minimum or maximum total number of vertices, minimum and/or maximum triangle edge lengths, maximum magnitude of various error metrics per triangle or vertex, including maximum curvature (area) error, maximum distance to the surface, and others. The mesh extraction process is fully automatic and does not require manual adjusting of parameters to produce the desired results as long as the user does not specify incompatible constraints. The algorithm robustly handles special topological cases, such as trimmed surfaces (intersections of the surface with the volume boundary), and manifolds with multiple disconnected components (several closed surfaces embedded in the same volume dataset). The meshes may self-intersect at coarse resolutions. However, the self-intersections are corrected automatically as the resolution of the meshes increase. We show several examples of meshes extracted from complex volume datasets.",,M. Gavriliu;J. Carranza;D.E. Breen;A.H. Barr,"Computer Science Department, California Institute of Technology, USA;Computer Science Department, California Institute of Technology, USA;Computer Science Department, California Institute of Technology, USA;Computer Science Department, California Institute of Technology, USA",,,,8,,
Vis-conf,2001,Undersampling and oversampling in sample based shape modeling,10.1109/VISUAL.2001.964497,https://doi.org/10.1109/VISUAL.2001.964497,83,545,Conferences,"Shape modeling is an integral part of many visualization problems. Recent advances in scanning technology and a number of surface reconstruction algorithms have opened up a new paradigm for modeling shapes from samples. Many of the problems currently faced in this modeling paradigm can be traced back to two anomalies in sampling, namely undersampling and oversampling. Boundaries, non-smoothness and small features create undersampling problems, whereas oversampling leads to too many triangles. We use Voronoi cell geometry as a unified guide to detect undersampling and oversampling. We apply these detections in surface reconstruction and model simplification. Guarantees of the algorithms can be proved. The authors show the success of the algorithms empirically on a number of interesting data sets.",,T.K. Dey;J. Giesen;S. Goswami;J. Hudson;R. Wenger;Wulue Zhao,"Ohio State Uinversity, Columbus, OH, USA;Ohio State Uinversity, Columbus, OH, USA;Ohio State Uinversity, Columbus, OH, USA;Ohio State Uinversity, Columbus, OH, USA;Ohio State Uinversity, Columbus, OH, USA;Ohio State Uinversity, Columbus, OH, USA",,,,7,,
Vis-conf,2001,Hardware-software-balanced resampling for the interactive visualization of unstructured grids,10.1109/VISUAL.2001.964512,https://doi.org/10.1109/VISUAL.2001.964512,199,558,Conferences,"In this paper we address the problem of interactively resampling unstructured grids. Three algorithms are presented. They all allow adaptive resampling of an unstructured grid on a multiresolution hierarchy of arbitrarily sized cartesian grids according to a varying element size. Two of the algorithms presented take advantage of hardware accelerated polygon rendering and 2D texture mapping. In exploiting new features of modem PC graphics adapters, the first algorithm tries to significantly minimize the number of polygons to be rendered. Reducing rasterization requirements is the main goal of the second algorithm, which distributes the computational workload differently between the main processor and the graphics chip. By comparing them to a new pure software approach, an optimal software-hardware balance is studied. We end up with a hybrid approach which greatly improves the performance of hardware assisted resampling by involving the main processor to a higher degree and thus enabling resampling at nearly interactive rates.",,M. Weiler;T. Ertl,"Visualization and Interactive Systems Group, University of Stuttgart, Germany;Visualization and Interactive Systems Group, University of Stuttgart, Germany",,,,7,,
Vis-conf,2001,Transport and anisotropic diffusion in time-dependent flow visualization,10.1109/VISUAL.2001.964494,https://doi.org/10.1109/VISUAL.2001.964494,61,542,Conferences,"The visualization of time-dependent flow is an important and challenging topic in scientific visualization. Its aim is to represent transport phenomena governed by time-dependent vector fields in an intuitively understandable way, using images and animations. Here we pick up the recently presented anisotropic diffusion method, expand and generalize it to allow a multiscale visualization of long-term, complex transport problems. Instead of streamline type patterns generated by the original method now streakline patterns are generated and advected. This process obeys a nonlinear transport diffusion equation with typically dominant transport. Starting from some noisy initial image, the diffusion actually generates and enhances patterns which are then transported in the direction of the flow field. Simultaneously the image is again sharpened in the direction orthogonal to the flow field. A careful adjustment of the models parameters is derived to balance diffusion and transport effects in a reasonable way. Properties of the method can be discussed for the continuous model, which is solved by an efficient upwind finite element discretization. As characteristic for the class of multiscale image processing methods, we can in advance select a suitable scale for representing the flow field.",,D. Burkle;T. Preusser;M. Rumpf,"Institut für Angewandte Mathematik, University of Freiburg, Freiburg im Breisgau, Germany;Fachbereich Mathematik, Duisburg University, Duisburg, Germany;Fachbereich Mathematik, Duisburg University, Duisburg, Germany",,,,6,,
Vis-conf,2001,Circular incident edge lists: a data structure for rendering complex unstructured grids,10.1109/VISUAL.2001.964511,https://doi.org/10.1109/VISUAL.2001.964511,191,557,Conferences,"We present the circular incident edge lists (CIEL), a new data structure and a high-performance algorithm for generating a series of iso-surfaces in a highly unstructured grid. Slicing-based volume rendering is also considered. The CIEL data structure represents all the combinatorial information of the grid, making it possible to optimize the classical propagation from local minima paradigm. The usual geometric structures are replaced by a more efficient combinatorial structure. An active edges list is maintained, and iteratively propagated from an iso-surface to the next one in a very efficient way. The intersected cells incident to each active edge are retrieved, and the intersection polygons are generated by circulating around their facets. This latter feature enables arbitrary irregular cells to be treated, such as those encountered in certain computational fluid dynamics (CFD) simulations. Since the CIEL data structure solely depends on the connections between the cells, it is possible to take into account dynamic changes in the geometry of the mesh and in property values, which only requires the sorted extrema list to be updated. Experiments have shown that our approach is significantly faster than classical methods. The major drawback of our method is its memory consumption, higher than most classical methods. However, experimental results show that it stays within a practical range.",,B. Levy;G. Caumon;S. Conreaux;X. Cavin,"Loria, ISA Inria Lorraine, Vandoeuvre-les-Nancy, France;Loria, ISA Inria Lorraine, Vandoeuvre-les-Nancy, France;Loria, ISA Inria Lorraine, Vandoeuvre-les-Nancy, France;Loria, ISA Inria Lorraine, Vandoeuvre-les-Nancy, France",,,,6,,
Vis-conf,2001,Volume rendering of fine details within medical data,10.1109/VISUAL.2001.964537,https://doi.org/10.1109/VISUAL.2001.964537,387,577,Conferences,"Presents a method concerning the volume rendering of fine details, such as blood vessels and nerves, from medical data. The realistic and efficient visualization of such structures is often of great medical interest, and conventional rendering techniques do not always deal with them adequately. Our method uses preprocessing to reconstruct fine details that are difficult to segment and label. It detects the presence of fine geometrical structures, such as cracks or cylinders that suggest the existence of, for example, blood vessels or nerves; the subsequent volume rendering then displays fine geometrical objects that lie on a surface. The method can also show structures within the volume, using a special ""integration sampling"" scheme to portray reconstructed volume texture, such as that exhibited by muscle fibers. By combining the surface structure and volume texture in the rendering, realistic results can be produced; examples are provided.",,Feng Dong;G.J. Clapworthy;M. Krokos,"Department of Computer & Information Sciences, De Montfort University, U. K., Milton Keynes, United Kingdom;Department of Computer & Information Sciences, De Montfort University, U. K., Milton Keynes, United Kingdom;Department of Computer & Information Sciences, De Montfort University, U. K., Milton Keynes, United Kingdom",,,,5,,
Vis-conf,2001,RTVR-a flexible Java library for interactive volume rendering,10.1109/VISUAL.2001.964522,https://doi.org/10.1109/VISUAL.2001.964522,279,564,Conferences,"This paper presents several distinguishing design features of RTVR-a Java-based library for real-time volume rendering. We describe, how the careful design of data structures, which in our case are based on voxel enumeration, and an intelligent use of lookup tables enable interactive volume rendering even on low-end PC hardware. By assigning voxels to distinct objects within the volume and by using an individual setup and combination of look-up tables for each object, object-aware rendering is performed: different transfer functions, shading models, and also compositing modes can be mixed within a single scene to depict each object in the most appropriate way, while still providing rendering results in real-time. While providing frame rates similar to volume visualization using 3D consumer hardware, the approach utilized by RTVR offers much more flexibility and extensibility due to its pure software nature. Furthermore, due to the memory-efficiency of the data representation and the implementation in Java, RTVR can be used to provide volume viewing facilities over low-bandwidth networks, with almost full control over rendering and visualization mapping parameters (clipping, shading, compositing, transfer function) for the user. This paper also addresses specific problems which arise by the use of Java for interactive visualization.",,L. Mroz;H. Hauser,"VRVis Research Center, Vienna, Austria;VRVis Research Center, Vienna, Austria",,,,5,,
Vis-conf,2001,Attribute preserving dataset simplification,10.1109/VISUAL.2001.964501,https://doi.org/10.1109/VISUAL.2001.964501,113,549,Conferences,"The paper describes a novel application of feature preserving mesh simplification to the problem of managing large, multidimensional datasets during scientific visualization. To allow this, we view a scientific dataset as a triangulated mesh of data elements, where the attributes embedded in each element form a set of properties arrayed across the surface of the mesh. Existing simplification techniques were not designed to address the high dimensionality that exists in these types of datasets. In addition, vertex operations that relocate, insert, or remove data elements may need to be modified or restricted. Principal component analysis provides an algorithm-independent method for compressing a dataset's dimensionality during simplification. Vertex locking forces certain data elements to maintain their spatial locations; this technique is also used to guarantee a minimum density in the simplified dataset. The result is a visualization that significantly reduces the number of data elements to display, while at the same time ensuring that high-variance regions of potential interest remain intact. We apply our techniques to a number of well-known feature preserving algorithms, and demonstrate their applicability in a real-world context by simplifying a multidimensional weather dataset. Our results show a significant improvement in execution time with only a small reduction in accuracy; even when the dataset was simplified to 10% of its original size, average per attribute error was less than 1%.",,J.D. Walter;C.G. Healey,"Department of Computer Science, North Carolina State University, USA;Department of Computer Science, North Carolina State University, Raleigh, NC, USA",,,,4,,
Vis-conf,2001,Wavelet representation of contour sets,10.1109/VISUAL.2001.964525,https://doi.org/10.1109/VISUAL.2001.964525,303,566,Conferences,"We present a new wavelet compression and multiresolution modeling approach for sets of contours (level sets). In contrast to previous wavelet schemes, our algorithm creates a parametrization of a scalar field induced by its contours and compactly stores this parametrization rather than function values sampled on a regular grid. Our representation is based on hierarchical polygon meshes with subdivision connectivity whose vertices are transformed into wavelet coefficients. From this sparse set of coefficients, every set of contours can be efficiently reconstructed at multiple levels of resolution. When applying lossy compression, introducing high quantization errors, our method preserves contour topology, in contrast to compression methods applied to the corresponding field function. We provide numerical results for scalar fields defined on planar domains. Our approach generalizes to volumetric domains, time-varying contours, and level sets of vector fields.",,M. Bertram;D.E. Laney;M.A. Duchaineau;C.D. Hansen;B. Hamann;K.I. Joy,"Department of Computer Science, University of Kaiserslautern, Kaiserslautern, Germany;Center for Applied Scientific Computing CASC, Lawrence Livemore National Laboratory, Livermore, CA, USA;Center for Applied Scientific Computing CASC, Lawrence Livemore National Laboratory, Livermore, CA, USA;Center for Image Processing and Integrated Computing CIPIC Department of Computer Science, University of California, Davis, CA, USA;SCI Institute, University of Utah, Salt Lake, UT, USA;Center for Image Processing and Integrated Computing CIPIC Department of Computer Science, University of California, Davis, CA, USA",,,,3,,
Vis-conf,2001,Variational classification for visualization of 3D ultrasound data,10.1109/VISUAL.2001.964539,https://doi.org/10.1109/VISUAL.2001.964539,403,410,Conferences,"We present a new technique for visualizing surfaces from 3D ultrasound data. 3D ultrasound datasets are typically fuzzy, contain a substantial amount of noise and speckle, and suffer from several other problems that make extraction of continuous and smooth surfaces extremely difficult. We propose a novel opacity classification algorithm for 3D ultrasound datasets, based on the variational principle. More specifically, we compute a volumetric opacity function that optimally satisfies a set of simultaneous requirements. One requirement makes the function attain nonzero values only in the vicinity of a user-specified value, resulting in soft shells of finite, approximately constant thickness around isosurfaces in the volume. Other requirements are designed to make the function smoother and less sensitive to noise and speckle. The computed opacity function lends itself well to explicit geometric surface extraction, as well as to direct volume rendering at interactive rates. We also describe a new splatting algorithm that is particularly well suited for displaying soft opacity shells. Several examples and comparisons are included to illustrate our approach and demonstrate its effectiveness on real 3D ultrasound datasets.",,R. Fattal;D. Lischinski,"School of Computer Science and Engineering, Hebrew University of Jerusalem, Israel;School of Computer Science and Engineering, Hebrew University of Jerusalem, Israel",,,,3,,
Vis-conf,2001,Nonmanifold subdivision,10.1109/VISUAL.2001.964528,https://doi.org/10.1109/VISUAL.2001.964528,325,569,Conferences,"Commonly-used subdivision schemes require manifold control meshes and produce manifold surfaces. However, it is often necessary to model nonmanifold surfaces, such as several surface patches meeting at a common boundary. In this paper, we describe a subdivision algorithm that makes it possible to model nonmanifold surfaces. Any triangle mesh, subject only to the restriction that no two vertices of any triangle coincide, can serve as an input to the algorithm. Resulting surfaces consist of collections of manifold patches joined along nonmanifold curves and vertices. If desired, constraints may be imposed on the tangent planes of manifold patches sharing a curve or a vertex. The algorithm is an extension of a well-known Loop subdivision scheme, and uses techniques developed for piecewise smooth surfaces.",,Lexing Ying;D. Zorin,"New York University, USA;New York University, USA",,,,2,,
Vis-conf,2001,Approximate shading for the re-illumination of synthetic images,10.1109/VISUAL.2001.964535,https://doi.org/10.1109/VISUAL.2001.964535,379,576,Conferences,"Presents a method to estimate illumination dependent properties in image synthesis prior to rendering. A preprocessing step is described in which a linear image basis is developed and a lighting-independent formulation defined. A reflection function, similar to hemispherical reflectance, approximates normal Lambertian shading. Intensity errors resulting from this approximation are reduced by use of a polynomial gamma correction function and scaling to a normalized display range. This produces images that are similar to normal Lambertian shading without employing the maximum (max) function. For a single object view, images can then be expressed in a linear form so that lighting direction can be factored out. During normal rendering, image quantities for arbitrary light directions can be found without rendering. This method is demonstrated for estimating image intensity and level-of-detail error prior to rendering an object.",,R. Scoggins;R. Machiraju;R.J. Moorhead,"U.S. Army Engineer Research and Development Center, USA;Computer Information and Science, Ohio State Uinversity, USA;Engineering Research Center, Mississippi State University, USA",,,,1,,
Vis-conf,2001,Case study: an environment for understanding protein simulations using game graphics,10.1109/VISUAL.2001.964547,https://doi.org/10.1109/VISUAL.2001.964547,445,586,Conferences,"We describe a visualization system designed for interactive study of proteins in the field of computational biology. Our system incorporates multiple, custom, three-dimensional and two-dimensional linked views of the proteins. We take advantage of modem commodity graphics cards, which are typically designed for games rather than scientific visualization applications, to provide instantaneous linking between views and three-dimensional interactivity on standard personal computers. Furthermore, we anticipate the usefulness of game techniques such as bump maps and skinning for scientific applications.",,D. Gresh;F. Suits;Yuk Yin Sham,"T.J. Watson Research Center, IBM, USA;T.J. Watson Research Center, IBM, USA;T.J. Watson Research Center, IBM, USA",,,,1,,
conference_external,2001,Proceedings Visualization 2001 (Cat. No.01CH37269),10.1109/VISUAL.2001.964488,https://doi.org/10.1109/VISUAL.2001.964488,3,,Conferences,,,,,,,,0,,
conference_external,2001,Author index,10.1109/VISUAL.2001.964565,https://doi.org/10.1109/VISUAL.2001.964565,531,531,Conferences,The author index contains an entry for each author and coauthor included in the proceedings record.,,,,,,,0,,
