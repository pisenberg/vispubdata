<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/pisenberg/grobid/grobid-0.6.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Text-to-Viz: Automatic Generation of Infographics from Proportion-Related Natural Language Statements</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weiwei</forename><surname>Cui</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoyu</forename><surname>Zhang</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yun</forename><surname>Wang</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">He</forename><surname>Huang</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bei</forename><surname>Chen</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Fang</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haidong</forename><surname>Zhang</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian-Guan</forename><surname>Lou</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongmei</forename><surname>Zhang</surname></persName>
						</author>
						<title level="a" type="main">Text-to-Viz: Automatic Generation of Infographics from Proportion-Related Natural Language Statements</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="DOI">10.1109/TVCG.2019.2934785</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2021-02-19T19:25+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
				<p>More than 20% of smartphone users are social network users More than 20% of smartphone users are social network users MORE THAN 20% OF SMARTPHONE USERS ARE SOCIAL NETWORK USERS More than 20% of smartphone users are social network users 40% of USA freshwater is for agriculture 40% USA freshwater is for agriculture 3 IN 5 Chinese people live in rural areas 3 in 5 Chinese people live in rural areas 65% of coffee is consumed at breakfast</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>49%</head><p>33% 21%  <ref type="figure" target="#fig_10">Figure 1</ref>. Examples created by Text-to-Viz. (a)-(d) are generated from the statement: "More than 20% of smartphone users are social network users." (e) and (f) are generated from the statement: "40 percent of USA freshwater is for agriculture." (g) and (h) are generated from the statement: "3 in 5 Chinese people live in rural areas." (i) and (j) are generated from the statement: "65% of coffee is consumed at breakfast." (k)-(m) are generated from the statement: "Among all students, 49% like football, 32% like basketball, and 21% like baseball." (n) and (o) are generated from the statement: "Humans made 51.5% of online traffic, while good bots made 19.5% and bad bots made 29%."</p><p>Abstract-Combining data content with visual embellishments, infographics can effectively deliver messages in an engaging and memorable manner. Various authoring tools have been proposed to facilitate the creation of infographics. However, creating a professional infographic with these authoring tools is still not an easy task, requiring much time and design expertise. Therefore, these tools are generally not attractive to casual users, who are either unwilling to take time to learn the tools or lacking in proper design expertise to create a professional infographic. In this paper, we explore an alternative approach: to automatically generate infographics from natural language statements. We first conducted a preliminary study to explore the design space of infographics. Based on the preliminary study, we built a proof-of-concept system that automatically converts statements about simple proportionrelated statistics to a set of infographics with pre-designed styles. Finally, we demonstrated the usability and usefulness of the system through sample results, exhibits, and expert reviews.</p><p>Index Terms-Visualization for the masses, infographic, automatic visualization, presentation, and dissemination</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Information graphics (a.k.a. infographics) is a type of data visualization that combines artistic elements (e.g. clip arts and images) with data-driven content (e.g. bar graphs and pie charts) to deliver information in an engaging and memorable manner <ref type="bibr" target="#b23">[24]</ref>.Due to these advan- <ref type="bibr">Cui</ref> tages, they are widely used in many areas, such as business, finance, and health-care, for advertisements and communications. However, creating a professional infographic is not an easy task. It is a timeconsuming process and also often requires designer skills to ensure the perceptual effectiveness and aesthetics.</p><formula xml:id="formula_0">â€¢ W.</formula><p>Much research has been devoted to investigating the design aspect of infographics <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b62">63]</ref> and developing authoring tools <ref type="bibr" target="#b29">[30,</ref><ref type="bibr" target="#b57">58,</ref><ref type="bibr" target="#b68">69]</ref> to facilitate the creation of data-driven infographics. Based on different considerations, these authoring tools all strive to reach a balance between the ease-of-use and the power of features, and then to speed up the authoring process. However, these tools generally target advanced users. With complicated editing operations and technical concepts, these tools are not friendly to casual users, who, we believe, form another major category of infographic creators, other than professionals, such as graphic designers and data scientists <ref type="bibr" target="#b35">[36]</ref>.</p><p>Consider a hypothetical example in which a program manager, Nina, is preparing a presentation for her manager and wants to emphasize in her slides that "40% of US kids like video games." She decides to add an infographic next to the statement with an authoring tool, e.g., DDG <ref type="bibr" target="#b29">[30]</ref> or InfoNice <ref type="bibr" target="#b68">[69]</ref>. Since Nina is not a professional graphic designer, she first needs to spend time (re-)familiarizing herself with the tool, such as the user interface and work flow. However, even if she were familiar with the tool, she still may not know where to begin to create a desired infographic, because all the existing authoring tools assume that the users have a clear or rough idea of what the final infographic may look like. Unfortunately, Nina has no design expertise and has little to no knowledge of how a professional infographic would look like. Therefore, she likely needs to go through existing well-designed infographics (in books or on the Internet) to look for inspiration. Based on the examined samples, she then settles on a design choice that has the best "return of investment" in terms of authoring time and her purpose of emphasizing the message.</p><p>From this example, we can summarize some common patterns for this user category. First, creators in this category only occasionally create infographics and thus are not proficient in the authoring tools. Second, they do not aim for the most creative/impressive infographics, which often involve complex designs and a long authoring time and are unnecessary in terms of "return of investment". Instead, something effective but professional is often sufficient for their purposes. Third, they often only have little design expertise, and would likely be unclear on how to design a decent infographic from scratch. On the other hand, if they were provided with good and relevant samples, they could often quickly pick one based on their personal preferences.</p><p>To address the needs of users in this category, we explored a new approach: to automatically generate infographics based on text statements. Since text is the most common form of communication to exchange information, we believe that this approach can help more people take advantage of infographics. To achieve this goal, there are two major challenges to overcome. The first one is to understand and extract appropriate information from a given statement. The second one is to construct professional infographics based on the extracted information. For the text understanding challenge, we first collected a corpus of real-world samples. Then, these samples were manually labeled to train a CRF-based model to identify and extract information for infographic constructions. For the infographic construction challenge, we analyzed and explored the design space of infographic exemplars that we collected from the Internet. Based on the design space, we proposed a framework to systematically synthesize infographics.</p><p>Considering the numerous types of information that can be represented by infographics <ref type="bibr" target="#b48">[49,</ref><ref type="bibr" target="#b61">62]</ref>, and the numerous ways to express the same information textually and visually, it is impossible to cover the entire space in one paper. Instead, we decided to focus on a relatively small and isolated text-infographic space and build a proof-of-concept system for it. To achieve this goal, we first conducted a preliminary survey on the existing infographics to identify a category of information that is commonly represented by infographics and also has clear textual and visual patterns to process systematically. Based on the preliminary survey, we chose a subtype of information related to proportion facts (e.g., "Less than 1% of US men know how to tie a bow tie.") and built an end-to-end system to automatically convert simple statements containing this type of information to a set of infographics with pre-designed styles. Finally, we demonstrate the usability and usefulness of the system through sample results, two public exhibits, and expert reviews.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK 2.1 Information Graphics</head><p>Infographics are a type of data visualization dedicated to presentations and communications, rather than data exploration <ref type="bibr" target="#b32">[33,</ref><ref type="bibr" target="#b44">45]</ref>. By combining data content with visual embellishments, they can effectively deliver complex messages in a memorable and engaging manner <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b23">24]</ref>.</p><p>Traditional research in infographics mainly focuses on the effects of visual embellishments and understanding their role as an attentiongetting device <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b62">63]</ref>.Although Tufte <ref type="bibr" target="#b66">[67]</ref> argued that visual embellishments might be harmful, many other studies <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b45">46]</ref> have shown that appropriate embellishments, such as pictographs <ref type="bibr" target="#b22">[23]</ref>, annotations <ref type="bibr" target="#b52">[53]</ref>, and imageries <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b15">16]</ref>, do not seem to interfere with the correct perception of information, and can increase the long-term memorability of visualizations. For example, Haroz et al. <ref type="bibr" target="#b22">[23]</ref> demonstrated that embellished charts are equivalent to plain charts in terms of reading speed and accuracy, but the added visual elements make them more memorable. Recently, studies have been conducted to directly understand infographics. For example, Bylinskii et al. <ref type="bibr" target="#b14">[15]</ref> adopted OCR techniques to assign hashtags to infographics for information retrieval purposes. Madan et al. <ref type="bibr" target="#b38">[39]</ref> used computer vision techniques to detect icons in infographics and proposed a solution to automatically summarize infographics.</p><p>Although these studies have extensively demonstrated the value of infographics from various perspectives, and started to investigate infographic understanding in general, none of them shares the same goal of ours, which is to build data-driven infographics automatically for general users.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Natural Language Interactions</head><p>Research on natural language processing <ref type="bibr" target="#b70">[71]</ref> provides effective ways to analyze texts. Syntax analysis <ref type="bibr" target="#b19">[20]</ref> and semantic analysis <ref type="bibr" target="#b7">[8]</ref> can be used to discover hierarchical structures and understand meanings in text, but they are more appropriate for general language understanding problems. Sequence tagging tasks, such as Part-Of-Speech tagging <ref type="bibr" target="#b39">[40]</ref> and Named Entity Recognition (NER) <ref type="bibr" target="#b47">[48]</ref>, aim to assign a categorical label to each word in text sequences, after that, text segments of different types can be obtained based on assigned categorical labels. Since the input of our system requires extracting text segments, we adopt the sequence tagging techniques. For sequence tagging techniques, rule-based methods <ref type="bibr" target="#b51">[52]</ref> are straightforward, but costly and limited. There are also many machine learning methods proposed which are more robust and easier to generalize, including Hidden Markov Models (HMM) <ref type="bibr" target="#b8">[9]</ref>, Support Vector Machines (SVM) <ref type="bibr" target="#b3">[4]</ref> and Conditional Random Fields (CRF) <ref type="bibr" target="#b33">[34]</ref>.</p><p>Recently, human languages have been used as an interface for visual data analysis. Systems like Articulate <ref type="bibr" target="#b65">[66]</ref>, DataTone <ref type="bibr" target="#b21">[22]</ref>, and Eviza <ref type="bibr" target="#b59">[60]</ref> adopt various methods to transpile natural language queries to formal database queries, such as SQL, and extract analysis results accordingly. Although similar to these solutions in terms of understanding user inputs, our system does not relate to database querying. Instead, we directly visualize user inputs. Specifically, we extract essential semantics from user inputs and translate them into infographic representations for visual data storytelling. In our prototype, we have developed CRF with Convolutional Neural Networks (CNN) because of its high accuracy and efficiency of prediction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Auto-Generated Data Visualizations</head><p>A group of visualization tools enables automatic generation of data visualization through a set of chart templates, including Tableau 1 , Power BI 2 , Many Eyes <ref type="bibr" target="#b67">[68]</ref>, and Voyager <ref type="bibr" target="#b71">[72]</ref>. Analysts can specify subsets of data to generate visualizations directly. These tools have eased the exploration of data through quick chart generation. Although these tools allow users to easily generate visualizations within a few mouse clicks, users still have to make decisions about what charts to show and how data items are encoded visually.</p><p>More recently, machine learning models are leveraged to improve the quality of generated visualizations. These solutions may adopt machine learning techniques at different stages of the process. Some of them, such as DataSite <ref type="bibr" target="#b18">[19]</ref>, Foresight <ref type="bibr" target="#b20">[21]</ref>, and Voder <ref type="bibr" target="#b63">[64]</ref>, try to automatically extract significant insights from raw datasets, while other ones, such as Show Me <ref type="bibr" target="#b37">[38]</ref>, DeepEye <ref type="bibr" target="#b36">[37]</ref>, Draco <ref type="bibr" target="#b46">[47]</ref>, and VizML <ref type="bibr" target="#b25">[26]</ref>, use algorithms to identify the best visual form for a given data pattern. Although all these systems have reduced the effort required for creating data queries and visual encodings, the generated data visualizations are usually standard charts, which are not very expressive and customizable. In contrast to these systems, we have dif-ferent focuses at both stages, which is to convert the information that is explicitly provided by users to infographic-style visualizations.</p><p>To improve the expressiveness of generated standard charts, some systems also incorporate algorithms to automatically add visual cues <ref type="bibr" target="#b31">[32]</ref>. For example, Contextifier <ref type="bibr" target="#b27">[28]</ref> and Temporal Summary Images <ref type="bibr" target="#b13">[14]</ref> support automatic generation of annotations. In a broader sense, most visual analytics systems also can automatically generate visualizations (often customized) from their targeting datasets for users to explore and analyze. However, these tools all require specific types of data format and aim at professional users trying to reveal complex patterns.</p><p>Our system also falls into this category. However, comparing with these existing tools that aim at standard charts or are deeply coupled with strict data formats, our system has very different input and output, helping users who know exactly what information to visualize and help them convert the information into infographics effortlessly.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Infographic Authoring Tools</head><p>Numerous interactive design tools have been proposed to help author more creative and customized infographics. For example, Lyra <ref type="bibr" target="#b57">[58]</ref>, iVisDesigner <ref type="bibr" target="#b53">[54]</ref>, and Charticulator <ref type="bibr" target="#b54">[55]</ref> improve the flexibility of visualization creation through easy manipulation of low-level graphical specifications or declarative models with graphical user interfaces. iVoLVER <ref type="bibr" target="#b41">[42]</ref> and Data Illustrator <ref type="bibr" target="#b35">[36]</ref> design easy data binding and direct manipulation of graphical widgets to help users automatically transform visual elements to reflect underlying datasets.</p><p>To create more customized and engaging infographics, hand-drawn or uploaded images are introduced to improve visualization authoring systems. For example, Data-Driven-Guides <ref type="bibr" target="#b29">[30]</ref> supports vector drawing and data binding, thus providing an authoring environment for data-driven infographics. DataInk <ref type="bibr" target="#b72">[73]</ref> enables the creation of infographics through data binding with manipulation of pen and touch interactions. InfoNice <ref type="bibr" target="#b68">[69]</ref> allows general users to convert unembellished charts into creative visualizations by manipulating visual marks and creating data-driven infographics easily.</p><p>Although these systems have greatly reduce the efforts of creating novel data-driven infographic designs they all require users to be familiar with certain non-trivial concepts, such as vector, layer and databinding, which are often technique barriers for general users to master these systems. In addition, users need to have an initial idea of the final infographic design and realize the idea step by step, which is also challenging for inexperienced users. Therefore, these tools, by design, target at professional users, such as designers and data scientists.</p><p>In contrast to the existing authoring tools, our system specifically targets users without design experience. By dramatically reducing the complexity of the authoring process, with the cost of flexibility, our system can help general users create a variety of infographics automatically, saving them time and inspiring their creativity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">PRELIMINARY SURVEY OF INFOGRAPHICS</head><p>The goal of this survey was to better understand how infographics are used in real life and identify a specific type on which to build our proof-of-concept system. Following the methodology used by Segel and Heer <ref type="bibr" target="#b58">[59]</ref>, we first harvested a representative corpus of infographics from the Internet. We used "infographic" as a search keyword and downloaded the first 200 distinct results manually from Google Image Search. Due to Google's ranking mechanism, the top query results were believed to have good quality and relevance. Since in each search result, multiple related infographics may be arranged together for a comprehensive story, we further manually broke them down into 983 individual infographic units ( <ref type="figure" target="#fig_1">Figure 2</ref>) based on the following criteria. A valid infographic unit should:</p><p>â€¢ deliver at least one message;</p><p>â€¢ contain at least one graphical element;</p><p>â€¢ be visually and semantically coherent and complete;</p><p>â€¢ not be able to split into smaller units that fulfill the above criteria.</p><p>We then categorized all the resulting infographic units into four main groups <ref type="table">(Table 1)</ref>     <ref type="table">Table 1</ref>. Information categories of the collected infographics. Please note that the percentages are based on 983 infographic units, rather than 200 infographic sheets. Therefore, the numbers for non-statistics based infographics are exceptionally low, since they often take a larger space than statistics-based ones.</p><p>â€¢ Statistical-based: This is the main category of infographics, which commonly includes horizontal bar charts, vertical column charts, pictographs, and pie/donut charts, for summarizing a large amount of statistical information. â€¢ Timeline-based: This category aims to show information and events happening over time, helping audiences realize chronological relationships quickly. Common visual representations include time-lines, tables, etc. â€¢ Process-based: This category aims to instruct readers to take step-by-step actions to achieve a certain goal. They are often used to illustrate cooking recipes in magazines, or to clarify operations in workspaces or factories. â€¢ Location-based: Infographics in this category generally contain a map and other annotations such as icons, diagrams, arrows, and tables for navigation. They are usually designed for places such as tourist spots, malls, factories, etc. Please note that this categorization and the others discussed in this paper were first independently performed by three of the co-authors, and then documented as discussion results among the co-authors.</p><p>When examining infographics in the dominant statistics-based category, we further discovered diverse patterns in terms of graphic designs and the underlying messages, which were categorized into four major sub-categories, namely proportion, quantity, change, and rank:</p><p>â€¢ Proportion: This category of infographics aims to convey statistical information about how much a part occupies the whole, e.g., "More than 1/3 of the U.S. adult population is obese". According to our survey, this is the most common type of information de-  livered in the data collected. Infographics in this category often have conspicuous visual and textual patterns. Visually, they often contain bar charts, donut charts, pie charts, pictographs, etc. Textually, the key information is often expressed in forms like "n%", "m in n ", "m/n", or "half of . . . ". Because of its prevalence in practice and relatively prominent visual and textual features, we decided to build the proof-of-concept system for this infographic category. â€¢ Quantity: The second largest category is related to quantities.</p><p>These infographics emphasize the quantitative amount of a certain unit, such as income, population, or speed. Since the values cannot be described as fractions, visuals such as donut charts and pie charts do not apply here. Popular charts in this category include pictographs, vertical column charts, and horizontal bar charts <ref type="figure" target="#fig_2">(Figure 3</ref>(b) and (c)). However, we also noticed that more samples in this category do not incorporate any data-driven visuals. Instead, these infographics mainly contain embellishment visuals (e.g., icons) along with the quantity values highlighted with color, font size/weight, etc. <ref type="figure" target="#fig_2">(Figure 3</ref>(a)). â€¢ Change: The third category aims at describing changes. Although values in this category are often also expressed as proportions or quantities, this category is different from the previous two by emphasizing the concept of change, such as "increase", "decrease", or "drop". In the corresponding infographics, arrows ( <ref type="figure" target="#fig_3">Figure 4</ref> â€¢ Rank: This category shows the relative position of a data item in a group, which is easy to identify based on ordinal numbers or specific symbols, such as "#", "No." or "Top n". However, the visualizations for single or multiple ranks are different. For a message that only contains one piece of ranking information, such as "Florida has the 3rd largest homeless population," infographics usually highlight the key words, such as "3rd", and sometimes incorporate metaphoric embellishments, such as stars, medals, or trophy cups ( <ref type="figure" target="#fig_5">Figure 5(a)</ref>). On the other hand, for a message that involves the ranking of multiple data items, infographics often arrange representing icons in an ordered list to directly convey their relative ranks ( <ref type="figure" target="#fig_5">Figure 5(b)</ref>). In addition to the information categories, we also discovered that the number of statistical facts covered in one infographic unit may vary. In many cases, an infographic unit only covers one fact. But there is also a considerable amount of infographics that contain multi- ple facts. Therefore, based on the number of facts and the relationships between facts in an infographic, we also identified four different categories, namely, single, composition, comparison, and accumulation, accounting for 32%, 25%, 27% and 16% of the collected infographic units respectively.</p><p>â€¢ Single: There is only one statistical fact in an infographic, it describes one facet of a subject. This is the simplest but the most commonly found type in our dataset. Since there is only one fact, the corresponding visualization is generally decided by its semantic type <ref type="table">(Table 1</ref>). â€¢ Composition: In this category, an infographic depicts more than one facet of a subject to form a complete picture of it. For example, in the statement, "In the United States alone, there were 10.5 billion searches in July 2009, which is a 106% increase from 5.1 billion in Dec. 2005," all of the numbers are used to provide information about searches in the United States. Since this category may involve different types of statistical facts, we do not cover it in our prototype system. â€¢ Comparison: For this category, multiple facts are provided to compare the same facet of different subjects. Taking the statement "49% of students like football, while 33% of students like basketball" as an example, numbers "49%" and "33%" compare the students who like football or basketball. The facets of these two numbers are the same, i.e., students. Therefore, they are either combined into a bar chart or placed side-by-side using the same type of visual element. When visual elements are placed side-by-side, distinguishing colors, sizes, or icons are usually used to show difference and assist in comparison. â€¢ Accumulation: Similar to comparison, this type of facts also depicts one single facet for different subjects. But these facts can be logically combined to form a larger whole. An example for accumulation is this statement, "60% of participants come from the US, while 40% come from Canada." In many cases, the numbers add up to one. And because of this characteristic, designers prefer to combine all the data into one pie chart, donut chart, or stacked bar chart, instead of visualizing individual facts separately. Please note that the visualizations may overlap for categories comparison and accumulation. For some messages in the category of accumulation, designers may still use visualizations for comparison, e.g., side-by-side visuals, to emphasize their difference. Therefore, the visualizations suitable for comparison are also suitable for accumulation. However, the same is not true vice versa.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">PROPORTION-RELATED INFORMATION</head><p>According to our preliminary survey, we decided to target proportionrelated facts because of their dominance in our harvested dataset and distinct visual and textual patterns. In this section, we further analyze the textual and visual spaces of this type of information, on which we can build a model to automatically convert natural language statements into proper infographics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Text Space</head><p>One goal of our system is to hide all technical concepts/details, so that the learning curve is minimized and everyone can easily create infographics without obstacles. Therefore, it is critical to allow users to provide the information to visualize using their daily language, rather than formal declarative languages, such as JSON or XML. However, since a message may have many different ways to express in the natural language, we need to collect real-world samples to understand how people usually deliver proportion facts in text.</p><p>From a search engine index, we collected a dataset of real-world PowerPoint files that contains approximately 100,000 slides. From the slides, we used regular expressions to capture 5,562 statements that contain common expressions for fraction, such as n%, m in n, m out of n, and half of. Please note that not all the captured statements can be classified as proportions based on the above definitions, since statements such as "Company revenue increased by 24%" are also included here, which, obviously, should belong to change. Therefore, from the collected statements, we further manually sampled 800 valid proportion-related ones, and used them as the training dataset to build a machine learning model for text processing (Section 5.1).</p><p>At first, we also collected samples from online news articles. However, comparing statements from these two sources, we found that statements in PowerPoint slides are often shorter and more concise than those in news articles. Since PowerPoint-style statements are more focused on statistical facts and better match descriptions in infographics, we eventually removed samples from news articles and only kept the ones collected from PowerPoint slides.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Visual Space</head><p>To understand the infographics of proportion facts, we held a one-hour discussion with two experts, both of whom have at least four years of experience as freelance graphic designers. During the interview, we presented examples of proportion-related infographics, and tried to understand how these infographics were generated from scratch based on their experiences. The discussion resulted in a design space with four dimensions: layout, description, graphic, and color. Although there are a wide variety of designs, every infographic can be described as a tuple of these values. And the design space also aligns with the designers' mental model to create infographics. By thoroughly examining the collected samples, we summarized each dimension as follows.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1">Layout</head><p>Based on the existing layout taxonomies on general visualization design <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b58">59]</ref>, we analyzed and discussed the layout of infographics for proportional facts.</p><p>Layout for Single Fact Infographics with single proportion facts are the simplest and most common type based on our preliminary survey. They are generally composed of two main visual elements: descriptions and graphics.</p><p>In most cases, the descriptions and graphics are arranged in a grid layout. They can be aligned in a horizontal <ref type="figure" target="#fig_10">(Figure 1(c)</ref> and (d)), vertical <ref type="figure" target="#fig_10">(Figure 1(b)</ref>, (g) and (j)), or tiled <ref type="figure" target="#fig_10">(Figure 1(a)</ref>, (f), and (i)) fashion. Another common method is overlaying <ref type="figure" target="#fig_10">(Figure 1(e)</ref>, (h)). For example, when proportion facts contain geographic information, descriptions are usually overlaid on top of a map.</p><p>Layout for Multiple Facts When combining multiple facts into one, there are four common strategies:</p><p>â€¢ Side-by-Side. To indicate comparison, hierarchy, or other logical relationships, multiple infographics can be arranged in grids, including ones that are parallel, tiled, circular, hierarchical, and stacked ( <ref type="figure" target="#fig_6">Figure 6</ref> graphics are placed according to the empty space of a common background <ref type="figure" target="#fig_6">(Figure 6(a)</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2">Description</head><p>Text description is another key component in data-driven infographics. The original statements provide basic materials of infographic descriptions. Infographic designers usually extract key information and arrange descriptions as text blocks. Each infographic may contain multiple text blocks, combined to deliver a complete message. As mentioned in Section 3, proportion-related facts are about how much a part occupies the whole. Therefore, there are three key pieces of information for each proportion fact: number, part, and whole, which are often explicitly expressed in infographics as descriptions. In addition to these three pieces, we also discovered that designers often treat a number's modifier (if there is one), such as "more than" and "less than", as an isolated description. Besides these four key types of descriptions, we also identify the following common forms:</p><p>â€¢ The entire statement.</p><p>â€¢ The statement with the number removed: For example, "of USA fresh water is used for agriculture" in the statement "40 percent of USA fresh water is used for agriculture." â€¢ The part as a verb-object phrase in the statement: Syntactically, when a statement contains a subject and a verb-object phrase, this type of description directly shows the phrase part, for example, "are consumed in breakfast" in the statement "65% of coffee are consumed in breakfast." â€¢ The number-whole phrase in the statement: Basically, this type of description shows the subject in a statement, where the modifier is optional, for example, "65% of coffee" in "65% of coffee are consumed in breakfast." â€¢ The text segments before and after the number in the statement:</p><p>Based on the position of the number component, a statement can also be segmented into three parts and arranged separately, for example, "In the US, less than", "1%", and "men know how to tie a bow tie" in "In the US, less than 1% men know how to tie a bow tie." This segmentation is particularly useful when a statement does not start with the number component.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.3">Graphic</head><p>The design of graphic components involves the selection and composition of graphics. There are two main considerations for how to display graphics in infographics. First, graphics should be semantically related to the content of the original statements. Second, different graphic elements may have different roles in helping to convey the message. Based on some existing visualization taxonomies <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b11">12]</ref>, we went through our infographic dataset for proportional facts. We summarized frequently-used visualizations into seven types, namely, pictograph <ref type="figure" target="#fig_10">(Figure 1(a)</ref>), adornment <ref type="figure" target="#fig_10">(Figure 1(d)</ref>), donut chart <ref type="figure" target="#fig_10">(Figure 1(c)</ref>), pie chart <ref type="figure" target="#fig_10">(Figure 1 (o)</ref>), bar chart <ref type="figure" target="#fig_10">(Figure 1(i)</ref>), filled icon <ref type="figure" target="#fig_10">(Figure 1(e)</ref>), and scaled icon <ref type="figure" target="#fig_10">(Figure1(g)</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.4">Color</head><p>Each infographic has a color theme consisting of harmonious colors, which may also help indicate latent semantics. For example, when an infographic is about environment protection, green or blue based themes are often used. In addition, given a color palette, colors also need to be assigned to different parts of an infographic. The designs in our samples share common rules:</p><p>â€¢ Background and foreground: The background color occupies the biggest area and contrasts the foreground color, while there are often multiple foreground colors used for different visual elements, such as the descriptions, title, and icons. In most cases, descriptions in different text blocks share the same color. Graphic elements, on the other hand, may use one or more colors based on their roles. For example, pictographs, pie charts, or donut charts often require at least two colors to correctly convey the proportion value. Embellishing icons often only use one color to keep a clean look. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">TEXT-TO-VIZ IMPLEMENTATION</head><p>Our system contains two main modules, namely text analyzer and visual generator. First, users provide a textual statement about a proportion fact, such as "More than 40% of students like football." Then, our text analyzer identifies the essential segments in the statement, including modifier, whole, part, number, and others (Section 4.2.2).</p><p>Then the original statement and the extracted segments are fed into the visual generator for infographic construction. For each dimension (i.e., layout, description, graphic, and color), a set of visual elements are generated or selected. Then, we enumerate all combinations of these elements, to synthesize valid infographic candidates. Finally, all the synthesized results are evaluated and ranked, and the ones with high scores are recommended to users. Then, users can either directly export anyone of them as an image to integrate into their reports or presentation slides, or select one and further refine it based on their personal preferences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Text Analyzer</head><p>Given a statement on proportion facts, the goal of this analyzer is to extract the segments of four predefined entity types: modifier (M), number (N), part (P), and whole (W), which is a fundamental task in natural language understanding called named entity recognition. Currently CRF-based approaches have the state-of-the-art performance <ref type="bibr" target="#b28">[29]</ref>. In this prototype, for efficiency, we develop a supervised CNN+CRF model to perform the task. Specifically, there are three steps:</p><p>â€¢ Tokenization: First, a sentence is converted into a token sequence through preprocessing, where we take punctuations, abbreviations, and special phrases into consideration. For example, given the statement in <ref type="figure" target="#fig_8">Figure 7</ref>, we can totally collect a sequence of nine tokens (i.e.,"more", "than", . . . , and the final period "."). â€¢ Featurization: Then, for each token, we extract multiple features, such as word embedding feature <ref type="bibr" target="#b42">[43]</ref>, syntactic feature (such as upper/lower case, punctuation, part-of-speech tag), and Brown clustering feature <ref type="bibr" target="#b12">[13]</ref>. All these features are concatenated together to form a larger feature vector to represent the token. For the aforementioned example of nine tokens, a 9 Ã— n feature matrix can be obtained, where n (n=2531 in our implementation) is the length of the concatenated feature vector. â€¢ CNN + CRF: In this step, we feed the output feature matrix to a one-dimensional Convolutional Neural Network (CNN) <ref type="bibr" target="#b24">[25]</ref>, on top of which is a Conditional Random Field (CRF) <ref type="bibr" target="#b40">[41]</ref> layer. In this step, the CNN layer is used to learn a better feature representation for each token from the input raw feature matrix. For the aforementioned example of nine tokens, our CNN layer will generate a 9 Ã— m feature matrix, where m (m=59 in our implementation) is the number of kernels in the layer. Then the CRF  layer is used to determine the entity labels for all tokens. The parameters of the CNN and CRF are jointly trained. We train the CNN+CRF model on 800 manually annotated statements. <ref type="table">Table 2</ref> shows the performance of 10-fold cross-validation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Visual Generator</head><p>Taking the information provided by the text analyzer, this generator identifies multiple candidates on each design space dimension, including layout, description, graphic, and color. After that, all the combinations of these candidates are enumerated to identify valid infographic results in the synthesis step. Then, the quality of the resulting infographics is evaluated through the ranking step.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.1">Layout</head><p>The layout module contains a set of blueprints that describe the overall look of the resulting infographics. First, a blueprint specifies the aspect ratio of the resulting infographic and how the space is divided into regions. More importantly, for each region, the blueprint also needs to specify what kind of information should be placed there, along with any constraints concerning the corresponding information. <ref type="figure" target="#fig_9">Figure 8(a)</ref> shows an example. This blueprint first specifies that the resulting infographic should have an overall 2 Ã— 1 aspect ratio. The canvas is then recursively divided into three regions. Although topological relationships are specified, individual regions are allowed to grow or shrink to accommodate their content. Furthermore, we added the following key constraints:</p><p>â€¢ This blueprint only accepts statements that start with numerical values, e.g., "76% students find math difficult." â€¢ Region 1 holds a graphical element, which can be a pictograph, a filled icon, a donut chart, or a pie chart; â€¢ Region 2 holds the number part in the input statement;</p><p>â€¢ Region 3 holds the the input with the number part removed;</p><p>â€¢ The font size in Region 2 should be at least three times and at most eight times the font size in Region 3. Clearly, this layout module cannot enumerate all creative infographic designs. However, the goal of this system is to provide the quickest way to generate common but professional infographics. Thus, we analyzed the collected samples, identified a set of exemplars, and built 20 layout blueprints in total. These layouts serve as our initial pool of blueprints for infographics generation. However, this is an expandable approach, so we can add more layouts as needed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.2">Description</head><p>The basic descriptions, i.e., modifier, part, whole, and number, are identified by the text analyzer. To provide additional description candidates (Section 4.2.2) that may be required by different blueprints, we adopted the Stanford Parser <ref type="bibr" target="#b19">[20]</ref> to analyze the grammatical structure of the input natural language statement. From the generated grammar tree, we extracted descriptions with different lengths and different components to meet the need of different layouts</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.3">Graphic</head><p>This graphic module aims to provide all graphic elements, including representative icons and other data-driven graphics, such as pie charts and donut charts. In addition, various applicable constraints should also be considered here. When integrating icons into layout blueprints, these constraints will decide whether the resulting infographic is a valid one or not. For example, country-shape icons are not suitable for pictographs and are often used as backgrounds <ref type="figure" target="#fig_10">(Figure 1(h)</ref>) or filled shapes <ref type="figure" target="#fig_10">(Figure 1</ref>(e)). Icons that represent the part are not suitable for pictographs either. Hollow icons also cannot be used as filled shapes, since the colors in them are hardly discernible. In our implementation, we built an icon library with 100 common icons. For each icon, we manually added one or more keywords indicating its semantic meaning, and proper applicable constraints. Then, for non-stop words in the part and whole components, we use the Word2Vec <ref type="bibr" target="#b42">[43]</ref> technique to find the best-matching icons in the icon library.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.4">Color</head><p>The color module aims to find a set of color palettes for a specific infographic. There are two considerations here. First and foremost, the colors within a palette should be harmonic. In addition, it would be better if the colors match the context of the given statement. For example, if the proportion fact is about environment protection, it is more appropriate for the color theme of the corresponding infographic to contain green or blue colors. Although several techniques <ref type="bibr" target="#b34">[35,</ref><ref type="bibr" target="#b60">61]</ref> have been proposed to identify semantically relevant colors from words, they mainly focus on individual colors and cannot generate harmonic color palettes. Therefore, to address the needs of our color module, we adopted a different approach and built a theme library, which contains a set of color palettes. In each palette, various colors are defined with annotations describing their specific uses, such as background, highlights, text, etc. Leveraging the color design knowledge <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b17">18]</ref>, we can ensure that the colors within a palette are harmonic. In addition, we also added one or more keywords to each color palette, describing their preferred context, such as "environment", "fruit", "taxi", and "technology". Then for the non-stop words in the input statements, we again use the Word2Vec <ref type="bibr" target="#b42">[43]</ref> technique to find the best-matching palette.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.5">Synthesis</head><p>At the synthesis step, for each layout blueprint, we enumerate through all recommended graphics, color palettes, and descriptions, and then generate all valid infographics. First, we rule out all the layout blueprints that require elements nonexistent in the input statement. For example, if a blueprint requires a region to be filled with modifier information (e.g., "More than"), but such information is not provided by the description module, then this blueprint will be considered invalid and ruled out. Then, for each valid blueprint, we extract the required icon and description information, calculate their aspect rations, and try to put them into the blueprint layout. The goal is to scale them uniformly and maximize their total size, given the predefined layout constraint. We formulate it as a UI interface optimization problem and solve it using the solver proposed by Badros et al. <ref type="bibr" target="#b5">[6]</ref>.</p><p>Since the final results are optimized based on the aspect ratios of visual elements, we also need to pre-compute several options for pictographs and descriptions. For example, we choose several common pictograph arrangement, such as 2Ã—5, 1Ã—5, and 1Ã—10, to obtain different aspect ratios for the solver to enumerate. Given a description, different line breakings may also yield different aspect ratios. To obtain a set of candidate aspect ratios for a description, we first consider the different line counts (from 1 to 10). Then, we use dynamic programming to obtain a line breaking setting that has the minimum raggedness <ref type="bibr" target="#b30">[31]</ref> for each line count, since designers generally prefer similar lengths when a text is broken into multiple lines. In addition, a pre-selected set of fonts with different compactnesses are also enumerated to find the font that yields the best aspect ratio to match the assigned canvas space.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.6">Ranking</head><p>Since there may be multiple values recommended by these modules, the number of valid combinations may be large. And clearly they are not equally appealing. Therefore, for each resulting infographic, we need to evaluate its quality of message delivery. In this system, we consider three scores, namely semantic, visual, and informative.</p><p>â€¢ Semantic score: This metric aims to evaluate the quality of the selected icons and themes. Since icons and themes are selected through keyword matching, the better the matching, the higher the semantic score is. For example, given the statement "70% students find math difficult," the icon of "student" should contribute to a higher semantic score than the icon of "person". Thus, we define the semantic score Î± s as the average value of all the displayed icons and color palettes picked from the graphic and color modules using the Word2Vec <ref type="bibr" target="#b42">[43]</ref> measure. Since we prefer infographics with graphic elements, we define Î± s = 0 if there are no matching icons or color palettes. â€¢ Visual score: This metric aims to evaluate the visual appearance of an infographic. Since the aspect ratio of icons or the length of the description embedded in the infographic may not be ideal to the layout design, icons and text may be scaled to fit into the layout. Thus, this metric is designed to measure the empty space that these visual elements waste. The better they fit, the higher the visual score is. Thus, we define the visual score as:</p><formula xml:id="formula_1">Î± v =</formula><p>the area of all displayed elements the area of the canvas</p><p>â€¢ Informative score: Ideally, readers should easily recover the original information from the resulting infographic. However, due to the applicable constraints of these values, some information may be left out in infographics, which clearly should be avoided. For example, shorter descriptions may be used due to space limitations. Therefore, we propose the informative metric to evaluate the completeness of message delivery. Thus, we define the informative score as Î± i = âˆ‘ Ï‰âˆˆS I(Ï‰)/|S|, where S denotes all the non-stop words in the input statement, and I(Ï‰) = 1 if Ï‰ appears in the result as an icon or word 0 otherwise.</p><p>The total score is defined as a weighted sum of all three scores:</p><formula xml:id="formula_2">Î± = w s Î± s + w v Î± v + w i Î± i .</formula><p>The default values of these weights are set to 0.25, 0.5, and 0.25, respectively, based on our experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.7">User Refinement</head><p>Although we realize that different users may have different tastes and aim to provide a variety of choices so that users can pick one that best meets their personal tastes, it is still possible that users need to perform minor touches to the final results. Without compromising too much of the intuitiveness of our system, we decided to support users replacing elements in each infographic, including icons, color palettes, and descriptions. By clicking on a recommended infographic, users can open a dialog, in which all the adopted icons, colors, and descriptions are listed. Then users can easily replace them with whatever alternatives they like. When users are satisfied with the result, they can easily save the template or infographic for the reuse purpose.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">EVALUATION</head><p>In this section, we first present a set of examples to demonstrate the diverse designs that our system can automatically create. To understand how general users perceive our system, we further conducted a set of casual interviews with a wide variety of audiences in two exhibit events. The last assessment involved expert evaluation with three professional graphic designers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Sample Infographics</head><p>To demonstrate the capabilities of Text-to-Viz, we present a variety of infographics created with our system <ref type="figure" target="#fig_10">(Figure 1</ref>). For example, <ref type="figure" target="#fig_10">Figure 1(a)-(d)</ref> and <ref type="figure" target="#fig_9">Figure 8</ref>(b) are all generated based on the same statement, "More than 20% of smartphone users are social network users."</p><p>We can see that different templates can produce different infographics. In particular, we can see that <ref type="figure" target="#fig_9">Figure 8</ref>(b) is based on the layout blueprint illustrated in <ref type="figure" target="#fig_9">Figure 8(a)</ref>. However, since the template does not reserve a place for the modifier component, the generated infographic is less accurate than the others, and hence has a lower informative score. <ref type="figure" target="#fig_10">Figure 1</ref>(e) shows an example of a filled icon, while <ref type="figure" target="#fig_10">Figure 1(f)</ref> shows an example of a tilted layout. <ref type="figure" target="#fig_10">Figure 1</ref>(g) and (h) demonstrate two examples of how our system handles proportion information in the form of "m in n". Our system can either choose the correct number of icons to form a pictograph <ref type="figure" target="#fig_10">(Figure 1(g)</ref>) or convert the information to a percentage number and show it with other visualizations <ref type="figure" target="#fig_10">(Figure 1(h)</ref>). <ref type="figure" target="#fig_10">Figure 1</ref>(i) and (j) show that our color strategy can correctly select colors based on semantic information. Since one of our color palettes has the descriptive keyword coffee, this color palette will be ranked higher when choosing colors for infographics. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Casual User Interview in Exhibits</head><p>Our system has been demonstrated to the public in two exhibits. One was a half-day exhibit with an audience consisting mostly of journalists, and the other event was a two-day exhibit with an audience consisting of employees from all departments of a tech company, including sales, software developers, program managers, and public relation managers, etc. In the two events, we received more than 80 different audience members in total. During each reception, we first introduced the background and system and gave them a short live demo to illustrate the idea. Then, we encouraged them to explore the system using their own statements. During the discussions, we focused on the following questions:</p><p>â€¢ Do you think this tool is useful?</p><p>â€¢ Do you like the results generated?</p><p>â€¢ Do you have any suggestions considering your background? Overall, the feedback is overwhelmingly positive. When we explained the problem to the audience members, they understood immediately, since they had all encountered similar situations as described in Section 1. Since most of them did not have a design background, this tool would provide much greater convenience when they need infographics. Several audience members described all the troubles they had gone through to build an infographic and how they had finally given up after several attempts, as they felt the tools were too complicated for them. Given their different backgrounds, the audience members also suggested a variety of applications for this tool. The journalists immediately saw the value of it for their reports. Several public relation managers and project managers believed this tool would greatly help their presentations. In particular, one development manager asked if we could support speech-to-infographics and said, "It would be very interesting to see infographics popping up on screens when people are discussing in a meeting."</p><p>One compromise we made for this system was creativity. Since our infographic layouts are based on templates, we were worried that the output infographics may also lack creativity and feel homogeneous. However, when we asked the audience how they felt about the output results, to our surprise, none of them unpromptedly noticed the homogeneity and creativity issue. All of them commented that the outputs were very impressive and professional and that they would love to directly use them out of the box. We suspected that this may be because they, again, lacked design experiences and only used our system momentary. However, we did encounter some problems when we asked the users to try our system with their own statements. The most critical problem was the recommended icons, which sometimes did not match the expectations from users. For example, when a lab director input the statement: "30% secretaries wear glasses", the recommended icon was a woman's skirt, which seemed inappropriate. This was caused by the Word2Vec matching algorithm. We also noticed that the audience members were the most sensitive to icons, which is probably because icons are more interpretable by non-designers, compared to other visual channels, such as layout, and color. Therefore, we should put more effort into generating meaningful icons from text in the future, to ensure more satisfactory infographics overall. Meanwhile, we allow users to manually replace icons as a temporary solution.</p><p>The most frequently asked question was when we would make this tool publicly available. In addition, the audience also asked if we could support more types of statements. Both requirements are expected since they can certainly help the audience members with their tasks. On the other hand, we also collected some unexpected feedback, which indicated us a future direction for this project. For example, one audience member asked if our algorithm could automatically adjust colors or styles to make it match an existing document or PowerPoint presentation. Another data scientist suggested that we could perhaps generate infographics directly from a dataset. By connecting to a data analysis module, our system can become more intelligent and then be used in many other scenarios.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Expert Interview</head><p>To understand the effectiveness of our system, we conducted a user study with three designers in a tech company. All of them had graduated (E1, E3) from or were enrolled (E2) in professional schools of design disciplines. E1 majored in user experience design and had more than four years of design experience; E2 was a student majoring in industrial design with more than two years of design experience; and E3 majored in visual communications and had more than eight years of experience in design and two years of experience in photography. Their current roles are user interface designer and design intern.</p><p>The 60-minute study started with a 10-minute introduction of our tool, including the usages, several use cases, and the sample infographic designs it generated. After that, a semi-structured interview was conducted to understand the designers' views on the workflow, the tool's usability, and the resulting infographics.</p><p>Overall, the designers agreed that the tool has very promising usages. They felt that the results generated are very impressive and can be used for different purposes, such as posters, presentation slides, and data reports. All of them said they would like to use it when available.</p><p>Our participants appreciated the overall design of the workflow. They expressed the needs for using such a system in their daily work and felt that it would be very convenient to have text as input and a list of candidate designs as output. "It can be used in many productivity tools to enhance data presentation," said one of the designers. Further, E1 suggested that it should be integrated into daily work settings, which would improve the authoring process to be transparent and without interruption. E1 also mentioned, "If it is not well-integrated, I would like to have a copy-to-clipboard button to reduce the effort of using it." In terms of the authoring functions we have provided, such as changing icons and color themes, the experts felt that there is no need to incorporate more editing, saying, "It is obvious that the target of this tool is not for producing very creative and elaborate designs, so it is great to keep it simple and clear."</p><p>In terms of the quality of the generated infographics, the designers thought it was good enough considering its target user group. E1 said, "Users may be lazy to seek perfection. A relatively good design using little effort is sufficient in most cases." For most of the use cases, the designers felt that they were flexible and diverse enough. They even commented: "The number of choices is 'not the more the better'. Too many choices may become a burden and make it hard to make decisions." They also gave advices on the resulting infographics. For example, E1 said, "Some of the infographics involve more than two fonts, but I think using one is ideal." E3 thought it would be acceptable to sacrifice visualization accuracy for better visual appealingness. For example, for the number "65%", E3 expressed that it would be better to fill in two out of three icons. They also made suggestions on further considering the semantic meaning of the icons. For example, when filling a cup or waterdrop icon with colors, it should be bottom-to-top instead of left-to-right.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">DISCUSSION</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1">Automatic Generation of Infographics</head><p>Traditionally, infographic design is considered a highly creative task that can hardly be performed solely by computers. Therefore, although many interactive tools have been developed to build infographics, they still maintain a manual editing process, in which designers lead and computers assist. This is not a suitable paradigm for casual users, who are also a major category of infographic users overlooked by previous research. Unlike designers, casual users neither possess design expertise nor are they familiar with advanced tools, which has also been repeatedly confirmed during our casual interviews (Section 6.2). Therefore, when they need an infographic in their presentations or reports, they must either go through the troubles of creating one by themselves, or ask a professional designer to make one for them. Neither approach seems to have a good return-of-investment, especially when their expectations for the infographic are not high. In our survey, we indeed found that, despite creative designs, there are simpler designs that are used repeatedly in various samples, which leads us to believe that many people (even designers) still favor simple and clear infographics, and do not like overly-embellished designs. This scenario motivated our work: to generate sufficiently good infographics in a most natural way, using natural language statements, for casual users.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2">Opportunities for New Usage</head><p>The opportunities for this solution are enormous. With little or no human interactions, infographics can now be produced effortlessly, hence attracting more and more casual users to take advantage of infographics in their daily life. However, our proof-of-concept implementation may not be the best use scenario for this kind of technology, since it is still an interruptive experience. Users have to stop their work at hand, open our system, enter the statement, then obtain a proper result to insert back into their work. However, we anticipate that this tool can work seamlessly with productivity software suites, such as Office and iWork. When users are working on their presentations and reports, the text analysis module can run silently in the background. Once it detects a statement that can be augmented with infographics, a message would come prompt up to check with users whether they want to take a recommended infographic. In this way, infographics can reach the broadest range of audience and be helpful to them. Another interesting opportunity is poster authoring. An infographic poster often contains multiple infographics that are semantically related. Although each infographic can be generated independently, combining them as a poster can deliver a stronger or more complex message. To achieve this goal, additional considerations, such as typesetting and visual consistency, should also be put into this equation.</p><p>In this paper, we demonstrate a proof-of-concept system that takes natural language statements as input. However, we think it is possible to connect the system to other data sources, such as database or documents. Although we may need to incorporate more machine learning techniques to extract interesting patterns first, it will also greatly expand the applicability of our approach, e.g., integrated into professional visual analytics systems for data analysis tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.3">Failure Cases and Limitations</head><p>During the development of our prototype, we also observed some failure cases, in which our system generates wrong or bad results. One critical source of these failure cases is the text analyzer. For some complicated and long statements, such as "funds for administration were limited to 15% of the scholarship amount," the analyzer may not segment correctly and provide correct tags, which will eventually lead to incomprehensible infographics. We believe more training data can mitigate this situation. In practical use, we can also increase the prediction threshold to reduce the number of inaccurate predictions to surface. Another main source is our icon selector. Many bad cases we observed are caused by inappropriately matched icons. In addition, the length and wrapping of descriptions may also cause less pleasing or readable infographics. For example, if a description is too long, our system will automatically select a small font size, which may result in an inharmonious or even illegible infographic. Although we have integrated a ranking mechanism to help evaluate the overall quality of generated infographics, there are still many aspects of aesthetic to consider in the future.</p><p>In addition, our design also has some limitations in terms of capability. The first and foremost limitation is that our current approach can only handle a relatively small set of information. However, there are various types of information that can be represented by infographics. So far, our approach has to manually identify key information and visual representations type by type. Although in this paper, we demonstrate the auto-generation paradigm on one type of information (proportion facts), it is still unknown how this paradigm extends to other types of information. The second limitation is infographic expressiveness. Clearly, this approach lacks human creativity and is based on a set of pre-designed infographic styles. Although it is an open framework that allows users to add more materials to enrich the infographic designs, the resulting infographics are still limited. The third limitation concerns expression ambiguity. For example, consider these two statements: "30% of students are French; while 40% are American," and "30% of students speak French, while 40% speak English." We can see that in the first statement, the two percentages can be aggregated, which makes it is acceptable to only use one pie chart to visualize the information. However, for the second statement, it is not appropriate to combine the two values in one pie chart, since there may be students who speak both French and English. This kind of ambiguity is extremely hard to resolve using our current machine learning model. Thus, a model that incorporates a deeper understanding of knowledge is required. What adds to the problem is user intent. Even for the former expression, users may still choose one or two pies to emphasize the aggregation or comparison, although both are reasonable visuals. The user intent is impossible to infer from the above examples. In our implementation, we do not tackle this ambiguity problem and leave the decision to users.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">CONCLUSION AND FUTURE WORK</head><p>In this paper, we introduce a framework to automatically generate infographics and demonstrate its feasibility through a proof-of-concept system. Our system takes a natural language statement on a proportion fact and translates it to a set of professional infographics with different styles and settings, which casual users select from or refine based on their personal preferences. Our approach does not require a complex authoring process or design expertise. The example results and user/designer interviews show the tool's usability and promise of being adopted in everyday life.</p><p>There are several avenues that are promising for future work. As a proof-of-concept, our system works relatively well and is only for a specific type of information. In the future, we would like to expand our work to support more types of statistical information or even other types of infographic, such as timelines and locations. On the other hand, the implementation of our current system is also limited. For example, many algorithms used here are still rule-based, such as icon selection, color selection, and ranking. We believe it will be very interesting to explore more techniques (especially machine learning based techniques) to further improve the result quality of our current system.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>proposed by Artacho-Ram et al.<ref type="bibr" target="#b2">[3]</ref>:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 .</head><label>2</label><figDesc>Example of breaking a search result (Infographic of Infographics [17]) down into individual valid infographic units. All valid units are marked with blue rectangles.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 .</head><label>3</label><figDesc>Exemplars of quantity-related infographics<ref type="bibr" target="#b43">[44]</ref>: (a) embellishment icons, (b) horizontal bar charts, and (c) pictographs.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 .</head><label>4</label><figDesc>Exemplars of change-related infographics [57, 65]: (a) contrast color + side-by-side comparison and (b) contrast color + arrows.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>(b)), contrasting colors (Figure 4(a) and (b)), and side-by-side comparison(Figure 4(a)) are often employed in this category to depict the directions of changes.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 5 .</head><label>5</label><figDesc>Exemplars of rank-related infographics<ref type="bibr" target="#b55">[56,</ref><ref type="bibr" target="#b69">70]</ref>: (a) highlighted keyword + star embellishment and (b) ordered small-multiples.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 6 .</head><label>6</label><figDesc>(a)). â€¢ Sharing axes. This type of layout aligns the visual marks of all single infographics so that they can be placed in a common coordinate system. It is applicable for statistical charts with axes, such as bar charts or scatterplots (Figure 6(b)). â€¢ Sharing center. This type of layout arranges multiple numerical facts in the form of concentric circles or sectors with the same center. It is applicable for circular charts, such as pie charts or Nightingale rose charts (Figure 6(c)). â€¢ Sharing context. This type of layout links multiple annotations to different positions of shared illustrative images. It is applicable to annotated infographics. Visual elements of multiple info-Exemplars of infographics with multiple facts [50]: (a) side-byside and sharing context, (b) sharing axes, (c) sharing center.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>â€¢</head><label></label><figDesc>Number highlight: Being an important component, numbers often require extra emphasis. Most of the samples highlight the values with a distinguished size, color, and font (e.g., Figure 1(a) and (g)). Alternatively, values can be embellished with background pictures (e.g., Figure 1(c) and (i)).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 7 .</head><label>7</label><figDesc>An example of entities and labels in a statement. Following the IOB (inside, outside, and beginning) format<ref type="bibr" target="#b50">[51]</ref>, we can map the text and entities into a sequence of labels, where B-, I-, and O represent begin, inside, and outside, respectively.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 8 .</head><label>8</label><figDesc>(a) A layout blueprint example and (b) its realization.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 1 (</head><label>1</label><figDesc>k)-(o) demonstrate the results for showing multiple percentages. Specifically, Figure 1(k)-(m) show a comparison case, in which proportion facts cannot be logically accumulated, while Figure 1(n) and (o) show an accumulation case.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>, Y. Wang, H. Huang, B. Chen, L. Fang, H. Zhang, J. Lou, and D. Zhang are with Microsoft Research Asia. Emails: {weiweicu, wangyun, rayhuang, beichen, leifa, haizhang, jlou, and dongmeiz}@microsoft.com.</figDesc><table /><note>â€¢ X. Zhang is with the ViDi Research Group in University of California, Davis, and this work was done during an internship at Microsoft Research Asia. Email: xybzhang@ucdavis.edu.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>Manuscript received 31 Mar. 2019; accepted 1 Aug. 2019. Date of publication 16 Aug. 2019; date of current version 20 Oct. 2019. For information on obtaining reprints of this article, please send e-mail to: reprints@ieee.org, and reference the Digital Object Identifier below. Digital Object Identifier no. 10.1109/TVCG.2019.2934785</figDesc><table /><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">https://public.tableau.com 2 https://powerbi.microsoft.com/</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Adobe color cc</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adobe</forename></persName>
		</author>
		<ptr target="https://color.adobe.com" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Authoring data-driven videos with dataclips</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Amini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">H</forename><surname>Riche</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Monroy-Hernandez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Irani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on visualization and computer graphics</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="501" to="510" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Influence of the mode of graphical representation on the perception of product aesthetic and emotional features: An exploratory study</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Artacho-Ramirez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Diego-Mas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Alcaide</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Industrial Ergonomics</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="page" from="942" to="952" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Japanese named entity extraction with redundant morphological analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Asahara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Matsumoto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2003 Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology</title>
		<meeting>the 2003 Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2003" />
			<biblScope unit="page" from="8" to="15" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Design patterns for data comics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Bach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Farinella</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Murray-Rust</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Henry Riche</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems</title>
		<meeting>the 2018 CHI Conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page">38</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">The cassowary linear arithmetic constraint solving algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">J</forename><surname>Badros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Borning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">J</forename><surname>Stuckey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Computer-Human Interaction (TOCHI)</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="267" to="306" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Useful junk?: the effects of visual embellishment on comprehension and memorability of charts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bateman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">L</forename><surname>Mandryk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Gutwin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Genest</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Mcdine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Brooks</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the SIGCHI Conference on Human Factors in Computing Systems</title>
		<meeting>the SIGCHI Conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="2573" to="2582" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Semantic parsing on freebase from question-answer pairs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Berant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Chou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Frostig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2013 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1533" to="1544" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Nymble: a high-performance learning name-finder</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">M</forename><surname>Bikel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Schwartz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Weischedel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the fifth conference on Applied natural language processing</title>
		<meeting>the fifth conference on Applied natural language processing</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="1997" />
			<biblScope unit="page" from="194" to="201" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">An empirical study on using visual embellishments in visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Borgo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Abdul-Rahman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Mohamed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">W</forename><surname>Grant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Reppa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Floridi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2759" to="2768" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Beyond memorability: Visualization recognition and recall</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Borkin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Bylinskii</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">W</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">M</forename><surname>Bainbridge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">S</forename><surname>Yeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Borkin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Pfister</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Oliva</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on visualization and computer graphics</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="519" to="528" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">What makes a visualization memorable</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Borkin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Vo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Bylinskii</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Isola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sunkavalli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Oliva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Pfister</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2306" to="2315" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Class-based n-gram models of natural language</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">F</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">V</forename><surname>Desouza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">L</forename><surname>Mercer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">J D</forename><surname>Pietra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">C</forename><surname>Lai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational linguistics</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="467" to="479" />
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Temporal summary images: An approach to narrative visualization via interactive annotation generation and placement</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Bryan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K.-L</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Woodring</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE transactions on visualization and computer graphics</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="511" to="520" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Bylinskii</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Alsheikh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Madan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Recasens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Pfister</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Durand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Oliva</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1709.09215</idno>
		<title level="m">Understanding infographics through textual and visual tag prediction</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Acquired codes of meaning in data visualization and infographics: beyond perceptual primitives</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Byrne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Angus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wiles</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on visualization and computer graphics</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="509" to="518" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Infographic of infographics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Cash</surname></persName>
		</author>
		<ptr target="http://www.ivan.cash/infographic-of-infographics" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Coolors</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Coolors</surname></persName>
		</author>
		<ptr target="https://coolors.co/browser" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Datasite: Proactive visual data exploration with computation of insightbased recommendations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">K</forename><surname>Badam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>YalÃ§in</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Elmqvist</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Visualization</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="251" to="267" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Generating typed dependency parses from phrase structure parses</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-C</forename><surname>De Marneffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Maccartney</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Language Resources and Evaluation Conference</title>
		<meeting>Language Resources and Evaluation Conference<address><addrLine>Genoa Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="449" to="454" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Foresight: Recommending visual insights</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ã‡</forename><surname>Demiralp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">J</forename><surname>Haas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Parthasarathy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Pedapati</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the VLDB Endowment</title>
		<meeting>the VLDB Endowment</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="1937" to="1940" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Datatone: Managing ambiguity in natural language interfaces for data visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Dontcheva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Adar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">G</forename><surname>Karahalios</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th Annual ACM Symposium on User Interface Software &amp; Technology</title>
		<meeting>the 28th Annual ACM Symposium on User Interface Software &amp; Technology</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="489" to="500" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Isotype visualization: Working memory, performance, and engagement with pictographs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Haroz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Kosara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">L</forename><surname>Franconeri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 33rd annual ACM conference on human factors in computing systems</title>
		<meeting>the 33rd annual ACM conference on human factors in computing systems</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1191" to="1200" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Infographic aesthetics: Designing for the first impression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Harrison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Reinecke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems</title>
		<meeting>the 33rd Annual ACM Conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1187" to="1190" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Convolutional neural network architectures for matching natural language sentences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="2042" to="2050" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Vizml: A machine learning approach to visualization recommendation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">Z</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Bakker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kraska</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">A</forename><surname>Hidalgo</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1808.04819</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">The impact of social information on visual judgments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hullman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Adar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Shah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the SIGCHI Conference on Human Factors in Computing Systems</title>
		<meeting>the SIGCHI Conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="1461" to="1470" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Contextifier: automatic generation of annotated stock visualizations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hullman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Diakopoulos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Adar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the SIGCHI Conference on Human Factors in Computing Systems</title>
		<meeting>the SIGCHI Conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="2707" to="2716" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">A neural layered model for nested named entity recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ju</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Miwa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ananiadou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1446" to="1459" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Data-driven guides: Supporting expressive design for information graphics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">W</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Schweickart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Dontcheva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Popovic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Pfister</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on visualization and computer graphics</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="491" to="500" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Breaking paragraphs into lines. Software: Practice and Experience</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">E</forename><surname>Knuth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">F</forename><surname>Plass</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1981" />
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="1119" to="1184" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Internal and external visual cue preferences for visualizations in presentations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H.-K</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Karahalios</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Graphics Forum</title>
		<imprint>
			<publisher>Wiley Online Library</publisher>
			<date type="published" when="2017" />
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="515" to="525" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Presentation-oriented visualization techniques</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Kosara</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE computer graphics and applications</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="80" to="85" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Textual analogy parsing: What&apos;s shared and what&apos;s compared among analogous facts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lamm</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">T</forename><surname>Chaganty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Jurafsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Liang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1809.02700</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Selecting semantically-resonant colors for data visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Fortuna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Kulkarni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Stone</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Heer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Graphics Forum</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="401" to="410" />
		</imprint>
		<respStmt>
			<orgName>Wiley Online Library</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Data illustrator: Augmenting vector design tools with lazy data binding for expressive visualization authoring</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Thompson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Wilson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Dontcheva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Delorey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Grigg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Kerr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Stasko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems</title>
		<meeting>the 2018 CHI Conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page">123</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Deepeye: Towards automatic data visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2018 IEEE 34th International Conference on Data Engineering (ICDE)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="101" to="112" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Show Me: Automatic presentation for visual analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Mackinlay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Hanrahan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Stolte</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE transactions on visualization and computer graphics</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="1137" to="1144" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Madan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Bylinskii</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Tancik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Recasens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Alsheikh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Pfister</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Oliva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Durand</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1807.10441</idno>
		<title level="m">Synthetically trained icon proposals for parsing and summarizing infographics</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Part-of-speech tagging using decision trees</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>MÃ rquez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>RodrÃ­guez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Machine Learning</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1998" />
			<biblScope unit="page" from="25" to="36" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Early results for named entity recognition with conditional random fields, feature induction and webenhanced lexicons</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mccallum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the seventh conference on Natural language learning at HLT-NAACL 2003</title>
		<meeting>the seventh conference on Natural language learning at HLT-NAACL 2003</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2003" />
			<biblScope unit="page" from="188" to="191" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">iVoLVER: Interactive visual language for visualization extraction and reconstruction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">G</forename><surname>MÃ©ndez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Nacenta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Vandenheste</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems</title>
		<meeting>the 2016 CHI Conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="4073" to="4085" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Efficient estimation of word representations in vector space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1301.3781</idno>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">Behind the internet curtain</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Mitchell</surname></persName>
		</author>
		<ptr target="https://www.digitalrealty.com/blog/behind-the-internet-curtain" />
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">On the role of design in information visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">V</forename><surname>Moere</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Purchase</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Visualization</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="356" to="371" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Evaluating the effect of style in information visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">V</forename><surname>Moere</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Tomitsch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wimmer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Christoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Grechenig</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on visualization and computer graphics</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2739" to="2748" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Formalizing visualization design knowledge as constraints: Actionable and extensible models in draco</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Moritz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">L</forename><surname>Nelson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">M</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Howe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Heer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on visualization and computer graphics</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="438" to="448" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">A survey of named entity recognition and classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Nadeau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sekine</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Lingvisticae Investigationes</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="3" to="26" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">A classification of infographics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">C</forename><surname>Purchase</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Isaacs</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Bueti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Hastings</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kassam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Van Hoesen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Theory and Application of Diagrams</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="210" to="218" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<title level="m" type="main">Mobile payments world view</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Raconteur</surname></persName>
		</author>
		<ptr target="https://michaelrosensays.wordpress.com/tag/giving-usa-2015-infographic" />
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Text chunking using transformation-based learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">A</forename><surname>Ramshaw</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">P</forename><surname>Marcus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Natural language processing using very large corpora</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1999" />
			<biblScope unit="page" from="157" to="176" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Extracting company names from text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">F</forename><surname>Rau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings., Seventh IEEE Conference on</title>
		<meeting>Seventh IEEE Conference on</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="1991" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="29" to="32" />
		</imprint>
	</monogr>
	<note>Artificial Intelligence Applications</note>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Chartaccent: Annotation for data-driven storytelling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Brehmer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>HÃ¶llerer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">K</forename><surname>Choe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2017 IEEE Pacific Visualization Symposium (PacificVis)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="230" to="239" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">iVisDesigner: Expressive interactive design of information visualizations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>HÃ¶llerer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Yuan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on visualization and computer graphics</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2092" to="2101" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Charticulator: Interactive construction of bespoke chart layouts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Brehmer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on visualization and computer graphics</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="789" to="799" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<monogr>
		<title level="m" type="main">Ibm tops u.s. patent ranking for 21st consecutive year</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Richter</surname></persName>
		</author>
		<ptr target="https://www.statista.com/chart/1796/us-patent-ranking-2013" />
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Rosen</surname></persName>
		</author>
		<ptr target="https://michaelrosensays.wordpress.com/tag/giving-usa-2015-infographic" />
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Lyra: An interactive visualization design environment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Satyanarayan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Heer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Graphics Forum</title>
		<imprint>
			<publisher>Wiley Online Library</publisher>
			<date type="published" when="2014" />
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="351" to="360" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Narrative visualization: Telling stories with data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Segel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Heer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on visualization and computer graphics</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1139" to="1148" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Eviza: A natural language interface for visual analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Setlur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">E</forename><surname>Battersby</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Tory</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Gossweiler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">X</forename><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 29th Annual Symposium on User Interface Software and Technology</title>
		<meeting>the 29th Annual Symposium on User Interface Software and Technology</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="365" to="377" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">A linguistic approach to categorical color assignment for data visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Setlur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">C</forename><surname>Stone</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on visualization and computer graphics</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="698" to="707" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Infographics: the new communication tools in digital age</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">V</forename><surname>Siricharoen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The international conference on e-technologies and business on the web (ebw2013)</title>
		<imprint>
			<publisher>The Society of Digital Information and Wireless Communication</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="169" to="174" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Readability and precision in pictorial bar charts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Skau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Kosara</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eurographics/IEEE VGTC Conference on Visualization: Short Papers</title>
		<meeting>the Eurographics/IEEE VGTC Conference on Visualization: Short Papers</meeting>
		<imprint>
			<publisher>Eurographics Association</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="91" to="95" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Augmenting visualizations with interactive data facts to facilitate interpretation and communication</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Srinivasan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M</forename><surname>Drucker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Endert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Stasko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on visualization and computer graphics</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="672" to="681" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<monogr>
		<title level="m" type="main">3 way to grow your support revenue</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Stegman</surname></persName>
		</author>
		<ptr target="https://www.tsia.com/blog/infographic-3-ways-to-grow-your-support-revenue" />
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Articulate: A semiautomated model for translating natural language queries into meaningful visualizations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Leigh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Symposium on Smart Graphics</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="184" to="195" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">R</forename><surname>Tufte</surname></persName>
		</author>
		<title level="m">The visual display of quantitative information</title>
		<meeting><address><addrLine>CT</addrLine></address></meeting>
		<imprint>
			<publisher>Graphics press Cheshire</publisher>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Manyeyes: a site for visualization at internet scale</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">B</forename><surname>Viegas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Wattenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Van Ham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kriss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mckeon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on visualization and computer graphics</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">6</biblScope>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Infonice: Easy creation of information graphics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Qu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems</title>
		<meeting>the 2018 CHI Conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page">335</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<monogr>
		<title level="m" type="main">Alligator pear: Imports and exports</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Willingham</surname></persName>
		</author>
		<ptr target="https://www.freightwaves.com/news/infographics/alligator-pear-import-export" />
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Understanding natural language</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Winograd</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognitive psychology</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="191" />
			<date type="published" when="1972" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Voyager: Exploratory analysis via faceted browsing of visualization recommendations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Wongsuphasawat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Moritz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Anand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Mackinlay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Howe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Heer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on visualization and computer graphics</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="649" to="658" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">Dataink: Direct and creative data-oriented drawing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Henry Riche</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Chevalier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">De</forename><surname>Araujo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Wigdor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems</title>
		<meeting>the 2018 CHI Conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page">223</biblScope>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
