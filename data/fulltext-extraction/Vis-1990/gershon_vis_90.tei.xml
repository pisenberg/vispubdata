<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/pisenberg/grobid/grobid-0.6.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Visualization and &apos;Three-Dimensional Image Processinqof Positron Emission Tomography (PET) Brain Images</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nahum</forename><forename type="middle">D</forename><surname>Gershon</surname></persName>
							<affiliation key="aff0">
								<address>
									<addrLine>7525 Colshire Drive Mchan</addrLine>
									<postCode>22102</postCode>
									<region>VA</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Visualization and &apos;Three-Dimensional Image Processinqof Positron Emission Tomography (PET) Brain Images</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2021-02-19T20:24+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
				<p>In this work, we have applied image processing and volume rendering algorithms together with considerations on the physiology of the human visual system to improve the quality of perception of the information contained in PET brain images. The psychophysical considerations for selecting color and brightness level are used to visualize functional and anatomical structures in three dimensions.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Introduction</head><p>Positron Emission Tomography (PET) is a versatile medical imaging technique that uses radio-pharmaceuticals to measure metabolism, revealing how well the body is working. Examples of metabolic activity that may be measured by PET include cerebral blood flow, oxygen consumption, and glucose metabolism. A sample of PET images is given in figure 1 and a more detailed description of the PET technique could be found in Herscovitch's review <ref type="bibr" target="#b2">[2]</ref>. However, the interpretation of PET images is limited because of both the inherently low resolution and the absence of apparent anatomical information. In addition, the information is usually presented in a set or series of two-dimensional (2-D) slices, or tomographs. In order to fully understand the informational contents of the set, the medical researcher or practitioner has to integrate the * This project is funded by The MITRE Corporation as part of The MITRE Sponsored Research (MSR) Program. information contained in multiple (i.e., 10 or more) slices into a complete model in his mind. A more detailed description of the characteristics of PET data and the limitations on the perception of its images is given in the next section.</p><p>In this work, we have applied image processing and volume rendering algorithms together with considerations on the physiology of the human visual system to improve the quality of perception of the information contained in PET brain images, and to highlight the existing anatomical information. The functional and anatomical information is displayed in three dimensions. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Perception of Information</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>within PET Images</head><p>PET results are depicted as grey scale images with brightness levels varying according to levels of metabolic activity. The observer would like to perceive the levels of brightness and the shapes and locations of regions of metabolic activity corresponding to brain anatomical structures. There are a number of characteristics associated with PET image data and with human visual perception that can affect the quality of perception of information presented by PET images. The main four causes of the degradation of perception quality of PET brain images are discussed below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Low Spatial Resolution</head><p>Images generated by PET contain noise and their resolution is low (.5 to 1.5 cm in plane) compared with other imaging techniques, such</p><p>as Magnetic Resonance Imaging @!RI) which is 1 mm in plane. Thus, the resulting images look fuzzy, and the localization of regions of interest could be difficult.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Display of Brightness Levels</head><p>The information given by PET is a distribution of metabolic rate values over spatial <ref type="bibr">(anatomical)</ref> areas, where the brightness in a location is proportional to the metabolic rate level at this point. However, the visual system can determine patterns quite well but is not as efficient in determining levels of brightness. The perceived brightness level of a region may depend on the brightness level of its neighboring regions <ref type="bibr" target="#b6">[5]</ref>. A bright spot looks brighter as the background becomes darker, while a dark spot looks darker as the background becomes brighter. This phenomenon is called brightness contrast. One way to let the visual system better discriminate between brightness levels is to divide the intensity range into a number of discrete levels displaying each one in a pre-assigned color (pseudocolors). Usually, a scale of colors based on the visible spectrum is chosen, with red representing high and violet representing low values of brightness. This representation may not be sufficient to clearly visualize position, depth, and shape of metabolically active regions. As discussed in the Discussion section, to improve the perception of position, depth, and shape, a scale of color based on brightness contrast of neighboring regions rather than on color shade is preferable.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Use of a Series of 2-D Slices to Represent Three-Dimensional Structures</head><p>The information provided by PET is three dimensional (3-D). However, it is given as a series of 2-0 images, or slices. In order to perceive the three-dimensional interrelationships of the data, the viewer has to integrate in his mind the information presented in 10 or more slices into a complete model. This problem is common to most of the tomographic techniques. The perception of the three-dimensional structure of PET data could be made easier by displaying the set of twodimensional slices as a three-dimensional object. or image volume. In addition, the use of s t e m viewing andlor motion to display the whole image volume could be used to make hard-to-see features more visible.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Shortage of Anatomical Information</head><p>PET measures metabolic activity and, thus, does not depict anatomical structure directly. Together with the poor resolution mentioned above, it is difficult in many cases to associate anatomical structures with metabolically active areas delineated by PET without further processing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Methods</head><p>Hardware, Data Acquisition, and Noise</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Removal</head><p>The system used in this study included a Pixar I1 Imaging Computer (Pixar, San Rafael, Califomia), a Sun 3/180 (Sun Microsystems, Mountain View, Califomia) used as a host computer, and a Stereographics (San Rafael, California) stereo display. PET data was obtained from normal subjects and patients with Dementia of the Alzheimer Type @AT) using Scanditronix Model 1024-7B at the Warren Magnuson Clinical Center of The National Institutes of Health, Bethesda, Maryland. Each set contained 14 images. The in-plane resolution of the PET images (128 by 128 pixels) was 6 mm, and the axial resolution was 6.9 mm. To eliminate noise, pixels with intensity lower than 10 percent of the maximum were set to zero brightness.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Visualization of 3-D PET Images</head><p>To render the image volumes of PET data and to produce their visual projections, we have used subroutines contained in Pixar's Chapvolumes software [ 11. The PET data was classified into four regions, high, medium-high, medium-low, and low metabolic rates. The opacity of the regions with high metabolic rates was chosen to be fully opaque (opacity=l), which is three times higher than the opacity assigned to the other regions (.33).</p><p>A number of steps were taken to visualize the 3-D PET information. Depth information was accentuated by using shading created by a simulated light. Two additional depth cues were stereo and motion. The use of stereo images and motion has two functions. The first one is to enable the viewer to perceive the relative depths of each part of the image volume projection. The second function is related to the fact that PET images are of low resolution and have a somewhat blurry appearance. The brain-visual system functions in such a way that the introduction of s t e m could make hard-to-see objects more visible (see <ref type="bibr">Livingstone [3]</ref>). Stereo pairs were generated by applying a simple rotation of 5 degrees around the image volume center. Since perspective was not used in the projection process, this method of stereo pair generation does not create artifacts that severely degrade the ease of stereo viewing. The shading produced by a simulation of reflected light generated by a light source fixed in space added to the stereo depth perception. The resulting stereo pairs could be viewed on the Stereographics stereo screen, or by means of stereo pair photographs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Color Assignment</head><p>The purpose of assigning color to a PET image volume is to help the viewer discern the brightness levels of regions in the volume, their shapes and locations. Human color perception has a resolution of 3 to 4 times lower than that of shape perception. On the other hand, position and depth perceptions are sensitive to color brightness contrast while color combinations are strong activators of shape perception (see <ref type="bibr" target="#b3">[3]</ref> and <ref type="bibr">Livingstone and Hubel [4]</ref>). Thus, to display position, shape and brightness of regions, we have assigned contrasty colors to the four brightness levels. The particular choice is discussed in the following sections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head><p>Eight se&amp; of PET data depicting glucose metabolism in normal subjects and DAT patients were studied. The range of brightness levels corresponding to glucose metabolic rates was classified into four equally spaced regions, high, medium-high, medium-low, and low. In these image volumes, voxels in the high brightness region were assigned the color white, while those in the medium-high and the medium-low brightness regions were painted green and blue. respectively. The grey levels of the green and blue regions were assigned a value of .33 relative to that of the white, which was assigned a maximal value. The color of the low region was chosen to be black. The next section discusses the considerations used to choose the colors taking into account the psychophysics of visual perception. The opacity values assigned to these ranges were l., .33, and .33, for high, medium-high and medium-low regions, respectively. Fully opaque regions block the view of other regions located further away from the observer. To enhance the visibility of structures contained in the image volumes, surfaces were extracted from the data, and reflections from these surfaces, using a single white-light lighting source, were simulated. A view from the top of a reconstructed PET brain image of a normal subject is given in figure 2 in stereo. In this figure, some anatomical structures are apparent.</p><p>It is possible to observe the interhemispheric fissure of the brain, the caudate nucleus, the thalamus, and parts of the cortex associated with high metabolic activity. Assigning red (with the same grey-level value as the white) to the high-level brightness range reduced the depth perception of these brain regions with high metabolic activity. In addition, the perceived size of these red regions was smaller than the apparent size of the same regions colored with white. These differences existed even when the data was visualized without  <ref type="figure">Figure 2</ref>. A stereo pair depicting a three-dimensional image volume of cerebral glucose metabolism of a normal subject. The view is from the top of the brain where the front is on the right-hand side. The range of the metabolic rates is divided into four regions that are represented in four colors, white, green, blue, and black (for the high, medium-high, medium-low, and low rates, respectively). The two bright spots in about the middle are located in the thalamus, and the longitudinal white structures at the bottom right are at the caudate nucleus area. patient. The view is from the top of the brain where the front is on the right-hand side. The range of the metabolic rates is divided into four regions that are represented in four colors, white, green, blue, and black (for the high, medium-high, medium-low, and low rates, respectively). The scale of the range of this patient's metabolic rates is the same as the one of figure 2.</p><p>reflection of simulated light. A view from the top of a reconstructed PET brain image of a DAT patient is given in figure 3 in stereo.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Discussion</head><p>The intent of the physician and researcher viewing PET images is to perceive the degree of metabolic activity at each location of the sample. Representing activity by grey levels could lead to error in perception. One reason for this possibility is the brightness-contrast phenomenon, the dependence of the perceived grey level on the brightness of the neighboring areas 13-41. One way to improve the accuracy of brightness perception is to divide the brightness range into discrete intervals assigning a different color shade to each one of them. In the absence of color capability, one could limit the number of intervals to a small number and use shades of grey.</p><p>To determine the location of a distinctive brightness region, it is necessary to have a brightness contrast between the region and its surroundings <ref type="bibr" target="#b5">[4]</ref>. If the color shades of two neighboring regions are perceived to be equiluminant, the regions may be still distinct visually, but the perception of their location in space using most of the known depth cues (e.g., stereopsis, perspective, relative motion, shading) may not be well defined. The discrimination of figures from the background and the use of colinearity of borders to link them together are also sensitive to contrast.</p><p>High resolution shape discrimination, however, is more sensitive to color (hue) than to contrast.</p><p>Thus, to perceive the degree of brightness and the location of a region, it is preferable to assign to it a color that has a brightness contrast with the colors of the surroundings.</p><p>The white color chosen to represent the high brightness region has a brightness contrast relative to the background composed of black, green, and blue. White is also perceived to be brighter than other colors (e.g., red) with equal value of grey level. In addition, a white spot appears to be larger than darker ones. This phenomenon, called irradiation [51, is responsible for a number of visual illusions. The better contrast and the larger size of the white spots in figures 2 and 3 contribute to an enhanced depth perception of these white regions. When the white was replaced by red with equal grey level value, the stereo perception of these spots was reduced. To enhance the visibility of non-uniformity in the image volume, we have extracted surfaces by calculating the 3-D gradient, and simulated the reflections of white light from these surfaces. In the lighting model used, the reflected light contained two components. The specular part was white, resulting from pure reflection, and the diffuse part had the color of the reflecting surface. Thus, the color of the light reflected from a surface appeared milky. The comparative effect of the white and the red was found to exist with or without lighting simulation. This means that the existence of a white component of the reflected light in these images was not responsible for the phenomenon of reduction of stereo perception caused by replacing the white with red.</p><p>The choice of colors could be further complicated by the fact that in a projected view of the 3-D image volume the colors of individual voxels could be superimposed depending on their location and the direction of view. This could mean that a superposition of a green and red voxels would result in a perceived yellow color. This of course will not exist in a pseudocolor display of 2-D information. However, a choice of colors that yields brightness contrast between neighboring areas would contribute to a better figure/background discrimination, and perception of location and shape in 2-D. The perception of brightness, or metabolic rate, could be aided by the appropriate consideration of warmness of the colors in addition to their brightness contrast (data not shown).</p><p>An additional consideration is the direction of the simulated light. The human visual system is accustomed to view objects illuminated by a light source located above rather than underneath the objects. Otherwise, one may perceive a valley as a mountain. This is less apparent in stereo images than in two dimensional projections. However, we have chosen the location of the light source to be above the illuminated brain image volume.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conclusion</head><p>Taking all of the above considerations into account, one is able to perceive in the images given in figures 2 and 3 the levels of rates of glucose metabolism of regions in the brain and their relative locations. In addition, some of the anatomic structures, such as the interhemispheric fissure, the caudate nucleus, and the thalamus, are apparent.</p><p>This work indicates the power of the method of volume rendering in presenting data of PET in three dimensions. The visualization and, subsequently, the perception of this threedimensional information could be greatly enhanced by employing psychophysical properties of the visual system in designing the data display.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>A sample of two-dimensional PET data used an input to this work. Surrounding the images of cerebral glucose metabolism depicted in this figure is artifactual noise. Each of the individual images is composed of 128 by 128 pixels. (Color Plate 56, Ppge 6 9 )</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>(</head><label></label><figDesc>Color Plate 57, page 469) (Color Plate 58, page 469)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 .</head><label>3</label><figDesc>A stereo pair depicting a three-dimensional image volume of cerebral glucose metabolism of a DAT</figDesc></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>The author would like to acknowledge John D.</p><p>Cappelletti and Stuart C. Hinds for their insight and work on the input and display of the data. The support and advice of Dr. Barbara D.</p><p>Kerlin are greatly appreciated. ?his work would not have been accomplished without the counsel of Drs. Peter Hescovitch, Barry Horwitz, and Cheryl L. Grady, and the data provided to us.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Volume Rendering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hanrahan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="65" to="74" />
			<date type="published" when="1988" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">A</forename><surname>Drebin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Carpenter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Measurement of Regional Cerebral Hemodynamics and Metabolism by Positron Emission Tomography</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Herscovitch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">in Neuromethods</title>
		<editor>Boulton, A., andBaker, G. B.</editor>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<date type="published" when="1988" />
			<publisher>The Humana Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">the Visual System</title>
	</analytic>
	<monogr>
		<title level="j">Sci. Am. =</title>
		<imprint>
			<biblScope unit="page" from="78" to="85" />
			<date type="published" when="1988" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Art, Illusion and</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">S</forename><surname>Livingstone</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Segregation of Form, Color, Movement, and Depth: Anatomy, Physiology, and Perception</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Livingstone</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Hubel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="page" from="740" to="749" />
			<date type="published" when="1988" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Publications</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1965" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Luckiesh</surname></persName>
		</author>
		<title level="m">Visual Illusions</title>
		<imprint>
			<publisher>Dover</publisher>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
