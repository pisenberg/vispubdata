<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/pisenberg/grobid/grobid-0.6.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A Graphical Interface for Robotic Remediation of Underground Storage Tanks&apos;</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brian</forename><forename type="middle">K</forename><surname>Christensen</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Sandia National Laboratories</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lisa</forename><forename type="middle">M</forename><surname>Desjarlais</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">University of New</orgName>
								<address>
									<country key="MX">Mexico</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">A Graphical Interface for Robotic Remediation of Underground Storage Tanks&apos;</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2021-02-19T20:24+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
				<p>Sensor-rich, intelligent robots that function with respect t o models of their environment have significant potential t o reduce the time and cost for the cleanup of hazardous waste while increasing operator safety. An animated graphical interface allows operaton to easily and safely program such robots. Sandia National Laboratories is performing experimental investigations into the application of intelligent robot control technology t o t h e problem of removing waste stored in tanks. This paper describes the experimental environment employed at Sandia with particular attention t o the hardware and software control environment, and the graphical interface. Intelligent system control is achieved through the integration of extensive geometric and kinematic world models with realtime sensor based control. All operator interactions with the system are through fully animated, graphical representations which validate all operator commands before execution t o provide for safe operation. Sensing is used t o add information t o t h e robot system&apos;s world model and to allow sensor based servo control during selected operations. T h e results of a first Critical Features Test are reported and the potential for applying advanced intelligent control concepts t o t h e removal of waste in storage tanks is discussed</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Significant quantities of waste in the form of radioactive sludges and solids are stored in tanks within the</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>U.S. Department of Energy complex at sites such as</head><p>Hanford, Washington, Oak Ridge, Tennessee, Fernald, Ohio and areas outside of Idaho Falls, Idaho. Many of these tanks have reached their design life and some are leaking to the environment. In many instances, the radiological hazard prohibits the entry of human workers into the tanks to perform in-contact manual cleanup operations; therefore, remote technologies will have to be used. Due to uncertainties about the contents of many of the tanks, it is anticipated that significant effort in characterizing the tanks and their contents will be required. In addition, it is believed that, in many cases, environmentally acceptable solutions to cleanup of these tanks may require removal of the waste for subsequent storage in safe facilities.</p><p>Current estimates suggest that the costs for cleanup and closure of the underground storage tanks could be as high as $40 billion and it is envisioned that removal of the waste from these tanks may require 10 to 15 years once the remote technology is in place. It is currently envisioned that this remote technology may be in the form of manually controlled remote manipulator arms which can negotiate around internal structures to deliver cleanup devices to all locations within the tank. The Department of Energy is emphasizing the development of computer controlled robotic technology to decrease the time required for remote cleanup and thus reduce the overall cleanup costs while maintaining high safety standards. Preliminary analyses at Sandia National Laboratories have indicated that computer controlled intelligent robots essentially eliminate operator exposure to radiation during the handling of hazardous materials while reducing the time for materials movement due to high speed programmed operations. Fast, remote materials handling provides significant reductions in facility capital and lifecycle costs with increased operator safety.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Description of Experimental System</head><p>The experimental facility serves to test intelligent robot control technologies for the cleanup of hazardous waste from underground storage tanks. Systems that integrate sensing with computer models to allow automatic operations or assist during manual control are targeted for study, including the development of both modular hardware and software systems. The experimental facility consists of a commercial gantry robot (Cimcorp XR6100) modified to allow hybrid force/position control <ref type="bibr" target="#b3">[4]</ref>. Force control of the large gantry robot is achieved through the integration of a force/torque sensor into the structure of the robot near the robot's wrist and by employing stiffness control to develop the desired forces of interaction with the environment. The test work environment consists of a 2.4 by 2.1 m rectangular tank filled to a depth of 0.6 m with moist sand representing the waste. The test tank con-CH2913-2/90/0000/0449/$01 .OO -1990 IEEE tains both buried objects and pipes as well as structures protruding above the surface of the waste to represent the types of obstacles that would be encountered during characterization and cleanup of actual storage tanks. An extension is attached to the robot arm to allow lateral coverage over the entire surface of the test tank, as shown in <ref type="figure">Figure 1</ref>. The end effector on the robot arm, shown in <ref type="figure">Figure 2</ref>, is instrumented with proximity sensors, a laser structured lighting system, video cameras, ground penetrating radar, a metal detector, and a waste removal system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Underground Storage Tank Workcell</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>SUN Computer</head><p>The tasks selected by Sandia to provide an initial focus for technology evaluation include in situ physical characterization of underground storage tanks as well as the contained waste and the removal of the waste from the tank both for laboratory analysis and as part of the</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Gantry Robot</head><p>JR3 Force Ultrasonlc Sensor Sensors </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Computing Environment</head><p>The distributed computing system employed for the supervisory and realtime control of the experimental facility robotic system is shown in <ref type="figure" target="#fig_2">Figure 3</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">The Graphical Interface</head><p>The human operator charged with control of the systems used for the cleanup of underground storage tanks will be required to perform very tedious and difficult operations. The cleanup operations will be time consuming and must of necessity be performed remotely due to the hazardous nature of the waste. Many of these environments are poorly characterized and great care must be exercised to prevent release of toxic elements into the environment. To aid the operator in the control of remote systems, Sandia has developed a graphical interface to the robot control environment. The foundation of the graphical interface is a time dependent, 3-D geometric model of the robot and its working environment. This geometric model is used to evaluate all commands to the robot system, and the fully animated graphics interface (see <ref type="figure" target="#fig_3">Figure 4)</ref> displays all robot interactions with the environment to the operator. As sensors provide additional information about the robot's working environment, the model is updated and graphically displayed. The geometric world model and the graphics interface to the operator are used in several ways to automatically program the robot system and verify safe operation. For example, prior to the start of a series of programmed operations, the computer compares the desired robot trajectories with the geometric knowledge contained in the world model. Any unsafe trajectory (e.g., a collision between the robot and a tank feature) that is detected is reported to the operator via the graphics interface. The operator can then modify the proposed robot trajectory by interactively manipulating the robot in the graphics interface. These modifications to the robot's trajectory are then verified for safe operation by comparison with the world model and then used by the computer system to automatically reprogram the robot's movements. Only collision-free robot trajectories can be used to automatically program the robot.</p><p>Sandia is also evaluating the technology required for task-level programming without the need for direct operator intervention. Such task-level programming can include automated path planning. An example of such task-level programming within the experimental facility is automated waste removal. In this operation, the computer system is instructed to direct the robot system to remove material, starting at the highest location on the waste surface. The computing system automatically searches the world model (which now contains the sensor mapped 3-D waste surface), plans a collision-free path to position the robot's waste removal end effector at the correct location, and then automatically formulates the program to drive the robot along the proper collision-free trajectory. The planned robot trajectory is presented to the operator using the animated graphics interface to allow verification. The operator may, if desired, modify the computer planned path using the graphics interface as described above. Under no circumstances, however, will the system accept an operator modification that the world model indicates would result in a collision. The graphics interface is also used, in conjunction with the geometric world model, to assist the operator during manual control. A &amp;axis force/torque ball (Spatial Systems) was integrated into the robot's control system to allow joystick control of the robot by the operator. In this mode of operation, the operator's commands are reviewed by the computer system and compared to the world model in realtime. The robot's motions resulting from the operator's joystick commands are displayed on the 3-D animated graphics interface to complement the direct video viewing available for teleoperation. The world model can detect the onset of collisions that are frequently not apparent using direct video viewing methods, and alert the operator via the graphics interface. This is particularly true if the end effector of the robot is free of collision danger (operators typically focus their attention on the end effector) while some other part of the robot arm structure is in danger of collision. The computing system can prevent further transmission of those operator commands that may indeed lead to a collision. This application of Human Assisted Computer Control is used both during offline programming of the robot trajectories by the operator and direct operator control.</p><p>The graphical interface aids the operator by presenting a selective, simplified, and operatorcustomizable view of the world model. Rather than overwhelming the operator with a direct representation of the entire world model and requiring the operator to pick out the useful subset, the graphical interface filters the world model for the operator and presents only that subset which is useful to the task at hand. For instance, the high-resolution map of the surface heights determined by the ultrasonic and structured lighting subsystems is reduced to a low-resolution map and displayed as a mesh. Graphics proves to be an effective means of conveying information. Color highlighting focusea the operator's attention on parts in near or actual collision, an arrow indicates the magnitude and direction of the force being applied to the end effector, and a circle marks the dig location.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Force and Torque Sensing</head><p>During tank characterization and removal of material from the test tank, the forces acting on the robot end effector are monitored by a 6 degree of freedom JR3 force/torque sensor. The Cimcorp XR6100 gantry robot controller has been modified to allow hybrid force/position control <ref type="bibr" target="#b3">[4]</ref>. Force control allows the robot to remove material from the surface under constant contact force. If excessive forces are encountered, they are displayed in the form of a vector at the graphic interface station and the system stops to allow operator intervention. During non-contact operations, force monitoring provides the lowest level of safety for the robot and the environment. If an obstruction is encountered that has not been modeled or detected by the proximity detection or vision systems, contact force sensing is used to report the obstacle and stop the robot.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Ultrasonic Proximity Sensor Sub-</head><p>Two independent ultrasonic proximity systems are employed for ranging, obstacle detection/verification and collision avoidance functions. These systems use the time-of-flight of an ultrasonic echo to measure range to a target.</p><p>The downward-looking ultrasonic proximity ranging (sonar) system is used for mapping the surface of the simulated waste material in the test tank. Two 50 kHz ultrasonic ranging detectors (Contaq Technologies Corp.) which measure range t o surfaces in a 12x field of view are mounted on the sides of the robot end effector (see <ref type="figure">Figure 2)</ref>. The dynamic range is from 15 to 60 cm, with a resolution of 0.2 mm and an accuracy of 1%. Range data from these two sensors are acquired at 6 Hz through a serial port to the VME sensor computer (CPU3 of <ref type="figure" target="#fig_2">Figure 3)</ref>. When combined with robot position information available from the robot controller, the ultrasonic range information provides high resolution 3-D maps of the waste surface.</p><p>An additional ultrasonic proximity sensing system is mounted on the sides and front of the instrumented end effector (see <ref type="figure">Figure 2)</ref> to detect obstacles in the tank in order t o prevent collisions and to add obstacle locations to the world model. Eight sensors are used to cover the field of view to the sides and front of the end effector. Each sensor transmits at 38 kHz into a 60x cone and covers a dynamic range from 5 to 150 cm with a resolution of 0.2 mm. A multichannel ultrasonic sensor controller was designed at Sandia and integrated into the VME sensor computer system. Range data are systems processed from these sensors at 60 Hz. All range data are time averaged for noise discrimination and checked for errors and validity.</p><p>A 2-D geometric model of the horizontal plane above the waste surface scanned by the robot end effector is maintained and shared by the graphics operator interface system and the VME sensor computer. This model divides the horizontal plane above the waste surface into cells approximately 15 cm square, and is composed of a world model and a sensor-based (sonar) map. The world model includes known information about the tank, including the location of walls and known obstacles such as vertical pipes. Each cell in the world model map is either full or empty, based on the current information available to the modeler.</p><p>The 2-D sonar map is maintained and continuously updated during a scan of the tank based on ultrasonic range data. When an object is detected by a sidelooking proximity sensor, and analysis concludes that the echo is from a real object ( v s noise), the robot kinematics are used together with the object range to determine the location of the object in the plane. The sonar map is incremented at this cell location to indicate that an object was observed. Obstacle detection algorithms were developed which include cell neighbor interactions, object shadowing, and dynamic thresholding to automatically identify modeled obstacles from sonar detected objects. Together, these algorithms have provided a robust obstacle detection technique.</p><p>Once an obstacle is detected and confirmed, it is added to the world model and communicated to the graphics interface to display the new obstacle. Path planning can then proceed around the detected obstacle. In addition, if the obstacle is unknown to the model and the path planning has not accounted for its presence, the ultrasonic obstacle detection system can immediately stop the robot if a collision is imminent. Thus, the sonar system provides two levels of safety to the system by informing the modeler of obstacles and by stopping the robot from impending collisions. Further, the ultrasonic system is used to verify the presence and location of obstacles already in the world model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5">Structured Lighting Range Map-Ping</head><p>A structured lighting system, consisting of a laser light source and a camera, was developed to provide an alternative surface geometry mapping technology. Range mapping by structured lighting is a complementary method to surface mapping by sonar. Structured lighting provides good resolution (&lt; 5 mm) and excellent lateral resolution (limited by the width of the laser beam). Unfortunately, since the light source and camera cannot be collinear, shadowing and occlusion may occur, thus limiting the field of view. However, surface features that are undetectable by ultrasonics because the acoustic energy is scattered away from the receiver (e.g., by curved surfaces) may be mapped by structured lighting, since near-normal viewing of the target is not required. The basic principle underlying the use of structured lighting for geometry mapping is that the 3-D location of a point may be found from the intersection of a known vector and a known plane. The plane is provided by the laser light, and the vector is derived from the point on the object illuminated by the laser and an illuminated pixel in the camera. The position of the laser is determined by calibration so that the geometric equation representing the laser plane is known. To determine the three dimensional location of the detected point, the intersection of the vector with the plane of laser light is computed.</p><p>The structured lighting system equipment includes a Cohu video camera and a Newport helium neon laser with a zoom line projector. This line projector contains the cylindrical optics necessary to create the plane of laser light. To improve the signal to noise ratio, a bandpass filter is used on the camera to filter out all light not at the wavelength of the laser (633 nm). The laser is mounted near the robot end effector and illuminates a strip of the tank surface approximately 15 cm wide.</p><p>The camera is mounted 1.5 m back along the robot arm. Computation of the surface map occurs in a VMEbased system consisting of a Force 68030-based processor and Datacube computer vision boards. Data are acquired at 15 Hz.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.6">Metal Detection Subsystem</head><p>A metal detector is integrated into the robot end effector to detect and map metal objects. The Sandia developed driver/detector electronics were designed into a VME computing system, where the metal detector analog signal is amplified and digitized for analysis. Output from the detector is calibrated to eliminate effects due to the test waste material composition and the distance of the coil from the waste material. The metal detector output is mapped and correlated with the results of the waste surface mapping to determine whether a. detected metal object is above or below the surface. Thus, metal detector signal strength, which varies with type and mass of metal, distance to the metal, and the local surroundings, need not be used to determine whether the metal object is above or below the surface. This information is added to the world model and displayed graphically to the operator.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.7">Ground Penetrating Radar Subsystem</head><p>During several characterization scans of the test tank, a ground penetrating radar system (Geophysical Survey Systems, Inc.) was used to perform subsurface mapping of the tank. The 900 MHz radar antenna is fielded on the robot end effector and is contained in an 8 x 18 x 33 cm package, weighing approximately 2 kg. The radar control electronics and display system are located away from the robot in the sensor control center. Ground penetrating radar at the applied frequency is capable of penetrating a few meters into the tank and is sensitive to changes in subsurface density and dielectric constant. Thus, metals, voids, buried objects, layered media, moisture variations, and other subsurface interface variations are detectable features. Radar echoes are returned from these changes in the media and are displayed as features in the radar image. Horizontal scanning of the test tank with the antenna yields a depth vs lateral distance radar image. Calibration with known materials and expert interpretation of the radar images are required. A variety of antenna sizes and frequencies are available for varying the penetration depth and lateral resolution of the system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.8">Ancillary Systems</head><p>Three CCTV video display systems are employed in the experimental facility to allow remote operator monitoring of the system operations. One camera is mounted on the end effector (see <ref type="figure">Figure 2)</ref> for closeup observation of the environment. Two video cameras with gimbal mounts and zoom lenses are mounted near the test tank for orthogonal viewing of the facility operations. Waste removal is accomplished by the end effector which incorporates a rotating brush to loosen material and a vacuum system to remove the material to a remote canister.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">System Operation and Results</head><p>The first Critical Features Test performed in the experimental facility involved mapping the surface and subsurface characteristics of the test tank as well as simulating waste removal operations. The time from first concept to execution of the first Critical Features Test was five months, even though physical modifications to the robot arm and extensive integration of new sensing modalities and control concepts were performed. Sensor based mapping was used to verify the location of known objects and to add unknown objects to the computer model of the test tank. The geometric world model representing the test tank, its contents, and the robot was displayed to the operator as an animated graphics representation, as shown in <ref type="figure" target="#fig_4">Figure 5</ref>. Ultrasonic and structured lighting sensing were used to correlate the location of actual objects in the test tank with those represented in the geometric world model and to generate maps of unmodeled objects such as the surface of the waste. The world model was updated with new information to allow automatic programming of robot motions if desired. In addition, a metal detector and ground penetrating radar were used to determine the location of buried objects. When the metal detector results were correlated with the surface profile maps resulting from the ultrasonic and structured lighting surface mapping analyses, subsurface objects could be distinguished from surface objects.</p><p>In addition to tank characterization, the experimental facility evaluated sensor based waste removal operations. Force control ensured that a rotating brush mounted at the end of the gantry robot arm to dislodge the simulated waste contacted the waste surface appropriately. The dislodged waste was removed by vacuum. During characterization of the tank, sixteen 3 m scans of the surface were obtained at a nominal spacing of 15 cm. Output from the metal detector map of the waste surface is shown in <ref type="figure">Figure 6</ref>, which shows the 16 scans and 2.5 cm resolution along each scan. Buried pipes, as well as unknown surface pipes and bolts, are detectable features in the metal intensity map.</p><p>The sonar map of the waste surface is shown in  The surface map obtained from the structured lighting system is shown in <ref type="figure">Figure 9</ref>, using an 8 cm resolution and a perspective similar to that in <ref type="figure" target="#fig_6">Figure 7</ref>. Again, the trench and mound are observed. Shadowing obscured the view in some areas of the tank such as the area behind the vertical pipe indicated in <ref type="figure" target="#fig_4">Figure 5</ref>.</p><p>This shows the importance of employing multiple sensing modalities when mapping unknown regions.</p><p>The ground penetrating radar system was shown capable of resolving a 5 cm buried pipe at 10 cm depth, and an 18 cm diameter metal plate buried 30 cm deep.</p><p>Other detectable features included the bottom of the test tank, the concrete floor about 1 m below the antenna, layered features beneath the concrete floor, and a granite block buried in the test tank. The resulting automatically generated world model, represented graphically, is shown in <ref type="figure" target="#fig_4">Figure 5</ref>. Note that all major geometric features are represented. The robot end effector is shown in position near the highest point of the surface of the waste, indicated by the circle. This robot operation resulted from the tasklevel request to the system to begin removing waste. The computing system has searched the mapped waste surface, located the highest point, automatically programmed the required robot trajectories to accomplish the waste removal task and is now informing the operator of the planned robot movements prior to initiating robot movement.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusions</head><p>Model based control of remote systems can accelerate tasks such as the removal of waste stored in underground storage tanks when compared to remote manual methods while increasing system safety. Figure 9: Structured lighting surface map systems a t the task level. This greatly reduces the requirements for detailed, step-by-step programming by skilled robot programmers. When coupled with graphics animation systems, geometric models allow the operator to interact with the robot system through a graphics interface. The geometric model can interpret operai tor manipulations of the graphical representation to automatically program the robot t o respond in the manner desired by the operator. In addition, the world model can be used to validate robot programs prior t o execution and display the results graphically t o the operator to ensure the desired robot motions are being executed.</p><p>The geometric world model can also be used to validate operator commands to the robot system t o ensure safe operation during manual control. Graphical display of the results of operator's robot commands can provide operators with perspectives not available from the direct video viewing commonly used in teleoperation of remote systems. This increases system safety by warning of impending collisions. This is especially important for impending collisions away from the robot end effector, where the operator's attention is frequently focused. If an operator's command could result in a collision, the computing system, with reference to the world model, can prevent execution of the command by the robot and communicate the source of the problem to the operator through the graphics interface.</p><p>Realtime sensor based mapping can be used t o expand the knowledge base contained in the world model by characterizing unknowns such as the surface geometry of the contained waste. Various sensors such as ultrasonic proximity sensors, laser baaed structured lighting, metal detectors, ground penetrating radar, etc. can be used to interrogate the environment and increase the fidelity of the world model. In addition, realtime sensing such as force/torque and proximity control can allow the robot t o interact with the environment in a safe manner even when under direct operator control.</p><p>Finally, the use of modular computing and software environments greatly decreases the time for system development. The Sandia developed Robot Independent Programming Environment, for example, allows reuse of previously develoned and validated software for much of the system control. Typically, much of the control software for intelligent robot systems is very similar from application t o application and only a relatively small portion of the overall system software is application specific. In addition, as more application areas are addressed, the libraries of available system control software grow. In a properly designed, modular software environment much software can be reused directly from project to project.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Acknowledgements</head><p>This project resulted from the efforts of several people. The design of the VMEbased custom electron-ics for the ultrasonic sensors and metal detector was done by Pablo Garcia. Mechanical design of the robot end effector was done by Alan Morimoto. Bill Drotning developed the ultrasonic control and analysis software. Colin Selleck developed the structured lighting system hardware and software. The video system was designed and implemented by John Webb, who also set up the radar system. The robot system control software and client/server communication software were developed by David Miller and William Davidson. Jill Werner assisted in the robot control programming. Jim Littlejohn and Jim Bailar provided electrical and mechanical technical assistance.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>'</head><label></label><figDesc>This work was s u p p o r t e d by t h e U.S. Department of Energy under C o n t r a c t DEAC04-76DP00789.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 :Figure 2 :</head><label>12</label><figDesc>Robot extension arm, end effector, and test tank Instrumented end effector on robot</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Computing Environment tank cleanup process. Both fully automatic and manual robot control technologies are being evaluated and demonstrated. The Sandia developed concept of Human Assisted Computer Control[l] is employed during manual control of the robot.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Geometric world model of robot and test tank (Color Plato 190, page 401)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 :</head><label>5</label><figDesc>Geometric world model of robot, test tank, and contents (cdor Pbto 181, p8ga 491)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 7 .Figure 6 :</head><label>76</label><figDesc>Pronounced features include a trench in the foreground and a mound on the left. The sharply defined vertical spike is a vertical pipe which was detected as an unknown obstacle and passed over by the end effector. The sonar surface map may also be displayed as contours of equal elevation as shown inFigure 8. In this view, the trench (lower left) is clearly defined as rectangular in shape with a depth of 13 to 15 cm. The elongated contour labelled "36" (36 in.) at the center of the tank correlates well with the metal intensity peaks in this region; the feature is in fact a 5 cm diameter pipe Metal intensity surface map</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 7 :</head><label>7</label><figDesc>Sonar surface map laying on the surface.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head></head><label></label><figDesc>Advanced 3-D geometric modeling concepts can allow robot motion planning and thus, automatic programming of robot Figure 8: Sonar surface contour map (Color Plato 192, pago 491)</figDesc></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">An Alternative Control Structure for Telerobotics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Boissiere</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Harrigan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1989 NASA Conference on Space Telembotics</title>
		<meeting>the 1989 NASA Conference on Space Telembotics</meeting>
		<imprint>
			<date type="published" when="1989" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">141</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">IROS, An Intelligent Robot Operating System</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Davidson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1990" />
		</imprint>
	</monogr>
	<note>to be published</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">An Object-Oriented Environment for Robot System Architures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Lennox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE International Conference on Robotics and Automation</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">352</biblScope>
			<date type="published" when="1990" />
		</imprint>
	</monogr>
	<note>Pmceedings of fhe</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Force Servocontrol of a Commercial Gantry Robot</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Petterson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Jones</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Robots 12 Conf. Proc</title>
		<meeting><address><addrLine>Detroit, MI</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1988" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
