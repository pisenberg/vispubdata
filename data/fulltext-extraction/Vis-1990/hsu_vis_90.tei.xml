<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/pisenberg/grobid/grobid-0.6.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">SUPERPOSING IMAGES WITH SHADOW CASTING</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><forename type="middle">C</forename><surname>Esu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Electrical Engineering</orgName>
								<orgName type="institution">University of Florida Gainesville</orgName>
								<address>
									<postCode>32611</postCode>
									<settlement>Florida</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Staudhammer</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Electrical Engineering</orgName>
								<orgName type="institution">University of Florida Gainesville</orgName>
								<address>
									<postCode>32611</postCode>
									<settlement>Florida</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">SUPERPOSING IMAGES WITH SHADOW CASTING</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2021-02-19T20:25+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
				<p>Algorithms are presented to render dynamic foreground images with shadows cast on static background scenes. The algorithms are based on the ray-tracing technique. We can produce complex and shaded animation with a lower cost. The target display device for these algorithms is a two-channel display in which one is for the background and the other is for the foreground.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>The display of dynamic image sequences can be enchanced by superposing a dynamic image on a quasi-static background. For instance, in robotic simulations, as we post a background scene on the display, the detail of the environment on the background adds more realism to the movement of robots. Moreover, if we render the robots' shadows cast on the background, we will increase the depth perception clues in the animation.</p><p>In a dynamic natural scene, some objects move relative to others. There are usually foreground objects and a background scene. Animation producers, such as Disney Studios, created multi-plane machines for superposing foreground on background images that simulate realistic scenes by moving such planes relative to another. Based on the above observation, the UF Computer Graphics Research Laboratory has designed an economic hardware, the run-length frame buffer display, for playing back animations in real-time [9, 121. The device is composed of three parts, as shown in <ref type="figure" target="#fig_7">Figure 1</ref>. A foreground generator, the run-length decoder, is used to produce the dynamic part of the image. A background generator, a relatively intelligent frame buffer, displays the quasi-static image. The third part is an arbitrator for combining the two portions.</p><p>This display is an on-line peripheral device to a VAX 11/780.</p><p>An animated scene can be formed by superposing two partial images. One is the CH2913-2/90/0000/0298/$01 .OO -1990 IEEE background that may be a very complex quasi-static scene.</p><p>The other is the foreground which consists of moving objects occupying part of the animated image area. Dynamic image sequences generated in such a way can be played back in real-time by posting the static background to the frame buffer display once and then sending dynamic foregrounds to the run-length decoder repeatedly.</p><p>The small amount of run-length codes of each foreground causes no difficulty for the data transmission.</p><p>Algorithms used to render the dynamic image of the foreground i are presented in this paper.</p><p>We first discuss the special animation effects produced by the superposing technique with ray tracing [15]. Then two algorithms are described which are tailored for ray tracing to render the dynamic images. One is an approximate bounding box algorithm used to reduce the image rendering time, and the other is the shadow generation algorithm which casts the dynamic objects' shadows onto the background scene.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">. Motion Effects Using superposing</head><p>Typically, if a superposing machine is equipped with two image planes--the foreground and the background--the dynamic objects on the foreground can move only relative to the background and in front of the background. They are unable to move into the background. Such a motion effect is not fully three-dimensional. Even if the machine is equipped with more than two image planes, the freedom of the dynamic objects' motion is still limited to be on the image plane on which they are located. The algorithm we developed produce animated image sequences with fully 3D motion effects. We can freely move the dynamic objects on the foreground in and out of the background scene.</p><p>As the dynamic objects are moved through the scene on the background, sometimes they may obstruct static objects in the background and hide behind them at other with Ray Tracing times.</p><p>Therefore, during rendering the image of the foreground, the hidden-surface removal procedure has to take account not only of the dynamic objects but also the static objects. The hidden-surface method used to determine the visibility of the dynamic objects on the foreground must be able to economically handle many static objects .</p><p>There are various approaches for hidden-surface removal such as the Z-buffer method, depth-sorting and area-subdivision [13, 71. Their efficiencies depend on the characteristics of a particular application. For instance, the depth-sorting method is a highly effective approach for scenes with few objects due to the fact that such scenes have few surfaces that overlap in depth. Ray tracing acts as a hidden-surface method as well as an illumination model. Ray tracing determines the visibility of each pixel on the image plane by ray-object intersection tests and finding the nearest intersection relative to the view point.</p><p>Although ray-object intersection tests, in general, are time consuming, ray tracing is suitable for hidden-surface removal in rendering the foreground image. That is because many techniques are available to accelerate ray tracing [ 1-5, 8, 10, 11, 141. Moreover, the bounding box algorithm discussed in the next section avoids tracing many unnecessary rays. These algorithms can save a great amount of time during rendering of the foreground image.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Approximate Bounding Box Algorithm</head><p>The image rendering time using ray-tracing techniques greatly depends on the image resolution. For dynamic objects that occupy only part of the whole image area, rendering the dynamic image of the foreground by firing rays throughout the whole image area is obviously not an economical approach. Actually, one needs to render only those specific image areas on CO I or Hon I t o r which the dynamic objects will appear. But those specific image areas have to be known before ray tracing can be applied.</p><p>A bounding box scheme can isolate the specific image areas relative to the dynamic objects from the image of the foreground. First, a bit map is created, which is in one-to-one correspondence to the dynamic image of the foreground.</p><p>Each dynamic object is tightly bounded in a box. Then each dynamic object's bounding box is projected onto the bit map under the same viewing conditions used to render the image of the background. The projection of each dynamic object's bounding box marked on the bit map is called the dynamic object's white area on the foreground. If a dynamic object is visible under the given viewing conditions, it must appear within the white area. In rendering the dynamic image of the foreground, we simply need to fire rays only at the white areas.</p><p>Before ray tracing takes place for the white areas, the dynamic objects need to be inserted into the background's object data structure. We use an irregular cutting 3D grid scheme to organize the objects on the target scene <ref type="bibr">[ 8 ]</ref> .</p><p>The algorithm for rendering the dynamic image of the foreground is in principle as follows: through each pixel of the white areas : if the ray directly hits any one of the dynamic objects, then complete the ray's trace and paint the pixel with the returned color: else terminate the ray's trace and do not paint the pixel.</p><p>We note that the ray's trace for each pixel of the white areas does not always need to be completed, if the ray does not directly hit any one of the dynamic objects. Either one of the following two reasons can explain why the ray's further trace for that pixel can be ignored immediately. One is that the dynamic objects are invisible at that pixel. Though they are projected at that pixel, they are obstructed by other static objects. The other reason is that the pixel is in the void parts of the white areas in which the dynamic objects do not appear. That is because the white areas are the projections of the dynamic objects' bounding boxes, not the projections of the dynamic objects themselves.</p><p>The tighter each bounding box of the dynamic objects is, the fewer voids there will be in the white areas. If there are fewer void areas, the rendering cost of the dynamic image of the foreground shall be lower, since less ray tracing is wasted on the void areas.</p><p>Hence, the slab-plane bounding scheme [ 101 is adopted to construct bounding boxes to fit the dynamic objects, since this scheme can flexibly construct bounding boxes as tightly as necessary.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">. shadow Generation Algorithm</head><p>Rendering the dynamic objects' shadows is like rendering the image of the dynamic objects themselves. One does not need to fire rays throughout the whole image area since most of the time the dynamic objects' shadows occupy only a small part of the whole image area. But one cannot use the same method to predict the shadows' locations on the image plane similar to the prediction of the dynamic objects' locations. That is because the shadows' locations are not only subject to the view point, but also to the light source. The algorithm for casting dynamic objects' shadows onto the static background is also based on the ray-tracing technique, but the ray is traced in a forward manner instead of the the conventional backward manner.</p><p>Shadows can be considered as the invisible areas of the scene viewed from the position of the light source. An object's shadow could be located by tracing those rays which are fired from the light source toward the object. When the rays hit the object, they penetrate through the object and keep flying forward.</p><p>As the rays continue to move in object space, they either fly out off the object space or hit other objects on which shadows are thus cast. Then one can determine the shadows' visibility by directing those shadow rays toward the view point.</p><p>If they are intercepted by other objects before they reach the view point, the shadows are invisible; otherwise, they are visible.</p><p>The algorithm based on forward ray tracing to cast the dynamic objects' shadows onto the background scene is described as follows :</p><p>(1) Set the view plane as viewing the scene from the light source. ( 2 ) Mount the window through which the dynamic objects are visible.</p><p>( 3 )</p><p>Choose the sampling rate for sampling the dynamic objects I shadows.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>( 4 )</head><p>Trace the rays starting from the light source back to the view point. (5) Cast and patch the shadows onto the final image.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Betting the Light Plane</head><p>First, a view plane is set up between the light source and the target scene as in viewing the scene from the position of the light source. The view plane set in front of the light source is also called the light plane, because rays will be fired from it toward the object space to locate the dynamic ob] ects shadows. The light source in this work is assumed to he parallel light and located outside the scene. Hence, the light plane can be placed anywhere outside the object space and its normal is in the direction of the light source. An W coordinate system is used on the light plane.</p><p>It can be set up at arbitrary orientation, but the line from the origin of the W coordinate to the origin of the object space's coordinate is parallel to the direction of the light source.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">. 2 . Mounting the Light Window</head><p>In setting up the light plane, a further concern is the size and the location of the window on the light plane. The window on the light plane is called the light window in order to distinguish it from the view window on the view plane that is set in front of the view (eye) point.</p><p>A parallel projection in the direction of the light source is used to project the vertices of all the dynamic objects' bounding boxes into the light plane. The maximum and the minimum U and V coordinates of those projecting points are used to form the light window. Therefore, as we trace rays from the light source through the light window, we shall be able to locate all the dynamic objects' shadows without missing any one of them.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">. 3</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Choosing the Sampling Rate</head><p>Since forward ray tracing is an image sampling technique, if the sampling rate chosen to render the shadows was not high enough, the constructed shadows might appear fragmentary. On the other hand, if a higher sampling rate were chosen, though the ..</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>(M x N resolution)</head><p>fragmentation problem might vanish, the shadow generating cost would be increased. Therefore, one must carefully choose the sampling rate for forward ray tracing.</p><p>Suppose that the backward ray tracing for rendering the quasi-static image of the background is carried out by firing M X N rays throughout the view window, and the front surface of the frustum of the view volume, which is clipped by the hither plane, has the size of XL x YL as showm in <ref type="figure">Figure 2</ref> . Every backward ray fired from the view (eye) point toward the object space will represent a small view volume with the shape of a truncated pyramid. This pyramid's front-truncated surface has the size (XL/M) x (YL/N). If the size of the light window is equal to UL x VL, then we choose to process the forward ray tracing by firing Mm x Nn rays in the UL x VL light window, where</p><formula xml:id="formula_0">U L / M m X L / M V L / N n Y L / N .</formula><p>and Such a sampling rate is called the basic sampling rate for the forward ray tracing. Using the basic sampling rate, each ray fired from the light window will represent a small light volume with the shape of square pipe whose perpendicular cross-section has the size of (UL/Mm) x (VL/Nn).</p><p>The basic sampling rate is described later in more detail. A bit map of size Mm x Nn, called the light buffer, is used to represent the light window. Then the parallel projection in the direction of light source projects each dynamic object's bounding box onto the light window. The projection of each bounding box is marked on the light buffer, and we call it the dynamic object's white area on the light buffer. Therefore, as we exerclse forward ray tracing to generate the dynamic objects' shadow, we simply need to fire rays at all the white areas of the light buffer.</p><p>Since the dynamic objects are relatively small, the size of the light window, UL x VL, in general will not be larger than the size of the front-truncated surface of the view volume, XL x YL. According to the definition of the basic sampling rate, the resolution of the light buffer, Mm x Nn, will not be greater than the resolution of the image of the foreground, M x N. In case the number Mm x Nn is relatively larger than the number M x N, the larger light buffer can be subdivided into several smaller ones. Then each of them is processed one at a time .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">. . Tracing the ahadow Ray</head><p>For each pixel in the white areas of the light buffer, a ray is fired from the pixel in the direction of the light source toward the object space. Once the ray departs the light buffer, if the ray immediately hits any one of the dynamic objects, it is allowed to pierce that dynamic object and to keep moving forward. Then if the ray hits another object, it will cast a shadow on that object, and we will call this ray a shadow ray. Note that the shadows on the dynamic objects, which are cast by the objects in the static background, are calculated by the bounding box algorithm described in the last section.</p><p>A Mm x Nn array, called the shadow buffer, which is in one-to-one correspondence to the light buffer, is used to record whether a ray fired from the white area becomes a shadow ray.</p><p>If the ray becomes a shadow ray, the distance from the ray's origin to the hit point at which the shadow is cast is recorded in the corresponding element in the shadow buffer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>When a shadow ray hits an object whose surface normal at the hit point</head><p>is approximately parallel to the direction of the light source, the shadow thus generated will have the approximate size (UL/Mm) x (VL(Nn)</p><p>Then we can determine the shadow's visibility by directing the shadow ray toward the view point.</p><p>If the shadow is visible from the view point, it should appear not more than a single pixel on the foreground image as shown in <ref type="figure">Figure 3</ref>. This is because the size of this shadow is about the size of the front-truncated facet of one pixel's view volume, which equals (XL/M) x (YL/N).</p><p>Thus the basic sampling rate is high enough for shadows falling on surfaces whose normals are approximately parallel to the direction of the light source.</p><p>We note from <ref type="figure">Figure 3</ref>, that if the shadow is cast on the surface whose normal is not parallel to the direction of the light source, the shadow might have a size much larger than (UL/Mm) x (VL/Nn). Such a shadow might appear at more than one pixel on the foreground image, if it is visible from the view point. This means the basic sampling rate is not high enough to define such shadow areas. A higher sampling rate is needed there in order to render those shadows in more detail.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5.">Checking and Patching the Shadows</head><p>After shadows are generated with the basic sampling rate, they have to be checked to determine whether additional samples are needed to depict them in more detail. Since shadows are 2D elements, every four adjacent shadow rays (i.e. 2 x 2) , which are marked on the shadow buffer, are examined together. suppose that R1, R2, R3 and R4 are 2 x 2 adjacent shadow rays. R1 is adjacent to R2 in the U direction, and R3 to R4 in the U direction. R1 is adjacent to R3 in the V direction, and R2 to R4 in the V direction. As shown in <ref type="figure" target="#fig_7">Figure 4, these four adjacent  shadow rays, having their origins at point  01, 02, 03 and 04, cast shadows at point P1,  P2, P3 and P4, respectively.</ref> The shadow area Pl-P2-P3-P4 is composed of either an integrated shadow or a number of disconnected, smaller shadows, depending on the environment encountered.</p><p>Similarly, we can obtain mm2, nnl and nn2 which represent the number of additional rays which are needed to be fired for the 03-04 side <ref type="bibr">(</ref>  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>= T T / u u</head><p>If ml is greater than one, this means we need to increase the sampling in the U direction in order to render the shadow area Pl-P2-P3-P4 in more detail on the Pl-P2 side.</p><p>Since a shadow with the size of (UL/Mm) x (VL/Nn) appears no more than in a single pixel in the final image, we estimate that mml number of additional rays are needed to be fired for the 01-02 side <ref type="bibr">(</ref>  Additional rays are fired through this mesh in order to render the shadow area Pl-P2-P3-P4 in more detail as shown in <ref type="figure">Figure 5</ref>. The shadow area will not appear fragmented as it is projected onto the image plane under the given viewing conditions.</p><p>Often it happens that for every 2 x 2 adjacent elements on the shadow buffer only three of the four are marked as shadow rays. when this case is encountered, a pseudo shadow ray is created and is jointed with those three adjacent shadow rays to form a 2 x 2 pattern. That is because every four adjacent shadow rays are treated at a time.</p><p>If these three adjacent shadow rays, for instance, are R1, R2 and R3 as described in the above example but without R4, we will create a pseudo ray to substitute R4 by duplicating R3 and identify it as (R3). That is economical enough for constructing computer animation of image complexities shown here.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">summary and conclusions</head><p>Algorithms for rendering complex and shaded animation sequences were described. The target display device for these image rendering algorithms is a multi-channel display based on the superposing technique realized in hardware. An animation sequence is displayed by superposing a dynamic foreground upon a static background. The static background can be a very complex scene, and the dynamic foreground can be an image with a simple to medium complexity. These two algorithms were developed based on ray tracing. Conventional superposing techniques can produce animated sequences in which dynamic objects move relative to other image parts by using depth information.</p><p>We avoid 2-buffering by the use of the bounding box algorithm and simplified ray-tracing, and we can produce a fully 3D motion effect.</p><p>The dynamic objects on the foreground can move freely in the space of the background scene, not just in front of or behind the background scene. In addition, using the shadow generation algorithm, we can cast the dynamic objects' shadows onto the background scene.</p><p>That cannot be computed by the conventional superposing techniques. Casting the dynamic objects' shadow onto the background scene, we vastly improve depth clues in animation.</p><p>In general, the objects on the foreground are opaque objects.</p><p>Scenes on the background cannot be seen through the objects on the foreground.</p><p>In this algorithm, the objects on the foreground can be transparent objects, since our rendering algorithms are based on the ray-tracing technique which allows transparency. Also the dynamic objects on the foreground can have reflecting surfaces.</p><p>Similarly the background scene can also be reflected on the dynamic objects' surfaces.</p><p>Currently the shadow generation algorithm only calculates the shadows cast by parallel light sources. The computation of shadows cast by point light sources is possible based on the same algorithm.</p><p>But the procedures of choosing the basic sampling rate and patching the final shadows needs more careful examination.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>Figure 1</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>Insert the dynamic objects into Bound each dynamic object with a Locate each dynamic object I s white Shoot a ray from the view point the 3D grid. box. area on the foreground.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>Figure 2</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>Figure 3</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>I</head><label></label><figDesc>U direction), the 01-03 side (V direction) and the 02-04 side (V direction) , T1 -T2 I U U = U L / M m SS**2 = TT**2 + W * * 2 With ml = SS / W, we can obtain ml = sqrt(TT**2 + UU**2) / UU = sqrt(TT**2 / W * * 2 + 1)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head></head><label></label><figDesc>U direction) , where m m l = Lml + .5J -1 Then a uniformly divided mesh, nun X nn, is created to fit the area 01-02-03-04 on the light window.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>1 behind</head><label>1</label><figDesc>Then R1, R2, R3 and (R3) are treated together as f o u r adjacent shadow rays. Therefore Rl-R2 and R3-(R3) become the two pairs of adjacent shadow rays in the U direction. Rl-R3 and R2-(R3) become the other two pairs of adjacent shadow rays in the V direction. Then we compute mml, "2, nnl and nn2 f o r Rl-R2, R3-(R3), Rl-R3 and R2-(R3) , respectively. Obviously, mm2 = 0 because there is no need to fire additional rays on the R3-(R3) side. coded in C language and run on a VAX-11/780 using Unix BSD 4.2. In order to demonstrate the capability of these algorithms, a model of a tree with recursively grown branches, which was provided by a procedural database generator [6], was used to represent the complex background scene. A specular sphere circulated around the tree. The circulating path of this sphere lay on a plane which slanted at 15 degrees to the horizontal. The path was equally divided into 48 steps. The animation test was rendered in the full color spectrum, but only displayed monochromatically with the intensity from 0 to 255. This is due to the display image frames, which represent a complete circulation of the sphere around the tree, are shown in Figure 6. All the images were rendered at a resolution of 512 x 512 pixels. But this presentation, every one of them was scaled down to the resolution of 128 x 128 pixels. Observing this animation sequence, one should notice that the moving sphere sometimes obstructs the tree and other times hides behind it. The dynamic sphere cast two shadows on the background due to the two light sources. Each frame was formed by superposing a dynamic image of the sphere on the static image of the tree. The 48 consecutive foreground images are shown in Figure 7. Several frames ofthis animation sequence displayed at a resolution of 482 x 512 are also shown. Figure 8-A shows the 24th frame in which the sphere is partially hidden P2 the tree, and Figure 8-B shows the foreground parts. Figure 9-A and 9-B show the composite image and the foreground of the 44th image frame. The sphere's shadows are cast not only on the ground but also on the tree trunk. The total image rendering time of these 48 dynamic images, which included time for computing the dynamic sphere's location and converting the images from pixel-by-pixel formats into run-length codes, was 4 hours and 21 minutes. The image rendering time for the static image of the tree was 2 hours and 15 minutes. The total run time of this animation sequence was 6 hours and 36 minutes. In other words, the average timing cost of one animated frame was about 8.25 minutes.</figDesc></figure>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Fast</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Ray</head><p>pp. 14-20. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Haines, E, I@A Proposal for Standard Graphics Environments," IEEE Computer</head></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Fast Ray Tracing by Ray Classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Alto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kirk</surname></persName>
		</author>
		<idno>Vo1.21</idno>
	</analytic>
	<monogr>
		<title level="j">I@ ACM Computer Graphics</title>
		<imprint>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="55" to="64" />
			<date type="published" when="1987-07" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">ARTS: Accelerated Ray-Tracing System,*@ IEEE Computer Graphics and Applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Fujimoto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Takayuki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kansei</forename><forename type="middle">I</forename></persName>
		</author>
		<imprint>
			<date type="published" when="1986-04" />
			<biblScope unit="volume">6</biblScope>
		</imprint>
	</monogr>
	<note>3. Glassner, A. S. , &apos;@Space Subdivision for</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
