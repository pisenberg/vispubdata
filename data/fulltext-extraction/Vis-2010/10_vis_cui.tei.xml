<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/pisenberg/grobid/grobid-0.6.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A Curved Ray Camera for Handling Occlusions through Continuous Multiperspective Visualization</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2010-10-24">24 October 2010</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Cui</surname></persName>
							<email>cui9@purdue.edu</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Rosen</surname></persName>
							<email>prosen@sci.utah.edu</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Voicu</forename><surname>Popescu</surname></persName>
							<email>popescu@purdue.edu</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christoph</forename><surname>Hoffmann</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Computer Science Department</orgName>
								<orgName type="institution">Purdue University</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">University of Utah</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">A Curved Ray Camera for Handling Occlusions through Continuous Multiperspective Visualization</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2010-10-24">24 October 2010</date>
						</imprint>
					</monogr>
					<note type="submission">received 31 March 2010; accepted 1 August 2010; posted online</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2021-02-20T19:55+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Alleviating occlusions</term>
					<term>camera model</term>
					<term>curved rays</term>
					<term>multiperspective visualization</term>
					<term>interactive visualization</term>
				</keywords>
			</textClass>
			<abstract>
				<p>Most images used in visualization are computed with the planar pinhole camera. This classic camera model has important advantages such as simplicity, which enables efficient software and hardware implementations, and similarity to the human eye, which yields images familiar to the user. However, the planar pinhole camera has only a single viewpoint, which limits images to parts of the scene to which there is direct line of sight. In this paper we introduce the curved ray camera to address the single viewpoint limitation. Rays are C 1-continuous curves that bend to circumvent occluders. Our camera is designed to provide a fast 3-D point projection operation, which enables interactive visualization. The camera supports both 3-D surface and volume datasets. The camera is a powerful tool that enables seamless integration of multiple perspectives for overcoming occlusions in visualization while minimizing distortions.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Almost all images used in visualization are computed with a planar pinhole camera (PPC). One reason for this is that the PPC models the human eye well, producing images that resemble what users would see if they were actually looking at the dataset to be visualized.</p><p>Another reason is simplicity: software and hardware implementations of PPC rendering algorithms allow visualizing complex 3-D datasets at interactive rates. However, the simplicity of the PPC model also brings three important limitations. First, the PPC has a limited field of view. Second, the sampling rate of the PPC is uniform over its entire field of view. Third, the PPC has only a single viewpoint, i.e. the pinhole where all rays converge. In this paper we address the single viewpoint limitation. The PPC can only sample data to which there is direct line of sight from the pinhole. In the context of complex 3-D datasets, occlusions hide regions of interest and reduce the visualization payload of PPC images. The problem of occlusions has been addressed in visualization using a variety of approaches. One approach is to render the occluding layers transparently, or to cut a hole into the occluding layers to reveal the hidden data subset. Such transparency and cutaway techniques work well when the number of occluding layers is small and when a summary representation of these layers is acceptable. A second approach is to distort the 3-D dataset such that the alignment between the viewpoint, the occluder, and the data subset of interest is broken. The approach has the advantage of a clear and complete visualization, but specifying a dataset distortion that achieves the desired disocclusion effect while minimizing the visualization distortion is challenging.</p><p>Another approach is to simply rely on the user to navigate the camera around occluders interactively in order to establish a direct line of sight to data subsets of potential interest. Such sequential visualization can be inefficient. When the disoccluded data subset turns out to be of no interest, the camera path has to be retraced which is wasteful and can confuse the user. The single viewpoint limitation has also been addressed by using several PPC images simultaneously. However, the approach suffers from visualization discontinuity between individual images. The user cannot monitor all images in parallel and has to spend considerable cognitive effort to adapt sequentially to each one of the many visualization contexts.</p><p>Multiperspective visualization is a promising approach based on integrating data sampled from multiple viewpoints into a single image. The multiple viewpoints are integrated tightly which alleviates the visualization discontinuity problem of multiple individual images. Like in the case of the dataset distortion approach, multiperspective visualization amounts to a warp of global spatial relationships between data subsets. However, multiperspective visualization allows specifying the desired disocclusion effect directly in the image, as opposed to indirectly, through a dataset distortion. Finally, multiperspective visualization does not preclude but rather enhances interactive exploration of datasets. The multiperspective image provides a preview of data subsets to come which improves interactive visualization efficiency.</p><p>Multiperspective visualization has challenges of its own. The multiperspective image is computed using a non-pinhole camera model that does not project 3-D lines to image plane lines, so one challenge is achieving the desired disocclusion effect while minimizing visualization distortions. The non-pinhole camera model is considerably more complex than the PPC model, so a second challenge is to achieve adequate rendering performance to support interactive visualization and dynamic datasets. Eliminating the single viewpoint constraint of the PPC model results in a multidimensional camera model design space. Whereas for the PPC model the only intrinsic parameter of significant relevance in shaping the visualization is the focal length, optimizing multiperspective visualization requires tuning a large number of parameters. Consequently a third challenge is to specify the camera model that best visualizes a given dataset from a given location.</p><p>We introduce a novel multiperspective visualization technique based on the curved ray camera (CRC). The CRC is designed to address the challenges of multiperspective visualization described above. The CRC integrates multiple viewpoints seamlessly. The curved rays allow for a progressive transition between one viewpoint and the next. A CRC ray is a sequence of line segments connected by conic curve segments. Each conic connects consecutive line segments with C 1 continuity, which alleviates visualization distortions. The CRC provides a fast projection operation which allows rendering 3-D surface datasets efficiently by projection followed by rasterization, with the help of graphics hardware. The rays of the CRC can be traced inexpensively which enables visualization techniques that require ray casting, such as volume rendering. We have developed several CRC constructors. An interactive constructor allows the user to set the viewpoints integrated by the CRC through a graphical user interface. A second constructor builds a CRC that disoccludes a user-specified target as the view changes or as the target moves. A third constructor builds a CRC that follows a predefined path through a 3-D dataset and provides a preview of the path ahead; how much of the path ahead is visualized is under user control. <ref type="figure" target="#fig_0">Figure 1</ref> illustrates the use of the CRC to alleviate occlusions in visualization (also refer to the accompanying video). In the top row, a CRC is used to preview the two side streets without advancing the camera (middle and right images). The CRC samples the main street up to the intersection and then switches to a second viewpoint to sample the side streets. The CRC rays for the right image are shown in <ref type="figure" target="#fig_1">Figure 2</ref>. Each ray consists of a first line segment, a conic curve segment, and then a second line segment (see purple lines). The first line segments converge at the first viewpoint, sampling the main street, and the second line segments converge at the second viewpoint, sampling the right side street. The conic curves implement the viewpoint change over a transition region. In <ref type="figure" target="#fig_2">Figure 3</ref> the car is located in the transition region. The car intersects a relatively small piece of the curved rays, a small piece of the ray is approximately straight, and distortions are minimized (left). Without the transition region, switching directly from the first to the second line segment (i.e. piecewise linear rays with only C 0 continuity), a disturbing distortion of the car occurs (right).</p><p>The second row of <ref type="figure" target="#fig_0">Figure 1</ref> illustrates CRC target tracking (left) and CRC volume rendering (right). Target tracking is illustrated in the context of the visualization of a DNA molecule. The user selects an atom as the target and, as the view translates, the algorithm attempts to avoid the occlusion of the target by modifying the parameters of the CRC dynamically. The third row illustrates CRC path previewing in the context of the visualization of a canyon terrain dataset. The path was chosen to correspond to the river. The CRC effectively linearizes a section of the river. The length of the linearized section is controlled with a user parameter. Evenly-spaced colored markers were added along the path in order to illustrate the path preview effect and to facilitate comparing the images.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">PRIOR WORK</head><p>We organize the review of prior work according to the main approaches developed for addressing the problem of occlusions. For additional details we refer the reader to a comprehensive taxonomy of over 50 occlusion management techniques <ref type="bibr" target="#b0">[1]</ref>. Transparency and cutaway techniques A natural approach for removing occlusion in visualization is to render the occluder transparently, or to remove parts of the occluder.  Such transparency <ref type="bibr" target="#b1">[2]</ref> and cutaway <ref type="bibr" target="#b2">[3]</ref> techniques have the advantage of an undistorted visualization that accurately conveys global spatial relationships. Transparency works best in the case of small depth complexity where the outer layers do not need to be represented in detail and only serve the purpose of providing context to the inner layers which are the focus of the visualization, as it is frequently the case for volume datasets. Cutaway techniques are typically used for opaque occluders but again outer layers are only summarily represented at the periphery of the image. Compared to transparency and cutaway, the proposed CRC technique warps global spatial relationships and requires access to the occluded data subset to route the curved rays, but the CRC scales better with depth complexity and produces clear and complete visualizations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Dataset distortion techniques</head><p>Another approach for alleviating occlusions is to distort the dataset such that there is direct line of sight to data subsets of interest. Earlier work targeted 2-D data <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b5">6]</ref>. Two types of distortion have been developed to handle 3-D datasets: explosion and deformation. Explosion techniques subdivide the dataset with the help of user interaction <ref type="bibr" target="#b6">[7]</ref>, or automatically <ref type="bibr" target="#b7">[8]</ref>, and then move the parts away from each other to alleviate occlusion. Deformation techniques modify the dataset to disocclude regions of interest while preserving the original connectivity. Deformation techniques have been used for example for occlusion-free perspective visualization for car navigation systems <ref type="bibr" target="#b8">[9]</ref> and for short route visualization <ref type="bibr" target="#b9">[10]</ref>.</p><p>The explosion approach is best suited for scenarios where the occluded subset is completely encapsulated. Explosions modify the dataset considerably and exploded views have to rely on the user's ability to mentally reassemble the dataset. On the other hand it is clear to the user that the visualization does not show the dataset in its original configuration and that it has been exploded for visualization purposes. Deformation techniques strive to modify the dataset as little as possible. The result is a plausible dataset similar to the original dataset, which is generally an advantage but can also sometimes lead to confusion. Also deformation techniques can only achieve disocclusion if there is access to the occluded data subset.</p><p>Our CRC technique is similar in effect to deformation techniques. All CRC visualizations shown in <ref type="figure" target="#fig_0">Figure 1</ref> could pass for conventional visualizations of plausible datasets: a town with curved streets, a DNA molecule with different angles between its bonds, an engine block with an obtuse angle between its front and left face, or a canyon dug by a river with a straighter path. The main difference between the CRC and the deformation techniques is in how the disocclusion effect is obtained. The CRC allows specifying directly the rays that sample the dataset, which guarantees the disocclusion effect, as opposed to deformation techniques which modify the dataset iteratively, measuring and minimizing the residual occlusion.</p><p>Multiperspective techniques Graphic artists have known for centuries that relaxing the single viewpoint constraint can be used to achieve effects that strengthen artistic expression. The same effects have been pursued by artistic rendering systems <ref type="bibr" target="#b10">[11]</ref>. Image-based rendering techniques have been developed to combine several photographs taken from different locations into a multiperspective panorama. For example street panoramas are assembled from photographs capturing the facades along a street <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b12">13]</ref>. Compared to the CRC technique, street panoramas work under the simplifying assumption of a horizontal ground plane and a vertical façade plane which allows the integration of the raw data without detailed knowledge of the scene geometry. Multiple-center-of-projection (MCOP) images <ref type="bibr" target="#b13">[14]</ref> were rendered for virtual scenes using a vertical push-broom camera that slides along a user chosen path. Like CRC images, MCOP images provide a smooth change in perspective which minimizes distortion. However rendering MCOP images is a laborious process that requires rendering the scene for each one of a large number of viewpoints along the finely discretized path. Even though its rays are curved, the CRC model provides a fast projection operation that allows computing the multiperspective image in a single pass.</p><p>Multiperspective images have also been used in cel animation <ref type="bibr" target="#b14">[15]</ref>. Like for MCOP images, cel panoramas are rendered offline by finely discretizing the desired camera path.</p><p>Removing the PPC constraints has also been investigated as a camera model generalization problem. We will limit the discussion to prior work aimed at removing the single viewpoint constraint, most relevant in the present context, and omit work addressing the field of view and uniform sampling limitation of the PPC.</p><p>The general linear camera (GLC) relaxes the pinhole constraint by interpolating between three given non-concurrent rays <ref type="bibr" target="#b15">[16]</ref>. The family of occlusion cameras has been introduced to shrink the occlusion shadow of foreground objects <ref type="bibr" target="#b16">[17]</ref>. Occlusion cameras are constructed from a PPC by distorting its rays to reach around occluders and to capture samples that are barely occluded. A barely occluded sample is a sample that projects close to the silhouette of an occluder and is thus likely to become visible even for minimal viewpoint translations. Both GLCs and occlusion cameras provide fast projection so rendering is efficient. Whereas the GLC and occlusion cameras provide a local disocclusion effect, as needed for applications such as reflection rendering <ref type="bibr" target="#b17">[18]</ref>, the CRC allows defining rays that reach far from the original viewpoint in order to disocclude distant data subsets.</p><p>The non-linear ray tracing framework <ref type="bibr" target="#b18">[19]</ref>, later mapped to GPUs <ref type="bibr" target="#b19">[20]</ref>, was developed with the initial motivation of visualization of mathematical and physical systems such as the generalized theory of relativity, black holes, and neutron stars where bent light rays occur. This pioneering work makes the important contributions of introducing the concept of curved rays, of introducing the idea of distorting rays as opposed to the 3-D dataset to be visualized, and of demonstrating the feasibility and potential of rendering images with curved rays. However, the curved rays are inherent to the system that is visualized and are thus considered input for the framework. The framework does not provide flexibility or assistance for defining the rays, as is needed for the task targeted by the CRC of achieving a specific disocclusion effect. Moreover, rendering relies exclusively on ray casting and is less efficient than in the case of the CRC.</p><p>Added ray definition flexibility is brought by a framework that allows defining any single-camera projection through the use of a flexible viewing volume <ref type="bibr" target="#b20">[21]</ref>. The framework subsumes inverted perspective projection, general linear cameras, and occlusion cameras. The major contribution of the framework is a formal foundation for the analysis and development of non-conventional projections. Rendering remains restricted to ray casting with the exception of some special cases. In essence the CRC builds upon this framework to define a camera model and construction algorithms specialized for the disocclusion application. The CRC provides specific solutions to the problems of combining two or more viewpoints, of how to modify the camera model in real time to track a target, and of how to disocclude a path.</p><p>One method of addressing the challenge of specifying the nonlinear projection that achieves a desired artistic <ref type="bibr" target="#b21">[22]</ref> or disocclusion <ref type="bibr" target="#b22">[23]</ref> effect is based on widgets, which are image regions where special projection rules apply. The projection of a widget is specified as one of several predefined projections or it is computed from a set of user specified constraints. The widgets bring local modifications to the original image which has the advantage of preserving global spatial relationships but also the disadvantage of limited disocclusion capability. Moreover disocclusion is limited to a single occluder as it is difficult to overlap multiple widgets for the camera rays to take multiple turns. Rendering is performed in feed forward fashion but performance decreases with the number of widgets.</p><p>The graph camera <ref type="bibr" target="#b23">[24]</ref> is a flexible camera model constructed from an initial PPC by applying a set of view frustum bending, splitting, and merging operations. Compared to the graph camera, the CRC only supports view frustum bending hence it brings less disocclusion flexibility. However, the graph camera switches perspectives abruptly using piecewise linear rays with only C 0 continuity, which causes sharp distortions like the ones shown in <ref type="figure" target="#fig_2">Figure 3</ref>. Moreover graph camera construction was done either with the help of the user or by relying on a maze with right-angle 4-way intersections, and did not support target tracking or path previewing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">CURVED RAY CAMERA MODEL</head><p>We first describe a camera model with curved rays that achieves the goal of smoothly connecting two viewpoints. The resulting camera model is suitable for rendering by ray casting, as is required in visualization applications such as volume rendering. Then, in the next section, we describe a modification to the original camera model that enables fast projection, making it suitable for feedforward rendering.</p><p>The design of the curved ray camera has to allow circumventing occluders and reaching deep into the dataset. By definition a camera model specifies the set of rays the camera uses to sample the dataset. In order to achieve the desired disocclusion effect we generalize the concept of a camera ray to the locus of 3-D points that project at a given image plane location, which allows for curved rays. Given a starting planar pinhole camera PPC 0 with viewpoint C 0 , a plane t 1 , and a second viewpoint C 1 , we want to build a camera model that uses viewpoint C 0 up to t 1 and then switches to C 1 . In order to make the transition smooth we use two additional planes t 0 and t 2 that define a transition region where the viewpoint change occurs ( <ref type="figure">Figure  4</ref>). We connect the C 0 and C 1 rays with a quadratic polynomial Bézier, which is the simplest curve that provides C 1 continuity at both connection points. For example, the CRC ray through P 0 is the C 0 ray up to plane t 0 , then the quadratic Bézier with control points P 0 , P 1 , and P 2 , and then the C 1 ray beyond plane t 2 .</p><p>In conclusion, given an image plane point P, the CRC camera ray is found by first intersecting ray C 0 P with planes t 0 and t 1 to obtain points P 0 and P 1 , then ray C 1 P 1 is intersected with plane t 2 to obtain point P 2 , and then control points P 0 , P 1 , and P 2 define the ray as explained above. The CRC can be extended by appending additional viewpoints, each with its own transition region.</p><p>The CRC model can be used directly to support visualization techniques that require ray casting, such as volume rendering. A CRC ray is traced by tracing the sequence of segments and arcs. The arcs are traced by iterating parameter t in the Bézier equation below. Equal t increments of course do not correspond to arc steps of equal length. For applications where the uniformity of the step is important one could evaluate Equation 1 with small steps in t and to use a piecewise linear approximation of the length of the arc step. In addition to the ability to trace rays, ray casting also requires the ability to clip a ray with the bounding volume of the dataset. Computing the intersection between a Bézier ray and a plane is easily done by plugging in the expression of a ray point given by Equation 1 into the plane equation, which results in a quadratic equation in parameter t.</p><p>It is straightforward to trace the CRC rays as defined, but the approach of choice for interactive visualization of 3-D surface datasets remains feed-forward rendering through projection followed by rasterization. Unfortunately, given a 3-D point P one cannot inexpensively compute the image plane projection of P with the CRC model as defined because the projection equation cannot be solved in closed form and a numerical solution is too expensive. We implemented a numerical solution based on the bisection method and found solutions with sub-pixel accuracy after an average of 10 iterations, too slow for interactive visualization of complex datasets. Fortunately a small modification to the CRC model enables fast, closed-form projection of 3-D points.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">A CURVED RAY CAMERA MODEL WITH FAST PROJECTION</head><p>We developed a fast projection operation based on the observation that it is advantageous to choose the three planes t 0 , t 1 , and t 2 defining the transition region such that they intersect along a common line l. This does not come at a significant loss of generality since planes t 0 and t 2 simply mark the beginning and the end of the transition region. Note that line l does not have to be vertical. In other words, rays can bend in any direction (see Section 7 and <ref type="figure" target="#fig_0">Figure  12</ref>). Given a 3-D point P to be projected, let A be the intersection of l with the epipolar plane C 0 C 1 P, and let P i be the intersection points of line AP and the bundle of Bézier arcs ( <ref type="figure">Figure 5</ref>). Let Q i be the intersection points between plane t 2 and the same Bézier arcs. Then lines P i Q i are almost concurrent, and the near-intersection occurs close to the baseline C 0 C 1 (see dotted circle). If lines P i Q i truly intersected at a point R on C 0 C 1 , point P could be projected by finding point R using a known ray, say the one through Q n . In other words R can be found without yet knowing the ray through P. Once R is known, Q, S, and the projection of P on the image plane are easily found by intersecting RP with t 2 , C 1 Q with t 1 , and C 0 S with the image plane. We first describe the camera model modification that achieves the desired convergence on the baseline while preserving the desired ray continuity property, and then we describe the projection algorithm in detail.   <ref type="figure">Figure 6</ref>. CRC model modified for fast projection.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>4.1</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Camera model modification</head><p>The modified CRC model is defined as follows ( <ref type="figure">Figure 5)</ref>. First, the left most ray in each epipolar plane stays the same as before; the ray through Q n remains the quadratic Bézier arc b. The other rays are constructed by rotating a line through point A from plane t 0 to plane t 2 . For each intermediate position, the line is intersected with b to define point P n , and then Q n P n is intersected with C 0 C 1 to find point R. The ray point P is defined by the intersection of RQ and line AP n . At a conceptual level, the modified CRC model switches gradually from C 0 to C 1 through a continuum of intermediate viewpoints on the baseline segment C 0 C 1 <ref type="figure">(Figure 6</ref>). Each intermediate viewpoint C i is used to image all 3-D points located in a plane t i of the transition region. For example C a images points in the plane t a . t a is defined by the line l through A (i.e. the intersection of t 0 and t 2 ) and point S n at the intersection of C a Q n and b. In other words, given a point P, the viewpoint to use depends on where line PA intersects the Bézier arc b. <ref type="figure">Figure 7</ref> shows that the modified rays are very similar to the original rays, and consequently the image differences are small as well.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Modified camera model properties</head><p>We first show that the modified arcs are conic sections that connect the component rays from the transitioned PPCs with C 1 continuity. Consider <ref type="figure">Figure 8</ref> that shows the modified rays of the CRC model in a single epipolar plane through C 0 and C 1 . T n , S n , and Q n are the control points of the Bézier arc b that aids with the projection of all points in the epipolar plane. Triangles T n S n Q n and T k S k Q k satisfy Desargues' Theorem <ref type="bibr" target="#b24">[25]</ref>. Since the intersections of planes t 0 , t 1 , and t 2 with the epipolar plane are concurrent, all such triangles are perspective, as are triangles P n S n Q n and P k S k Q k . Here, A is the center and line C 0 C 1 is the axis of perspectivity. By construction, lines Q k P k intersect on the axis of perspectivity in a common point R k and therefore points P k are also perspective. Now the Bézier curve b is the projected intersection of a quadratic cone in 3D, with vertex A, and a plane through a line that projects onto the axis of perspectivity. Since triangles T k S k P k are perspective, the other transition curves are also conic sections.</p><p>Again in 3D, the plane containing lines AT n and AS n is tangent to the cone, in a line projecting onto line AT n and so the conic arcs are all C 1 continuous with the lines through C 0 . Likewise, lines through C 1 are C 1 continuous with the conic arcs on the other end.</p><p>Having established that the transition curves are tangent continuous and are conics, we now establish that different transition arcs cannot intersect in the transition region.</p><p>Let P k S k Q k and P j S j Q j be two triangles defining the intersecting transition curves. Since the control points P k P j and Q k Q j are distinct, the intersection must be in the interior of the arcs, say at X. The lines Q k X and Q j X are distinct and intersect in X. Thus they do not intersect on the line C 0 C 1 and so the point X is not perspective on the two curves, yet the line XA establishes projective correspondence. Hence the two arcs cannot intersect in the interior. An alternative argument is as follows. There must be perspective points Y k and Y l on the intersecting curves such that X is on opposite sides of the line Y k Y l A that establishes the correspondence. Since this is impossible, there cannot be an intersection in the interior of the arcs either. For the modified model lines P i Q i converge on baseline C 0 C 1 by construction and the following projection algorithm applies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Projection operation</head><p>A point P is projected with the following steps ( <ref type="figure">Figure 5</ref>): 1. Intersect line AP with Bézier arc b to obtain point P n .</p><p>2. Intersect P n Q n with baseline C 0 C 1 to obtain point R.</p><p>3. Intersect RP with plane t 2 to obtain Q. 4. Intersect C 1 Q with plane t 1 to obtain point S. 5. Intersect C 0 S with the image plane. The first step implies solving a single variable quadratic equation, as discussed above (b is intersected with a plane through AP). All other steps are simple line/plane intersections. Moreover the projection of point Q onto plane t 1 using C 1 (step 4) and the projection of S onto the image plane (step 5) can be combined into a single projection by concatenating the projection matrices of PPC 1 and PPC 0 . PPC 1 is defined by viewpoint C 1 and image plane t 1 .</p><p>Points inside the frustum of PPC 0 but outside the transition region are simply projected with PPC 0 . Points inside the frustum of PPC 1 but outside the transition region are projected with the concatenated projection matrices of PPC 1 and PPC 0 . The cost of projection does not increase as additional turns are added to the rays of the CRC. The matrices corresponding to the additional turns are concatenated and points are projected directly to the image plane, in one step.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">CRC CONSTRUCTORS</head><p>We have developed several CRC constructors to facilitate achieving the desired disocclusion effect in various contexts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Interactive Constructor</head><p>We have developed an interactive CRC constructor that allows the user to set all components of a two viewpoint CRC through a graphical user interface. The position of the second viewpoint C 1 and of the transition region controls how much and which way the CRC rays should bend, and the size of the transition region controls how  abrupt the transition between the two viewpoints should be. The CRC components are manipulated in a window that gives an overhead view of the scene and that also visualizes the rays of the CRC. A second window shows the corresponding CRC image for immediate feedback. The image in <ref type="figure" target="#fig_7">Figure 9</ref> was rendered with a CRC that was designed with the interactive constructor to capture the entire forward and right street branches.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Target tracking</head><p>The disocclusion capability of the CRC can be used to avoid that an object of interest, i.e. a target, becomes occluded as the view, the target, and/or other objects move. We have developed a CRC constructor that automatically computes a CRC that shows a given target <ref type="figure" target="#fig_0">(Figure 1 &amp; video)</ref>. The CRC is controlled with 3 parameters: the depth z 0 from the first viewpoint C 0 where rays should start to bend, a translation amplitude a that defines the maximum lateral offset of the second viewpoint C 1 with respect to C 0 , and a fraction f between 1 and 1 that modulates the maximum offset. When f is 1/+1 the CRC rays are bent all the way left/right. When f is 0 rays are straight and the CRC is a PPC. We set both z 0 and a as half the distance from C 0 to the target. The ray bending fraction f is updated dynamically for every frame with the following algorithm.</p><p>1. If the target is visible for f = 0, set f to 0. The rays are bent only if needed and the same bending factor is kept if possible. The search for a new f value that disoccludes the target starts at the current f value and iteratively tests f values left and right at increasing distance. If the search succeeds f is updated to the new value, else f is set to 0 (i.e. the target cannot be disoccluded). The frame to frame change of f is capped to avoid abrupt changes in the visualization. The gradual change of f comes at the cost of occluding the target for a few frames as the rays swing to the new value of f that disoccludes the target. The only state data maintained by the algorithm is the ray bending factor f, so it directly supports dynamic occluders, dynamic targets, and dynamic views.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Path previewing</head><p>We have developed a CRC constructor that alleviates occlusions along a given visualization path through a 3-D dataset. Visualization paths can be defined in a variety of ways, including by leveraging inherent properties of the dataset (e.g. a river cutting through a canyon, a road, a blood vessel), by following an object that moves through the dataset, or by finding and saving a sequence of relevant views through interactive visualization. As the turns in the path are typically chosen to circumvent occluders, following a path with a PPC limits the visualization to the first turn in the path. We have developed an algorithm for constructing a CRC that previews forthcoming parts of the path. The CRC linearizes the path locally which allows the user to see beyond one or several turns in the path <ref type="figure" target="#fig_0">(Figure 11</ref>). The algorithm takes two parameters as input: the current position along the path, and how much of the path should be linearized, i.e. the preview length. Both parameters are under user control. The user can advance the current position and increase/reduce how far ahead the visualization shows. For a given position and preview length, the CRC is constructed using control points (red dots in <ref type="figure" target="#fig_0">Figure 10</ref>) along the path (blue line). Three consecutive control points that are not collinear define a turn. The current position corresponds to the image plane. When the image plane is about to enter a transition region, the planes t 0 , t 1 , and t 2 defining the transition regions are collapsed progressively (see middle and right figures). Conversely, as the current position advances, new control points enter the linearization region and their transition planes are deployed progressively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">RESULTS AND DISCUSSION</head><p>We have tested CRC visualization on 5 datasets: a city model <ref type="figure" target="#fig_0">(Figure 1, top row, Figure 2</ref>, <ref type="figure" target="#fig_2">Figure 3</ref>, and <ref type="figure" target="#fig_7">Figure 9</ref>), a ball and stick DNA molecule model [26] <ref type="figure" target="#fig_0">(Figure 1, middle row)</ref>, the Engine Block volume dataset <ref type="bibr">[27]</ref>  <ref type="figure" target="#fig_0">(Figure 1, middle row)</ref>, a set of random blocks (video), and a canyon terrain dataset corresponding to a section of the Colorado river <ref type="bibr" target="#b25">[28]</ref>  <ref type="figure" target="#fig_0">(Figure 1</ref>, bottom row, and <ref type="figure" target="#fig_0">Figure 11)</ref>. Quality As the images in the paper and the accompanying video attest, the CRC succeeds at alleviating occlusions in complex datasets while minimizing distortions. Objects that traverse the region where rays transition between one viewpoint and the next deform only very little, resulting in a visualization effect comparable to that of a rigid body transformation. The GUI-based constructor allows the user to design the disocclusion effect interactively. The user can explore distant, occluded data subsets without modifying the visualization context of nearby data. The target tracking constructor keeps the target visible as the target, the view, and/or occluders translate, as long as a solution exists given the maximum ray curvature allowed by the user. The path previewing constructor allows the user to visualize a pre-recorded path without being limited by the occlusions brought by the next few turns in the path.</p><p>Performance All performance numbers reported in this paper were measured on a workstation with a Dual Xeon 3.2GHz Intel processor, with 4GB of RAM, and with an NVIDIA GTX 285 graphics card. The interface to the graphics hardware was implemented using OpenGL and the Cg shading language. The output resolution was 1280x720.</p><p>All datasets except for the Engine Block are 3-D surface datasets and are rendered by projection followed by rasterization. CRC projection is implemented in a vertex program. The program first determines the CRC sub-frustum that contains the vertex. If the vertex is inside a conventional PPC sub-frustum, the vertex is projected directly to the output image by multiplication with a 4-D matrix pre-computed by concatenating the modelview and projection matrices of all the viewpoints from the current viewpoint to the root.   <ref type="figure" target="#fig_0">Figure 1</ref>. The blue line shows the path that follows the river. The CRC conforms to a section of the path using 4 turns.</p><p>If the vertex is inside a transition region sub-frustum, the vertex is projected as described in Section 4. For datasets where the triangles are small, conventional rasterization is a good approximation of the non-linear rasterization mandated by the non-linear projection of the CRC. Datasets with large triangles are subdivided as a pre-process. In our case the only dataset that required subdivision was the city dataset due to large triangles used to model the ground (e.g. sidewalks, roads). We have also implemented a geometry program that performs on demand subdivision but performance is lower than in the case of off-line uniform subdivision, which we attribute to the primitive emission bottleneck of GPU geometry programs.</p><p>The side faces of the CRC frusta are planes. For the Canyon and City datasets we perform view frustum culling at primitive group level using a simple uniform 3-D grid. We avoid triangle level clipping by enlarging the frustum of the CRC and discarding any triangle for which at least one of the vertices is outside the CRC frustum. This is done with a simple geometry program that emits 1 or 0 triangles per incoming triangle. Triangles do not need to be clipped with the separation planes between CRC sub-frusta; a triangle crossing such a plane is simply handled by projecting each one of its vertices with the projection function of its sub-frustum.</p><p>Rendering performance is given in <ref type="table" target="#tab_0">Table 1</ref>. The geometry load figures correspond to primitives that pass view frustum culling. We compare the CRC to a PPC (i.e. rendering the dataset with the root PPC 0 of the CRC), and to a camera with C 0 continuous rays that switches abruptly between the viewpoints of the CRC. The CRC renders all datasets comfortably except for the City dataset which is too large to fit on the graphics card, and which none of the 3 methods render quickly. The ratio between PPC and CRC performance is at most 2.08; between C 0 and CRC it is at most 1.39. The CRC vertex projection performance is at least 12, 50, 222, and 83 million vertices per second for the first 4 datasets in the table, respectively. These figures were computed by multiplying the frame rate by the number of vertices, which counts the entire frame time as projection time. As such, the figures give a lower bound on projection performance.</p><p>We measured performance for the Canyon dataset for CRCs with an increasing number of viewpoints. Performance remains virtually unchanged even for as many as 8 viewpoints, which is expected since the few additional dot products needed to classify the vertex sub-frusta are a small cost compared to the vertex projection operation as a whole.</p><p>The Engine Block dataset is volume rendered by ray casting using the original CRC model with all ways being Bézier arcs. One could also ray cast using the modified CRC model, but the additional cost incurred by tracing the conic rays is unnecessary. For the transition region we derive the number of steps from the sum of the length of the original viewpoint C 0 and C 1 rays (i.e. P 0 P 1 + P 1 P 2 in <ref type="figure">Figure 4</ref>). The numbers reported in the table correspond to the left Block Engine image in <ref type="figure" target="#fig_0">Figure 1</ref> for the PPC and to the right image for the CRC. The difference in performance is due to the fact that the volume covers a considerably larger fraction of the image for the CRC, and that the CRC rays travel longer through the volume.</p><p>Limitations Whereas for a PPC rasterization parameter variation is linear after perspective correction, in the case of the CRC rasterization parameters vary non-linearly. Our current work takes the approach of subdividing triangles to make linear rasterization acceptable. Of course, the approximation (and subdivision) can be avoided by ray tracing which computes the intersection between a CRC ray and a triangle and evaluates the rasterization parameters in model space using the barycentric coordinates of the intersection point. Another potential solution which we will investigate in the future is a hybrid approach that borrows from both the feed forward and the ray tracing pipelines: first an approximate bounding box of the curved CRC projection of a triangle is computed by projecting several points on the perimeter of the triangle, and then, for each pixel in the bounding box, the triangle is intersected with the corresponding CRC ray.</p><p>One of the potential strengths of the CRC model is that although it integrates multiple viewpoints, the CRC image rendering cost is independent of the number of viewpoints. For this to hold true the frustum containing a given 3-D point needs to be identified in constant time. As mentioned above, we are currently testing all subfrusta sequentially, which is acceptable for a small number of viewpoints. To scale to hundreds of viewpoints the point to subfrustum assignment needs to proceed hierarchically. We foresee that a binary space partitioning tree would be an adequate data structure for this task given the fact that sub-frusta are separated by planar faces and that they do not intersect.</p><p>Although the CRC minimizes small-scale distortions, the CRC does perturb global spatial relationships, which can lead to confusion. This limitation is inherent to all dataset distortion and multiperspective visualization techniques. Some applications could prefer that the data subsets that are displaced from their PPC projection location be highlighted to clearly communicate to the user the deviation from a regular PPC image.</p><p>Finally, the CRC needs an albeit indirect way of accessing the occluded data subset through which to route its rays. A CRC cannot, for example, disocclude the engine of a car with the hood closed. One option is to combine the CRC with other disocclusion management techniques such as transparency, cutaway, or explosion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">CONCLUSIONS AND FUTURE WORK</head><p>The CRC model offers good flexibility for disoccluding complex datasets yet local distortion is minimized. Although the rays are curved, the CRC was designed to provide a fast projection operation which allows rendering 3-D surface data efficiently. Ray casting is straight forward, which enables visualization techniques such as volume rendering and ray tracing. Whereas the previously developed non-linear ray tracing <ref type="bibr" target="#b22">[23]</ref> and flexible view volume <ref type="bibr" target="#b20">[21]</ref> frameworks offer the generality needed to experiment in the complex space of possible camera models, the CRC framework identifies camera models and construction algorithms well suited for the disocclusion task in terms of effectiveness and performance.</p><p>One line of future work is to develop additional CRC constructors. A constructor useful in the context of interactive visualization would be one that probes a dataset automatically, by building a CRC that bends to crawl into empty space and visualizes occluded data subsets. The CRC could be extended to support frustum splitting and merging, making it the equivalent of a graph camera with C 1 frustum to frustum transitions, which would increase its disocclusion and multiperspective visualization capability. In the  examples shown so far, the disocclusion effect was obtained by lateral translation of the viewpoint. The CRC model supports any relative position of consecutive viewpoints <ref type="figure" target="#fig_0">(Figure 12</ref>), which can be exploited by future constructors for the added multiperspective expressivity of non-planar 3-D rays obtained by changing the bending direction from one transition region to the next. We are in the process of conducting an extensive user study to investigate and quantify the potential benefits of multiperspective visualization like the one enabled by the CRC in the context of 3-D dataset exploration. Our study is conducted using 47 subjects whose accuracy and speed were tested for a number of basic tasks such as object finding, object counting, and path memorization (i.e. the subject is asked to remember the path taken through the dataset). The conditions we are investigating include static and dynamic datasets, as well as multiperspective images of varying complexity, i.e. images integrating from a few to tens of viewpoints.</p><p>Preliminary results are encouraging. By using multiperspective visualization, subjects are able to locate objects on average 35% faster compared to using a PPC visualization. This confirms the intuition that a multiperspective visualization that provides a preview beyond immediate occluders does accelerate the process of finding an object: the subject can tell without additional navigation whether the object is hidden or not behind the occluder. When counting objects, comprehensive multiperspective visualization resulted in an accuracy of 90% compared to only 44% when using visualization based on a comprehensive set of PPCs. This confirms the intuition that a multiperspective visualization that shows the entire 3-D data in a non-redundant and continuous image facilitates disambiguating identical objects and tracking dynamic objects. For the path memorization task, subjects performed virtually identically using multiperspective and PPC visualizations (69.8% and 66.7% accuracy, respectively), which indicates that the auxiliary viewpoints augmenting the main viewpoint do not disturb significantly the subject's sense of orientation.</p><p>Additional user studies are needed to fully identify the types of basic tasks where CRC visualization is beneficial. Such user studies will allow deriving empirical guidelines to make best use of the flexibility of the camera model for optimizing visualization payload. The benefits of CRC visualization will have also to be studied in the context of high-level tasks performed by domain experts. CRC visualization will have to be compared to alternative approaches for overcoming occlusions. For example, in the context of computational molecular dynamics, disocclusion can be achieved using conventional graph visualization techniques, against which the CRC approach has to be compared. In addition to task performance, other possible comparison points include tractability, magnitude and effects of distortion, 2-D vs. 3-D, and rendering performance in light of interactive visualization and dynamic datasets.</p><p>Another possible direction of future work is to investigate constructing CRC visualizations of real world scenes. A piecewise linear approximation of the CRC rays can be implemented by using multiple physical video cameras. Merging the video feeds would be greatly aided by the availability of a geometric proxy of the scene. For example for the canyon shown in this paper the proxy could be provided by the terrain data.</p><p>This work is inscribed in the camera model design paradigm which advocates for the relaxation of the planar pinhole camera constraints and for the development of camera models that adapt dynamically to the data they are sampling. We believe that camera model design can be used to develop solutions to other challenging problems in visualization and beyond.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>Top: conventional planar pinhole camera (PPC) street-level visualization (left), and curved ray camera (CRC) visualizations showing the left and right side streets (middle and right). Middle row, left: DNA molecule with target atom shown with wireframe bounding box occluded in PPC view (left) and disoccluded in CRC view (right). Middle row, right: block engine dataset volume rendered with a PPC (left) and CRCs with rays of increasing curvature (middle and right). Bottom: canyon terrain dataset visualized with a PPC (left) and with CRCs that preview an increasing section of the river bed ahead (middle and right).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 .</head><label>2</label><figDesc>Visualization of CRC rays (see top-right image inFigure 1).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 .</head><label>3</label><figDesc>Comparison between CRC visualization (left) and a visualization that switches abruptly between viewpoints (right).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 .Figure 5 .</head><label>45</label><figDesc>CRC model visualization. Illustration of desired fast projection operation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 7 .Figure 8 .</head><label>78</label><figDesc>Modified (black) and original (red) CRC rays. Modified CRC model.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 9 .</head><label>9</label><figDesc>CRC image that captures all of the forward and right streets.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>2 .</head><label>2</label><figDesc>Else if the target is visible with current f, keep current f. 3. Else search for a new f such that the target is visible. Visibility of the target for a given value of f is determined efficiently at bounding box level: axis aligned bounding boxes are fitted to objects and to target, the bounding boxes are projected on the CRC image, and the image aligned bounding boxes of the projections are tested for intersection. The target bounding box is enlarged a user chosen number of pixels to achieve a clear disocclusion of the target.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 10 .</head><label>10</label><figDesc>Illustration of CRC construction for path tracking. As the current position advances the transition planes are collapsed.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 11 .</head><label>11</label><figDesc>Visualization of the CRC used to render the bottom right image in</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Figure 12 .</head><label>12</label><figDesc>Examples of no, lateral, vertical, and diagonal ray bending.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>Rendering Performance for Various Datasets</figDesc><table><row><cell>Dataset</cell><cell>Vertices x1,000</cell><cell>Tris x1,000</cell><cell>PPC</cell><cell>Frame rate (Hz) C 0</cell><cell>CRC</cell></row><row><cell>Blocks</cell><cell>90</cell><cell>43</cell><cell>153</cell><cell>136</cell><cell>137</cell></row><row><cell>DNA</cell><cell>2,170</cell><cell>4,112</cell><cell>48</cell><cell>32</cell><cell>23</cell></row><row><cell>Canyon</cell><cell>4,287</cell><cell>2,168</cell><cell>99</cell><cell>56</cell><cell>52</cell></row><row><cell>City</cell><cell>29,892</cell><cell>10,351</cell><cell>2.8</cell><cell>2.8</cell><cell>2.8</cell></row><row><cell cols="3">Engine 256×256×110 vol. res.</cell><cell>7.9</cell><cell>6.7</cell><cell>4.1</cell></row></table><note></note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A Taxonomy of 3D Occlusion Management for Visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Elmqvist</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Tsigas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TVCG</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1095" to="1109" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">ClearView: An interactive context preserving hotspot vis technique</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kruger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schneider</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Westermann</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TVCG</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="941" to="947" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Adaptive cutaways for comprehensible rendering of polygonal scenes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Burns</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Finkelstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM SIGGRAPH Asia</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Generalized fisheye views</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">W</forename><surname>Furnas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CHI&apos;86 Conference on Human Factors in Computer Systems</title>
		<imprint>
			<date type="published" when="1986" />
			<biblScope unit="page" from="16" to="23" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">The Hyperbolic Browser: A focus + context technique for visualizing large hierarchies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lamping</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Rao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. of Visual Languages and Computing</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="33" to="35" />
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">EdgeLens: An interactive method for managing edge congestion in graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">S T</forename><surname>Carpendale</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Greenberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc of the IEEE Symp. on Info Vis</title>
		<meeting>of the IEEE Symp. on Info Vis</meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="51" to="58" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Exploded View for Volume Data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bruckner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">E</forename><surname>Groller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TVCG</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1077" to="1084" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Automated generation of interactive 3D exploded view diagrams</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Agrawala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Curless</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Salesin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Graph</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1" to="7" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Occlusion-Free Animation of Driving Routes for Car Navigation Systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Takahashi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Yoshida</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Shimada</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Nishita</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TVCG</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1141" to="1148" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Effective visualization of short routes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Degener</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Schnabel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Schwartz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Klein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TVCG</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1452" to="1458" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Artistic Multiprojection Rendering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Agrawala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Zorin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Munzner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc of the EG Workshop on Rendering Techniques</title>
		<meeting>of the EG Workshop on Rendering Techniques</meeting>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="page" from="125" to="136" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Interactive Design of Multi-Perspective Images for Visualizing Urban Landscapes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Román</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Garg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Levoy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc of Visualization &apos;04</title>
		<meeting>of Visualization &apos;04</meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="537" to="544" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Photographing long scenes with multi-viewpoint panoramas</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Agarwala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Agrawala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Salesin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Szeliski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. on Graphics</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="853" to="861" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Multiple-center-of-projection images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Rademacher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Bishop</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc of SIGGRAPH &apos;98</title>
		<meeting>of SIGGRAPH &apos;98</meeting>
		<imprint>
			<date type="published" when="1998" />
			<biblScope unit="page" from="199" to="206" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Multiperspective panoramas for cel animation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">N</forename><surname>Wood</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Finkelstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">F</forename><surname>Hughes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">E</forename><surname>Thayer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">H</forename><surname>Salesin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc of SIGGRAPH &apos;97</title>
		<meeting>of SIGGRAPH &apos;97</meeting>
		<imprint>
			<date type="published" when="1997" />
			<biblScope unit="page" from="243" to="250" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">General Linear Cameras</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Mcmillan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc of the European Conference on Computer Vision (ECCV)</title>
		<meeting>of the European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="14" to="27" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">The Occlusion Camera</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Mei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Popescu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Sacks</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">proc. of EG 2005</title>
		<meeting>of EG 2005</meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="volume">24</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Modelling Reflections via Multiperspective Imaging</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Mcmillan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of Eurographics Symposium on Rendering</title>
		<meeting>of Eurographics Symposium on Rendering</meeting>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Groller</surname></persName>
		</author>
		<title level="m">Nonlinear ray tracing: Visualizing strange worlds. The Visual Computer</title>
		<imprint>
			<date type="published" when="1995" />
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="263" to="274" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">GPU-based nonlinear ray tracing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Weiskopf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Schafhitzel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Ertl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics Forum</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="625" to="633" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Single camera flexible projection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Brosz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Samavati</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sheelagh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sousa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc of the 5th international Symposium on Non-Photorealistic Animation and Rendering</title>
		<meeting>of the 5th international Symposium on Non-Photorealistic Animation and Rendering</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="33" to="42" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">3D screen-space widgets for non-linear projection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Coleman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Barrett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Sudarsanam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Grimm</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc of the 3rd international Conference on Computer Graphics and interactive Techniques in Australasia and South East Asia</title>
		<meeting>of the 3rd international Conference on Computer Graphics and interactive Techniques in Australasia and South East Asia</meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="221" to="228" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Non-linear perspective widgets for creating multiple-view images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Sudarsanam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Grimm</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Singh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 6th international Symposium on Non-Photorealistic Animation and Rendering</title>
		<meeting>of the 6th international Symposium on Non-Photorealistic Animation and Rendering</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="69" to="77" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Popescu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Rosen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Adamo-Villani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Graph Camera. International Conference on Computer Graphics and Interactive Techniques</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Desargues</forename><surname>Thoerem</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Wikipedia</surname></persName>
		</author>
		<ptr target="http://en.wikipedia.org/wiki/Desargues&apos;_theorem" />
		<imprint>
			<date type="published" when="2010-03" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title/>
		<ptr target="http://www.usgs.gov/" />
	</analytic>
	<monogr>
		<title level="j">United States Geological Survey</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
