<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/pisenberg/grobid/grobid-0.6.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">An Information-theoretic Framework for Visualization</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><roleName>Member, IEEE</roleName><forename type="first">Min</forename><surname>Chen</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><roleName>Member, IEEE</roleName><forename type="first">Heike</forename><surname>Jänicke</surname></persName>
						</author>
						<title level="a" type="main">An Information-theoretic Framework for Visualization</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2021-02-20T19:55+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Index Terms-Information theory</term>
					<term>theory of visualization</term>
					<term>quantitative evaluation</term>
				</keywords>
			</textClass>
			<abstract>
				<p>In this paper, we examine whether or not information theory can be one of the theoretic frameworks for visualization. We formulate concepts and measurements for qualifying visual information. We illustrate these concepts with examples that manifest the intrinsic and implicit use of information theory in many existing visualization techniques. We outline the broad correlation between visualization and the major applications of information theory, while pointing out the difference in emphasis and some technical gaps. Our study provides compelling evidence that information theory can explain a significant number of phenomena or events in visualization, while no example has been found which is fundamentally in conflict with information theory. We also notice that the emphasis of some traditional applications of information theory, such as data compression or data communication, may not always suit visualization, as the former typically focuses on the efficient throughput of a communication channel, whilst the latter focuses on the effectiveness in aiding the perceptual and cognitive process for data understanding and knowledge discovery. These findings suggest that further theoretic developments are necessary for adopting and adapting information theory for visualization.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Information theory is "the science of quantification, coding and communication of information" <ref type="bibr" target="#b43">[44]</ref>. Visualization is concerned with visually coding and communicating information. Many aspects of a visualization pipeline feature events of a probabilistic nature, bearing a striking resemblance to a communication pipeline. For instance,</p><p>• data abstraction usually results in data compression;</p><p>• creating and viewing a visualization is usually an information discovery process; • the messages in a visualization are not guaranteed to be received by a viewer; • the quality of a visualization is often measured by probabilistic experiments; and so forth.</p><p>This suggests a strong connection between information theory and visualization. It is a reasonable assumption that the science of visualization should be built upon a number of theories established in different disciplines. It is also rational to consider information theory as one of these theories. This paper presents a theoretic study into a conceptual connection between information theory and visualization.</p><p>In the scientific world, a theory is a fact-based framework for explaining a set of observed phenomena or events. To examine the role of information theory in visualization, one can consider the following propositions: (a) information theory can explain all phenomena or events in visualization; (b) information theory can explain some but not all phenomena or events in visualization; (c) information theory can explain none of the phenomena or events in visualization.</p><p>For most people, proposition (b) is likely to be an instinctive hypothesis. In order to confirm or disprove (a), (b) or (c), one naive approach to examine exhaustively every phenomenon and event in visualization is to see whether or not it can be explained by any aspect of information theory. Such an approach would clearly be beyond the scope of this paper, if it were not impossible. Moreover, information theory is a scientific subject that is continuingly being developed and broadened. Even if we cannot find an explanation of a visualization phenomenon in the current information theory, it does not necessarily prove (a) is false. We thereby adopt an approach to examine the major concepts of information theory through its taxonomy, and for each major concept, we appraise its applicability to visualization. If a concept contradicts with some observations in visualization, we consider this as evidence indicating that information theory cannot explain one particular phenomenon. As the theoretical development of information theory is more mature than that of visualization, it also makes sense to use the taxonomy of information theory as a basis and to view visualization from the perspective of information theory.</p><p>In the remainder of this paper, after a brief review of the literature, we examine the similarity and difference between a visualization system and a communication system in Section 3. In Section 4, we juxtapose the two subjects by outlining an information-theoretic taxonomy, and annotate the relevance in visualization. This is followed by a detailed examination of four major concepts of information theory in Sections 5-8. We then briefly discuss the role of user studies under an information theoretic framework in Section 9. We offer our concluding remarks in Section 10.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK</head><p>It is generally agreed that information theory was founded by Shannon <ref type="bibr" target="#b35">[36,</ref><ref type="bibr" target="#b37">38]</ref> and Wiener <ref type="bibr" target="#b52">[53]</ref>. While the development of information theory has been focused on the fundamental limits of data compression and reliable communication <ref type="bibr" target="#b46">[47]</ref>, it has stimulated a wide spectrum of applications including biology, psychology, linguistics, game theory, and decision theory. Over the last two decades, information theory has been applied extensively to image processing and analysis, including quantization, compression, segmentation, registration, and object detection and recognition (e.g., <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b27">28]</ref>).</p><p>Information theoretic measures have also been used in visualization and computer graphics, including scene and shape complexity analysis by Feixas et al. <ref type="bibr" target="#b14">[15]</ref> and Rigau et al. <ref type="bibr" target="#b32">[33]</ref>, light source placement by Gumhold <ref type="bibr" target="#b19">[20]</ref>, view selection in mesh rendering by Vázquez et al. <ref type="bibr" target="#b45">[46]</ref> and Feixas et al. <ref type="bibr" target="#b15">[16]</ref>, view selection in volume rendering by Bordoloi and Shen <ref type="bibr" target="#b1">[2]</ref>, and Takahashi and Takeshima <ref type="bibr" target="#b39">[40]</ref>, focus of attention in volume rendering by Viola et al. <ref type="bibr" target="#b47">[48]</ref>, multi-resolution volume visualization by Wang and Shen <ref type="bibr" target="#b48">[49]</ref>, feature highlighting in unsteady multi-field visualization by Jänicke and Scheuermann <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b23">24]</ref>, feature highlighting in time-varying volume visualization by Wang et al. <ref type="bibr" target="#b49">[50]</ref>, measuring aesthetics by Rigau et al. <ref type="bibr" target="#b33">[34]</ref>, and transfer function design in volume rendering by Bruckner and Möller <ref type="bibr" target="#b3">[4]</ref>. Chen suggested several uses of information theory in visual analytics <ref type="bibr" target="#b6">[7]</ref>. These works focused primarily on measuring the information in the data, and some attempted to optimize viewing coordinates using such measurements.</p><p>Yang-Peláez and Flowers proposed to use entropy-based measurements for evaluating the effectiveness of information visualization <ref type="bibr" target="#b53">[54]</ref>, providing metrics for four types of information contents. Part of our work is to consolidate their metrics by removing the assumption of uniform probability distribution for some metrics (see Section 5.1).   </p><formula xml:id="formula_0">Destination g M 0 g M 1 g M k g M k-1 N N process</formula><formula xml:id="formula_1">image V optical signal S optical signal S' image V' N N N N N N N</formula><p>Mapping Transmission vis-encoder vis-channel machine-centered human-ce (e) a general visualization pipeline, without interaction <ref type="figure">Fig. 1</ref>. This series of drawings illustrate the similarity between the models of communication and visualization. When some subsystems in the visualization model (e) are combined to form composite subsystems, vis-encoder, vis-channel, and vis-decoder, the model is similar to the general communication system in (a). When all subsystems, except the source and destination, in the visualization model (e) are amalgamated into a composite system (d), the composite system is similar to a virtual channel in communication (c).</p><p>In addition, our work examines the applicability of information theory to a broader spectrum of visualization (e.g., visual design, interaction, redundancy, and user studies).</p><p>In theoretic aspects of visualization, there have been significant advances in taxonomies for visualization. Wehrend and Lewis proposed perhaps the first classification based on visualization operations and types of objects and their attributes <ref type="bibr" target="#b51">[52]</ref>. During 1990s and early 2000s, we saw a number of taxonomy proposals, including those based on data types by Shneiderman <ref type="bibr" target="#b38">[39]</ref>, display modes by Keim and Kriegel <ref type="bibr" target="#b25">[26]</ref>, interaction operations by Chuah and Roth <ref type="bibr" target="#b9">[10]</ref>, main types of analytical tasks and view manipulation by Buja et al. <ref type="bibr" target="#b4">[5]</ref>, visual analytical tasks by Zhou and Feiner <ref type="bibr" target="#b55">[56]</ref> operational states of data by Chi <ref type="bibr" target="#b8">[9]</ref>, five factors (data, task, skill, context and interaction) by Pfitzner et al. <ref type="bibr" target="#b29">[30]</ref>, and attributes of data models (e.g., continuity, connectivity, dimensionality and variable types) by Tory and Möller <ref type="bibr" target="#b40">[41]</ref>. A noticeable contribution of Tory and Möller's work is a common taxonomic framework for both scientific and information visualization.</p><p>In addition, there are a number of taxonomical studies on interaction in visualization (e.g., <ref type="bibr" target="#b41">[42,</ref><ref type="bibr" target="#b50">51,</ref><ref type="bibr" target="#b54">55]</ref>). There are also several taxonomy proposals for specific classes of techniques and applications, e.g., <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b13">14]</ref>. Brodlie proposed a notation for symbolic labeling visualization methods <ref type="bibr" target="#b2">[3]</ref>. Card and Makinlay proposed a descriptive structure for visualization <ref type="bibr" target="#b5">[6]</ref>. <ref type="bibr">Duke et al.</ref> presented an argument to bring taxonomy and ontology together <ref type="bibr" target="#b11">[12]</ref>.</p><p>There are many forms of visualization pipelines. Upson et al. provided a generic abstraction of a pipeline with four main components, data source, filtering and mapping, rendering and output <ref type="bibr" target="#b42">[43]</ref>. There are many variations, such as <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b24">25]</ref>. Van Wijk proposed an abstract model that includes perception, cognition and knowledge as part of the visualization model <ref type="bibr" target="#b44">[45]</ref>. This article inspired much discussion about the needs for theoretical frameworks for visualization. Liu et al. considered distributed cognition as a theoretic framework for informa-tion visualization <ref type="bibr" target="#b26">[27]</ref>. Purchase et al. examined three possible theoretic frameworks for information visualization, including data-centric predictive theory, information theory, and visualization process models <ref type="bibr" target="#b30">[31]</ref>. Our work builds upon their outline of the need for measuring "information transfer, content, or loss at all stages of the pipeline".</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">MODELS OF COMMUNICATION AND VISUALIZATION</head><p>Information theory was first introduced in conjunction with the model of a basic communication system <ref type="bibr" target="#b35">[36]</ref>. In this section we examine the similarity and difference between the models of communication and visualization from the perspective of information theory. <ref type="figure">Fig. 1(a)</ref> shows a typical depiction of a basic communication system considered by Shannon and Weaver <ref type="bibr" target="#b37">[38]</ref>. The source and destination of the message can be a person or a machine. The encoder (also referred to as transmitter) and decoder (also referred to as receiver) transform messages into signals and vice versa. Conceptually, the term "signal" is a generalization encapsulating messages represented by both digital and analog signals. In modern communication systems, we can simply consider both messages and signals as "data". Traditionally, the term "channel" refers to a transmission medium. In abstract, it is a function or process that operates on the input signal S and sometimes adds noise, resulting in the output signal S .</p><p>By grouping the encoder, channel and decoder into a communication subsystem, we can build more complex communication systems. <ref type="figure">Fig. 1(b)</ref> shows a point-to-point communication system composed of k subsystems. In data communication, the term "virtual channel" is often used to denote such a composite communication system, as illustrated in <ref type="figure">Fig. 1(c)</ref>. Let D be the set of all machine-representable data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Any communication system or subsystem is thus a function F : D → D.</head><p>A communication system may be affected by both internal and external noise. Historically information theory considered mainly the noise present in a channel, as most theoretic and algorithmic discussions as- <ref type="table">Table 1</ref>. Important information-theoretic concepts and applications, and their relevance in visualization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Information Theory Taxonomy</head><p>Relevance in Visualization Fundamental Concepts A possible mathematical framework that underpins the subject of visualization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Major Quantities and Properties</head><p>Quantitative measurements about the data and visualization space, and the relationship between input and output of a process or subsystem at different stages of a visualization pipeline.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Entropy</head><p>Measuring information content (see Section 5.1); salience in visualization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Mutual Information</head><p>Uncertainty reduction in visualization (see Section 5.3); information-assisted visualization.</p><p>Major Theorems Many theorems can be used to explain visualization phenomena and events.</p><p>Information balance (conservation law) Given two visualizations, A and B, the amount of information about A contained in B is the same as that about B in A; overview + detail (see Section 5.3); multi-view visualization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Data processing inequality</head><p>After visual mapping, the visualization normally cannot contain more information than the original data (see Section 6.3); information cannot be recovered after being degraded by some processes or subsystems in a visualization pipeline.</p><p>Channel Types Providing a theoretical basis for classifying visualization subsystems (see Section 6).</p><p>Noiseless channel Not common in practical visualization pipelines (see Section 3).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Noisy channel</head><p>Most visualization processes and subsystems can be affected by noise (see Section 3).</p><p>Channel Capacity It can be adapted to define the maximum amount of information that can be visualized or displayed (see Section 5.1) but a major extension is necessary when considering channels with memory and interaction (see Section 6). sume that encoders and decoders are error-free. In principle, however, noise can also affect encoders and decoders. For example, JPG encoding introduces compression errors. <ref type="figure">Fig. 1</ref>(e) depicts a general visualization pipeline, without humancomputer, human-human or inter-process interaction. Interactive exploration is important in visualization but less so in communication. We will consider interactive visualization later in Sections 6 and 8. Note that almost every process in the pipeline can be affected by noise or errors. For example, the process for data filtering may cause information loss or distortion. The visual mapping process may introduce quantization errors due to limited bandwidth in geometrical space and attribute space of visual metaphors. The rendering process may introduce distortion and ambiguity due to projection, occlusion, and color and opacity mixing. The displaying process may introduce errors due to bandwidth limitation and incorrect calibration of a display device. Even the transmission between a display and human eyes may suffer from distance attenuation. The viewing, perception and cognition processes are three human-centered processes, which are much less "mechanical" or "algorithmic" than the earlier machine-centered (or mediated) processes. As Pettersson pointed out, these three processes may be affected by many factors. In terms of noise, it ranges from external distractions to the diversity between individuals <ref type="bibr" target="#b28">[29]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Redundancy</head><p>Abstractly we can define a superset Ω as a union of the set of all machine-representable data, information and knowledge, and the set of all data, information and knowledge stored in human brains, despite that we are yet to have an adequate understanding about how information and knowledge are represented in the human brain. This generalization allows us to denote every visualization system or subsystem as a function G : Ω → Ω. The similarity between G and the above-mentioned F for the communication system is palpable.</p><p>To make the comparison easier, we can group all the processes in <ref type="figure">Fig. 1</ref>(e), except the source and destination, into a single "virtual channel" as depicted in <ref type="figure">Fig. 1(d)</ref>, which is juxtaposed with <ref type="figure">Fig. 1(c)</ref>. We can also group the pre-defined processes, from filtering to displaying, into a machine-centered virtual channel, and the three processes, from viewing to cognition into human-centered processes, resulting in a model similar to that in <ref type="figure">Fig. 1(a)</ref>. If we wish to place an emphasis on the visualization images as the intermediate "signals", we can group the eight processes, from filtering to cognition into three subsystems as in <ref type="figure">Fig. 1</ref>(e), which also results in a model similar to <ref type="figure">Fig. 1(a)</ref>. We colloquially refer the three subsystems as vis-encoder, vis-channel, and vis-decoder. In the remainder of the paper, we use the three subsystem model as the main basis for our discussions.</p><p>While the models of communication and visualization are unmistakably similar, it is necessarily to recognize the difference between typical communication and visualization systems. For example, a communication system normally assumes that encoders and decoders behave in a deterministic manner. This cannot be said for any humancentered process in a visualization system. In most communication systems, the focus is usually placed on the compact representation of data transmitted through the systems. In most visualization systems, the priority is usually given to the requirements of viewing, perception and cognition, such as intuitiveness and clarity. When translating into the vocabulary of processes, this means that the priority is given to the speed, simplicity and accuracy of the vis-decoder subsystem rather than the vis-encoder and vis-channel subsystems. Despite such difference, we will see in the following sections that information theory can explain many phenomena and events in visualization systems, including the underlying reasons for the different focuses.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">HOW INFORMATION THEORY RELATES TO VISUALIZATION</head><p>There is not much discussion about taxonomies in the literature of information theory, perhaps because it is a relatively mature subject. We thereby compiled a collection of major information theoretic concepts and applications based on a number of textbooks, including <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b43">44,</ref><ref type="bibr" target="#b46">47]</ref>. <ref type="table">Table 1</ref> lists these concepts and applications in a taxonomical manner (on the left), and provides our annotation as to their possible relevance to visualization (on the right). It is not intended to provide an exhaustive coverage of either information theory or visualization. This would be beyond the scope a single paper. For example, the textbook by Cover and Thomas <ref type="bibr" target="#b10">[11]</ref> has some 170 theorems, each of which can potentially be applied to visualization. Nevertheless, these brief annotations suggest that there are strong connections between information theory and visualization in a broad spectrum.</p><p>From the table, we can observe that there are many existing visualization techniques that can be related to concepts and algorithms in information theory, especially in relation to source coding (i.e., coding for noiseless channels). With respect to channel coding (i.e., coding for noisy channels), interactive and multi-view visualization offers a means of error detection and correction. Uncertainty visualization may also be very relevant. In general, there has been limited development in visualization, with an explicit intention to deal with the noise in visualization pipelines. This is an area that we hope future visualization techniques can address.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">QUANTIFYING VISUAL INFORMATION</head><p>To keep this article concise, our following technical discussions assume that readers are familiar with the most fundamental concepts of information theory. Detailed explanations of these concepts, and the related mathematical formulae, theorems and proofs, can be found in a number of textbooks (e.g., <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b43">44]</ref>). We adopt the notation of Cover and Thomas's book <ref type="bibr" target="#b10">[11]</ref> for this work. We use the base 2 logarithm wherever appropriate, so bit is the unit of the main information theoretic quantities such as entropy H and mutual information I .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Entropy</head><p>Entropy is a fundamental measure in information theory. There are two common descriptions of entropy H (X). It can be thought of as the average uncertainty in a random variable X, or the minimal number of bits that are required on average to describe this variable. The random variable X takes a finite number of values x 1 , x 2 ,...,x m , each with a probability p(x i ). p is referred to as a probability mass function. Such a random variable can be used to describe the probabilistic attributes of a variety of entities, phenomena and events, such as all instances of data at a sample point, all datasets in a data space, and all visual representations used in an application.</p><p>Let us consider a simple, black-white time-series visualization as shown in <ref type="figure" target="#fig_1">Fig. 2(a)</ref>. Assume that the graph plotting area is given as 256 × 64 pixels. The time series has 64 independent samples, and each sample has an integer value range between 0 and 255. Samples are taken at a regular temporal step. The visualization displays 64 pixels corresponding to the random samples, and the connecting lines between consecutive samples. The probability mass function of each sampling value is independent and identically-distributed, we have p = 1/2 8 . Let S denote the random variable for a single sample, and Z denote the data space encompassing all time series with 64 samples. <ref type="figure" target="#fig_1">Fig. 2(a)</ref> shows an instance z ∈ Z. The entropy for this variable Z is calculated as:</p><formula xml:id="formula_2">H (Z) = 64 ∑ t=1 H (S t ) = − 64 ∑ t=1 255 ∑ i=0 1 2 8 log 2 1 2 8 = 512.<label>(1)</label></formula><p>This is very much expected as the time series requires a minimum of 64 bytes (i.e., 512 bits) to encode. In theory, we can also display this binary code as shown in <ref type="figure" target="#fig_1">Fig. 2(b)</ref>, which would require a huge perceptual and cognitive load to decode if not impossible. <ref type="figure" target="#fig_1">Fig. 2</ref>(b) actually uses more than 1 pixel for each "bit" box, as the figure would otherwise be unreadable by human eyes. If we use only 4 × 4 pixels per "bit" box, it would result in a total of 2 <ref type="bibr" target="#b12">13</ref> bits. In practice, we choose to use a graphical (or visual) mapping G(Z) as in <ref type="figure" target="#fig_1">Fig. 2(a)</ref>, for which a plotting area with 256 × 64 black-white pixels (2 14 bits) would be a minimal requirement. For this particular design of G(Z), if it uses 2 <ref type="bibr" target="#b13">14</ref> bits of display space, it is capable of depicting on average 512 bits of information.</p><p>If all of the samples take values only in the lower half of the value range, the entropy will be 448 instead of 512. Meanwhile, most users may sensibly halve the plotting area by remapping the y-axis from [0 − 255] to [0 − 127]. The proportion of entropy reduction seems to differ from that of space reduction. It is interesting to know how well entropy relates to the visual display. We now introduce two new quantities: Visualization Capacity. Assume that the data space is sufficiently large for a static graphical mapping G, we define the average amount of information that G can depict as Visualization Capacity, V (G). G is usually constrained by a number of parameters, such as the required display space, the spatial partitioning of the display in relation to the data, use of colors, etc. Once these parameters are fixed, V (G) is the entropy of a random variable that takes all possible distinguishable outputs of this specific mapping G.</p><formula xml:id="formula_3">minimal 64 pixels X X X X X X X X X X X byte 1 7 6 5 4 3 2 1 0 X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X 192 X X X X X X X X X X X X X X X X X XX X X X X X X X X X X X X X X byte 16 128 256 pixels X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X 64 pixels byte 32 128 minimal 2 X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X minimal 6 y 64 X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X byte 48 X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X 0 X X X X X X X X X X X X X X X X X X X X X minimal byte 64 (a) (b)</formula><p>For a specific input data space X, we have V (G) = min(V (G(X)), H (X)). The "min" function indicates that a visualization normally cannot display more information than what is contained in the input data space X. This follows the principle of data processing inequality in information theory <ref type="bibr" target="#b10">[11]</ref>. However, in visualization, it is often advantageous to break the conditions of this principle. We will discuss this further in Section 6.3.</p><p>Display Space Capacity. We define the display bandwidth available for visualization as Display Space Capacity, D, which takes into account of the number of pixels in the display, and the depth of each pixel. Note that D is independent of a data space X or a graphical mapping G. It indicates the maximum entropy achievable by any graphical mapping within this display space.</p><p>Yang-Peláez and Flowers <ref type="bibr" target="#b53">[54]</ref> proposed measurements similar to H (X), V (G) and D, but theirs were based on a uniform probability  distribution of X. Here we do not impose this restriction for H (X) and V (G), as a priori knowledge about the distribution is usually an essence of a design process in visualization. Later in Section 7, we will show an example how a non-uniform probability mass function leads to a commonly-used visual representation. The quantities V and D have the same unit as entropy H . This allows us to define the following measurement:</p><formula xml:id="formula_4">Visual Mapping Ratio (VMR) = V (G) H (X) . (2) Information Loss Ratio (ILR) = max(H (X) − V (G), 0) H (X) . (3) Display Space Utilization (DSU) = V (G) D .<label>(4)</label></formula><p>Here we assume H (X) &gt; 0. When H (X) = 0, there is no uncertainty or information in X <ref type="bibr" target="#b10">[11]</ref>. Similarly we assume D &gt; 0.</p><p>Using the time series visualization in <ref type="figure" target="#fig_1">Fig. 2(a)</ref> as an example, we have H (Z) = 512 = 2 <ref type="bibr" target="#b8">9</ref> , V (G) = 2 <ref type="bibr" target="#b8">9</ref> , and D = 2 <ref type="bibr" target="#b13">14</ref> . Hence, VMR = 1, ILR = 0, and DSU = 2 −5 = 0.03125.</p><p>For the above example of remapping the y-axis from [0 − 255] to [0 − 127], we can obtain H (Z) = 448 = 7 × 2 <ref type="bibr" target="#b5">6</ref> , V (G) = 7 × 2 <ref type="bibr" target="#b5">6</ref> , and D = 2 <ref type="bibr" target="#b12">13</ref> . Hence, the entropy and visualization capacity reduce proportionally the same number of bits. Note that VMR, ILR and DSU are measurements of ratios, and thus unitless.</p><p>From the perspective of data compression, coding an 8-bit value using 2 8 bits for each sample seems totally insane. Nevertheless, it makes sense for visualization. The human visual system is a highly parallel system. It takes a single viewing step to determine that in <ref type="figure" target="#fig_1">Fig.  2(a)</ref> has a starting value of 64. It would take 8 viewing steps, together with much cognitive reasoning, to establish this fact from <ref type="figure" target="#fig_1">Fig. 2(b)</ref>. There is thus no reason to be apprehensive about the apparently "inefficiency" of visualization from the perspective of data compression.</p><p>This suggests that application of information theory to visualization needs to accommodate and address a different emphasis.</p><p>However, there is often not 2 k bits of display space for every kbit value as we are usually constrained by a limited number of pixels available in most practical applications. In such a situation, the above measurements provide us with a quantitative evaluation of a visual design G. For instance, let us reduce the display space from 64 × 256 pixel to 64 × 64 pixels. We denote the new Display Space Capacity as D , which is 2 <ref type="bibr" target="#b11">12</ref> bits. The geometry mapping of the original visual design G has to be modified. The new design G may not be able to depict the full amount of raw data.</p><p>Consider a simple data mapping function, M, that maps the abovementioned time series data space Z to a new data space Z , where each value j ∈ Z is mapped to i ∈ Z such that i = j/4 . We have:  <ref type="figure" target="#fig_7">Fig. 5(a)</ref> shows a visualization of M(z), where z ∈ Z is the same time series as in <ref type="figure" target="#fig_1">Fig. 2(a)</ref>. In Section 7, we will discuss the relative merits of several visual mappings for a different data space on the same 64 × 64 display.</p><formula xml:id="formula_5">V</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Joint Entropy and Conditional Entropy</head><p>In visualization, it is common that many events are inter-related. For example, in interactive exploration, a user may first obtain an overview visualization G overview of a dataset, and then apply a zoom-in operation, resulting in one of the possible detailed views G detail <ref type="bibr">[i]</ref> . The information contained in G detail <ref type="bibr">[i]</ref> is thus related to that in G overview .</p><p>Let X and Y be two random variables with a joint probability mass function p(x, y). H (X,Y ) denotes the joint entropy of the two variables; H (Y |X = x) denotes the conditional entropy of Y given that X is known to be x; and H (Y |X) denotes the conditional entropy of Y for all possible events in X.</p><p>Consider that X and Y model the probabilistic attributes of G overview and G detail[i] respectively. Here X and Y represent two visualization spaces, G overview (Z) and G detail[i] (Z), where Z is the input data space shared by both views. We can apply some fundamental theorems in information theory to explain different phenomena in the overviewdetail situation. Below are examples of applying two such theorems. Rule 1. H (X,Y ) ≤ H (X) + H (Y ) [1] -The joint uncertainty of the two views does not exceed the sum of the uncertainty exhibited by each individual view. In other words, having two views can reduce uncertainty. The equality is valid only when X and Y are independent, i.e., G overview and G detail <ref type="bibr">[i]</ref> are not related to each other.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Rule 2. H (Y |X) ≤ H (Y ) [19] -In the overview-detail situation, the possible variations of G detail[i]</head><p>is strongly governed by those of G overview . As illustrated in <ref type="figure" target="#fig_3">Fig. 3</ref>, the distribution and orientation of the visual primitives in the overview determine the overall trend of the distribution and orientation of those in the detailed view. If the event of the square box to be zoomed is known, the entropy of G detail[i] is reduced significantly. After having seen the overview, the viewer has a rough idea about the detailed view G detail <ref type="bibr">[i]</ref> , and hence is less uncertain about it. Information-theoretically, this means H (Y |X = x) &lt; H (Y ).</p><p>In particular, this rule underpins the design principle for interactive exploration with overview, zoom and detailed views <ref type="bibr" target="#b38">[39]</ref>.</p><p>In situations where H (Y |X = x) is not as low as the viewer expected, the viewer would be either confused or surprised. For example, if a visualization system did not follow the basic design guideline that a zoom operation should ensure a succeeding view G k+1 has the same orientation of the preceding view G k , the uncertainty about G k+1 will be significantly increased. In the case of <ref type="figure" target="#fig_3">Fig. 3</ref>, most viewers would be confused when encountering a rotated <ref type="figure" target="#fig_3">Fig. 3</ref>(b) (e.g., by 90 • ).</p><p>Alternatively, a viewer may be surprised to see some vortices in <ref type="figure" target="#fig_3">Fig. 3(b)</ref> as there may not be a hint of its existence in <ref type="figure" target="#fig_3">Fig. 3(a)</ref>. In such a situation, the instinctive expectation of a higher conditional entropy is disadvantageous, especially in very large dataset visualization.</p><p>Much research effort has been made to extract important features and highlight such features in higher level views (e.g., <ref type="bibr" target="#b22">[23]</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Mutual Information</head><p>Mutual information I (X;Y ) measures the amount of the reduction of uncertainty of one random variable X due to the knowledge of another Y . In information theory, there are a number of fundamental rules about mutual information, which are applicable to visualization events. For example, Rule 3. I (X;Y ) = I (Y ; X) <ref type="bibr" target="#b10">[11]</ref> -This implies that the information about G overview in G detail <ref type="bibr">[i]</ref> is the same as that about G detail <ref type="bibr">[i]</ref> in G overview . Undoubtedly, in most cases, the information about G detail <ref type="bibr">[i]</ref> resides primarily in the corresponding window in G overview . Let us partition G overview into n disjoint windows, each corresponding to a G detail <ref type="bibr">[k]</ref> , k = 1, 2,...,n. We have:</p><formula xml:id="formula_6">∑ n k=1 I (G detail[k] ; G overview ) = ∑ n k=1 I (G overview ; G detail[k] ) (6)</formula><p>The left-hand side represents the total mutual information about all detailed views in an overview, while the right-hand represents the total mutual information about the overview in all n detailed views. The former corresponds to one viewing step, but the latter n viewing steps. This confirms the principle of overview first and details after <ref type="bibr" target="#b38">[39]</ref>.</p><p>Mutual information can also be used to quantify the effectiveness of a type of visualization. Consider a simplified example, where a viewer makes a decision to zoom-in about the box in <ref type="figure" target="#fig_3">Fig. 3(a)</ref> based on whether there is a hint of vortices in the box. Let A be a random variable with two possible states, "show hints" and "show no hint" in that box. Similarly, let B be a variable about the detailed view of the box, with two possible states, "show at least one vortex" and "show no vortex". <ref type="table" target="#tab_4">Table 2</ref> shows an example joint probability mass function p(a, b) in columns 3 and 4. We obtain I (B; A) ≈ 0.147, indicating the amount of uncertainty of <ref type="figure" target="#fig_3">Fig. 3(b)</ref> that can possibly be reduced by having visualized <ref type="figure" target="#fig_3">Fig. 3(a)</ref>. Suppose that we introduce a feature highlighting technique to improve <ref type="figure" target="#fig_3">Fig. 3(a)</ref>, as shown in <ref type="figure" target="#fig_3">Fig. 3(c)</ref>. C is a random variable similar to A but corresponds to <ref type="figure" target="#fig_3">Fig. 3(c)</ref>. The new probability mass function p(c, b) is given in columns 6 and 7 of <ref type="table" target="#tab_4">Table 2</ref>. The technique results in a 40% probability (instead of 25% previously) of showing a hint of any vortex in the same box area. Although the false positive has increased from 5% to 10%, the mutual information I (B;C) has risen to about 0.278. In other words, <ref type="figure" target="#fig_3">Fig.  3</ref>(c) can now tell more about <ref type="figure" target="#fig_3">Fig. 3(b)</ref> in terms of vortices. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">INFORMATION SOURCES AND COMMUNICATION CHANNELS</head><p>In information theory and its application of data communication, the terms of information sources and communication channels are formally defined and categorized. In this section, we propose our adaptation of these concepts from the perspective of visualization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Information Sources</head><p>An information source is a process that produces a message or a sequence of messages to be communicated. A source is said to be "memoryless" if each message is an independent random variable and obeys the same probability distribution stochastically as the other messages. A source is said to be "stationary" if its probability distribution is spatially and temporally invariant. In information theory, these two properties are the preconditions of many theorems <ref type="bibr" target="#b18">[19]</ref>. The preconditions are also commonly assumed by most communication systems and compression algorithms.  A visualization system may encounter three types of information sources, namely input data, interaction, and pre-stored knowledge. If we focus only on the input data, as in Section 3, the parallel between visualization and communication is apparent <ref type="figure">(Fig. 1)</ref>. In most cases, assuming that the input is a memoryless and stationary source is a sensible abstraction for both theoretic and algorithmic development.</p><formula xml:id="formula_7">y 1 x 1 X Y noisy p(y 1 |x 1 ) x 1 y 1,1 y 1,2 lossless X Y y 1 x 1,1 x 1,2 deterministic X Y x 1 X noiseless y 2 x 2 p(y 1 |x 2 ) ( | ) y 1,</formula><p>Interaction allows users to provide a visualization system with additional information, such as viewing parameters and mapping functions, resulting in different output data.</p><p>Pre-stored knowledge includes hard-coded knowledge (e.g., feature recognition) in vis-encoder, and human knowledge in vis-decoder ( <ref type="figure">Fig. 1(e)</ref>). The former normally is not of a stochastic nature, but this may change in future systems with the introduction of knowledgeassisted visualization <ref type="bibr" target="#b7">[8]</ref>. The latter is stochastic, especially when considering the whole population of potential users of a system.</p><p>There is still a major scientific gap in understanding the probabilistic properties of human interaction and human knowledge. Many existing theorems in information theory may not be readily applicable when such information sources are considered, and some adaptation and extension of information theory will be necessary.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Channels</head><p>A channel is the medium over which coded messages are transmitted from the encoder to the decoder. Here, we consider only discrete channels. In communication, unintended changes could be made to a coded message, resulting in errors in transmission. Such changes are referred to as noise or perturbation. A channel may have properties such as bandwidth, transmitted power and error rate.</p><p>Let X and Y denote the random variables corresponding respectively to the input and output of a channel. <ref type="figure" target="#fig_5">Fig. 4(a)</ref> shows a typical noisy channel, where an input message x i may be received as y j with a probability mass function p(y j |x i ).</p><p>In visualization, X and Y typically represent various input and output data spaces of each subsystem in <ref type="figure">Fig. 1(e)</ref>, while x i and y i represent instances in each space. For example, considering a vis-encoder subsystem for the time series visualization in <ref type="figure" target="#fig_1">Fig. 2(a)</ref>, we have X = Z for the space of raw data and Y = G(Z) for the space of visualization images. When we study a particular algorithmic component of a subsystem, e.g., a filtering or clustering function, X and Y can also represent the input and output spaces related only to this component.</p><p>Many processes in a visualization pipeline are noisy channels. In a vis-decoder subsystem, a graphical object depicted in a visualization can easily result in different interpretations by different viewers. Using the notation in <ref type="figure" target="#fig_5">Fig. 4(a)</ref>, it means that an instance x 1 , for example, may be probabilistically interpreted as different instances y i ∈ Y , with different p(y i |x 1 ), i = 1, 2,...,m. When x 1 is intended to be seen as a specific y k , we would like to maximize p(y k |x 1 ). This can be achieved by a better design of the visual mapping, or by helping the viewers to detect errors.</p><p>A channel is said to be "lossless" if every input message can be uniquely determined from an output message as illustrated in <ref type="figure" target="#fig_5">Fig.  4(b)</ref>. Though it is a one-to-many mapping for each x i , the mapped messages {y i,1 , y i,2 ,...,y i,k i } are grouped into a set corresponding to x i uniquely. Such a channel has a conditional entropy H (X|Y ) = 0 for all input distribution. The "lossless" channel, which introduces redundancy, provides a mean for error detection and correction in communication. We will examine this in Section 8.</p><p>A channel is said to be "deterministic" if every input message uniquely determines an output message, as shown in <ref type="figure" target="#fig_5">Fig. 4(c)</ref>. Such a channel has a conditional entropy H (Y |X) = 0 for all input distribution, and can facilitate abstraction. For example, quantization at different stages of the pipeline, such as color mapping, or the range mapping M in Section 5.1, behaves as a "deterministic" channel.</p><p>A channel is said to be "noiseless" if it is lossless and deterministic, resulting in a one-to-one mapping between input and output messages as illustrated in <ref type="figure" target="#fig_5">Fig. 4(d)</ref>. In visualization, such a channel is only desirable when the input data space is small. For large scale data visualization, a totally noiseless visualization system may be neither practical nor helpful.</p><p>In visualization, an abstraction process often does not throw the original data away, and the abstraction is merely used to support visual mapping, e.g., assigning colors to data points in different clusters. In other words, such a process is a combination of "deterministic" and "noiseless" channels. This mechanism is commonly used in supporting visual categorization, and focus of attention.</p><p>A channel is said to be "useless" if every output message has an equal chance of resulting from any input message, as shown in <ref type="figure" target="#fig_5">Fig.  4(e)</ref>. In terms of entropy, we have H (X|Y ) = H (X).</p><p>A discrete channel is said to be "memoryless" if the probability distribution of the output depends only on the input at that time, and is independent of previous inputs and outputs of the channel <ref type="bibr" target="#b10">[11]</ref>. The channels in vis-decoder are certainly not memoryless, while interaction introduces historical dependency. This hinders the direct application of some major theorems in information theory, e.g., Shannon's channel coding theorem <ref type="bibr" target="#b35">[36]</ref>. Nevertheless, the basic idea for handling errors in noisy channels is very much applicable to visualization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">On Data Processing Inequality</head><p>It is necessary to note that the actual size of a data set may increase after calling a visualization process. However, in principle, the visualization process does not generate more information than what is in the original data space. In communication, it is referred to as data processing inequality <ref type="bibr" target="#b10">[11]</ref>, which states: if random variables X, Y , Z form a Markov chain in the order of X → Y → Z, then we have the following inequality between their mutual information:</p><formula xml:id="formula_8">I (X;Y ) ≥ I (Y ; Z)<label>(7)</label></formula><p>X, Y , Z are said to form a Markov chain if Z depends only on Y and is conditionally independent of X.  If we only allow data input as the information source for the channels in the chain, this inequality stands. However, this principle should not be naively applied to all visualization processes, because the pipeline is mostly not a Markov chain.</p><p>Firstly, many processes in visualization are interactive processes, so we cannot guarantee that Z solely depends on Y . Secondly, even if there is no interaction, we usually take into account our knowledge about the raw data (e.g., X), when we design an algorithm at a late stage of the chain (e.g., for Y → Z). Z is not conditionally independent of X. The condition for a Markov chain is thus broken.</p><p>In fact, we should not be disappointed by the fact that the data processing inequality is not as ubiquitous in visualization as one would expect. This fact only implies that interaction and domain knowledge about the raw data are critical in breaking the bottleneck of "data processing inequality". This explains why most visualization systems are interactive systems, and supports the argument for knowledge-assisted visualization <ref type="bibr" target="#b7">[8]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">CODING IN NOISELESS CHANNELS</head><p>In data communication, coding schemes are broadly divided into two main categories, namely source coders and channel coders. A source coder focuses on the messages from the source, and tries to find the most compact representation of the messages. A channel coder focuses on the noise on the channel, and tries to find a cost-effective representation that can help detect or/and correct errors introduced by the channel. We study these two categories in the context of visualization in this section and Section 8 respectively.</p><p>As we can see from <ref type="table">Table 1</ref>, there is a good collection of source coding schemes designed for noiseless channels. Many of these schemes correlate to some visualization techniques. Most importantly, they can inspire us to develop new data abstraction and visual encoding techniques. Here we give one example of such schemes to illustrate the relevance of source coding to visualization. We call this scheme Entropy-based Spatial Mapping.</p><p>Recall the time series example in <ref type="figure" target="#fig_7">Fig. 5</ref> For example, when d = 2, we have four sub-ranges, with probabilities, 1/2, 1/4, 1/8 and 1/8 respectively. <ref type="figure" target="#fig_7">Fig. 5(b)</ref> shows the visualization of such a time series, which uses the same linear mapping from [0, 255] to [0, 63] as in <ref type="figure" target="#fig_7">Fig. 5(a)</ref>. Assume that p(w i, j ) within each sub-range is independent and identically-distributed. We thus have p(w i, j ) = 1/2 7 in R 1 , 1/2 8 in R 2 , and 1/2 9 in R 3 and R 4 . The data space entropy H (W ) is the sum of entropies of the four sub-ranges. The visualization capacity for the linearly mapped data is the sum of those of the sub-ranges. We have H (W ) = 496 and V (G l (W )) = 368.</p><p>Hence, we have visual mapping ratio VMR l = 368/496 ≈ 0.742, information loss ratio ILR l = (496 − 368)/496 ≈ 0.258, and display space utilization DSU l = 368/2 12 ≈ 0.09. In comparison with a uniform distribution (Section 5.1), the visualization capacity V is slightly reduced, while there is slightly more information loss, poorer utilization of display space.</p><p>Let us consider a non-linear mapping function, which maps  <ref type="bibr" target="#b55">[56,</ref><ref type="bibr">63]</ref>. It is not difficult to derive that V (G nl (W )) = 384 with VMR nl ≈ 0.774, ILR nl ≈ 0.226, and DSU nl ≈ 0.094. We have slightly improved the visualization capacity, and as well reduced information loss. When we plot out G nl in <ref type="figure" target="#fig_7">Fig. 5(c)</ref>, this is conceptually similar to a logarithmic mapping in <ref type="figure" target="#fig_7">Fig. 5(d)</ref>.</p><p>If we increase the number of sub-ranges, for instance, for d = 3, 4, 5, the improvement becomes more significant and interesting as shown in <ref type="table" target="#tab_6">Table 3</ref>. For d = 3, 4, 5, the six lower data ranges are mapped to six visualization ranges with 32, 16, 8, 4, 2, 1 pixels respectively. The remaining high-value data ranges are mapped to a single 1-pixel range. The non-linear mapping manages to maintain the visualization capacity at 384. The higher d is, the closer the distribution is to a logarithmic distribution. In other words, logarithmic plots are in effect a means to increase visualization capacity V when the distribution of the sample values follows a certain logarithmic pattern. This explains why logarithmic plots are commonly used in sciences and engineering.</p><p>Conceptually entropy-based spatial mapping bears a strong resemblance to entropy coding in data compression and communication. The latter is a family of coding schemes, which replace fixed-length codewords with variable-length codewords. The well-known entropy encoding schemes include Huffman encoding, Shannon-Weaver-Fano encoding and arithmetic encoding.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">CODING IN NOISY CHANNELS</head><p>In visualization, interaction is the primary means for helping a viewer to detect and correct errors. For example, in medical visualization, a volumetric model (e.g., a CT scan dataset) is often displayed using direct volume rendering. In a resulting visualization, as illustrated in <ref type="figure" target="#fig_9">Fig. 6</ref>, samples at different depth along the same ray are projected onto the same pixel, and the colors and opacities of these samples are combined according to the volume rendering integral, resulting in a pixel color capturing information from many samples. The process itself is very similar to frequency-division multiplexing in communication, where different signals are transmitted in several distinct frequency ranges over that same medium. However, in the case of volume visualization, we cannot assure the distinctive separation between different frequency ranges, though a good transfer function may provide more visual cues to alleviate the problem. Furthermore, there is a substantial loss of 3D information in a 2D projection. In other words, viewers are expected to make mistakes in determining the shapes depicted in such a visualization.</p><p>Typically, a viewer interactively rotates the volume, receiving multiple visualizations for the same model. From these interactively generated visualizations, the imprecise models perceived initially gradually converge to a more accurate 3D model in the viewer's mind. Conceptually, this is similar to "backward error correction" (or automatic repeat request) in communication, which requests for retransmission of erroneous data. The changes of viewing positions spread errors across different parts of the model, making error detection and correction possible for each individual part. This is conceptually very similar to multidimensional parity-check coding, which is a type of block-based error correction schemes.</p><p>Multi-view visualization is another means for error detection and correction, especially in visualizing non-spatial data, where errors are often due to the perceptual load of visual search, change detection and attention. Multi-view visualization allows the same information to be found in different views, increasing the probability of locating the information. This is very similar to repetition coding schemes in data communication.</p><p>This naturally leads to the issue of redundancy. All error detection or correction coding schemes cause redundancy. Rheingans and Landreth studied the benefits of redundancy in visualization <ref type="bibr" target="#b31">[32]</ref>. They found that (i) different parameters of a visual mapping convey different types of information with different efficiency, (ii) multiple display parameters can overcome visual deficiencies; (iii) multiple display parameters reinforce each other. Information theory can provide support to their conclusions.</p><p>Considering that the vis-decoder part of the pipeline in <ref type="figure">Fig. 1</ref> is highly noisy, it is a great challenge to design visual mappings with built-in error detection and correction mechanisms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9">THE ROLE OF USER STUDIES</head><p>In previous sections, we have shown that information theory provides a quantitative measure about information in a visualization context. We do not however suggest that such quantitative measurements might replace user studies. On the contrary, the above discussions have naturally led to the question as to what is the role of user studies from the perspective of information theory, since users studies produce statistics about phenomena and events in visualization.</p><p>In an information-theoretic framework, user studies have a much bigger role than what is in the state of the art of visualization. A fundamental component of any information-theoretic measure is the probability mass function. Perhaps we may estimate such a function for an input variable X based on our domain knowledge about the application concerned, or we may obtain this by placing a data flow monitor in the vis-encoder part of the visualization pipeline ( <ref type="figure">Fig. 1(e)</ref>). However, we simply do not have sufficient knowledge about human perception and cognition in order to estimate such a function yet.</p><p>Recall the overview+detail example in Section 5.3, the two joint probability mass functions in <ref type="table" target="#tab_4">Table 2</ref> are synthetic data to demonstrate a mathematical concept. However, such data can be collected through user studies, and to a certain extent, may also be collected seamlessly through users' interaction with the system. The challenges will be our understanding of what probabilistic attributes are fundamental and generic in visualization, so we can estimate a finite set of probability mass functions to be used in practical applications of information theory. For example, in language processing, we have statistics about probability of the appearance of each English letter, the conditional probability about one letter after another, the redundancy in printed English, and so on. Such statistically estimated probability mass functions have been used effectively in applications such as data compression and hand-writing recognition. If we have such fundamental statistical findings from visualization user studies, we can transfer information theory to practice in visualization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="10">CONCLUSIONS</head><p>In this paper, we have reported our theoretic findings on whether information theory can become one of the theoretic frameworks of visualization. Our contributions are:</p><p>• We have presented an information theoretic view of a visualization pipeline <ref type="figure">(Fig. 1</ref>).</p><p>• We have examined information theory and its major applications taxonomically, and established connections between information theory and visualization in a broad spectrum <ref type="table">(Table 1</ref>).</p><p>• We have applied the information-theoretic measures to several aspects of visualization, and we have consolidated and extended the measures proposed in <ref type="bibr" target="#b53">[54]</ref>. We have used examples to show that these quantities can explain some phenomena and events in visualization (e.g., visual mapping, and overview+detail).</p><p>• We have shown that the major concepts of information theory, ranging from information sources to channel coding theory, and from data processing inequality to redundancy, are all relevant to visualization. In some cases (e.g., channel coding theory), adaptation and extension are necessary. In other cases (e.g., data processing inequality), visualization exhibits features that are not commonly seen in data compression and communication.</p><p>• We have also studied the parallel of source coding and channel coding in the context of visualization, and the role of user studies in the framework, suggesting challenges in dealing with noisy channels in visualization, and in organizing user studies from an information theoretic perspective.</p><p>Based on these, we can state that information theory can explain a very large collection of phenomena and events in visualization. It can provide visualization with a theoretic framework, underpinning many aspects of visualization, including but not limited to visual mapping, interaction, user studies, quality metrics, and knowledge-assisted visualization. Having a theoretic framework is only a start. For future work, we quote Shannon's words, it will be a "slow tedious process of hypothesis and experimental verification" <ref type="bibr" target="#b36">[37]</ref>.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Noise</head><label></label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>(a) A 64-sample time series with possible integer values ranging between 0 and 255 is plotted as a line graph. A display space with a minimal of 256x64 pixels will be necessary to depict all information possibly contained in the data space. (b) The same time series can in theory be displayed using 64x8 pixels. In practice, more pixels are needed to make individual squares more distinguishable.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>an overview with feature highlighting</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 3 .</head><label>3</label><figDesc>An example flow visualization, where the overview in (a) may not show enough information to encourage a user to explore the detailed view in (b). Using feature extraction and highlighting, the new overview in (c) contains more feature-related mutual information about (b).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>(G ) = H (Z ) = H (M(Z)) = − = 384/512 = 0.75, ILR = (512 − 384)/512 = 0.25, and DSU = 384/2 12 ≈ 0.094.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 4 .</head><label>4</label><figDesc>Five common types of communication channels.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 5 .</head><label>5</label><figDesc>(a) Reduced display may result in information loss. When displaying the same time series inFig. 2(a) using only 64x64 pixels, the visualization capacity V is reduced from 512 to 384 bits, resulting in 25% information loss. (b) For a data space with a non-uniform probability mass function p, the visualization capacity V is further reduced to 368, while the entropy of the input data is now 496. (c) Using 4 regional spatial mappings, one can improve V and reduce the information loss. However, though this is entropy-based, the transitions between the 4 data ranges are not continuous. (d) One can replace (c) with a logarithmic plot to maintain the continuous spatial transition.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head></head><label></label><figDesc>(a). The original data space is Z, where Z = {z i, j |i = 1, 2,...,64; j = 0, 1,...,255}. Consider a different data space W . Its value range [0, 255] is divided into 2 d equalsized sub-ranges, R 1 , R 2 ,...,R 2 d , where d may take an integer value between 0 and 8. Each sub-range thus has 2 8−d possible data values. Fig. 5(a) is an instance when d = 0, after a linear mapping of the value range from [0, 255] to [0, 63]. When d &gt; 0, the probability mass function, p(w i, j ) varies according to the sub-ranges. Suppose that there is a 1/2 k chance that the sample values will fall into subrange R k , k = 1,...,2 d − 1. The chance for sub-range R 2 d is the remainder of probability, i.e., R 2 d and R 2 d −1 have the same probability.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig. 6 .</head><label>6</label><figDesc>Motion parallax<ref type="bibr" target="#b16">[17]</ref>, facilitated by interaction and real-time rendering, is a form of error correction in visualization.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>•</head><label></label><figDesc>Min Chen is with Swansea University, E-mail: m.chen@swansea.ac.uk.</figDesc><table /><note>• Heike Jänicke is with Ruprecht-Karls-University Heidelberg, E-mail: heike.jaenicke@iwr.uni-heidelberg.de. Manuscript received 31 March 2010; accepted 1 August 2010; posted online 24 October 2010; mailed on 16 October 2010. For information on obtaining reprints of this article, please send email to: tvcg@computer.org.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 2 .</head><label>2</label><figDesc>Two example joint probability mass functions p(a, b) and p(c, b).</figDesc><table><row><cell></cell><cell>p(b)</cell><cell></cell><cell>p(a, b)</cell><cell>p(b)</cell><cell cols="2">p(c, b)</cell></row><row><cell></cell><cell></cell><cell cols="2">hint no hint</cell><cell></cell><cell cols="2">hint no hint</cell></row><row><cell>vortex</cell><cell>0.5</cell><cell>0.25</cell><cell>0.25</cell><cell>0.5</cell><cell>0.4</cell><cell>0.1</cell></row><row><cell>no vortex</cell><cell>0.5</cell><cell>0.05</cell><cell>0.45</cell><cell>0.5</cell><cell>0.1</cell><cell>0.4</cell></row><row><cell></cell><cell>p(a)</cell><cell>0.3</cell><cell>0.7</cell><cell>p(c)</cell><cell>0.5</cell><cell>0.5</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 3 .</head><label>3</label><figDesc>Quantities and measures of different number of sub-ranges. When the number is 2 d , d &gt; 1, the probability mass function varies logarithmically in different sub-ranges.</figDesc><table><row><cell># sub-ranges</cell><cell>1, 2</cell><cell>4</cell><cell>8</cell><cell>16</cell><cell>32</cell></row><row><cell>entropy H</cell><cell>512</cell><cell>496</cell><cell>447</cell><cell>384</cell><cell>320</cell></row><row><cell>linear V (G l )</cell><cell>384</cell><cell>368</cell><cell>319</cell><cell>256</cell><cell>192</cell></row><row><cell>linear VRM l</cell><cell cols="5">0.750 0.742 0.714 0.667 0.600</cell></row><row><cell>linear ILR l</cell><cell cols="5">0.250 0.258 0.286 0.333 0.400</cell></row><row><cell>linear DSU l</cell><cell cols="5">0.094 0.090 0.078 0.062 0.047</cell></row><row><cell>non-linear V (G nl )</cell><cell>-</cell><cell>384</cell><cell>384</cell><cell>384</cell><cell>384</cell></row><row><cell>non-linear VRM nl</cell><cell>-</cell><cell cols="4">0.774 0.859 1.000 1.200</cell></row><row><cell>non-linear ILR nl</cell><cell>-</cell><cell cols="4">0.226 0.141 0.000 0.000</cell></row><row><cell>non-linear DSU nl</cell><cell>-</cell><cell cols="4">0.094 0.094 0.094 0.094</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head></head><label></label><figDesc>R 1 : [0, 63] to [0, 31], R 2 : [64, 127] to [32, 47], R 3 : [128, 191] to [48, 55], and R 4 : [192, 255] to</figDesc><table /><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Acknowledgment. The authors wish to thank Professor Mark Bell (Purdue University) for identifying a calculation error in an early draft.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Information Theory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ash</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1965" />
			<publisher>John Wiley &amp; Sons</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">View selection for volume rendering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Bordoloi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H.-W</forename><surname>Shen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Visualization</title>
		<meeting>IEEE Visualization</meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="487" to="494" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A classification scheme for scientific visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Brodlie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Animation and Scientific Visualization</title>
		<editor>R. A. Earnshaw and D. Watson</editor>
		<imprint>
			<publisher>Academic Press</publisher>
			<date type="published" when="1993" />
			<biblScope unit="page" from="125" to="140" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Isosurface similarity maps</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bruckner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Möller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics Forum</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="773" to="782" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Interactive high-dimensional data visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Buja</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Cook</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">F</forename><surname>Swayne</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Computational and Graphical Statistics</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="78" to="99" />
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">The structure of the information visualization design space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Card</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Mackinlay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Information Visualization</title>
		<meeting>IEEE Information Visualization</meeting>
		<imprint>
			<date type="published" when="1997" />
			<biblScope unit="page" from="92" to="99" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">An information-theoretic view of visual analytics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer Graphics and Applications</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="18" to="23" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Data, information and knowledge in visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ebert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Hagen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">S</forename><surname>Laramee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Van Liere</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K.-L</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Ribarsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Scheuermann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Silver</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer Graphics and Applications</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="12" to="19" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A taxonomy of visualization techniques using the data state reference model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">H</forename><surname>Chi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Information Visualization</title>
		<meeting>IEEE Information Visualization</meeting>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="page" from="69" to="75" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">On the semantics of interactive visualizations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">C</forename><surname>Chuah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">F</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Information Visualization</title>
		<meeting>IEEE Information Visualization</meeting>
		<imprint>
			<date type="published" when="1996" />
			<biblScope unit="page" from="29" to="36" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Elements of Information Theory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">M</forename><surname>Cover</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Thomas</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006" />
			<publisher>John Wiley &amp; Sons</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Do you see what I mean?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">J</forename><surname>Duke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">W</forename><surname>Brodlie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename><surname>Duce</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Herman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer Graphics and Applications</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="6" to="9" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">A taxonomy of clutter reduction for information visualisation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Ellis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Dix</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1216" to="1223" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">A taxonomy of 3d occlusion management for visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Elmqvist</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Tsigas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1095" to="1109" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">An information theory framework for the analysis of scene complexity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Feixas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Acebo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Bekaert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sbert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics Forum</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="95" to="106" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A unified information-theoretic framework for viewpoint selection and mesh saliency</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Feixas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sbert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>González</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Applied Perception</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="23" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Motion parallax and absolute distance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">H</forename><surname>Ferris</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology</title>
		<imprint>
			<biblScope unit="volume">95</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="258" to="63" />
			<date type="published" when="1972" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Provenance and annotation for visual exploration systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Groth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Streefkerk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1500" to="1510" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Information Theory with Applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Guiaşu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1977" />
			<publisher>McGraw-Hill</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Maximum entropy light source placement</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gumhold</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Visualization</title>
		<meeting>IEEE Visualization</meeting>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="275" to="282" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Information theoretic feature extraction for audio-visual speech recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gurban</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-P</forename><surname>Thiran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Signal Processing</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="4765" to="4776" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Introduction to Information Theory and Data Compression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Hankerson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">A</forename><surname>Harris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">D</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jr</forename></persName>
		</author>
		<imprint>
			<date type="published" when="2003" />
			<publisher>CRC Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Visual analysis of flow features using information theory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Jänicke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Scheuermann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer Graphics and Applications</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="40" to="49" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Multifield visualization using local statistical complexity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Jänicke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Wiebel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Scheuermann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Kollmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1384" to="1391" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">A model and framework for visualization exploration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Jankun-Kelly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K.-L</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gertz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="357" to="369" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Visualization techniques for mining large databases: A comparison</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename><surname>Keim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H.-P</forename><surname>Kriegel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Knowledge and Data Engineering</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">16</biblScope>
			<biblScope unit="page" from="923" to="936" />
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Distributed cognition as a theoretical framework for information visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Nersessian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Stasko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1173" to="1180" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Informationtheoretic image formation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>O'sullivan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">E</forename><surname>Blahut</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">L</forename><surname>Snyder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Information Theory</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="2094" to="2123" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Pettersson</surname></persName>
		</author>
		<title level="m">Visual Information. Educational Technology Publications</title>
		<imprint>
			<date type="published" when="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">A unified taxonomic framework for information visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Pfitzner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Hobbs</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Powers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Asia-Pacific Symposium on Information Visualisation</title>
		<meeting>Asia-Pacific Symposium on Information Visualisation</meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="57" to="66" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Theoretical foundations of information visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">C</forename><surname>Purchase</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Andrienko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Jankun-Kelly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ward</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Information Visualization: Human-Centered Issues and Perspectives</title>
		<editor>A. Kerren, J. T. Stasko, J.-D. Fekete, and C. North</editor>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2008" />
			<biblScope unit="volume">4950</biblScope>
			<biblScope unit="page">4664</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Perceptual principles for effective visualizations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Rheingans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Landreth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Perceptual Issues in Visualization</title>
		<editor>G. Grinstein and H. Levkowitz</editor>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="1995" />
			<biblScope unit="page" from="59" to="74" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Shape complexity based on mutual information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Rigau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Feixas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sbert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Shape Modeling and Applications</title>
		<meeting>IEEE Shape Modeling and Applications</meeting>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Informational aesthetics measures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Rigau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Feixas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sbert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer Graphics and Applications</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="24" to="34" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Introduction to Data Compression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Sayood</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1996" />
			<publisher>Morgan Kaufman</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">A mathematical theory of communication</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">E</forename><surname>Shannon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bell System Technical Journal</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="379" to="423" />
			<date type="published" when="1948" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">E</forename><surname>Shannon</surname></persName>
		</author>
		<title level="m">The bandwagon. IRE Transactions on Information Theory</title>
		<imprint>
			<date type="published" when="1956" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">The Mathematical Theory of Communication</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">E</forename><surname>Shannon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Weaver</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1949" />
			<publisher>University of Illinois Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">The eyes have it: A task by data type taxonomy for information visualizations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Shneiderman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Symposium on Visual Languages</title>
		<meeting>IEEE Symposium on Visual Languages</meeting>
		<imprint>
			<date type="published" when="1996" />
			<biblScope unit="page" from="336" to="343" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">A feature-driven approach to locating optimal viewpoints for volume visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Takahashi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Takeshima</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Visualization</title>
		<meeting>IEEE Visualization</meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="495" to="502" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Rethinking visualization: A high-level taxonomy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Tory</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Moller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Information Visualization</title>
		<meeting>IEEE Information Visualization</meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="151" to="158" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Characterizing interactive externalizations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Tweedie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ACM CHI</title>
		<meeting>ACM CHI</meeting>
		<imprint>
			<date type="published" when="1997" />
			<biblScope unit="page" from="375" to="382" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">The application visualization system: A computational environment for scientific visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Upson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Faulhaber</surname><genName>Jr</genName></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kamins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">H</forename><surname>Laidlaw</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Schlegel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Vroom</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Gurwitz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Van Dam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer Graphics and Applications</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="30" to="42" />
			<date type="published" when="1989" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">Information Theory for Information Technologists. MacMillan</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Usher</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1984" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">The value of visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">J</forename><surname>Van Wijk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Visualization</title>
		<meeting>IEEE Visualization</meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="79" to="86" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Automatic view selection using viewpoint entropy and its application to image-based modelling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P.-P</forename><surname>Vázquez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Feixas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sbert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Heidrich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics Forum</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="689" to="700" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Verdu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">W</forename><surname>Mclaughlin</surname></persName>
		</author>
		<title level="m">Information Theory: 50 Years of Discovery</title>
		<imprint>
			<publisher>IEEE Press</publisher>
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Importance-driven focus of attention</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Viola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Feixas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sbert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">E</forename><surname>Gröller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="933" to="940" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">LOD Map -a visual interface for navigating multiresolution volume visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H.-W</forename><surname>Shen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1029" to="1036" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Importance-driven time-varying data visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K.-L</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1547" to="1554" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Interaction spaces in data and information visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">O</forename><surname>Ward</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Eurographics/IEEE TCVG Symposium on Visualization</title>
		<meeting>Eurographics/IEEE TCVG Symposium on Visualization</meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="137" to="145" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">A problem-oriented classification of visualization techniques</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wehrend</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Lewis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Visualization</title>
		<meeting>IEEE Visualization</meeting>
		<imprint>
			<date type="published" when="1990" />
			<biblScope unit="page" from="139" to="143" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Wiener</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1948" />
			<publisher>John Wiley &amp; Sons</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Information content measures of visual displays</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yang-Peláez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">C</forename><surname>Flowers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Information Vizualization</title>
		<meeting>IEEE Information Vizualization</meeting>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="page" from="99" to="103" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Toward a deeper understanding of the role of interaction in information visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">S</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">T</forename><surname>Stasko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Jacko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1224" to="1231" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Visual task characterization for automated visual discourse synthesis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">X</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">K</forename><surname>Feiner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CHI &apos;98: Proceedings of the SIGCHI conference on Human factors in computing systems</title>
		<imprint>
			<date type="published" when="1998" />
			<biblScope unit="page" from="392" to="399" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
