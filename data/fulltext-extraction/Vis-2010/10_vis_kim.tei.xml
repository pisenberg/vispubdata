<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/pisenberg/grobid/grobid-0.6.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Interactive Visualization of Hyperspectral Images of Historical Documents</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Seon</forename><forename type="middle">Joo</forename><surname>Kim</surname></persName>
						</author>
						<title level="a" type="main">Interactive Visualization of Hyperspectral Images of Historical Documents</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2021-02-20T19:56+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Hyperspectral visualization</term>
					<term>data exploration</term>
					<term>image fusion</term>
					<term>document processing and analysis</term>
				</keywords>
			</textClass>
			<abstract>
				<p>This paper presents an interactive visualization tool to study and analyze hyperspectral images (HSI) of historical documents. This work is part of a collaborative effort with the Nationaal Archief of the Netherlands (NAN) and Art Innovation, a manufacturer of hyperspectral imaging hardware designed for old and fragile documents. The NAN is actively capturing HSI of historical documents for use in a variety of tasks related to the analysis and management of archival collections, from ink and paper analysis to monitoring the effects of environmental aging. To assist their work, we have developed a comprehensive visualization tool that offers an assortment of visualization and analysis methods, including interactive spectral selection, spectral similarity analysis, time-varying data analysis and visualization, and selective spectral band fusion. This paper describes our visualization software and how it is used to facilitate the tasks needed by our collaborators. Evaluation feedback from our collaborators on how this tool benefits their work is included.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Archives serve as the custodial record keepers of our nations' collective memories. The role of these institutions is to amass collections of historically significant records and maintain them for future generations. In recent decades, digital imaging has become a mainstay tool used by archives and related institutions such as libraries and museums in their repertoire of management and preservation methods. Processing and analyzing digital images offer a non-invasive approach to study and disseminate historical documents without the risk of damaging the primary source. In addition, digital processing allows the document's contents to be enhanced and analyzed in ways that are not possible with the actual documents themselves.</p><p>This work is done in partnership with the Nationaal Archief of the Netherlands (NAN), one of Europe's leading research archives, and Art Innovation, a manufacturer of hyperspectral imaging hardware designed for historical documents. The NAN has recently started capturing HSI of historical documents and exploring the data for a variety of tasks related to document analysis, management, and conservation. In contrast to the standard 3-channel imaging (RGB) which combines response of all visible electro-magnetic (EM) radiation into three bands, HSI captures a dense set of spectral measurements over a much broader spectral range, including the invisible spectral bands in ultra-violet (UV) and near-infrared (NIR) <ref type="figure" target="#fig_0">(Fig. 1)</ref>. This enables the HSI to provide a high-quality quantitative recording of the historical document that is decoupled from the environmental lighting. Such quantitative measurements offer new opportunities for a wide range of tasks in document management and analysis, including, but not limited to, the analysis of document elements (e.g., ink pigments, paper media, biological damage and foxing, etc.), the monitoring of spectral changes due to environmental aging, and the ability to emphasize faded or hard to see document content through spectral information.</p><p>This project is led by NAN conservator, Roberto Padoan, and senior engineer, Marvin Klein, from Art Innovation. Our role in this collaboration is the development of software to visualize and manipulate the HSI data. The capture and analysis of the highly calibrated HSI data offered by Art Innovation's hardware represents a pioneering effort in the archival community. While there is an open agenda to the potential applications of this device in the archival setting, several key tasks for using the HSI data have been established by our collaborators. The first task involves using the HSI data to analyze deterioration artifacts commonly found in archival materials, such as biological and physical damages, metal gall inks corrosion, paper oxidation (foxing), and pigment fading. This task is important to help decide on an adequate conservation treatment to avoid further damages <ref type="bibr" target="#b24">[25]</ref>. While the variations in environmental lighting, humidity, and temperature are known to induce damage to the document over the long term, the exact process of document aging is still unknown. Understanding how HSI data is correlated to the aging process will play a significant role in helping to manage valuable historical documents by measuring subtle changes that are difficult, if not impossible, to distinguish by the unaided eye. To this end, the NAN has devised an elaborate controlled experiment to induce artificial aging on a wide assortment of documents of various materials and inks. The goal is to systematically monitor and quantify changes in the HSI of these documents to track the aging process.</p><p>Another important task of our collaborators is the enhancement of deteriorated documents for improved legibility and interpretation of the materials. In particular, document content often appears more salient at different spectral bands. The goal in this task is to use the varying contextual information at different wavelength to selectively enhance the desired content in an interactive fashion.</p><p>To assist our collaborators, we have designed and implemented a comprehensive visualization tool that offers an assortment of visualization and analysis features including:</p><p>• Basic features for exploring and visualizing the HSI data to identify and monitor damages or specific region-of-interest (ROI) on archival materials. The features include interactive wavelength selection, interactive region-of-interest exploration, data similarity analysis (with user selected bands), and RGB image rendering with tunable illumination;</p><p>• Analysis and visualization tools of time-varying reflectance change for monitoring and quantifying the effects of external aging factors including lighting, and changes in humidity and temperature; • Interactive visualization of HSI data based on gradient domain fusion for enhancing the legibility of HSI data based on dynamic selection of spectral bands. There are two major contributions within this feature. First, we apply illustrative visualization to the fusion of HSI data to enhance the contextual details in the data. Second, the fusion technique makes use of the focus+context visualization by enabling the user to explore the fused result with focus on a local region while showing the regions outside with original appearance.</p><p>The remainder of the paper is organized as follows: we begin by reviewing related work in Section 2 and describe the imaging process in Section 3. Basic visualization features are explained in Section 4. Visualizing changes in the documents due to aging factors is described in Section 5, and HSI enhancement and visualization based on gradient domain fusion is presented in Section 6. We conclude with a discussion and summary that includes evaluation from our collaborators in Sections 7 and 8.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK</head><p>Visualization is highly effective in enhancing data exploration and data understanding in a wide range of applications, ranging from biology and medicine to climate research. For example, Kruger et al. <ref type="bibr" target="#b18">[19]</ref> applied GPU volume rendering for virtual sinus endoscopy, while Miller et al. <ref type="bibr" target="#b23">[24]</ref> employed interactive visualization to study the structure of intercluster galaxies with a collection of visual and analytical tools. Johnson et al. <ref type="bibr" target="#b13">[14]</ref> studied the data management and visualization aspects of large transitional flow on desktop PCs and Kehrer et al. <ref type="bibr" target="#b14">[15]</ref> demonstrated how interactive visual exploration helps scientists in climate research to evaluate their hypothesis. In this work, we deal with practical problems faced by conservators in libraries, museums, and archives, with the goal of helping them analyze and manage historical documents by deploying related analysis and visualization techniques. Document Processing. Hyperspectral imaging is a relatively new procedure in libraries and archives. Most existing work in document processing deal with standard RGB images with the focus on correcting the artifacts such as ink-bleed and corrosion. Without additional benefits of spectral bands, artifacts are detected by adaptive thresholding <ref type="bibr" target="#b26">[27]</ref>, source separation <ref type="bibr" target="#b28">[29]</ref>, or user-assisted training <ref type="bibr" target="#b21">[22]</ref>. The goal of these approaches is the detection of the artifact with little emphasis placed on the final output of the image, i.e., there is no mechanism to enhance the visualization of the data to preserve the look and feel of the original document.</p><p>There does exist prior work addressing historical documents and paintings captured using multispectral or hyperspectral imaging. Historical books and archival documents were imaged by a multispectral imaging system in <ref type="bibr" target="#b22">[23]</ref> and a hyperspectral imaging system in <ref type="bibr" target="#b24">[25]</ref> which is our collaborator's early work. In <ref type="bibr" target="#b7">[8]</ref>, a 13-channel spectral imaging system was used to capture Leonardo Da Vinci's Mona Lisa. These prior works only discussed that enhancement or restoration could be achieved using multispectral or hyperspectral imaging, however, the realization of of such enhancement was ad hoc in nature. A comprehensive framework has yet to be demonstrated.</p><p>Our work presents one of the first fully functional software for analyzing and manipulating hyperspectral images of old documents. In contrast to the methods mentioned above, our approach is user-centric with tools that allow the users to navigate the hyperspectral data and perform analytical analysis using various visualization techniques. We can also utilize the additional data in the invisible wavelength to enrich the image with details or reduce artifacts in the image while keeping it visually as close to the original RGB image as possible. Hyperspectral/Multispectral Data Visualization. Hyperspectral and multispectral imaging 1 has been applied to data ranging from those in very large scale to objects at atomic scales. Examples include spectral imaging of astrophysical data <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b20">21]</ref>, earth science data <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b9">10]</ref>, and biological and medical data <ref type="bibr" target="#b29">[30,</ref><ref type="bibr" target="#b30">31]</ref>. Among these works, most relevant works to this paper are those that focus on the visualization of hyperspectral (multispectral) geo-science data (remote sensing). In remote sensing, hyperspectral images at different spatial, temporal, and spectral resolution are fused to increase the visual saliency of the area being imaged. To merge multispectral satellite images, Choi et al. <ref type="bibr" target="#b6">[7]</ref> proposed a curvelet-based image fusion method which represents edges better than wavelets resulting in richer information in both the spatial and spectral domains. Socolinsky and Wolff <ref type="bibr" target="#b27">[28]</ref> presented an optimal grayscale visualization method by taking multispectral contrast into account to increase the quality of image fusion. Cui et al. <ref type="bibr" target="#b8">[9]</ref> introduced an interactive scheme for visualizing hyperspectral images using convex optimization. In <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b12">13]</ref>, design goals and solutions for the display of fused hyperspectral aerial images on tristimulus displays were presented. There are also softwares available for visualizing hyperspectral data for remote sensing, e.g., <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b1">2]</ref>.</p><p>The focus of visualization in remote sensing is to increase the visual saliency and assist with the interpretation of the data, in many cases simply by false-coloring. In contrast, we focus on visualization that suits the HSI of historical documents and related tasks. Specifically, we present an image fusion technique for enhancing the contextual details with an emphasis on maintaining the natural look and the feel of the document. In addition, our fusion technique enables the focus+context visualization through user-interaction by introducing a special lens feature.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">HYPERSPECTRAL IMAGING : DATA ACQUISITION</head><p>Before going into the details of our visualization software, we first describe the imaging process used to acquire the HSI data. As previously mentioned, this work is part of a collaboration with the NAN where documents are imaged using the SEPIA Quantitative Hyper-Spectral Imager (QHSI) device developed by Art Innovation <ref type="bibr" target="#b15">[16]</ref>. The device performs hyperspectral imaging by capturing a very narrow spectral band of EM radiation one at a time by placing a bandpass filter in front of the light source to block out all but a selected band of the EM spectrum. A monochromatic camera is then used to capture the amount of light that is reflected by the document at that selected band. The filter is changed for each image, thus capturing different parts of EM spectrum to build up the HSI. <ref type="figure">Fig. 2</ref> (A) illustrates this imaging process. A picture of the device is shown in <ref type="figure">Fig. 2</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>(B).</head><p>The QHSI device captures images at different wavelength bands from 365 nm (UV) to 1100 nm (near infrared (NIR)) with the step size of 10nm in most cases except the bands in 300nm's and 1000nm's. The images have the resolution of 4 mega pixels (2048×2048) for a physical surface area of 125 mm × 125 mm and are captured at 16 bit per pixel. Such high-resolution (approximately 256 pixels per mm 2 ) provides a reliable spatial measurement suitable for even thin lines of handwriting and printed text. Before imaging archival materials, the QHSI device is calibrated via a spectral pattern with known spectral response.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A B</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Fig. 2. (A)</head><p>The hyperspectral imaging process: at each scan, a monochrome camera measures the reflected light from the document surface. The document reflects a very narrow band of EM radiation due to the bandpass filter positioned in front of the light source (500nm in this example). This process is repeated using multiple bandpass filters (70 in the paper) to build the HSI. (B) SEPIA quantitative hyperspectral imager from Art Innovation <ref type="bibr" target="#b15">[16]</ref>.</p><p>The following notations will be used to represent the acquired HSI data. The term I λ indicates the image of the data at a spectrum λ , x indicates a pixel location, and s x indicates the spectral response (spectrum) at point x:</p><formula xml:id="formula_0">s x = [I λ 1 (x), I λ 2 (x), ••• , I λ m (x)] T .</formula><p>(1)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">BASIC FEATURES FOR HSI VISUALIZATION</head><p>This section describes the elementary features offered by our visualization tool. Using the basic functions of the software, the user can load an HSI datacube and interactively navigate through the spectral bands using a slider widget. Each spectral image is displayed as a monochromatic image representing the percentage of spectral reflectance at each pixel for this band. <ref type="figure" target="#fig_0">Fig. 1</ref> shows an example of images at different bands. Note, that the HSI data does not explicitly contain an RGB representation of the imaged document, however, it does have the complete spectral response of each pixel for the visible range. Thus we are able to provide a function that can render the RGB images of the HSI data under different illuminations (e.g., daylight at different color temperatures, white illumination, fluorescent lighting, or user-specified color temperature). This is a useful feature as the RGB image represents the most natural way to display the document as it would appear to our unaided eyes under the various illumination (see accompanying video). While pure white light was useful for the majority of visualization, the ability to change the type of lighting was welcome by our collaborators because it provides the ability to see how the document appears under different exhibition lighting environments.</p><p>Another basic operation necessary to analyze the hyperspectral data is to compare spectrums of different image points to see how similar (or dissimilar) the spectrums are. This operation is useful for tasks such as separating the foreground contents from the background of the document and measuring the corrosion and ink-bleed severity in the document. Our software provides this similarity computation feature by user mark-up interaction. The user marks on a region or regions of interest, then the similarity measure (S) between every pixel in the image and the mean spectrum of the marked-up area (p) is computed as follows :</p><formula xml:id="formula_1">S(x) = 1 − p − s x 2 m ,<label>(2)</label></formula><p>where m is the number of spectral samples. An example of the similarity computation is shown in <ref type="figure" target="#fig_1">Fig. 3(A)</ref>. Our colleagues also wanted to perform this similar metric using selective bands, and not always the entire HSI spectrum. This allows the evaluation of results obtained by using only a few bands for similarity analysis, as prior research in the archival domain has established that certain bands are more suitable for various tasks and materials being observed (e.g., animal skin parchment versus paper-based substrates). Such experimentation is also useful for managing future data collection in which only the useful bands may need to be captured. <ref type="figure" target="#fig_1">Fig. 3</ref>(B-C) shows an example where various band combinations are being used, in particular the visible range (B) and a few NIR bands (C).</p><p>Another basic feature included in our software enables the user to focus on a certain region of interest on the document and visualize how the content in the selected region changes over different wavelength. To provide this context-focus feature, a lens interface termed the hyperspectral lens (inspired by <ref type="bibr" target="#b3">[4]</ref>) was designed to view either a selected rectangle, circle, or free-form region, while maintaining the current spectral context. <ref type="figure">Fig. 4</ref> illustrates an example of this feature. This basic visualization metaphor is also available for use with the band fusion feature that will be discussed in Section 6.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">MONITORING CHANGES IN TIME VARYING HSI DATA</head><p>As discussed in Section 1, one of the tasks targeted by the NAN is to utilize hyperspectral imaging to detect changes in documents due to environmental factors affecting archival documents, namely, exposure to light, changes in humidity and temperature, and combination of both. While the effects of these factors are known to induce damage to the document over the long term, a systematic way to monitor and visualize changes to track the exact process of aging is not currently available in the archival community. This is particularly important for highly valued documents which are subject to more exposure due to exhibition. Currently, the majority of archives monitor the conditions of documents by visual inspections, a method that is highly unreliable and often catches changes only after a major deterioration has occurred, such as age-related spots. <ref type="figure">Fig. 4</ref>. Context-focus through hyperspectral lens. The user can explore the HSI data with the focus on a local region of interest by using the hyperspectral lens feature in our software.</p><p>1st "Aging" Exposure 2nd "Aging" Exposure 3rd "Aging" Exposure 4th "Aging" Exposure Humidity The major drawback to this effort is that the aging of documents is a very slow process and could potentially take decades under natural conditions to collect data with meaningful changes. To expedite data collection for testing, the NAN has devised an elaborate and on-going controlled experiment to induce artificial aging on a wide assortment of documents of various materials and inks. In this experiment, a series of documents have been cut into four sections (or strips), resulting in four pieces from the same source. One of these pieces is used as the "control" and placed in standard storage conditions, i.e., boxed with no light exposure and with constant temperature and humidity. The remaining strips are periodically artificially aged using 1) lighting; 2) temperature and humidity change; and 3) both lighting and temperature/humidity change. Specifically, artificial aging for lighting replicates the spectral characteristics equivalent to four months of light exposure in a matter of days. Temperature and humidity change are performed following the procedures practiced in the conservation field <ref type="bibr" target="#b4">[5]</ref>. After each aging cycle, the HSI datacube of the document is captured and then the material is placed back into storage to settle. <ref type="figure" target="#fig_2">Fig. 5</ref> shows an exemplar document from this experiment after four applications of this cumulative artificial aging. The visible change is difficult to observe by unaided eyes.</p><p>Our software offers several ways to analyze the effects of environmental aging as recorded in the HSI data. One of the most obvious ways is to compute the spectral difference between the same strip as it is aged (method 1). The strips are geometrically aligned and their per pixel spectral difference is computed based on Eq. (2). An advantage of this type of visualization is that it shows the effect of the aging spatially. Another way to visualize aging is the show the changes due to different environmental factors (method 2). The intent is to see the changes due to different methods of aging rather than over time. The mean spectrums of the background substrate (which is interactively selected by the user) of different strips are compared for this visualization. Finally, we provide histograms plot features to help visualize the aging process (method 3). By jointly displaying histograms of the document strips with increasing amounts of cumulative aging, we can elucidate the overall trend of how the HSI data changes due to different environmental stress. Since HSI is a 3D data (cube), the histogram of a HSI data is 3D. Our tool visualizes the histograms of HSI in two ways. First, the software provides a slider widget that allows the user to see the 2D histogram at each spectral band. We also provide a 3D spectral histogram with additional axis for the wavelength to help reveal the overall trend between two aged strips at the same time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Case Examples</head><p>Two datasets are shown as examples of how our collaborators can use the technique described in this section to analyze and quantify changes in the documents due to external aging factors. The first data is a handwritten document circa 1800s and the second example is a blank paper that has been constructed based on a historical paper making method from the same era ( <ref type="figure" target="#fig_4">Fig. 7)</ref>. <ref type="figure" target="#fig_3">Fig. 6</ref> shows an example where the per pixel spectral difference between the same strip of HSI data is compared at the first aging exposure and then after the fourth cumulative exposure (method 1). The difference map in <ref type="figure" target="#fig_3">Fig. 6</ref> reveals non-uniform response of the paper substrate to the aging process. In this example, we have also shown the spectral plots of ink-regions and background regions (i.e., the substrate). The ink's spectral response has changed more than the paper, which is reflected in the difference map. The spectral change for the ink is also more distributed over the entire spectrum, while the paper is affected in wavelengths below 700nm.  <ref type="figure" target="#fig_4">Fig. 7(A)</ref> shows the mean spectrums of the background which indicate the difference in aging due to different aging factors (method 2). The plots for both cases reveal that the change in humidity/temperature affects the document aging the most. Notice that computing the difference map as in <ref type="figure" target="#fig_3">Fig. 6</ref> is not a viable option since the content of each strip is different. Visualization of aging through histogram (method 3) is illustrated in <ref type="figure" target="#fig_4">Fig. 7(C)</ref>. Four histograms at each spectral band in <ref type="figure" target="#fig_4">Fig. 7(C)</ref> represent the histograms of the data as it is progressively aged <ref type="figure" target="#fig_4">(Fig. 7(B)</ref>). We also provide a 3D spectral histogram with additional axis for the wavelength to help reveal the overall trend between two aged strips at the same time ( <ref type="figure" target="#fig_4">Fig. 7(D)</ref>). This again reveals that the spectral response to the aging is most notable in bands below 700nm. Furthermore, it is possible to verify that we are actually tracking aging process rather than errors from the imaging system through visualization schemes shown in this section. This is important because aging is a slow process and the effect of aging in these experiments are very small.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">VISUALIZATION THROUGH FUSION</head><p>Although displaying individual image per wavelength provides a direct view on the raw HSI data, contextual details in the entire data volume are rarely distributed evenly through different spectral ranges. Our NAN collaborator expressed the desire to visualize the HSI data in its natural appearance, but at the same time emphasizing various contents in the invisible range to enhance the legibility of the data. A natural way to do this is an illustrative visualization approach where the aim is to maximize the amount of contextual details while maintaining the appearance of the document in the visible range. In addition, our collaborator preferred to interactively select the bands that provide contextual details.</p><p>As discussed in Section 4, an RGB image of the HSI data under a user-specified lighting condition can be generated and displayed. However, such an image cannot represent the entire HSI data since it integrates only the visible spectrums (400nm to 700nm) and excludes potentially valuable information in the invisible range (UV, NIR).</p><p>A new scheme for visualizing the information in the invisible bands while keeping user's perceptual context with views on the visible portion (RGB) is necessary. For such visualization, we introduce a gradient-based fusion technique which has been shown to be effective for computer vision and graphics tasks such as image editing <ref type="bibr" target="#b25">[26]</ref>, contrast adjustment <ref type="bibr" target="#b10">[11]</ref>, image stitching <ref type="bibr" target="#b19">[20]</ref>, and image fusion <ref type="bibr" target="#b16">[17]</ref>. Specifically, we want to reconstruct a new image I i (x) by fusing the contextually rich gradients of the image at a wavelength λ (F λ (x) = ∇I λ (x)) with the color of the original RGB (I i (x)), where index i indicates color channel, x represents pixels, and ∇ is the gradient operator. To do this, we solve for each color channel of the new image I by minimizing the following cost function :</p><formula xml:id="formula_2">argmin I i ∑ x γ(I i (x) − I i (x)) 2 + ∇I i (x) − β F λ (x) α .<label>(3)</label></formula><p>The first term in above equation makes the color values of the reconstructed image I to be close to the color of the original image I under an 2 norm. The second term forces the gradient of the reconstructed image to be close to the gradient of an image at a wavelength λ under a sparse norm (α ≤ 1). Note that it is the gradient structures that contain the relevant information, not the gradient magnitudes. Hence, the reason for using the sparse norm is because the sparse norm on the gradient terms encourages the edge structures in I to align spatially with those in F λ compared to the 2 norm where ∇I will be matched closely with F λ in magnitudes <ref type="bibr" target="#b16">[17]</ref>. The parameter γ controls the balance between the color term and the gradient term. The parameter β scales the strength of the gradient. To optimize Eq. 3, we modified a fast optimization scheme used for image deconvolution recently introduced in <ref type="bibr" target="#b17">[18]</ref>. This gradient fusion method for transferring information from the invisible range to the RGB image is incorporated into the hyperspectral lens feature (Section 4). Not all areas have to be visualized using the new fusion technique since the invisible bands do not contain any additional information in many regions. To this end, we add additional feature to the existing user-interface so that the user can efficiently select the area for fusion and the band to transfer the data from by looking at the fused result. The user selects a region-of-interest within the image with the hyperspectral lens feature. When the user scrolls through the wavelength, the hyperspectral lens can now display the newly fused color image using the gradient of the image at the current wavelength instead of showing the gray-scale image at each band. This enables the user to browse through the HSI data for analysis with color perception.</p><p>We can also use the fusion technique to visualize the HSI data with an artifact-free RGB image in which the artifacts on the document such as ink-bleed, ink corrosion, and foxing (age spots) are removed. For this task, the user can use the similarity computation feature introduced in Section 4. After the user marks-up on a foreground text area, the HSI data can be segmented into the foreground and the background by using the computed similarity scores. A new gradient map (F i ) is constructed by combining the gradients of the original RGB (∇I i ) as the foreground and the gradients of a band (∇I λ ) chosen by the user with less artifacts as the background <ref type="figure" target="#fig_0">(Fig. 10 (B)</ref>) :</p><formula xml:id="formula_3">F i = M .× ∇I i + (1 − M) .× ∇I λ ,<label>(4)</label></formula><p>where M is a binary mask with 1's in the foreground and 0's in the background. With the new gradient map F i , a new RGB image I is reconstructed by optimizing the cost function in Eq. 3.</p><p>Case Examples <ref type="figure" target="#fig_5">Fig. 8</ref> shows part of a late 17th century map that belonged to Michiel de Ruyter, a famous Dutch admiral. The original RGB image in <ref type="figure" target="#fig_5">Fig. 8</ref> contains several regions with low contrast and it is difficult to clearly see the textures within those regions. There is even a tear inside one of the ships that is difficult to recognize in the original RGB image. With our fusion tool, our NAN collaborator enhanced the local areas with low contrast by selectively choosing spectral bands that have more salient content. The salient content in this example represents crisper edges. In this case, the spectral band at 850nm is selected to enhance the boat region, while 750nm is selected for the lower part of the map.</p><p>A new gradient map is composited from these selections (small color map in <ref type="figure" target="#fig_5">Fig. 8 (A)</ref>), and the enhanced image is reconstructed by optimizing Eq. 3. Another case is shown in <ref type="figure">Fig. 9</ref> where our tool was used to reveal a tear in a document suffering from significant ink-corrosion while maintaining the original look of the document. For both cases, the use of the hyperspectral lens is used to provide a focus+context visualization of the desired regions. In addition to enhancing information, the fusion technique can be used to reduce artifacts. <ref type="figure" target="#fig_0">Fig. 10</ref> shows an example where the age spots due to foxing can be reduced while the look and the feel of the document are preserved. The ability to preserve the look and the feel of the original RGB image holds a significant advantage over most existing document processing techniques in which the output of the artifact removal is a binary image with a uniform color background such as the mean of the input background color or simply white. While the binarization enhances the ability to interpret the data, the texture and the look of the original document is completely lost <ref type="figure" target="#fig_0">(Fig. 10 (D)</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">DISCUSSION</head><p>Before our involvement, our NAN collaborator only had a set of menudriven Matlab routines at his disposable to process the data. Analysis was performed in a serial fashion with results being saved to images. Not surprisingly, the interactive nature of our software was welcomed. Our NAN collaborator noted that our interactive software allowed the  basic tasks of computing similarity measurements and producing false color images to be performed in a matter of minutes, while the previous menu-driven software could take up to hours to produce the desired output. It was from this early uses of our tool that our NAN collaborator suggested that a region of interest tool (hyperspectral lens) be introduced to enable focus+context visualization concept to allow focus on a particular region of the document while the rest of the image remained in natural appearance.</p><p>Towards the effort in using the HSI data to monitor the aging of documents under environmental exposures, our NAN collaborator pointed out that computing the spatial variation of aging on the whole document was a first of its kind in the archival community, where it was previously limited to comparing only a small number of spots on the document using single-point spectrum measurements. Our visualization of spatial variations of aging helps to reveal non-uniform aging that are common to papers, which is due to non-uniform light exposures as well as the paper's own physical construction. Multi-dimensional histogram plots which help to reveal the trends in aging in different materials due to different factors was also welcomed by our collaborators. The ability of our software to provide instant feedback with different types of histograms provides more in-depth analysis of the data to our collaborators. The 3D histogram was also useful as it helped to overview the global trend in the spectrums. We note that measuring the effects of environmental aging is part of an on-going research at the NAN (and also at other archives). Currently, even with the assistance of our visualization tool, no quantitative assignment of damage can be applied to the documents. To be able to do this will require a long-term experiment where artificially aged documents begin to exhibit strong artifacts such as foxing. This is an evolving experiment of which our visualization tool will play a vital role.</p><p>While selective band fusion has been demonstrated in other domains, within the archival community it is a first of its kind. Our collaborators informed us that they had previously attempted to produce examples similar to ours, but did so manually using Adobe Photoshop to composite contrast enhanced monochrome images by stitching different parts of the spectral images together, which proved unsatisfactory. Our approach allows this to be done interactively and within the context of an RGB image. Our NAN collaborator explained that there are two main uses of this feature in his domain. First, the fusion procedure can be used to produce an enhanced version of the object that can be displayed next to the original in the exhibition case. Producing a result that is perceptually similar helps to maintain the look and feel of the document, while revealing salient information. Second, this feature is useful to the conservator for producing reports to share with colleagues to help reveal regions that require repair, as demonstrated in <ref type="figure" target="#fig_5">Fig. 8</ref> and <ref type="figure">Fig. 9</ref>. By having the damaged region shown in the context of the whole document, the conservator in charge of physical repair can easily identify the corresponding region on the physical document. Our collaborators (both from NAN and Art Innovation) also suggested to maintain the control over which bands to use for fusion, even though we indicated that this could be potentially automated based on some objective criteria (such as local contrast or local gradient). The reason given is that the use of this particular feature can vary greatly between tasks and documents, and it is difficult to predict exactly what they may want to highlight.</p><p>Finally, one theme that recurred in the discussions with our colleagues was that while the NAN is fortunate enough to be able to perform research on the HSI, the hardware cost is currently prohibitive for most archives. Instead, highly controlled RGB imaging together with a set of filters and illumination for selective invisible spectrums may be a preferred option for many tasks. Thus, the ability of our software to explore the data and perform analysis in band-selective manner is useful in providing the insight for the construction of future multispectral or single band devices, custom tailored for particular tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">CONCLUSION AND FUTURE WORK</head><p>We have presented a visualization tool tailored for use on hyperspectral images of historical documents. Our tool was developed to support the tasks of our collaborators in NAN and we have discussed how various visualization and analysis features inside can assist our collaborators on the analysis and management of historical documents. For future work, we will continue collaborating with the NAN to develop suitable ways of further revealing subtle changes due to environmental aging and to quantify this damage. This will include exploring better spectral similarity measure (e.g., <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b5">6]</ref>) and higher level data analysis such as principal component analysis (PCA). The ultimate goal is to be able to establish models of document aging to predict how a document will appear after an exhibition or within a certain time span. We envision that this type of models would also lead to developing algorithms for restoring damaged documents.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>(A) Standard three channel RGB image, (B) 70+ band hyperspectral image.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 3 .</head><label>3</label><figDesc>Similarity computation. Similarity measure (Eq. 2) between the mean spectrum of the marked area (red) and other points in the data are computed by using the entire spectral bands (A), visible bands (B), and selected bands in NIR (C). Different bands can be selected for different tasks providing more flexibility in similarity computation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 5 .</head><label>5</label><figDesc>Artificial aging applied periodically to a document. Each document is divided into four strips with the bottom strip serving as a control with no aging induced. The remaining strips from the bottom are artificially aged using 1) lighting; 2) temperature and humidity change; and 3) both lighting and temperature/humidity change.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 6 .</head><label>6</label><figDesc>(A) Two strips artificially aged at the first aging exposure and then after the fourth cumulative exposure based on changes in the temperature/humidity. (B) Spectral plots of the background paper (top) and the ink (bottom) in the strips. The ink shows more spectral change than the paper substrate. (C) Spectral difference map shows that the response of the paper substrate to the aging process is spatially varying.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 7 .</head><label>7</label><figDesc>(A) Effects of different aging methods. As can be seen, changes in humidity/temperature has the biggest effect on aging. (B) Strips are aged cumulatively more in the vertical direction. (C) 2D histograms for each aging step are jointly displayed at each spectral band. (D) 3D spectral histograms of two time instances reveal the overall trend between two aged strips at the same time.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 8 .</head><label>8</label><figDesc>(A) Contrast of some parts in the original RGB image (left) is enhanced with our gradient fusion method (middle). Side by side comparison of enhanced regions are shown on right. (B)(C) Enhancement using each band is shown locally through the hyperspectral lens. User can interactively choose the band that suits the application (highlighted with dashed line), where in this case is the contrast enhancement.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 9 .Fig. 10 .</head><label>910</label><figDesc>(A) The image at 1050nm (right) reveals a tear in the document that is extremely difficult to catch in the original image (left). Using our fusion technique for visualization, we can show the condition of the document while keeping the color in the image (middle). (B) Fusion results using different bands with our user interface. (A) Original RGB image of the HSI data. (B) Source for providing gradients for the background (900nm). (C) New RGB image with artifacts removed using our technique. (D) RGB image with the background filled with the mean value of the background. The resulting image using our technique maintains the look and the feel of the original in contrast to the result in (D).</figDesc></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">The difference between multispectral vs. hyperspectral imaging is related to the number of bands as well as the manner in which the data is collected. In this paper, we refer to our data as hyperspectral as it provides a dense and highly calibrated spectral response from a single sensor.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS</head><p>We gratefully acknowledge the support and efforts from our collaborators Roberto Padoan from the Nationaal Archief of the Netherlands (NAN) and Marvin Klein from Art Innovation. This work was supported in part by the NUS Young Investigator Award, R-252-000-379-101, and the A*Star SERC Grant (SERC Grant No. 092 101 0063).</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<ptr target="http://www.ittvis.com" />
		<title level="m">ENVI</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Pci Geomatica</surname></persName>
		</author>
		<ptr target="http://www.pcigeomatics.com" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Interactive visualization of function fields by range-space segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">C</forename><surname>Anderson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">J</forename><surname>Gosink</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Duchaineau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">I</forename><surname>Joy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Graphics Forum (Proc. of EuroVis)</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="727" to="734" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Toolglass and magic lenses: The see-through interface</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">A</forename><surname>Bier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">C</forename><surname>Stone</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Pier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Buxton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">D</forename><surname>Derose</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of SIGGRAPH</title>
		<meeting>of SIGGRAPH</meeting>
		<imprint>
			<date type="published" when="1993" />
			<biblScope unit="page" from="445" to="446" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Explorations of the role of humidity fluctuations in the deterioration of paper</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bogaard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">M</forename><surname>Whitmore</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Workshop of Art on Paper Books, Documents and Photographs</title>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="11" to="15" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">An information-theoretic approach to spectral variability, similarity, and discrimination for hyperspectral image analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-I</forename><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Information Theory</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1927" to="1932" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Fusion of multispectral and panchromatic satellite images using the curvelet transform</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">Y</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-R</forename><surname>Nam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">O</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Geoscience and Remote Sensing Letters</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="136" to="140" />
			<date type="published" when="2005-04" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Spectral imaging of Leonardo Da Vinci&apos;s Mona Lisa: An authentic smile at 1523 dpi with additional infrared data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Cotte</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Dupraz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IS&amp;T Archiving Conf</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="228" to="235" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Interactive hyperspectral image visualization using convex optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Razdan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Wonka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Geoscience and Remote Sensing</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1673" to="1684" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Color display for hyperspectral imagery</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Raksuntorn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Shanshu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">J</forename><surname>Moorhead</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Geoscience and Remote Sensing</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1858" to="1866" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Gradient domain high dynamic range compression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Fattal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lischinski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Werman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. on Graphics</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="249" to="256" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Astronomers and their shady algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Gooch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of IEEE Visualization Conf</title>
		<meeting>of IEEE Visualization Conf</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="1995-10" />
			<biblScope unit="page" from="374" to="377" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Design goals and solutions for display of hyperspectral images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Jacobson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gupta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Geoscience and Remote Sensing</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2684" to="2692" />
			<date type="published" when="2005-11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Interactive visualization and analysis of transitional flow</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Calo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Gaither</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1420" to="1427" />
			<date type="published" when="2008-12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Hypothesis generation in climate research with interactive visual data exploration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kehrer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Ladstadter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Muigg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Doleisch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Steiner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Hauser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1579" to="1586" />
			<date type="published" when="2008-12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Quantitative hyperspectral reflectance imaging</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">J</forename><surname>Aalderink</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Padoan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>De Bruin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">A G</forename><surname>Steemers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sensors</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="5576" to="5618" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Dark flash photography</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Krishnan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Fergus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of SIGGRAPH)</title>
		<meeting>of SIGGRAPH)</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="1" to="11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Fast image deconvolution using hyperlaplacian priors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Krishnan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Fergus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of Neural Information Processing Systems</title>
		<meeting>of Neural Information essing Systems</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="1033" to="1041" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Sinus endoscopyapplication of advanced GPU volume rendering for virtual endoscopy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kruger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Kubisch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Strauss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Preim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1491" to="1498" />
			<date type="published" when="2008-12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Seamless image stitching in the gradient domain</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Levin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zomet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Peleg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Weiss</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of European Conf. on Computer Vision</title>
		<meeting>of European Conf. on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="377" to="389" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Visualizing multiwavelength astrophysical data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-W</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">J</forename><surname>Hanson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1555" to="1562" />
			<date type="published" when="2008-12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Directed assistance for ink-bleed reduction in old documents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">S</forename><surname>Brown</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conf. on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="88" to="95" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Digitization and multispectral analysis of historical books and archival documents: Two exemplary cases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Maino</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the International Conf. of Image Analysis and Processing</title>
		<meeting>of the International Conf. of Image Analysis and essing</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="119" to="124" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Interactive visualization of intercluster galaxy structures in the horologium-reticulum supercluster</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">W</forename><surname>Quammen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">C</forename><surname>Fleenor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1149" to="1156" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Quantitative hyperspectral imaging of historical documents : Technique and applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Padoan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Steemers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Aalderink</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>De Bruin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc.International Conf. on NDT of Art</title>
		<meeting>.International Conf. on NDT of Art</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="445" to="446" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Poisson image editing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Pérez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gangnet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Blake</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. on Graphics (Proc. of SIGGRAPH)</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="313" to="318" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Historical document image enhancement using background light intensity normalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Govindaraju</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE International Conf. on Pattern Recognition</title>
		<meeting>IEEE International Conf. on Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="473" to="476" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Multispectral image visualization through first-order fusion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename><surname>Socolinsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">B</forename><surname>Wolff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Image Processing</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="923" to="931" />
			<date type="published" when="2002-08" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Restoration of archival documents using a wavelet technique</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">L</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Shen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1399" to="1404" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Multispectral imaging system applied to element testing of biology</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Meng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 2008 international Conf. on Biomedical Engineering and informatics</title>
		<meeting>of the 2008 international Conf. on Biomedical Engineering and informatics</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="volume">02</biblScope>
			<biblScope unit="page" from="648" to="651" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Visible and infrared hyperspectral visualization of normal and ischemic tissue</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Zuzak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Schaeberle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Levin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Freeman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Mcneil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Cancio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the First Joint BMES/EMBS Conf., volume</title>
		<meeting>of the First Joint BMES/EMBS Conf., volume</meeting>
		<imprint>
			<date type="published" when="1999" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">1118</biblScope>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
