<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/pisenberg/grobid/grobid-0.6.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">The Not-so-Staggering Effect of Staggered Animated Transitions on Visual Tracking</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fanny</forename><surname>Chevalier</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierre</forename><surname>Dragicevic</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Franconeri</surname></persName>
						</author>
						<title level="a" type="main">The Not-so-Staggering Effect of Staggered Animated Transitions on Visual Tracking</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="DOI">10.1109/TVCG.2014.2346424</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2021-02-19T19:11+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Animated transitions</term>
					<term>staggered animation</term>
					<term>visual tracking</term>
				</keywords>
			</textClass>
			<abstract>
				<p>Interactive visual applications often rely on animation to transition from one display state to another. There are multiple animation techniques to choose from, and it is not always clear which should produce the best visual correspondences between display elements. One major factor is whether the animation relies on staggering-an incremental delay in start times across the moving elements. It has been suggested that staggering may reduce occlusion, while also reducing display complexity and producing less overwhelming animations, though no empirical evidence has demonstrated these advantages. Work in perceptual psychology does show that reducing occlusion, and reducing inter-object proximity (crowding) more generally, improves performance in multiple object tracking. We ran simulations confirming that staggering can in some cases reduce crowding in animated transitions involving dot clouds (as found in, e.g., animated 2D scatterplots). We empirically evaluated the effect of two staggering techniques on tracking tasks, focusing on cases that should most favour staggering. We found that introducing staggering has a negligible, or even negative, impact on multiple object tracking performance. The potential benefits of staggering may be outweighed by strong costs: a loss of common-motion grouping information about which objects travel in similar paths, and less predictability about when any specific object would begin to move. Staggering may be beneficial in some conditions, but they have yet to be demonstrated. The present results are a significant step toward a better understanding of animation pacing, and provide direction for further research.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>The purpose of an interactive visualization is to allow analysts to view a dataset from multiple perspectives. When these perspectives change, it is critical that the observer understands how the data in a new display corresponds to data from a display that has now vanished. For example, when switching between two different 2D scatterplots of a multidimensional dataset, the analyst needs to understand how data points map from the old projection to the new one <ref type="bibr" target="#b16">[18]</ref>. When displays undergo large changes in an abrupt manner, understanding changes can be extremely difficult <ref type="bibr" target="#b37">[39]</ref>. A common solution is to smoothly animate the transition between displays, allowing elements to gradually move from one position or visual state to the other, and thus allowing the observer to perceive the correspondence between displays.</p><p>Animated transitions have been shown to yield a number of advantages, such as helping users keep oriented during pan and zoom operations <ref type="bibr" target="#b4">[6,</ref><ref type="bibr" target="#b35">37]</ref> and helping them understand changes between different visual representations of statistical data <ref type="bibr" target="#b22">[24]</ref>. But little is known on how to best design animated transitions. There are multiple animation techniques to choose from, and it is not always clear which should produce the best visual correspondence between display elements. For example, elements can be set to follow different trajectories, or move at different times and/or accelerate or slow down (i.e., animation pacing). Staggering is one animation pacing technique: rather than having all the elements move at the same time, it introduces an incremental delay in start and stop times. Several visual applications have adopted this design, including Pivot [1], DynaVis <ref type="bibr" target="#b22">[24]</ref> and Histomages <ref type="bibr" target="#b9">[11]</ref>. Staggering has been suggested to help reduce inter-elements occlusion and to provide less overwhelming visual transitions <ref type="bibr" target="#b22">[24]</ref>. However, there is no empirical evidence for these purported advantages.</p><p>One way to put this question to the test is to determine whether or not staggering makes it easier for users to visually track elements from one display state to the other. Researchers in perceptual psychology have extensively studied the processing limitations of the human vi- sual system <ref type="bibr" target="#b18">[20]</ref> and more specifically, the mechanisms involved in the tracking of multiple objects over time. Past work indicates that inter-object proximity (i.e., crowding) has an influence on visual tracking performance <ref type="bibr" target="#b17">[19]</ref>. These results align with the intuition that an animated transition technique that reduces crowding may have a facilitating effect. Yet, many questions remain to be addressed. One question is whether staggering does reduce crowding in the first place. Furthermore, the effects of crowding have been generally observed on animations where all objects move at the same time, and the potential benefits of staggering may be outweighed by strong costs associated with non-simultaneous object motions. This article attempts to move closer to a better understanding of animated transition design by examining the effect of two types of staggered animation on multiple object tracking performance. We ran a series of simulations and controlled experiments on randomly moving dots as found in, e.g., 2D scatterplot transitions. These experiments address the following questions: i) which animation characteristics (crowding or otherwise) affect the difficulty of tracking multiple objects? ii) can these characteristics be manipulated using staggering? and iii) provided this is the case, will staggering yield observable benefits on object tracking performance, or will these benefits be outweighed by the costs associated with non-simultaneous object motions? We first present an overview of related work, then the general design rationale for our study. We then report on our experiments, and finally conclude with general implications for the design of animated transitions in interactive information visualization systems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">BACKGROUND</head><p>Animations consist of creating the illusion of continuous visual changes through the rapid display of a sequence of static images. Partly building on the tradition of cartoon animations <ref type="bibr" target="#b7">[9,</ref><ref type="bibr" target="#b26">28]</ref>, animations are widely used in graphical user interfaces for helping users understand dynamic processes and time-varying data, or simply for their compelling value. Many benefits of animations have been pointed out <ref type="bibr" target="#b3">[5]</ref>, as well as a certain number of pitfalls <ref type="bibr" target="#b38">[40]</ref>. Despite their popularity, animations are still poorly understood. Here we discuss animated transitions, i.e., a particular class of computer animations whose purpose is to turn abrupt visual changes into smooth ones. We discuss prior work on animated transitions both in general human-computer interaction (HCI) and in information visualization (infovis). We also discuss how previous work in perceptual psychology has attempted to shed light on how we apprehend changes in dynamic displays. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Animated Transitions</head><p>Animated transitions have been used in a variety of interactive applications for a variety of reasons, including for facilitating the use of zoomable user interfaces <ref type="bibr" target="#b35">[37]</ref>, to aid the tracking of changes in dynamic data <ref type="bibr" target="#b2">[4,</ref><ref type="bibr" target="#b8">10,</ref><ref type="bibr" target="#b36">38]</ref>, and to facilitate the understanding of transitions between different representations of the same data <ref type="bibr" target="#b5">[7,</ref><ref type="bibr" target="#b9">11,</ref><ref type="bibr" target="#b15">17,</ref><ref type="bibr" target="#b16">18,</ref><ref type="bibr" target="#b22">24]</ref>.</p><p>Although prior work has demonstrated the benefits of animated transitions for particular tasks, this work has mainly focused on particular instances of animated transitions. There are many possible designs for animations, and with a few exceptions <ref type="bibr" target="#b13">[15,</ref><ref type="bibr" target="#b22">24]</ref>, there exist very little empirical research comparing the effectiveness of different types of designs. A better understanding of good animated transition design is particularly important for interactive information visualization applications, where the analyst needs to constantly navigate between different views of the same data. Understanding how views relate to each other is an integral part of the visual exploration activity.</p><p>A few general design recommendations have been proposed for animations <ref type="bibr" target="#b38">[40]</ref>, such as apprehension -the information conveyed by the animation should be accurately perceived -and congruence -the animation should be predictable and understandable. Other general recommendations have been derived from cartoon animation principles <ref type="bibr" target="#b7">[9,</ref><ref type="bibr" target="#b26">28]</ref>. Many of these recommendations are too general to effectively guide the design of animated transitions. While some animations can be authored manually, an animated transition technique must produce an effective and meaningful sequence of frames from any pair of initial and final frames. For developers of information visualization applications, animated transitions are functions with a multitude of free parameters (e.g, the duration, the temporal pacing, the interpolation function between positions, etc.), and they need operational recommendations as to which parameter to choose and when. Only a few studies have attempted to empirically investigate these <ref type="bibr" target="#b13">[15,</ref><ref type="bibr" target="#b22">24,</ref><ref type="bibr" target="#b33">35]</ref>.</p><p>Animated transitions are generally characterized by spatial and temporal parameters, i.e., parameters that involve object trajectories and parameters that involve object speed or pacing. One important aspect of temporal pacing is whether all the display elements move at the same time, or if there is delays in motion start times. For example, a transition can be broken down into different stages based on the structure of the data (e.g., delete first, then move, then add <ref type="bibr" target="#b29">[31]</ref>. Staged animations can be valuable when the inherent structure of the data allows for the definition of meanigful stages, but their benefit is not systematic <ref type="bibr" target="#b22">[24]</ref>. The sequencing the transition into several stages can also dramatically increase the animation duration.</p><p>Another pacing effect is staggering, where the start time of elements is delayed incrementally <ref type="bibr" target="#b22">[24]</ref>. Staggering is commonly found in visual applications <ref type="bibr">[1,</ref><ref type="bibr" target="#b9">11]</ref> and generally preferred over other animations <ref type="bibr" target="#b22">[24]</ref>. It has been suggested that staggering may reduce occlusion, while also reducing display complexity and producing less overwhelming animations. However, no study has explicitely demonstrated these advantages. This work attempts to address this lack.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Studies on Visual Tracking</head><p>In many animated transitions, individual objects (points, bars, pixels, icons, ...) shift their position over time, requiring the observer to understand which points moved to which new locations. A substantial perceptual psychology literature examines how well the visual system can deal with such animations, testing how many objects can be successfully tracked under different conditions. These tests rely on Multiple Object Tracking (MOT) tasks, which require observers to mentally track a set of target objects moving among distractor objects <ref type="bibr" target="#b31">[33]</ref>. The challenge is similar to tracking a single target cup as a street magician shuffles it rapidly among identical distractor cups but here there are multiple target cups. In a typical task, a set of circles are presented on a display, and a subset is briefly cued by a color change. All of the objects then move randomly across the screen for several seconds. During this phase, all objects are visually identical in color and shape, in order to ensure that the task tests an observer's ability to track via object location alone. When the objects stop, the observer must click on the original highlighted circles, and experimenters examine their accuracy depending on display conditions.</p><p>The results from such studies reveal a clear set of conditions affecting performance. Perhaps the most important factor is crowding, the spacing among objects <ref type="bibr" target="#b17">[19]</ref>. When objects become crowded, targets and distractors can become confused with each other <ref type="bibr" target="#b28">[30]</ref>. These results also reveal that people can track a maximum of 7-8 objects under carefully controlled conditions, though this limit appears to drop to 3-4 objects in more general cases <ref type="bibr" target="#b17">[19]</ref>. There are also factors that surprisingly do not seem to limit tracking performance. Object speed only appears to impair performance at extremes -the types of speeds that strain the refresh rate of typical monitors <ref type="bibr" target="#b17">[19]</ref>. Trajectory changes and curved paths appear to have only minimal impacts on performance <ref type="bibr" target="#b21">[23]</ref>. Extreme magnification changes of the display do not have a substantial impact <ref type="bibr" target="#b20">[22]</ref>. Object occlusion is surprisingly undisruptive when the occluding surface is clearly distinguishable from the tracked objects <ref type="bibr" target="#b34">[36]</ref>, but when objects occlude each other performance can be impaired because of the extreme crowding that this entails.</p><p>In infovis, animated transitions can be used for switching between different views of the same data, or for switching between different temporal snapshots. In these contexts, it is important to be able to track data points when the display changes. In some cases, e.g., when analyzing clusters or during faceted navigation, it is enough to be able to track collections of objects as single entities. In these cases, individual identity may not be critical. Visual objects can also have labels or color encodings that mark their individual identities. But in other cases, several visual objects need to be tracked as distinct individuals, such that interchanging them would lead to incorrect or inefficient use of the displayed information. For example, a user who swaps data points during a scatterplot axis transition <ref type="bibr" target="#b16">[18]</ref> may get an erroneous perception of how dimensions correlate.</p><p>Work in the perceptual psychology literature also examines these distinct conditions, cases where tracking identity is not required (NoID), and cases where it is critical to the task (ID). This work clearly shows that while capacity for NoID tracking can reach several objects, ID tracking is strikingly hard, with capacities as low as 1-2 objects <ref type="bibr" target="#b23">[25,</ref><ref type="bibr" target="#b32">34,</ref><ref type="bibr" target="#b30">32]</ref>. It appears that while separate systems can track object positions and object identities, coordinating these systems is a strongly resource-limited operation <ref type="bibr" target="#b19">[21]</ref>.</p><p>Despite a wealth of empirical data available from the psychology literature, the data is still too incomplete and controversial to have clear and direct implications to animated transition design. Furthermore, the stimuli used in these studies are primarily designed to capture everyday human experiences. Typical computer animated transitions differ from these stimuli in several respects:</p><p>• Most animated transitions employ object paths reflecting purposeful transitions, instead of animations containing complex behavior involving wandering, collision avoidance, bouncing, and changes in direction <ref type="bibr" target="#b0">[2]</ref>, or rotation <ref type="bibr" target="#b17">[19]</ref>.</p><p>• Most animated transitions are short (the generally recommended duration is 1s <ref type="bibr" target="#b13">[15,</ref><ref type="bibr" target="#b22">24]</ref>), instead of animations lasting e.g., 8s <ref type="bibr" target="#b21">[23]</ref>).</p><p>• Many animated transitions use a slow in/out pacing <ref type="bibr" target="#b13">[15]</ref>, while past psychology studies often use abrupt transitions <ref type="bibr" target="#b31">[33]</ref>.</p><p>• When interacting with a computer eye movements are not restricted, while previous studies use a fixation point ("+") <ref type="bibr" target="#b17">[19]</ref> In summary, though despite there exist extensive research in HCI and infovis on animations, prior work has typically focused on particular instances of these animations making it difficult to derive general guidelines for the design of animated transtions. In particular, staggering is believed to has a potential benefit on crowding, but such advantages remain speculative. This work builds on methods employed in perceptual psychology to study to adress this question.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">STUDY DESIGN RATIONALE</head><p>The goal of our study is to i) determine the factors that affect the difficulty of tracking multiple objects during animated transitions, and ii) determine whether these factors can be manipulated using staggering in order to facilitate tracking. We discuss the rationales behind our task design and describe the difficulty metrics and error measures that we introduced for this study.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Basic Animation Terminology</head><p>In HCI and infovis, an animated transition between two distinct visual states smooths out an otherwise abrupt visual change. In this article, we refer to the terms transition and animation as follows:</p><p>• A transition is a pair of visual states -an initial one and a final one. A visual state can be thought of as a structured image.</p><p>• An animation is a (usually perceptually continuous) sequence of intermediary images that give the illusion of a smooth progression from a transition's initial visual state to its final visual state.</p><p>Transitions are given, i.e., they are outside the control of the animation designer. For example, when a data change causes a bar chart to be updated, or when a user chooses to remap a scatterplot's axes, both the initial and the final images are given. In contrast, animations are designed, i.e., the designer has total freedom on how to choose all intermediary visual states (i.e. frames). In infovis, animation frames do not necessarily map to real data or well-formed visual encodings <ref type="bibr" target="#b22">[24]</ref>.</p><p>Since it is unrealistic to manually design animations for every possible transition, the frame generation process is usually automated:</p><p>• An animated transition technique is an algorithm for generating animations from transitions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Tasks</head><p>The effectiveness of animated transition techniques can be estimated empirically by giving users tasks, i.e., by presenting them with various animations and testing their ability to follow these animations. Similar methods are used in visual tracking studies in psychology <ref type="bibr" target="#b31">[33]</ref>, but these involve long and complex animations which are not representative of animated transitions in infovis. An infovis study requires manipulation of animations -which are a characteristic of the technique being evaluated -independently of the transitions -which are a characteristic of the task. Therefore a task is only defined by a transition and a test for measuring how well this transition can be understood.</p><p>We are interested in evaluating the effectiveness of animated transition techniques at a low perceptual level. We chose to give visual tracking tests that require following one or more moving objects (targets) while ignoring other moving objects (distractors). Although this is an elementary low-level task, higher level infovis tasks will likely be equally or more difficult as they heavily rely on such perceptual capabilities (see a discussion in <ref type="bibr" target="#b13">[15]</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1">Choice of Transitions</head><p>Because we study visual tracking performance, we focus on transitions that involve changes in object location (transitions can also involve changes in, e.g., color or shape). In order to control for other perceptual processes such as preattentive color processing and visual search, we focus on collections of visually identical objects that move from a location to another. The rationale is that if an animated transition technique makes it easier to follow visually identical objects, it should also make it easier to follow visually dissimilar objects (also see <ref type="bibr" target="#b13">[15]</ref> for a discussion).</p><p>We choose to focus on simple objects that are small enough (dots) so that the likelihood of overlap or occlusion is reasonably small when few of them are present. Dots capture the visual marks that can be found in many high-density visualizations such as scatterplots, glyphbased visualizations or node-link diagrams.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2">Choice of Tests</head><p>While Dragicevic et al.used tracking of a single object <ref type="bibr" target="#b13">[15]</ref>, many analytical tasks likely require to follow more than one object at a time. We therefore focus on tests involving multiple object tracking (MOT) instead. We consider two types of MOT tests that have been previously studied in psychology: i) group tracking, i.e., tracking collections of moving objects as a whole, and ii) identity tracking, i.e., tracking a set of targets with distinct identities. While the first task only requires to identify target objects' final location, the second task also requires to specify which target is which. To summarize, the tasks we consider are defined by:</p><p>• A transition: a set of dots with initial and final positions.</p><p>• A set of targets: a subset of dots to be tracked.</p><p>• A test type: either tracking targets as a group (NoID) or tracking target identities (ID). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Complexity metrics</head><p>Depending on the nature of a task, i.e., a transition, a set of targets and a test type, its difficulty will vary greatly. For example, difficulty likely increases with additional targets or distractors -the number of distractors being correlated with crowding. Assuming the number of targets is known, based on our literature review and informal observations we identified three characteristics of animations likely to influence tracking difficulty: i) target crowding, ii) inner crowding and iii) deformation. We refer to them as complexity metrics and provide operational definitions in the following.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.1">General Notations</head><p>In the following, we use P to refer to the set of dots in a transition or animation, and T ⊂ P to refer to the set of targets to track. The symbol p refers to a particular dot in P, and p t refers to its location at the instant t of the animation. Similarly, P t refers to the particular configuration of dots at the instant t. All dots have the same size, s. Dot sizes and coordinates are all normalized between 0 and 1, i.e., divided by the dimensions of the animation window.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.2">Target Crowding</head><p>As seen in the background section, previous studies on object tracking suggest that the difficulty of a tracking task highly depends on how often distractors cross the targets' path or come in their vicinity <ref type="bibr" target="#b20">[22]</ref>. We define a target crowding metric that captures interactions between distractors and targets, and between the targets themselves. We first define the instantaneous crowding of a single dot p ∈ P at instant t as follows:</p><formula xml:id="formula_0">crowd(p,t) =      1 if d(p t , p t close ) ≤ s 1/d(p t ,p t close ) − 1 1/s − 1 if s &lt; d(p t , p t close ) &lt; 1 0 otherwise (1)</formula><p>where d is the distance between two points and p t close is the closest neighbor of p at t.</p><p>This metric ensures that i) crowding is between 0 and 1; ii) crowding is 1 when p and p close touch each other or overlap, iii) crowding is less than 1 when they do not overlap, iv) crowding is 0 when their distance is greater than 1, and v) crowding decreases rapidly with distractor distance.</p><p>For a given animation A, we define the crowding of the dot p, noted crowd(p, A), as the mean value of its instantaneous crowding across the entire animation. Finally, we define the crowding of a set of dots P as the mean value of all their crowdings:</p><formula xml:id="formula_1">crowd(P, A) = 1 |P| ∑ p i ∈P crowd(p i , A)<label>(2)</label></formula><p>where P is a sets of dots, |P| is the number of dots in this set, and A is an animation.</p><p>For any given task (with a set of targets to track), we define target crowding as the crowding of T . Note that this metric depends on both the task and the animation chosen. In order to get a task complexity metric, we define the TARGETCROWDING metric of a tracking task as the crowding of T computed on the simplest possible animated transition, i.e., a direct linear interpolation of all dot positions. <ref type="figure" target="#fig_1">Figure 1</ref> illustrates cases of a low and a high target complexity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.3">Inner Crowding</head><p>As discussed in a background section, previous work has suggested that tracking multiple objects involves attending the entire convex spatial region formed by the targets <ref type="bibr" target="#b39">[41]</ref>. This hypothesis together with our informal observations suggest that distractors located between targets may interfere with tracking more than distractors located outside of the convex region. We therefore introduce another metric, inner crowding, that captures the average number of distractors intersecting the convex hull formed by the targets (see <ref type="figure" target="#fig_1">Figure 1)</ref>.</p><p>We define the instantaneous inner crowding of a set of dots P at instant t as:</p><formula xml:id="formula_2">incrowd(P,t) = ∑ p i ∈P\P inside(p t i , conv(P t ))<label>(3)</label></formula><p>where conv refers to the convex hull and inside is 1 if the point belongs to the polygon and 0 otherwise. In other terms, incrowd captures the number of distractors within the convex hull defined by P.</p><p>As before, we derive a measure of average inner crowding incrowd(P, A) to capture the amount of inner crowding occurring across an entire animation. This allows us to define inner crowding for any particular combination of task and animation by setting P = T . As before, we also define a general task complexity metric INNERCROWDING by setting A to a direct linear interpolation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.4">Deformation</head><p>Previous work also suggests that when tracking three targets, the task is harder when the triangle formed by these targets undergoes important distortions over time <ref type="bibr" target="#b39">[41]</ref>. This was confirmed by our informal observations. We introduce a deformation metric that captures these variations.</p><p>We first define the instantaneous deformation of a set of dots P at the instant t as:</p><formula xml:id="formula_3">de f orm(P,t) = ∑ {p i ,p j }∈P, i&lt; j |d(p t i , p t j ) − d(p t−δ i , p t−δ j )| (4)</formula><p>where d is the distance between two points and δ is the duration of an animation frame.</p><p>In other terms, this metrics captures the instantaneous change in length of all possible segments connecting the points P.</p><p>We use all segments instead of, e.g., the convex hull or a triangulated mesh, because this structure remains stable over time.</p><p>We derive a measure of cumulative deformation over an animation, noted de f orm(P, A), by summing up all instantaneous deformations across the entire animation. Note that while instantaneous deformation depends on animation pacing -including its total length and framerate -cumulative deformation does not. Animation framerate only affects the precision with which cumulative deformation is computed. As before, we derive a deformation metric for a specific task and animation by setting P = T , and we define a task complexity metric DEFORMATION by setting A to a linear interpolation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Difficulty Metrics</head><p>The complexity metrics we introduced only capture characteristics of tasks and animations that we think are correlated with task difficulty, but not task difficulty per se. Task difficulty can only be empirically determined by looking at actual user performance, i.e., by measuring the average precision with which users can track targets. Tracking precision can be estimated through different metrics.</p><p>We refer to S as the set of dots selected by the participant in the test phase of the task. An error metric captures the difference between the selection S and the set of initial targets T . It can be either binary (correct vs. incorrect), discrete (e.g., number of correct targets) or continuous -capturing how "far" the participant was from the actual answer. In psychology, binary and discrete measurements are commonly used and are aggregated across trials to yield proportions of correct answers. This aggregated measure is commonly referred to as accuracy <ref type="bibr" target="#b24">[26]</ref>. Another approach is to report the average distance to the correct answer <ref type="bibr" target="#b13">[15,</ref><ref type="bibr" target="#b27">29]</ref>. Both are useful, so we provide operational definitions for both.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.1">Accuracy</head><p>For any given trial, we define the accuracy of a participant's answer as the number of correctly marked dots divided by the total number of targets. Correctly marked dots refer to all s i ∈ S that belong to T and, in the case of ID tests, are assigned the correct identity.</p><p>To guarantee that this proportion is meaningful, we enforce |T | = |S| by requiring participants to mark as many dots as targets to track before they can proceed. In the case of ID tests, we also require that all identities (colors) are selected once and only once.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.2">Error</head><p>Although accuracy metrics have the advantage of simplicity, they tell little about how far the answer is from the actual answer. In our case, a selection that is far from any target should be penalized more than a selection that is right next to a correct target. In infovis, for example, the latter error can be negligible if the position of the dot is used to read values. We therefore introduce a continuous error metric that captures the distance to the correct answer.</p><p>Dragicevic et al introduced an error metric for single object tracking <ref type="bibr" target="#b13">[15]</ref>. We generalize their definition to multiple targets and define the error between a selection S and a set of targets T as:</p><formula xml:id="formula_4">error(S, T ) = ∑ i err(s i ,t 1 i ) E(err(P, T )) , err(a, b) = ||a − b||<label>(5)</label></formula><p>The numerator captures the total distance between targets and selected dots. t 1 i is the final position of the target of index i, while s i is the matching selection (a dot). In the ID case, targets and selections are matched according to their identity (color), whereas in the NoID case, they are matched in a way that yields the lowest possible error.</p><p>The denominator is a normalizer as in <ref type="bibr" target="#b13">[15]</ref>: E(err(P, T )) corresponds to the expected error that would have been measured had the participant selected random targets, estimated using Monte Carlo methods. Thus, an average error of 1 would mean no knowledge whatsoever on target locations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">EXPERIMENT 1: VALIDATION OF TASK COMPLEXITY METRICS</head><p>In this first experiment, we set out to determine whether task complexity -with regard to the three metrics previously defined -correlates with task difficulty -as measured by our tracking accuracy and error metrics. If lower task complexity yields higher tracking accuracy and lower errors, then our complexity metrics can be used as a proxy for task difficulty, and help design staggered animated transition techniques that improve visual tracking performance without the need to collect empirical data.</p><p>Since the purpose of this experiment is only to validate our task complexity metrics, it does not involve staggered animations: all dots move at the same time from their initial to their final position.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Task Generation</head><p>The following describes how we generated the tasks in order to manipulate task complexity. A task consists of a transition, a set of targets, and a test type. Transitions and sets of targets are randomly generated, then selected based on their complexity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.1">Generation of Random Tasks</head><p>We generated random dot transitions of 30 dots in total including targets, with a dot size of 0.03 (recall all measures of distance are normalized between 0 and 1). In addition, each transition had to meet the following requirements: i) dots are at a minimum distance of 0.08 from each other at the initial and final states, and ii) dots travel a fixed distance of 0.5. The goal of requirement i) was to facilitate target cueing and selection. The goal of requirement ii) was to reduce the space of possible transitions and to control for dot speed, since dot speed depends on both animation duration and the distance covered. Transitions were therefore generated by taking segments of fixed length (corresponding to a dot's path), and randomly drawing their midpoint and orientation. All values were chosen based on pilot studies in order to obtain tasks that are neither too difficult nor too easy, and avoid ceiling and floor effects across the different complexity conditions. We generated tasks for both NoID and ID test types by randomly selecting a set of n = 3 targets among the 30 dots. For the ID test these 3 target were randomly labeled red, green and blue.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.2">Orthogonality of Task Complexity Metrics</head><p>Before proceeding, we tested the orthogonality of our task complexity metrics. The reason is that a task that is high or low on a certain metric (say, target crowding) could also tend to be high or low on another metric (say, deformation). This would mean that our three metrics are not independent and could be reduced to two or one metrics.</p><p>We used a Monte Carlo simulation on 10,000 randomly generated tasks to measure the correlation between our three complexity metrics, and obtained the following results:</p><p>• Correlations are remarkably low, suggesting that our three metrics are close to orthogonal, and successfully capture different, independent characteristics of the tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.3">Manipulation of Task Complexity</head><p>We used the same Monte Carlo simulation to derive a value distribution for each of our metrics. We then took the first and last decile of these distributions in order to classify task complexity into three levels: Low, Medium and High.</p><p>In other terms, a task is said to have Low target crowding if the target crowding measure belongs to the left tail of the overall target crowding distribution, and to have a High target crowding if it belongs to the right tail. The same is true for inner crowding and deformation.</p><p>We ignored Medium complexity tasks in order to get more sensitive measures. This left us with eight (2 3 ) different task complexity profiles: LLL (for Low target crowding, Low inner crowding, Low deformation), LLH, LHL, LHH, HLL, HLH, HHL, and HHH. Tasks following any of these profiles were obtained by selecting from a pool of randomly-generated tasks as detailed above. With two test type conditions (NoID and ID), the experiment involved a total of 2 × 8 = 16 different types of task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Procedure and Apparatus</head><p>Here we cover the experimental setup and procedure. The experimental software can be downloaded and tested at http://fannychevalier.net/animations</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1">Procedure</head><p>Participants first filled out a background questionnaire, then were shown a slideshow explaining the experimental conditions and interactions. They were then asked to perform a series of visual tracking tasks under different complexity conditions and test types. The experiment was broken down into two parts, one for each test type (NoID and ID). At the beginning of each part, participants were prompted with an instruction screen followed by a block of practice trials. Each trial (practice or measured) consisted in the following sequence:</p><p>The participant was first presented with a set of black dots, then asked to press and hold the space bar to reveal the three targets -displayed in red for NoID, and red, green and blue for ID. Releasing the space bar removed the target highlights (we ensured a minimum highlight duration of 0.5 seconds). Then the participant was asked to press the space bar again to trigger the animation of the dots to their final position. After the animation was completed, the participant was then asked to select the targets in the final point cloud using the mouse. Once satisfied with her answer, the participant had to press and hold the space bar in order to validate her answer and reveal the solution.</p><p>For the NoID condition, a target was selected by clicking on a dot, and could be deselected by clicking again. For the ID condition, we designed a pie menu widget for quick and effortless ID selection (see <ref type="figure" target="#fig_2">Figure 2</ref>). To mark a dot blue, for example, the participant just had to perform a mouse press on the dot and drag to the blue area of the pie menu. Clicking without dragging would deselect an already-selected target. Participants could not proceed until they provided a complete answer, i.e., three red dots in the NoID test, and one dot of each color in the ID test. The correct answer was shown in order to motivate participants and reduce the likelihood that they misunderstood the tasks.</p><p>Participants were instructed to answer as accurately as possible, and make their best guess whenever they did not know the answer. Pilot testing suggested that ID tracking required effortful memorization unless the initial target colors were subvocalized. Since we wanted to test visual tracking and not short-term memory, we allowed subvocalization and even explicitly encouraged its use in order to level out strategies. Participants were instructed not to point at the screen. Participants were regularly prompted with an invite to rest.</p><p>After completing all trials, participants filled out a qualitative questionnaire. The whole experiment took approximately one hour.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2">Apparatus and Setup</head><p>The experiment was conducted on a desktop computer equipped with a mouse, keyboard, and an LCD display of resolution 1280×1024 pixels, 2.95×2.96 mm pixel size, and 60 Hz refresh rate. Dots were shown in a 600×600 pixels area (17.72×17.75 cm), and were displayed as black circles of 18 pixels (∼0.53 cm). Participants were sitting at a distance of approximately 65 cm to the display.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Participants</head><p>We recruited 20 unpaid participants (12 female) aged 18-20 (mean 18.5). All were students in psychology and were given course credit in compensation for participating in this experiment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Experimental Design</head><p>Our independent variables were test type (NoID or ID) and task complexity profile. The task complexity profile has eight levels that can be broken down into two levels (Low or High) for each of the three complexity metrics. Each type of task was repeated eight times. To summarize, our factors were: 20 participants × 2 TEST (NoID, ID) × 2 TARGETCROWDING (Low, High) × 2 INNERCROWDING (Low, High) × 2 DEFORMATION (Low, High) × 8 repetitions 2 560 trials Animated transition technique was not a factor in this experiment. All tasks were presented with a non-staggered, direct animation, where all dots moved at the same time, at the same speed and on a straight path. All animations lasted one second and used a slow-in slow-out pacing as recommended in <ref type="bibr" target="#b13">[15]</ref>.</p><p>The trials were blocked by TEST, yielding two blocks of 2 × 2 × 2 × 8 = 64 trials. Each block was preceded by 8 practice trials (1 per complexity profile). Trials were fully randomized within each block and the block presentation order was counterbalanced across participants.</p><p>Our two dependent variables were tracking ACCURACY and tracking ERROR, as defined in the previous section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Hypotheses</head><p>Based on our previous analysis, our hypothesis was that our three task complexity metrics all correlate with task difficulty, and that all three metrics are equally important. In other terms, we predicted that:</p><p>• For all three metrics (TARGETCROWDING, INNERCROWDING and DEFOR-MATION), tasks of high complexity will be clearly more difficult on average than tasks of low complexity,</p><p>• These effects will be observed for both difficulty metrics (ACCURACY and ERROR),</p><p>• The effects will be similar for all three task complexity metrics. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6">Results</head><p>Due to growing concerns in various research fields over the limits of null hypothesis significance testing for reporting and interpreting experimental results <ref type="bibr" target="#b11">[13,</ref><ref type="bibr" target="#b14">16]</ref>, we base all our analyses and discussions on estimation, i.e., effect sizes with confidence intervals <ref type="bibr" target="#b12">[14]</ref>. This approach also aligns with the latest recommendations from the APA <ref type="bibr" target="#b1">[3]</ref>.</p><p>We break down our analysis into a confirmatory and an exploratory section <ref type="bibr" target="#b11">[13]</ref>. All analyses in the confirmatory section were prespecified before conducting the experiment, i.e., the R scripts used for computing effect sizes, confidence intervals and for generating initial drafts of the figures were written in advance and tested on pilot data. Analyses in the exploratory section were conducted to address additional questions raised while looking at the experimental data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6.1">Confirmatory analysis</head><p>We observed similar trends for the two difficulty metrics, so we focus our analysis on ACCURACY. The effect of task complexity on ACCURACY is reported in <ref type="figure">Figures 3 and 4</ref>, for the NoID and ID tasks respectively.</p><p>On <ref type="figure">Figure 3</ref>, the left plot shows the effect of each complexity metric (one per row). The effect of each metric was assessed by performing a contrast, i.e., aggregating all trials where the metric was Low and all trials where the metric was High. For each metric, two mean accuracies were therefore derived for each participant (one for Low and one for High), yielding a total of 20 data points for Low and 20 data points for High. Point estimates and 95% confidence intervals were computed using bootstrapping <ref type="bibr" target="#b25">[27]</ref>. On the <ref type="figure">Figure,</ref> higher values (to the right) mean higher accuracy. Points indicate best estimates while intervals indicate all plausible values, the point estimates being about 7 times more likely than interval endpoints <ref type="bibr" target="#b10">[12]</ref>. Thus the effect of complexity on accuracy is clear, except for DEFORMATION. The right plot shows point and interval estimates of the difference of mean accuracy between Low and High, computed for each participant (yielding 20 data points in total). This method gives more precise effect size estimates (as often in within-subjects designs) that leave no doubt as to the effect of DEFORMATION. <ref type="figure">Figure 4</ref> shows the results of the same analysis considering ID tasks instead of NoID tasks. Clear effects can also be seen for all three metrics, and this time the effects are quite similar.</p><p>Overall, our data are consistent with the trends initially predicted by our hypothesis, except for the relative importance of our three metrics. We initially conjectured that the three metrics would have roughly the same importance, which was confirmed for the ID tracking task but not the NoID tracking task: when the task only requires to track targets as a group, DEFORMATION has a measurable detrimental effect but it is the least important factor. Both TARGETCROWDING and INNERCROWDING have a higher influence on performance, with INNERCROWDING being particularly detrimental to tracking accuracy. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6.2">Exploratory analysis</head><p>Here we address the question as to why the three metrics have a comparable effect for ID tasks, but quite different effects for NoID tasks. Recall the ID tasks involved two components and thus two possible sources of error: i) identifying where the three targets ended up and ii) identifying which target is which. To get a better understanding of the results for the ID task, we examined the two types of error separately.</p><p>We first reanalyzed the answers to the ID task by considering participants' accuracy in selecting targets irrespective of their identities, as we did for the NoID task. <ref type="figure" target="#fig_5">Figure 5</ref> shows the mean accuracy and mean accuracy difference for the ID task estimated using the same metric as the NoID task. The results were remarkably close to the NoID task <ref type="figure">(Figure 3</ref>), suggesting that participants were able to follow the three targets as if no identity tracking was required, but mixed up their identities more or less frequently depending on the task's complexity profile. This in turn suggests that the difficulty of tracking dot identities varies depending on the task's complexity profile, since the trends are very different (i.e., accuracies even out) when both sources of error are accounted for (see <ref type="figure">Figure 4</ref>). This conjecture is confirmed when analyzing the proportion of misidentification errors (i.e., wrongly selected colors) among the dots that have been correctly identified as targets. The plot in <ref type="figure" target="#fig_6">Figure 6</ref> shows the proportion of misidentification errors for trials where participants successfully selected all three targets (∼30% of all trials). Trends were similar in the other cases, though the interval estimates were too wide for a meaningful analysis.</p><p>On <ref type="figure" target="#fig_6">Figure 6</ref>, higher estimates (i.e., more to the right) mean more identification errors. It can be seen that deformation seriously impairs target identity tracking, as participants are much more likely to mix up colors than when the triangle formed by the three targets only translates or rotates. Target crowding also seems to play a role, although to a much lesser extent. Most remarkably, a task with higher inner crowding makes participants less likely to mix up targets. One possible explanation is that when inner crowding is low, the three targets are mostly separated by empty space and tend to be close to each other, and thus are more likely to be merged into a single object by visual attention processes <ref type="bibr" target="#b21">[23]</ref>. This attentional merging can lead participants to "forget" target identities. In contrast, in high inner crowding conditions, the larger spacing between targets and the intervening distractors may facilitate the tracking of the three targets as separate objects. This however only concerns trials where dots have been successfully tracked in the first place, which are much less numerous when inner crowding is high (see <ref type="figure" target="#fig_5">Figure 5</ref>). Nevertheless, these findings can have interesting applications for situations where switching target identities is much more costly than loosing track of them.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6.3">Questionnaire</head><p>Since participants were told that some tasks were more difficult than others without further details, we only asked which strategy they developed, and when such strategy was challenged. Their feedback provides valuable insights on the perceived difficulty of the tasks.</p><p>Among the developed strategies, participants i) pictured the dots as a virtual triangle (4 participants) -which they reported to be challenging when the shape collapsed, i.e., when a vertex crossed the opposite edge, especially in the ID test; ii) "blurred" their focus and relied on peripheral vision during the animation (5 participants) -a strategy that was perceived more difficult when the targets were crowded; or iii) eventually gave up on tracking all three targets and kept their focus on only two of them, hoping to guess the third right without conviction.</p><p>These results suggest that though the difference in complexity between the Low and High conditions are rather low values (10% to 20% of the total range of complexities), these variations for TARGETCROWD-ING and DEFORMATION are still perceived as being highly different.</p><p>In summary, this experiment confirms that task complexity as we defined it can be used as a proxy for task difficulty, and that each of the three metrics captures a different aspect of difficulty. The following examines whether staggering can be used to manipulate these factors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">ANALYSIS: CAN STAGGERING REDUCE TASK COMPLEXITY?</head><p>We know from the previous experiment that our complexity measures are correlated to task difficulty. As discussed in Section 3, task complexity is a function of the animated transition chosen. An animated transition technique that reduces task complexity on average may be therefore more promising than a technique that leaves it unchanged or increases it. In this analysis, we set out to determine whether staggering can reduce task complexity when very few assumptions are made about the nature of the visual transition.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Staggered Animation Designs</head><p>By staggered animation we mean an animation where all elements move at different times and i) each element starts moving with a constant temporal delay δ t after the previous one, and ii) all elements move for the same duration. Such animations can be characterized by two parameters:</p><p>• the order in which the individual elements move, and,</p><p>• a dwell factor, capturing the degree of motion sequentiality:</p><formula xml:id="formula_5">dwell(|P|,t(A), δ t ) = δ t • |P| t(A)</formula><p>where |P| is the number of moving elements, t(A) is the total animation duration, and δ t is the delay previously mentioned. In other terms, a dwell of 0 corresponds to an animation where all dots move simultaneously (no sequentiality), and a dwell of 1 corresponds to an animation where they all move in sequence (maximum sequentiality).</p><p>When designing staggered animation techniques, there are many possible orders to chose from and many possible values for dwell, and these choices might influence the effectiveness of the technique for a number of reasons. While our primary concern is reducing task complexity, staggering may cause additional perceptual difficulties due to i) a lower predictability as to which elements will move and when, and ii) the increased speed with which elements move. While i) is impacted by the choice of ordering, ii) is impacted by the choice of dwell. We explain which designs we chose for the purposes of this analysis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.1">Choice of Order</head><p>The predictability of staggered transitions may be facilitated by moving the dots in a systematic order, such as based on their initial location (e.g., from top to bottom). However, fixing the ordering also limits the possible animations to choose from, making it less easy to optimize complexity. We therefore chose to test two ordering schemes: one that optimizes predictability, and another one that optimizes complexity.</p><p>• Spatial ordering consists in having dots move according to their initial y-coordinate, starting from the topmost dot and finishing with the bottom-most dot.</p><p>• Smart ordering consists in having dots move in a way that tries to minimize crowding. For smart ordering, we focus on minimizing crowding primarily because informal experimentation suggested it is the complexity metric that is the easiest to minimize. This will be later confirmed by our analyses. Our current implementation uses a simple Monte Carlo approach that generates 2,000 random orders and picks the one with the lowest crowding. Crowding is computed by setting all dots as targets (i.e., we compute TARGETCROWDING, for T = P). Although one could possibly optimize complexity only for the targets, such a technique would be of little use for real computer applications, where the system is rarely aware of which elements of the display the user chose to focus on. Nevertheless, minimizing global crowding makes it more likely that target crowding is also reduced. Finally, smart ordering is computed based on the dwell value, discussed in the next section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.2">Choice of Dwell</head><p>The same way different staggering orders come with benefits and drawbacks, different dwell times also have trade-offs. In particular, a higher dwell increases motion sequentiality, which could help focus on individual dots. However, for a fixed animation duration, a higher dwell also increases motion speed, since dots have less time to reach their final destination. Though speed is not an issue per se, devoting fewer animation frames to each dot motion may be detrimental <ref type="bibr" target="#b17">[19]</ref>.</p><p>After informal testing with different dwell values on transitions involving 30 dots, we converged to three values: a LOW DWELL (0.2), a MEDIUM DWELL (0.4) and a HIGH DWELL (0.6). These values provide a good coverage of all reasonable dwell values, as values higher than 0.6 yielded animations close to impossible to follow for these transitions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Analysis Results</head><p>We tested the six different staggering techniques obtained by fully crossing the ORDER conditions (SPATIAL, SMART) and the DWELL conditions (LOW, MEDIUM, HIGH). We generated 10,000 random tasks using the same criteria as in the previous experiment, and measured the differences in task complexity profiles compared to no staggering.</p><p>In <ref type="figure" target="#fig_7">Figure 7</ref>, scatterplots show the complexity for all 10,000 tasks, for all complexity metrics (on columns) and dwell values (on rows)due to space limitation, only the most illustrative conditions are showed. The x-axis of each scatterplot is the complexity measurement without staggering. The y-axis reflects the complexity measurement of the same task with staggering. The dashed line is the identity line. The thick line is the linear regression. Any data point located under the dashed line (the green area) indicates that staggering has successfully reduced task complexity with regard to the complexity metric.</p><p>The plots for target crowding (two left columns) suggest that SPA-TIAL staggering slightly reduces crowding overall, both with LOW and HIGH dwell, while SMART yields more improvement. However, there is a large variability in both cases (sometimes staggering makes things worse) and the reduction is overall modest for SPATIAL in particular. Reassuringly, the slope of the regression lines suggest that staggering reduces crowding more when it is already high. These results confirm previous intuitions that staggering can reduce crowding by having visual objects move at different times and "avoid" each other, but the average reduction on unstructured transitions is surprisingly low.</p><p>The plots for inner crowding (third column) suggest that SMART staggering has little impact on inner crowding, as the linear regression and identity line are almost confounded. With HIGH dwell, the effect is observable but still small. We observed similar trends for SPATIAL. That staggering does not affect inner crowding is hardly surprising: inner crowding is generally high when targets are spaced out, and staggering does little in bringing targets closer to each other.</p><p>The plots for deformation (to the right) suggest that SMART with LOW dwell has little impact on deformation, while its effect with HIGH dwell is mostly detrimental, especially when deformation is initially low. Here too, SPATIAL yielded similar trends, though to a lesser extent. Again, this result is not surprising, since if objects move together in a coherent fashion, staggering will tend to break this coherence.</p><p>In summary, our analyses confirm that staggering can help reduce task complexity is some cases, but these cases are rare and the difference on average is modest (for target crowding) or negligible (for inner crowding). Moreover, staggering tends to increase deformation. Given the possibly detrimental effects introduced by staggering that are independent from the task complexity profile, the benefits of staggering -at least when systematically applied to unstructured transitionsare doubtful. The question however remains as to whether staggering can be beneficial for those rare cases where it does significantly reduce task complexity. This is the subject of our second experiment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">EXPERIMENT 2: MEASURING THE EFFECT OF STAGGERING</head><p>So far we have learned that staggering fails to consistently reduce task complexity metrics. Furthermore, staggering can decrease predictability and increase motion speed, which may make tracking tasks even harder. A pending question is whether staggering still helps when it successfully reduces task complexity. We conducted a second experiment where we tested SPATIAL and SMART staggering on the most favorable tasks. While such tasks are unrepresentative of unstructured transitions, we seek to understand whether staggering can sometimes be beneficial, and whether one should try to minimize complexity as much as possible at the detriment of predictability, or vice versa.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Task Generation</head><p>In contrast with our first experiment where the goal was to test tasks with different complexity profiles, the goal in this second experiment is to test the tasks that are likely to benefit the most from staggering. Since all three complexity metrics correlate with difficulty, we must choose which importance to give to each metric. We found ID tasks to be equally impacted by all metrics <ref type="figure">(Figure 4</ref>), while NoID tasks were the most impacted by DEFORMATION ( <ref type="figure">Figure 3</ref>). Our simulations also revealed that staggering has very little impact on INNERCROWDING and tends to increase DEFORMATION more than it reduces it. Therefore, we selected tasks where staggering yields the best reduction in TAR-GETCROWDING without increasing INNERCROWDING and DEFORMATION.</p><p>One difficulty is that a task that favors a given staggering technique may not favor another technique. To guarantee a fair comparison, we select the most favorable tasks per technique. Thus we compare techniques by the gain in performance they yield in the best cases scenarios, using direct animation as a baseline.</p><p>For each technique defined by an ORDER and a DWELL, we picked the n most favorable tasks as follows: we generate n × 10, 000 random tasks for the ID task, and prune those where INNERCROWDING or DEFOR-MATION is increased by staggering. From the remaining pool, we keep the n tasks that reduce TARGETCROWDING the most. In other words, we select the 0.01% most favorable cases for each staggering technique.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Procedure and Apparatus</head><p>We used the same setup and followed the same procedure as Experiment 1 (Sec. 4.2) with a few changes. First, we tested the ID tasks only, based on the results of Experiment 1 suggesting that performance for NoID tasks can be estimated fairly well by using ID tasks and the accuracy metric from the NoID task (compare <ref type="figure" target="#fig_5">Figures 3 and 5)</ref>. The experiment was also broken down into 16 blocks instead of 2. Each block consisted of a series of trials with the same animation technique preceded by instructions (more below on the experiment design).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Participants</head><p>We recruited 20 new participants (14 female) aged 18-35 (mean 22.5). All were students or University staff and were compensated $10.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.4">Experimental design</head><p>Since we were interested in the improvement provided by staggering over direct animations, we presented each task twice, with and without staggering, to allow for pairwise comparison. Due to the block design, a task was never presented twice in the same block.</p><p>Our independent variables were presence of staggering (on, off ), ORDER (SPATIAL, SMART) and DWELL (LOW, HIGH). Participants were presented with two blocks of five repetitions each for each combination of staggering, ORDER and DWELL. To summarize, our factors were: 20 participants × 2 staggering (on, off ) × 2 ORDER (SPATIAL, SMART) × 2 DWELL (LOW, HIGH) × 2 blocks × 5 repetitions 1 600 Trials</p><p>The presentation order of all 2×2×2×2 = 16 blocks was fully randomized, as well as all 5 repetitions within each block. The experiment was preceded by 32 practice trials, 4 for each technique.</p><p>We computed accuracy gain and error gain by taking the difference in ACCURACY and ERROR between staggering and no staggering for the same task. Both gains were measured by taking into account identification errors (ID metric), and without taking into account identification errors (NoID metric). Therefore we had four dependent variables.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.5">Hypotheses</head><p>Based on our simulations and on further informal observations, our hypothesis was that for the favorable tasks, staggering will slightly improve accuracy if the dwell is low and if the order is predictable. We indeed noticed that both fast and unpredictable dot movements seemed to make tracking more challenging. In other terms, we predicted that:</p><p>• Tasks will be easier on average for staggered animations using SPATIAL ordering and LOW dwell, compared to direct animations.</p><p>• The SMART technique will exhibit no observable improvement over direct animations or will be detrimental, for both dwell conditions.</p><p>• HIGH dwell will exhibit no observable improvement over direct animations or will be detrimental, for both order conditions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.6">Results</head><p>As before, we use an estimation approach to data analysis and break down our analyses into confirmatory and exploratory.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.6.1">Confirmatory Analysis</head><p>The effects of staggering ORDER and DWELL on accuracy gain are reported in <ref type="figure">Figure 8</ref>. The left plot shows the accuracy gain for each of the four staggering techniques, using the ID performance metric. For each staggering condition, a mean accuracy gain was derived for each participant, yielding a total of 20 data points. Point estimates and 95% confidence intervals were computed using bootstraping methods. The right plot shows the effects measured when the NoID performance metric is used. <ref type="figure">Figure 9</ref> shows the same analyses for error gain. On all Figures, values to the right (high for accuracy difference and low for error difference) indicate that staggering is beneficial.</p><p>Contrary to what we predicted, SMART staggering with a HIGH dwell yields an observable gain in accuracy, particularly for the ID metric <ref type="figure">(Figure 8, left plot)</ref>. We can also be fairly confident that SPATIAL staggering with a HIGH gain yields a small increase in error, particularly for the NoID metric <ref type="figure">(Figure 9, right plot)</ref>. For all other conditions, the sampling error is too large for us to be able to conclude, but the general trend seems to be that SMART ordering outperforms SPATIAL ordering.</p><p>Overall these results suggest that contrary to what we initially expected, reducing TARGETCROWDING -which SMART staggering with HIGH dwell does best <ref type="figure" target="#fig_7">(Figure 7</ref>) -seems to be more important than enforcing predictability. This seems to be true both for ID and NoID tasks. Despite these trends, if we consider effect sizes, the benefits of staggering are lower than we could have expected. For the best technique, the increase in accuracy most likely does not go beyond 0.15 and the reduction in error does not go beyond 0.1. These very liberal estimates are comparable to the gains brought by, e.g., switching from high to low deformation when performing NoID tracking tasks on non-staggered animations (see <ref type="figure">Figure 3)</ref>. These gains are substantial but surprisingly low given that we selected the 0.01% (1 out of 10,000) most favorable cases from our pool of randomly-generated tasks. Given this, we can fairly conclude that the facilitating effects of staggered animated transitions are far from staggering when applied to complex dot transitions as found in, e.g., dynamic scatterplots.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.6.2">Exploratory Analysis</head><p>We focus the rest of our exploratory analysis on the questionnaire.</p><p>In contrast with our first experiment, participants were fully aware of the set of experimental conditions (i.e. animation techniques). We asked them to rank task difficulty for each condition on a five-point Likert scale (very easy to very difficult). <ref type="figure" target="#fig_1">Figure 10</ref> shows the results. An interesting result is that the tasks where participants performed the best (SMART, HIGH) were also perceived as the most difficult overall. Answers align with our first conjecture that both fast and unpredictable dot movements appear to be highly challenging. Similarly, participants ranked the SPATIAL ordering with LOW dwell as easier than no staggering overall, though the gain was not measurable in practice.</p><p>This suggests that even though a staggering technique improves performance, the observer may still feel overwheled by the perceived difficulty. Conversley, it seems that staggering that is not beneficial for visual tracking, can give the illusion of facilitating. From an animation design perspective, this means that there may still be a value of using staggered animations in applications that do not require high accuracy.</p><p>In summary, this last experiment confirms that for best performance, animated transitions should try to reduce TARGETCROWDING first, though participants found unpredictability harder. We found some minor evidence of gains of staggering in some particular conditions. The effect is discouragingly poor given that we tested the best case scenarios for staggering. On all possible transitions, we suspect that the gains would have most likely been non-measurable, or even possibly negative given the non-predictability and the increase in deformation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">DISCUSSION</head><p>Our study confirms that task difficulty can be assessed by the means of our three complexity metrics. In particular, we were able to validate prior work in perceptual psychology that visual tracking is impaired by crowding. We also found that higher inner crowding harms tracking of the target end position, whereas it surprisingly facilitates identity tracking. In contrast, deformation is harmful to tracking, but only when individual target identities must be maintained.</p><p>Follow-up investigations showed that staggering can reduce complexity as measured by crowding (keeping the two other metrics constant), under two different animation techniques. However, such cases are rare, and the gain is modest overall. We tested tracking performance on the 0.01% best case scenarios to assess whether reducing crowding with staggering was beneficial keeping in mind that any improvement could be at the cost of additional difficulties introduced by staggering. Interestingly, experimental data provide evidence that it is preferable to reduce crowding than maintain predictability and low motion speed, with a measurable gain of performance.</p><p>What makes these 0.01% of trials so special? These rare trials where crowding is reduced by staggering must have a particular type of spatial structure, or exhibit a particular type of motion pattern. Previous work that explores staggering focus on visualizations with specific configurations, such as 1-dimensional bar charts, pie charts <ref type="bibr" target="#b22">[24]</ref> and histograms <ref type="bibr" target="#b9">[11]</ref>. In contrast, our study focused on the more general case of 2D random point clouds. We attemped to find generalized structures or motion patterns among the top 0.001% of least-crowded staggered trials, to no avail. Our selected tasks reduce complexity for the arbitrarily-chosen targets only, and it is possible that no staggered transition technique will reduce complexity in a target-agnostic way.</p><p>All in all, while more work is needed to identify the potential benefits for staggering, this work contributes several methodological tools, and overall design considerations:</p><p>• All three complexity metrics target crowding, inner crowding and deformation are a good proxy for visual tracking task difficulty and can be used as reference measures in further experiments.</p><p>• Among the three complexity metrics, target crowding is the one that yields the most benefit from staggering. We thus recommend to primarily consider this factor when designing staggered animations.</p><p>• From a viewer's perspective, the positive aspect of staggeringa potential to bring tiny improvements in crowding and accuracy -is likely to be outwheighted by its negatives -a loss of predictability in motion start times, and faster motion of individual elements.</p><p>The above implications for design, though informative, must be considered with caution since we tested the effect of staggering on very specific, low level tasks which may not be strongly representative of typical infovis tasks. We have chosen to carefully control the details that may affect the study results in order to isolate the effect of our independant variables on our dependant variables. We thus favoured internal validity over external validity <ref type="bibr" target="#b6">[8]</ref>, and future work should confirm that our results apply more widely in real-world contexts. This said, as previously discussed, if users are unable to perform such elementary tasks, then more complex tasks involving visual tracking will likely be as much or more difficult to carry out (see also <ref type="bibr" target="#b13">[15]</ref>). This work helps us better understand animations, and we hope that it will inspire further development in the area.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">CONCLUSION AND FUTURE WORK</head><p>This work examines the potential for staggering to improve visual tracking tasks in animated transitions. We contribute the definition of complexity metrics to assess task difficulty, and measure if and to which extent reducing complexity through staggering yields better performance. Our results suggest that staggering may be beneficial in some conditions, but they have yet to be demonstrated.</p><p>This work is a significant step toward a better understanding of pacing in animated transitions. While our results do not demonstrate strong benefits for staggering, this work provide useful directions for further research. More work is needed to identify the potential of staggered animations beyond their aesthetic value. In particular, we plan to study effects on data that exhibit meaningful spatio-temporal structure and extend our investigation to sequential animations.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>For</head><label></label><figDesc>information on obtaining reprints of this article, please send e-mail to: tvcg@computer.org. Manuscript received 31 Mar. 2014; accepted 1 Aug. 2014 ate of publication 2014; date of current version 2014. 11 Aug. 9 Nov. D . Digital Object Identifier 10.1109/TVCG.2014.2346424</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 1 .</head><label>1</label><figDesc>Illustration of the complexity measures.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 2 .</head><label>2</label><figDesc>Marking a blue target with the pie menu widget in the ID task.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>inner crowding / crowding: r = −0.045, 95% CI [-0.065, -0.026], • inner crowding / deformation: r = −0.078, 95% CI [-0.098, -0.059], • deformation / target crowding: r = 0.080, 95% CI [0.060, 0.100].</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 3 .Fig. 4 .</head><label>34</label><figDesc>Mean ACCURACY and mean ACCURACY difference as a function of task complexity for the NoID tracking task. Error bars are 95% CIs. Mean ACCURACY and mean ACCURACY difference as a function of task complexity for the ID tracking task. Error bars are 95% CIs.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 5 .</head><label>5</label><figDesc>Mean ACCURACY and mean ACCURACY difference of target selection only (no identification) as a function of task complexity for the ID tracking task. Error bars are 95% CIs.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 6 .</head><label>6</label><figDesc>Left: Total number of trials per successfully selected targets and complexity. Right: Percentage of misidentified targets per correctly selected targets as a function of task complexity for 3 correctly selected targets. Error bars are 95% CI.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 7 .</head><label>7</label><figDesc>Complexity of transitions without staggering vs. with staggering animation for SPATIAL, and Low (top) and High (bottom) dwell.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 8 .Fig. 9 .</head><label>89</label><figDesc>Mean accuracy gain as a function of staggering technique, for the ID metric (left) and the NoID metric (right). Error bars are 95% CIs. Mean error gain as a function of staggering technique, for the ID metric (left) and for the NoID metric. Error bars are 95% CIs.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig. 10 .</head><label>10</label><figDesc>Participants' assessment of difficulty per condition.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>•</head><label></label><figDesc>Fanny Chevalier is with Inria. E-mail: fanny.chevalier@inria.fr • Pierre Dragicevic is with Inria. E-mail: pierre.dragicevic@inria.fr • Steven Franconeri is with Northwestern University. E-mail: franconeri@northwestern.edu</figDesc><table /><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS</head><p>We thank Bruno de Araujo and Mathieu Nancel for their valuable input on this paper, Kevin Hartstein and Alan Pan for their help running the experiments, and our reviewers for their useful comments.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">How many objects can you track?: Evidence for a resource-limited attentive tracking mechanism</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">A</forename><surname>Alvarez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">L</forename><surname>Franconeri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Vision</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">13</biblScope>
			<biblScope unit="page">14</biblScope>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m">The Publication manual of the American psychological association</title>
		<meeting><address><addrLine>Washington, DC</addrLine></address></meeting>
		<imprint>
			<publisher>American Psychological Association</publisher>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
	<note>6th ed.</note>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Graphdiaries: Animated transitions and temporal navigation for dynamic networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Bach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Pietriga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Fekete</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Animation at the interface</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Baecker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Small</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1990" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Does animation help users build mental maps of spatial information?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">B</forename><surname>Bederson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Boltman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Information Visualization, 1999.(Info Vis&apos; 99) Proceedings. 1999 IEEE Symposium on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="1999" />
			<biblScope unit="page" from="28" to="35" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Graphdice: A system for exploring multivariate social networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bezerianos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Chevalier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dragicevic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Elmqvist</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-D</forename><surname>Fekete</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Graphics Forum</title>
		<imprint>
			<publisher>Wiley Online Library</publisher>
			<date type="published" when="2010" />
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="863" to="872" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">The concept of external validity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">J</forename><surname>Calder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">W</forename><surname>Phillips</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">M</forename><surname>Tybout</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Consumer Research</title>
		<imprint>
			<biblScope unit="page" from="240" to="244" />
			<date type="published" when="1982" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Animation: from cartoons to the user interface</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B.-W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ungar</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Using text animated transitions to support navigation in document histories</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Chevalier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dragicevic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bezerianos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-D</forename><surname>Fekete</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the SIGCHI Conference on Human Factors in Computing Systems</title>
		<meeting>the SIGCHI Conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="683" to="692" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Histomages: fully synchronized views for image editing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Chevalier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dragicevic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Hurter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th annual ACM symposium on User interface software and technology</title>
		<meeting>the 25th annual ACM symposium on User interface software and technology</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="281" to="286" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Understanding the new statistics: Effect sizes, confidence intervals, and meta-analysis. Routledge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Cumming</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">The new statistics: Why and how</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Cumming</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological science</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="7" to="29" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Inference by eye: Confidence intervals and how to read pictures of data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Cumming</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Finch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">American Psychologist</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">170</biblScope>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Temporal distortion for animated transitions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dragicevic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bezerianos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Javed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Elmqvist</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-D</forename><surname>Fekete</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the SIGCHI Conference on Human Factors in Computing Systems</title>
		<meeting>the SIGCHI Conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="2009" to="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Running an hci experiment in multiple parallel universes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dragicevic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Chevalier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Huot</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CHI &apos;14 Extended Abstracts on Human Factors in Computing Systems</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="607" to="618" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Gliimpse: Animating from markup code to rendered documents and vice versa</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dragicevic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Huot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Chevalier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th annual ACM symposium on User interface software and technology</title>
		<meeting>the 24th annual ACM symposium on User interface software and technology</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="257" to="262" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Rolling the dice: Multidimensional visual exploration using scatterplot matrix navigation. Visualization and Computer Graphics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Elmqvist</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dragicevic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-D</forename><surname>Fekete</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1539" to="1148" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Tracking multiple objects is limited only by object spacing, not by speed, time, or capacity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Franconeri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Jonathan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Scimeca</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Science</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="920" to="925" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">The nature and status of visual resources. Oxford handbook of cognitive psychology</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">L</forename><surname>Franconeri</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">8481</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Flexible cognitive resources: competitive content maps for attention and memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">L</forename><surname>Franconeri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">A</forename><surname>Alvarez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Cavanagh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Trends in cognitive sciences</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="134" to="141" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Evidence against a speed limit in multiple-object tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">L</forename><surname>Franconeri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">T</forename><surname>Enns</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><forename type="middle">W</forename><surname>Pylyshyn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Fisher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychonomic Bulletin &amp; Review</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="802" to="808" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">A simple proximity heuristic allows tracking of multiple objects through occlusion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">L</forename><surname>Franconeri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><forename type="middle">W</forename><surname>Pylyshyn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">J</forename><surname>Scholl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Perception, &amp; Psychophysics</title>
		<imprint>
			<biblScope unit="volume">74</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="691" to="702" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
	<note>Attention</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Animated transitions in statistical data graphics. Visualization and Computer Graphics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Heer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">G</forename><surname>Robertson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1240" to="1247" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Tracking unique objects</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">S</forename><surname>Horowitz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">B</forename><surname>Klieger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">E</forename><surname>Fencsik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">K</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">A</forename><surname>Alvarez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Wolfe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Perception &amp; psychophysics</title>
		<imprint>
			<biblScope unit="volume">69</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="172" to="184" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">The mathematics of multiple object tracking: From proportions correct to number of objects tracked</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hulleman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Vision research</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">17</biblScope>
			<biblScope unit="page" from="2298" to="2309" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Bootes: An r package for bootstrap confidence intervals on effect sizes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">N</forename><surname>Kirby</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Gerlanc</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Behavior research methods</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="905" to="927" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Principles of traditional animation applied to 3d computer animation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lasseter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In ACM Siggraph Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="35" to="44" />
			<date type="published" when="1987" />
			<publisher>ACM</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Assessing the effect of visualizations on bayesian reasoning through crowdsourcing. Visualization and Computer Graphics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Micallef</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dragicevic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Fekete</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2536" to="2545" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Crowding is unlike ordinary masking: Distinguishing feature integration from detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">G</forename><surname>Pelli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Palomares</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">J</forename><surname>Majaj</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of vision</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page">12</biblScope>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Spacetree: Supporting exploration in large node link tree, design evolution and empirical evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Plaisant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Grosjean</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">B</forename><surname>Bederson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Information Visualization</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2002" />
			<biblScope unit="page" from="57" to="64" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Some puzzling findings in multiple object tracking: I. tracking without keeping track of object identities</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Pylyshyn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Visual cognition</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="801" to="822" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Tracking multiple independent targets: Evidence for a parallel tracking mechanism</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><forename type="middle">W</forename><surname>Pylyshyn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">W</forename><surname>Storm</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Spatial vision</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="179" to="197" />
			<date type="published" when="1988" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Multiple-object permanence tracking: Limitation in maintenance and transformation of perceptual objects</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Saiki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Progress in brain research</title>
		<imprint>
			<biblScope unit="volume">140</biblScope>
			<biblScope unit="page" from="133" to="148" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Les transitions visuelles différenciées: principes et applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Schlienger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dragicevic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Ollagnon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chatty</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 18th International Conferenceof the Association Francophone d&apos;Interaction Homme-Machine</title>
		<meeting>the 18th International Conferenceof the Association Francophone d&apos;Interaction Homme-Machine</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2006" />
			<biblScope unit="page" from="59" to="66" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Tracking multiple items through occlusion: Clues to visual objecthood</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">J</forename><surname>Scholl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><forename type="middle">W</forename><surname>Pylyshyn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognitive psychology</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="259" to="290" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">The effect of animated transitions in zooming interfaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Shanmugasundaram</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Irani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the working conference on Advanced visual interfaces</title>
		<meeting>the working conference on Advanced visual interfaces</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2008" />
			<biblScope unit="page" from="396" to="399" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Can smooth view transitions facilitate perceptual constancy in node-link diagrams?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Shanmugasundaram</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Irani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Gutwin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Graphics Interface</title>
		<meeting>Graphics Interface</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2007" />
			<biblScope unit="page" from="71" to="78" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Change blindness</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">J</forename><surname>Simons</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">T</forename><surname>Levin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Trends in cognitive sciences</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="261" to="267" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Animation: can it facilitate? International journal of human-computer studies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Tversky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">B</forename><surname>Morrison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Betrancourt</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="page" from="247" to="262" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Multielement visual tracking: Attention and perceptual organization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Yantis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognitive psychology</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="295" to="340" />
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
