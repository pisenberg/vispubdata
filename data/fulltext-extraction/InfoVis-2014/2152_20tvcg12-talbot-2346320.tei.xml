<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/pisenberg/grobid/grobid-0.6.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Four Experiments on the Perception of Bar Charts</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Justin</forename><surname>Talbot</surname></persName>
							<email>jtalbot@tableausoftware.com</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vidya</forename><surname>Setlur</surname></persName>
							<email>vsetlur@tableausoftware.com</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anushka</forename><surname>Anand</surname></persName>
							<email>aanand@tableausoftware.com.</email>
						</author>
						<title level="a" type="main">Four Experiments on the Perception of Bar Charts</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="DOI">10.1109/TVCG.2014.2346320</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2021-02-19T19:10+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>Graphical perception, bar charts</keywords>
			</textClass>
			<abstract>
				<p>Bar charts are one of the most common visualization types. In a classic graphical perception paper, Cleveland &amp; McGill studied how different bar chart designs impact the accuracy with which viewers can complete simple perceptual tasks. They found that people perform substantially worse on stacked bar charts than on aligned bar charts, and that comparisons between adjacent bars are more accurate than between widely separated bars. However, the study did not explore why these differences occur. In this paper, we describe a series of follow-up experiments to further explore and explain their results. While our results generally confirm Cleveland &amp; McGill&apos;s ranking of various bar chart configurations, we provide additional insight into the bar chart reading task and the sources of participants&apos; errors. We use our results to propose new hypotheses on the perception of bar charts.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>In their classic graphical perception paper, Cleveland &amp; McGill <ref type="bibr" target="#b0">[1]</ref> studied how accurately people can estimate relative heights in different bar chart designs. They used these results to rank the designs; for example, suggesting that aligned bar charts should be preferred to stacked bar charts since the former allow more accurate estimates. Their work introduced a quantitative and experimentally-grounded approach for choosing between alternative visualization designs.</p><p>In this paper, we describe a series of four follow-up experiments to further explore and understand Cleveland &amp; McGill's results. Our primary goal is to understand how different bar chart designs impact accuracy. In particular, we find:</p><p>• In simple bar charts, comparisons between non-adjacent bars are difficult due to the separation between them. Separation makes comparison of short bars particularly difficult. Intervening distractor bars may also increase difficulty, but our estimates suggest that this effect is smaller.</p><p>• In stacked bar charts, distractors substantially increase difficulty, perhaps because they reduce the visual saliency of the lengths to be compared. Also, in Cleveland &amp; McGill's study, bars were marked with a small dot. Surprisingly, our results suggest that the placement of this dot confounds their results.</p><p>• Comparisons between adjacent bars in the same stack have much higher error than non-adjacent comparisons. We speculate that this is due to a bias towards making part-of-whole comparisons.</p><p>• In aligned bar comparisons, responses vary widely across subjects. In general, our results suggest that people are much better at 50% comparisons than other ratios, that multiples of 5 and 10 are more common responses than simple fractions, and that increased response time correlates weakly with higher accuracy.</p><p>The next section summarizes the previous work on the graphical perception of bar charts. This is followed by a description and discussion of the four experiments we conducted. Finally, we draw conclusion from the studies and outline future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK</head><p>The <ref type="bibr">Cleveland &amp;</ref> McGill study that forms the basis for this paper is described in the following section. Then we discuss two other pieces of closely related work-an approximate replication of the original study done by Heer &amp; Bostock <ref type="bibr" target="#b5">[6]</ref> and a paper by Zacks et al. <ref type="bibr" target="#b11">[12]</ref>, which evaluates the same task on somewhat different bar chart stimuli, including 3D charts. Finally, we discuss selected related work in graphical perception.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Cleveland &amp; McGill</head><p>Cleveland &amp; McGill's bar chart experiment studied how well participants could estimate the ratio of the lengths of two bars <ref type="bibr" target="#b0">[1]</ref>. Participants were shown bar charts in five different configurations ( <ref type="figure" target="#fig_1">Figure 1</ref>) and were asked to estimate the height of the shorter marked bar as a percent of the height of the taller marked bar (the "reference bar"). The first two conditions test comparisons of adjacent and separated bars in simple bar charts. The third and fourth conditions test aligned and unaligned comparisons in stacked bar charts. The fifth condition tests comparisons across divisions in a single stacked bar.</p><p>Fifty-five subjects were shown 10 variants of each of the five chart types. The 10 variants were made using 7 distinct true percents, 3 of which were used twice with different absolute heights-17.8%, 26.1%, 38.3%, 46.4% (twice), 56.2%, 68.2% (twice), and 82.5% (twice). Cleveland &amp; McGill's description of the design does not specify the absolute heights of the judged bars. The heights of the distractor bars (those not marked for comparison) were chosen at random.</p><p>Fifty-one of the subjects provided usable results. For each chart type, Cleveland &amp; McGill computed the average log absolute error (the difference between a participant's response and the true percent). This measure was used to rank the chart types, from Type 1 (lowest error) through Type 5 (highest error), as shown in <ref type="figure" target="#fig_1">Figure 1</ref>. For all chart types, they found that the average log absolute error was highest for true percents around 60%-80% and fell off for lower and higher percents.</p><p>Cleveland &amp; McGill noted that the three designs (Adjacent Bars, Separated Bars, and Aligned Stacked Bars) in which the compared bars are aligned along a common baseline scored substantially better than the two designs (Unaligned Stacked Bars and Divided Bar) where the comparisons were unaligned. They hypothesized that this difference results from the use of two different visual estimation strategiesfor aligned bars, viewers make visual comparisons of positions, while for unaligned bars, viewers must make less accurate visual comparisons of lengths. In a later paper, <ref type="bibr">Cleveland and McGill [2]</ref> looked at the same estimation task on much simpler stimuli consisting of just points and lines, rather than complete bar charts. In these somewhat more artificial conditions, they confirmed that position judgments were more accurate than length judgments.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Heer &amp; Bostock</head><p>Recently, Heer &amp; Bostock <ref type="bibr" target="#b5">[6]</ref> performed an approximate replication of the first Cleveland &amp; McGill study while examining the crowdsourcing of perceptual experiments. Their experimental design was similar to the original experiment, but they used Amazon Mechanical Turk (https://www.mturk.com) participants and they studied a somewhat different set of true percents (18%, 22%, 26%, 32%, 39%, 47%, 55%, 56%, 69%, and 85%). In addition to bar charts, they also evaluated pie charts, bubble charts, and tree maps. They confirmed the relative rankings of the same 5 comparison tasks, but their absolute accuracy results are somewhat better than in the original study. While some of this difference may be due to the populations studied, the study design may also contribute. Cleveland &amp; McGill's true percents were rounded to tenths, but Heer &amp; Bostock's were whole numbers. If we make the plausible assumption that participants in both studies largely responded with whole numbers, then Heer &amp; Bostock's results would appear to have lower error. This difference might appear to be small, but both studies use a log-transformed error metric which exaggerates small differences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Zacks et al.</head><p>In separate work focused on understanding the effect of 3D perspective bars on graphical perception, Zacks et al. ran a similar experiment which focused on percent estimation between pairs of axis-aligned bars without extraneous distractor bars <ref type="bibr" target="#b11">[12]</ref>. They tested 15 different true percents (1%, 8%, 15%, 22%, 29%, 36%, 43%, 50%, 57%, 64%, 71%, 78%, 85%, 92%, and 99%), which provides much broader coverage of the percent space than the previous two studies. Since they were trying to understand 3D bar perception, their work focused on varying the presentation of the bars, rather than on the configuration of the bar chart as a whole. Their stimuli included simple lines, rectangles, 3D bars, and somewhat abstract geometric shapes.</p><p>In contrast to Cleveland &amp; McGill's finding that the error function has a maximum around 60%-80%, Zacks et al. found that the error function is symmetric around 50% with a local minimum at 50%.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Other graphical perception work on bar charts</head><p>Simkin and Hastie develop an explanatory model of visual comparisons in bar charts <ref type="bibr" target="#b9">[10]</ref>. In their model, proportion judgments begin with anchoring, in which the two bar charts are jointly segmented to allow for comparison, followed by a scanning step which gives the final estimate. They provide some experimental results supporting their model. Elzer et al. present a mental processing model for bar chart reading <ref type="bibr" target="#b4">[5]</ref>. Their preliminary eye tracking studies show that comparison of non-adjacent bars requires more saccades than comparison of adjacent bars. Newman and Scholl <ref type="bibr" target="#b7">[8]</ref> show that bars representing the means of a sample create a false "within-the-bar bias" that incorrectly suggests that values within the bar are more likely than values outside the bar.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">EXPERIMENTS</head><p>To better understand Cleveland &amp; McGill's results, we ran four experiments to clarify how bar chart design impacts accuracy:</p><p>• Experiment 1 compares the Adjacent and Separated Bars tasks to disentangle the effects of visual separation and intervening distractors on error.</p><p>• Experiment 2 compares the Aligned and Unaligned Stacked Bars tasks to isolate the effects of unaligned comparison, distractors, and dot position.</p><p>• Experiment 3 compares variants of the Divided Bar task to understand why comparisons of bars in the same stack are more difficult than in different stacks. We use a consistent analysis procedure across all four experiments. First, to deal with outliers, we use the same robust aggregation procedure as in Cleveland &amp; McGill and Heer &amp; Bostock. We compute 25% trimmed means (the "midmeans") for each experimental condition and then average across them to get marginal and grand means. Since trimmed means discard outliers, our estimates should be interpreted as the mean of "typical" responses, not of the entire distribution. The choice of 25% trimming was made a priori to match the previous work. We also ran our analysis with a more conservative trim of 15% and verified that our results are robust to this choice.</p><p>Second, rather than rely on null hypothesis significance testing, which has been challenged on numerous grounds <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b6">7]</ref>, we instead report estimates of simple effect sizes and associated confidence intervals (CIs) computed via bootstrapping <ref type="bibr" target="#b3">[4]</ref>. This method of analysis has been advanced in psychology <ref type="bibr" target="#b2">[3]</ref> to address the shortcomings of significance testing and we adopt it here for similar reasons.</p><p>By reporting effect size-the change in an outcome of interest, usually response error, across experimental conditions-we can situate our results within the previous work and we can make judgements about the practical significance of the effects we find. By reporting CIs we can communicate the uncertainty in our results. We consistently provide 95% CIs in square brackets after our effect size estimates. CIs that are narrow compared to the estimated effect size imply that we have strong evidence for the size, while those that are wide imply that the size is uncertain. CIs that do not include 0 indicate that we have strong evidence for the sign of the effect and those that include 0 indicate that we have weak or no evidence for the sign.</p><p>One challenge is that, since we use a within subjects design in each experiment, our CIs are necessarily correlated, which means that they cannot be directly compared to each other. To emphasize this limitation, we plot each CI in its own frame. When we want to compare two values, we directly estimate the difference between them.  <ref type="figure" target="#fig_1">(Figure 1b</ref>) was higher than between Adjacent Bars <ref type="figure" target="#fig_1">(Figure 1a</ref>) by roughly 0.6-1 percentage points <ref type="bibr" target="#b0">1</ref> . In this experiment, our goal is to better understand this Separation Effect. In particular, we are interested in three questions: The bar chart variants studied in Experiment 1 are shown in <ref type="figure" target="#fig_4">Figure 2</ref>.</p><p>To address our first two questions, we include factors for separation and distractors. In the top row, we show adjacent and separated bar comparisons without distractors. In this case, any increased difficulty in making the right comparison can only arise from the increased distance between the bars (195 pixels). In the second row, we introduce short distractors, which are shorter than almost all the compared bars. While these distractors add to the visual clutter of the plot, they do not interfere with visually comparing the tops of the two bars. Any increased difficulty here will result from a combination of the effects of separation and the intervening distractor bars. In the bottom row, we add tall distractors. These distractors visually interfere with making a comparison between the tops of the two marked bars. Again, any increased difficulty here will arise from a combination of separation and the distractors. The heights of the distractor bars are fixed to avoid possible confounding.</p><p>To address our third question, we also include three conditions for the height of the reference bar-125, 250, and 375 pixels-and tested all other factors at all three heights. In the original study, the reference bar height depended on the true percent. If reference bar height has a strong effect on accuracy, this dependence on the true percent may confound the results. We revisit this potential issue with the Cleveland &amp; McGill study in Experiment 4.</p><p>Since Cleveland &amp; McGill found a clear effect of true percent in some of their tasks, we use the same 7 true percents (17.8%, 26.1%, 38.3%, 46.4%, 56.2%, 68.2%, and 82.5%) to ensure that our results are comparable. In our analysis, we average over this factor since we are interested in the overall accuracy. In Experiment 4, we explore the effect of true percent in detail.</p><p>These choices of factors result in a total of 126 conditions (2 separations × 3 distractor variants × 3 reference bar heights × 7 true percents). We used a within subjects design where all subjects saw all 126 conditions.</p><p>In contrast to the Cleveland &amp; McGill design, we did not randomize whether the reference comparison bar appeared on the left or right. In Zacks et al., they found a small effect for the side of the reference bar, which they hypothesized may be due to reading order in their population. To avoid possible confounding due to this effect, we fixed the reference bar to be on the left side. The Cleveland &amp; McGill design <ref type="bibr" target="#b0">1</ref> Reanalysis of Heer &amp; Bostock's data <ref type="bibr" target="#b5">[6]</ref> gives an estimate of 0.6 percentage points. We do not have access to <ref type="bibr">Cleveland</ref>  also included small letters beneath the x-axis, labeling the two bar groups. Since these letters were not essential to the task we omitted them.</p><p>Fifty Amazon Mechanical Turk users were recruited to participate in this study. Only users with a 95% or higher Human Intelligence Task (HIT) acceptance rating were allowed to participate. The study requirements indicated that users should be between 18 and 65 years old, and would need to be comfortable with English instructions and with using an online interface to perform relative judgments. Participants were first shown an instruction page that specified the task-to make a quick visual judgement of what percent the smaller marked bar is of the larger one. They were instructed that answers should range between 0% and 100%, and that comparisons should be made unaided by fingers, rulers, or other external tools. They were told to target an average of about 7-9 seconds per response. Three example plots were provided with the corresponding true percents-70%, 59%, and 23.2%. Examples with various amounts of rounding were selected to suggest to participants that they could use as much precision as they desired. After choosing to participate in the study on the Amazon Turk site, we redirected participants to our own website where we could measure response time, and ensure that a single user completed all 126 tasks. In contrast, Amazon Turk's default website allows multiple users to collaborate in completing a replication making within subject designs difficult. Participants were paid $0.02 per comparison, or $8 an hour at 9 seconds per response. The HIT, once accepted by a participant, was set to expire in 60 minutes.</p><p>We validated that subjects understood the task by looking at the correlation between subject responses and the true values. In our first run of 50 subjects, 46 had correlations higher than 0.8, while 4 had correlations ranging from -0.4 to 0.5. We considered these extremely low correlations strong evidence that these four subjects did not understand the task. We rejected their responses and recruited four additional subjects. The replacement subjects all had correlations greater than 0.8. Contribution to Separation Effect <ref type="figure">Fig. 4</ref>: Estimates of the contributions of separation and distractors to the Separation Effect. Separation between the comparison bars makes the percentage estimation task more difficult. The impact of distractors, whether short or tall, is estimated to be smaller; however, our CIs are relatively wide.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.2">Results</head><p>In <ref type="figure" target="#fig_5">Figure 3</ref>, we show the total Separation Effect, including the increased difficulty due to both distractors and the separation between the comparison bars. We confirm that comparison of separated bars is more difficult than comparison of adjacent bars. Our first experimental question asks whether this increased difficulty arises from the separation between the bars or from the presence of intervening distractor bars. In <ref type="figure">Figure 4</ref>, we estimate how much each contributes individually to the total effect. The contribution of separation is estimated by looking at the separation-only variants shown in the top row of <ref type="figure" target="#fig_1">Figure 1</ref>. These conditions have no distractors, so any difference in error must come from the increased separation between the bars. Our estimate of this error is 0.70 [0.46, 0.99] percentage points. The contributions of the short and tall distractors are computed using a difference-in-difference approach. Comparing the conditions in the second or third rows of <ref type="figure" target="#fig_1">Figure 1</ref> will result in an estimate that includes the impact of both distractors and separation. To get the impact of distractors alone, we subtract out the separation estimate from the first row. The effect of short distractors is estimated to be very small, 0.07 [-0.30, 0.43], but with a wide CI. The estimated effect of the tall distractors is larger, 0.28 [-0.04, 0.58]. Pairwise comparison of the effect of separation with the effects of distractors indicates that it has a larger impact than short distractors by 0.72 [0.18, 1.29] percentage points and a larger impact than tall distractors by 0.33 [-0.12, 0.83] percentage points, though the CI covers 0 so the evidence is weaker.</p><p>Our second question asks how distractors impact the Separation Effect; in particular, do tall distractors add more difficulty than short distractors? Pairwise comparison of the effect of short and tall distractors indicates that tall distractors add 0.10 [-0.29, 0.45] percentage points of error over short distractors. Given the small estimate and the breadth of the CI, there is little evidence that tall distractors make separated comparisons more difficult than short distractors.</p><p>Our third question is about the effect of the reference bar height. In <ref type="figure">Figure 5</ref> we show estimates of the Separation Effect conditioned on the height of the reference bar. Regardless of the height, separated bar comparisons are more difficult than adjacent bar comparisons. However, for short reference bars (125 pixels), our estimate of the effect is much larger. Pairwise comparison of these three conditional effects confirms that comparison against a short bar is substantially more difficult than comparison against a medium bar, adding 0.74 [0.22, 1.29] We also looked for interactions between the reference heights and the heights of the distractors; but we did not find any clear patterns in our data. Finally, while our data does not clearly show whether distractors differentially increase the difficulty of separated bar comparisons over adjacent comparisons, post hoc analysis of our data does show that tall distractors increase the difficulty of both comparison tasks. <ref type="figure">Figure 6</ref> shows estimates of the effect of distractors averaged across both adjacent and separated bar comparisons. In the top row, we see that Discussion Our results from Experiment 1 show that separating bars in space makes comparison of their heights more difficult. In contrast, the effect of distractors was more ambiguous. While our point estimates were consistent with distractors not substantially increasing the difficulty of separated comparisons, our CIs were relatively wide. We conclude that the Separation Effect results from either the separation between the bars alone, or from some combination of separation and distractors. Since we did not find a clear difference between short and tall distractors, we cannot determine whether distractors increase error by adding visual clutter or by interfering with the visual task.</p><p>Our results also show that comparisons against small reference bars are particularly difficult when separated. A clearer understanding of this interaction between separation and height may give insight into the visual mechanism by which these comparisons are being made. An obvious follow-up experiment would vary the reference bar heights and the separation distance more finely than we did here. Also, given the impact of distance, particularly for small reference bars, interaction techniques that bring distant bars closer together, such as sorting, drawing reference lines, or windowing <ref type="bibr" target="#b10">[11]</ref> are likely to improve the readability of bar charts. We found in post hoc analysis of our data that short distractors do not increase the difficulty of adjacent or separated bar comparisons. This suggests that subjects are relatively robust to at least some kinds of visual noise. However, we did find that tall distractors increased the difficulty of both adjacent and separated bar comparisons. That this effect occurred for both comparisons suggests that the increased difficulty is not due to visual interference when comparing the tops of the bars. However, more study will be necessary to determine the mechanism by which tall distractors interrupt the height comparison task and to understand if visual changes such as highlighting the comparison bars can effectively decrease the impact of tall distractors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Experiment 2: Aligned Bars vs. Unaligned Bars</head><p>Our second experiment explores the difference between comparisons of Aligned and Unaligned Bars in stacked charts <ref type="figure" target="#fig_1">(Figures 1c and 1d)</ref>. Cleveland &amp; McGill found that it is substantially harder to make height comparisons between unaligned bars than between bars aligned to a common baseline. They hypothesize that this is due to position comparison being a fundamentally easier visual task than length comparison. <ref type="bibr">The</ref>  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Does the location of the marking dot make unaligned bar comparisons more difficult? In simple bar charts, Cleveland &amp;</head><p>McGill mark their bars with a dot at the bottom, but in stacked bar charts, they mark the bars in the middle. Placing the dot in the middle provides a convenient 50% reference point, which may be more useful when the bars are aligned than when they are unaligned. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Does the height of the reference bar impact the Unalignment Effect?</head><p>In Experiment 1, we found that the height of the reference bar substantially impacted the accuracy of responses for separated comparisons in simple bar charts. Does this effect also occur for length comparisons in stacked bar charts?</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1">Method</head><p>Some of the bar chart variants considered in Experiment 2 are shown in <ref type="figure" target="#fig_8">Figure 7</ref>. In the first row, we compare aligned and unaligned bars. In the second row, we vary the presence of distractors. With stacked bars it is difficult to simultaneously control the heights of all the bars, so we randomly generate the distractor heights. We randomly vary the overall heights of the stacks to ensure that the unaligned bars do not align at the top of the chart. In the third row, we also vary the position of the mark, either at the bottom, as in Cleveland &amp; McGill's simple bar charts, or in the middle of the bar, as in their stacked charts. We use the same 3 reference heights and 7 true percents as in the previous experiment. This results in 168 conditions (2 alignments × 2 distractors × 2 mark positions × 3 reference bar heights × 7 true percentages). We again used a within subjects design with 50 Mechanical Turk users. The criteria for participation and the experimental set up were the same as in the previous experiment. We evaluated the subjects' task understanding by again looking at the correlation between their responses and the true values. In this experiment, all 50 subjects had correlations higher than 0.8 and all were accepted.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2">Results</head><p>Our estimate of the Unalignment Effect is 1.16 [0.80, 1.61] percentage points <ref type="figure">(Figure 8</ref>). To be comparable to the previous work, this estimate only includes our conditions with distractors and with the marking dot in the middle of the bar. Our estimate is marginally lower than Heer &amp; Bostock's estimate of 1.2. We can confirm that unaligned bar comparisons are more difficult than aligned comparisons in stacked bar charts.</p><p>In <ref type="figure">Figure 9</ref>, we plot the impact of unalignment, distractors, and placing the marking dot in the middle of the bar, rather than at the bottom, on the Unalignment Effect. Making an unaligned bar comparison has a clear strong effect, increasing error over aligned bar comparisons by an estimated 0.84 [0.59, 1.1] percentage points. As in the first experiment, we use a difference-in-difference approach to examine the effect of distractors and dot position. In contrast to the first experiment, distractors have a larger and more robust contribution to the Unaligned Effect, adding an estimated 0. While the marking dot position does not have a clear impact the Unalignment Effect, we did find in post hoc analysis that placing the dot in the middle of the bar makes both aligned and unaligned comparisons easier <ref type="figure" target="#fig_1">(Figure 10</ref> means that stacked distractors disproportionately impact length comparisons. We speculate that one possible reason for this effect is that stacked distractors change visually salient bar corners into less visually salient T-junctions, which may make length estimation more difficult, but more study is clearly needed. A possible implication of this result is that if visualization users must make unaligned bar comparisons in a stacked bar charts, interactive visual techniques such as highlighting, which help the user visually separate the bars of interest from the surrounding distractors should help users make more accurate comparisons.</p><p>In post hoc analysis we found evidence that the positioning of the marking dot likely does have an effect on the difficulty of the task. This means that Cleveland &amp; McGill's results for simple bar charts (with a dot at the bottom of the bar) are not directly comparable with their results for stacked bar charts (which have dots in the middle of the bar). We estimate this effect to be about a fifth of a percentage point, which, while small, is potentially enough to impact Cleveland &amp; McGill's ranking of bar chart types. If all chart types used a marking dot at the botton, this would increase the error of all the stacked bar variants, potentially swapping the ranking of Aligned Stacked Bar comparisons ( <ref type="figure" target="#fig_1">Figure 1c)</ref> and Separated Bar comparisons <ref type="figure" target="#fig_1">(Figure 1b</ref>). Since this effect was identified in post hoc analysis, a follow up study reevaluating the rank order of Cleveland &amp; McGill's chart types with a consistent dot position or other visual mark (e.g. highlighting) is needed.</p><p>If marking the middle of the bar results in higher accuracy, this suggests an interesting interactive tool for bar charts. When visually highlighting a bar, a visualization system might automatically add subtle lines or tick marks to the bar itself at common ratios (e.g. 25%, 50%, and 75%) to aid in comparisons with that bar.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Experiment 3: Divided Bars</head><p>This experiment explores relative height comparisons in Divided Bar scenarios <ref type="figure" target="#fig_1">(Figure 1e</ref> As in the previous experiments, we control the height of the reference bar. However, since the compared bars have to be stacked on each other while still fitting within the vertical limit of the chart, we cannot use a height of 375 pixels. We instead use the heights 62.5, 125, and 250 pixels. We continue to use the same set of 7 true percents. This leads to a total of 126 conditions (2 distractors × 3 intervening bars × 3 reference bar heights × 7 true percents) which we ran with a within subjects design on 50 Mechanical Turk users. The qualifications and instructions remained the same as in the previous studies.</p><p>We again validated user understanding of the tasks by looking at the correlation of their responses with the true values. The correlations of 49 of the subjects were at least 0.71. One outlying subject had a correlation of 0.44; their responses were rejected and rerun.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.2">Results</head><p>Our estimate for the absolute error of divided bar comparisons is 7.38 <ref type="bibr">[6.65, 8.23</ref>] percentage points, which is higher than the estimates reported by Heer &amp; Bostock (4.7) and by <ref type="bibr">Cleveland &amp; McGill (6.6)</ref>.</p><p>In <ref type="figure" target="#fig_1">Figure 12</ref> we show estimates for the marginal effects of distractors and separation on divided bar comparisons. Distractors add roughly 0.37 [0.05, 0.66] percentage points of additional error. This is similar to our estimate of the effect of distractors on unaligned comparisons in the previous experiment. Our estimates for the impact of separation are, perhaps surprisingly, negative, which means that subjects did better when comparing separated bars than when comparing  True percent Bias (percentage points) Discussion While Cleveland &amp; McGill found that comparison of bars in the same stack is substantially more difficult than other stacked bar configurations, our results suggest that this may only be true when the compared bars are immediately adjacent to each other. An intervening bar or gap reduces the average absolute error. The observed effect size in our data (0.87 percentage points) falls between the previous estimates of the difference between unaligned comparisons <ref type="figure" target="#fig_1">(Figure 1d)</ref> and divided bar comparisons <ref type="figure" target="#fig_1">(Figure 1e)</ref>.</p><p>A clue to the source of the higher error of adjacent comparisons can be found in Cleveland &amp; McGill's analysis of the bias (subject response − true percentage) in these types of comparisons. They found that, unlike the other chart types studied, divided bar comparisons had a large negative bias for middle true percents. This bias also replicated in our results for adjacent bars, but was substantially attenuated for non-adjacent ones <ref type="figure" target="#fig_1">(Figure 13</ref>). One possible explanation for this bias is that subjects are influenced by the part-to-whole comparison. For example, if we show two bars of size 60 and 30 units respectively, then the correct response to the height ratio task is 30/60 = 50%. However, if the bars are adjacent, subjects may instead respond closer to the part-to-whole ratio 30/(30 + 60) = 33%.</p><p>If this explanation is correct, an interesting research question is how this bias is affected by the size of the gap between the bars, or if there are other visual differences (e.g. color) which help reduce its impact. One possible design implication is that height comparisons in a stacked bar chart can be aided by the interactive introduction of gaps between adjacent bars to reduce this bias.</p><p>As in the previous experiment, the presence of distractors increases the difficulty of the divided bar task. Again, this may be related to how people make visual length comparisons. But a comparison of the distractor effect sizes found in Experiment 2 and in this experiment doesn't suggest that distractors make divided bar comparisons disproportionately harder than other unaligned stacked bar comparisons. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Experiment 4: Effects of True Percent and Rounding</head><p>Like the Cleveland &amp; McGill study, our first three experiments were largely focused on understanding how bar chart design factors influence performance on the height ratio estimation task. In this final experiment, we focus on better understanding the height estimation task itself. We are interested in two questions:  <ref type="figure" target="#fig_1">Figure 14)</ref>. This design is also very similar to that used by Zacks et al. Since only two bars are shown, we omitted the marking dots. This allows us to make very short bars without having to reserve room to place a dot inside. The only controlled factor in this experiment is the true percent. We used all integer true percents from 1 to 100, for a total of 100 tasks (we omitted 0 since we felt that this case would likely be confusing for our participants). We randomly varied the height of the reference bar between 350-400 pixels. This variation discourages users from forming a fixed mental scale that could be reused from task to task. However, we kept the range of height variation relatively small to avoid possible confounding from the reference height effect seen in the previous experiments. The left bar was always taller. We used a within subjects design on 50 Mechanical Turk users. The study qualifications and instructions were similar to those in the previous experiments. One subject did not finish the study and their partial responses were rejected and rerun. We validated understanding by looking at correlation between subject responses and the true values. All 50 subjects had correlations higher than 0.86; so were accepted.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.2">Results</head><p>We first examine the results of Experiment 4 by true percent. In the top plot in <ref type="figure" target="#fig_1">Figure 15</ref> we show our estimate of the absolute error as a function of true percent in blue with the pointwise 95% confidence interval in gray. Our error function has minimums near 0% (which we did not test), 50%, and 100%. The error function is roughly symmetric around 50%. For context, we also plot the results of Cleveland &amp; McGill (orange) and of Heer &amp; Bostock (teal), which are only approximate since we had to convert from their reported log absolute errors to absolute errors, and the results of <ref type="bibr">Zacks et al. (brown)</ref>. Our results are clearly most similar to those of Zacks et al. The middle plot shows the raw error as a function of the true percent. There is some evidence of overestimating for small true percents and underestimating for large true percents. The bottom plot shows response time, which is similar in shape to the absolute error.</p><p>We next look at the results of Experiment 4 by participant. <ref type="figure">In Figure</ref> 16, each panel shows the histogram of responses of the 10 most accurate participants (numbered 1-10) and the 10 least accurate participants (numbered 41-50), as measured by their average absolute error. Orange indicates responses that overestimated the true percent by more than 2.5 percentage points, blue indicates responses that underestimated the true percent by more than 2.5 percentage points, and gray indicates "close" responses. If a participant always rounded to the nearest multiple of 5, their plot should be entirely gray. This plot reveals a considerable diversity in participant strategies. At a high level, participants can be split into those who provided "rounded" responses (e.g. participants 2 and 45) and those who provided more precise responses (e.g. participants 1 and 42). However, perhaps counterintuitively, rounding is not clearly associated with overall lower accuracy. As can be seen from the prevalence of orange and blue in the lower half, the between subject performance difference is largely caused by errors much larger than the amount of rounding that occurred.</p><p>In <ref type="figure" target="#fig_1">Figure 17</ref>, we plot the trimmed mean absolute error for each participant against their trimmed mean response time. As might be expected, the data suggests that increasing time spent on the task did lead to improved performance. However, there are a number of outliers from this trend. Also, some subjects achieved the same accuracy as others while spending less than half the time per response.</p><p>Discussion Our absolute error results are quite similar to those of Zacks et al., but very different from the two other studies. The other studies included distractors, which may confound comparing results. However, a possible explanation for the discrepancy is the fact that both this experiment and that of <ref type="bibr">Zacks</ref>  The minimum in the absolute error function at 50% is very prominent and was previously noted in <ref type="bibr">Zacks</ref>   , where they hypothesized that it resulted from rounding on the part of participants. To explore this, in <ref type="figure" target="#fig_1">Figure 18</ref> we plot the most common participant responses in Experiment 4. Participants responded 50% nearly 5 times as often as expected in this study, indicating a strong rounding bias towards this value. However, participants responded 80% more frequently and 20% nearly as often, yet our data in <ref type="figure" target="#fig_1">Figure 15</ref> do not show any evidence of a minimum at either point. Thus, while there is substantial rounding in our data, the minimum at 50% appears to be caused not by rounding, but by subjects actually being more accurate there. <ref type="figure" target="#fig_1">Figure 18</ref> also provides insight about the common estimation strategies in use. The most common responses are multiples of 10, followed by multiples of 5. This suggests that many participants are mentally dividing the reference bar into tenths followed by twentieths if necessary. Simple fractions, such as quarters (25% and 75%) and thirds (33% and 66%), do appear on this list, but less frequently than tenths.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">CONCLUSION</head><p>The experiments in this paper explore variations of the bar charts originally studied by Cleveland &amp; McGill and lead to insight into the sources of bar chart interpretation error. We found that short bars are more difficult to compare. Distractors have different effects in simple bar charts and stacked bar charts. The way bars are marked can influence accuracy. The introduction of a gap between stacked bars can prevent erroneous part-of-whole comparisons when desired. These results highlight the fact that small design changes can significantly affect how bar charts are perceived, and that even for simple visualizations, such as bar charts, we still do not have a complete understanding of what impacts chart perception.</p><p>Our experiments also raise new questions that will need to be addressed with additional studies. Future experiments will help understand the perceptual and mental strategies used in making bar height comparisons. Study designs that gather richer quantitative data, such mouse or eye movements, or more qualitative data, such as participant introspection on strategy, might provider deeper insight. Future directions might include exploring the effect of distractors in sorted bar charts, the impact of bar heights in constrained displays, and the effect of common interactions on bar charts, such as proportional brushing.</p><p>Predicting how people will perform on more complicated bar chart designs or how well people interpret bar charts "in the wild" remains difficult. However, we believe that concrete, experimentally-supported progress in understanding basic graphical perception effects is the most promising avenue towards improving visualization practice and towards a high-level theory of visualization.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>For</head><label></label><figDesc>information on obtaining reprints of this article, please send e-mail to: tvcg@computer.org. Manuscript received 31 Mar. 2014; accepted 1 Aug. 2014 ate of publication 2014; date of current version 2014. 11 Aug. 9 Nov. D . Digital Object Identifier 10.1109/TVCG.2014.2346320</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 1 :</head><label>1</label><figDesc>The five bar chart tasks studied in Cleveland &amp; McGill [1]. Study participants were asked to estimate the height of the shorter marked bar as a percent of the taller marked bar. Cleveland &amp; McGill's ranked these tasks from lowest error (Type 1) to highest error (Type 5).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>•</head><label></label><figDesc>Experiment 4 examines the discrepancy between Cleveland &amp; McGill's and Zacks et al.'s error funtions and explores how participants make estimates.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>3. 1 Experiment 1 :</head><label>11</label><figDesc>Adjacent Bars vs. Separated Bars Both Cleveland &amp; McGill and Heer &amp; Bostock found that the absolute error (|subject response − true percent|) for comparisons between Separated Bars</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 2 :</head><label>2</label><figDesc>&amp; McGill's original data, but rough approximation based on Figure 16 in their first paper [1] suggests an estimate of around 1 percentage point. (Cleveland &amp; McGill report the mean log absolute error, which we can only approximately invert to get the mean absolute error.) Bar chart variants used in Experiment 1, which contrasts adjacent bar comparisons (left) with separated bar comparisons (right). To tease apart the effects of separation and distractors we include three distractor conditions: (top) no distractors, to evaluate the impact of separation alone, (middle) short distractors, which add visual clutter, and (bottom) tall distractors, which may visually interfere with the comparison task.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 3 :</head><label>3</label><figDesc>Estimate of the total Separation Effect from Experiment 1, including the effect of both separation and distractors. The point estimate, 0.81, is in line with estimates from previous work.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 5 :Fig. 6 :</head><label>56</label><figDesc>Estimates of the Separation Effect conditioned on the height of the reference bar. Regardless of the height, separated bar comparisons are more difficult than adjacent comparisons. However, for short reference bars (125 pixels), our estimate of the effect is much larger. From post hoc analysis, estimates of the effect of distractors averaged over both adjacent and separated bar tasks. The top row shows that short distractors are estimated to have little impact compared to no distractors. In contrast, tall distractors substantially increase the error over no distractors and short distractors.percentage points of additional error, or against a tall bar, adding 0.88 [0.41, 1.4] points. Pairwise comparison provides only weak evidence that comparison against a medium bar is harder than against a tall bar, adding 0.24 [-0.25, 0.68] percentage points of error.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head></head><label></label><figDesc>short distractors have no clear impact over no distractors, 0 [-0.17, 0.19]. But in the bottom two rows we see that tall distractors increase the error over both no distractors (0.42 [0.23, 0.64] percentage points) and short distractors (0.37 [0.15, 0.59] percentage points).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 7 :</head><label>7</label><figDesc>Factors studied in Experiment 2. The top pair contrasts aligned and unaligned bar comparisons. The second pair contrasts comparisons with and without distractors. The bottom pair contrasts placing the marking dot at the bottom or in the middle of the bar.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig. 8 :Fig. 9 :</head><label>89</label><figDesc>The estimate of the Unalignment Effect and corresponding CI from Experiment 2. The point estimate of 1.15 is marginally smaller than estimates in previous work. Estimates of the contribution of unalignment, distractors, and placing the marking dot in the middle of the bar to the Unalignment Effect. Both unalignment itself and the distractors in a stacked bar arrangement make unaligned bar comparisons difficult.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head></head><label></label><figDesc>), decreasing absolute error by 0.18 [0.04, 0.33] percentage points. Discussion In contrast to the simple bar charts of Experiment 1, in stacked bar charts, distractors have a clear effect on error in unaligned bar comparisons. If Cleveland &amp; McGill are right that aligned bar comparisons are made based on position and unaligned bar comparisons are made based on length, this</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Fig. 11 :</head><label>11</label><figDesc>). Cleveland &amp; McGill find that this arrangement has the highest error of all the comparison types they considered-they estimate an overall absolute error of roughly 6.6 percentage points, while Heer &amp; Bostock's estimate is around 4.7 percentage points. This is 0.6 (Heer &amp; Bostock) or 1.4 (Cleveland &amp; McGill) percentage points harder than making unaligned comparisons across different stacks. Bar chart variants used in Experiment 3, without distractors on the left and with distractors on the right. In the top row the comparison bars are adjacent as in the the Cleveland &amp; McGill design. In the middle row, the comparison bars are separated by a single bar. And, in the bottom row, they are separated by 2 bars. Cleveland &amp; McGill do not suggest a perceptual reason for this high error. In this experiment, we explore the question: What contributes to the high error of Divided Bar comparisons? 3.3.1 Method The divided bar variants studied in this experiment are shown in Figure 11. We include conditions with and without distractors to see if they negatively impact divided bar comparisons. Also, since separation had a substantial effect in Experiment 1, we include a condition where the comparison bars are adjacent as in Cleveland &amp; McGill's experiment, and conditions where the comparison bars are separated by 1 or 2 intervening bars.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Fig. 12 :</head><label>12</label><figDesc>Estimates of the marginal effects of distractors (compared to no distractors) and separation (compared to adjacent) when making divided bar comparisons. As in Experiment 2, stacked distractors clearly increase the error when making length comparisons. Somewhat surprisingly, separating the compared bars actually decreases the error.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Fig. 13 :</head><label>13</label><figDesc>Bias in Experiment 3 conditioned on separation and the true percent. The bias is large when the compared bars are vertically adjacent, but when they are separated, the bias is considerably reduced. adjacent bars. The effect of one bar of separation is to make divided bar comparisons 0.87 [0.47, 1.3] percentage points easier.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>Fig. 14 :</head><label>14</label><figDesc>Two examples of the bar chart design used in Experiment 4. The layout is similar to Cleveland &amp; McGill's aligned stacked bar charts, but without distractors or dots marking the bars. The height of the reference bar (the taller bar) was varied slightly between tasks.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head>Fig. 15 :</head><label>15</label><figDesc>(Top) Absolute error as a function of the true percent (blue, with confidence interval) compared to results from the previous work-Cleveland &amp; McGill (orange), Heer &amp; Bostock (teal), and Zacks et al. (brown). (Middle) Raw error, showing that small true percents are overestimated. (Bottom) Response time by true percent.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_16"><head>Fig. 16 :</head><label>16</label><figDesc>Histograms of the responses for the ten most accurate (top) and ten least accurate (bottom) participants in Experiment 4. Blue indicates underestimates by at least 2.5 percentage points, orange indicates overestimates by at least 2.5 percentage points. Note the strong evidence of rounding by many, but not all participants. However, rounding is not directly predictive of overall rank.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_17"><head></head><label></label><figDesc>et al. explicitly control for the height of the reference bar. In contrast, Cleveland &amp; McGill and Heer &amp; Bostock chose the height of the reference bar conditioned on the true percent. Given the strong effect of height seen in the previous experiments, it is plausible that the asymmetric error function found by Cleveland &amp; McGill and Heer &amp; Bostock is due to confounding of reference bar height and the true percent.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_18"><head>Fig. 17 :Fig. 18 :</head><label>1718</label><figDesc>The average absolute error against the average response time for each participant in Experiment 4. While there are some outliers, there is evidence of a downward trend in error for increasing response times as shown by the robust linear fit. The 25 most common user responses in Experiment 4 plotted against their relative frequency. to have been identified by the coarser sampling used in Cleveland &amp; McGill or Heer &amp; Bostock)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>Our estimate of 0.81 [0.59, 1.03] percentage points is between the previous estimates due to Cleveland &amp; McGill and Heer &amp; Bostock.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>Heer &amp; Bostock estimate of this Unalignment Effect is 1.2 percentage points; Cleveland &amp; McGill's estimate is roughly 2.0 percentage points. In this experiment, we want to confirm this result while exploring three questions not considered in the previous work: 1. What is the source of the Unalignment Effect? Does it arise from unalignment only or do distractors also play a role?</figDesc><table /><note>This could happen if, for example, distractors increase the difficulty of length comparisons more than they increase the difficulty of position comparisons.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head></head><label></label><figDesc>50 [0.14, 0.91] additional Dot In Middle Effect Fig. 10: Estimate of the overall effect of placing the marking dot in the middle of the bar, rather than at the bottom. That the estimate is negative indicates that placing the dot in the middle makes bar comparison tasks easier than placing it at the bottom. percentage points of absolute error to unaligned bar comparisons over aligned bar comparisons. But there is little evidence that placing the dot in the middle of the bar disproportionately increases the difficulty of unaligned bar comparisons (estimated 0.12 [-0.19, 0.42]).Unlike in Experiment 1, we found no clear evidence that the reference bar height impacts the Unalignment Effect. We did find some evidence that distractors increase the difficulty of aligned comparisons, but only mildly (estimated 0.2 [-0.01, 0.4] percentage points).</figDesc><table><row><cell></cell><cell></cell><cell>•</cell><cell>Dot Effect</cell></row><row><cell>−0.6</cell><cell>−0.4</cell><cell>−0.2</cell><cell>0.0</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head></head><label></label><figDesc>et al. (the dip is too narrow</figDesc><table><row><cell></cell><cell></cell><cell>•</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>•</cell><cell></cell><cell>•</cell></row><row><cell cols="2">•</cell><cell></cell><cell></cell><cell></cell><cell>•</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell>•</cell><cell cols="2">•</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell>• •</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>•</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell cols="2">• • • •</cell><cell cols="2">•</cell><cell></cell><cell></cell><cell></cell><cell>•</cell><cell></cell><cell></cell><cell></cell></row><row><cell>•</cell><cell>• •</cell><cell>• • • • • • • • •</cell><cell cols="2">• • •</cell><cell>• •</cell><cell>•</cell><cell>• • • • • • •</cell><cell>•</cell><cell>•</cell><cell>•</cell><cell>•</cell><cell>• •</cell><cell>• •</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">•</cell></row></table><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS</head><p>The authors wish to thank Maureen Stone for substantial help in improving the presentation of this paper and the anonymous reviewers for suggesting ways to greatly improve the rigour of our analysis.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Graphical perception: Theory, experimentation, and application to the development of graphical methods</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">S</forename><surname>Cleveland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Mcgill</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Statistical Association</title>
		<imprint>
			<biblScope unit="volume">79</biblScope>
			<biblScope unit="issue">387</biblScope>
			<biblScope unit="page" from="531" to="554" />
			<date type="published" when="1984-09" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">An experiment in graphical perception</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">S</forename><surname>Cleveland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Mcgill</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Man-Machine Studies</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="491" to="500" />
			<date type="published" when="1986-11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">The new statistics: Why and how</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Cumming</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Science</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="7" to="29" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">J</forename><surname>Diciccio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Efron</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bootstrap confidence intervals. Statistical Science</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="189" to="228" />
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">A model of perceptual task effort for bar charts and its role in recognizing intention</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Elzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Green</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Carberry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hoffman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">User Modeling and User-Adapted Interaction</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="30" />
			<date type="published" when="2006-03" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Crowdsourcing graphical perception: Using mechanical turk to assess visualization design</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Heer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bostock</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM Human Factors in Computing Systems (CHI)</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="203" to="212" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Beyond significance testing: Reforming data analysis methods in behavioral research</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">B</forename><surname>Kline</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004" />
			<publisher>APA Books</publisher>
			<pubPlace>Washington, DC</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Bar graphs depicting averages are perceptually misinterpreted: The within-the-bar bias</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Newman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">J</forename><surname>Scholl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychonomic Bulletin &amp; Review</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="6014" to="607" />
			<date type="published" when="2012-08" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Eight common but false objections to the discontinuation of significance testing in the analysis of research data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">L</forename><surname>Schmidt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">E</forename><surname>Hunter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">What if there were no significance tests?</title>
		<editor>L. L. Harlow, S. A. Mulaik, and J. H. Steiger</editor>
		<meeting><address><addrLine>New Jersey, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Lawrence Erlbaum Associates</publisher>
			<date type="published" when="1997" />
			<biblScope unit="page" from="37" to="68" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">An information-processing analysis of graph perception</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Simkin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Hastie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Statistical Association</title>
		<imprint>
			<biblScope unit="volume">82</biblScope>
			<biblScope unit="issue">398</biblScope>
			<biblScope unit="page" from="454" to="465" />
			<date type="published" when="1987" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Interaction support for visual comparison inspired by natural behavior</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Tominski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Forsell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Johansson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2719" to="2728" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Reading bar graphs: Effects of extraneous depth cues and graphical context</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zacks</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Tversky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">J</forename><surname>Schiano</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: Applied</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">119</biblScope>
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
