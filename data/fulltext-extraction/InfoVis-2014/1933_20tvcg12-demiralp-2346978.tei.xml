<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/pisenberg/grobid/grobid-0.6.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Learning Perceptual Kernels for Visualization Design</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ç</forename><surname>Agatay Demiralp</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Stanford University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">S</forename><surname>Bernstein</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Stanford University</orgName>
							</affiliation>
							<affiliation key="aff0">
								<orgName type="institution">Stanford University</orgName>
							</affiliation>
						</author>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Heer</surname></persName>
							<email>jheer@uw.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">Stanford University</orgName>
							</affiliation>
							<affiliation key="aff0">
								<orgName type="institution">Stanford University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">•</forename><forename type="middle">Ç</forename><surname>Agatay Demiralp</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Stanford University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Learning Perceptual Kernels for Visualization Design</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="DOI">10.1109/TVCG.2014.2346978</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2021-02-19T19:09+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Visualization</term>
					<term>design</term>
					<term>encoding</term>
					<term>perception</term>
					<term>model</term>
					<term>crowdsourcing</term>
					<term>automated visualization</term>
					<term>visual embedding</term>
				</keywords>
			</textClass>
			<abstract>
				<p>Visualization design can benefit from careful consideration of perception, as different assignments of visual encoding variables such as color, shape and size affect how viewers interpret data. In this work, we introduce perceptual kernels: distance matrices derived from aggregate perceptual judgments. Perceptual kernels represent perceptual differences between and within visual variables in a reusable form that is directly applicable to visualization evaluation and automated design. We report results from crowdsourced experiments to estimate kernels for color, shape, size and combinations thereof. We analyze kernels estimated using five different judgment types-including Likert ratings among pairs, ordinal triplet comparisons, and manual spatial arrangement-and compare them to existing perceptual models. We derive recommendations for collecting perceptual similarities, and then demonstrate how the resulting kernels can be applied to automate visualization design decisions.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Visual encoding decisions are central to visualization design. As viewers' interpretation of data may shift across encodings, it is important to understand how choices of visual encoding variables such as color, shape, size -and their combinations -affect graphical perception.</p><p>One way to evaluate these effects is to measure the perceived similarities (or conversely, distances) between visual variables. We broadly refer to subjective measures of judged similarity as perceptual distances. In this context, a perceptual kernel is the distance matrix of aggregated pairwise perceptual distances. These measures quantify the effects of alternative encodings and thereby help create visualizations that better reflect structures in data. <ref type="figure">Figure 1a</ref> shows a perceptual kernel for a set of symbols; distances are visualized using grayscale values, with darker cells indicating higher similarity. The prominent clusters suggest that users will perceive similarities among shapes that may or may not mirror encoded data values.</p><p>Perceptual kernels can also benefit automated visualization design. Typically, automated design methods <ref type="bibr" target="#b26">[27]</ref> leverage an effectiveness ranking of visual encoding variables with respect to data types (nominal, ordinal, quantitative). Once a visual variable is chosen, these methods provide little guidance on how to best pair data values with visual elements, instead relying on default palettes for variables such as color and shape. Perceptual kernels provide a means for computing optimized assignments to visual variables whose perceived differences are congruent with underlying distances among data points. In short, perceptual kernels enable the direct application of empirical perception data within visualization tools.</p><p>In this work, we contribute the results of crowdsourced experiments to estimate perceptual kernels for visual encoding variables of shape, size, color and combinations thereof. There are alternative ways of eliciting judged similarities among visual variables. We compare a variety of judgment types: Likert ratings among pairs, ordinal triplet comparisons, and manual spatial arrangement. We also assess the resulting kernels via comparisons to existing perceptual models. We find that ordinal triplet matching judgments provide the most consistent results, albeit with higher time and money costs than pairwise ratings or spatial arrangement. We then demonstrate how perceptual kernels can be applied to improve visualization design through automatic palette optimization and by providing distances for visual embedding <ref type="bibr" target="#b7">[8]</ref> of data points into visual spaces.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Fig. 1: (Left)</head><p>A crowd-estimated perceptual kernel for a shape palette. The kernel was obtained using ordinal triplet matching. (Right) A two-dimensional projection of the palette shapes obtained via multidimensional scaling of the perceptual kernel.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK</head><p>We draw on prior work in similarity judgments, interactions among perceptual dimensions, graphical perception and automated design.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Analysis of Perceptual Similarity Judgments</head><p>Prior research has analyzed similarity judgments to model perceptual spaces. Measurement methods involve asking subjects to rate or match multiple stimuli. One approach is to ask subjects to rate the perceived similarity of visual stimulus pairs using numbers on a specified numerical scale (such as a Likert scale). However, pairwise scaling can cognitively overload subjects and differences between subjects may confound analysis. These issues led to the use of simpler discrimination tasks involving ordinal judgments. Consider matching judgments over triplets: "Is A more similar to B than it is to C?" Ordinal judgments on triplets have been found more reliable and robust <ref type="bibr" target="#b19">[20]</ref>. However, the number of pairs and triplets increases quadratically and cubically, respectively, with the number of visual stimuli. The method of spatial arrangement, where subjects rearrange stimuli in the plane such that their proximity is proportional to their similarity, was proposed as an efficient alternative <ref type="bibr" target="#b11">[12]</ref>. In our experiments, we use direct judgment types, including Likert ratings among pairs, ordinal triplet rankings, and manual spatial arrangement.</p><p>Similarities may also be indirectly inferred from measurements such as subject response time (confusion time) or manual clustering <ref type="bibr" target="#b11">[12]</ref>. For example, use of response time assumes that the similarity between two stimuli is related to the probability of confusing one with the other. Subjects are asked to quickly decide whether two given stimuli are the same; it is assumed that they take more time if the stimuli are more similar. In a clustering measure, subjects are asked to group given stimuli. It is assumed that the frequency with which two stimuli are placed in the same group is proportional to their similarity. Embedding perceptual measurements in Euclidean space is an active line of research with impacts beyond psychology. Typically, such methods aim to model perceptual distances in terms of Euclidean distances. Torgerson's metric multidimensional scaling (MDS) <ref type="bibr" target="#b44">[45]</ref> maps quantitative judgments onto Euclidean space. However, the use of triplet comparisons requires one to map ordinal judgments. Shepard and Kruskal <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b31">32]</ref> proposed non-metric multidimensional scaling (NMDS) to handle general cases of perceptual measurements. Their formulation requires a complete ranking of all stimulus pairs, prompting more general formulations of NMDS that derive perceptual distances from only a partial set of ordinal judgments <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b46">47]</ref>. These methods allow distances to be inferred from only a subset of all possible comparisons. Tamuz et al. <ref type="bibr" target="#b43">[44]</ref> further propose an adaptive sampling method for more efficient learning of crowdsourced kernels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Dimensional Integrality of Perceptual Dimensions</head><p>Visual variables are often applied in tandem to represent multidimensional data. How does perception of one visual variable change when combined with another? To address this question, researchers have investigated interactions between perceptual dimensions <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b34">35]</ref>. These investigations led Garner and Felfoldy <ref type="bibr" target="#b10">[11]</ref> to introduce a distinction between two types of stimulus dimensions: integral and separable. Visual stimulus dimensions are considered integral if they interfere with or facilitate perception of the other. Dimensions are considered separable if they do not. For integral dimensions, redundant encoding (representing the same data with multiple visual variables) can improve task performance. When the dimensions are fully separable, redundant encoding does not affect task performance. If a task requires selective attention (focusing on one dimension while filtering out the other), integral dimensions can interfere, impairing task performance. Integrality and separability do not form a crisp dichotomy, but rather a continuum with varying degrees of interaction <ref type="bibr" target="#b10">[11]</ref>.</p><p>Integrality can also be measured in terms of the structure of perceptual spaces. Prior research <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b44">45]</ref> provides some evidence that, for integral dimensions, perceptual distances over multiple visual variables form a Euclidean (L 2 ) metric. For separable dimensions, they form a city-block (L 1 ) metric. For example, Attneave <ref type="bibr" target="#b1">[2]</ref> found that the city-block metric better explained his experimental measurements than the Euclidean metric for size and shape and for size and brightness. Torgerson <ref type="bibr" target="#b44">[45]</ref> showed that color value and chroma elicit judgments consistent with a Euclidean metric. We revisit these findings in our analysis of crowd-estimated perceptual kernels.</p><p>The importance of this dichotomy from the perspective of perceptual kernels is that it may give hints about how to build new perceptual kernels for multidimensional visual stimuli by using already-known perceptual distances of individual dimensions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Graphical Perception</head><p>A related area of research is graphical perception <ref type="bibr" target="#b5">[6]</ref>: the decoding of data presented in graphs. How do choices of visual variables such as position, size, shape or color impact visualization effectiveness? Bertin was among the first to systematically study visual variables' "capacities for portraying given types of information" <ref type="bibr" target="#b2">[3]</ref>. Following Bertin, researchers in multiple disciplines have conducted human subjects experiments <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b37">38,</ref><ref type="bibr" target="#b45">46]</ref> and proposed perceptuallymotivated rankings of visual variables for nominal, ordinal or quantitative data <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b35">36]</ref>. Researchers have also investigated how different choices of design parameters such as aspect ratio <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b41">42]</ref>, chart size <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b22">23]</ref>, axis labeling <ref type="bibr" target="#b42">[43]</ref> and animation design <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b28">29]</ref> influence the effectiveness of graphs. This work typically compares the effectiveness of alternative visual variables. In contrast, perceptual kernels enable analysis of visual encoding assignments both within and between specific classes of visual encoding variables.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Automated Visualization Design</head><p>Mackinlay's <ref type="bibr" target="#b26">[27]</ref> Automatic Presentation Tool (APT) is one of the most influential systems for automated visualization design. Mackinlay formulates visualizations as sentences in a graphical language and argues that good visualizations are those that meet his criteria of expressiveness and effectiveness. According to Mackinlay, a visualiza- tion is expressive if it faithfully presents the data, without implying false inferences. A visualization is effective if the chosen visual variables are accurately decoded by viewers. APT employs a composition algebra over a basis set of graphical primitives derived from Bertin's encodings to generate visualizations. The system then selects the visualization that best satisfies formal expressiveness and effectiveness criteria. To operationalize effectiveness, APT uses a rank ordering of visual variables by data type, which is informed by prior studies in graphical perception (e.g., <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b33">34]</ref>).</p><p>APT does not explicitly take user tasks or interaction into account. To this end, Roth et al. <ref type="bibr" target="#b29">[30]</ref> extend Mackinlay's work with new types of interactive presentations. Similarly, Casner <ref type="bibr" target="#b3">[4]</ref> builds on APT by incorporating user tasks to guide visualization generation. Some of these ideas are now used for visualization recommendation within Tableau, a commercial visualization tool <ref type="bibr" target="#b25">[26]</ref>.</p><p>Demiralp et al. <ref type="bibr" target="#b7">[8]</ref> propose visual embedding as a model for visualization construction and evaluation. A visual embedding is a function from data points to a space of visual primitives that measurably preserves structures in the data (domain) within the mapped perceptual space (range). This framework can be used to generate and evaluate visualizations based on both underlying data and -through the choice of preserved structure -desired perceptual tasks. To assess structural preservation, the visual embedding model requires perceptual distance measures for a given visual embedding space. In some cases, existing perceptual spaces, such as CIELAB color space, can be used to perform embeddings <ref type="bibr" target="#b6">[7]</ref>. In this work, we evaluate crowdsourcing methods to estimate perceptual kernels for visual encoding variables that lack suitable models. The resulting kernels can be applied directly in visual embedding procedures or used to derive and evaluate more general perceptual models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">RESEARCH GOALS AND EXPERIMENT OVERVIEW</head><p>Our ultimate goal in introducing perceptual kernels is to facilitate automated visualization design. In order to do so, we must be able to estimate perceptual kernels reliably. Our first research goal was to evaluate and compare multiple approaches for collecting crowdsourced judgments to construct perceptual kernels. Our second research goal was to demonstrate the utility of these kernels for generating and evaluating visual encoding choices.</p><p>We conducted two experiments to learn perceptual kernels for visual encoding variables of shape, color, size and their combinations. The first experiment elicited judgments for univariate encodings, the second for bivariate encodings. The two experiments share the same procedure: collect similarity judgments under various rating schemes, construct perceptual kernels, then analyze the results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Visual Stimuli</head><p>We used color and shape stimuli from palettes in Tableau, a commercial visualization tool. Tableau's shape and color palettes were manually designed with consideration of perceptual issues such as discriminability, saliency and naming of colors <ref type="bibr" target="#b39">[40]</ref>, and robustness to spatial overlap of shapes. As such, these palettes constitute a good base from which to evaluate perceptual kernels. Also, using palettes from a popular visualization tool provides ecological validity for our study. Both the basic color and shape palettes have ten distinct values. For size, we used ten circles with linearly increasing area. We obtained perceptual kernels for each of these stimulus sets and their bivariate combinations. In total, we evaluated the six palettes shown in <ref type="figure" target="#fig_0">Figure 2</ref>: color, shape, size, shape-color, size-color, shape-size.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Judgment Types</head><p>We compared five similarity judgment types, each differing in terms of elicitation strategy or reported precision:</p><p>Pairwise rating on 5-Point Scale (L5): Subjects were sequentially presented pairs of visual stimuli and asked to rate the similarity of each pair on a 5-point Likert scale <ref type="figure" target="#fig_1">(Figure 3</ref>). The order between and within pairs was randomized for each subject. Task progress was visualized as an upper-triangular matrix, which was filled in as the subject provided ratings. This representation allowed subjects to see all their ratings together and readjust them as needed. Once all pairwise ratings were completed, subjects could click any cell and change the rating for the corresponding pair. The design goal was to help subjects distribute their ratings within the Likert scale so that the most different stimulus pairs get the highest rating while the most similar, non-identical stimulus pairs get the lowest possible rating. This also helps mitigate the effects due to differences between internal scales of subjects, a wellknown problem for subjective pairwise scaling <ref type="bibr" target="#b19">[20]</ref>.</p><p>Pairwise rating on 9-Point scale (L9): Same as the task above, except that a 9-point Likert scale was used.</p><p>Triplet ranking with matching (Tm): Subjects were sequentially presented triplets of stimuli, with one indicated to be a reference. We asked subjects to decide which of the other two stimuli was the most similar to the reference ( <ref type="figure" target="#fig_2">Figure 4</ref>). The order between and within triplets was randomized for each subject.</p><p>Triplet ranking with discrimination (Td): Subjects were sequentially presented triplets of stimuli and asked to decide which one was the most dissimilar to the other two ( <ref type="figure" target="#fig_3">Figure 5</ref>). The order between and within triplets was randomized for each subject.</p><p>Spatial arrangement (SA): Subjects were asked to manually arrange stimuli in the plane such that the 2D distances between pairs are proportional to their perceived dissimilarity ( <ref type="figure" target="#fig_4">Figure 6</ref>). The initial layout was randomized for each subject. To standardize interpretation of the instructions, we provided an example demonstrating the continuous nature of the judgments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Experimental Platform &amp; Subjects</head><p>We collected similarity judgments by submitting jobs to Amazon's Mechanical Turk (MTurk), a popular micro-task market that is regularly used for online human subjects experiments. For example, Heer &amp; Bostock <ref type="bibr" target="#b13">[14]</ref> reproduced prior laboratory experiments on spatial encoding <ref type="bibr" target="#b5">[6]</ref> and alpha contrast <ref type="bibr" target="#b40">[41]</ref>, demonstrating the viability of crowdsourced graphical perception studies. We ran thirty separate (six visual variables × five judgment types) MTurk jobs. Each job was completed by 20 Turkers, for a total of 600 distinct subjects. We limited the participant pool to Turkers based in the United States with a minimum 95% approval rate and at least 100 approved tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Procedure</head><p>For all but the spatial arrangement (SA) task, subjects carried out the experiments in five steps. Subjects were first presented a description of the task with an option of accepting it. Once the task was accepted, subjects completed a training session using an interface identical to the actual task interface but populated with different visual stimuli. After the training session, subjects were prompted with the full set of visual stimuli and asked to think about the most similar and dissimilar stimuli in the set ( <ref type="figure" target="#fig_5">Figure 7</ref>). Once they were ready, subjects completed the experimental task. In the last step, they provided comments on their rating or ranking strategies and submitted their results.</p><p>The SA experiments were carried out in two simple steps. The task interface and instructions were directly presented to subjects upon introduction. Instructions included a spatial arrangement example <ref type="figure" target="#fig_4">(Figure 6</ref>). Once the subjects were satisfied with the layout, they provided comments on their strategies and submitted their layout.     : Visual stimuli overview. We asked subjects to consider and compare the stimuli before starting the experimental task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Data Processing</head><p>Our pairwise judgment tasks directly produce a distance matrix among visual stimuli; we simply rescale the per-user ratings to the range [0,1]. For triplet judgments, we derive per-user kernels from a set of rankordered triplets using generalized non-metric multidimensional scaling <ref type="bibr" target="#b0">[1]</ref>. In both cases, we then average the per-user kernels and renormalize the result to form an aggregate perceptual kernel.</p><p>To safeguard data quality, we use errant ratings of identical stimuli pairs (both in the pairwise and triplet cases) to filter "spammers." In the pairwise cases, subjects were instructed to rate the similarity of identical pairs as 0. They were also expected to match or filter identical stimuli pairs in the triplet cases. We excluded the data from subjects who failed in 40% or more of these judgments.</p><p>For spatial arrangements, we align each arrangement with every other arrangement using similarity transforms via Procrustes analysis <ref type="bibr" target="#b18">[19]</ref>. We designate the arrangement that requires the minimum total transformation to align with others as the reference arrangement. We then align all responses to this reference arrangement, use in-plane Euclidean distances to construct distance matrices for each subject, and normalize the results. To combat spam, we removed layouts with an alignment error greater than two standard deviations away from the mean alignment error. Finally, we average the distance matrices and normalize the result to obtain a perceptual kernel.</p><p>Throughout the paper, we present the resulting perceptual kernels as matrix diagrams alongside a 2D projection obtained using multidimensional scaling (MDS). These projections are intended to provide a more intuitive, overall sense of the kernel. Note, however, that each projection is a lossy representation, in some cases providing only partial insight into the kernel structure.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">EXPERIMENT 1: UNIVARIATE KERNELS</head><p>In the first experiment, we estimated perceptual kernels for stimuli that change only in one perceptual dimension (i.e., univariate visual variables). We chose the visual variables shape, color, and size due to their common use in practice. For values of shape and color, we used Tableau's default shape and color palettes, each of which has ten values. We presented colors to subjects as rectangular chips, which is customary in perceptual experiments. For the size variable, we used ten circles with linearly increasing area. <ref type="figure" target="#fig_8">Figure 8</ref> visualizes the resulting kernels for each palette and judgment type. We summarize specific results for each palette below. <ref type="figure">Figure 1</ref> shows a matrix and two-dimensional MDS projection of the perceptual kernel estimated from triplet matching (Tm) judgments. The MDS projection shows distinct perceptual shape clusters. Across all kernels <ref type="figure" target="#fig_8">(Figure 8</ref>), we see strong groupings among triangles and stroked shapes, and a looser cluster of other filled shapes. <ref type="figure" target="#fig_6">Figure 9</ref> shows a matrix and two-dimensional MDS projection of the perceptual kernel (Tm) for the color palette. From the MDS projection we readily see that subjects judged color similarity primarily by hue and secondarily by lightness.   To further validate the crowd-estimated kernels, we can compare them to kernels derived from existing color models. CIELAB is an approximately perceptually uniform color space with a lightness component L* and opponent color components a* and b*. CIEDE2000 is a more complex color difference formula that was developed to better fit empirical perceptual judgments than the Euclidean LAB distances. Heer and Stone <ref type="bibr" target="#b17">[18]</ref> introduced distances based on color-name associations to reflect linguistic boundaries among colors. Here, we use the Hellinger distance between multinomial color name probability distributions estimated from the XKCD color naming survey <ref type="bibr" target="#b27">[28]</ref>. <ref type="figure" target="#fig_7">Figure 10</ref> compares the triplet matching (Tm) kernel with kernels constructed using CIELAB, CIEDE2000 and color-name distance <ref type="bibr" target="#b17">[18]</ref> distance measures. The plotting symbols in <ref type="figure" target="#fig_7">Figure 10</ref> were chosen automatically via visual embedding of the rank correlations between metrics using the triplet matching (Tm) perceptual kernel for shapes (see §7.2). All kernels are strongly correlated, but we also see some variation, consistent with the fact that longer distances in existing perceptual color spaces tend to be less accurate than short proximal judgments. Interestingly, of the existing models color name distance correlates most highly with the crowd-estimated kernel. We hypothesize that perceptual judgments from crowd participants are influenced by color name associations in addition to lower-level features. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Estimated Univariate Perceptual Kernels</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.1">Shape</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.2">Color</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.3">Size</head><p>As shown in <ref type="figure" target="#fig_8">Figure 8</ref>, of the three visual variables we considered, size is the most robust across judgment task types. <ref type="figure">Figure 11</ref> shows a matrix and two-dimensional MDS projection of the perceptual kernel estimated using the triplet matching (Tm) task. The MDS projection clearly demonstrates a one-dimensional structure, in which linear increases in area map to non-linear perceptual distances. Non-linearity of area judgments is consistent with perceptual models such as the Weber-Fechner Law <ref type="bibr" target="#b9">[10]</ref> and Stevens' Power Law <ref type="bibr" target="#b38">[39]</ref>. Stevens posits a power-law relationship between the magnitude of a physical stimulus and its perceived intensity: S ∼ I β , where S and I are the sensed and the true intensities, respectively. <ref type="figure" target="#fig_0">Figure 12</ref> shows Stevens' Power Law fits and corresponding exponent values for each judgment type. Pairwise and triplet kernels result in exponents consistent with the literature on area estimation (0.7-0.8). For spatial arrangement (SA) we find an exponent larger than one, which is inconsistent with prior work. To compute these fits, we calculate individual area estimates from each row of the kernel, treating the diagonal value as a reference. We then average the resulting magnitude estimates and directly perform least-squares fitting of the exponent. We constrain the lowest and highest areas to their true values, as the full palette was known to subjects from the outset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">EXPERIMENT 2: BIVARIATE KERNELS</head><p>In the second experiment, we estimated perceptual kernels for stimuli that change in two perceptual dimensions (i.e., bivariate visual variables). We chose four elements from each of the univariate palettes and used their pairwise combinations to create three bivariate palettes with 16 values: shape-color, size-color, and shape-size <ref type="figure" target="#fig_0">(Figure 2</ref>). To test interactions among perceptual dimensions, we intentionally included both highly similar and highly dissimilar values from the univariate palettes (e.g., two small sizes and two large sizes).</p><p>We did not use the complete set of elements from the univariate palettes, as this would cause the bivariate palettes to become too large to practically run our experiments. A bivariate variable with 100 values requires rating 4,950 (=100 × 99/2) pairs. As discussed previously, this number is even larger when using triplet ratings.   <ref type="figure" target="#fig_1">Figure 13</ref> visualizes the estimated bivariate kernels for each palette and judgment type. <ref type="figure" target="#fig_2">Figure 14</ref> shows both kernels and two-dimensional MDS plots for triplet matching (Tm) judgments. In most cases we observe balancing among visual variables: large distances in one variable dominate smaller distances in the other. We also note limitations of the MDS plots in <ref type="figure" target="#fig_2">Figure 14</ref>: the 2D projection collapses smaller distances, resulting in overlapping points. The actual structure is better described by three dimensions, in which these clusters are more distributed. We summarize specific results for each palette below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Estimated Bivariate Perceptual Kernels</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.1">Shape-Color</head><p>For all kernels but triplet discrimination (Td), shape-color stimuli form four dominant intersecting clusters, grouped by the most similar color and shape values. For the Td kernel, shape dominates color entirely, forming four clusters of distinct shapes and mixed colors. As we will describe in the next section, this is likely due to the failure of triplet discrimination to elicit more fine-grained comparisons.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.2">Shape-Size</head><p>Across all judgment types, the shape-size kernels exhibit four dominant clusters, grouped by the most similar shape and size values.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.3">Size-Color</head><p>The results for size-color kernels are similar to those for shape-size kernels: the size-color kernels exhibit four dominant clusters, grouped by the most similar size and color values. Three-dimensional MDS plots (see supplementary material) reveal additional stratification by color value.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Analysis of Dimensional Integrality</head><p>Visual variables potentially interact with each other when used to encode multiple dimensions of data. Our bivariate palettes are examples of two-dimensional stimuli. Prior research states that dimensions of a visual stimulus are separable if they do not confound or facilitate perception of the other and are considered integral if they do <ref type="bibr" target="#b10">[11]</ref>.</p><p>Researchers further argue (e.g., <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b44">45]</ref>) that if the dimensions constituting a multidimensional stimulus are integral then the multi-dimensional perceptual distances can be approximated using the Euclidean (L 2 ) metric. If the dimensions are separable, then the distance in the multidimensional stimulus space can be better approximated with the city-block (L 1 ) metric.</p><p>To assess if either of these metric structures holds for estimated perceptual kernels, we fit the following weighted power model to predict the values of the bivariate shape-color, shape-size, and size-color kernels based on the corresponding univariate kernels:</p><formula xml:id="formula_0">d i j ∼ b 0 + ((b 1 d 1 ) n + (b 2 d 2 ) n ) 1/n</formula><p>Here, d i j is the observed perceptual distance between two bivariate stimuli i and j. d 1 is the univariate distance between i and j on the first perceptual dimension and d 2 is the univariate perceptual distance on the second dimension. b 1 and b 2 are scaling parameters acting on the perceptual space, which account for any non-uniformity in the strength of the individual perceptual dimensions. Prior work <ref type="bibr" target="#b10">[11]</ref> suggests that the value of n depends on the level of integrality between dimensions. A value of n = 1 would indicate total separability, whereas a value of n = 2 would indicate complete integrality. We fit the weighted power model to our experimental data using non-linear regression routines in Matlab. We set b 2 = 1 − b 1 without constraining the sum to be 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>shape-color</head><p>shape-size size-color    <ref type="table" target="#tab_3">Table 1</ref> summarizes the model parameters and goodness-of-fit in terms of log-likelihood. With the exception of spatial arrangement (SA), each judgment type exhibits similar values of the scaling parameters b 1 and b 2 , indicating the degree by which each dimension is scaled. In accordance with prior research, some level of integrality (n values intermediate between 1 and 2) is seen across all variables, more so on average for interactions involving size (particularly size and color) than for color and shape. As indicated by model loglikelihood, across all palettes triplet matching judgments provide the most accurate prediction of bivariate distances from univariate kernels.</p><formula xml:id="formula_1">b 0 b 1 n llik b 0 b 1 n llik b 0 b 1 n</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">COMPARISON OF JUDGMENT TASKS</head><p>One goal of this work is to understand the trade-offs among different judgment tasks. In addition to the perceptual analyses in previous sections, we performed comparative analyses considering factors such as collection cost, agreement and robustness. We then provide recommendations based on the results of our analysis. <ref type="table">Table 2</ref> presents summary statistics for each judgment type. Across judgments, triplet matching (Tm) exhibits the lowest cross-subject variance and lowest unit task time. The low per-task time is consistent with the binary perceptual judgment required. Other tasks require considering more potential responses: three in the case of triplet discrimination, and either five or nine for pairwise Likert ratings. Unsurprisingly, L9 exhibits the longest per-judgment time. However, pairwise rating requires fewer total judgments, leading to lower overall experiment time and cost than triplet comparisons. Spatial arrangement (SA) is by far the fastest, and hence cheapest, elicitation method.   <ref type="table">Table 2</ref>: Summary comparison of judgment task types: standard deviation across per-subject kernel distances (σ m ), average judgment time (µ t ), standard deviation of average judgment time (σ t ), the average duration of the experiment (µ T ), and per Turker compensation ($). All time measurements listed are in seconds. Measurements µ t and σ t are not directly applicable to SA, and so left blank. shape color size shape-color shape-size size-color Avg.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Variance and Cost</head><formula xml:id="formula_2">σ m µ t σ t µ T $ σ m µ t σ t µ T $<label>L5</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>L5</head><p>0  <ref type="table">Table 3</ref>: Average rank correlations between each estimated kernel and all other perceptual kernels for the same palette. All correlations from which the averages are computed are significant at p &lt; 0.002 according to permutation (Mantel) tests.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Correlations</head><p>To better understand the degree of compatibility between the five judgment tasks, we compared their corresponding perceptual kernels. To quantify the degree of similarity between perceptual kernels, we use Spearman's rank correlation coefficient. While we believe rank correlation is the most appropriate measure, we note that standard correlation coefficients (Pearson's product moment) provide similar results. <ref type="table">Table 3</ref> summarizes these correlations. SA has the lowest average correlation across all variables; the other task types exhibit similar correlations. We see that both task type and visual variable affect the level of correlation. Color has the least agreement while size has the most, suggesting a potential relationship between the dimensionality of the underlying perceptual space and agreement across task types. When the perceptual space has low dimensionality, tasks may become easier due to the reduced degrees of freedom.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Sensitivity</head><p>How sensitive are the kernels to the number of subjects who participate? To address this question, we ran a sensitivity analysis on judgment tasks across univariate and bivariate kernels ( <ref type="figure" target="#fig_3">Figure 15)</ref>. We randomly remove subjects from the experiments and compare the original perceptual kernels with those derived from the reduced datasets.</p><p>The results show that on average spatial arrangement (SA) is the least robust to changes in data size, while triplet matching (Tm) is the most robust. The sensitivity to subject pool size is also affected by the visual variable used. All judgment types are highly stable with the size variable, as it forms a relatively simple perceptual space. Conversely, estimated kernels are less stable with color and, to a lesser degree, with shape. The five judgment types are less stable with the univariate variables than they are with the bivariate variables, though this is likely due (at least in part) to the very specific stimuli chosen for our bivariate experiments. Overall, each of the judgment types is considerably robust. Even in the case of SA, the rank correlation is above 0.6 when 80% of the experimental data is removed.</p><p>Note that we observe interesting differences among per-subject perceptual kernels (see supplementary material). However, the overall robustness shown here supports the use of aggregate kernels. For shape and color, the stability decreases faster, with the spatial arrangement (SA) task deviating considerably from the others.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.4">Discussion: Which Judgment Task to Use?</head><p>Our analyses have identified trade-offs among judgment types. Which should be preferred? We now consider each class of judgments in turn.</p><p>Spatial Arrangement (SA). Spatial arrangement is clearly the fastest and cheapest method for eliciting perceptual kernels. However, for all other measures it is the worst-performing judgment task among the five considered. We believe there are multiple reasons for this outcome. First, SA tasks are the least structured, leading to higher variance across subjects. Second, by design SA tasks are inherently limited to two-dimensional structures. Unlike the other judgment tasks, SA can not accurately express higher dimensional structures. This limitation is especially problematic for the case of color (which is known to be best modeled using three dimensions) and for judgments spanning multiple perceptual dimensions.</p><p>Pairwise Likert Ratings (L5 &amp; L9). Pairwise rating fared admirably in our experiments. These ratings are faster and cheaper to elicit than exhaustive triplet comparisons. However, triplet matching (Tm) exhibits lower variance and slightly improved robustness. One potential issue with Likert judgments is a possible confound of scale cardinality. When the number of stimuli outnumber the Likert scale levels (in this case, 5 or 9), judgments are limited in their precision, as certain fine-grained differences may be inexpressible. That said, we do not see any clear evidence of this issue affecting the results of this work. One potential explanation is that such high-precision judgments, while desirable in theory, are in fact dominated by between-subject variation.</p><p>Triplet <ref type="bibr">Comparison (Tm &amp; Td)</ref>. Setting aside issues of experiment time and cost, our analyses indicate that triplet matching with a reference (Tm) is the preferred judgment type. Triplet matching exhibits the lowest variance in estimates, is the most robust across the number of subjects, and results in the most accurate prediction of bivariate kernels from univariate inputs. Triplet matching also involves the shortest unit task time (as opposed to overall experiment duration). Triplet matching involves a two alternative forced-choice, and so arguably is the simplest and most "perceptual" of the tasks considered.</p><p>Why does triplet matching (Tm) outperform triplet discrimination (Td)? First, as noted above, it involves a simpler binary (as opposed to trinary) decision. Second, triplet matching elicits more fine-grained distinctions. Consider three stimuli A, B and C, and assume the "true" distances are as follows: In the case of Td, when subjects see the triplet A, B, C they should pick the most distinct, which in this case is C. In the case of Tm, some judgments will use C as the reference. Subjects are then forced to choose either A or B as the most similar. In this case, most subjects will probably pick A (as 0.8 &lt; 0.9). Thus triplet matching encourages more fine-grained distinctions, providing more information for the subsequent scaling. This comes with the potential cost of requiring multiple judgments per triplet, using different references. However, in our experiments we use the same total number of judgments as triplet discrimination and still see better, more robust results.</p><p>As a result of these considerations, we advocate for the use of triplet matching (Tm) judgments unless prohibited by time or cost. There are also various means of scaling triplet judgments to larger palettes. One method is to subdivide the stimulus set and parcel out different subsets to different subjects. A complementary method is to use adaptive sampling methods <ref type="bibr" target="#b43">[44]</ref> for more scalable, active learning of perceptual kernels. We defer further exploration of these options to future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">APPLICATIONS</head><p>In this section, we present example applications using perceptual kernels for automated visualization design. In the first application, we generate re-orderings of the Tableau palettes to optimize perceptual discriminability. In the second application, we demonstrate how perceptual distances provided by the kernels can be used to perform visual embedding for optimized assignment of palette entries to data points.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1">Automatically Designing New Palettes</head><p>Given a perceptual kernel, we can use it to revisit existing palettes. For example, we can order a set of stimuli to maximize perceptual distances according to the kernel. <ref type="figure" target="#fig_4">Figure 16</ref> shows both original and re-ordered palettes for shape, color and size variables. (We include size for completeness, though in practice this palette is better suited to quantitative, rather than categorical, data.) To perceptually re-order a palette, we first initialize the set with the variable pair that has the highest perceptual distance. We then add new elements to this set, by finding the variable whose minimum distance to the existing subset is the maximum (i.e., the Hausdorff distance between two point sets).</p><p>It is instructive to compare the re-ordered palettes with the twodimensional MDS projections of the kernels. For example, the first four elements in the re-ordered shape palette include representatives original re-ordered <ref type="figure" target="#fig_4">Fig. 16</ref>: Shape, color and size palettes: (top) original palettes and (bottom) palettes re-ordered to maximize perceptual discriminability according to triplet matching (Tm) kernels. from each of the four clusters seen in <ref type="figure">Figure 1b</ref>. Each palette has been re-ordered such that more perceptually discriminable stimuli are used first. Thus, sequential assignments from the re-ordered palettes should better promote discrimination among visual elements.</p><p>There are several ways we might re-order palettes. For example, for palettes of varying size n, we could perform a global optimization for each value of n. However, one advantage of the method used here is that it is stable: a given subset palette grows only by adding new elements, without replacing the existing ones. We do not need to change the visual variables already assigned if new data values are added.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2">Visual Embedding</head><p>Perceptual kernels can also guide visual embedding <ref type="bibr" target="#b7">[8]</ref> to choose encodings that preserve data-space distance metrics in terms of kerneldefined perceptual distances. To perform discrete embeddings, we find the optimal distance-preserving assignment of palette items to data points (e.g., using simulated annealing or other optimization methods).</p><p>The scatter plot in <ref type="figure" target="#fig_7">Figure 10</ref> compares color distance measures. The plotting symbols were chosen automatically using visual embedding. We use the correlation matrix between color models as the distances in the data domain, and the triplet matching (Tm) kernel for the shape palette as the distances in the perceptual range. This automatic assignment reflects the correlations between the variables. The correlation between CIELAB and CIEDE2000 is higher than the correlation between the triplet matching kernel and color names, and the assigned shapes reflect this relationship perceptually. For example, the perceptual distance between upward-and downward-pointing triangles is smaller than the perceptual distance between circle and square.</p><p>In a second example, we use visual embedding to encode community clusters in a character co-occurrence graph derived from Victor Hugo's Les Misérables. Cluster memberships were computed using a standard modularity-based community-detection algorithm (see <ref type="bibr" target="#b14">[15]</ref>). For the data space distances, we count all inter-cluster edges and then normalize by the theoretically maximal number of edges between groups. To provide more dynamic range, we re-scale these normalized values to the range [0.2,0.8]. Clusters that share no connecting edges are given a maximal distance of 1. We then perform visual embeddings using univariate color and shape kernel, both estimated using triplet matching. As shown in <ref type="figure" target="#fig_5">Figure 17</ref>, the assigned colors and shapes perceptually reflect the inter-cluster relations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">CONCLUSION</head><p>We introduce perceptual kernels, perceptual distance matrices formed from aggregate similarity judgments. Through a set of crowdsourced experiments, we compare the use of different judgment tasks to estimate perceptual distances. We find that ordinal triplet matchingin which subjects are shown a triplet of stimuli and asked to choose which of two items is more similar to a designated reference -exhibit the least inter-subject variance, are less sensitive to subject count, and enable the most accurate prediction of bivariate kernels from univariate inputs. Pairwise Likert scale judgments also fare well, and involve faster and cheaper experiments than triplet comparisons. Spatial arrangement tasks, on the other hand, exhibit much higher variance and can produce results inconsistent with existing perceptual models. Based on these considerations, we recommend the use of triplet matching judgments unless prohibited by issues of time or cost. We demonstrate how perceptual kernels enable automated design by re-ordering palettes to enhance discriminability and using visual embedding <ref type="bibr" target="#b7">[8]</ref> to assign visual stimuli to data points in a structure-preserving fashion.</p><p>Our results also have broader implications. Our analysis is relevant to the general problem of crowdsourcing similarity models <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b43">44,</ref><ref type="bibr" target="#b46">47]</ref>, providing new evidence in support of triplet matching. The poor performance of spatial arrangement (SA) also has implications for existing visual analytics tools. Semantic interaction systems (e.g., ForceSPIRE <ref type="bibr" target="#b8">[9]</ref>) use SA tasks to elicit domain expertise to drive modeling and layout. Our results suggest that this mode of interaction may engender significant variation among experts and provide insufficient expressiveness for high-dimensional relations. Such tools may benefit by incorporating alternative similarity judgment tasks.</p><p>With respect to future work, integrating perceptual kernels into visualization design tools is an important next step. Towards this aim, we have made our perceptual kernels and experiment source code publicly available at https://github.com/uwdata/perceptual-kernels. While we focused on specific shape, color, and size palettes, we plan to incorporate additional stimuli in each of these perceptual channels. Moreover, we can collect data for other channels, such as opacity, orientation, and lightness. Future work should also explore techniques for scaling to larger palettes, such as partitioning and adaptive sampling <ref type="bibr" target="#b43">[44]</ref>.</p><p>Future research might also extend our approach to more situated contexts. In this work we used direct measurement types, but it is possible to derive perceptual similarities through indirect judgments, such as the time taken to complete low-level graph reading tasks. As visual variables do not live in isolation, how different contexts may bias judgment remains an important concern. Gathering similarity judgments within the presence of competing variables would be valuable for assessing contextual effects. In the meantime, perceptual kernels provide a useful operational model for incorporating empirical perception data directly into visualization design tools.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 2 :</head><label>2</label><figDesc>Palettes of visual stimuli used in our experiments: shape, color, size, shape-color, shape-size, size-color.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 3 :</head><label>3</label><figDesc>Experiment interface for the pairwise rating task on a Likert scale of five (L5).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 4 :</head><label>4</label><figDesc>Interface for the triplet matching task (Tm).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 5 :</head><label>5</label><figDesc>Interface for the triplet discrimination task (Td).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 6 :</head><label>6</label><figDesc>Interface for the spatial arrangement task (SA). Subjects can rearrange visual stimuli (here shapes) with drag and drop.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 7</head><label>7</label><figDesc>Fig. 7: Visual stimuli overview. We asked subjects to consider and compare the stimuli before starting the experimental task.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 9 :</head><label>9</label><figDesc>(a) A crowd-estimated perceptual kernel elicited using triplet matching (Tm) for the color palette. (b) A two-dimensional projection of the palette colors obtained via multidimensional scaling of the perceptual kernel.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 10 :</head><label>10</label><figDesc>(Top) Projections of a crowd-estimated color kernel and kernels induced by CIELAB, CIEDE2000 and color name distances, aligned by similarity transforms. Plotting symbols are chosen automatically by visual embedding of the rank correlations, using the triplet matching (Tm) perceptual kernel for shapes. (Bottom) The rank correlation between kernels. All the correlations are significant at p &lt; 0.002 (determined using permutation testing).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 8 :</head><label>8</label><figDesc>Experiment 1 Results. Univariate perceptual kernels for the shape, color and size palettes across different judgment types. Darker colors indicate higher perceptual similarity. For each palette, the matrices exhibit consistent structures across judgment types.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig. 11 :Fig. 12 :</head><label>1112</label><figDesc>(a) A crowd-estimated perceptual kernel (Tm) for the size palette. (b) A two-dimensional projection of the size values obtained via multidimensional scaling of the perceptual kernel. 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 L5 (Exp: 0.72) L9 (Exp: 0.73) (Exp: 0.77) (Exp: 0.66) SA (Exp: 1.13) Tm Td Stevens' Power Law fits to kernel-estimated area magnitudes.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Fig. 13 :</head><label>13</label><figDesc>Experiment 2 Results. Bivariate perceptual kernels for the shape-color, shape-size, and size-color palettes across judgment types.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Fig. 14 :</head><label>14</label><figDesc>(Left) Crowd-estimated kernels (Tm) for the shape-color, shape-size and size-color palettes. (Right) Two-dimensional projections of the kernels obtained by multidimensional scaling.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head></head><label></label><figDesc>univariate bivariate</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Fig. 15 :</head><label>15</label><figDesc>Sensitivity of judgment types to the removal of subject data. The x-axis indicates the percentage of subjects dropped from each experiment; the y-axis indicates rank correlation. All kernels are highly stable for the size palette, as it is a relatively simple perceptual space.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head></head><label></label><figDesc>d(A, B) = 0.1, d(A,C) = 0.8, d(B,C) = 0.9.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head>Fig. 17 :</head><label>17</label><figDesc>Graph of character co-occurrences in Les Misèrables, with node colors and shapes automatically chosen via visual embedding to reflect connection strengths between community clusters.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 1 :</head><label>1</label><figDesc></figDesc><table /><note>Estimated parameters of the weighted power model fitted to perceptual kernels. b 0 is the intercept (or bias), b 1 is the scaling of the first dimension, b 2 = 1 − b 1 is the scaling factor for the second dimension, and n is the exponent of the model. Across palettes, triplet matching (Tm) provides the best prediction (highest log-likelihood, in boldface) of bivariate distances from univariate kernels.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head></head><label></label><figDesc>0.03 3.29 2.25 180.96 0.75 0.04 3.28 3.02 446.67 2.00 L9 0.04 3.63 2.22 199.74 0.75 0.05 3.58 3.24 486.79 2.00 SA 0.04 43.18 0.20 0.03 180.79 0.35 Tm 0.02 2.51 2.42 345.73 1.00 0.01 2.36 2.11 1401.48 3.50 Td 0.02 3.18 2.48 439.25 1.00 0.03 2.37 1.81 1407.21 3.50</figDesc><table /><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS</head><p>This research was supported by the Intel Science &amp; Technology Center (ISTC) for Big Data and NSF Grant 1351131.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Generalized non-metric multidimensional scaling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wills</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Cayton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Lanckriet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kriegman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Belongie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. AIS-TATS</title>
		<meeting>AIS-TATS</meeting>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Dimensions of similarity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Attneave</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The American Journal of Psychology</title>
		<imprint>
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="page" from="511" to="556" />
			<date type="published" when="1950" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Semiology of graphics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bertin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1983" />
			<publisher>University of Wisconsin Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Task-analytic approach to the automated design of graphic presentations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M</forename><surname>Casner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Graph</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="111" to="151" />
			<date type="published" when="1991-04" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Visualizing Data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">S</forename><surname>Cleveland</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1993" />
			<publisher>Hobart Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Graphical perception: Theory, experimentation, and application to the development of graphical methods</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">S</forename><surname>Cleveland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Mcgill</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Statistical Association</title>
		<imprint>
			<biblScope unit="volume">79</biblScope>
			<biblScope unit="issue">387</biblScope>
			<biblScope unit="page" from="531" to="554" />
			<date type="published" when="1984" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Similarity coloring of DTI fiber tracts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ç</forename><surname>Demiralp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">H</forename><surname>Laidlaw</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">MICCAI Workshop on DMFC</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Visual embedding: A model for visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ç</forename><surname>Demiralp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">E</forename><surname>Scheiddegger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">L</forename><surname>Kindlmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">H</forename><surname>Laidlaw</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Heer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer Graphics &amp; Applications</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Semantic interaction for visual text analytics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Endert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Fiaux</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>North</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM Human Factors in Computing Systems (CHI)</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="473" to="482" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Elements of Psychophysics. Holt, Rinehart and Winston</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Fechner</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1966" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Integrality of stimulus dimensions in various types of information processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">R</forename><surname>Garner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">L</forename><surname>Felfoldy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognitive Psychology</title>
		<imprint>
			<biblScope unit="page" from="225" to="241" />
			<date type="published" when="1970" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">An efficient method for obtaining similarity data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Goldstone</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Behavior Research Methods Instruments &amp; Computers</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="381" to="386" />
			<date type="published" when="1994" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Multi-scale banking to 45 degrees</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Heer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Agrawala</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Visualization &amp; Comp. Graphics</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="701" to="708" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Crowdsourcing graphical perception: Using mechanical turk to assess visualization design</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Heer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bostock</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM Human Factors in Computing Systems (CHI)</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">A tour through the visualization zoo</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Heer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bostock</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Ogievetsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="59" to="67" />
			<date type="published" when="2010-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Sizing the horizon: The effects of chart size and layering on the graphical perception of time series visualizations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Heer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Agrawala</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM Human Factors in Computing Systems (CHI)</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Animated transitions in statistical data graphics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Heer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Robertson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Visualization &amp; Comp. Graphics</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="1240" to="1247" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Color naming models for color selection, image editing and palette design</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Heer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Stone</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM Human Factors in Computing Systems (CHI)</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">A survey of the statistical theory of shape</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">G</forename><surname>Kendall</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Statistical Science</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="87" to="99" />
			<date type="published" when="1989" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Rank correlation methods. Theory and applications of rank order-statistics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kendall</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1962" />
			<publisher>Hafner Pub. Co</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Perceptual guidelines for creating rectangular treemaps</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Heer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Agrawala</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Visualization &amp; Comp. Graphics</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="990" to="998" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Multidimensional scaling by optimizing goodness of fit to a nonmetric hypothesis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychometrika</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="27" />
			<date type="published" when="1964" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Overview use in multiple visual information resolution interfaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Munzner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Kincaid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Visualization &amp; Comp. Graphics</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1278" to="1285" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Discriminating strata in scatterplots</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lewandowsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Spence</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of American Statistical Association</title>
		<imprint>
			<biblScope unit="volume">84</biblScope>
			<biblScope unit="issue">407</biblScope>
			<biblScope unit="page" from="682" to="688" />
			<date type="published" when="1989" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">How Maps Work: Representation, Visualization, and Design</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Maceachren</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1995" />
			<publisher>Guilford Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Show me: Automatic presentation for visual analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Mackinlay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Hanrahan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Stolte</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Visualization &amp; Comp. Graphics</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1137" to="1144" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Automating the design of graphical presentations of relational information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">D</forename><surname>Mackinlay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Graph</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="110" to="141" />
			<date type="published" when="1986" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Munroe</surname></persName>
		</author>
		<ptr target="http://blog.xkcd.com/2010/05/03/color-survey-results/" />
		<title level="m">Color survey results</title>
		<imprint>
			<date type="published" when="2010-05" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Effectiveness of animation in trend visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Robertson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Fernandez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Fisher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Stasko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Visualization &amp; Comp. Graphics</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1325" to="1332" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Interactive graphic design using automatic presentation knowledge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">F</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kolojejchick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Mattis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Goldstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM Human Factors in Computing Systems (CHI)</title>
		<imprint>
			<date type="published" when="1994" />
			<biblScope unit="page" from="112" to="117" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Learning a distance metric from relative comparisons</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Schultz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Joachims</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NIPS)</title>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">The analysis of proximities: Multidimensional scaling with an unknown distance function. I</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Shepard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychometrika</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="125" to="140" />
			<date type="published" when="1962" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Attention and the metric structure of the stimulus space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">N</forename><surname>Shepard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Mathematical Psychology</title>
		<imprint>
			<biblScope unit="page" from="54" to="87" />
			<date type="published" when="1964" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Toward a Universal Law of Generalization for Psychological Science</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">N</forename><surname>Shepard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">237</biblScope>
			<biblScope unit="issue">4820</biblScope>
			<biblScope unit="page" from="1317" to="1323" />
			<date type="published" when="1987" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Integrality versus separability of stimulus dimensions: From an early convergence of evidence to a proposed theoretical basis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">N</forename><surname>Shepard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The perception of structure: Essays in honor of Wendell R</title>
		<imprint>
			<publisher>Garner. APA</publisher>
			<date type="published" when="1991" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Stimulus processing models from psychology: can we use them in cartography? The American Cartographer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Shortridge</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1982" />
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="155" to="167" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">An information-processing analysis of graph perception</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Simkin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Hastie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of American Statistical Association</title>
		<imprint>
			<biblScope unit="volume">82</biblScope>
			<biblScope unit="issue">398</biblScope>
			<biblScope unit="page" from="454" to="465" />
			<date type="published" when="1987" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Displaying proportions and percentages</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Spence</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lewandowsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Applied Cognitive Psychology</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="61" to="77" />
			<date type="published" when="1991" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">On the psychophysical law</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">S</forename><surname>Stevens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Review</title>
		<imprint>
			<biblScope unit="volume">64</biblScope>
			<biblScope unit="page" from="153" to="181" />
			<date type="published" when="1957" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Color in information display: From theory to practice</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Stone</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Tutorial in IEEE Visualization</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Alpha, contrast and the perception of visual metadata</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Stone</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bartram</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Color Imaging Conference</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Arc length-based aspect ratio selection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Talbot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gerth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Hanrahan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Visualization &amp; Comp. Graphics</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">An extension of Wilkinson&apos;s algorithm for positioning tick labels on axes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Talbot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Hanrahan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Visualization &amp; Comp. Graphics</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Adaptively learning the crowd kernel</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Tamuz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Shamir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kalai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Belongie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th International Conference on Machine Learning (ICML-11)</title>
		<editor>L. Getoor and T. Scheffer</editor>
		<meeting>the 28th International Conference on Machine Learning (ICML-11)</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="673" to="680" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Multidimensional scaling: I. theory and method</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Torgerson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychometrika</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="401" to="419" />
			<date type="published" when="1952" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">The visual separability of plotting symbols in scatterplots</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Tremmel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Computational and Graphical Statistics</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="101" to="112" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Stochastic triplet embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Van Der Maaten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Weinberger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning for Signal Processing</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
