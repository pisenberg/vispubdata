<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/pisenberg/grobid/grobid-0.6.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Fast Stereo Volume Rendering</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Taosong</forename><surname>He</surname></persName>
							<email>taosong@cs.sunysb.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">State University of New York at Stony Brook Stony Brook</orgName>
								<address>
									<postCode>11794-4400</postCode>
									<region>NY</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arie</forename><surname>Kaufman</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">State University of New York at Stony Brook Stony Brook</orgName>
								<address>
									<postCode>11794-4400</postCode>
									<region>NY</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Fast Stereo Volume Rendering</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2021-02-19T20:34+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
				<p>We present new volume rendering techniques for efficiently generating high quality stereoscopic images and propose criteria to evaluate stereo volume rendering algorithms. Specifically, we present fast stereo volume ray casting algorithms using segment composition and linearlyinterpolated re-projection. A fast stereo shear-warp volume rendering algorithm is also presented and discussed.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Stereoscopic rendering is paramount for a variety of applications such as virtual reality and scientific visualization. A stereoscopic pair of images can solely provide unambiguous depth information, or enhance the depth discrimination provided by other depth cues (e.g., <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b16">17]</ref> ) Intuitively, if the time for rendering a single image is t, a stereo pair of images can be generated in 2t by rendering the left-eye image (in short, left-image) and the right-eye image (in short, right-image) separately. Fast stereo rendering, on the other hand, utilizes the coherence between the left-image and the right-image, and generates a stereo pair in one pass. Significant rendering time, therefore, can be saved. Most of the existing fast stereo rendering algorithms are based on a standard rendering scheme, such as ray tracing <ref type="bibr" target="#b0">[1]</ref>. They usually can be divided into the following three steps: (1) Select an appropriate viewpoint position (e.g., left-eye, right-eye, or the middle-eye, that is, the middle point between the left-eye and the right-eye.) (2) Apply the chosen standard rendering scheme for the selected viewpoint.</p><p>(3) Re-project the results or intermediate results of step 2 onto the right image or left-image or both according to certain coordinate transformations.</p><p>Direct volume rendering is a key technology for the visualization of large sampled, simulated, or synthesized 3D datasets from scientific, engineering, and medical applications. It approximates how the volume data generates, scatters, or occludes light <ref type="bibr" target="#b7">[8]</ref>. Unlike surfacebased rendering, where only the properties on the object surfaces are displayed, volume rendering presents information about both the surfaces and the inner structures of the model. Therefore, it has been widely used to visualize models with no tangible surfaces, such as clouds and fog. However, volume rendering is notoriously slow because of the large amount of data to be processed and the lack of hardware support. A fast stereo volume rendering algorithm is therefore critical to many applications. Adelson and Hansen <ref type="bibr" target="#b1">[2 ]</ref> have proposed the first fast stereo volume rendering algorithm. Basing their approach on the standard volume ray casting algorithm <ref type="bibr" target="#b9">[10 ]</ref>, they follow the three steps of fast stereo rendering described above. First, the viewpoint is placed at the lefteye position; then, conventional ray casting is applied for the generation of the left-image. At the same time, sampling points along the left-eye rays (for short, left-rays) are appropriately chosen to re-project along the right-eye ray (for short, right-ray) direction onto the right-image. An efficient viewing geometry has been developed to reduce the operations needed for re-projection to a minimum. Using this method, the right-image can be generated in a small fraction of the time of the left-image. However, the sampling points along the left-rays normally are not reprojected onto the integer grids of the right-image. The solution used by the algorithm is to round the re-projected samples to their nearest integer neighbor on the rightimage. As a result, errors are introduced.</p><p>In this paper, we propose a new segment composition scheme to further accelerate the stereo volume ray casting. Basically, since the angle between the left-rays and the right-rays is small, it is much faster to re-project several sampling points simultaneously. Although perspective projection is very important for stereo rendering, it is more difficult to implement than parallel projection for fast stereo rendering since the relation between the left-image and the right-image is more complicated. In this paper we focus on parallel projection, which has been used by Adelson and Hansen and in many visualization applications. The rest of the paper is organized as follows. We propose in Section 2 criteria for evaluating the performance of a stereo rendering algorithm. In particular, we consider that balanced image quality between the leftimage and the right-image is an important criterion. We then present in Section 3 the segment composition scheme and apply it to standard ray casting. We introduce in Section 4 a linearly-interpolated re-projection method to increase image accuracy of stereo rendering. Existing volume ray casting acceleration methods can then exploited and applied to the stereo pair generation. In Section 5 we present a fast stereo shear-warp volume rendering algorithm, which has lower image quality compared to the standard ray casting. The testing results of our algorithms are summarized in Section 6.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Stereo Volume Rendering Criteria</head><p>Generally, to measure the performance of a fast stereo rendering algorithm, we propose the following three criteria:</p><p>(1) Minimum total time for generating both the left-image and the right-image.</p><p>(2) High image quality.</p><p>(3) Balanced image quality between the left-image and the right-image. The first and the second criteria are obvious, and are addressed in Sections 3 and 4. The third criterion states that image quality should be balanced between the stereo pair. To avoid the discomfort caused by an unbalanced stereo pair, it is better to generate both the left-image and the right-image in medium accuracy than to generate one of them in high accuracy and one of them in low accuracy. Here image quality is judged based on the result of the corresponding single-eye rendering algorithm, and can be calculated using methods such as mean square error. For example, in <ref type="bibr" target="#b1">[2 ]</ref>, since the re-projected position of a lefteye sampling point is simply rounded to the nearest pixel on the right-image, the right-image is of lower accuracy than the left-image. To generate balanced images, the idea of re-projection can be intuitively extended by placing the viewpoint in the middle between the left and the right eyes, and re-projecting the sampling points on the middle-eye rays to both the left-image and the right-image. Since the angle between the middle-point rays and the left-rays is half of the angle between the left-rays and the right-rays, balanced image quality is achieved. Unfortunately, depending on the order of the rays cast (left to right scanline order or vice versa), one of the stereo pair images must be composed in a back-to-front order, which prevents the use of early ray termination. As described in Section 5, this problem can be solved by applying the stereo shearwarp volume rendering scheme.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Segment Composition</head><p>As mentioned above, the main idea of the fast stereo volume rendering proposed in <ref type="bibr" target="#b1">[2 ]</ref> is to re-project the sampling points of the left-rays onto the right-image. By placing the origin at the left center of projection, the reprojected pixel on the right-image can be found with two multiplications, two additions, and one round operation.</p><p>One of the main problems of the above approach is that reprojection and composition are performed on the rightimage for each sampling point on the left-rays. To further accelerate the generation of the right-image, we develop a segment composition scheme. The basic idea is to reproject and composite several sampling points simultaneously. Before we discuss the scheme, we first define the timesaving V for the right-image generation as:</p><formula xml:id="formula_0">(1) V = 1 − T l+r − T l T l</formula><p>where T l+r is the total time for the rendering of a stereo pair, T l is the time for the rendering of the left-image, and T r is the time for the rendering of the right-image. Usually, the angle between the left-rays and the right-rays, φ , is small. For example, Hodges <ref type="bibr" target="#b5">[6 ]</ref> has recommended that φ should be smaller than 1. 5 degrees. As a result, a series of sampling points along a single left-ray could be re-projected to the same right-eye pixel. This effect is illustrated in <ref type="figure" target="#fig_0">Figure 1</ref>, where φ has been greatly exaggerated for the legibility of the figure.</p><p>Mathematically, we assume that a sampling point (x p , y p , z p ) is projected to (x sl , y sl ) of the left-image and (x sr , y sr ) of the right-image, and the distance between the left and the right centers of projection is e. If we assign</p><p>(2) c = x p cos φ − e cos φ /2 then for a left-ray, Ray, cast from (x sl , y sl ), c is a constant, and</p><formula xml:id="formula_1">(3) x sr = round (c + z p sin φ ). Assume that (4) c + z p sin φ = n</formula><p>where n is an integer, then for all the sampling points on Ray in the interval:  Equation 6 states that instead of re-projecting the sampling points on Ray one by one, we can re-project segments of Ray with length l = 1/ sin φ each, and composite the color and opacity of the segments onto a pixel on the rightimage. The composition of segments is straightforward, and we present the formulas using the simple over operations <ref type="bibr" target="#b13">[14]</ref>. To simplify the calculations, the translucency t = 1 − α is used in our implementation instead of opacity α . Suppose that the color and the accumulated translucency are C in and t in , respectively, at the entry point of a certain segment, and t out and C out , respectively, at the exit point, the translucency t seg and color C seg of this segment can be calculated as:</p><formula xml:id="formula_2">(5) [(x p, y p, z p − 0. 5/ sin φ ), (x p, y p, z p + 0. 5/ sin φ )]</formula><formula xml:id="formula_3">(7) t seg = t out t in (8) C seg = C out − C in t in (1 − t seg )</formula><p>and the composition on the re-projected pixel is:</p><formula xml:id="formula_4">(9) C pixel = C pixel + C seg t pixel (1 − t seg ) (10) t pixel = t pixel t seg.</formula><p>The main advantage of this segment composition scheme is that the re-projection and composition time on the rightimage can be greatly reduced. Since composition time could take most of T r , the timesaving V is increased. Mathematically, assuming that the sampling distance on the image plane is d img , and the average sampling distance along the left-rays is d ray , the number of composition operations needed using segment composition is about (d ray sin φ )/d img 100% of the number of composition operations needed for re-projecting each sample point as in <ref type="bibr" target="#b1">[2]</ref>. For example, when d img = d ray , and even when φ = 5 o , which is three times larger than recommended, the composition operations needed for segment by segment reprojection is only about 8. 7% of that needed for point by point re-projection. Of course, the actual timesaving depends on the relationship between d ray and d img and the operations used for composition. It also depends on the translucency of the specific dataset, because of the utilization of early ray termination.</p><p>Early ray termination <ref type="bibr" target="#b10">[11 ]</ref> is a commonly used volume rendering acceleration method. It states that when the accumulated opacity along a certain ray that emanated from the eye-point reaches a certain threshold (e.g., 1), the ray traversal can be terminated. Yet for the fast stereo volume ray casting as described above, if a left-ray is terminated early, the area behind the termination point becomes unknown. To guarantee the correct composition on the right-image, right-eye re-projection of any sampling point should not go across this area in the first pass. However, the disadvantage of this approach is that left-eye sampling points behind the termination points that could contribute to the right-image are ignored in the first pass, and a second pass is thus needed.</p><p>In our approach, the left-ray is not terminated when the opacity threshold is reached. Instead, we first continue to traverse the sampling points inside the same segment, then jump to the entry point of the next segment which corresponds to the next non-opaque right-eye pixel, and reproject the sampling points inside that segment. The same process is applied to all the segments that correspond to non-opaque right-eye pixels and are behind the early termination point. As a result, the corresponding right-ray can also be terminated early. Note that after the opacity threshold is reached, the sampling points behind the leftray termination point are re-projected one by one, not segment by segment, onto the right-image. This process is illustrated in <ref type="figure" target="#fig_2">Figure 2</ref>. Unlike <ref type="bibr" target="#b1">[2]</ref>, in our algorithm the right-image is generated solely from the left-eye sampling points. Both time and space are saved by omitting the overhead of re-examining and re-casting the unfinished right-rays, and by not keeping the last projection position for each right-eye pixel.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Linearly-interpolated Re-projection</head><p>A very important criteria for stereo volume rendering is image quality. To increase the image quality of the rightimage, we propose a linearly-interpolated re-projection scheme. In the simple re-projection method discussed in <ref type="bibr" target="#b1">[2 ]</ref> and in Section 3, a right-ray is the zero-order interpolation between the corresponding left-rays. This is  <ref type="figure" target="#fig_5">Figure 3</ref>(a), where segment S r on a right ray is equivalent to segment S l on the neighboring left-ray. To increase image quality, linear-interpolation can be applied. One of the difficulties, though, is that since composition is not a linear process, sampling values for the right ray must be calculated, as illustrated in <ref type="figure" target="#fig_5">Figure 3</ref>(b).</p><p>To derive the value of the sampling points along S r1 , both the sampling points on S l1 and S l2 are needed. In other words, if a scanline ray traversal order is adopted, sampling results of the previous rays must be saved. Similar to Section 2, we notice that each sampling point on a left-ray affects one sampling point on each of the two neighboring right-rays. Similar to that for segment composition, each left-ray can be divided into several segments with length d img / sin φ , and all the sampling points in a segment affect the same right-eye pixels. The linear-interpolation algorithm is thus similar to the simple re-projection, where the right to left scanline order is adopted. Specifically, for each scanline: (1) Process the right-most left-ray:</p><p>For the nth sampling point, save the color, opacity, affected right-eye pixel x coordinate, and the weight in the nth element of a 1D array Ray. To apply early ray termination, we apply an idea similar to the one presented in Section 3. When the accumulated opacity of the left-ray is above a certain threshold, it is not terminated. The remaining sampling points on the ray are checked segment by segment, but re-projected point by point. If both the right-eye pixels affected by a left-ray  Although the linearly-interpolated re-projection is more accurate than the zero-order interpolation, it is still not equivalent to the standard rendering image. The reason is that in the standard ray casting, interpolation is performed within the neighboring voxels, not between neighboring rays. The commonly used tri-linear interpolation is a high order interpolation along the non-main-axis direction, and the viewing direction is generally non-orthogonal. Nevertheless, the linearly-interpolated re-projection scheme is more accurate, and taking advantage of the reprojection pattern as described above, it is still much faster than separately rendering the left-eye and right-eye images.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Stereo Shear-warp Volume Rendering</head><p>In general, a volume ray casting algorithm can be divided into three main steps, <ref type="bibr" target="#b9">[10]</ref> traversing and sampling along the ray, shading the sampling point, and compositing the color. For stereo volume ray casting, there is generally a tradeoff between speed and the achieved image quality. Re-projecting the left-eye sampling points achieves very high timesaving for right-image generation because it skips the traversing/sampling and shading steps, and shortens the color composition step by using segment composition. The linear interpolation approach simplifies the traversing/sampling step, and skips the shading step by directly interpolating the color and opacity from the lefteye sampling points.</p><p>The standard ray casting algorithms used for stereo rendering cast rays in such a ray-by-ray order. For example, both <ref type="bibr" target="#b1">[2 ]</ref> and the segment composition described above follow the scanline order for casting rays, and process the rays one by one. In Section 2, we have discussed the difficulties of generating balanced stereo images through re-projection when applying such a ray-byray order. Recently a volume rendering scheme based on slice-by-slice traversing order has been developed (e.g. <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b12">13]</ref>, ). The basic idea of slice-by-slice rendering is to first shear the original slices so that the viewing direction is parallel to a main axis, then traverse consecutive data slices perpendicular to this main axis in scanline order. Among such algorithms, shear-warp volume rendering proposed by Lacroute and Levo y <ref type="bibr" target="#b8">[9 ]</ref> further takes advantage of the data coherence, and achieves high performance. It is a hybrid of image-order ray casting and object-order projection algorithms, and it takes advantage of both. In this section, we focus on the application of shear-warp to stereo rendering. We first discuss briefly the shear-warp volume rendering scheme, and then propose a stereo shear-warp algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Shear-warp rendering</head><p>For parallel projection, the main steps of shear-warp volume rendering are:</p><p>(1) Preprocessing the dataset, including pre-computing normals, opacities, and a shading lookup table.</p><p>(2) Transforming the volume so that the viewing direction is parallel to a main axis. Processing slices perpendicular to this main axis in a front-to-back order. Jumping opaque pixels, and skipping empty voxels by marching along the intermediate image scanlines and the voxels simultaneously.</p><p>(3) Shading, re-sampling, and compositing the voxels that are not skipped. (4) Warping the intermediate image onto the final image. The reasons that shear-warp rendering achieves fast speed include performing pre-computation, accessing the memory consecutively, directly warping the low resolution image into the high resolution image, bi-linear interpolating slices instead of tri-linear interpolating the volume, and adopting view-dependent sampling rate.</p><p>On the other hand, the performance of shear-warp is closely related to the property of the dataset and the opacity transfer function. More specifically, since image quality is decided by the volume resolution through a 2D warp, it does not improve with the increase of the image resolution. Unfortunately, even with a very smooth transfer function, this 2D warp can not generate a high quality image. The complete proof of this claim is out of the scope of this paper, and here we only outline the general steps. We first accept the basic assumption of volume rendering that the input signal is band-limited and that the original signal is properly sampled. In other words, the continuous signal represented by the volume can theoretically be perfectly reconstructed. We then assume that simple density accumulation, instead of complex non-linear composition, is used for image rendering. Therefore, the Fourier slice projection theorem <ref type="bibr" target="#b11">[12 ]</ref> can be applied. The theorem states that the projection of the 3D data volume in a certain view direction can be obtained by extracting a 2D slice perpendicular to that view direction out of the 3D Fourier spectrum, and inverse Fourier transforming it. Suppose that the resolution of the original volume is N 3 ; the resolution of the slice extracted from the spectrum can be (√ 3N ) 2 when the viewing direction is π /4 to one of the main plane. Thus, the highest frequency of the projected image can be √ 3 times the highest frequency in the volume. As a result, the image resolution should be at least √ 3 of the volume resolution. When the complex nonlinear composition is incorporated, the required image resolution should be even higher. Another place where inaccuracy is introduced for shear-warp is the viewdependent sampling distance. For parallel rendering of uniform grids, the sampling distance along π /4 viewing direction is √ 3 of that along π /2 viewing direction. Again, we can prove that the sampling distance along π /4 viewing direction should be at least as high as that along π /2 viewing direction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Stereo Shear-warp</head><p>There are several methods,based on the shear-warp approach, of generating both the left-image and the rightimage in one pass by trading speed for quality. Conventional shear-warp can be first applied for the rendering of the left-image; then sampling points are appropriately re-projected onto the intermediate rightimage. Special attention must be paid to using early ray termination for the right-image. A more accurate approach is to linearly interpolate the left-eye sampling points for the generation of the right-image. In this section, we describe how to apply the segment composition scheme for stereo shear-warp. In the discussion, we assume that both the left-rays and the right-rays are perpendicular to the same volume slices in the sheared object space. When this condition is not satisfied, several solutions are proposed. <ref type="figure" target="#fig_6">Figure 4</ref> illustrates the relationship between the viewing direction and the volume coordinate system. Assume that the left-ray direction is (α 1 , β 1 ) and the right-ray direction is (α 2 , β 2 ). Note that the translation between the left-image and the right-image origins does not affect the discussion below. The shear factor for the nth slice, starting from the nearest slice most perpendicular to the viewing direction, can therefore be calculated as :</p><formula xml:id="formula_5">(11)      V left = −ndz( cos α 1 cos β 1 sin β 1 , sin α 1 cos β 1 sin β 1 , 1) V right = −ndz( cos α 2 cos β 2 sin β 2 , sin α 2 cos β 2 sin β 2<label>, 1)</label></formula><p>.</p><p>Since the angle between the left-ray and the right-ray is φ ,</p><formula xml:id="formula_6">V left •V right |V left ||V right | = cos φ yielding: (13) cos β 1 cos β 2 cos(α 1 − α 2 ) + sin β 1 sin β 2 = cos phi. Therefore, (14) α 1 − α 2 ≤ φ and β 1 − β 2 &lt; φ .<label>(12)</label></formula><p>Without loss of generality, we assume that β 1 ≥ β 2 and </p><formula xml:id="formula_7">(x + ndz cos α 1 cos β 1 sin β 1 , y + ndz sin α 1 cos β 1 sin β 1 , z + ndz).<label>(15)</label></formula><p>The projection of v x,y,z onto the left-image is:</p><formula xml:id="formula_8">(16) P l = (x, y)</formula><p>and the projection of v x,y,z onto the right-image is:</p><formula xml:id="formula_9">P r = (x + ndz( cos α 1 cos β 1 sin β 1 − cos α 2 cos β 2 sin β 2 ), (17) y + ndz( sin α 1 cos β 1 sin β 1 − sin α 2 cos β 2 sin β 2 )).</formula><p>In other words, the offset between the left-eye projection and the right-eye projection is the same for all the sampling points on the same slice. Let:</p><formula xml:id="formula_10">(18)      C x = cos α 1 cos β 1 sin β 1 − cos α 2 cos β 2 sin β 2 C y = sin α 1 cos β 1 sin β 1 − sin α 2 cos β 2 sin β 2 . since a 1 − a 2 ≤ φ : (19) C 2 x + C 2 y ≤ ( sin(β 1 − β 2 ) sin β 1 sin β 2 ) 2 + 2( cos(β 1 − β 2 ) − cos φ sin β 1 sin β 2 ) Let (20) φ 1 = π /4 − (β 1 − β 2 ) since β 1 ≥ π /4, C 2 x + C 2 y ≤ ( sin(π /4 − φ 1 sin π /4 sin φ 1 ) ) 2 + 2( cos(π /4 − φ 1 ) − cos φ sin π /4 sin φ 1 ) ) (21) = 1 sin 2 φ 2 + 2 − ( 4 cos φ √ 2 ) 1 sin φ 2 .</formula><p>Clearly, the right of Inequation 22 achieves maximum value when φ 2 = π /4 − φ . If we assume that φ = 5 o , three times bigger than recommended, then, This states that on the average, we can re-project the lefteye composition result of at least five slices onto the rightimage when the image sampling distance is equivalent to the volume sampling distance. Since the actual φ is usually much smaller, a higher acceleration rate can be achieved through segment composition.</p><p>The key idea of stereo shear-warp is thus to apply the conventional shear-warp for the left-image, but re-project the composition result of several left-eye slices to the rightimage. To assure the correct early ray termination, a left-eye intermediate image scanline and the corresponding right-eye intermediate image scanline are marched simultaneously with the voxel scanline. Only when a pixel on both of the scanlines is opaque is the corresponding voxel skipped. This process is illustrated in <ref type="figure" target="#fig_9">Figure 5</ref>. Note that in <ref type="figure" target="#fig_9">Figure 5</ref>, there are three different ways to process a non-transparent voxel. The first is simply to composite on the left-eye pixel when the corresponding right-eye pixel is opaque. The second is to composite with the right-eye pixel when the left-eye pixel is opaque and the left-ray is terminated earlyi. The third way is to composite on the left-eye pixel, but only re-project and composite on the right-eye pixel when the integer right-eye re-projection offsets (δ x, δ y ) are changed. Since C x and C y in Equation 18 are constants, these changes can be detected by two additions and comparisons for each slice.</p><p>Compared to the ray-by-ray order stereo ray casting, stereo shear-warp further simplifies right-image calculations because of the constant offsets for each slice, as illustrated in <ref type="figure" target="#fig_9">Figure 5</ref>. Balanced images can be generated by placing the viewpoint in the middle-eye, applying the conventional shear-warp algorithm, and re-projecting the middle-eye results onto both the left-image and the right-image. Since the slices are processed in a front-to-back order, early ray termination for both the left-rays and the right-rays can be applied. By using this middle-eye algorithm, the angle between the middle-ray and both the left-ray and the rightray is reduced to half the angle between the left-ray and the right-ray. As a result, the length of a segment on the middle-ray is doubled.</p><p>The algorithm discussed above works only when both the left-rays and the right-rays are parallel to the same main axis in the sheared object space. When this condition is not satisfied, a simple solution is to separately render the left-image and the right-image under such situations. However, since the angle φ between the left-eye and righteye viewing direction is very small, we can assume that  both the left-rays and the right-rays are perpendicular to the same volume slice, and continue to apply the above algorithm with little sacrifice of the sampling distance. The maximum enlargement of the sampling distance is 108% at the worst case when φ is 5 o . When the middle-eye algorithm is used, the enlargement is even smaller. It can be proved that by following an appropriate scanline order, correct slice composition can still be achieved.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Results</head><p>We hav e implemented the segment composition scheme as outlined in Section 3, together with the stereo shear-warp algorithm. All the experiments were conducted on a Silicon Graphics High Impact, equipped with one 250MHZ R4400 processor and 128MB of RAM.</p><p>The implementation of segment composition is based on the high quality volume ray casting of the public domain VolVis system, <ref type="bibr" target="#b2">[3]</ref> developed at Stony Brook. <ref type="figure" target="#fig_1">Figure  6</ref>(top) presents the rendering of a negative potential of a high potential iron protein using the segment composition scheme. The resolution of the dataset is 66 × 66 × 66; the image size is 256 × 256. We set the angle between the lefteye and the right-eye viewing directions to be 1 o , and the maximal voxel opacity in the data to be 0. 1. The total rendering time for the stereo pair is 8. 61 sec. For comparison, <ref type="figure" target="#fig_1">Figure 6</ref>(bottom) presents the stereo pair generated by rendering the datasets separately from the left-eye and the right-eye view points using standard ray casting. The rendering time is 8. 31 sec for the left-image, and 8. 52 sec for the right-image. The timesaving V is therefore 97%.</p><p>The performance of segment composition is closely related to the translucency of the datasets. Generally, if a dataset is mostly opaque, T r will be smaller because of the early ray termination. For example, in <ref type="figure" target="#fig_1">Figure 6</ref> no left rays are terminated early. If we increase the maximal voxel opacity in the data to be 0. 5, 27% of the left-rays are early terminated. The total rendering time for both the leftimage and right-image using segment composition is 7. 98 sec. The time for separately rendering left-image and rightimage is 7. 20 and 7. 31 sec, respectively, and T r is 89%.</p><p>Our implementation of the stereo shear-warp volume rendering algorithm is based on the public domain VolPack volume renderer package. <ref type="bibr" target="#b8">[9]</ref> For comparison, we use the human head dataset enclosed in the package. <ref type="figure" target="#fig_10">Figure 7</ref> presents the shear-warp rendering of the MRI scan of a human head. The resolution of the dataset is 128 × 128 × 84. The maximal voxel opacity has been set to be 1. 0, and the opacity threshold has been set to be 0. 95. For rendering, the volume has been pre-classified and shaded, which maximizes the rendering speed. The image size is 256 × 256, and the angle between the left-eye and the right-eye viewing direction is one degree.  <ref type="figure" target="#fig_10">Figure 7</ref>(bottom) presents the stereo pair generated by rendering the datasets separately from the left-eye and the right-eye viewpoints using conventional shear-warp. The rendering time is 131ms for the leftimage and 144ms for the right-image, respectively. The timesaving S r is therefore 60%.</p><p>One of the reasons that T r is low is that our stereo shearwarp does not save time on 2D warping. For large datasets, the 2D warping time can usually be ignored. However, for small datasets such as the MRI head in this example, warping can take a significant portion of the time. The 2D warping time for the left-image and the right-image in the <ref type="figure" target="#fig_10">Figure 7</ref>(top) is 41ms and 38ms, respectively; and that for the left-eye image and right-image in <ref type="figure" target="#fig_10">Figure 7</ref>(bottom) is 43ms and 43ms, respectively. If we exclude the time for warping, the timesaving V is 79%. This warping-excluded timesaving is generally irrelevant to the resoultion of the datasets.</p><p>Another reason that T r is relatively low is that the transfer function has been assigned so that the volume is mostly opaque. If we set the maximal voxel opacity to be 0. 2, the total time for rendering using stereo shear-warp is 429ms, while the warping time is 41ms and 44ms, respectively. The time for separately rendering the left-image and rightimage is 340ms and 354ms, respectively, while the warping time is 42ms and 42ms, respectively. The V is 75%, and the warping-excluded V is 85%.</p><p>In all the experiments performed, many parameters are precomputed. For example, generally the most timeconsuming step of volume rendering, on-the-fly shading, has been replaced by pre-shading and table lookup on-thefly. The result is the speedup of volume rendering. On the other hand, timesaving V for the right-eye image is much higher if these volume rendering parameters are calculated on-the-fly. The reason is that the shaded left-eye sampling points are directly re-projected to generate the right-eye image.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Conclusions and Future Work</head><p>In this paper, we hav e presented new volume ray casting techniques for generating high quality stereoscopic images by using segment composition and linearly-interpolated reprojection. Stereo volume rendering criteria are proposed to evaluate the fast stereo rendering algorithms. Existing volume rendering accelerators are discussed, and specifically, a new stereo shear-warp volume rendering has been designed. The efficiency of our algorithms are mathematically proved. Our experiments have presented a from 79% to 97% saving for the generation of the second image in a stereo pair. Compared to the previous algorithm, much higher acceleration rates have been achieved.</p><p>Perspective projection is inherent to stereo rendering. The idea of re-projecting the sampling points of the left-rays onto the right-image can be directly applied to perspective projection. Segment composition is still valid, but the calculation becomes more complicated. For perspective shear-warp, each volume slice has different shear and scale factors for the left-image and the right-image, and a more complicated scanline marching scheme must be designed. However, the basic algorithm is still similar to that of <ref type="figure" target="#fig_9">Figure 5</ref>. Nevertheless, the timesaving V for perspective projection is expected to be lower than that for parallel projection. Further research has to be conducted in this area.</p><p>Fast stereo volume rendering with high quality for both images is still an open problem. The main reason is that the complicated color composition requires paticular distribution of the sampling points. For example, the rendering time of ray casting is basically decided by the number of sampling points. Unfortunately, if N sampling points are needed to generate a single-eye image, it is impossible to find N + o sampling points satisfying the uniform distribution requirement on both the left and right rays, where o is a small number compared to N . The solution we are working on is to design new algorithms specifically for stereo volume rendering. We are also designing algorithms to apply the fast stereo rendering to recursive volumetric ray tracing. <ref type="bibr" target="#b15">[16]</ref> Another research direction is to apply the same idea of fast stereo volume rendering to fast animation. <ref type="figure" target="#fig_1">Figure 6</ref>: Fast stereo r endering of a negative potential of a high potential iron protein. top a stereo p air generated using segment composition, bottom the same stereo p air generated using the standard r ay casting. <ref type="figure" target="#fig_10">Figure 7</ref>: Fast stereo shear-warp rendering of an MRI head. top a stereo p air generated using fast stereo shear-warp volume rendering, bottom the same stereo p air generated using the standard shear-warp rendering.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Segment re-reprojection.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>( 6 )</head><label>6</label><figDesc>x sr = n.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Early ray termination. illustrated in</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>( 2 )</head><label>2</label><figDesc>For each remaining left-ray from right to left: (a) For the nth sampling point on the ray, generate the right-eye sample values as: R_Sample (c,α ) = Sample (c,α ) × (1 − Ray[n]. weight) +Ray[n]. (c, α ) × Ray[n]. weight. (b) Re-project the right-eye sampling points onto Ray[n]. pixel. (c) Ray[n]. weight = 1 − Ray[n]. weight Ray[n]. pixel = Ray[n]. pixel − 1 Ray[n]. (c, α ) = Sample c,α</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 3 :</head><label>3</label><figDesc>Zero order vs. linear interpolation. segment are opaque, the segment is skipped.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 4 :</head><label>4</label><figDesc>Relation between viewing rays and volume coordinate system. β 1 ≥ π /4. Then as in Section 3, we use the zero-order interpolation on the right-image. For a point v x,y,z on a left-ray in the volume coordinate system,</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>C 2 x + C 2 y</head><label>2</label><figDesc>≤ 0. 03676944. In other words, (23) C x ≤ 0. 19175359 and C y ≤ 0. 19175359.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head></head><label></label><figDesc>voxel run non−opaque image pixel run w1 : normal marching for left−eye image w2: re−projecting to right−eye image pixel point by point w3: re−projecting to right− pixel using segment composition δ : integer offsets in x and y directions</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 5 :</head><label>5</label><figDesc>Scanline marching for stereo shear-warp.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 7 (</head><label>7</label><figDesc>top) presents the result of the stereo shear-warp rendering. The total rendering time is 188ms. For comparison,</figDesc></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.">Acknowledgments</head><p>This work has been partially supported by the National Science Foundation under grants CCR-9205047 and MIP-9527694 and by the Department of Energy under the PICS grant. The high potential iron protein in <ref type="figure">Figure 6</ref> is courtesy of Scripps Clinic, La Jolla, CA, and the MRI head in <ref type="figure">Figure 7</ref> is included in VolPack.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Stereoscopic Ray Tracing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Adelson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Hodges</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Visual Computer</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="127" to="144" />
			<date type="published" when="1993-12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Fast Stereoscopic Images with Ray-Traced Volume Rendering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Adelson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">D</forename><surname>Hansen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Symposium on Volume Visualization</title>
		<imprint>
			<date type="published" when="1994-10" />
			<biblScope unit="page" from="3" to="9" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">VolVis: A Diversified Volume Visualization System</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Avila</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kaufman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Pfister</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Silva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Sobierajski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Visualization&apos;94 Proceedings</title>
		<imprint>
			<date type="published" when="1994-10" />
			<biblScope unit="page" from="31" to="38" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Rendering Volumtetric Medical Image Data on a SIMD-architecture Computer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Cameron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Undrill</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Third Eurographics Workshop on Rendering</title>
		<meeting>the Third Eurographics Workshop on Rendering<address><addrLine>Bristol, UK</addrLine></address></meeting>
		<imprint>
			<biblScope unit="page" from="135" to="145" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Stereoscopic Display for Design Visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Hodges</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mcwhor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Image Communication</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="3" to="13" />
			<date type="published" when="1991-11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Time-Multiplexed Stereoscopic Computer Graphics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Hodges</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer Graphics and Application</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="20" to="30" />
			<date type="published" when="1992-03" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A Study of the Effecttiveness of Stereo Imaging Truth or Dare: Is Stereo Viewing Really Better?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">F</forename><surname>Babbs</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">M</forename><surname>Chelberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Pizlo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">J</forename><surname>Delp</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SPIE Proceedings 2177a: Stereoscopic Displays and Applications V</title>
		<imprint>
			<date type="published" when="1994-02" />
			<biblScope unit="page" from="211" to="222" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">The Applications of Transport Theory to Visualization of 3D Scalar Data Fields</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Krueger</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1991-08" />
			<biblScope unit="page" from="397" to="406" />
		</imprint>
	</monogr>
	<note>Computer in Physics</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Fast Volume Rendering Using a Shear-Warp Factorization of the Viewing Transformation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Lacroute</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Levo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Graphics Proceedings, Annual Conference Series, ACM SIGGRAPH</title>
		<imprint>
			<date type="published" when="1994-07" />
			<biblScope unit="page" from="451" to="458" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Display of Surfaces from Volume Data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Levo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer Graphics and Applications</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="29" to="37" />
			<date type="published" when="1988-05" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">A Hybrid Ray Tracer for Rendering Polygons and Volume Data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Levo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer Graphics and Applications</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="33" to="40" />
			<date type="published" when="1990-03" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Fourier Volume Rendering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Malzbender</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Tr ansactions on Graphics</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="233" to="250" />
			<date type="published" when="1993-07" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Cube --A Scalable Architecture for Real-Time Volume Rendering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Pfister</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kaufman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM Volume Visualization Symposium</title>
		<imprint>
			<date type="published" when="1996-10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Compositing Digital Images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Porter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Duff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Graphics (SIGGRAPH&apos;84 Proceedings</title>
		<imprint>
			<date type="published" when="1984-07" />
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="253" to="259" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Data Parallel Volume Rendering as Line Drawing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Schroder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Stoll</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1992 Workshop on Volume Visualization</title>
		<meeting>the 1992 Workshop on Volume Visualization</meeting>
		<imprint>
			<date type="published" when="1992-10" />
			<biblScope unit="page" from="25" to="32" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Volumetric Ray Tracing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Sobierajski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">E</forename><surname>Kaufman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Symposium on Volume Visulization</title>
		<imprint>
			<date type="published" when="1994-10" />
			<biblScope unit="page" from="11" to="18" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Visual Performance with Monoscopic and Stereoscopic Presentation of Identical Three-Dimensional Visual Tasks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Silverstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SID International Symposium Digest of Technical Papers</title>
		<imprint>
			<date type="published" when="1990-05" />
			<biblScope unit="page" from="359" to="362" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
