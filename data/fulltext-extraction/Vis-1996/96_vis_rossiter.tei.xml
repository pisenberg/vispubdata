<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/pisenberg/grobid/grobid-0.6.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A System for the Complementary Visualization of 3D Volume Images using 2D and 3D Binaurally Processed Sonification Representations</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Rossiter</surname></persName>
							<email>frossiter@ie.cuhk.edu.hk</email>
							<affiliation key="aff0">
								<orgName type="department">The Department of Information Engineering</orgName>
								<orgName type="institution">The Chinese University of Hong Kong</orgName>
								<address>
									<settlement>Shatin, Hong Kong</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wai-Yin</forename><surname>Ng</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">The Department of Information Engineering</orgName>
								<orgName type="institution">The Chinese University of Hong Kong</orgName>
								<address>
									<settlement>Shatin, Hong Kong</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">A System for the Complementary Visualization of 3D Volume Images using 2D and 3D Binaurally Processed Sonification Representations</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2021-02-19T20:34+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
				<p>Typically, feedback from analysis of three-dimensional volume image structures are presented in the visual domain. This ignores the potential for complementary analysis of feedback in the aural domain. This paper presents a system in which visualization of a volume image may be enhanced through representation of the voxel structure by a sound sequence (termed a &apos;sonification&apos;) in which a sequence of sound signals is generated by the mapping of voxel values to pitch, amplitude, timing and other acoustic parameters according to the design of the selected sound instrument(s). Stereo audio or spatial audio processing techniques are employed to enhance the perception of the representative sonification as eminating from the visual loci of the associated voxel.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Currently, feedback from analysis of 3D volume images are themselves presented in the visual domain. Consequently, the potential for information feedback in other sensory domains, particularly sound, is ignored. Feedback presented in the acoustic domain in conjuction with visually presented feedback may serve to enhance the effectiveness of the analysis task. This paper discusses a system which has been developed to support the visualization of 3D volume images through the generation of representative sound sequences whose parameters are adapted for voxel representation and are further processed so that their aurally perceived loci corresponds to their visually perceived loci.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Aural Feedback and Sonification</head><p>There are clear indications that sound constitutes an extremely important medium for the conveyance of day-to-day information. For example, the sound of a scream immediately conveys the impression of danger; the sound of an alarm urges the need for immediate action. It has also been scientifically demonstrated that sound information presented in combination with visual information can greatly enhance an information analysis task. For example, in one study it was concluded that the subjects in their study of auditoryvisual speech recognition achieved recognition scores in the region of 90% when presented with information in combined audio and visual presentation, compared to 30% to 40% for visual data in solitude <ref type="bibr" target="#b0">[1]</ref>.</p><p>Further projects have explored the use of sound for the analysis of data (i.e., <ref type="bibr" target="#b1">[2]</ref>, <ref type="bibr" target="#b2">[3]</ref>, <ref type="bibr" target="#b3">[4]</ref>). A good overview of the potential advantages (and disadvantages) of the use of sonification in the field of visualization is presented in <ref type="bibr" target="#b4">[5]</ref>. Two conclusions drawn from these projects are that (i) the aural presentation of data can provide a useful aid in some contexts, and (ii) the presentation of information in the acoustic domain is most effective when provided in conjunction with information presented in the visual domain.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">System Overview</head><p>The system has been developed using the C language on a Silicon Graphics Indigo2. For efficient graphical control over system parameters, the 'XForms' graphical user interface (GUI) software is employed, with which a GUI for data control and sonification has been developed. The sound generation language called 'Csound' <ref type="bibr" target="#b5">[6]</ref> has been adopted for audio control. This latter package enables the user to write scripts for precise control over the generation of digital sound. These scripts are interpreted at run-time by the Csound program, and are used for audio output, which may be achieved in real-time. The visualization software called 'BOB' (which stands for 'Brick Of Bytes', the headerless voxel file format which the program reads) which was developed by the Minnesota Supercomputer Center for the Graphics and Visualization Lab of the Army High Performance Computing Research Centre has been adopted as a base for the development and exploration of sonification for voxel volume visualization. The program has been expanded and is now called 'BobSon' (dually implying that the development is a sonification extension of the Bob software and may perhaps also be regarded as a 'son of bob'). Each of the three packages is public domain, and both the XForms and Csound packages have readily-available pre-compiled binaries for a very wide range of platforms, facilitating easy porting of the system at a later date. An simplified overview of the system structure is shown in figure 1.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">System Usage</head><p>The system is currently intended for use in the context of a single user, with eye position at approximately that of the level of the centre of the VDU image. Aural feedback is presented to the user via stereo headphones. The complete volume or an arbitrary subset may be selected for the sonification process. During the sonification procedure, the volume image is traversed, the constituent voxel elements analysed, and for each voxel an instance of voxel sonification generated. By default, traversal through the volume takes place from left to right in terms of the user perspective, although the user may select a negatively or positively moving mode of analysis along any of the three axes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Sonification Design</head><p>Parameters which are employed for sonification include fundamental frequency, amplitude, timing parameters, and potentially other parameters according to the design of the instrument(s) selected for sonification. For the first two parameters a linear or logarithmic mapping may be applied, as fundamental frequency and amplitude are perceived logarithmically. Each parameter may be employed in isolation or in combination with each other. A list of audio generation instruments which have been constructed in the Csound audio design language is presented for user selection. The list includes a number of musical instruments (such as a clarinet and a piano), purely synthetic sound instruments (such as a buzz sound and a sine wave), and instruments which function only to replay a pre-recorded soundfile (such as the record-ing of a spoken message or alarm). The range of instruments may be further expanded by the user, or public domain instrument designs adopted. As Csound scripts are interpretted during run-time, no system re-compiling is required in order to expand the selection of instruments. For example, in one project the difference between two data values was perceived as a beat frequency when each variable was mapped to the frequency of a sine wave <ref type="bibr" target="#b6">[7]</ref>. This method or others derived from an analysis of the phenomenon of sound (i.e. <ref type="bibr" target="#b7">[8]</ref>) could be adopted and extended for use in volume sonification by creating appropriate audio generation scripts in the Csound language.</p><p>Each sonified voxel audio event that is generated is further processed such that, as presented to the user via headphones, the sonification elements are perceived as emanating from the same apparent loci in 3D space as that of the visual loci of the source voxel.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Audio Positioning</head><p>Two degrees of audio positioning are available. In the first mode, the audio signals that result from voxel sonification are simply treated to provide a basic sense of dimension. The second processing mode produces a much more effective result, but at the cost of a greater degree of processing and therefore time required.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Stereo audio</head><p>The stereo positioning of sonified voxel instances is achieved by the generation of an appropriate signal balance for left and right headphone speakers. When a sonification signal is generated which corresponds to a particular loci in the 3D volume image, the distance of the loci along the x-axis (from the user perspective) is used as the reference from which to calculate the relative balance of left and right signals. The amplitude of the auralization signal is attenuated in order to reflect the distance of the apparent loci within the volume image to the user.</p><p>Spatial audio In this mode, sonified voxel instances are processed with binaural spatialised sound techniques in order to more effectively increase the perception of the audio signal as eminating from the associated 3D loci within the volume image. In order to achieve this, a processing mechanism was derived which operates by time delaying the left and right ear signals exactly according to the distance from the source to ear, in addition to scaling the volume of each signal in proportion to the inverse square of the distance. An optional level of forward/backward positioning is also supported. In order to enhance the audio cues required for this, the volume of the sound is attenuated according to direction, and high frequencies subsequently attenuated according to the relative position of the virtual sound source to the head. These emulate the effects of sound wave diffraction around the head.</p><p>Each sonified voxel instance is aurally processed according to one of these two modes. Sliders are provided so that the perceived scale of the aural representation may be adjusted to match the perceived visual scale of the rendered </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Illustrations</head><p>A region of voxel elements indicating a region of malignant tissue may be presented to the user in the visual domain as a highlighted area, and optionally in the acoustic domain as an sonification sequence. The content and 3D position of the tissue is therefore presented both visually and aurally. Using the combination of visual and aural cues, and by interactively altering the sonification parameters and the selection of sub-regions of the entire image volume, the user may interactively navigate through and analyse the volume area requiring investigation. The system may be further complemented by the use of stereoscopic glasses to enhance the illusion of a true 3D image.</p><p>A simple illustration of volume sonification using only one sound instrument follows. If the user maps voxel values both to fundamental frequency and note duration ensuring all other parameters remain constant, traversal of a volume consisting of a few scattered voxel elements of generally low value and a central mass consisting of a range of relatively high value voxels will be presented as silence interspersed with brief low-frequency sounds as the sonification analysis sweeps across the volume, until the central mass is reached, whereupon the sonified representation will be perceived to 'slow down' as a dense collection of many high pitched notes are generated. Each sound instance is perceived as emanating from the corresponding visualization loci. As the area of analysis moves past the central entity, the stream of sonified voxel entities would return again to a few interspersed notes of relatively low pitch.</p><p>However, for more effective representation it is common to employ a number of sound instruments, selecting each for acoustic representation of a particular, although not neces-sarily unique, voxel range. This is illustrated in figure 2 in the context of a classified volume, and in figure 3 there is an illustration of the complete system in use.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Large Volume Analysis</head><p>One advantage of the system lies in the analysis of high volume three dimensional data sets where the size of the data is too large for efficient rendering as a single entity. An example is the recently released data for the Visible Human Project, in which digitally stored slices of a female cadaver taken at 0.33mm intervals have been made available. The size of the resulting data set is in the region of 40 gigabytes. Currently, interactive rendering and analysis of such a vast dataset outstrips the technical ability of all visualization systems. In contrast, analysis via sonification may commence immediately, as an incremental traversal of the data set is part of the mode of operation, in contrast to the complete volume analysis required prior to volume visualization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9">Conclusions</head><p>This paper has reported on a project which addresses the use of sound as a medium to complement the visualization of volume images. System structure, operation, and examples of usage have been discussed. The system would benefit from development in a number of aspects such as with the introduction of a head-tracking system so that the headphone position and orientation in 3D space can be determined thus enabling more accurate spatialized audio rendering. Development of the system continues in order to address these and other areas. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>A simplified overview of the system</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>3 Figure 2 :</head><label>32</label><figDesc>An illustration of voxel sonification volume.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>An example session, with Bob (left), Bob icol colour mapping control (middle) and BobSon sonification extension (right)</figDesc></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Benefit from visual cues in auditory-visual speech recognition by middle-aged and elderly persons</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">E</forename><surname>Walden</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename><surname>Busacco</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Montgomery</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Speech and Hearing Research</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="431" to="437" />
			<date type="published" when="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Using sound to extract meaning from complex data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Scaletti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">B</forename><surname>Craig</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the SPIE Conference</title>
		<meeting>the SPIE Conference<address><addrLine>San Jose, California</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1991" />
			<biblScope unit="volume">1459</biblScope>
			<biblScope unit="page" from="207" to="219" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">InfoSound: An Audio Aid to Program Comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">H</forename><surname>Sonnenwald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Gopinaht</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">O</forename><surname>Haberman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">M</forename><surname>Keese</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">S</forename><surname>Myers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd Hawaii International Conference on System Sciences</title>
		<meeting>the 22nd Hawaii International Conference on System Sciences</meeting>
		<imprint>
			<date type="published" when="1990" />
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="541" to="546" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Aural signatures of parallel programs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Jackson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Francioni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th Hawaii International Conference on System Sciences</title>
		<meeting>the 25th Hawaii International Conference on System Sciences</meeting>
		<imprint>
			<date type="published" when="1991" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="218" to="229" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">An illustrated analysis of sonification for scientific visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Minghim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">R</forename><surname>Forrest</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE Visualization &apos;95</title>
		<meeting>IEEE Visualization &apos;95</meeting>
		<imprint>
			<date type="published" when="1995" />
			<biblScope unit="page" from="110" to="117" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">The Csound Users Reference Guide</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barry</forename><surname>Vercoe</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1992" />
			<pubPlace>Media Lab, MIT: USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">On the sensations of tone as a physiological basis for the theory of music</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Helmholtz</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1877" />
			<publisher>Dover</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
	<note>2nd edition (1885</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">A system for three-dimensional acoustic &quot;visualization&quot; in a virtual environment workstation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">M</forename><surname>Wenzel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Fisher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">K</forename><surname>Stone</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">H</forename><surname>Foster</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE Visualization &apos;90</title>
		<meeting>IEEE Visualization &apos;90</meeting>
		<imprint>
			<date type="published" when="1990" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
