<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/pisenberg/grobid/grobid-0.6.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Simple 3D Glyphs for Spatial Multivariate Data</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Camilla</forename><surname>Forsell</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Seipel</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mats</forename><surname>Lind</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Dept. of Information Science</orgName>
								<orgName type="institution">Uppsala University Uppsala</orgName>
								<address>
									<country key="SE">Sweden</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">Dept. of Mathematics, Natural-and Computer Science</orgName>
								<orgName type="institution">University of Gävle</orgName>
								<address>
									<settlement>Gävle</settlement>
									<country key="SE">Sweden</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="department">Dept. of Information Science</orgName>
								<orgName type="institution">Uppsala University</orgName>
								<address>
									<settlement>Uppsala</settlement>
									<country key="SE">Sweden</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Simple 3D Glyphs for Spatial Multivariate Data</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2021-02-19T18:51+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>I. 3.6 [Computer Graphics]: Methodology and techniques: Interactive techniques multidimensional visualization</term>
					<term>perception</term>
					<term>3D glyphs</term>
				</keywords>
			</textClass>
			<abstract>
				<p>We present an effort to evaluate the possible utility of a new type of 3D glyphs intended for visualizations of multivariate spatial data. They are based on results from vision research suggesting that our perception of metric 3D structure is distorted and imprecise relative to the actual scene before us (e.g., [1]); only a class of qualitative properties of the scene is perceived with accuracy. These properties are best characterized as being invariant over affine but not Euclidean transformations. They are related, but not identical to, the non-accidental properties (NAPs) described by Lowe [2] on which the notion of geons is based [3]. A large number of possible 3D glyphs for the visualization of spatial data can be constructed using such properties. One group is based on the local sign of surface curvature. We investigated these properties in a visualization experiment. The results are promising and the implications for visualization are discussed.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Information technology rapidly changes the ways in which information can be accessed and visualized. New sensor technology can provide us with near-real-time geo-spatial observations and measurements of the real world. This technology improves our ability to discover, access and integrate data and offer the promise of better and quicker decision making, as well as the potential to improve monitoring, detection and planning activities over a wide range of areas. The critical question is how to transform such raw data into visualizations that can be effectively and efficiently used as optimal support. In other words, to help users' discover the task-relevant information available and enable them to do it quickly and correctly. Information obtained from a specific geographical location is often of a multivariate nature. Consider, for instance, meteorology. Here, one location produces data of several kinds such as temperature, humidity, wind (speed and direction) and atmospheric pressure. If one also includes simulation programs (for possible course of events), the available amount of data to a decision maker often becomes immense. When visualizing multidimensional information, the human perceptual system sets a limit on the number of dimensions in a data set that can be meaningfully shown. Several ideas to extend the number of dimensions have been suggested over the years by, for instance: Chernoff <ref type="bibr" target="#b3">[4]</ref> utilizing simple depictions of faces, Chambers, Cleveland, Kleiner and Tukey <ref type="bibr" target="#b4">[5]</ref> using "star plots" and by Picket and Grinstein <ref type="bibr" target="#b5">[6]</ref> using stick figures. Such visualizations could also be placed in a grid structure illustrating multivariate geospatial data. One further option is to explore the inherent nature of human perception and somehow use a 3D spatial layout for the data. However, as pointed out by Lind, Bingham and Forsell <ref type="bibr" target="#b0">[1]</ref>, 3D depictions, regardless of the type of display technique employed, must be used with discretion. A large set of 3D relationships are simply not perceived by humans although our subjective experience leads us to believe that our visual system delivers a complete and veridical representation of the scene before us. Research on human spatial vision shows that an observer's judgments of metric 3D shape and relationships contain large errors relative to the actual structure of the observed scene <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b6">[7]</ref> and <ref type="bibr" target="#b7">[8]</ref>. Only structural properties in 3D left invariant by affine mappings are reliably perceived. Examples of such structural relationships are the relative sign of the curvature on a surface, the parallelism of lines or planes and relative distance intervals in parallel directions. Thus, the perceptual representation of 3D shape is likely to be based on such qualitative aspects of structure. All remaining aspects (of structure) are inherently ambiguous. From a visualization perspective, this implies that we can expect users to misinterpret or overlook some, even largely significant, relations in most 3D visualizations.</p><p>As we see it, these results do not imply that 3D visualizations should not be used, only that care must be taken when employing them. Because qualitative aspects of 3D structure are reliably perceived, conveying nominal or ordinal relationships by means of 3D structure should be an interesting option to investigate. In this vein we have looked at the possibility of constructing 3D glyphs that could depict ordinal data by using the sign of curvature of surface elements. In 2D a line segment could represent three ordinal levels by having a negative curvature, no curvature or a positive curvature. By employing this in two orthogonal directions, a small square surface patch in 3D could show three ordinal levels for two independent variables. The surface patch will then, of course, have one of nine different shapes ( <ref type="figure" target="#fig_0">Figure 1</ref>). Using shape to depict ordinal data goes completely against the recommendations by McKinlay <ref type="bibr" target="#b9">[10]</ref>,</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IEEE Symposium on Information Visualization 2005</head><p>October 23-25, Minneapolis, MN, USA 0-7803-9464-X/05/$20.00 ©2005 IEEE.</p><p>something he considered should be avoided and being the worst possible choice. However, we still found merit in our idea for three reasons. First, the sign of curvature, and therefore also the resulting shapes, ought to be easily distinguishable from one another for theoretical reasons. Second, although each shape represents an integral impression of the two variables, they were, both to us and to other viewers of our sample visualizations, quite possible to visually investigate variable by variable. Perhaps this is because that only three levels for each variable are used. Third, the sign of curvature, at least to us, has an intuitive coupling to a three-level ordinal scale. To be useful in a real application, three levels are probably not enough, at least most of the time, and it is probably desirable to show more than two variables per grid cell. We therefore looked into possibilities of extending our idea to incorporate more levels and more variables per surface patch. To find more levels we looked at the possibility of using infinite curvature at the negative and positive side of curvature and in this manner produce five levels per variable. By using a discontinuity, an edge, this can be accomplished ( <ref type="figure" target="#fig_1">Figure 2</ref>). A surface having an edge or not is also a qualitative property invariant over affine transformations, so it should be easy to perceive as well. Furthermore we think that these levels are easy to perceive as an ordered sequence, especially if a difference in height is superimposed. Height, naturally, is not invariant over affine transformations and thus not reliably perceived, but because it is used redundantly it will aid the perceiver, at least in some cases.</p><p>To add one more variable we covered each surface with a color chosen from a sequence based on increasing luminance and differences in hue. A fourth, nominal, variable was also added by the use of different textures on the colored surface patches.</p><p>Before implementing these ideas in a larger scale, however, we wanted to empirically investigate their merit, doing it in an incremental fashion. Therefore, we started with the original and simpler three-level idea with an added three level color-coding to get a visualization with three ordinal variables each having three levels. Here we report the results of this first investigation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">TO EVALUATE THE EFFICIENCY OF VISUALIZATIONS OF SPATIAL MULTIVARIATE DATA</head><p>The effectiveness of visualizations will largely be determined by the number of fixations a viewer needs in order to extract the relevant information contained in the visualization. This, in turn, is largely determined by the number of repeated re-fixations between two objects in the scene that is needed to perceive the structural differences between them. Elsewhere <ref type="bibr" target="#b10">[11]</ref>, we have investigated the differences in orientation between two 2D squares needed for certain discrimination utilizing only one fixation per square. The results show that, even if humans are able to perceive orientation differences as small as 5 to 6 degrees under more or less unlimited viewing conditions <ref type="bibr" target="#b11">[12]</ref>, when restricted to one fixation per object the orientation difference needed is roughly 25 degrees. This means that if we use orientation of a square as a carrier of data in a visualization and only used two values represented by a square and a 45 degree rotated square (a diamond), a user of this visualization could scan through it using only one fixation per square. On the other hand, if several values were used resulting in orientation differences of only 10 degrees or so between the squares, a user would spend a considerably longer amount of time changing his or her fixation back and forth between the squares to determine if they were different. It could reasonably be argued that the longer time needed is compensated by the higher degree of accuracy obtained in the reading. However, you could also argue that, given our results, orientation differences are not suitable for more levels than two and that other forms of data representations should be considered in this case. Undoubtedly, though, an important metric to consider when discussing the effectiveness of visualizations is the amount of refixations needed for a user to discover the relevant information. A similar approach was used by Lightner <ref type="bibr" target="#b12">[13]</ref> when analyzing the effectiveness of visualizations. She used a simple model to calculate the minimum time needed for a user to successfully investigate a visualization:</p><formula xml:id="formula_0">( ) 1 230 200 min − × + = a T</formula><p>where a is the number of areas that needs to be fixated in the visualization to solve the task and Tmin is the minimum expected time, in msec, to solve this task. The logic behind the model is that a fixation usually lasts for around 200 msec and that an average saccade (movement of the eye to fixate a new point) takes about 30 msec. These figures are, of course, only approximations. A fixation can last up to 500 msec <ref type="bibr" target="#b13">[14]</ref> and the time it takes for a saccade is dependent on the amount of rotation of the eyeball needed. The model can therefore be simplified further into: without any significant loss of resolution. However, even as such it can be extremely useful and we will use it to predict and interpret our empirical findings below.</p><formula xml:id="formula_1">4 min a T = ; min T in seconds</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">EXPERIMENT</head><p>To evaluate the effectiveness of our proposed simple 3D glyphs we created a judgment situation to be performed as a free-scan visual search task. The data visualized were hypothetical meteorological data. There were three variables defined in each of 144 (12 by 12) grid cells symmetrically positioned over a square geographical area. The three variables were temperature, precipitation and wind speed. Each variable was categorized into three levels: "below average", "average" and "above average". Two of these variables, temperature and wind speed, were mapped onto the curvature of a surface patch for each grid cell. This surface patch would take on one of the nine possible shapes defined by the sign of curvature in the x and y directions ( <ref type="figure" target="#fig_0">Figure  1</ref>). The third variable, precipitation, was mapped onto each surface patch by the use of color. A value of "below average" resulted in a dark blue surface patch; the value "average" resulted in a medium gray surface patch; and the value "above average" resulted in a bright red surface patch.</p><p>The 144 grid cells that could contain surface patches were clustered into 9 (3x3) main areas, each comprising 16 (4 x 4) individual grid cells ( <ref type="figure">Figure 6</ref>) The observer's task in all conditions was to identify which of these nine main areas contained at least four grid cells having surface patches of a specified kind called "target patches". Only one main area met this condition per trial. All other individual grid cells had randomly chosen surface patches among the 27 possible types.</p><p>Forsell and Lind (in preparation) studied the relative discriminability of these surfaces. Most of the surfaces could be discriminated from the others during only one fixation per surface, even under extremely poor viewing conditions (top-view, monocular viewing, depth only conveyed by cast shadows). A slightly lower performance, however, was found with the two saddle shaped surfaces under these conditions. For this experiment, we therefore chose one of the "easy" surfaces and one of the "difficult" surfaces as target patches -the "top" and one of the "saddles". In the terminology of the task these were described to the observers as "high risk for fire" and "high risk for contamination". High risk for fire was defined as temperature above normal, precipitation below normal and wind above normal. In our visualization this was characterized as red saddles (a 'difficult" surface) in a specific orientation. High risk for contamination was defined by all three variables having levels above normal. In our visualization red tops (a "simple" surface) characterized this condition.</p><p>The display used in the experiment, given our set up, subtended a visual angle of about 36 degrees squared. Because the display was horizontal and because the observers looked at it from one side, the visual angle subtended by the display was of course slightly different close to the observers as compared with further away from the observers. In that we used 12 by 12 individual grid cells, each grid cell subtended a mean visual angle of about 3 by 3 degrees. The visual acuity of the human visual system is very nonuniformly distributed over the visual field. Already at 10 degrees from the fovea we can only resolve 1/5 the detail compared with the fovea <ref type="bibr">[15 p. 59]</ref>. A reasonable approximation is therefore that our surfaces patches can be discriminated from one another with certainty within a solid angle in the visual field having a diameter of somewhere between 5 and 10 degrees. A separate experiment would be needed to determine a more exact value. This means that somewhere between 1 and 4 grid cells can be searched per fixation. Because our task was such that the search could be terminated once an area with four target patches was found, and random placement was used for target areas, the mean number of surface patches needed to be searched was 144/2 = 72. Using these numbers in our simple model, we can estimate that a minimal search time for finding the target area in the display is between [(72/4) / 4] = 4.5 sec and [(72/1)/4) = 18.5 sec. If the time needed to find the target area is longer than this range it is a strong indication that a non-negligible amount of refixations is needed. Our prediction for the experiment, given our theoretical considerations, is however that the time we obtain for our observers to solve a trial will be within the 4.5 to 18.5 sec range, indicating that only few re-fixations are necessary.</p><p>A common method of depicting grid cell values in geographical information systems is to color grid cells according to some color scheme. If there is more than one variable defined over the geographical area, these systems often force you to look at them one at a time using the same color scheme. As a simple control condition, we therefore introduced a visualization that contained three layers over our square display surface. Each layer consisted of the same 12 by 12 grid cells as in the 3D condition but here no surface patches were added. Instead, each layer was assigned to a variable and the color scheme used for one variable in the 3D condition was employed for each of the layers, i.e., for all of the three variables, which could then be viewed one at a time by switching layers. To improve the usability of this condition, three specially designated keys were used so that each layer could be addressed with the press of a single button. <ref type="figure" target="#fig_2">Figure 3</ref> shows a trial in the 3D condition while <ref type="figure" target="#fig_4">Figure 4</ref> depicts the layers of the 2D condition, here shown adjacent to one another.  of approximately 36 degrees. The matrix was divided into 9 main areas, each with 16 grid positions. Each grid position was assigned a set of values that defined its shape and color. In one of the nine areas four grid cells contained a target surface patch. All other grid cells contained randomly sampled surface patches from the 27 possible combinations (3 x 3 x 3). There was one parameter controlling the random sampling; no other main area, of the nine, contained more than three target surface patches.</p><p>The images were rendered using Open GL. A polka dot texture with two shades of the designated color was added to each surface patch to provide one further cue to 3D structure.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>3.1.2</head><p>Apparatus and viewing conditions The physical display system used was an integrated retroprojection display system in which the projection screen is oriented horizontally. This approach provides a viewing metaphor of a virtual world that is perceived as a bird's eye view. The display environment has a square screen area of 0.8 by 0.8 meters. It can simultaneously project the content of eight co-located and interactive views and thus provide four independent observers with individual stereoscopic imagery. For our purposes, we used only one of these views (two projectors). The visible pixel resolution of each projection image on screen was 768 by 768 pixels. The separation of stereo image pairs was accomplished by using polarizing filters in front of the image projectors. The display system was driven by a small cluster of four commercial off-the-shelf computers interconnected with a Giga-Ethernet local area network. The computers were equipped with Nvidia QuadroFX graphics cards. For the purpose of head position tracking a magnetic tracking system, connected to a separate computer, was used (the Ascension Flock of Birds).  The observers were standing in front of the screen, which meant they were viewing the stimulus from an upright position ( <ref type="figure" target="#fig_5">Figure  5</ref>). They wore polarizing glasses with a position sensor attached. Movement along the side of the screen was allowed. Thus motion parallax was introduced to further enhance the stereoscopic illusion. A keyboard used for responses was placed in front of the observer. Dim lighting was used in the room.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>3.1.3</head><p>Experimental design The study was designed as a five-factor mixed factorial design with three within-subject factors: viewing condition (2D/3D), target-glyphs (top/saddle) and block of trials. The between-subject factors were two, order of presentation of viewing condition and order of presentation of target-glyphs. The experiment was performed over four separate sessions, each consisting of three blocks of three trials. In order to prevent effects of any use of search strategies, these blocks were balanced with respect to target placement. The presentation order of the four separate sessions was counterbalanced using a Latin-square procedure. Half of the observers started with one of the two 3D conditions while the other half started with one of the two 2D conditions. This design yielded a total of 36 trials per observer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>3.1.4</head><p>Procedure Before the start of the experiment the observers were shown printed, black and white wire-frame images representing the nine possible glyphs. They were extensively instructed about the geometric definition of the different types of curvature and orientation depicted. The experimenter explained the task, demonstrated the response apparatus to the observer and then the experiment commenced. The observers were told that their response times would be measured and that they should therefore respond as quickly as possible while maintaining high accuracy. Before each of the four separate sessions the observers were given written instructions about the task and completed a short block of practice trials. Response time was measured from the onset of the stimulus to the response. The sequence of trials was self-paced, and the observers controlled the screen by pressing the space bar when they wished a trial to begin. A blank screen was immediately presented after a response and at the start of each session. Directly after the space bar was pressed the search image appeared.</p><p>In the 2D sessions with three search images to be judged and compared within each trial the observer alternated between these images with keys dedicated to display each one at a time. The three images were labeled in their top left corners as an aid for the observer to keep track: 1 for temperature, 2 for precipitation and 3 for wind speed respectively. The alphabetical keys Z, X and C were used for navigation and relabeled with 1, 2 and 3 respectively. The observer's task in any individual trial was to search the image (3D) or the images (2D) and find the correct target area as specified by the target state described earlier.</p><p>Stimuli were displayed until a response was given. This completed a trial and a blank screen reappeared. The response keys used were the numbers 1 to 9 on the numerical keyboard and chosen such that each key corresponded to one area on the stimulus display. Each area corresponded to the numerical keyboard with identical numbering, starting from the bottom of the display to the top and from left to right, creating a logical mapping between stimulus and response apparatus ( <ref type="figure">Figure 6</ref>). To initiate a new trial the observer pressed the space bar. Errors and reaction times for each trial were recorded. No feedback was provided 3.1.5</p><p>Observers Twelve male observers, aged between 24 and 43 years old, took part in the experiment. All but one were students or staff of the Swedish National Defense College (SNDC). They had no prior knowledge of the purpose of the experiment or the specific hypotheses tested. All observers had normal or corrected to normal vision. They received a small compensation for taking part in the experiment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>3.1.6</head><p>Results First, we analyzed the error data in the 3D condition. Errors were scarce; the group mean value was as small as 0.42 errors per 18 trials and the largest amount of errors for any observer was 2 out of the 18 trials, suggesting that the search times are good representatives of performance. The group mean value for the search times in the 3D condition was 9.12 sec, which is well within the range we specified for efficient performance.</p><p>Next, we turned to the comparison with the 2D condition. To begin with we compared the error rates. Because this type of data cannot be considered ideal for parametric testing, an exact test was used. First, the number of errors for the whole 18 trials in the 2D condition was determined for each observer; then the corresponding numbers for the 3D condition were compared. As stated above, the group mean value for the 3D condition was 0.42 errors per 18 trials. For the 2D condition this value was 1.75. The exact test, i.e. going through all 4096 permutations of values between the two conditions and for all observers, revealed that the probability ("two-tailed") of finding this large, or larger, absolute difference in the group mean value by chance is less than 0.024 . We therefore conclude that, for our observers, the 2D condition produces more errors.</p><p>Because reaction time data are typically not normally distributed, we employed a logarithmic transformation of these data before further statistical testing. We also collapsed each observer's data over each set of three trials because such a set is less contaminated by possible response preferences in that it contains a balancing of the occurrence of the correct position within the grid. A mixed ANOVA was carried out using a decision criterion of 0.05 and with the order conditions as between-subjects factors and 2D/3D, target type and block as within-subjects factors. No main effect of the ordering factors was <ref type="figure">Figure 6</ref>. The numerical keyboard was used as the response apparatus and the observers were instructed to consider the areas in a trial display as having identical numbering. Hence, when the target of a search was located in area nine the observer pressed key "9", etc.</p><p>found. The 3D times were significantly faster than the 2D times (F(1,8)=787.7, p &lt; 0.0001). No significant difference was found between the two targets shapes (F(1,8)=1.499, p &lt; 0.26), nor any interaction between target shapes and the 2D/3D condition (F(1,8)=1.618, p &lt; 0.24). There was, however, a significant effect of block (F(2,16)=5.398, p &lt; 0.02). The main finding (i.e. the main effect of the 2D/3D condition) is summarized in <ref type="figure">Figure 7</ref>.</p><p>It is noteworthy that the group mean search time for a correct response in the 2D condition (57.7 sec) was more than six times longer than in the 3D condition (9.1 sec). We do not suggest that this is a fair comparison. A more logical comparison would be to use a 2D glyph intended for multivariate data. However, in our study it served the purpose of comparing our visualization to the one actually used at the SNDC where the study was conducted. The primary goal of this study was to determine whether observers would make efficient use of the 3D structural information we made available, i.e. to discriminate between the 3D glyphs and identify the correct main target area among the alternatives. The results of the experiment suggest that our observers were indeed able to do make this discrimination. In this richer visual environment no difference was found between the "top" and the "saddle", something we found earlier under much more impoverished conditions. Our conclusion is that the results clearly demonstrate that affine 3D properties can be successfully used in some 3D visualizations of multivariate data and that further examinations of the perception of 3D glyphs and their potential use as elements for visualization are worthwhile. It should be noted that most of the non-accidental properties (NAP:s) identified by Lowe <ref type="bibr" target="#b1">[2]</ref>, in a quest for view-point invariant cues to 3D shape can be expressed as structural properties invariant over affine transformations. Therefore, our proposed shapes are relatives of the geons proposed by Biederman [e.g., 3] to be the building blocks of mental representations of objects. However, other structural relationships than NAPs could also be utilized. For instance, the midpoint between two points on a straight line (bisection) is a property that is invariant over affine transformations. We will continue to investigate the possible use of such structural properties and their role in creating efficient 3D visualizations and hope to reach a point soon where recommendations for use outside of the lab can be made. <ref type="figure">Figure 7</ref>. The main effect of the 2D/3D condition. Please note the search time values are logarithmic. The group mean value for the 2D condition is 57.7 sec and the group mean value for the 3D condition is 9.1 sec.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>The nine shapes as defined by the sign of curvature.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 .</head><label>2</label><figDesc>Five levels of potentially easily discriminable 2D curvatures.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 .</head><label>3</label><figDesc>A screen shot from the 3D condition. Target state for search is "high risk for fire". Here it is characterized by four red saddles in one of two possible orientations within the same area. The target is located in the middle area of the bottom row as illustrated.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>As described above, each stimulus display was comprised of a 12 by 12 matrix of grid cells creating a total of 144 grid positions with a square size of 0.8 by 0.8 meters subtending a visual angle</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 .</head><label>4</label><figDesc>Screen shots from the 2D condition. The target state for search is, as inFigure 3, "high risk for fire". The target area is located in the top right corner. It contains four grid cells in corresponding locations in the three separate layers, with the variables colored as defined by the target state: red for temperature (top display), blue for precipitation (middle display) and red for wind speed (lower display).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 5 .</head><label>5</label><figDesc>The experimental set up.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head></head><label></label><figDesc>2D vs 3D (transformed values); LS Means Current effect: F(1, 8)=787.71, p=.00000Effective hypothesis decomposition Vertical bars denote 0.</figDesc></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">Camilla.Forsell@dis.uu.se 2 SSL@hig.se<ref type="bibr" target="#b2">3</ref> Mats.Lind@dis.uu.se</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGEMENTS</head><p>This research was in part sponsored by project AQUA at the Swedish National Defense College in Stockholm, Sweden.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mats</forename><surname>Lind</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">P</forename><surname>Bingham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Camilla</forename><surname>Forsell</surname></persName>
		</author>
		<title level="m">Metric 3D structure in visualizations. Information Visualization</title>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="51" to="57" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Lowe Perceptual Organization and Visual recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><forename type="middle">G</forename></persName>
		</author>
		<imprint>
			<date type="published" when="1984" />
			<pubPlace>Stanford, CA</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Stanford University</orgName>
		</respStmt>
	</monogr>
	<note>Unpublished doctoral dissertation</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Recognition-by-components -A theory of image understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Irving</forename><surname>Biederman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Review</title>
		<imprint>
			<biblScope unit="volume">94</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="115" to="147" />
			<date type="published" when="1987" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Using faces to represent points in k-dimensional space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Herman</forename><surname>Chernoff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Statistical Association</title>
		<imprint>
			<biblScope unit="volume">68</biblScope>
			<biblScope unit="page" from="361" to="368" />
			<date type="published" when="1973" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Graphical methods for data analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><forename type="middle">M</forename><surname>Chambers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><forename type="middle">S</forename><surname>Cleveland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Kleiner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><forename type="middle">A</forename><surname>Tukey</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1983" />
			<pubPlace>Wadsworth, Belmont, CA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Iconographic displays for visualizing multidimensional data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ronald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><forename type="middle">G</forename><surname>Picket</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Grinstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1988 IEEE Conference on Systems, Man and Cybernetics</title>
		<meeting>the 1988 IEEE Conference on Systems, Man and Cybernetics</meeting>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="415" to="519" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">The visual perception of 3-D shape from multiple cues: Are observers capable of perceiving metric structure?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><forename type="middle">T</forename><surname>Todd</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Farley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Norman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Perception &amp; Psychophysics</title>
		<imprint>
			<biblScope unit="volume">65</biblScope>
			<biblScope unit="page" from="31" to="47" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Distortions of three-dimensional space in the perceptual analysis of motion and stereo</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><forename type="middle">T</forename><surname>Todd</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><forename type="middle">S</forename><surname>Tittle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Farley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Norman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Perception</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="75" to="86" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">The visual perception of 3D shape</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><forename type="middle">T</forename><surname>Todd</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Trends in Cognitive Science</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="115" to="121" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Automating the design of graphical presentations of relational information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jock</forename><forename type="middle">D</forename><surname>Mackinlay</surname></persName>
		</author>
		<editor>Stuart K. Card, Jock D. Macinlay and Ben Schneiderman</editor>
		<imprint>
			<date type="published" when="1999" />
			<publisher>Morgan Kaufman Publishers</publisher>
			<pubPlace>San Francisco, CA</pubPlace>
		</imprint>
	</monogr>
	<note>Information Visualization: Using vision to think</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Effective visualizations for large displays -The role of transsaccadic memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mats</forename><surname>Lind</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Camilla</forename><surname>Forsell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Allard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the VIIP 2003 conference</title>
		<meeting>the VIIP 2003 conference<address><addrLine>Benalmadena, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Probing the spatial frequency spectrum for orientation sensitivity in stochastic textures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Terry</forename><surname>Caelli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Bevan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Vision Research</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="39" to="45" />
			<date type="published" when="1983" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Model testing of users&apos; comprehension in graphical animation: The effect of speed and focus areas</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nancy</forename><forename type="middle">J</forename><surname>Lightner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Human-Computer Interaction</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="53" to="73" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Perception as purposeful inquiry. Behavior and Brain Sciences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julian</forename><surname>Hochberg</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999" />
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="619" to="620" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Information Visualization: Perception for design</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><surname>Ware</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000" />
			<publisher>Morgan Kaufman Publishers</publisher>
			<pubPlace>San Francisco, CA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
