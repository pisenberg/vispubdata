<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/pisenberg/grobid/grobid-0.6.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Information Visualization and Proxemics: Design Opportunities and Empirical Findings</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mikkel</forename><forename type="middle">R</forename><surname>Jakobsen</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yonas</forename><forename type="middle">Sahlemariam</forename><surname>Haile</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">SÃ¸ren</forename><surname>Knudsen</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kasper</forename><surname>Hornbaek</surname></persName>
						</author>
						<title level="a" type="main">Information Visualization and Proxemics: Design Opportunities and Empirical Findings</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2021-02-19T19:08+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Proxemics</term>
					<term>information visualization</term>
					<term>user study</term>
					<term>large displays</term>
					<term>user tracking</term>
					<term>movement</term>
					<term>orientation</term>
					<term>distance</term>
				</keywords>
			</textClass>
			<abstract>
				<p>People typically interact with information visualizations using a mouse. Their physical movement, orientation, and distance to visualizations are rarely used as input. We explore how to use such spatial relations among people and visualizations (i.e., proxemics) to drive interaction with visualizations, focusing here on the spatial relations between a single user and visualizations on a large display. We implement interaction techniques that zoom and pan, query and relate, and adapt visualizations based on tracking of users&apos; position in relation to a large high-resolution display. Alternative prototypes are tested in three user studies and compared with baseline conditions that use a mouse. Our aim is to gain empirical data on the usefulness of a range of design possibilities and to generate more ideas. Among other things, the results show promise for changing zoom level or visual representation with the user&apos;s physical distance to a large display. We discuss possible benefits and potential issues to avoid when designing information visualizations that use proxemics.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>INTRODUCTION</head><p>Information visualization uses interactive graphics to amplify cognition <ref type="bibr" target="#b4">[5]</ref>. It can improve many aspects of dealing with large sets data: Visualizations help explore and navigate large information spaces <ref type="bibr" target="#b40">[40]</ref>, analyze and make discoveries in high-dimensional data <ref type="bibr" target="#b44">[44]</ref>, and discuss data within on-line communities <ref type="bibr" target="#b52">[52]</ref>.</p><p>Most information visualizations-commercial products and research prototypes alike-are designed for a setting where the user interacts using a mouse on a desktop-sized display. Recent research has explored how visualizations should be designed for non-desktop settings <ref type="bibr" target="#b26">[27]</ref>, in particular for large high-resolution displays. Examples of visualizations designed for this setting include using tangible input controllers <ref type="bibr" target="#b20">[21]</ref>, sensing body movements as implicit navigation input <ref type="bibr" target="#b8">[9]</ref>, and adapting interaction techniques for large displays <ref type="bibr" target="#b18">[19]</ref>.</p><p>We extend this work by using the notion of proxemics to identify design opportunities. Proxemics studies the relation between people as it is expressed in the use of space <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b14">15]</ref>. Compared to early work on proxemics, recent work <ref type="bibr" target="#b12">[13]</ref> as well as this paper extend the notion of proxemics to describe also the relation between people and objects (often user interfaces). In research on human-computer interaction (HCI), proxemics has for instance been used to design interaction techniques that change user interface layout based on the user's position <ref type="bibr" target="#b2">[3]</ref>, and to study orientation and distance among devices and doctors in neurosurgery <ref type="bibr" target="#b30">[31]</ref>. Previous research has also demonstrated how body orientation and position can be used with visualizations: for implicit interaction with ambient displays <ref type="bibr" target="#b53">[53]</ref> and for coarse 3D navigation in microseismic visualizations <ref type="bibr" target="#b31">[32]</ref>. We build on previous work to explore how the notion of proxemics can be applied to interaction with information visualization.</p><p>The opportunities for proxemics in information visualization are manifold. First, it may be used to adapt visualizations based on the users' position and orientation relative to the display. Second, it could use movements in front of a display to have visualizations follow users' movements or blend as two users get close. Third, we could augment users' backing away from a large display by even further zooming out or abstracting the visualizations. Many other uses of proxemics in information visualizations may be imagined.</p><p>This paper explores in particular design opportunities for information visualization based on movement and distance to large high-resolution displays. We focus on using movement and distance because earlier work has emphasized physical navigation as important when using large displays <ref type="bibr" target="#b1">[2]</ref> and in group work <ref type="bibr" target="#b19">[20]</ref>. We explore spatial relations only between a single user and visualizations; exploring relations between people would provide more opportunities, but is beyond the scope of this paper. The opportunities are illustrated with a design space and with sketches; the opportunities focus both on supplementing other input techniques and on replacing them. We also show how earlier work that has not explicitly used the notion of proxemics (e.g., <ref type="bibr" target="#b53">[53]</ref>) can be understood through proxemics and potentially benefit from its analytic framework. We select a subset of design opportunities to implement and test in three user studies: (1) navigation by physical movement, (2) querying coordinated views by movement, and (3) adapting visual representations to distance. We do so to generate design ideas, but also to provide initial data on the usefulness of combining information visualization and proxemics. Our approach is to ground some opportunities in empirical data rather than to give an exhaustive systematic review of the opportunities or to present indepth data on a single case.</p><p>We contribute (a) an initial analysis of using proxemics for information visualization, (b) prototypes of information visualizations that adapt based on tracking of their users, and (c) an evaluation of a set of proxemic visualizations. The argument is that proxemics may offer promising design opportunities for non-desktop visualizations; we think such opportunities are valuable to both researchers in visualization and to designers for large displays.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">RELATED WORK</head><p>The term proxemics is due to Edward T. Hall <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b14">15]</ref>, who used it to describe the study of "how man unconsciously structures microspace-the distance between men in the conduct of daily transactions, the organization of space in his houses and buildings, and ultimately the layout of his towns". Among other contributions, he related physical and social distance in a set of four zones, from intimate space (less than 46cm between people) over personal and social space to public space (more than 3.7m). Hall discussed how social, gender, and cultural factors may mediate this relation. Much research has built on and extended Hall's work, applying it for instance to design <ref type="bibr" target="#b48">[48]</ref>, human-robot interaction <ref type="bibr" target="#b33">[33]</ref>, and HCI. Proxemics is increasingly used in HCI, both as (1) a notion to understand and analyze collaboration and interaction, and (2) a notion to drive the interaction among users and devices. The first point has been studied in computer supported collaborative work (CSCW), where the relation between physical distance and perception of social distance has been a key issue <ref type="bibr" target="#b38">[38]</ref>. Applications in CSCW include a study by Hawkey et al. <ref type="bibr" target="#b16">[17]</ref> investigating the relation between proxemics and collaboration success with a large wall display. Stretching proxemics to include the relation among users and devices has led to several descriptive accounts. Mentis et al. <ref type="bibr" target="#b30">[31]</ref> studied orientation and distance among devices and doctors in neurosurgery using notions of proxemics. Jakobsen and Hornbaek <ref type="bibr" target="#b19">[20]</ref> used proxemics to describe interaction in front of a large display.</p><p>The second point above has in particular been inspired by Marquardt and Greenberg's notion of proxemic interactions <ref type="bibr" target="#b12">[13]</ref>. Their work extends the notion of proxemics so that it pertains not only to relations among persons, but also to relations among people, digital devices, physical objects, and the environment. They consider five categories of proxemic dimensions particularly for ubiquitous interaction (which is relevant more broadly for HCI):</p><p>â¢ Distance, the physical distance between entities, either given as a continuous measure or relative to discrete zones. In Lean and Zoom, for instance, semantic zooming is based on the user's distance to a laptop screen <ref type="bibr" target="#b15">[16]</ref>. â¢ Orientation concerns which direction a person (or other entity)</p><p>is facing. This has been used, for instance, to adapt presentation software to different views depending on which way the presenter is facing <ref type="bibr" target="#b12">[13]</ref>. â¢ Movement concerns the changes in distance and/or orientation over time. For instance, personal territories on tabletops can be adapted when one user approaches another user's space <ref type="bibr" target="#b25">[26]</ref>. â¢ Identity concerns distinguishing between entities. For instance, a display may respond differently to the movement of a mobile phone than to the movement of a person <ref type="bibr" target="#b12">[13]</ref>. â¢ Location describes the place of interaction. A simple instance is the presence of a person in a room. A recent toolkit helps detect and react to these dimensions <ref type="bibr" target="#b28">[29]</ref>.</p><p>Some earlier work has used related types of movement to control interaction, without explicitly using the notion of proxemics. Vogel and Balakrishnan <ref type="bibr" target="#b53">[53]</ref> presented a display system that supported a smooth transition from public use of the display, through implicit interaction at a distance, to up close, personal interaction. Ju et al. <ref type="bibr" target="#b22">[23]</ref> presented an interactive whiteboard that sensed users' distance to the board for switching between modes of using a whiteboard, in particular between authoring and ambient use. Marquardt describes gradual engagement in providing connectivity, information exchange and transfer as a function of proximity <ref type="bibr" target="#b27">[28]</ref>. Marquardt and colleagues give many other examples of using movement to control interaction <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b29">30]</ref>. Work on navigating virtual environments has also used movement and orientation extensively. For instance, Souman et al. <ref type="bibr" target="#b49">[49]</ref> described how an omnidirectional treadmill allowed participants to walk in any direction they wanted in a virtual environment, with information in a head-mounted display being updated based on their walking. Such work differs from the focus of the present paper in that movement and orientation are used to generate a view (say, in a head-mounted display) of a virtual environment corresponding to a particular position of the user's head; instead, we consider uses of proxemics data for changing visualizations of abstract data.</p><p>The present paper uses the notion of proxemics to drive innovation in interaction with information visualizations. One reason to do so is that the notion of proxemics might help generate interesting designs, beyond those described in the literature. Another reason is that to our knowledge, no paper has attempted to relate proxemics and visualization, despite the interest in using visualization on large displays and despite the frequent observation that movement <ref type="bibr" target="#b1">[2]</ref> and orientation <ref type="bibr" target="#b3">[4]</ref> play key roles in interaction with large displays. A third reason is that even though earlier papers have used movement to control interaction (e.g., Vogel and Balakrishnan <ref type="bibr" target="#b53">[53]</ref>) they rarely relate to the information visualization literature and do not evaluate visualization tasks. Thus we proceed to discuss the relation between proxemics and visualization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">DESIGN OPPORTUNITIES</head><p>As argued earlier, a variety of design opportunities may be generated from the proxemics literature. Because these have not been explored in relation to visualization activity, we next discuss some design opportunities, in part summarized as the design space in <ref type="table">Table 1</ref>. Some of the opportunities are implemented as prototypes and evaluated in user studies in the second half of the paper (marked #1, #2, or #3). Some entries in the table are blank, either because they are uninteresting or because we have yet to come up with, or find in the literature, a compelling example.</p><p>The design space is organized from established views of key characteristics of proxemics and information visualization. To this end we choose categories from earlier work on proxemics <ref type="bibr" target="#b12">[13]</ref> and information visualization tasks <ref type="bibr" target="#b17">[18]</ref>.</p><p>Many alternatives to these two choices exist. With respect to <ref type="table">Table 1</ref>. Combinations of information visualization tasks (excerpt from <ref type="bibr" target="#b17">[18]</ref>) and proxemics categories (excerpt from <ref type="bibr" target="#b12">[13]</ref>). The symbols #1, #2, and #3 refers to design opportunities that are tested in the second part of the paper. proxemics, earlier definitions emphasize different types of proxemics. We chose the much cited taxonomy of proxemic interaction <ref type="bibr" target="#b12">[13]</ref>, because it captures the relations between people and devices like large displays, which is our focus. With respect to information visualization, a host of alternative models exist. We decided against relatively low-level models (e.g., <ref type="bibr" target="#b0">[1]</ref>) of information visualization because we think the initial promise of proxemics is to enhance higher-level tasks. We also decided against taxonomies focused on data (e.g., <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b46">46]</ref>), because they were not easy to combine with the proxemics taxonomy. Finally, the visualization taxonomy that we have chosen to use integrates many aspects of earlier work; for example, it includes most of the tasks in Shneiderman's task by data type taxonomy <ref type="bibr" target="#b46">[46]</ref>. The resulting design space does not include all categories: Some categories of proxemics are less applicable to single-person interaction with visualizations on a large display (e.g., Identity). Similarly, some visualization tasks do not map well to proxemics (e.g., Derive). The opportunities presented here are intended to generate design ideas. Other possibilities exist that could be more useful than the examples given here.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Information visualization task</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Visualize</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Distance</head><p>Viewing distance is important in using information visualization on large high-resolution displays: Users can step back to get an overview and to navigate <ref type="bibr" target="#b1">[2]</ref> or to see patterns in data <ref type="bibr" target="#b7">[8]</ref>. However, earlier work has mainly studied visualizations that do not change with user's distance. Vogel et al. <ref type="bibr" target="#b53">[53]</ref> is a notable exception as they adapt visual representations and interaction modes to discrete distances. Below we describe how visualizations can adapt and react to distance for particular visualization tasks. Visualize. Visual encodings may dynamically change with the user's distance. Different tasks can thus be supported at varying distances, for instance by showing aggregate representations at a distance and details up-close. This is illustrated in <ref type="figure" target="#fig_5">Fig. 5</ref>, where each level of aggregation is associated with a discrete distance zone. The alternative, combining the data in the same static visualization, can overload the display and potentially overwhelm the user. While we focus on the spatial distance between user and display, the distance of a hand-held display relative to a large display could similarly be used for semantic zooming in for instance graph visualizations <ref type="bibr" target="#b50">[50]</ref>.</p><p>Filter. Distance can be mapped to a variable so as to allow filtering out data. For instance, adapting the generalized fisheye view <ref type="bibr" target="#b10">[11]</ref> to a large display, could help users focus on the most relevant items; items are filtered out if they have a degree-of-interest below a threshold that grows proportional to the user's distance to the display. More interesting items can be made prominent or shown in detail at a distance while other items are aggregated.</p><p>Select. Distance can influence the scope or granularity of user's selections. For instance, Peck et al. <ref type="bibr" target="#b39">[39]</ref> describe a multi-scale interaction technique that "chang[es] the user's scale of interaction depending on their distance from the current object(s) of interaction."</p><p>Navigate. One possible visualization that adapts to large displays for supporting multi-scale navigation is focus+context: As the user steps back from the display, selected elements in focus can be magnified to remain a constant size in the user's field-of-view; in effect those elements are brought closer together, for instance to support comparison, while the context is demagnified (rather than being filtered out as done in the generalized fisheye view discussed above). This is illustrated in <ref type="figure" target="#fig_0">Fig. 1</ref>. Another idea is to relate distance to zoom-level, so that when a user moves away from the display, the zoom level changes.</p><p>Coordinate. Whereas most coordination of views relies on explicit actions <ref type="bibr" target="#b37">[37]</ref>, the user's distance to particular views in the display may provide for implicit coordination. For instance, depending on which graphs that are close to the user, they could automatically become linked, so that data points selected in the one are highlighted in the others.</p><p>Organize. Views can be reorganized for interaction when the user stands within touching distance of the display (e.g., showing data views and widgets for dynamic querying), while larger overviewproviding views are shown when the user is standing at a distance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Orientation</head><p>Although orientation is used extensively in virtual reality, it is rarely seen in research on information visualization. Research that comes close are the ChairMouse <ref type="bibr" target="#b8">[9]</ref>, which used the users' rotation on a chair to control cursor movement, and the study by Bezerianos and Isenberg <ref type="bibr" target="#b3">[4]</ref>, who looked at the role of angle and movement in perception on large displays. Neither study used orientation to adapt visualizations.</p><p>Visualize. Visual encodings that become distorted at extreme viewing angles cause problems <ref type="bibr" target="#b3">[4]</ref>. A visualization can dynamically change to a visual encoding that is more robust to extreme viewing angles, based on its orientation toward the user. Related techniques are E-conic, which dynamically corrects the perspective of windows <ref type="bibr" target="#b34">[34]</ref>, and Screenfinity, which rotates, translates, and zooms content to ease reading while users pass by large displays <ref type="bibr" target="#b43">[43]</ref>.</p><p>Sort. Ordering data helps reveal trends or clusters of values. The most common method of ordering, sorting records by one or more variables <ref type="bibr" target="#b17">[18]</ref>, could be supported by detecting the user's orientation toward a particular variable (e.g., a column in TableLens).</p><p>Select. Orientation may supplement other pointing input for selecting data points in visualizations. For instance, a user's motor space with a pointing device can map to a particular view, which is selected by changing orientation (see <ref type="figure" target="#fig_1">Fig. 2</ref>).</p><p>Navigate. Orientation may control navigation by giving additional information about the user's current focus. For instance, orientation may be used to enrich the parts of the display that the user focuses on or (as will be experimented with in study #1) to control the point around which zooming is performed.</p><p>Coordinate. Orientation can support exploration across views. For instance, body and head orientation can be used together for indicating distinct areas of interest, so that relations between data in those areas can be visualized.    Filter. The spatial relation between the user and a dynamic query slider can be used for filtering. By mapping the user's position to the slider in the display, the user can move relative to the slider in order to change the value. For instance, in <ref type="figure" target="#fig_2">Fig. 3</ref> the user's lateral position maps to a timeline: in that way, the user can move right towards the most recent data.</p><p>Sort. In study #3 we explore the use of movement to select a variable for sorting a table of data items.</p><p>Select. Movement could be used for coarse selection of a view in order to help users select data points in a visualization.</p><p>Navigate. The user's physical navigation around a large display can be further supported through view manipulations. For instance, physical navigation can be extended through movement-based zooming and panning: moving forward to zoom in and back to zoom out; moving sideways to pan. This is explored in study #1. This is related to work in virtual reality that have used omnidirectional treadmills to allow movement (e.g., <ref type="bibr" target="#b42">[42]</ref>); such studies have typically strived to make rendering of the virtual reality smooth and realistic, not to use movement to adapt interactive visualizations.</p><p>Coordinate. Selected views could move with the user's position, for instance to allow comparison across views that are otherwise too far apart to be viewed simultaneously.</p><p>Organize. Manually reorganizing visualization views, legends, and controls can be tedious, particularly on a wall-display. However, related views and legends could be automatically reorganized depending on the user's movement relative to the workspace in order to fit the user's focus in a task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Location</head><p>Visualize. Facilities for creating new visualizations could leverage contextual information from the location so that a new visualization is tailored to that particular context. Filter. Visualization views could be filtered to show different subsets of the data as the user switches between different locations.</p><p>Navigate. To aid navigation, different visualizations that are aimed at taking a broad view of the data (overview) and at specific, detailed investigations of parts of the data (details) may be anchored to different physical locations. For instance, having an overview perspective on the left part of a large display would provide the user with custom visualizations tailored for coordinating several detailed investigations going on in the right part of the display.</p><p>Organize. Different configurations of views may be shown at different locations in order to give different perspectives of the data (e.g., when the user stands near the left side of the display, the rest of the display changes to show information related to the views at that location) or to provide stations for different activities (e.g., monitoring while seated in a certain part of the room).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5">Prototyping and testing opportunities and options</head><p>The techniques that we prototype and test in the next section present a sample of the design space (see <ref type="table">Table 1</ref>) selected to probe interesting options. First, we wanted to study one of the simplest cases of linking proxemics and visualization: linking movement of the body to zooming and panning. It is unclear whether continuous or discrete measures are the most appropriate in that case, or whether to base interaction on absolute or relative movement. Second, we wanted to compare continuous measures of proximity (e.g., controlling filtering through movement) to discrete measures (e.g., levels of aggregation for discrete distances). Third, proxemics may be used to control fluid visual transitions (e.g., zooming, panning) and discontinuous changes (e.g., change encoding, linking movement to selection of variables). We wanted to see if either is more useful or more sensible when linked to proxemics data. Fourth, a potential use of proxemics data is to make things appear to be constant size (adapting for instance a graph based on distance) or in the same relative location (e.g., always near the users right arm). We wanted to explore such effects. In sections 4.1, 5.1, and 6.1, we explain the designs we have studied in detail.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">OVERVIEW OF USER STUDIES</head><p>Whereas the exploration of design opportunities has identified novel and interesting designs, it has not provided any data about the usefulness of such designs. Next, we therefore present three user studies aimed at obtaining such data. The studies aim to provide initial, qualitative data about usefulness by having participants use and compare designs. The studies are lightweight (i.e., each participant interacts for about 40 min) and formative (i.e., qualifying and developing design opportunities rather than finding a "best" option). This choice of method requires justification. The overall aim of the present paper is to explore design opportunities. We therefore decided against running a controlled experiment, as done in many evaluations of information visualizations and of proxemics <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b56">56]</ref>. Instead we wanted to gain empirical insight on a range of design possibilities. We also wanted to avoid rushing to experimentation (as warned about by Shadish et al. <ref type="bibr" target="#b45">[45]</ref> and Greenberg and Buxton <ref type="bibr" target="#b11">[12]</ref>). We decided against some of the other methodologies for evaluating information visualizations <ref type="bibr" target="#b5">[6]</ref> because they mostly assume a hi-fidelity and well-defined design or require a specific application domain, task set, or user base. The former is not the case for the combination of information visualization and proxemics, and the latter seemed to constrain finding and developing design opportunities.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Commonalities of the studies</head><p>The three user studies presented next have a common structure (see <ref type="table" target="#tab_2">Table 2</ref>). First, they all have six participants. This number is often recommended for formative user studies <ref type="bibr" target="#b36">[36]</ref> and while it gives low power (in the sense of being able to detect quantitative differences, see <ref type="bibr" target="#b6">[7]</ref>), it does allow us to gain qualitative insights about usefulness. Second, all studies use one or two combinations of proxemics/visualization and a reference interaction style. It has been shown that users generate more comments when exposed to several alternatives than to just one <ref type="bibr" target="#b51">[51]</ref>.</p><p>Third, we collect qualitative data from the studies. In addition to capturing preference data, we have at least two persons observing users while interacting: the observers take time-stamped notes that can be referenced and coupled to video recordings during analysis. Fourth, while the studies are formative, we prescribe tasks for users to solve. The idea is to ensure that they engage in demanding tasks so as to experience and be able to discuss the usefulness of the interaction styles. All tasks were adapted from previous studies of information visualizations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Participants</head><p>In all, 18 participants (4 female), ages between 23 and 37 years (M = 29.8), were recruited by word of mouth; six participants for each study.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Procedure</head><p>The procedure was similar across studies. Participants were welcomed to the study, and informed of its purpose. They were introduced to the wall-display and the interfaces, and the tasks were explained to them. Participants then completed a set of tasks with each interface. For each interface, the experimenter first explained its use and participants were given time to try using it. Participants were then given the tasks, one at a time. They were encouraged to ask questions during the experiment. After completing the last task with an interface, we asked participants about their experience with the interface they had just used, including its benefits and drawbacks. Finally, after having completed all the tasks, participants were interviewed about each of the forms of proxemic interaction provided by the interfaces.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Data analysis</head><p>Sessions were video recorded and the experimenter and one or two additional data loggers took notes. Each study was analyzed immediately following its last session using the Instant Data Analysis technique <ref type="bibr" target="#b24">[25]</ref>. For the analysis, the experimenter and the data loggers gathered in front of a whiteboard. Observations from the notes and comments from interviews were discussed. When an important issue was identified, it was written on a post-it note and put on the whiteboard. The notes were categorized into themes. Based on the clusters of post-its on the whiteboard, the most important findings were written down with clear references to the observations and any supporting video recordings. On average, the analysis session lasted around two hours.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Technical setup</head><p>Participants used a 24 megapixel display that measures 3mÃ1.3m. The display consists of 4Ã3 tiles projected from the back by 1920Ã1080 projectors. Projectors are manually aligned so as to minimize seams between tiles. The display was run by a single computer running Microsoft Windows 7. The room in which the display was set is 3.5m wide and the distance from the display to the back wall is 2.95m. For input we used a NaturalPoint OptiTrack motion capture system (www.naturalpoint.com/optitrack/) that tracks, via reflective infrared markers attached to a baseball cap, the location and orientation of the participant's head. Participants also used a wireless gyroscopic mouse. The mouse cursor was enlarged to maximum size.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">STUDY #1: NAVIGATION BY PHYSICAL MOVEMENT</head><p>The first study investigates the potential of using physical movement in the zoom+pan visualization technique.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Conditions</head><p>Three variations of a zoom+pan interface were used for navigating geographical maps. In all conditions, a Gyro mouse was used for interacting with targets in the tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.1">Absolute: Navigation by absolute movement</head><p>This interface uses a direct mapping between participants' movement and movement of the map. The user moves toward the display in order to zoom in (i.e., to see details) and away from the display to zoom out. This is illustrated in <ref type="figure">Fig. 4 (a-c)</ref>. Movement is combined with head orientation for zooming. A crosshair indicates the point where the ray cast from the cap worn by the user intersects the display, and zooming is centered on that point. Lateral movement controls horizontal panning: Moving left causes the map to move right; moving right causes the map to move left. Our initial intent was to map floor position directly to map position. However, to keep panning speed at a reasonable pace when the user is close to the display (i.e., at high zoom factors), we reduced the floor-to-map movement ratio. This restricts the panning range when close to the display. Head orientation is used for panning up and down. Pitching the cap so that the ray intersects the display plane above or below the display causes the map to pan vertically at a fixed rate.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.2">Relative: Navigation by location</head><p>In this interface, participants control zooming and panning by moving relative to a 75x75 cm rectangular region in the center of the floor, illustrated by <ref type="figure">Fig. 4 (d-f)</ref>. The map moves right when the user's body is left of the region; moves left when the user's body is right of the region. Similarly, the map zooms in when the user has stepped toward the display from the center region; zooms out when the user has stepped backward from the center. The zoom rate is inversely proportional to the zoom level so that when zoomed in to a detailed level, the zoom rate is lower. The use of head orientation for zooming and for vertical panning is similar to Absolute.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.3">Baseline: Virtual navigation using mouse</head><p>In this condition, the user operates the interface using only the gyro mouse. The interface resembles widespread mouse-operated map interfaces (e.g., Google Maps): To pan the map, the user clicks and drags the mouse opposite the panning direction (i.e., so that the map follows the mouse cursor); to zoom the map, the user rolls the scroll wheel on the mouse forward (for zooming in) or backward (for zooming out). Mid-air input techniques for zoom+pan interfaces <ref type="bibr" target="#b35">[35]</ref> allow more efficient navigation than the baseline interface we used here. However, we did not aim for performance, but rather a simpleto-use mouse-based interaction style that we expected users to be familiar with.  <ref type="figure">Fig. 4</ref>. Zooming in the two conditions that use proxemics in Study #1. In Absolute (a-c), the zoom level increases as long as the user keeps moving toward the display, and stops zooming when the user stands still. In <ref type="figure">Relative (d-f)</ref>, the zoom level increases as long as the user is within the zoom zone (e). Zooming is centered on a crosshair, which indicates the point where the ray cast from the user's head intersects the display.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Tasks</head><p>Participants performed a series of tasks using a map obtained from OpenStreetMap (www.openstreetmap.org) at different scale levels. The following types of task adapted from <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b47">47]</ref> were used:</p><p>â¢ Navigate: Participants had to navigate to a clearly marked target and click on it with the mouse. Then a new target was shown, until participants had navigated to ten targets. â¢ Trace: Participants had to trace a railway, where targets were placed close to ten selected stations. Participants had to move each of the pins onto the station using the mouse. â¢ Search: Participants were handed a description on paper of a location (e.g., "Near 'city' find 'lake'") and they had to point out the location. Participants were given three locations to search for.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Results</head><p>We present only results that relate to the use of movement and location to control navigation. In the instant data analysis, four themes emerged.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.1">Using your body for navigation was liked</head><p>Several participants said they liked controlling navigation with their body: it is a "nice concept to use your body to move" and "it is nice that you move a lot, particularly in a work environment". Reasons for this view varied. Two participants mentioned that movement was intuitive, three that movement required less effort than the mouse, and two perceived movement to be faster than using the mouse.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.2">Observed benefits and drawbacks of using body</head><p>We saw much movement in the Absolute and Relative conditions. Body movement was expected as it controlled navigation. Some observations were nevertheless surprising. One participant transformed the navigation task of finding and clicking an object at high magnification to a smooth movement from the back of the room (zoomed out) to the display (zoomed in). Several participants moved to the back of the room in preparation for receiving the next task. We noticed a lot of awkward movement. Some participants moved very slowly, some expressed uncertainty about the size of the steps to take. Also, movement of your body is difficult to use for fine-grained navigation and it is hard to stop panning as quickly as with a mouse. Some participants adopted particular movement types to deal with these limitations. Three participants leaned rather than moved to control location; in the Relative condition, two participants kept a foot in the center region while lunging forward or to the sides (one participant mentioned the similarity to dance-mat games).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.3">Movement versus location</head><p>A key difference among conditions was the use of movement for navigation versus using location for navigation. Participants were split in their preference for either technique (movement: 3; location: 2; one undecided).</p><p>Navigation by movement was well received. Two participants commented that this technique was intuitive, in particular because there was a direct relation between your movement and what happened on the screen. Another difference was the freedom to move around. With Absolute, one participant found "a lot of freedom to move all over the place"; two participants contrasted this with feeling "restricted" and unable to "move freely" with Relative.</p><p>Navigation by location was liked for several reasons. One reason was that "zooming was nice here" because one could zoom without getting too close to the screen; when using movement to zoom, participants by definition were close to the screen when they had zoomed a lot. One participant mentioned the benefit of a stable center, in contrast to navigation by movement where the display was changing much of the time. However, participants had to keep track of their position relative to the center. They described how you were "fixed to the center" and that it "requires concentration to keep track of zones".</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.4">Design ideas and variations</head><p>Several design ideas came up. Rate control was mentioned as an improvement for Relative, so that the speed at which panning and zooming was done depended on your distance to the center point. This would increase the issue of small movements causing large steps in navigation, which is why we did not implement it in the first place.</p><p>Movement did not control all aspects of navigation in Absolute or Relative. Head pitch was used to control panning up/down, which caused unintended panning when participants looked down. Participants suggested the use of alternative means for controlling panning, for instance by using gestures.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">STUDY #2: ADAPTING REPRESENTATIONS TO DISTANCE</head><p>The second study investigates the adaptation of visualizations based on the user's distance and movement.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Conditions</head><p>Two variations of a map-based visualization of real-estate data were used. The visualization allows the user to vary the visual representation of the data (individual homes or geographic areas) and to select an area for which to call up details. A diverging color scale is used to indicate how the value of an attribute, which the user can select from a menu (e.g., price per m 2 ), is above or below the mean value of that attribute.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.1">Distance-based aggregation and details on demand</head><p>This condition uses distance and movement. First, distance-based aggregation changes the visual representation based on the user's distance to the display (see <ref type="figure" target="#fig_5">Fig. 5</ref>). At less than .75m, individual homes are shown as points. As the distance increases, the representation changes to show data aggregated on geographic areas (.75m: postal districts; 1.25m: municipalities; 1.75m: regions), and using larger font sizes. Transitions between representations use alpha blending over a 20cm distance range. Second, movement-based Excentric Labeling <ref type="bibr" target="#b9">[10]</ref> gives details about homes within a selection box that follows the user's position horizontally and moves vertically with the pitch of the user's head. Third, for multi-scale interaction <ref type="bibr" target="#b39">[39]</ref>, the selection box grows in size with increasing distance and details are shown for data at higher scales: homes, districts, or municipalities. Fourth, movement-based change of color encoding. When the user is more than 2.5m away from the display, the attribute menu (shown in the top-center area of the display) responds to the user's lateral movement: Moving left or right causes an indicator to move to another attribute that will be used for color encoding.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.2">Baseline: Gyro mouse</head><p>In this condition, the user operates the interface using only the gyro mouse, that is, for changing the visual representation of home data and for selecting the area of the map for which details are shown. The mouse scroll wheel maps to distance as it is used in the other condition: scrolling the wheel forward corresponds to walking forward (and vice versa). This changes the representation, the size of the selection box, and the level of details that are shown. As feedback to the user, the four representations of home data are placed on a vertical slider in the left side of the visualization, with an indication of the representation that is currently shown. The selection box is moved with the mouse cursor (that is, while the mouse trigger button is pressed); and details about homes within the selection box remain fixed when the user stops moving the mouse cursor.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Tasks</head><p>Participants performed the following tasks, some adapted from <ref type="bibr" target="#b54">[54]</ref>, with subsets of a real-estate database:</p><p>â¢ Find the region that has the lowest average price per m 2 (or lowest average number of rooms). â¢ Find the municipality in a given region that has the highest average asking price (or largest average area). â¢ Find the home in a particular postal district that has the largest area (or smallest area). â¢ Find the postal district in a particular municipality that has the highest average price per m 2 . â¢ Find the most expensive house in two (geographically remote) municipalities.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Results</head><p>Three themes that are related to distance and movement emerged in the analysis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>5.3.1</head><p>Use of distance makes sense and "works well"</p><p>Four participants described the Distance condition as natural, intuitive, and making good sense. For instance, one said it was "natural to use the body", another that it was "intuitive to get more information in less space when up close. It works very well." In relation to aggregation of data with increasing distance, one participant said that it was nice that there was not much data when standing at the back.</p><p>Several participants seemed to change between representations with ease by moving. In particular, we observed three participants that moved back and forth repeatedly to switch between representations for solving tasks that involved relating homes or districts to municipalities. Changing representations using the mouse seemed less fluid, and participants glanced more often at the slider at the left side of the interface.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>5.3.2</head><p>Discrete distance zones versus free movement However, using distance did not work equally well for all participants. For instance, one participant said that although it was natural to move, he had to think more while moving than while using the mouse. Another said that she had to remember to stand still at a distance. One drawback, which was clear from our observations and from participants' comments, relates to the discrete distance zones: To see certain information, the user is bound to a certain distance. From our observations this was a problem for one participant in particular, who said that it is "natural to step back for overview, but then the data I want to overview disappears." In the mouse condition, this participant solved the tasks while standing noticeably farther away from the display than the other participants: He read details about individual homes from around 1.5m distance. Other participants made related comments. One said you have to get close to see details on individual homes, but then "up close, I had trouble keeping an overview of it all."</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>5.3.3</head><p>Details-on-demand too sensitive to movement</p><p>All the participants said they liked the mouse better for selecting the area to show details. One reason is that the mix of using body position and head orientation for selection was confusing. Participants suggested different ways of improving details-ondemand based on movement. Three participants said that they wanted to use their hands to "lock" the view of details or for selecting houses, when they were within reaching distance. Also, two participants suggested leaning toward the display as a way to lock the view of details. Details on proximity, or using head position relative to body position, could be a promising design variation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">STUDY #3: DYNAMIC QUERY BY MOVEMENT</head><p>The last study investigates the use of movement for attribute selection, brushing and linking, and filtering of multivariate data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Conditions</head><p>Participants used two variations of an interface containing multiple coordinated views of data about cars. The interface comprises a window containing nine scatterplots and a data table, a view showing a histogram for an attribute, and a view listing the available attributes. If the user selects an attribute from the list, the histogram for that attribute is shown and the data table is sorted by that attribute. For visualizing the histogram, the values of most attributes were binned to produce 10 bars. For attributes with less than 30 values, each value had its own bar (e.g., model year of cars spans 12 years). Histogram bars can be selected: the table is filtered to show only the corresponding data points, which are also marked red in the scatterplots. The two variants of the interface differ in the way that the user can select attributes from the list or select bars in the histogram.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1.1">Position-controlled variable selection and brushing</head><p>This condition uses distance and movement. First, the attributes in the list are mapped to discrete distance zones, 1m (the first attribute) to 2.5m (the last attribute) from the display. The user selects an attribute by moving closer or farther from the display, shown in <ref type="figure" target="#fig_6">Fig.  6 (b-c)</ref>. In the attribute list, a circle indicates the user's position relative to the attribute zones. Hysteresis tolerance is used for transitions between the zones of two variables: The user enters and exits a zone at separate distances. This helps avoid unintentional switching back and forth between two attributes. Users' sideways movement is used for brushing over bars in the histogram: The user's position along an axis parallel to the display maps to the x-axis of the histogram, see <ref type="figure" target="#fig_6">Fig. 6</ref> (a-b). One bar is selected at a time. The physical space for brushing (from the leftmost to the rightmost bar) spans 1.65m in the center of the display. To enable users to read the data while they move, the views are scaled depending on the user's distance, see <ref type="figure" target="#fig_6">Fig. 6 (b-c)</ref>. Also, the window containing the table and the scatterplots is positioned according to the user's position. The other views remained fixed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1.2">Baseline: Gyro mouse</head><p>In this condition, the interface is operated using only the gyro mouse. Attributes can be selected from the list by pointing and clicking with the mouse cursor. Histogram bars can be brushed by clicking on the bars. Views are fixed in a size corresponding to standing 1.5m from the center of the display in the Position-controlled condition.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Tasks</head><p>Participants performed five types of task adapted from <ref type="bibr" target="#b55">[55]</ref>, using a dataset with eight attributes for 406 cars <ref type="bibr" target="#b41">[41]</ref>:</p><p>â¢ Find the car that has the most power among Ford cars.</p><p>â¢ Is there a correlation between engine power and weight?</p><p>â¢ Does Dodge make more car models than other American manufacturers? â¢ Please categorize car models into two types: one consisting of cars with poor mileage and one consisting of cars with good mileage. Try to take model year into account. Which has most models? â¢ State the conditions for your ideal car and identify it using the interface.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Results</head><p>Three themes that are related to distance and movement emerged from our analysis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3.1">Physical mapping of data</head><p>Participants liked the idea of mapping physical space to data space. After having used both conditions, one participant said: "Distance for selection of variables seems very natural"; another described it as fun, but said he felt more efficient when using the mouse. Participants were split on preference for using movement and using the mouse; all suggested combining the two forms of interaction, one reason being that they could change variables using the mouse. They also suggested adding a lock to position tracking so as to be able to approach the display or step back from it. One said "[I would like to] be able to lock such that I can walk closer to something and then unlock it again"; another that "[I would like to] be able to lock variable choice such that you don't change in error, when you are busy." One participant demonstrated this by taking off the tracking cap so that he could move without changing a variable.</p><p>One reason why participants wanted such a lock was because they found it difficult to keep the attribute selected while moving sideways to brush bars. Participants were observed to "drift" in distance to the display while brushing; this could result in abrupt changes of selection. It seems this issue caused some participants to move more cautiously and to look at the histogram while moving.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3.2">Scaling</head><p>Four participants disliked the way the views were scaled and positioned depending on location. They suggested instead a fixed size (and using a locking mechanism as suggested above to be able to look closer at an item). Three participants suggested that the location-dependent scaling and positioning could be improved by moving and scaling in discrete steps, instead of continuously. One participant got confused when pointing at the scatterplots, because it scaled when he walked closer to the display while doing so. This participant proposed zooming in when approaching the display (similar to the absolute condition in Study #1). In the baseline condition, several participants moved close to the data to point at it.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>6.3.3</head><p>Thinking physically about the data space</p><p>Two participants used physical descriptions of the data space. For example, one participant said: "Let me see what is out here", another: "I was in kind of a lane where I could filter instead of clicking with a mouse." That participant added: "It feels navigable," and considered that the way he had the attributes mapped to the floor space, he would be able to "Go to cars with large engines".</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">DISCUSSION</head><p>We have explored opportunities for using body movement to interact with visualizations on large high-resolution displays and we have tested several of them. In particular, we have relied on the notion of proxemics <ref type="bibr" target="#b14">[15]</ref> and a particular set of visualization tasks <ref type="bibr" target="#b17">[18]</ref>. Overall, the three user studies provide initial data in support of the idea of using movement and distance to change visualizations. Participants in all studies said that using body movement was intuitive or natural. Specifically, changing the visualization in response to changes in the user's distance to the display seemed useful. In Study #1, participants moved closer to the display for zooming in; in Study #2, participants moved closer to see data represented in higher detail ("more data in less space"). Changes to zoom level and representation made sense to several participants, maybe because it relates to the experience of physically zooming out and seeing less detail (due to limits of visual acuity). In contrast, scaling views with user's distance worked contrary to the expectations of some participants (Study #3).</p><p>Based on observations and feedback from participants, potential benefits of proxemics-based zooming and aggregation are reduced effort and more smooth interaction compared to mouse control. Proxemics-based control also seems to allow navigation in or manipulation of many variables at a time in a natural way.</p><p>Another opportunity is the use of body movement for dynamic querying: In Study #3, we mapped the user's movement to selection of attribute values. One benefit observed for several participants, was that they could fix their focus on the data views while changing the selection by moving their body.</p><p>The studies also showed how using proxemics and visualizations together may give a distinct physical sense to abstract data. Study #3 differed from the other two in that movement was mapped to abstract data rather than spatial data. We note that the proxemics mappings used here did not directly reflect spatial relation between the user and the on-screen data range (as does <ref type="figure" target="#fig_2">Fig. 3</ref>), rather the data range was mapped onto the floor. The study revealed some interesting interactions nonetheless: You can step back to get an overview or walk to the left-hand side of the display to re-find previously seen details. The purpose of our empirical studies was not to provide detailed experimental data on the cognitive benefits of proxemics in visualization, but we think exploring this is important future work.</p><p>Our studies also suggested a need to get the fine details of interaction right. Participants needed a way of locking, both when using orientation and when using their body to change views: For instance, leaning forward, close to the screen, could lock the screen. Such interactions could derive from more sophisticated proxemics data for distinguishing between relative poses of different parts of the body (e.g., shoulder relative to torso or hip) in addition to distance. Alternatively, users could have discrete zones for interacting through touch (close to the display) and for navigating through movement of the body (farther from the display). Also, proxemics-enhanced visualizations in our studies occasionally had unintended consequences: When participants in Study #3 moved to brush coordinated views, they sometimes changed the attribute unintentionally. Giving users more feedback on the sensed proxemics data might alleviate some of these problems. Vogel and Balakrishnan <ref type="bibr" target="#b53">[53]</ref> also found that users were sometimes unsure about the exit threshold of a distance zone.</p><p>The idea of using proxemics for interacting with information on large displays is not new. Recent work has for instance demonstrated use of discrete distance zones for changing layout and representation of information <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b53">53]</ref>. The present work differs from previous work by explicitly relating proxemics to information visualization tasks; the studies demonstrate mapping of movement, orientation, and distance (continuous measures as well as discrete zones) to visualize, filter, sort, select, navigate, and coordinate tasks <ref type="bibr" target="#b17">[18]</ref>.</p><p>Also, whereas previous work has investigated mainly static visualizations on large high-resolution displays <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b56">56]</ref>, the present research has investigated physical navigation for interactive visualizations, which presents new opportunities. For instance, Endert et al. showed that different encodings offer varying support for visual aggregation and thus impact the effectiveness of largedisplay visualizations <ref type="bibr" target="#b7">[8]</ref>: "To support physical navigation, encodings need to have a balance between the expressiveness of glyphs and good visual aggregation properties." However, the findings from the present studies suggest that alternative designs are possible that allow users to benefit from different encodings at different distances and from more generally changing visualizations through movement.</p><p>Our studies suggest several avenues of future work; in particular we want to highlight four of these: (a) We have prototyped and evaluated uses of movement and distance for information visualization, but uses of other proxemics categories need to be explored in more depth, as well as combination of proxemics-driven interactions with other input (as already discussed above); (b) our aim was not to empirically understand the cognitive benefits of proxemics in visualization, this is important future work; (c) we have focused on single-user interaction, but proxemics may help us design visualizations for multiple users-to help doing so, future work should relate proxemics to research on collaborative visualization; (d) we have not looked at combining proxemics with other emerging interaction styles, such as mid-air pointing (e.g., <ref type="bibr" target="#b35">[35]</ref>) or free hand gestures, which is another promising avenue of future research.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">CONCLUSION</head><p>The present paper has presented findings from initial probing into proxemics-based interactions with visualizations. We intend to experiment further with combining proxemics-driven interactions and other input for information visualization; the studies presented here are intended to lend credibility to the hypothesis that it is useful (and even pleasant) to control and interact with visualizations using ones body movements.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Distance-based focus+context: Focus elements are selected (outlined in red) while up close (left). As the user steps back, the focus elements are magnified (right).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Selecting view by changing orientation relative to the display.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .</head><label>3</label><figDesc>Changing a dynamic query slider by moving.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>2 . 3 Movement</head><label>23</label><figDesc>Visualize. Study #2 will present an example where movement is used to change the encoding of visual representations.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 5 .</head><label>5</label><figDesc>(a) Aggregate, municipalities (b) Aggregate, postal districts (c) Individual homes Techniques used in Study #2: Distance-dependent aggregation of real-estate data by geographic area in (a) and (b); details on demand for geographic areas in (a) and (b), and for individual homes in (c); multi-scale selection of map area.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 6 .</head><label>6</label><figDesc>Techniques used in Study #3: The user brushes the bars in a histogram by walking sideways, (a) to (b); the views move to stay in front of the user. The user moves backwards in order to select another attribute (c); the views scale to remain at a readable size.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 .</head><label>2</label><figDesc>Overview of user studies. Categories refer to the information visualization tasks and proxemics categories inTable 1.</figDesc><table><row><cell cols="2">Study Categories</cell><cell cols="2">Users Interfaces</cell><cell>Tasks</cell><cell>Data</cell></row><row><cell>#1</cell><cell>[Navigation] +</cell><cell>6</cell><cell>(a) Absolute: Navigation by absolute movement</cell><cell>Three tasks involving</cell><cell>Map from</cell></row><row><cell></cell><cell>[Move, Location]</cell><cell></cell><cell>(c) Baseline: Virtual navigation with gyro mouse (b) Relative: Navigation by location</cell><cell>[19,47] maps, adapted from</cell><cell>OpenStreetMap</cell></row><row><cell>#2</cell><cell>[Visualize] +</cell><cell>6</cell><cell>(a) Distance-controlled detail/aggregation</cell><cell>Five tasks, some</cell><cell>Data sets of 1000-3000</cell></row><row><cell></cell><cell>[Dist, Move]</cell><cell></cell><cell>(b) Baseline: Interaction with gyro mouse</cell><cell>adapted from [54]</cell><cell>homes (5 attributes)</cell></row><row><cell>#3</cell><cell>[Filter, Sort] +</cell><cell>6</cell><cell>(a) Position-controlled variable selection and brushing</cell><cell>Five multi-variate</cell><cell>406 cars (8 attributes)</cell></row><row><cell></cell><cell>[Dist, Move]</cell><cell></cell><cell>(b) Baseline: Interaction with gyro mouse</cell><cell>analysis tasks [55]</cell><cell>[41]</cell></row></table><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS</head><p>This work has been supported in part by the Danish Council for Strategic Research grant 10-092316.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Low-Level Components of Analytic Activity in Information Visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Amar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Eagan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Stasko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2005 IEEE Symposium on Information Visualization</title>
		<meeting>the 2005 IEEE Symposium on Information Visualization<address><addrLine>Washington, DC, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2005" />
			<biblScope unit="page" from="15" to="21" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Move to improve: promoting physical navigation to increase user performance with large displays</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ball</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>North</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename><surname>Bowman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CHI &apos;07: Proceedings of the SIGCHI conference on Human factors in computing systems</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2007" />
			<biblScope unit="page" from="191" to="200" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Proxemic interaction: designing for a proximity and orientation-aware environment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Ballendat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Marquardt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Greenberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM International Conference on Interactive Tabletops and Surfaces</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="121" to="130" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Perception of Visual Variables on Tiled Wall-Sized Displays for Information Visualization Applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bezerianos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Isenberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Transactions on Visualization and Computer Graphics (Proc. InfoVis)</title>
		<imprint>
			<date type="published" when="2012-12" />
			<biblScope unit="volume">18</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">K</forename><surname>Card</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">D</forename><surname>Mackinlay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Shneiderman</surname></persName>
		</author>
		<title level="m">Readings In Information Visualization: Using Vision To Think</title>
		<imprint>
			<publisher>Academic Press</publisher>
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Information Visualization: Human-Centered Issues and Perspectives</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Carpendale</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="19" to="45" />
		</imprint>
	</monogr>
	<note>Evaluating Information Visualizations</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A power primer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Cohen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychol Bull</title>
		<imprint>
			<biblScope unit="volume">112</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="155" to="159" />
			<date type="published" when="1992-07" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Visual encodings that support physical navigation on large displays</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Endert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Andrews</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>North</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Graphics Interface</title>
		<meeting>Graphics Interface</meeting>
		<imprint>
			<publisher>Canadian Human-Computer Communications Society</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="103" to="110" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">ChairMouse: leveraging natural chair rotation for cursor navigation on large, high-resolution displays</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Endert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Fiaux</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Stewart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Andrews</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>North</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CHI &apos;11 Extended Abstracts on Human Factors in Computing Systems</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="571" to="580" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Excentric labeling: dynamic neighborhood labeling for data visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-D</forename><surname>Fekete</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Plaisant</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CHI &apos;99: Proceedings of the SIGCHI conference on Human factors in computing systems</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="1999" />
			<biblScope unit="page" from="512" to="519" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Generalized fisheye views</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">W</forename><surname>Furnas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the SIGCHI conference on Human factors in computing systems</title>
		<meeting>the SIGCHI conference on Human factors in computing systems<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="1986" />
			<biblScope unit="volume">86</biblScope>
			<biblScope unit="page" from="16" to="23" />
		</imprint>
	</monogr>
	<note>CHI</note>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Usability evaluation considered harmful (some of the time)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Greenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Buxton</surname></persName>
		</author>
		<imprint>
			<biblScope unit="page" from="111" to="120" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Greenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Marquardt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Ballendat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Diaz-Marino</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Wang</surname></persName>
		</author>
		<title level="m">Proxemic interactions: the new ubicomp?,&quot; interactions</title>
		<imprint>
			<date type="published" when="2011-01" />
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="42" to="50" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">A System for the Notation of Proxemic Behaviour</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">T</forename><surname>Hall</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">American Anthropologist</title>
		<imprint>
			<biblScope unit="volume">65</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1003" to="1026" />
			<date type="published" when="1963" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">The Hidden Dimension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">T</forename><surname>Hall</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1966" />
			<pubPlace>Garden City, N. Y.; Doubleday</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Lean and zoom: proximity-aware user interface and content magnification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Harrison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">K</forename><surname>Dey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the SIGCHI Conference on Human Factors in Computing Systems</title>
		<meeting>the SIGCHI Conference on Human Factors in Computing Systems<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2008" />
			<biblScope unit="page" from="507" to="510" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">The proximity factor: impact of distance on co-located collaboration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Hawkey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kellar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Reilly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Whalen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">M</forename><surname>Inkpen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2005 international ACM SIGGROUP conference on Supporting group work</title>
		<meeting>the 2005 international ACM SIGGROUP conference on Supporting group work<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2005" />
			<biblScope unit="page" from="31" to="40" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Interactive dynamics for visual analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Heer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Shneiderman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Commun. ACM</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="45" to="54" />
			<date type="published" when="2012-04" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Sizing up visualizations: effects of display size in focus+context, overview+detail, and zooming interfaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">R</forename><surname>Jakobsen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Hornbaek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the SIGCHI Conference on Human Factors in Computing Systems</title>
		<meeting>the SIGCHI Conference on Human Factors in Computing Systems<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="1451" to="1460" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Proximity and physical navigation in collaborative work with a multi-touch wall-display</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">R</forename><surname>Jakobsen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Hornbaek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CHI EA &apos;12: Extended abstracts on Human Factors in Computing Systems</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="2519" to="2524" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Tangible remote controllers for wall-size displays</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Jansen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dragicevic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-D</forename><surname>Fekete</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the SIGCHI Conference on Human Factors in Computing Systems</title>
		<meeting>the SIGCHI Conference on Human Factors in Computing Systems<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="2865" to="2874" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Polyzoom: multiscale and multifocus exploration in 2d visual spaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Javed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ghani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Elmqvist</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the SIGCHI Conference on Human Factors in Computing Systems</title>
		<meeting>the SIGCHI Conference on Human Factors in Computing Systems<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="287" to="296" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Range: exploring implicit interaction through electronic whiteboard design</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Ju</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">A</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">R</forename><surname>Klemmer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2008 ACM conference on Computer supported cooperative work</title>
		<meeting>the 2008 ACM conference on Computer supported cooperative work<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2008" />
			<biblScope unit="page" from="17" to="26" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Information Visualization and Visual Data Mining</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename><surname>Keim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="8" />
			<date type="published" when="2002-01" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Instant data analysis: conducting usability evaluations in a day</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kjeldskov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">B</forename><surname>Skov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Stage</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the third Nordic conference on Human-computer interaction</title>
		<meeting>the third Nordic conference on Human-computer interaction<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2004" />
			<biblScope unit="page" from="233" to="240" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Adaptive personal territories for co-located tabletop interaction in a museum setting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Klinkhammer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Nitsche</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Specht</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Reiterer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM International Conference on Interactive Tabletops and Surfaces</title>
		<meeting>the ACM International Conference on Interactive Tabletops and Surfaces<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="107" to="110" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Beyond Mouse and Keyboard: Expanding Design Considerations for Information Visualization Interactions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Isenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">H</forename><surname>Riche</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Carpendale</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2689" to="2698" />
			<date type="published" when="2012-12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Gradual engagement: facilitating information exchange between digital devices as a function of proximity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Marquardt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Ballendat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Boring</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Greenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Hinckley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2012 ACM international conference on Interactive tabletops and surfaces</title>
		<meeting>the 2012 ACM international conference on Interactive tabletops and surfaces<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="31" to="40" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">The proximity toolkit: prototyping proxemic interactions in ubiquitous computing ecologies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Marquardt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Diaz-Marino</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Boring</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Greenberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th annual ACM symposium on User interface software and technology</title>
		<meeting>the 24th annual ACM symposium on User interface software and technology<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="315" to="326" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Informing the Design of Proxemic Interactions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Marquardt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Greenberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Pervasive Computing</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="14" to="23" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Interaction proxemics and image use in neurosurgery</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">M</forename><surname>Mentis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>O'hara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sellen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Trivedi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the SIGCHI Conference on Human Factors in Computing Systems</title>
		<meeting>the SIGCHI Conference on Human Factors in Computing Systems<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="927" to="936" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Interacting with microseismic visualizations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">E</forename><surname>Mostafa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Greenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Brazil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Sharlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">C</forename><surname>Sousa</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>in CHI &apos;13</note>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Extended Abstracts on Human Factors in Computing Systems</title>
		<imprint>
			<date type="published" when="2013" />
			<publisher>ACM</publisher>
			<biblScope unit="page" from="1749" to="1754" />
			<pubPlace>New York, NY, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Human-robot proxemics: physical and psychological distancing in human-robot interaction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Mumm</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Mutlu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 6th international conference on Human-robot interaction</title>
		<meeting>the 6th international conference on Human-robot interaction<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="331" to="338" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">E-conic: a perspectiveaware interface for multi-display environments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Nacenta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sakurai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Yamaguchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Miki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Itoh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Kitamura</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Subramanian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Gutwin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 20th annual ACM symposium on User interface software and technology</title>
		<meeting>the 20th annual ACM symposium on User interface software and technology<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2007" />
			<biblScope unit="page" from="279" to="288" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Mid-air pan-and-zoom on wall-sized displays</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Nancel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wagner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Pietriga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Chapuis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Mackay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the SIGCHI Conference on Human Factors in Computing Systems</title>
		<meeting>the SIGCHI Conference on Human Factors in Computing Systems<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="177" to="186" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">A mathematical model of the finding of usability problems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Nielsen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">K</forename><surname>Landauer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the INTERACT &apos;93 and CHI &apos;93 Conference on Human Factors in Computing Systems</title>
		<meeting>the INTERACT &apos;93 and CHI &apos;93 Conference on Human Factors in Computing Systems<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="1993" />
			<biblScope unit="page" from="206" to="213" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Snap-together visualization: a user interface for coordinating visualizations via relational schemata</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>North</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Shneiderman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the working conference on Advanced visual interfaces</title>
		<meeting>the working conference on Advanced visual interfaces<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2000" />
			<biblScope unit="page" from="128" to="135" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Distance matters</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">M</forename><surname>Olson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">S</forename><surname>Olson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Hum.-Comput. Interact</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="139" to="178" />
			<date type="published" when="2000-09" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">A multiscale interaction technique for large, high-resolution displays</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M</forename><surname>Peck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>North</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Bowman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2009 IEEE Symposium on 3D User Interfaces</title>
		<meeting>the 2009 IEEE Symposium on 3D User Interfaces<address><addrLine>Washington, DC, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="31" to="38" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Sigma lenses: focus-context transitions combining space, time and translucence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Pietriga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Appert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CHI &apos;08: Proceeding of the twenty-sixth annual SIGCHI conference on Human factors in computing systems</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2008" />
			<biblScope unit="page" from="1343" to="1352" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">The 1983 ASA data exposition dataset: Cars</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Ramos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Donoho</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1983" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Walking improves your cognitive map in environments that are large-scale and large in extent</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">A</forename><surname>Ruddle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Volkova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">H</forename><surname>BÃ¼lthoff</surname></persName>
		</author>
		<idno>1-10:20</idno>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Comput.-Hum. Interact</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2011-07" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Screenfinity: extending the perception area of content on very large public displays</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Schmidt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>MÃ¼ller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Bailly</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 ACM annual conference on Human factors in computing systems</title>
		<meeting>the 2013 ACM annual conference on Human factors in computing systems<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1719" to="1728" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Knowledge Discovery in High-Dimensional Data: Case Studies and a User Survey for the Rank-by-Feature Framework</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Seo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Shneiderman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="311" to="322" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title level="m" type="main">Experimental and Quasi-experimental Designs for Generalized Causal Inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">R</forename><surname>Shadish</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">D</forename><surname>Cook</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">T</forename><surname>Campbell</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002" />
			<publisher>Houghton Mifflin</publisher>
			<pubPlace>Boston, MA, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">The Eyes Have It: A Task by Data Type Taxonomy for Information Visualizations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Shneiderman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1996 IEEE Symposium on Visual Languages</title>
		<meeting>the 1996 IEEE Symposium on Visual Languages<address><addrLine>Washington, DC, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="1996" />
			<biblScope unit="page" from="336" to="343" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Shaping the Display of the Future: The Effects of Display Size and Curvature on User Performance and Insights</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Shupp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Andrews</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Dickey-Kurdziolek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Yost</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>North</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Human-Computer Interaction</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="230" to="272" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<title level="m" type="main">Personal Space: The Behavioral Basis of Design</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Sommer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1969" />
			<publisher>Prentice Hall</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">CyberWalk: Enabling unconstrained omnidirectional walking through virtual environments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">L</forename><surname>Souman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">R</forename><surname>Giordano</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Schwaiger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Frissen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>ThÃ¼mmel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ulbrich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">D</forename><surname>Luca</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">H</forename><surname>BÃ¼lthoff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">O</forename><surname>Ernst</surname></persName>
		</author>
		<idno>25:1-25:22</idno>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Appl. Percept</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">4</biblScope>
			<date type="published" when="2008-12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Tangible views for information visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Spindler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Tominski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Schumann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Dachselt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM International Conference on Interactive Tabletops and Surfaces</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="157" to="166" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Getting the right design and the design right</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Tohidi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Buxton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Baecker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sellen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the SIGCHI Conference on Human Factors in Computing Systems</title>
		<meeting>the SIGCHI Conference on Human Factors in Computing Systems<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2006" />
			<biblScope unit="page" from="1243" to="1252" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">ManyEyes: a Site for Visualization at Internet Scale</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">B</forename><surname>Viegas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Wattenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Ham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kriss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mckeon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1121" to="1128" />
			<date type="published" when="2007-11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Interactive public ambient displays: transitioning from implicit to explicit, public to personal, interaction with multiple users</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Vogel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Balakrishnan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">UIST &apos;04: Proceedings of the 17th annual ACM symposium on User interface software and technology</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2004" />
			<biblScope unit="page" from="137" to="146" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">The dynamic HomeFinder: evaluating dynamic queries in a real-estate information exploration system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Williamson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Shneiderman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 15th annual international ACM SIGIR conference on Research and development in information retrieval</title>
		<meeting>the 15th annual international ACM SIGIR conference on Research and development in information retrieval<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="1992" />
			<biblScope unit="page" from="338" to="346" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Dust &amp; magnet: multivariate information visualization using a magnet metaphor</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">S</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Melton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Stasko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Jacko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Visualization</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="239" to="256" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">The Perceptual Scalability of Visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Yost</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>North</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="837" to="844" />
			<date type="published" when="2006-09" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
