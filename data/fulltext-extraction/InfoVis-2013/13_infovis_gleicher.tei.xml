<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/pisenberg/grobid/grobid-0.6.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Perception of Average Value in Multiclass Scatterplots</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2013-10-13">13 October 2013</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><roleName>Member, IEEE</roleName><forename type="first">Michael</forename><surname>Gleicher</surname></persName>
							<email>gleicher@cs.wisc.edu</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><roleName>Student Member, IEEE</roleName><forename type="first">Michael</forename><surname>Correll</surname></persName>
							<email>mcorrell@cs.wisc.edu</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christine</forename><surname>Nothelfer</surname></persName>
							<email>cnothelfer@u.northwestern.edu</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Franconeri</surname></persName>
							<email>franconeri@northwestern.edu</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Sciences</orgName>
								<orgName type="institution">University of Wisconsin -Madison</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">Department of Computer Sciences</orgName>
								<orgName type="institution">University of Wisconsin -Madison</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="department">Department of Psychology</orgName>
								<orgName type="institution">Northwestern University</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="department">Department of Psychology</orgName>
								<orgName type="institution">Northwestern University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Perception of Average Value in Multiclass Scatterplots</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2013-10-13">13 October 2013</date>
						</imprint>
					</monogr>
					<note type="submission">received 31 March 2013; accepted 1 August 2013; posted online</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2021-02-19T19:07+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Psychophysics</term>
					<term>Information Visualization</term>
					<term>Perceptual Study</term>
				</keywords>
			</textClass>
			<abstract>
				<p>Larger differences between means lead to improved performance. (b) As the number of points per class increases performance remains good (in fact it may improve). (c) Stronger cues (color) outperform weaker ones (shape). Although, participants performed well even with weak cues. (d) Combining cues redundantly does not improve performance. (e) Irrelevant cues do not degrade performance. Here, class is shown by color, but the random shape does not degrade performance. (f) Adding irrelevant additional classes to the scatterplot does not degrade performance. Fig. 1. Summary of results: viewers can efficiently make comparative mean judgements, choosing the class with the highest average position in multiclass scatterplots across a wide variety of conditions and encodings.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Many visualization tasks require the viewer to create abstractions, or statistical summaries, over groups of marks. We use the term visual aggregation for such situations where the viewer "computes" the aggregate properties when presented with a collection of objects. In many cases, these abstractions can be constructed rapidly even for large numbers of objects (i.e.,"preattentively"). This ability has been studied extensively in the perception literature, leading to models of the mechanisms behind them as well as implications for visualization. However, models of aggregation from the perception literature are typically based on performance patterns for brief display expo-sures, leaving it unclear whether their implications apply to situations where viewers contemplate more complex displays across longer periods of time. Prior studies isolate individual mechanisms, but provide little insight on how these mechanisms may be combined.</p><p>In this paper, we explore aggregate judgement in visualizations using a realistic task: assessing the difference in class means in a scatterplot. The task involves accurate localization, and we permit viewers to take time to make accurate judgements. This differs from prior studies that use unrealistically short exposures in order to build models of efficient aggregation in the visual system.</p><p>Scatterplots are a common visual presentation. Viewer ability to rapidly and accurately assess trends has been studied (e.g. Doherty et al. <ref type="bibr" target="#b16">[17]</ref> and Rensink &amp; Baldridge <ref type="bibr" target="#b44">[45]</ref>). Scatterplots often present multiple data classes simultaneously to aid comparison. Such displays are advantageous because they allow the viewer to see specifics and trends within each class, as well as to make relative judgements between classes. Li et al. <ref type="bibr" target="#b37">[38,</ref><ref type="bibr" target="#b38">39]</ref> demonstrate viewers' ability to make rapid judgements about multi-class scatterplots for several tasks. While there are many different ways to measure the difference between classes <ref type="bibr" target="#b49">[50]</ref>, comparison of the means of groups is common as it corresponds to many decision criteria (e.g. is one class better than another). The importance of mean separation has lead to view selection methods, such as <ref type="bibr" target="#b51">[52]</ref> and <ref type="bibr" target="#b15">[16]</ref>, that maximize it.</p><p>It is often possible to present the descriptive statistics to the viewer (e.g. explicitly marking the means). However, allowing the viewer to make the judgement by aggregating the data visually can offer a number of advantages, such as not needing to know the viewer's needs, not needing to clutter the displays with another form of information, and providing a natural combination of the statistics with the details and trends. However, these potential benefits of visual aggregation can only exist if viewers are able to make reliable judgements.</p><p>The theory and evidence in the perception literature illuminates mechanisms that viewers can use for aggregation tasks. However, this prior work has typically focused on performance within relatively simple displays that are briefly flashed, in contrast to more complex visualizations that can be inspected over the course of several seconds. Even though viewers can make rapid judgements about multi-class scatterplots when forced (e.g. <ref type="bibr" target="#b37">[38,</ref><ref type="bibr" target="#b38">39]</ref>), they generally choose to take more time. The perception literature describes constraints on the visual system for rapid, simple tasks. If the same mechanisms are part of more complex judgements, these constraints make predictions about our tasks of interest, in situations where viewers take more time.</p><p>Because we are interested in viewer performance when they are not time constrained, our questions cannot be studied using the standard experimental paradigm that measures response time, either by asking participants to respond as quickly as possible or varying exposure time. Instead, we use an experimental design where participants are not time constrained (within limits), and we vary the challenge level of the trials by altering proprties of the stimulus. Fortunately, the multi-class scatterplot mean comparison problem affords many types of control over task hardness. Also, the fact that we do not need precise timing allows us to implement the experiment in a standard web browser, affording the use of crowd sourcing which gives us access to a large and diverse participant pool.</p><p>Based on the prior evidence of the limitations of visual mechanisms, we generated a set of predictions, described in §1.1 below, and tested these predictions by asking over 750 crowd-sourced participants to compare group means within scatterplots. These experiments share many common features, discussed in Section 3. The specific results of the experiments are discussed in Section 4. The first experiment, discussed in Section 4.1, uses a between-subjects design to establish the main points of our theory. However, since many of the important results are null results (i.e. we predict no performance differences between different sorts of scatterplots), this design does not provide the statistical power needed to make some conclusions with confidence. Therefore, we conducted a series of within-subjects experiments, described in Section 4.2, that reinforce these results with higher confidence. After presenting these results, we discuss their ramifications both in terms of providing an understanding of the perceptual mechanisms in visualization tasks, but also to the design of displays that support aggregate judgement.</p><p>We find that viewers can make efficient judgements about the means in scatterplots, and that constraints on this ability follow predictions based on the perception literature. Our key findings are summarized in <ref type="figure">Figure 1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Contributions:</head><p>We test a set of predicted constraints on visual aggregation tasks that involve relatively complex displays viewed over the course of several seconds. We present a large scale, crowd-sourced study that supports these predictions. Our task requires judgements within multi-class scatterplots, a very common visualization, and our work provides an empirical assessment of how viewers perform on aggregation tasks, as well as guidance on how to create visualizations that support these tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1">Predictions of Performance</head><p>Both the perception and visualization communities have demonstrated that the visual system can accomplish a wide range of tasks efficiently, such as estimation of numerosity or mean value.</p><p>One common mechanism underlying performance across many of these tasks is attentional selection: the ability to amplify visual information that meet some criteria, while suppressing the rest. One criterion is location, set both by the position of the eyes, as well as the "spotlight" of attention (though these two are typically highly correlated; see <ref type="bibr" target="#b22">[23]</ref> for review). Other criteria for selection are featural, constrained by the presence of existing tuning mechanisms that alter the weighting of particular features (e.g., certain colors or shapes). The visual system uses these features to create an abstract map of the information present. After a subset of visual information is selected from this map, the visual system can form abstractions over that subset <ref type="bibr" target="#b32">[33,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b56">57]</ref>. Tasks can be done efficiently (with only a "flash" of exposure time) if the viewer is able to weight a map to select the appropriate features and make simple assessments.</p><p>Unfortunately, these prior models do not explain what a viewer does with more time, or how they might be able to use more time to achieve better performance. These prior studies outline limitations on what the human visual system is capable of selecting, ignoring, and aggregating, and here we test how observers perform when they are allowed sufficient time to use this architecture effectively, and in situations that are relevant to visualization.</p><p>For example, studies from the perception literature show that observers can efficiently average position across a handful of points <ref type="bibr" target="#b0">[1]</ref>, but what about the dozens of points in a typical scatterplot? Perception studies show that global selection of a single feature value (e.g. red) is possible (e.g., <ref type="bibr" target="#b48">[49]</ref>), but can average position be extracted from these subsets? Perceptual studies show that some features are easier to select or localize than others (e.g., color vs. shape) <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b55">56]</ref> -does this generalization hold when more time is provided to inspect a visualization? Perceptual theory suggests that selecting a value within a single dimension (e.g., red among colors) can be difficult (e.g., <ref type="bibr" target="#b57">[58]</ref>), so will observers really select a value for a second dimension (e.g. circles among shapes) to take advantage of redundant encoding? Perceptual studies of selective attention suggest that irrelevant 'distractor' features are extremely difficult to ignore in briefly presented displays (e.g., <ref type="bibr" target="#b57">[58]</ref>), but will this still be true when observers have sufficient time to tune their feature-selective filters?</p><p>These questions lead to more concrete predictions based on limitations in the basic mechanisms.</p><p>• As the means become closer, the task will become more difficult, and performance will degrade. This prediction is included as a check of our experimental design.</p><p>• Because feature selection acts globally over large collections, and some work has shown that center-judgements are possible over large collections of points, performance should not be impaired by larger collections. <ref type="figure">(Fig 1b)</ref> • Because the effectiveness of selection is influenced by feature contrast, features that are easy to select (e.g. salient colors) will lead to better performance than features that are harder to select (e.g. shape, or less salient colors). <ref type="figure">(Fig 1c)</ref> • Because features must be selected individually, redundant encodings that provide multiple features will not improve performance, beyond giving the viewer a choice of a feature to select. <ref type="figure">(Fig 1d)</ref> • Because selecting one feature suppresses the others, conflicting encodings, such as adding variability along a different feature dimension, will not impair performance unless the conflicting feature is so salient that it interferes with the selection of the primary feature. <ref type="figure">(Fig 1e)</ref> • Because the viewer selects specific values of the feature, adding other values does not cause significant distraction. For example, if the viewer selects purple, then orange, the existence of green dots should not interfere. <ref type="figure">(Fig 1f)</ref> • Because selection requires choosing what to select and what to suppress, a sufficient diversity of distractions may impair performance.</p><p>Our premise is that some of the same underlying mechanisms used in rapid response tasks are used in longer time tasks. This does not imply that performance is the same: viewers may have different ways of using the basic mechanisms. However, it does suggest that the fundamental limitations of the mechanisms (what can be selected and what can be extracted from the resulting subset) still apply at longer durations. Our experiments seek to confirm these performance predictions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">BACKGROUND AND RELATED WORK</head><p>The literature on perceptual psychology provides inspiration for both the types of abstractions that can be constructed over sets of objects, and the types of cues that allow efficient segmentation of these sets. The human visual system can quickly construct many types of abstractions from sets, including numerosity (see <ref type="bibr" target="#b21">[22]</ref>, for review), and averages over dimensions like size <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b9">10]</ref>, orientation <ref type="bibr" target="#b10">[11]</ref>, motion direction <ref type="bibr" target="#b36">[37]</ref>, spatial frequency <ref type="bibr" target="#b1">[2]</ref>, and perhaps even more complex properties like facial emotion and gender <ref type="bibr" target="#b25">[26]</ref> (but see <ref type="bibr" target="#b39">[40]</ref>, for caveats). Efficient segmentation of sets has been studied using tasks such as visual search <ref type="bibr" target="#b53">[54]</ref>, texture boundary identification <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b8">9]</ref>, and number discrimination <ref type="bibr" target="#b26">[27]</ref>. Most relevant to the present studies, observers can average spatial position over a set of objects <ref type="bibr" target="#b0">[1]</ref>, but this study only demonstrated this ability for a handful of objects. Other work shows that people can make saccades to the centerpoint of objects made up of large sets of dots that form a rough object contour <ref type="bibr" target="#b40">[41]</ref>, but it is not clear that this ability will generalize, or that this centerpoint estimate is consciously available.</p><p>These tasks have revealed many features that serve to segment sets of objects broadly and rapidly, including relative differences in hue, orientation, shape, and size <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b55">56,</ref><ref type="bibr" target="#b56">57]</ref>, as well as some more complex visual properties such as lighting direction <ref type="bibr" target="#b19">[20]</ref>. Some features are processed more efficiently than others <ref type="bibr" target="#b55">[56]</ref> -e.g. tasks involving selecting lines with atypical colors in a display are faster and less error prone than tasks involving selecting lines with atypical concavity. Haroz and Whitney <ref type="bibr" target="#b28">[29]</ref> also explore how the mechanisms of attention limit performance in various visual tasks.</p><p>The visual system can create abstractions (e.g. numerosity estimation, mean position, spatial envelope extraction) across the set of visual field locations that are currently selected by attention. Concretely, attentional selection is a relative amplification of visual information that meets certain criteria, such as being in a specific location (e.g., in the upper left of a display), or containing specific feature values (e.g., red, left tilted, curved, or two-inches-tall). The possible criteria are constrained by the presence of existing feature maps <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b50">51]</ref> that index the presence or absence of that feature across the visual field, such that novel or arbitrary criteria are not available. Increasing the weight on one or more of these maps would lead to amplification of the visual information that is spatially correlated with the locations highlighted by that map. The perception literature explores many questions related to how this type of model operates, such as whether we can amplify multiple maps corresponding to values on the same dimension <ref type="bibr" target="#b32">[33,</ref><ref type="bibr" target="#b36">37]</ref>, or whether new maps can be constructed with practice <ref type="bibr" target="#b6">[7]</ref>.</p><p>For present purposes, the most pressing questions revolve around how well people can use these maps and the underlying mechanisms for performing more complex tasks. Most of this work relies on briefly presented visual search displays, and shows that ignoring particularly salient objects can be difficult in some types of displays, suggesting a default mode where people automatically weight maps with unique spots of activation (e.g., <ref type="bibr" target="#b4">[5]</ref>). Other work shows that instruction or recent experience can alter the weights on these maps, leading to increased attentional control over what spatial locations or feature values contribute most to attentional selection (for review see <ref type="bibr" target="#b18">[19]</ref>) .</p><p>While such results from the perception literature are informative, their conclusions about attentional selection do not necessarily generalize to the types of set segmentation needed within data visualizations. First, the tasks used typically require responses within less than a second, which may lead to an underestimate of the types of attentional selection control that may be possible given less rushed visualization tasks that extend over the course of several seconds. We believe the same constraints apply within more complex and extended visual operations that unfold beyond the first "preattentive" snapshot. Second, the tasks typically require observers to either find a single unique object (visual search) or compare relative size or numerosity across multiple sets of objects (e.g. <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b26">27]</ref>), leaving open the question of whether other types of judgements (e.g. mean spatial position) can rely on the same mechanisms.</p><p>Researchers in visualization and graphics have investigated how known perceptual processes and features interact in more realistic displays. Healey, Booth &amp; Enns varied features for encoding salmon migration data <ref type="bibr" target="#b30">[31]</ref>, finding that participants could successfully perform numerical estimation of items of a particular hue (with task-irrelevant orientation) and of a particular orientation (with task-irrelevant hue) quickly (&lt; 200 ms) and accurately. They also found no effect of interference from the task-irrelevant features, unlike previous studies <ref type="bibr">( [8, 9]</ref>). Their displays were regular grids, and the values were contiguous regions, and therefore are quite different than scatterplots. More recently, others have investigated the best symbols for data encoding. Li et al. varied lightness and size of symbols in scatterplot displays from which participants performed several visual analytic tasks <ref type="bibr" target="#b37">[38,</ref><ref type="bibr" target="#b38">39]</ref>. Participant performance was used to model an optimal discriminability scale with equal perceptual separation between scatterplot symbol lightness and sizes.</p><p>This work is one of several in a recent trend towards using empirical methodology to analyze how aggregate statistics are perceived and compared in common visual displays. The proposed experimental task (comparison of mean values) and its connection with a relatively high-level aggregate statistical comparison of mean has been used by Foureizos et al. to analyze statistical decision-making in bar charts <ref type="bibr" target="#b20">[21]</ref>, where as Doherty et al. <ref type="bibr" target="#b16">[17]</ref> and Rensink &amp; Baldridge <ref type="bibr" target="#b44">[45]</ref> have both looked at correlation coefficients in scatterplots. Two recent papers by Correll et al. have examined the visual perception, aggregation, and comparison of mean values, in both time series data and in paragraphs of tagged text <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b14">15]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">EXPERIMENTAL DESIGN</head><p>Our work involved a series of pilot studies and two main experiment sets <ref type="bibr" target="#b0">1</ref> . This section describes the elements common among them.</p><p>The model task chosen for our study was to judge the average height of the classes in a multi-class scatterplot. We presented this to participants as a two-alternative forced choice -"which type of point is on average higher?"</p><p>Our performance measure was participant accuracy. We explicitly do not consider time as a performance criteria: we want to understand viewer performance when they can take the amount of time they feel is necessary to perform accurately. Participants were instructed to answer as accurately as possible, rather than as quickly as possible. We did bound the exposure time of the displays (to ten seconds), to ensure that the participants made sufficient progress and to thwart certain kinds of cheating. The experiment was instrumented to enforce the time limit and record time measurements. Very rarely did participants run into this time limit.</p><p>Multi-class scatterplots have a number of attributes that may affect performance on the mean estimation task. First is the number of classes. In our experiments, we only consider two-way comparisons, although for some conditions we add a third class as a distractor. Second is the number of points per class. For this study, we consider only cases where each class has the same number of points, as we did not wish to confound numerosity (which has been previously studied) with mean position. In pilot studies, we confirmed that performance was consistent over a range of numbers of points per class . We were limited in the range we could explore: if there are too few points, the viewer may be tempted to use a serial strategy; if there are too many points the display may become too dense for the points to be presented distinctly. In most experiments, we chose to use 50 points per class in each display, with exception of one condition where we have 75 points per class to assess the impact of number of points. A third issue is the degree that the classes are inter-mixed. If the different classes are highly disjoint then the comparative averaging task is triv-  Example stimuli from our various levels of task difficulty parameter ∆, the difference (in pixels) between classes in our scatterplots. When ∆ = 0, both classes of points have the same average. In 2a,2c,2e purple points have the highest average. For the others, orange points have the highest average. For this set of stimuli orange points always have the highest absolute value, to disambiguate averaging and peak-finding tasks. Even for the lowest levels of ∆ used in our experiments, aggregate performance was significantly better than chance.</p><p>ial. If the points are clustered, various visual mechanisms can simplify the task <ref type="bibr" target="#b28">[29]</ref>. The primary "hardness" attribute in our design is the vertical distance between the means of each class of points. The closer these are together, the more accurately the means must be localized such that a correct comparison can be made. We call this parameter ∆, the distance between centers, and measure it in pixels. <ref type="figure" target="#fig_1">Figure 2</ref> shows various stimuli at different levels of ∆. In the experiments below, we confirm that this parameter is correlated with performance. In pilot studies we observed that when the task was "sufficiently hard," people took a few seconds to make a judgement. There is an expected ceiling: when the task becomes sufficiently easy, most people can get the right answer most of the time. In pilot studies we observed that if we only showed participants hard examples, their performance on those hard examples was significantly worse than if we also showed them some easier examples. Through additional piloting we determined appropriate hardness levels that were used in subsequent experiments.</p><p>For each condition, each participant was shown a number of different hardness levels. For each hardness level, six different trials were shown, three of each class as the correct answer. Within each condition, the order was fully randomized.</p><p>After giving consent, participants were given a color vision deficiency test using Ishihara plates <ref type="bibr" target="#b27">[28]</ref>. Participants failing this test were barred from participating in the main study. Those qualifying were shown a brief tutorial explaining the experimental task that emphasized that they were to identify the class with the highest average value, not the highest specific value. Participants were then shown a number of practice stimuli. The practice consisted of a set of "very easy" stimuli. If the participants correctly answered two of these set in a row they proceeded to a set of slightly more difficult stimuli. After correctly guessing two in a row of these stimuli, they were shown an example of a difficult stimulus. After an incorrect guess, participants were explicitly shown the right answer and then allowed to proceed (see <ref type="figure">Figure 3</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Stimulus and Generation</head><p>Our stimuli are randomly generated multi-class scatterplots. The points were placed according to a uniform random distribution subject to constraints that the difference in the means between groups had the specified value of ∆, and that the points were spaced sufficiently such that no glyphs would overlap. To generate a set of points for a trial, the vertical center of the two classes was randomly selected to be somewhere in the middle third of the display. Randomly shifting the center discouraged strategies that involved considering the mid-point of the display. Given the center of the entire point set, the mean for each class is computed by displacing them above and below. To generate the random points, a dart-throwing approach <ref type="bibr" target="#b35">[36]</ref> was used for the Poisson sampling (to prevent overlaps), and best-candidate sampling <ref type="bibr" target="#b41">[42]</ref> was used to bias the random distributions to have the appropriate means. Darts were thrown alternating between the two classes to allow for random mixing. The points were adjusted by displacing the points of each class a small amount such that the difference in the <ref type="figure">Fig. 3</ref>. An example stimulus from our experiments. Participants were asked "Which type of points are on average higher?" In this case the types of points being purple or orange circles. In this example the actual mean values are marked to make the difference between classes obvious. means had exactly the required value. When a third class of points was necessary as a distractor this was added after the first two classes of points were generated using the same best-candidate dart throwing sampler. In cases where there was a conflicting cue, the specific level of the conflicting cue for each point was determined randomly.</p><p>In pilot studies, we noted that the class with the higher average was more likely to have one of its points be the highest on the chart, leading to a dominant strategy where participants would simply pick the highest point in the chart achieve good accuracy. To discourage this strategy, we purposefully de-correlate which class has the topmost (and bottom-most) point from which class has the higher average by making one class always have the highest point (and the other have the lowest).</p><p>In the pilot studies and initial trials, an alternate set of stimuli was created by flipping the stimuli vertically. We counter-balanced flipped and non-flipped cases in a between subjects design and found no significant difference between them. This further added to our confidence that the random process did not create artifacts that skewed the results.</p><p>The specific point values of all classes across all levels of ∆ were computed in advance. We used the same sets of points for different conditions between participants, to the extent possible. That is, all of the conditions in Experiment Set One that have two classes of 50 points used the same positions for those points, only altering the way the points were drawn. Similarly, all within-subjects experiments used the same data. Different sets were generated for each block of the experiments, but all experiments (except for the one with 75 points) used the same generated point sets. Stimuli were generated for a variety of visual encodings. Color encodings used orange and purple for the two classes, chosen from a ColorBrewer <ref type="bibr" target="#b29">[30]</ref> qualitative set. In pilot studies, we confirmed that there was neither bias between these colors, or to which one was listed first on the question page. In contrast, our pilot studies found that there was a bias towards red, which is consistent with effects seen in other experiments <ref type="bibr" target="#b12">[13]</ref>  <ref type="bibr" target="#b52">[53]</ref>. Glyphs were usually drawn as filled circles, except when a shape encoding was used, in which case glyphs included triangles, pluses, or squares. The glyphs were sized such that they had (approximately) equal area.</p><p>Stimuli were pre-rendered as 400 pixel square images, with white backgrounds and without axes. They were delivered to the participants web browsers in a lossless image format to avoid differences in browser rendering. Circular glyphs were 6 pixels in radius, other shapes were adjusted to have similar area. Each glyph had a 10 pixel radius "exclusion zone" in which no other glyph could be drawn. Since these zones do not overlap, the minimum distance between two circular glyphs is 8 pixels. Stimuli were rendered using sub-pixel accurate anti-aliasing.</p><p>Practice and tutorial stimuli were generated using a similar procedure to the actual experimental stimuli. However, the dart throwing process was used to ensure that a space was left for the mean mark. This additional space may have skewed the distributions, but we were not concerned about this for the tutorial and practice images. <ref type="figure">Figure  3</ref> shows an example stimulus generated by this method, as well as showing an example of a mean mark of the type seen by participants in practice images.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Crowdsourcing</head><p>We chose to use Amazon's Mechanical Turk crowdsourcing platform to conduct our experiments -previous research has shown that Turk offers a participant pool that is more diverse than would be recruited from a college campus <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b46">47]</ref>, and that the relatively quick turn around of Turk studies fits our model of performing a large number of iterative, somewhat contingency-based studies. With proper care in experimental design to avoid "click through" or other cheating behavior, Turk studies can be a reliable source of human subjects data <ref type="bibr" target="#b42">[43]</ref>, and data for the analysis of the efficacy of designs in information visualization specifically <ref type="bibr" target="#b31">[32,</ref><ref type="bibr" target="#b34">35]</ref>.</p><p>For our experiments only Turkers from the United States were eligible to participate, and once a participant completed an experiment they were added to a blacklist such that were not eligible for any of the other experiments discussed in this paper. To prevent click-through behavior we randomized question order, included non-obtrusive validation questions, and split questions across multiple pages and response types (e.g. binary choices, text fields, constrained response). Participants were paid at a standard rate ($6 per hour) for the estimated time the study took (10 minutes ($1) for the between subjects experiments, 15 minutes ($1.50) for the within subjects experiments). Participants completing the study were paid for the full expected time, even though most completed more quickly.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1">Demographics</head><p>We recruited 778 participants in total, 453 (58%) men and 325 (42%) women. Ages ranged from 18-65 (µ age = 32.6, σ age =10.5). 117 participants were recruited for pilot studies and other test experiments that are not included in the final analysis. While the age data seem close to the expected values of U.S. Turkers as a whole, our gender ratios do not match the self-reported demographics of U.S. Turkers as measured in previous studies <ref type="bibr" target="#b46">[47]</ref>, indicating either a shift in demographics for Turk as a whole, or a recruited population with a different profile than in previous census tasks (as an example our task was higher paying than tasks designed just for self-reporting of demographic data, which may attract a different participant pool).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">EXPERIMENTS</head><p>In Section 1.1, we made predictions about the mean comparison task. These lead to a set of hypotheses:</p><p>1. Our parameter ∆ would be a useful metric for task hardnessacross all experiments, ∆ would be positively correlated with overall performance at the mean estimation task.</p><p>2. Within reasonable bounds, increasing the number of points would not significantly hurt performance.</p><p>3. Color, as a very strong cue, would have higher performance than other choices for primary cue, such as shape or orientation.</p><p>4. Using multiple cues to redundantly encode class membership would not significantly help performance -since efficient selection is accomplished using a single feature, so making the selection easier would not translate to improved accuracy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>5.</head><p>Having a second cue which is non-informative as to class membership would not hurt performance, for similar reasons.</p><p>6. Adding additional classes which were non-informative to the binary forced choice would also not hurt performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>7.</head><p>A sufficient diversity of distractions will impair performance.</p><p>We ran an initial set of between-subjects experiments to confirm or disconfirm these hypotheses. Since many of our hypotheses (2,4,5,6) were suppositions about negative results, we also performed a set of within-subjects experiments where negative results would be stronger statements about the actual difference in means.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Experiment Set One (Between-Subjects)</head><p>We performed a series of eleven disjoint experiments that we treat as one between-subjects experiment 2 in order to initially explore the parameter space for encodings and confirm our hypotheses about the pre-attentive aspects of the mean estimation task. In each experiment participants were exposed to a single type of multiclass scatterplot.</p><p>Participants were shown 39 total stimuli in random order -six stimuli from each of six different levels of our proposed hardness parameter ∆ (the pixel difference between means of the two classes in the scatterplot): 8, 16, 24, 32, 40, and 80 pixels. In addition there were three questions with a ∆ of 0 pixels -that is, both classes had identical means. The ∆ = 80 questions were used for validation purposes -if participants did not get more than 50% of these questions correct then they were excluded from analysis. The ∆ = 0 questions were used to determine if there was systematic bias towards one answer or another (the expected distribution of answers should be approximately even at this level, since the participants would be essentially guessing). Both the ∆ = 80 and ∆ = 0 questions were otherwise excluded from the main analysis. 32 participants were recruited for each experiment. Participants not meeting the inclusion criteria were removed entirely from the main analysis, but no additional participants were recruited. Ultimately 40 exclusions were made using this criterion, out of a total participant pool of 352 people.</p><p>We performed eleven experiments with this general model, each with a different choice of class encoding. <ref type="figure">Figure 4</ref> summarizes these choices of encoding. We had three main groups of encoding: one in which hue was used to encode class membership (in this case one class was orange and the other purple), shape encodings of class membership (one class had circular glyphs and the other triangular glyphs), and a single experiment where luminance was used (one class with light gray glyphs and the other dark gray glyphs). We also investigated the effect of having additional encodings layered on top of the main class encoding, which either supported the main cue (they were redundant with the main encoding) or provided no information (they conflicted with the main encoding).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.1">Results</head><p>Our results across all experiments in this set confirmed hypothesis 1: as ∆ increased, participants performed monotonically better. <ref type="figure">Figure 5</ref> presents these results broken down by ∆. A one-tailed t-test confirmed that even at our lowest sampled level of ∆, participants still performed significantly better than chance (t(1868)=9.89, p(µ x &lt; 0.5) &lt; 0.0001. Hypothesis 3 was also confirmed by this set of experiments. We conducted a two-way Analysis of Variance (ANOVA) to determine the effect of our eleven encoding/secondary cue choices on performance. We found a significant effect of this factor on performance (F(10,9328) = 9.91, p &lt; 0.001). Post hoc analysis using a Tukey test of Honest Significant Difference (HSD) revealed two clusters of performance: one cluster where color (hue or luminance) was used as the main cue, which significantly outperformed the cluster where shape was used as the main cue.</p><p>This clustering also provides evidence that causes us to fail to reject our other hypotheses (2,4,5, and 6). There was no significant difference between performance when the number of points per class was increased from 50 to 75 (experiment 1c), nor when additional classes of points were included (experiment 1d,1h), or when secondary cues where used (either redundantly as in experiment 1e or in conflict with the main cue as in experiments 1f and 1k). While these similar levels of performance provided some evidence of the validity of these hypotheses, we decided that a between-subjects experiment was an insufficiently powerful model to capture these negative results. <ref type="figure">Figure 4</ref> presents the results of experiment block one in detail.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Experiment Set Two (Within-Subjects)</head><p>In order to reconfirm our results with a stronger model of participant variance, as well as explore the inter-relation between more specific classes of encodings, we performed nine within-subjects experiments in which one participant saw two different sets of scatterplots with different sets of encodings.</p><p>The task and parameters of the stimuli were similar to the first set of experiments. One difference is that participants were given two "blocks," each containing 36 different scatterplots, for a total of 72 questions. In each block there were an equal number of stimuli with the following pixel differences (our ∆ parameter) between the per-class Δ (pixels) <ref type="figure">Fig. 5</ref>. The effect of our proposed hardness parameter ∆ on hardness across all of our between-subjects experiments. ∆ represents the difference, in pixels, between the mean values of each class in a particular scatterplot. As ∆ increases the comparative judgement of which class of points is on average higher becomes easier.</p><p>means: 4, 12, 20, 28, 36, and 80. These ∆ values were chosen to provide more information about the more difficult questions while still containing enough easier questions to not discourage participants. The ∆ = 80 questions were used for validation but otherwise excluded from analysis: if participants got 50% or fewer correct they were excluded. One block was a "baseline" block with a simpler choice of encoding, and the second had a more difficult encoding scheme. The presentation order was counter-balanced across all participants such that an equal number was exposed to each presentation order. If an exclusion was made additional participants were recruited dynamically, so that for the final analysis 16 participants were exposed to each presentation order for a total of 32 participants. 27 additional participants were recruited for this purpose, for a total subject pool of 319 people. The choices of main encoding across these experiments, as well as the choices of difference between the first and second blocks, were aligned to provide additional evidence for hypotheses 2,4,5, and 6, for which we had some evidence of validity from our previous set of experiments, but no concrete measures of interaction between the baseline condition and individual factors (increasing the number of points, adding redundant cues, adding conflicting cues, and adding additional classes respectively). <ref type="figure">Figure 6</ref> lists these choices of encoding in detail. Color as conflicting cue. p = 0.91 <ref type="figure">Fig. 6</ref>. An overview of results from our within-subjects experiments. Participants were presented with two different classes of stimuli in discrete blocks (presentation order was counterbalanced across participants). Unless otherwise noted, each stimulus had 50 points of each class. Statistical significance was determined via a two-way ANOVA. Green rows indicate significant difference (p &lt; .05) in performance between the two blocks, light green indicates statistically marginal difference (.1 &gt; p &gt; .05), white indicates no significant difference between blocks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1">Results</head><p>This block of experiments provided more evidence for hypothesis 2 (that additional points would not make the mean estimation task more difficult). We performed a repeated measures ANOVA (rANOVA) on experiment 2d to determine the effect of block (where one block had 75 points per class, and the other had 50 points per class) on performance. There was a marginal effect of adding additional points on performance (F(1,2110)=2.83, p = 0.09), but as the number of points increased performance was marginally higher (accuracy of 75.8% when there were only 50 points per class versus 78.9% when there were 75 points per class), not lower (as one would expect if adding additional points hurt performance). Our experiments also provided more evidence for hypothesis 4: experiments 2g and 2h both dealt with redundancy, using color and shape simultaneously to encode class membership. Two rANOVAs were performed on experiments 2g and 2h to determine the effect on the inclusion of redundancy on performance. Performance was not significantly different comparing these redundant encodings to color encoding alone (2g, F(1,1917)=0.36, p = 0.55 ) or shape encoding alone (2h, F(1,1917)=0.01, p = 0.91).</p><p>Likewise experiments 2a, 2b, 2c, 2e, and 2i all featured conflicting cues, providing evidence concerning hypothesis 5. In experiments 2b, 2c, and 2i the addition of a cue which conflicted with the main class membership cue was the only difference between blocks. rA-NOVAs were performed on each of these experiments. For 2i (where the main cue was shape, and color of stroke was added as a conflicting cue) there was no significant effect of conflict on performance (F(1,1917)=0.01, p = 0.91). There were marginal effects of performance for 2b, where color was the main cue and shape was used as a distractor <ref type="figure">(F(1,1917)</ref>=3.2, p = 0.07), but it was the presence of conflict where performance was higher (80.1% accuracy where shape conflict was present, 76.8% where shape conflict was absent). Experiment 2c had shape as the primary cue with color as conflict: there was also a marginal effect of conflict on performance (F(1,1917)=3.2, p = 0.07), but in this case it was the absence of conflict where performance was marginally better (76.4% accuracy where there was no color conflict vs. 72.9% accuracy where conflict was present).</p><p>Experiments 2a, 2e, and 2f all featured a third distracting class of points that were meant to provide evidence for hypothesis 6. In experiment 2f the addition of a third class was the only difference between blocks. We performed an rANOVA on experiment 2f to test for the effect of the presence of an additional class of points on performance. We found no significant effect (F(1,1917)=0.54, p = 0.46).</p><p>Experiments 2a and 2e dealt with the conjunction of hypotheses 5 and 6, and provide evidence for hypothesis 7. Experiments 2b and 2f discussed previously provided evidence that the addition of a shape as a conflicting cue, and the addition of another class of points, were by themselves not significant effects on performance. Likewise, an rA-NOVA performed on experiment 2e to check of the effect of shape conflict once a distractor class is already present on performance showed no significant effect (F(1,1917)=0.74, p = 0.39). Only when the jump was made from stimuli with neither additional classes nor shape conflict to stimuli where both were present (as in experiment 2a) was there a significant negative effect on performance (performance of 79.5% when no cue conflict or additional classes were present versus 75.5% when both cue conflict and additional were present). An rANOVA confirmed the statistical significance of this effect (F <ref type="bibr" target="#b0">(1,</ref><ref type="bibr">1917)</ref>=4.53, p &lt; 0.03). This is consistent with hypothesis 7.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">DISCUSSION</head><p>The mostly negative results of the first experiment set speak to the efficiency of this task: even with significant inter-participant variance from a diverse participant pool, and with a wide diversity of cues, aggregate performance across conditions differed only by as much as 13.1%. Within-cue variability was even lower: aggregate differences of 5.1% across eight experiments when hue was used as encoding, and 1.5% for both experiments where shape was used as the encoding.</p><p>Our experiments 2a, 2b, 2c, 2e, and 2i initially seem ambiguous as to the effect of conflicting encodings (additional cues beyond the main cue). While 2b, 2e, and 2i show no harm (or a marginal positive benefit) in the presence of conflicting encodings, 2a and 2c seem to point to a negative impact of cue conflict on performance. While marginal, the results of 2c might speak to our hypothesis that color is a much stronger cue for selection than other cues like shape (which is reflected in the literature, where color selection is more efficient in terms of accuracy and precision compared to many other potential choices of encoding <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b55">56]</ref>). This would also explain why experiment 2i, which was very similar in design and choices of cue, did not see a similar degradation in performance -by using stroke color rather than fill color, the salience of color as a potentially distracting cue is reduced.</p><p>Experiment 2a represents an upper end to the complexity of the task: neither conflict (as in 2b) nor distractor classes (as in 2f) by themselves are sufficient to negatively affect performance. <ref type="figure">Figure 7</ref> shows this visual complexity of these various levels -resulting in a stimulus which is very dense and very visually complex. Visual complexity (and specifically visual clutter) has been shown to lead to errors in judgement <ref type="bibr" target="#b3">[4]</ref>. It is important to note that simply adding a few extra points does not add as much visual clutter as introducing visual heterogeneity to the existing points <ref type="bibr" target="#b45">[46]</ref>, which contributes to the negative result in experiment 2d. While it is likely that there is an upper limit (in terms of number of additional conflicting cues, or number of additional distracting classes) that would substantially reduce performance for the averaging task, in most real world settings the number  <ref type="figure">Fig. 7</ref>. An overview of the positive result in our within-subjects experiment. Performance was marginally better when conflicts in shape (7a vs. 7b) were included and statistically indistinguishable when distractor classes were included (7a vs. 7c), or when shape conflict was introduced to stimuli where a distractor class was already present (7c vs. 7d). Only when both potentially harmful conditions were introduced simultaneously (7a vs. 7d) was there a statistically significant impact on performance. of classes to be distinguished are relatively small, and the number of dimensions which are simultaneously to be encoded is also small.</p><p>In experiments 2g and 2h, we found that redundant encodings (shape and fill color; shape and stroke color) did not improve performance. This contrasts with both common wisdom and past empirical findings that Ware <ref type="bibr" target="#b58">[59]</ref> summarizes with the guideline "To make symbols in a set maximally distinctive, use redundant coding wherever possible" (guideline 5.11). Future work should re-evaluate this guideline.</p><p>These findings have ramifications for the design of multi-class scatterplots. First, viewers are capable of making judgements about the difference between classes, even when there are many points and the differences are small. This suggests that scatterplots can convey the inter-class differences without explicitly showing the means. The benefits of scatterplots in showing the data (e.g. distributions and trends) also afford communicating aggregate properties. Second, because conflicting cues do not hinder performance in the assessment of aggregates, layering information in multiple cues (e.g. using both color and shape to encode different properties) is likely to be an effective strategy. Third, because distractor classes have little effect on performance, multi-class scatterplots should not necessarily be avoided in favor of simpler ones. These guidelines are qualified by a number of limitations. For example they assume that the viewer has ample time to view the display and that the classes of points are sufficiently distinct. Other limitations are considered in the next section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Limitations and Future Work</head><p>We have tried to generate data in ways that preclude dominant strategies where the experimental participants can easily figure out the correct answers, for example by crafting our data so that choosing the maximal points does not work. It is impossible to know that such a strategy does not exist. We did ask participants to self-report their strategies at the end of the experiment, although this is generally a poor assessment of how they actually do the task. These self-reports did not reveal any clear dominant strategy (except for the top-most strategy in the pilot study). However, if the participants were able to develop a strategy over the course of the experiment (without us providing feedback, and without them showing learning effects), they would probably develop similar strategies in realistic tasks as well. Indeed, some of the strategies that a participant might apply still work within our model, as they require pre-attentive selection and aggregation.</p><p>Our experiments only consider a single distractor task. In theory, our model suggests that more distractor classes should not hinder performance. In practice, however, this is difficult to test or exploit: as more classes are added, they are (necessarily) less distinctive. This loss of distinctness of classes would cause a degradation of performance, even if the increase of the number of classes does not.</p><p>A key limitation of our study is that we do not manipulate timing. While the lack of hard time constraints may be more realistic, our experiments cannot explain what a viewer does with this time, or even show that having time makes a difference. Participants chose to spend more time than they were given in prior studies of rapid response tasks, despite the fact that, as crowd-workers, they have financial incentive to finish their tasks quickly.</p><p>Our data show that the same attentional limits that apply in rapid response tasks also apply in the non-time-constrained mean comparison task. Given this, we might wonder how more time might be helpful. Viewers choose to take more time when asked to focus on accuracy, presumably because they believe it will help, and we have initial pilot data that suggests performance does vary with time. We do not believe this is a contradiction: while more time cannot improve the performance of the attentional mechanisms, it does give a viewer the opportunity to use these mechanisms differently.</p><p>The overall task of making mean judgements from a scatterplot is a higher-level task than considered in the perception literature. Breaking the task into smaller subtasks presumes a model of what the subtasks are and how they integrate. Sections 1.1 and 2 already describe some of the subtasks: selecting individual collections and constructing average position values from each. Our data are consistent with these mechanisms being involved: their limitations can be seen in performance on the compound task.</p><p>The literature suggests that the subtasks may be assembled as a serial process -one feature value (e.g. red, or circles), and thus one collection, is selected at a time. This property stems from theories and supporting evidence that keeping representations of different objects or subsets of objects separated requires that they be isolated over time. Selecting multiple things at once mixes their properties within the visual system's representation <ref type="bibr" target="#b43">[44,</ref><ref type="bibr" target="#b54">55]</ref>. Thus, processing the individual group centers of two collections required that each group be isolated serially <ref type="bibr" target="#b32">[33,</ref><ref type="bibr" target="#b36">37]</ref>. Without such serial selection, these theories predict that the visual system could only provide the center of the entire superset, which is a useful statistic for many purposes, but not for determining the higher collection. For the same reasons, determining the spatial relationship between the two collection centerpoints (is collection A higher than collection B) also likely requires serial selection over time <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b47">48]</ref> The serial selection process suggests theories of what a viewer may do with more time. For example, they may make several passes of selection across each feature dimension, selecting one group of points by color, abstracting its mean value, and then doing the same for the other group. For novices at the task, extended amounts of time may be beneficial as they develop routines of serial selection, and they become even more efficient at ignoring otherwise salient information from distractor collections. Even with practice, repeating this serial cycle may allow even expert observers to increase their accuracy for the collection difference, by combining information from several judgements, especially given that spatial memory for the means is likely to be noisy and time-limited.</p><p>A future goal is to better understand the specific subtasks as well as the mechanisms by which they are combined. We have begun pi-lot explorations, both by considering the subtasks independently and by better instrumenting our observations of performance of the compound tasks. While our present studies focus on aggregation in scatterplots, we hope to consider other tasks to develop and validate a general model of non-time-constrained performance in visual aggregation tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">CONCLUSION</head><p>In this paper, we have studied empirically the human ability to meaningfully, efficiently, and accurately compare average value in multiclass scatterplots. Using stimuli with longer exposure times and more varied difficulty levels than in previous work we show that, within reasonable limits, this ability is robust across scatterplots with differing numbers of points per class, additional distracting classes, and with additional conflicting cues. Encoding data with redundant cues, which common wisdom would suggest would be helpful for tasks where users must select individual classes from a group, is likewise not a factor in performance. We consider limitations of the mechanisms of attentional selection that have been established in simpler tasks under time constraints, and show that they apply in this compound task without time pressure. We believe that our methodology, and our model of assembling more basic subtasks to achieve compound performance, is extensible to a wide range of common tasks in information visualization, where users must extract and possibly compare the aggregate statistics of different classes in a display.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>(a) ∆ = 4 pixels. (b) ∆ = 12 pixels. (c) ∆ = 20 pixels. (d) ∆ = 28 pixels. (e) ∆ = 36 pixels.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Example stimuli from our various levels of task difficulty parameter ∆, the difference (in pixels) between classes in our scatterplots. When ∆ = 0, both classes of points have the same average. In 2a,2c,2e purple points have the highest average. For the others, orange points have the highest average. For this set of stimuli orange points always have the highest absolute value, to disambiguate averaging and peak-finding tasks. Even for the lowest levels of ∆ used in our experiments, aggregate performance was significantly better than chance.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>(a) A baseline condition: no distracting groups, no conflict in encoding. (b) The conflict condition: the shape cue conflicts with the main cue of color. (c) The distractor condition: there is an extra class of green points (d) Both conflicting cues and a distractor class are present.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>User performances in the first block of between-subjects experiments. Unless otherwise noted, participants saw 50 points of each class of glyph and were asked to guess which class was on average higher. Using the results of a Tukey's HSD, light green rows were statistically indistinguishable from each other but significantly different from the orange rows, and vice versa.</figDesc><table><row><cell>Label</cell><cell>Encoding</cell><cell>Glyphs</cell><cell>Notes</cell><cell>Accuracy</cell></row><row><cell>a)</cell><cell>Hue</cell><cell>vs.</cell><cell>-</cell><cell>79.4%</cell></row><row><cell>b)</cell><cell>Hue</cell><cell>vs.</cell><cell>-</cell><cell>80.6%</cell></row><row><cell>c)</cell><cell>Hue</cell><cell>vs.</cell><cell>75 points per class</cell><cell>84.5%</cell></row><row><cell>d)</cell><cell>Hue</cell><cell>vs.</cell><cell>distractor points</cell><cell>83.8%</cell></row><row><cell>e)</cell><cell>Hue</cell><cell>vs.</cell><cell>Shape as redundant cue</cell><cell>82.8%</cell></row><row><cell>f)</cell><cell>Hue</cell><cell>vs.</cell><cell>Shape as conflicting cue</cell><cell>79.8%</cell></row><row><cell>g)</cell><cell>Hue</cell><cell>vs.</cell><cell cols="2">Orientation as conflicting cue 84.2%</cell></row><row><cell>h)</cell><cell>Hue</cell><cell>vs.</cell><cell>distractor points</cell><cell>80.0%</cell></row><row><cell>i)</cell><cell>Luminance</cell><cell>vs.</cell><cell>-</cell><cell>79.2%</cell></row><row><cell>j)</cell><cell>Shape</cell><cell>vs.</cell><cell>-</cell><cell>72.9%</cell></row><row><cell>k)</cell><cell>Shape</cell><cell>vs.</cell><cell>Color as conflicting cue</cell><cell>71.4%</cell></row><row><cell>Fig. 4.</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">Further details of the experiments, including stimuli, instructions, and result tables are available at the project website http://graphics.cs.wisc.edu/Vis/ScatterVis13/.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">We note that this was a sequential series of experiments, and not a proper single between-subjects experiment, as we ran different conditions on different days at different times. Since the participant pool of Mechanical Turkers may vary widely depending on time of day, this was a potential source of variance in our results which we could not adequately model, although experiments were run at similar times each day.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS</head><p>This work was supported in part by NSF awards CMMI-0941013, BCS-1056730, SBE-1041707, DRL-0918409, DRL-1247262, and IIS-1162037 and NIH award R01 AU974787.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">The representation of simple ensemble visual features outside the focus of attention</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">A</forename><surname>Alvarez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Oliva</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Science</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="392" to="398" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Spatial ensemble statistics are efficient codes that can be represented with reduced attention</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">A</forename><surname>Alvarez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Oliva</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the National Academy of Sciences of the United States of America</title>
		<meeting>the National Academy of Sciences of the United States of America</meeting>
		<imprint>
			<date type="published" when="2009-05" />
			<biblScope unit="volume">106</biblScope>
			<biblScope unit="page" from="7345" to="50" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Seeing sets: Representation by statistical properties</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ariely</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Science</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="157" to="162" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Visual clutter causes highmagnitude errors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Baldassi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Megna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">C</forename><surname>Burr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS biology</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">56</biblScope>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">The size of an attentional window modulates attentional capture by color singletons</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">V</forename><surname>Belopolsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zwaan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Theeuwes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">F</forename><surname>Kramer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychonomic bulletin &amp; review</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="934" to="942" />
			<date type="published" when="2007-10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Amazon&apos;s mechanical turk a new source of inexpensive, yet high-quality, data?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Buhrmester</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kwang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">D</forename><surname>Gosling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Perspectives on Psychological Science</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="3" to="5" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Cortical plasticity: from synapses to maps. Annual review of neuroscience</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">V</forename><surname>Buonomano</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">M</forename><surname>Merzenich</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998-01" />
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="149" to="86" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Dimensional interaction of hue and brightness in preattentive field segregation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">C</forename><surname>Callaghan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Perception &amp; psychophysics</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="25" to="34" />
			<date type="published" when="1984-07" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Interference and dominance in texture segregation: hue, geometric form, and line orientation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">C</forename><surname>Callaghan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Perception &amp; psychophysics</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="299" to="311" />
			<date type="published" when="1989-10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Statistical processing: computing the average size in perceptual groups</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">C</forename><surname>Chong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Treisman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Vision research</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="891" to="900" />
			<date type="published" when="2005-03" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Average orientation is more accessible through object boundaries than surface features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Choo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">R</forename><surname>Levinthal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">L</forename><surname>Franconeri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: Human Perception and Performance</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">585</biblScope>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Review and Analysis of Color Coding Research for Visual Displays</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">E</forename><surname>Christ</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Human Factors: The Journal of the Human Factors and Ergonomics Society</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="542" to="570" />
			<date type="published" when="1975-12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">A color-caused optical illusion on a statistical graph</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">S</forename><surname>Cleveland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">S</forename><surname>Cleveland</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The American Statistician</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="101" to="105" />
			<date type="published" when="1983" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Comparing averages in time series data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Correll</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Albers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Franconeri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gleicher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2012 ACM annual conference on Human Factors in Computing Systems (CHI 2012)</title>
		<meeting>the 2012 ACM annual conference on Human Factors in Computing Systems (CHI 2012)</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1095" to="1104" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Quantity estimation in visualizations of tagged text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Correll</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Alexander</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gleicher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 ACM annual conference on Human Factors in Computing Systems (CHI 2013)</title>
		<meeting>the 2013 ACM annual conference on Human Factors in Computing Systems (CHI 2013)</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="2697" to="2706" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Class visualization of highdimensional data with applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">S</forename><surname>Dhillon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">S</forename><surname>Modha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Spangler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Statistics &amp; Data Analysis</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="59" to="90" />
			<date type="published" when="2002-11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">The perception of scatterplots</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">E</forename><surname>Doherty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">B</forename><surname>Anderson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">M</forename><surname>Angott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">S</forename><surname>Klopfer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Perception, &amp; Psychophysics</title>
		<imprint>
			<biblScope unit="volume">69</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1261" to="1272" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
	<note>Attention</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Color in visual search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>D'zmura</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Vision research</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="951" to="966" />
			<date type="published" when="1991" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Why salience is not enough: reflections on top-down selection in vision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">E</forename><surname>Egeth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">J</forename><surname>Leonard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">B</forename><surname>Leber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Acta psychologica</title>
		<imprint>
			<biblScope unit="volume">135</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="130" to="132" />
			<date type="published" when="2010-10" />
		</imprint>
	</monogr>
	<note>discussion 133-9</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Influence of scene-based properties on visual search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">T</forename><surname>Enns</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">A</forename><surname>Rensink</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">247</biblScope>
			<biblScope unit="issue">4943</biblScope>
			<biblScope unit="page" from="721" to="724" />
			<date type="published" when="1990-02" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Fouriezos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Rubenfeld</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Capstick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Visual statistical decisions. Attention</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="page" from="456" to="464" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Number estimation relies on a set of segmented objects</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Franconeri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Bemis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Alvarez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognition</title>
		<imprint>
			<biblScope unit="volume">113</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="13" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Oxford Handbook of Cognitive Psychology, chapter 10</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">L</forename><surname>Franconeri</surname></persName>
		</author>
		<editor>D. Reisberg</editor>
		<imprint>
			<date type="published" when="2013" />
			<publisher>Oxford University Press</publisher>
		</imprint>
	</monogr>
	<note>The nature and status of visual resources</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Flexible cognitive resources: competitive content maps for attention and memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">L</forename><surname>Franconeri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">A</forename><surname>Alvarez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Cavanagh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Trends in cognitive sciences</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Flexible visual processing of spatial relationships</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">L</forename><surname>Franconeri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Scimeca</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">C</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">A</forename><surname>Helseth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">E</forename><surname>Kahn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognition</title>
		<imprint>
			<biblScope unit="volume">122</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="210" to="237" />
			<date type="published" when="2012-02" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Rapid extraction of mean emotion and gender from sets of faces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Haberman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Whitney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Current Biology</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">17</biblScope>
			<biblScope unit="page" from="751" to="753" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Multiple spatially overlapping sets can be enumerated in parallel</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Halberda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">F</forename><surname>Sires</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Feigenson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological science</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="572" to="578" />
			<date type="published" when="2006-07" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Tests for detection and analysis of color blindness: I. an evaluation of the ishihara test</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">G H</forename><surname>Hardy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Rand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">C</forename><surname>Rittler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Archives of Ophthalmology</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">295</biblScope>
			<date type="published" when="1945" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">How Capacity Limits of Attention Influence Information Visualization Effectiveness</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Haroz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Whitney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2402" to="2410" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Colorbrewer. org: an online tool for selecting colour schemes for maps</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Harrower</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Brewer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cartographic Journal, The</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="27" to="37" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">High-speed visual estimation using preattentive processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">G</forename><surname>Healey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">S</forename><surname>Booth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">T</forename><surname>Enns</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Computer-Human Interaction</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="107" to="135" />
			<date type="published" when="1996-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Crowdsourcing graphical perception: using mechanical turk to assess visualization design</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Heer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bostock</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2010 ACM annual conference on Human Factors in Computing Systems (CHI 2010)</title>
		<meeting>the 2010 ACM annual conference on Human Factors in Computing Systems (CHI 2010)</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="203" to="212" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">A boolean map theory of visual attention</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Pashler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological review</title>
		<imprint>
			<biblScope unit="volume">114</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">599</biblScope>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Computational modeling of visual attention</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Itti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Koch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature reviews neuroscience</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="194" to="203" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Do mechanical turks dream of square pie charts?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Kosara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Ziemkiewicz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 3rd BELIV&apos;10 Workshop: BEyond time and errors: novel evaLuation methods for Information Visualization</title>
		<meeting>the 3rd BELIV&apos;10 Workshop: BEyond time and errors: novel evaLuation methods for Information Visualization</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="63" to="70" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">A comparison of methods for generating poisson disk distributions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lagae</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dutré</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Graphics Forum</title>
		<imprint>
			<publisher>Wiley Online Library</publisher>
			<date type="published" when="2008" />
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="114" to="129" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Common-fate grouping as feature selection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">R</forename><surname>Levinthal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">L</forename><surname>Franconeri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological science</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1132" to="1137" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">A model of symbol size discrimination in scatterplots</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-B</forename><surname>Martens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">J</forename><surname>Van Wijk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2010 ACM annual conference on Human Factors in Computing Systems (CHI 2010)</title>
		<meeting>the 2010 ACM annual conference on Human Factors in Computing Systems (CHI 2010)</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="2553" to="2562" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">A model of symbol lightness discrimination in sparse scatterplots</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">J</forename><surname>Van Wijk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-B</forename><surname>Martens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Pacific Visualization Symposium (PacificVis)</title>
		<imprint>
			<date type="published" when="2010-03" />
			<biblScope unit="page" from="105" to="112" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Ensemble representations: Effects of set size and item heterogeneity on average size perception</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">P</forename><surname>Marchant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">J</forename><surname>Simons</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">W</forename><surname>De Fockert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Acta psychologica</title>
		<imprint>
			<biblScope unit="volume">142</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="245" to="50" />
			<date type="published" when="2013-02" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">Shapes, surfaces and saccades. Vision Research</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Melcher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Kowler</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999-08" />
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page" from="2929" to="2946" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Spectrally optimal sampling for distribution ray tracing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Mitchell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM SIGGRAPH Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="157" to="164" />
			<date type="published" when="1991-07" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Running experiments on amazon mechanical turk</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Paolacci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Chandler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Ipeirotis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Judgment and Decision Making</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="411" to="419" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">The Dynamic Representation of Scenes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">A</forename><surname>Rensink</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Visual Cognition</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="17" to="42" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">The perception of correlation in scatterplots</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">A</forename><surname>Rensink</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Baldridge</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Graphics Forum</title>
		<imprint>
			<publisher>Wiley Online Library</publisher>
			<date type="published" when="2010" />
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="1203" to="1210" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Measuring visual clutter</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Rosenholtz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Nakano</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Vision</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Who are the crowdworkers?: shifting demographics in mechanical turk</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Irani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Silberman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zaldivar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Tomlinson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Extended Abstracts on Human Factors in Computing Systems (CHI EA &apos;10)</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="2863" to="2872" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Asymmetric coding of categorical spatial relations in both language and vision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">C</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">L</forename><surname>Franconeri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Frontiers in psychology</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">464</biblScope>
			<date type="published" when="2012-01" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Global feature-based attention for motion and color</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sàenz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">T</forename><surname>Buraĉas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">M</forename><surname>Boynton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Vision Research</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="629" to="637" />
			<date type="published" when="2003-03" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">A Taxonomy of Visual Cluster Separation Factors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sedlmair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Tatu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Munzner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Tory</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics Forum</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">3pt4</biblScope>
			<biblScope unit="page" from="1335" to="1344" />
			<date type="published" when="2012-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Feature-based attentional modulations in the absence of direct visual stimulation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">T</forename><surname>Serences</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">M</forename><surname>Boynton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuron</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="301" to="312" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Selecting good views of high-dimensional data using class consistency</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sips</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Neubert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">P</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Hanrahan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics Forum</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="831" to="838" />
			<date type="published" when="2009-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">The size-color illusion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Tedford</surname><genName>Jr</genName></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bergquist</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Flynn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of General Psychology</title>
		<imprint>
			<biblScope unit="volume">97</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="145" to="149" />
			<date type="published" when="1977" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Preattentive processing in vision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Treisman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer vision, graphics, and image processing</title>
		<imprint>
			<date type="published" when="1985" />
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="156" to="177" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">The binding problem</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Treisman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Current Opinion in Neurobiology</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="171" to="178" />
			<date type="published" when="1996-04" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Feature analysis in early vision: evidence from search asymmetries</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Treisman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gormican</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological review</title>
		<imprint>
			<biblScope unit="volume">95</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="15" to="48" />
			<date type="published" when="1988-01" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">A feature-integration theory of attention</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">M</forename><surname>Treisman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Gelade</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognitive psychology</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="97" to="136" />
			<date type="published" when="1980-01" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">The limits of top-down control of visual attention</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Van Der Stigchel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">V</forename><surname>Belopolsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">C</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">G</forename><surname>Wijnen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Meeter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Theeuwes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Acta psychologica</title>
		<imprint>
			<biblScope unit="volume">132</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="201" to="213" />
			<date type="published" when="2009-11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<monogr>
		<title level="m" type="main">Information Visualization: Perception for Design</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Ware</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
			<publisher>Morgan Kaufmann</publisher>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
