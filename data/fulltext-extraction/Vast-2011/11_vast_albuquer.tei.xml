<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/pisenberg/grobid/grobid-0.6.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Perception-Based Visual Quality Measures</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georgia</forename><surname>Albuquerque</surname></persName>
							<email>georgia@cg.cs.tu-bs.de</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">U</forename><surname>Braunschweig Germany</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Eisemann</surname></persName>
							<email>eisemann@cg.cs.tu-bs.de</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcus</forename><surname>Magnor</surname></persName>
							<email>magnor@cg.cs.tu-bs.de</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Braunschweig</forename><surname>Tu</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Germany</surname></persName>
						</author>
						<title level="a" type="main">Perception-Based Visual Quality Measures</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2021-02-19T19:55+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval-</term>
					<term>Clustering</term>
					<term>I.3.3 [Computer Graphics]: Picture/Image Generation</term>
				</keywords>
			</textClass>
			<abstract>
				<p>In recent years diverse quality measures to support the exploration of high-dimensional data sets have been proposed. Such measures can be very useful to rank and select information-bearing projections of very high dimensional data, when the visual exploration of all possible projections becomes unfeasible. But even though a ranking of the low dimensional projections may support the user in the visual exploration task, different measures deliver different distances between the views that do not necessarily match the expectations of human perception. As an alternative solution, we propose a perception-based approach that, similar to the existing measures, can be used to select information bearing projections of the data. Specifically, we construct a perceptual embedding for the different projections based on the data from a psychophysics study and multi-dimensional scaling. This embedding together with a ranking function is then used to estimate the value of the projections for a specific user task in a perceptual sense.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Innovative approaches in visual analytics for high-dimensional data sets have presented quality measures that can be used to automatically select promising projections of the data <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b13">14]</ref>. The visual analysis of such data sets usually requires projecting the data into lower-dimensional representations. However, with the increasing amount of dimensions in scientific data sets the exhaustive analysis of all possible projections requires prohibitive time. So-called quality measures have been used in a pre-processing phase to the visual exploration. They can be effectively used to rank the possible projections of the data according to one or more user tasks and reduce the number of views to be examined by sorting them or selecting the best ones.</p><p>Usually defined with respect to an exploration task, the quality measures can be defined as ranking functions for the projections.</p><p>However, an open issue of these methods is that the range and distribution of ranking values depends on the algorithm of each individual measure and it is not possible to directly compare the results of the different measures. Specifically, the possible values of the measures are often relative values and it is therefore impractical to quantify the amount of structure present in a projection for a specific user task.</p><p>In contrast, we propose a quality measure to appraise the quality of a certain projection based on human perception. By means of a psychophysics study we estimate the similarity between the projections in a perceptual space and define a measure based on these observations. Compared to the previously presented methods, our approach has the advantage that the values assigned to the projections have a direct relation to the perceptual quality impression of human beings. In our case especially, it aims at matching the perceptual quality of visual analysts. The presented measure is very general, can be trained for a variety of exploration tasks and exploits measures derived from the human visual system to rank new unknown visualizations. Our contributions in this paper are:</p><p>• a new quality measure for projections of high-dimensional data sets based on human perception;</p><p>• the measure is generally applicable, as it can be trained for different visualizations and user tasks;</p><p>• it allows comparison of a variety of quality measures by projecting their results into our perceptual quality measure;</p><p>• we show how to train, rank and optimize our method for specific user tasks.</p><p>We present results on evaluating and ranking scatterplots for two exploration tasks: finding correlation between the dimensions and separation between classes. However, the extension to other visualization methods, e.g. parallel coordinate and pixel based displays, and other user tasks, should be straightforward. The quality estimation for scatterplots is made based on two psychophysics studies concerning each user task. The first study is used to measure similarity and dissimilarity between the visualizations. The second study estimates a ranking based on the user task. Additionally, our method allows comparison of different measures directly by mapping the acquired quality values of the visualizations into our perceptual ranking scheme.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">BACKGROUND</head><p>There have been numerous publications that proposed methods to support the exploration of high-dimensional data sets. Asimov presented the Grand Tour <ref type="bibr" target="#b3">[4]</ref> as an approach to exhaustively analyze a dataset using low-dimensional projections. The main idea was to supply the user with a complete overview of the data by generating sequences of two-dimensional projections. Nevertheless, the extensive exploration of high-dimensional datasets is usually effortful and time consuming. To address this issue different quality measures to select the best views of data sets have been proposed: From the Projection Pursuit <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b8">9]</ref> method, over the well known Scagnostics indices <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b17">18]</ref>, to more recent metrics for different visualization methods and user tasks <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b4">5]</ref>. All those measures can be used to support the visual analysis of high-dimensional data sets, but they do not necessarily relate to the analysts opinion.</p><p>An initial study towards human perception with visual quality metrics for multidimensional data has been proposed in <ref type="bibr" target="#b14">[15]</ref>. Tatu et al. did a user study to investigate the relationship between human perception and automatically computed measures. The authors compared three different measures from <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b13">14]</ref> that can be used to estimate class separation in scatterplots and showed which measure better fits the user's opinion. Our approach is different in the sense that we propose an automatic measure based on user perception itself. Specifically, the proposed distance in the ranking function of the scatterplots is optimized to resemble the distance in a perceptual embedding for scatterplots.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IEEE Symposium on Visual Analytics Science and Technology</head><p>October 23 -28, Providence, Rhode Island, USA 978-1-4673-0013-1/11/$26.00 ©2011 IEEE In this work we use the analysis of paired comparisons <ref type="bibr" target="#b5">[6]</ref> where an individual expresses a preference between two mutually distinct scatterplots. Such comparison studies have been successfully used to produce rankings <ref type="bibr" target="#b5">[6]</ref>. Recently, Wills et al. <ref type="bibr" target="#b18">[19]</ref> proposed a method to construct a low-dimensional perceptual embedding for bidirectional reflectance distribution functions that can be used to navigate in the space of gloss and construct new materials. The perception space is built based on a user study with paired comparisons and an extended multidimensional non-metric scaling algorithm. This multidimensional scaling algorithm copes with incomplete and inconsistent dissimilarity matrices and can therefore be trained using observations from a paired comparisons study. A detailed description of the multidimensional scaling algorithm is presented by Agarwal et al. <ref type="bibr" target="#b0">[1]</ref>. Inspired by this, we construct a similar embedding for scatterplots that, together with a ranking function, can be used as a visual quality measure to quantify the value of the projection given a specific user task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">OVERVIEW</head><p>In this paper we present a perception-based quality measure to appraise the quality of visualizations. The goodness values assigned to the visualization by this novel measure are based on human observations from paired comparison studies. In particular, the distances between the measure values are optimized to be consistent with an estimated perception distance between the corresponding visualizations. It can be applied for a variety of visualizations and exploration tasks. However, for the presentation in this paper we concentrated on scatterplots and the user task of two-dimensional correlation search and class separation. <ref type="figure" target="#fig_0">Figure 1</ref> gives an overview of our technique. It can be divided in two main phases: a training phase where the measure is trained for a specific user task and a test phase where new visualizations can be ranked by the finished measure. The method starts with the training phase. First, a set of visualizations for the specific exploration task is chosen, and then a perceptual two-dimensional embedding P for the defined task and visualization is trained based on this set. This embedding provides a perceptually motivated similarity measure to compare different visualizations. However the embedding alone is not enough to decide when a visualization is better than another, according to the exploration task. In order to compare the quality of the visualization, we initialize a second, one-dimensional space R for ranking the visualizations. In a final stage we optimize the distances in R to resemble the distances in the perceptional embedding. This optimized ranking space R is then used to evaluate the quality of new visualizations, according to their similarity to the visualizations in the ranking space. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">PERCEPTUAL SPACE FOR SCATTERPLOTS</head><p>Our perception-based quality measure is defined based on two user studies with paired comparisons: The first is used to estimate mutual perceptual distances between the plots (Section 4.1). The second is used to define a ranking function (Section 4.2). For each user task, a collection of scatterplots S is chosen to train the perceptual embedding and perceptual ranking. The scatterplots can be either synthetically created or taken from the projections of existing high-dimensional data sets. Choosing a representative training set S for the desired user task is of fundamental importance as it directly reflects the coverage of the final measure. A series of scatterplot triplets is presented to each participant of the study. For each triplet, the participant is asked to decide which of the lateral images is more similar to the central one.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Perceptual Embedding</head><p>Once we have defined the exploration task, the perception embedding P for scatterplots is built in a two-step approach <ref type="bibr" target="#b18">[19]</ref>: In the first step, a user study to estimate similarity between scatterplots is performed. In this study, a series of scatterplot triplets is presented to each participant. For each triplet, the participant is asked to decide which of the lateral images is more similar to the central one according to the specific exploration task ( <ref type="figure" target="#fig_1">Figure 2</ref>). The scatterplots are randomly selected from the training set and are different from each other in the triplet. The result of the study is stored as a list of inequalities in the form:</p><formula xml:id="formula_0">L P = {(i, j, k)|d i j ≤ d jk },<label>(1)</label></formula><p>where i, j, k are indices of the scatterplots and d i j denotes the perceptual distance between the scatterplots i and j. At this stage we do not know the absolute values of d i j and d jk , but due to the user input we know the correct ordering of i, j, k to fulfill the inequality.</p><p>In the second step, the set L P is used to train the embedding using a general non-metric multidimensional scaling algorithm (GN-MDS) <ref type="bibr" target="#b0">[1]</ref>. Multidimensional scaling (MDS) can be defined as the process of assigning Euclidean coordinates to a set of objects based on a set of constraints. These constraints can be a set of dissimilarities, similarities or ordinal relations between the objects. The coordinates are assigned to the objects by fitting as close as possible to these constraints. The GNMDS method was developed to learn a low rank embedding from a collection of paired comparisons, applying convex optimization techniques, as described in Agarwal et al. <ref type="bibr" target="#b0">[1]</ref>. While in the classical MDS the dissimilarity values of the objects are directly interpreted as Euclidean distances, in the GN-MDS, only the relative order of the object dissimilarities is necessary. Specially, the GNMDS method has the advantage that it can be used in a variety of cases where the magnitude of the dissimilarity is uncertain or unknown, as is the case in the aforementioned paired comparison study. The method can deal with repetitions and inconsistencies that commonly arise in such studies as distinct participants may have different opinions when comparing the scatterplots. The evaluation of a set L P using this algorithm results in a two-dimensional embedding P of the visualizations, so that the distances in this embedding directly correlate to the user's perception. <ref type="figure">Figure 8</ref> shows an embedding example trained for the correlation task according to the user's expectation of similarity between the scatterplots. <ref type="figure">Figure 3</ref>: Screenshot of the rank comparison test. A series of scatterplot pairs is presented to each participant of the study. For each pair, the participant is asked to decide which of the visualizations has a higher quality considering a specific task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Perceptual Ranking</head><p>Given the perceptual embedding P for the scatterplots, we are able to measure the perceptual distance between them. We now need an efficient way to define a ranking function for the corresponding scatterplots. Our perception ranking R is defined in a three step approach:</p><p>To estimate the ordering of the scatterplots, we perform a second paired comparison study. In this study, two scatterplots are presented to the participants and they are asked to choose the best one considering the defined user task. <ref type="figure">Figure 3</ref> shows a screenshot of one of those tests. Similar to the first study, the presented scatterplots pairs are randomly chosen from the training set and the result is a collection of observations in the form:</p><formula xml:id="formula_1">L R = {(i, j)|p i &lt; p j },<label>(2)</label></formula><p>where i, j are indices of the scatterplots, p i represents the i th scatterplot and the inequality p i &lt; p j denotes that p j is better then p i , considering the chosen task.</p><p>Given the set of inequalities L R we need an efficient way to find an optimal ordering for the scatterplots of the training set. Considering that L R may contain inconsistencies, the problem of finding the optimal ordering for the visualizations is NP-Complete as its is equivalent to the Traveling Salesman problem. It therefore requires exhaustively searching all possible visualization arrangements. We use a greedy incremental algorithm to find a suitable order that obeys the observations in L R as close as possible. Our approach provides a trade-off between finding the optimal solution and completing all computations in a feasible time.</p><p>We start by reducing the inconsistencies between the inequalities in L R . We define v i j as the number of observations of L R in the form p i &lt; p j and v i j , the number of observations in the form</p><formula xml:id="formula_2">p j &lt; p i . p i is considered smaller than p j , only if v i j − v i j &gt; 0.</formula><p>To insert a new visualization into the current sequence we test all possible configurations for the new plot within the sequence and choose the one that best fits the observations in L R . This is done by incrementally placing the actual scatterplot in all possible configurations of the sequence and evaluating how the best ordering fits the observations in L R . The algorithm is initialized with the first plot and the best placement for the second plot is computed. We then add the third plot and create all possible sequence arrangements. The process is repeated, inserting each new element one by one at the positions that fulfills the most inequalities in R until all elements have been added. The value of a sequence is defined by the number of observations that are fulfilled and is therefore defined by:</p><formula xml:id="formula_3">s = n−1 ∑ i=1 n ∑ j=i+1 1, p i &lt; p j 0, otherwise<label>(3)</label></formula><p>When all scatterplots are added, the sequence with highest value is chosen as the relative ordering for the scatterplots. <ref type="figure" target="#fig_2">Figure 4</ref> shows an illustrative example with three visualizations. Given the set of observations p 1 &gt; p 2 , p 1 &gt; p 3 and p 2 &lt; p 3 , the best placement for p 2 is found <ref type="figure" target="#fig_2">(Figure 4(c)</ref>) and the final sequence is defined <ref type="figure" target="#fig_2">(Figure 4</ref>(e)). Up to now the ordering is only relative, in order to qualitatively evaluate the scatterplots we need to combine it with the perceptual embedding P. Our goal now is to find a ranking that, constrained to the optimized ordering, fits as close as possible the mutual distances in P. </p><formula xml:id="formula_4">E = arg min x Ax − d 2 2 x i ≤ x j , i &lt; j.<label>(4)</label></formula><p>To solve this problem, x is first initialized with the cumulative pairwise distances of the embedding P, i.e. the scatterplot ranked lowest is initialized to x 1 = 0 and each remaining scatterplot x i = x i−1 + d i,i−1 . Afterwards, the values x i are optimized to fit as close as possible all distances d i j of the embedding P. The minimization of Equation (4) can then be computed using quadratic programming. As the problem is convex we iterate several times over x, optimizing each point locally, until the algorithm converges to the global minimum.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">PERCEPTUAL QUERY</head><p>After defining the perceptual ranking for a chosen user task, we can finally appraise the quality of new, previously unknown scatterplots. To define the goodness value of a new scatterplot p q , we  search for the k−nearest scatterplots in our training set. Instead of directly comparing points of scatterplots, we choose to extract specific features to represent them and yield a more robust comparison. Principal Component Analysis (PCA) <ref type="bibr" target="#b16">[17]</ref> is a common approach to find such robust feature descriptors of images.We follow this approach, by using the set of previously selected scatterplots in the training phase to compute an eigenobject basis. After projecting the scatterplots on this eigenobject basis, the ten first main components are chosen as feature vector.</p><p>For a new query we use a fast nearest-neighbor search <ref type="bibr" target="#b2">[3]</ref> to find the k-best matching scatterplots in our training basis. If k is larger than 1, the influence of outliers is reduced. We use k = 3 throughout the paper. The final goodness value is computed as the weighted sum of the goodness values of the k best matching scatterplots. The Perception-based Measure (PBM) is therefore defined as:</p><formula xml:id="formula_5">PBM = ∑ K k=1 w k x k ∑ K k=1 w k ,<label>(5)</label></formula><p>where the weight w k is defined as 1 d k , d k is the Euclidian distance between the feature vectors of the query and the k th best scatterplot. Again, it is worth noting that choosing a representative training set for the desired user task is of fundamental importance for this method because the final measure value for a new scatterplot is computed based on the values of the most similar plots in the training set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">EXPERIMENTS AND ANALYSIS</head><p>Our PBM measure can be trained to select high quality projections for different user tasks. For each user task, the measure is trained using a set of training visualizations to represent the task. The quality of the training set is crucial to the outcome of the PBM measure as it is always relative to the provided set. In the best case, this training set should contain evenly distributed examples of the possible space of all visualizations as the later goodness value of the visualizations is dependend on this training set. But even with incomplete training data, the results are often sufficient. We only used incomplete training data for our tests presented in this paper.</p><p>We trained our measure separately for two distinct exploration tasks: correlation finding for unclassified data and class separation for classified data, two standard tasks in visual analytics <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b13">14]</ref>. For the correlation analysis task, we have chosen a set of scatterplots from the abalones data set <ref type="bibr" target="#b10">[11]</ref>, containing examples of linear and non-linear correlation, as well as different degrees of correlation. <ref type="figure" target="#fig_6">Figure 6</ref> shows three examples of 21 scatterplots chosen to represent this task. For the class separation task, we have chosen a set of scatterplots from a synthetically generated data set <ref type="bibr" target="#b13">[14]</ref>, containing examples with two distinct classes, represented by two point clouds in two different colors. By choosing an example with only two classes, we aim to show the effectiveness of our measure for the class separation task. Note that the class separation task consists of finding scatterplots were the classes, which are already known and represented by different colors, are well separated. However, our measure can be similarly trained for the task of finding projections containing separate clusters in data sets where no label information is available. <ref type="figure" target="#fig_7">Figure 7</ref> shows three examples of 28 scatterplots chosen to represent this task. These training sets are not complete to describe the cited tasks, but they could be successfully used to test the effectiveness of the measure.  For each separate task, we executed two psychophysics studies using the selected scatterplots. The participants of the studies were 20 undergraduate students, PhD students and post docs working in the field of visual computing. In the first study, 200 randomly chosen scatterplot triplets from the task training set were presented to them. They were then asked which of the lateral plots is more similar to the central one. In the second study, 100 scatterplot pairs were presented to the participants, again randomly chosen from the task training set, and they were asked to choose the best scatterplot considering the task. For the correlation task, the participants were instructed to observe the amount of correlation between the scatterplot axes and the difference between linear and non-linear correlation. Similarly, for the class separation task, they were asked to observe the separation between the class clusters, i.e. the best plots have well separated clusters and no overlap between the classes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Perceptual Space</head><p>Using the results of the first study, we trained two perceptual embeddings, as described in Section 4.1. <ref type="figure">Figure 8</ref> shows the resulting two-dimensional perceptual embedding trained using the scatterplots from the training set for the correlation task. It is worth noting how the scatterplots are clustered according to the kind (linear and non-linear) and the amount of correlation. We can clearly <ref type="figure">Figure 8</ref>: Resulting two-dimensional perceptual embedding trained using the scatterplots for the correlation task. The scatterplots are clustered according to the kind of axis correlation (linear and non-linear) and the amount of correlation. We can see three main clusters in this embedding: scatterplots presenting high and non-linear correlation cluster on the right of the embedding; lower non-linear correlation on the top and scatterplots depicting nearly linear correlation can be found on the bottom left. see three main clusters: scatterplots presenting high and non-linear correlation clusters on the right of the embedding, lower non-linear correlation at the top, and scatterplots depicting nearly linear correlation can be found at the bottom left. Additionally, we can observe three important subclassifications in this last cluster: strong linear correlation on the middle, sparse linear correlation on the top, and lower linear correlation on the bottom. <ref type="figure">Figure 9</ref> shows the resulting perceptual embedding for the class separation task. Similar to the correlation space, the clusters of scatterplots can be observed according to the presented class separation. Three main clusters can be observed in this embedding as well: scatterplots with bad separation between the two classes on the right, with horizontal separation on the top-left corner and with vertical separation on the bottom-left corner.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Perceptual Ranking</head><p>The perceptual rankings for the respective tasks were created based on the second study as described in Section 4.2. <ref type="figure" target="#fig_0">Figure 10</ref> shows the resulting ranking for the correlation task. Small-scaled scatterplots are shown in the middle row and their respective quality values are show in the bottom row. Note that as result of the optimiza-tion, similar plots have the same or almost the same quality value. Also this value increases according to the distance between the plots in the perceptual embedding <ref type="figure">(Figure 8)</ref>. A larger discrepancy between the values can be observed when neighboring scatterplots are quite different due to the different clusters in the perception embedding. As for example in <ref type="figure" target="#fig_0">Figure 10</ref>, between scatterplots (7) and <ref type="bibr" target="#b7">(8)</ref> where <ref type="bibr" target="#b6">(7)</ref> behaves as an outlier and between <ref type="bibr" target="#b14">(15)</ref> and <ref type="bibr" target="#b15">(16)</ref> where the transition from non-linear to linear correlation occurs. The resulting order of the scatterplots resembles the observations of the second study. A characteristic that can be observed in the correlation ranking is the preference of the participants for scatterplots that present linear correlation between the dimensions. Unfortunately, some participants were unexperienced in the field of visualization and visual analytics. Therefore, these participants had problems choosing scatterplots showing the higher correlation value as they assumed correlation and skinny structures to be equal. This may result in outliers that can be minimized by using more experienced participants for the study.</p><p>Similarly, <ref type="figure" target="#fig_0">Figure 11</ref> shows the resulting ranking for the class separation task. Again, we can observe large discrepancies between the quality values of different scatterplots. Some examples are be- <ref type="figure">Figure 9</ref>: Perceptual embedding for the class separation task. Clusters of scatterplots can be observed according to the presented class separation. Three main clusters can be observed: scatterplots with bad separation between the two classes on the right; with horizontal separation on the top-left corner and with vertical separation on the bottom-left corner. <ref type="figure" target="#fig_0">Figure 10</ref>: Perceptual ranking for the correlation task. Small-scaled scatterplots are shown in the middle row and their respective quality values are show in the bottom row. Note that similar scatterplots have the same, or almost the same quality value and this value increases according with their mutual distances in the perceptual embedding <ref type="figure">(Figure 8</ref>). <ref type="figure" target="#fig_0">Figure 11</ref>: Perceptual ranking for the class separation task. We can observe large discrepancies between the quality values of differing scatterplots. For example between scatterplot (10) and <ref type="bibr" target="#b10">(11)</ref>, where a clear difference concerning the separation the two classes can be observed.</p><p>tween scatterplot <ref type="bibr" target="#b9">(10)</ref> and <ref type="bibr" target="#b10">(11)</ref> where a clear difference concerning the separation of the two classes can be observed. From <ref type="bibr" target="#b0">(1)</ref> to <ref type="bibr" target="#b9">(10)</ref> the scatterplots present a large overlap between the classes. An interesting aspect that can be noted in ordering of the visualizations is the preference for the horizontal separated class clusters. During the study we could observe that horizontal separated point clusters appeared to be more disjoined in the participants opinions than vertical separated ones.</p><p>To verify the stability of the scatterplot ranking, we performed a leave-one-out test with the scatterplots of the class separation task. We removed each of the 28 scatterplots and trained the measure with the 27 remaining samples. As result the newly created rankings presented an average difference of 1.28 position, compared to the original one. That means an error of 4.6%, indicating that the ranking is stable considering the dependence on the individual scatterplots of the training set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Perception-Based Measure</head><p>To evaluate our measures we tested them with two synthetically generated data sets. To test our PBM measure with the correlation task, we used an unclassified data set with 6 dimensions and 1000 sampling points. <ref type="figure" target="#fig_0">Figure 12</ref>(a) presents the scatterplot matrix of the data set showing scatterplots above the main diagonal and their respective values according to the PBM measure under the diagonal. These values were computed based on the 3-best matching scatterplots of the training set. E.g. for the scatterplot (dim0-dim1), the scatterplots (10), <ref type="bibr" target="#b10">(11)</ref>, and (15) were automatically chosen from the training set ( <ref type="figure" target="#fig_0">Figure 10</ref>) and their respective ranks were used to compute the PBM measure (Section 5). Our measure successfully ranked linear and non-linear correlation between dimensions (dim0-dim1) and (dim4, dim5) with suitable values according to the previously computed perceptual ranking. The remaining scatterplots were ranked with a low value for the PBM measure, in consistence with the perceptual ranking.</p><p>Similarly, we compute the values of the scatterplots using the RVM measure <ref type="bibr" target="#b13">[14]</ref> (see <ref type="figure" target="#fig_0">Figure 12(b)</ref>). The RVM measure is used to find linear and non-linear correlations between pairwise dimensions. Both measures successfully select the scatterplots with the strongest correlation as best plots. Note that in the perception ranking we trained for correlation ( <ref type="figure" target="#fig_0">Figure 10</ref>), the worst ranked scatterplots are similar to the scatterplots (dim0-dim2) and (dim1-dim2), what justifies their low values for the PBM. Compared to the RVM measure, the PBM has the advantage that the ranking values resemble the user perception and that it can be trained not only for correlation but for a variety of user tasks. The PBM measure has a lower sensibility due to it restrictions to the used training set, using a more comprehensive training set may increase this sensibility.</p><p>To test the PBM measure with the class separation task, we used a classified data set with 6 dimensions and 2000 sampling points and two classes. <ref type="figure" target="#fig_0">Figure 12(c)</ref> presents the scatterplot matrix of this data set showing scatterplots above the main diagonal and their respective values according to the PBM measure under the diagonal. The PBM measure successfully ranks the new scatterplots according to the previously defined perceptual ranking <ref type="figure" target="#fig_0">(Figure 11</ref>). Note that the scatterplots with horizontal class separation are rated with higher scores compared to vertical class separation due to the preference of the participants for the vertical layouts. <ref type="figure" target="#fig_0">Figure 12(d)</ref> shows the CDM measure <ref type="bibr" target="#b13">[14]</ref> computed for this data set. The CDM evaluates scatterplots according to the separation properties of the classes. Comparing our PBM to the CDM measure, we can observe that the PBM measure delivers more accurate values for this data set. For example the scatterplot (dim2-dim3) that presents the best separation of the class clusters is ranked with the best value by the PBM but not by the CDM measure.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">CONCLUSION</head><p>In this paper we presented the first perceptually motivated goodness measure for qualitatively evaluating visualizations. Our new quality measure can serve several purposes. It is a very general technique that is not limited to scatterplots, but we expect it to also be applicable to other visualization methods as Parallel Coordinates or Pixel Bar Charts. We showed how to apply our technique for common visual analytics tasks such as finding projections with high (non-)linear correlations or good class separability. Further user tasks can be directly included and will be investigated in the future. We compared our method with previously proposed quality measures <ref type="bibr" target="#b14">[15]</ref> and showed that our approach can be similarly used to rank visualizations. Our measure has the advantage that it can be trained to evaluate a variety of user tasks and that the computed quality values resemble the human perception, even though considering its limitations to the training set and user preferences.</p><p>The presented measure opens new possibilities to aid the visual exploration of high-dimensional data sets capitalizing on the human visual system. As future work, we intent to test our measure with other visualization methods and to extend the existing set of user tasks. Additionally, we aim at comparing different quality measures with different ranges in their goodness values by projecting them into our perceptual ranking function. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Working steps to select the best visualizations of a highdimensional data set. A ranking function is defined in the training phase, based on a perceptual embedding for scatterplots. This function is used later to measure the goodness value of new scatterplots from a multivariate data set.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Screenshot of the distance comparison test.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4 :</head><label>4</label><figDesc>Placement algorithm for three example visualizations, given the set of observationsp 1 &gt; p 2 , p 1 &gt; p 3 and p 2 &lt; p 3 . (a)The algorithm is initialized with the first visualization p 1 . (b) All possible sequence arrangements for p 2 are tested. The set of possible insertion positions are marked with dotted boxes. (c) The best sequence is saved in next step. (d) The algorithm searches for the best placement for p 3 and the best sequence is saved at the end (e).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 5</head><label>5</label><figDesc>depicts such an example. Given an ordering of the visualization in the form p 1 ≤ p 2 ≤ p 3 , and their mutual distances in the perceptual embedding d 12 , d 13 , and d 23 , we want to find the best fitting goodness values for x 1 , x 2 , x 3 , where x i is the rank value for the scatterplot p i . Stating the problem in terms of a matrix Ax = d, we want to solve the following optimization problem:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 5 :</head><label>5</label><figDesc>Embedding and ranking examples, given an ordering to the visualizations p 1 ≤ p 2 ≤ p 3 , and their mutual distances in the perceptual embedding d 12 , d 13 , and d 23 , we want to find the best values for x 1 , x 2 , x 3 .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 6 :</head><label>6</label><figDesc>Examples of scatterplots from the trainig set for the correlation task.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 7 :</head><label>7</label><figDesc>Examples of scatterplots from the trainig set for the class separation task.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 12 :</head><label>12</label><figDesc>Scatterplot matrix of two test data sets, showing scatterplots above the main diagonal and their respective values according to the measures under the diagonal. (a) Results for the PBM measure and the correlation task, scatterplots with high correlation between the dimensions present a high quality value. (b) Results for the RVM measure. (c) Results for the PBM measure and the class separation task, scatterplots with well separated classes present a high quality value. (d) Results for the CDM measure.</figDesc></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGEMENTS</head><p>The authors gratefully acknowledge funding by the German Science Foundation from project DFG MA2555/6-1 within the strategic research initiative on Scalable Visual Analytics. We also want to thank the anonymous reviewers for their many valuable suggestions.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Generalized non-metric multidimensional scaling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wills</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Cayton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Lanckriet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kriegman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Belongie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AIS-TATS</title>
		<meeting><address><addrLine>San Juan, Puerto Rico</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Improving the visual analysis of high-dimensional datasets using quality measures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Albuquerque</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Eisemann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">J</forename><surname>Lehmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Theisel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Magnor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Symposium on Visual Analytics Science and Technology</title>
		<meeting>the IEEE Symposium on Visual Analytics Science and Technology</meeting>
		<imprint>
			<publisher>IEEE VAST</publisher>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">An optimal algorithm for approximate nearest neighbor searching in fixed dimensions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Arya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">M</forename><surname>Mount</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">S</forename><surname>Netanyahu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Silverman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">Y</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM-SIAM Symposium on Discrete Algorithms</title>
		<imprint>
			<date type="published" when="1994" />
			<biblScope unit="page" from="573" to="582" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">The grand tour: a tool for viewing multidimensional data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Asimov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal on Scientific and Statistical Computing</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="128" to="143" />
			<date type="published" when="1985" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Pargnostics: Screen-space metrics for parallel coordinates</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Dasgupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Kosara</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<date type="published" when="2010-11" />
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="1017" to="1026" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">The Method of Paired Comparisons</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">A</forename><surname>David</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1988" />
			<publisher>Chapman and Hall</publisher>
			<pubPlace>London</pubPlace>
		</imprint>
	</monogr>
	<note>2 edition</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Exploratory projection pursuit</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">H</forename><surname>Friedman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Statistical Association</title>
		<imprint>
			<biblScope unit="volume">82</biblScope>
			<biblScope unit="issue">397</biblScope>
			<biblScope unit="page" from="249" to="266" />
			<date type="published" when="1987" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Coordinating computational and visual approaches for interactive feature selection and multivariate clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Guo</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="232" to="246" />
		</imprint>
	</monogr>
	<note>Information Visualization</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Projection pursuit</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">J</forename><surname>Huber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Annals of Statistics</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="435" to="475" />
			<date type="published" when="1985" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Interactive dimensionality reduction through user-defined combinations of quality metrics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Johansson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Johansson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="993" to="1000" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">The Population biology of abalone (Haliotis species) in Tasmania. 1, Blacklip abalone (H. rubra) from the north coast and the islands of Bass Strait. Sea Fisheries Division, Dept. of Primary Industry and Fisheries</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">J</forename><surname>Nash</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tasmania</forename></persName>
		</author>
		<imprint>
			<date type="published" when="1994" />
			<pubPlace>Tasmania, Hobart</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Pixnostics: Towards measuring the value of visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schneidewind</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sips</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Keim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Symposium On Visual Analytics Science And Technology</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">0</biblScope>
			<biblScope unit="page" from="199" to="206" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Selecting good views of high-dimensional data using class consistency</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sips</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Neubert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">P</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Hanrahan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Graphics Forum (Proc. EuroVis</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="831" to="838" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Combining automated analysis and visualization techniques for effective exploration of high-dimensional data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Tatu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Albuquerque</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Eisemann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schneidewind</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Theisel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Magnor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Keim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE Symposium on Visual Analytics Science and Technology</title>
		<meeting>IEEE Symposium on Visual Analytics Science and Technology<address><addrLine>Atlantic City, New Jersey, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE VAST</publisher>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Visual quality metrics and human perception: an initial study on 2d projections of large multidimensional data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Tatu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Bak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Bertini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Keim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schneidewind</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Advanced Visual Interfaces, AVI &apos;10</title>
		<meeting>the International Conference on Advanced Visual Interfaces, AVI &apos;10<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="49" to="56" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Computing graphics and exploratory data analysis: An introduction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tukey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Tukey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Sixth Annual Conference and Exposition</title>
		<meeting>the Sixth Annual Conference and Exposition</meeting>
		<imprint>
			<date type="published" when="1985" />
			<biblScope unit="volume">85</biblScope>
		</imprint>
	</monogr>
	<note>Computer Graphics</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Eigenfaces for recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Turk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">P</forename><surname>Pentland</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Cognitive Neuroscience</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="71" to="86" />
			<date type="published" when="1991" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Graph-theoretic scagnostics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wilkinson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Anand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Grossman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Symposium on Information Visualization</title>
		<meeting>the IEEE Symposium on Information Visualization</meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="157" to="164" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Toward a perceptual space for gloss</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wills</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kriegman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Belongie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Graph</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="1" to="103" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
