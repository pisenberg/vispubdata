<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/pisenberg/grobid/grobid-0.6.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Interactive Decision making using Dissimilarity to visually represented Prototypes</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Migut</surname></persName>
							<email>m.a.migut@uva.nl</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">C</forename><surname>Van Gemert</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Worring</surname></persName>
							<email>m.worring@uva.nl</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="laboratory">Intelligent Systems Lab</orgName>
								<orgName type="institution">Amsterdam University of Amsterdam</orgName>
								<address>
									<country key="NL">The Netherlands</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">Expertise Center Forensic Psychiatry Utrecht</orgName>
								<address>
									<country key="NL">The Netherlands</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="department">Intelligent Systems Lab Amsterdam</orgName>
								<orgName type="institution">University of Amsterdam</orgName>
								<address>
									<country key="NL">The Netherlands</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="department">IEEE Symposium on Visual Analytics Science and Technology October</orgName>
								<address>
									<addrLine>23 -28, Providence, Rhode Island</addrLine>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Interactive Decision making using Dissimilarity to visually represented Prototypes</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2021-02-19T19:56+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>dissimilarity based classification</term>
					<term>dissimilarity based visualization</term>
					<term>prototypes</term>
					<term>interactive visualization</term>
					<term>visual analytics</term>
				</keywords>
			</textClass>
			<abstract>
				<p>To make informed decisions, an expert has to reason with multidimensional, heterogeneous data and analysis results of these. Items in such datasets are typically represented by features. However, as argued in cognitive science, features do not yield an optimal space for human reasoning. In fact, humans tend to organize complex information in terms of prototypes or known cases rather than in absolute terms. When confronted with unknown data items, humans assess them in terms of similarity to these prototypical elements. Interestingly, an analogues similarity-to-prototype approach, where prototypes are taken from the data, has been successfully applied in machine learning. Combining such a machine learning approach with human prototypical reasoning in a Visual Analytics context requires to integrate similarity-based classification with interactive visualizations. To that end, the data prototypes should be visually represented to trigger direct associations to cases familiar to the domain experts. In this paper, we propose a set of highly interactive visualizations to explore data and classification results in terms of dissimilarities to visually represented prototypes. We argue that this approach not only supports human reasoning processes, but is also suitable to enhance understanding of heterogeneous data. The proposed framework is applied to a risk assessment case study in Forensic Psychiatry.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>In many applications in medicine, security or forensics <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b14">15]</ref>, predictions and decisions are made by domain experts based on the analysis of multi-dimensional, heterogeneous data. Typically, the items in these datasets are represented by features which capture one characteristic of an item in a nominal, ordinal, or numeric value. These features may then be used by automated data analysis and visualization systems supporting experts in their decision making process <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b1">2]</ref>. We identify three problems with such a feature-centered approach. First, those systems have to deal with the problem of many dimensions. Second, they have to represent different types of feature heterogeneity, like mixed types or different measurements units. Third, features represent data in absolute terms, which, as argued in cognitive science, are not easy to process <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b24">25]</ref>.</p><p>Where humans are weak at extracting information from features, they are very good in analogies and case-based reasoning, often exclusively based on personally experienced past cases. This view is related to cognitive prototype theory <ref type="bibr" target="#b24">[25]</ref>, where humans abstract out a prototypical example of all the ones experienced and use it for further decision making. This suggests that people do not categorize based on a list of descriptive features, but rather in terms of similarity to known examples. They perform even better when multiple prototypes are used <ref type="bibr" target="#b24">[25]</ref>.</p><p>Since a dataset can be characterized by prototypes, a degree of similarity to these prototypes can replace feature values as the dataset description. Such a description would represent each dataset element by their similarity to a fixed set of prototypes. Such similarities are uniformly measured for each dataset item on a single, shared scale as a directly comparable distance value. Hence, a description by prototype similarities helps to overcome the problem of data heterogeneity. In such a uniform representation there are no mixed feature types nor varying measurement units. This naturally allows a simpler visual representation without the need to step back and convert scales or to look up feature types. A uniform data representation, based on distance to prototypes, allows the user to directly compare patterns leading to homogeneous visual thinking.</p><p>The similarity-to-prototypes approach has been successfully adopted in pattern recognition <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b21">22]</ref>. In pattern recognition the prototypes are chosen to best represent different groups in the dataset and the classifier is trained on pairwise dissimilarities of each element in the dataset to those prototypes. If a good similarity representation is chosen, only a small number of prototypes are needed to build a good classifier <ref type="bibr" target="#b21">[22]</ref>. This approach has been applied for classification in many domains such as prediction of cancer, toxicity and schizophrenia <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b29">30]</ref>.</p><p>To our knowledge, there is no literature on using a similarity-toprototypes approach in a Visual Analytics context, but some steps in this direction have been made. On the one hand, the dissimilarity space used for classification has been visualized <ref type="bibr" target="#b21">[22]</ref>, but merely to illustrate the workings of a classification technique. On the other hand, a dissimilarity space has been used to visualize a multi-dimensional datasets using 2D embeddings <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b27">28]</ref>. Integrating these two approaches in an interactive expert-oriented framework would constitute a powerful Visual Analytics tool and fill the gaps as identified in <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b4">5]</ref>. To this end, the prototypes should be exploited as the driving force of the Visual Analytics system. When the prototypes characterizing the dataset have a clear meaning to the expert they trigger direct associations for the expert user. In many cases the expert user knowledge, which is not included in the data, can provide additional insight about an item which can be extracted by such visual associations. Such a visual representation of a prototype might be of various types, e.g. symbols or images. In this paper we propose to combine the associative power of images, with the cognitive strength of prototypes, integrated with interactive dissimilarity-based classification. To this end, a set of visualizations are used that allow to explore different aspects of information space induced by prototype dissimilarities.</p><p>This paper is organized as follows. The related work section presents an overview of systems that combine classification with interactive visualizations. Subsequently, we substantiate the integration of image prototypes into a Visual Analytics framework. From there, we describe the dissimilarity-to-prototypes classification, to-gether with techniques to derive similarity measures from heterogeneous features and selected prototypes. Following the section describing the visualization of the image prototypes in dissimilarity space, we propose an intelligent way to integrate the described techniques into a highly interactive framework and show its application in Forensic Psychiatry.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK</head><p>In recent years the idea of combining classification with interactive visualization has gained a lot of interest in literature. To structure this section we follow Bertini and Lalanne <ref type="bibr" target="#b4">[5]</ref> who divide the existing approaches in the following categories: 1) integrated Visualizations and Mining (VM), 2) visually enhanced Mining (M++) and 3) computationally enhanced Visualizations (V++).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Visual Mining systems (VM)</head><p>A framework for Visual Mining/Analytics is formally described by Keim <ref type="bibr" target="#b14">[15]</ref>. It proposes a tightly coupled system with controlled interaction between the automated data analysis and visualization elements. Moreover it allows users to steer the visualization process and to actively participate in the classification process. Building upon Keim's framework, Yu et al <ref type="bibr" target="#b33">[34]</ref> propose a smooth interface between data mining and visualization for multimedia data in social and behavioral studies. They visualize all intermediate and final results of data mining, allowing the user to obtain new insights and develop more hypotheses about the data. Ankerst proposes the DataJewel architecture <ref type="bibr" target="#b2">[3]</ref> coupling a visual, an algorithmic and a database approach for temporal data mining. The system focuses on the improvement of the discovery of useful temporal patterns. Interactive construction of decision tree classifiers is proposed in <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b1">2]</ref>. Here, the user can interactively select the splitting attribute from the dataset visualization after which the current decision tree is visualized and the user can proceed with expanding the decision tree. A way of improving and analyzing a classifier is described in <ref type="bibr" target="#b9">[10]</ref>. Starting from an initial hypothesis, created with linking and brushing, the user steers a heuristic search algorithm to search for alternative hypotheses.</p><p>All the above approaches tightly integrate classification and interactive visualizations. They however only consider datasets represented by features. In this paper we build on these ideas by proposing an interactive image prototype visualization which is tightly coupled with dissimilarity-based data mining.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Dissimilarity to prototype classification (M++)</head><p>In <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b21">22]</ref> Pekalska et. al. propose to use prototypes for dissimilarity-based classifiers. A set of prototypes is chosen that best characterizes the dataset. Classifiers are trained on the pairwise dissimilarities of each data-element to those prototypes. This approach has been used in several application, for detection of schizophrenia <ref type="bibr" target="#b29">[30]</ref>, for cancer prediction using gene expression profiles <ref type="bibr" target="#b5">[6]</ref> and for detecting hepatotoxicity <ref type="bibr" target="#b19">[20]</ref>. Pekalska et. al. include a few static visualizations in their article. They show the dissimilarity to prototypes for two dimensional examples in a scatterplot. They also show the approximate 2D embedding of dissimilarities. However, those statically generated plots serve only as an illustration of their classification approach, and is not presented to the end-user. The visual explanation of the dissimilarly based classification could, however, contribute to the expert's understanding of a classifier, when incorporated into an interactive exploration framework.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Visualization of dissimilarity to prototypes (V++)</head><p>To visualize multi-dimensional datasets, often projections to lower dimensional spaces are used. For visualization, the projection should preserve the resulting structure of the data in the lowdimensional space. Common techniques to represent dissimilarities between the items are multidimensional scaling and Isomap <ref type="bibr" target="#b16">[17]</ref>. Different variations of these algorithms are used. In <ref type="bibr" target="#b3">[4]</ref> an adapted, incremental projection algorithm is proposed to visualize high-dimensional numerical data. In <ref type="bibr" target="#b18">[19]</ref> Isomap is used to visualize image collections represented by a high-dimensional feature vector.</p><p>In the above techniques, the projection techniques to lowdimensional space are treated as support to efficiently visualize data. Their aim is a good visualization. However, by projecting a high-dimensional dataset to lower dimensions it is nearly inevitable to lose some information. Hence, we use such a visualization to obtain a global overview while retaining visual access points to the original high-dimensional data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Contribution</head><p>From the related work we have studied, it appears that the dissimilarity based techniques have never been applied in the setting where the exploration of data and classification are combined. To combine the M++ and V++ approaches into a highly interactive Visual Analytics framework we propose to make prototypes the primary objects of dataset and classifier exploration. By intelligently integrating the techniques proposed for dissimilarity classification, with various visualizations in dissimilarity space by using prototypes we respect and stimulate the cognitive economy of the expert-user.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">VISUALLY REPRESENTED PROTOTYPES IN VISUAL ANA-</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>LYTICS</head><p>In Visual Analytics, an expert and his knowledge are an integral part of the decision making process. We first need to understand how experts perceive the presented data and how they assign meaning to the patterns that they find. We want to understand and support the visual thinking <ref type="bibr" target="#b31">[32]</ref> of an expert.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">On features</head><p>The very first step in Visual Analytics is data preparation. We need to understand how a dataset is represented and how it can be transformed to most effectively support the human expert. Since the most important goal of the visualizations is to reveal assign meaning to patterns, the main challenge is to transform data into a form where important patterns are easy to interpret.</p><p>Typically, items in the dataset are represented by a feature vector which describes measured properties of the items. A well-defined feature vector constitutes a description of all relevant characteristics of an item. Each feature characterizes an aspect of an item in a nominal, ordinal, or numeric value type. The feature-based representation of the data is commonly used in visualizations and pattern recognition alike. The use of features has, however, several limitations. First, in many applications, the domain expert is the only person understanding the features, and he needs to be skilled to interpret them fast and correctly. Second, in real applications the number of features needed for a good description of the data items can be large. This is a serious limitation, not only for humans but also when designing the visualization and analysis tools. In automatic pattern recognition the curse of dimensionality is a well known problem. In visualizations it is hard to meaningfully represent the data in terms of features for more then a few dimensions. Third, the description of the items' characteristics can be very specific to each item, and the possibility exists of losing the context of the data, when focusing on very specific characteristic of a particular item in the dataset. Fourth, the heterogeneity of features forms a serious problem in visualization and data analysis. There can be several sources of heterogeneity, like mixed types values or the different measurements units. These characteristics make it hard to visualize the features in such a way that they can be directly compared with each other, without the loss of information. For automatic analysis, such data has to be translated to a uniform measure or type, which may also result in loss of information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">On human prototype perception</head><p>Humans do not excel at processing complex information due to the limited size of our working memory <ref type="bibr" target="#b24">[25]</ref>. Presenting humans with visualizations of many heterogeneous features might be confusing, and highly depends on the knowledge, and analytical skills of the expert. This is related to the gestalt law, where the sum of many low-level patterns have to be put into one whole. The more items are included in the data set, the more cognitively expensive the interpretation process becomes. Therefore, the main challenge is to transform data into a form where important patterns are easy to interpret.</p><p>Humans tend to focus on the fewest possible represented items in order to reduce the cognitive burden. Humans primarily focus on the items that are most characteristic and well-known: the prototypical items. The details of prototypical items are fixated in our memory and are linked to various kinds of information through a network of associations, and therein lies the power of our proposed system. Through semantic interpretation of prototypes it is possible to extract high-level patterns.</p><p>In fact, to understand other instances in the dataset humans typically relate them to prototypes. On the one hand, it is easy for human to make comparison between a prototype and another item in the database. On the other hand, an exact specification and quantification of these differences is difficult for an expert to give <ref type="bibr" target="#b13">[14]</ref>. To facilitate the understanding of similarities, the contribution of each separate feature to a similarity should be taken into account. This allows the user to understand why items are considered similar or dissimilar by the system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Why visually represented prototypes?</head><p>In <ref type="bibr" target="#b31">[32]</ref>, Ware discusses concept-proxies, which can be given to the user to visually represent prototypes. Once proxies are fixated in the brain, the corresponding concepts become activated. This visual trigger mechanism allows for fast information retrieval of a concept, opposed to accessing slow long-term memory without using such visual aids. The use of proxies is only useful if there are learned associations to the visual representations. In fact, the activation of meaning from a visual representation generally occurs in a fraction of a second, which is much less time then it takes to read a paragraph of text. Therefore, to support the prototype recognition and comparison process, the prototypes should be visually distinctive, represented in a such a way that they trigger direct associations.</p><p>In applications where decision making can be supported by Visual Analytics, the images associated with data items can be used. In Forensic Psychiatry for example, features describing the patients can be combined with pictures of these patients. We assume that an expert can recall more about the patient when the associations are triggered by presenting the photo of a patient, then just by looking at the associated data. In the medical field the exploration of radiology images of the liver, when diagnosing a certain disorder, allows the expert to directly relate measures derived from an image to the actual content of the image. In the applications, where data items do not have associations with visual appearances, the trigger mechanism can be used as well. In such case, the prototypes can be represented by any meaningful visual representation that experts agree upon.</p><p>In this paper, due to privacy reasons, we use photographs of the authors, their colleagues and relatives. We use those photographs merely to illustrate our approach, for actual association triggering the actual photographs must be used.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">ON CLASSIFICATION WITH DISSIMILARITIES TO VISUALLY</head><p>REPRESENTED PROTOTYPES In this section we describe how the notion of prototypes and dissimilarities is adapted for classification. We describe how to derive the dissimilarity measure from the feature representation for the data of mixed types. The methods to select the sufficient minimum number of prototypes are discussed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Classification</head><p>Suppose we have a dataset consisting of n items described by a vector of f features, divided into two classes. According to the class membership, a positive or negative label is assigned to each item in the dataset. In the classification pipeline, the dataset is first divided into a train and a test set, both described by all the features. The classifier is trained on the training set resulting in the f -dimensional decision boundary, that best separates the two classes. The classifier can be then used for prediction on the test set, where based on all the features the class membership of a new item is predicted, with the corresponding classifiers accuracy. To performance of the classifier is commonly represent by ROC curve that visualizes possible tradeoffs of the trained classifier. In the dissimilarity based classification, as proposed in <ref type="bibr" target="#b20">[21]</ref>, the dataset is described in terms of pairwise dissimilarities between items, instead of features. For n items in the dataset, the dissimilarity input for classifier is of size n x n.</p><p>In <ref type="bibr" target="#b21">[22]</ref> it has been shown, that only small number of prototypes for such dissimilarity representation is enough to train a good classifier. Therefore, first a set of prototypes is selected from the training set. The classifier is trained on this set, and consecutively applied to the test set, that only consists of the dissimilarities to the prototypes. This procedure is visually represented in figure 1. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Dissimilarity measure</head><p>To support prototype-based reasoning of humans we need to represent the prototypes in the relation to each other and in the relation to other items comprising the dataset. We want to show how much items differ from each other, or in other terms how similar they are to each other.</p><p>A suitable similarity measure is not easy to derive from features. The Euclidean distance is the most commonly used dissimilarity    <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b22">23]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Type of variable</head><p>Similarity measure s i jk</p><formula xml:id="formula_0">nominal if( x ik = x i j ) then 1 else 0 ordinal |rank(x ik )−rank(x i j )| (k distinct−ranks )−1</formula><p>interval and ratio</p><formula xml:id="formula_1">x ik −x i j range i</formula><p>measure when dealing with numeric features. For features of mixed types this measure fails, as the Euclidean distance is not defined for ordinal and nominal values. As summarized in <ref type="bibr" target="#b22">[23]</ref>, there are several approaches to deal with the mixed data types. One of them is to convert features a specific coefficient that allows the use of different data types. This similarity measure could be directly fed into the classifier as proposed by <ref type="bibr" target="#b20">[21]</ref>. It could also be visualized to show the relations between the items. Podani <ref type="bibr" target="#b22">[23]</ref> proposes to use Gower's general coefficient <ref type="bibr" target="#b10">[11]</ref> of similarity for the analysis of the mixed data types. Podani extends Gower's coefficient to deal with ordinal data as well. The similarity coefficient between items j and k is defined as follows:</p><formula xml:id="formula_2">G jk = n ∑ i=0 w i jk s i jk n ∑ i=0 w i jk (1)</formula><p>where w i jk = 0 if items j and k can not be compared for variables i because the value of item j or k is unknown, 1 otherwise. The value of s i jk is a dissimilarity between the item j and k for the feature i. The possible measures s i jk for various types of features are summarized in table 1.</p><p>Podani <ref type="bibr" target="#b22">[23]</ref> points out that the ordinal variables must be fully ranked because the ranks are used instead of scores. The differences between the scores can not be calculated and the similarity between them depends on the frequency of this score for a given feature in the whole data set. For details, see Podani <ref type="bibr" target="#b22">[23]</ref>.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Prototype selection for dissimilarity based classifier</head><p>The selection of prototypes is a crucial element of the dissimilarity based classification and visualization. We need to represent the dataset in its most characteristic items. Experiments show that a random selection of prototypes works well <ref type="bibr" target="#b20">[21]</ref>. A systematic procedure has also been investigated <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b11">12]</ref>. In <ref type="bibr" target="#b21">[22]</ref> the authors show that for two-class problem, the systematic approaches have similar or better results than the random selection, especially for a small number of prototypes. In general, we are interested in a limited number of prototypes not to overload the expert's cogni-tive processes, but also we want to build a good and reliable classifier. Following Pekalska et al. <ref type="bibr" target="#b21">[22]</ref>, we select the prototypes using k-centers, which is one of the selection methods that she investigates. K-centers is applied to each class separately. For each class this algorithm tries to choose k items such that the maximum of the dissimilarities over all items to the nearest center is minimized. The prototypes must be selected from the data items that are known to the experts. In this way we assure that the expert does have associations with the visual representation of those prototypes. If expert is not familiar with all the data items, the prototypes can be chosen, according to experts familiarity to them. They must be characteristic for the specific category of data items. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">VISUALIZATION OF PROTOTYPES IN THE DISSIMILARITY</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>SPACE</head><p>In this section we investigate possible visual solutions for the dissimilarity-to-prototype space. We propose a set of visualizations that address different aspects of this space. One of important aspects for the expert, that we take into account, is how to relate the similarity-to-prototypes back to the feature space, which is familiar to the experts. Throughout all the visual components of this framework the prototypes are visualized using images. This supports the visual thinking theory, as discussed by Ware <ref type="bibr" target="#b31">[32]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Prototypes matrix</head><p>To explore the dissimilarities of data items to the prototypes a scatterplot is used. This fairly simple visualization technique is easily understandable and therefore used in many systems, such as Spotfire <ref type="bibr" target="#b0">[1]</ref>, XmdvTool <ref type="bibr" target="#b30">[31]</ref>, Tableau/Polaris <ref type="bibr" target="#b25">[26]</ref>, GGobi <ref type="bibr" target="#b26">[27]</ref>. To represent dissimilarities of two prototypes, a prototype P1 is plotted on the X axis and the dissimilarity to prototype P2 on the Y axis. Each item from the dataset is visualized in a scatterplot, based on these two coordinates, x: dissimilarity to P1 and y: dissimilarity to P2. To allow the user to explore the dissimilarity to all prototypes we visualize a series of scatterplots for all combinations of prototypes, and arrange them in a scatter matrix. To use the visualization space efficiently we only show the part of the matrix under the diagonal, since the matrix is symmetric we do not show redundant information. Further, we follow the approach of <ref type="bibr" target="#b12">[13]</ref> and use the diagonal to show the scatterplot axis. Instead of names, we show images of the prototypes for association purposes, as described in section 3. In figure 3 we show the dissimilarity matrix for 8 prototypes. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Dissimilarity space visualization</head><p>To make it possible for the expert to globally relate the prototypes to each other and to all other items in the dataset, all the elements should be presented in one single visual space. For this purpose a method that projects data to a lower dimension can be used. Multidimensional scaling (MDS) is a set of such techniques for exploring similarities in data, that has been proven useful as a dimension reduction technique <ref type="bibr" target="#b16">[17]</ref>. MDS projects items into low dimensional space, providing a spatial configuration, preserving pairwise dissimilarities between the items. Such mapping may reveal characteristic structures in data, where similar item are close to each other in the projected space. Given a pairwise similarity matrix, MDS assigns a location to each item in p-dimensional space. P is the dimension of the smallest space in which the items can be embedded. In <ref type="figure" target="#fig_4">figure 4</ref> we show an MDS-projection of the dissimilarity space to 2D.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Detail-on-demand</head><p>The most important cognitive task for the expert is to explore interesting data elements in the relation to prototypes in order to find patterns. As Ware emphasizes <ref type="bibr" target="#b31">[32]</ref>, the most important and frequent visual task needs the most support. Hence, the supporting mechanism should be visually the most distinct. Therefore, we propose a set of techniques that facilitate the expert in exploring and interpreting the relation between the individual data elements, the prototypes, and the classification model. As proposed so far, the dataset can be either explored in a 2D projection of the dissimilarity space or in the matrix, through the scatterplots of actual dissimilarities to two chosen prototypes. To allow an expert to directly see the dissimilarity between a single item of interest and all the prototypes, we combine two important features from both the matrix that presents the actual distances, and the 2D projection, that show relation to all the prototypes. To this end we use a star plot, which was first proposed by <ref type="bibr" target="#b8">[9]</ref>. The star plot is primarily suited for showing commonalities, which is exactly our aim. The item of interest is visualized in the center of a circular plot. The prototypes are visualized according to actual dissimilarities to the item of interest. An image representing a prototype is visualized on a circle with radius equal to the dissimilarity and a color corresponding with the prototypes original class label, see <ref type="figure" target="#fig_6">figure 6</ref>.</p><p>To support investigating the contribution of single features and relate to the conceptual feature-based framework of the expert, we show how much each of the features contributes to a prototype's similarity. When an expert poses a query, in terms of exploring a single element in the 2D projection or in the scatterplot, the set of feature-related visualizations are provided. Three feature-related visualizations are proposed, see <ref type="figure" target="#fig_6">figure 6</ref>. First, the 'regular' detailson-demand are provided, with the features values in text, to be explored. Second, the dissimilarity to each prototype is provided for each of the features. In fact, this shows the dissimilarity between the item of interest and the prototype for each feature. Combination of those values constitute the final dissimilarity between the item of interest and the prototype. To show the contribution for each feature, a heatmap is visualized for the item of interest. For each feature, the heatmap represents the dissimilarity values of the item of interest to each of the prototypes. The darker the color of a single square, the higher value of similarity it represents. Hence, the lighter the color of a single square, the lower the value of dissimilarity. Note that the heatmap does not show feature values, but the differences in feature values of a single item under investigation and all prototypes, as illustrated in <ref type="figure" target="#fig_6">figure 6</ref>. Third, the difference in dissimilarities is shown for the item of interest and two prototypes, as selected in the matrix. Those dissimilarity differences are presented per feature. This allows to directly observe which feature contributes to one prototype being more similar to the item of interest than the other. We propose to visualize those differences using bars. The color of the bar indicates the original label of the prototype that the item of interest is more similar to. Note that again we show the differences between the features' values of the item, and the two prototypes, see figure 6.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">INTERACTIVE DECISION MAKING 6.1 Classifier visualization and cost selection</head><p>To enhance understanding of the model, the visual representation of its decision boundary should be placed in the space as where the model has been trained. Since in our framework we use classification in the dissimilarity-to-prototypes space, we would like to visualize decision boundary in the dissimilarity to prototypes scatterplots and the 2D MDS projection. To this end we use the Voronoibased approximation of the decision boundary as proposed by <ref type="bibr" target="#b17">[18]</ref>. From the same framework, we integrate the interactive ROC curve to allow interactive exploration of the result of classifier for different trade-offs.</p><p>The performance of the classifier is visualized using a performance curve, which represents the rate of miss-classifications on both sides of the decision boundary. An interactive operating point is visualized on the curve allowing the expert to explore all possible trade-offs for a given classifier on the whole data set. Notice the difference that for the training of the classifier we use an independent test set to evaluate the classifier. However for the visualization purposes, the whole data set is visualized in relation to different classifiers. Those are all classifiers possible for the given classifier and train set, so changing the operating point is allowed on the test set as well because it does not change the classifier. Therefore we can visualize the whole dataset in one plot, and it can be explored in relation to the dissimilarities for the whole dataset.</p><p>From the same framework we also adopt the notion of critical elements. However, in our setting those are no longer all the data elements influenced by classification, but only the prototypes. If an expert requires to move a certain prototype onto the different side of the decision boundary this should be possible, as it might be in agreement with expert's knowledge. This leads to interactive selection of the prototypes. That would require re-training of the classifier after the selection process, and updating the visualizations as new prototypes are chosen. This is however a topic of future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Interaction Design</head><p>The interaction design in our framework is structured according to <ref type="bibr" target="#b32">[33]</ref>. To explore the dissimilarities to prototype the system uses at the basis a CONNECT interaction. All visual components are connected to each other, meaning then whenever the user interacts with one of the components, his actions will be propagated and the connect of other visual components is updated. ELABORATE interaction is build up of nested details-on-demand. Those, not only visualize data information in textual information, but also represent details visually. For exploration of data, in relation to dissimilarity based classification results, a set of interactions, as proposed in <ref type="bibr" target="#b17">[18]</ref>, is integrated into the system. This extends the basic set with the interaction associated with exploration of classification models and performance. The interaction design is shown in figure 7.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Visual Design</head><p>The system we propose consists of several visual components. The implementation of the system is shown in <ref type="figure" target="#fig_9">figure 8</ref>.</p><p>The main components of the system are:</p><p>• Scatter Matrix: serves both as an overview and a navigation tool. Miniature versions of the individual plots are shown as the cells of the matrix, and one selected plot is shown in detail. This plot serves as navigation tool for details-on-demand. In each plot all the data elements are visualized together with the decision boundary.</p><p>• Projection Plot: displays the 2D MDS projection together with the decision boundary. This plot as well serves as navigation tool for detail-on-demand.</p><p>• ROC curve: includes ROC curve with interactive operating point and critical elements.</p><p>• Details-on-demand: includes all the visualizations that show information on a particular interactively selected data item. Those include regular text detail-on-demand, starplot with dissimilarities to all the prototypes, and heatmap and difference bar plot showing contribution of each feature to similarity.</p><p>The spatial arrangement of the visual components corresponds to their functionality. The ROC curve is placed in the direct neighborhood of projection plot and scatterplot matrix. A set of details-ondemand visualizations, represents details of interactively selected  <ref type="figure">Figure 7</ref>: Our framework for a prototype-based visual decision making system, with the proposed visualization solutions and interaction techniques. Both system and user actions are indicated. This system extends the one proposed in <ref type="bibr" target="#b17">[18]</ref>.</p><p>elements on the projection plot or on scatterplots of dissimilarity, and is therefore placed in their direct neighborhood.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">CASE STUDY 7.1 Implementation details</head><p>The system is implemented using ProtoVis <ref type="bibr" target="#b6">[7]</ref>. Protovis is a free and open-source, JavaScript and SVG based, toolkit for web-native visualizations. The 2D projection space is pre-computed using MDS in Matlab. The classifiers and ROC curve are pre-computed in Matlab.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2">Forensic Psychiatry application</head><p>In a case study we use a dataset of forensic psychiatric patients in the Netherlands provided by the Expertise Center for Forensic Psychiatry (EFP). In the Dutch legal system, a forensic expert often has to advise the court whether a mentally disordered criminal should be released back to the society or should be treated in the closed mental institution. In fact, the expert has to assess the risk that the patient will re-offend (recidivism). This decision has to be taken very consciously, as it might have great consequences. Therefore, the expert has to understood his data and the predictive models very well. A system for exploring the data and the models is an important contribution in this field. The dataset consists of 103 offenders who, at the time of the alleged crime, suffered from mental disorder and received what is called a 'disposal to be involuntarily admitted to a forensic psychiatry hospital on behalf of the state' (a so called 'TBS-order' in Dutch). The termination of the TBS-orders are based exclusively on the professional expertise of the clinicians. Each patient is assigned a class label indicating whether he has been convicted for a new crime after his TBS-order has been terminated. Of the 103 defendants, 38 were convicted again, whereas 65 are non-recidivists. There are 20 ordinal features and 7 numeric features, which are the scores of the PCL-R (Psychopathic Checklist-Revised) test. Patients were retrospectively scored with these risk assessment measures and recidivism data was retrieved from the documentation of the Dutch Ministry of Justice.</p><p>For this dataset we calculate the dissimilarity matrix, using Gower's coefficient <ref type="bibr" target="#b10">[11]</ref> with Podani's extension <ref type="bibr" target="#b22">[23]</ref>. We select 4 prototypes per class, using the k-centers algorithm. A fisher linear discriminant classifier is trained with the dissimilarities to the selected prototypes on a train set and evaluated on the test set. Note that a linear classifier in dissimilarity space is a non-linear classifier in the original feature space. The accuracy of the classifier is 72%. The classifier is then applied to the entire dissimilarity matrix and visualized in the dissimilarity scatter matrix and in the 2D MDS of the dissimilarity space. To visualize the patients we assign red color to recidivists and blue color to non-recidivists. As we can not use the real photos due to privacy reasons, we use again photos of the authors, their colleagues and relatives. The corresponding ROC curve for fisher classifier is also visualized as can be seen in figure 8. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.3">Usage Scenario</head><p>We now demonstrate how our system can be used for visual exploration of the prototypes in the dissimilarity space and the corresponding fisher classifier trained on the criminal patients dataset. We describe a basic scenario. For additional details, please refer to submitted video-demo of our implemented system. The usage scenario is based on the first exploration round done by the expert. The expert was already familiar with implemented techniques and with the feature representation of the dataset.</p><p>Analyst X is asked to explore the system, in particular to look for patterns in the prototypes space and explore the classification model. The expert is familiar with all the prototypical patients. Other patients do not necessary have to be known to the expert. First, the dataset is loaded, without the visualization of the classification model. The images of the prototypical patients are visualized on the diagonal of the matrix. The analyst starts to explore from the Scatter Matrix Window to get an overall view of the selected prototypes and the general patterns visible from the plots. She hovers over the scatterplots highlighting several items. Those items are highlighted in all the plots in the Scatter Matrix. She comes across a plot of dissimilarities to prototypes that directly draw her attention, as she knows those prototypes very well. One of them is a recidivist, the other not. From the photographs she directly recalls the cases of these patients and the general characteristic of their criminal profiles. She selects this plot to explore all other data elements in relation to those patients, in detail. She is interested in the data element that is the least similar to prototypical recidivist and she is intrigued why exactly they are dissimilar. By looking at the details-on-demand she sees that for two features that patient is actually quite similar to the prototypical recidivist. She finds this an interesting discovery. She recalls, that the prototypical recidivist patient had indeed a low score for those characteristics. Further, she moves to the projection view and discovers the neighbors of the previously selected patient. By hovering over those patients she explores their details and discovers that they do not differ much from the selected patient in the dissimilarities and in the contribution of the features. Next, the analysts explores the classification model. She would like to have less wrongly classified recidivists. She manipulates the operating point on the ROC curve to include less wrongly predicted recidivists. The decision boundary is updated in the scatterplots and in the projection plot. One of the patients has now assigned different label. She explores the details of this patient and his similarity per feature to the most similar prototype. Based on the features similarity to the nearest prototype, she assesses that this patient should indeed be classified as a recidivist. She decides that this classification model is more suitable.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.4">Evaluation and discussion</head><p>The framework proposed in this paper was developed in collaboration with the experts in Forensic Psychiatry. The system has been introduced to several forensic psychiatry experts from the Netherlands and United Kingdom. Based on the conversations with the experts, during which they were shown the system, several interesting discussion points emerged. In this section we describe the most important comments of the experts and how they influenced the design of the system.</p><p>The most important issue is a conceptual difference in interpreting similarities and dissimilarities. The experts indicated that they can interpret the relation between the prototypes and data items bet-ter when they are visualized in terms of similarities. From technical point of view there is no difference between those two. However from perception point of view it appeared to be an important issue. Therefore, we explicitly make a choice to visualize the difference in similarity to two prototypes in the barplot, see figure 6(b).</p><p>In addition, the experts indicated that the colors corresponding with degree of similarity were misleading. Experts consistently indicated red as the color they associate with high degree of similarity. We have taken it into account in our visualizations.</p><p>We acknowledge the fact, that these were merely primary interviews. The most important next step is to conduct systematic empirical evaluation of the system. We plan to use multiple rounds of evaluation with the end users to test the usefulness of the approach and identify the areas of improvement. However user evaluation is difficult for such broad tasks as visual exploration, so we anticipate performing time consuming qualitative studies. The experts themselves indicated the difficulties that they foresee. The most concerns of the experts involved the ethical, privacy and legal issues.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">CONCLUSION</head><p>This papers proposes to primarily focus on dissimilarities to visually represented prototypes instead of features. We argue that from a human's visual thinking point of view this is a more suitable approach. We propose an interactive framework to explore visually represented prototypes space and results of classification in this space. We propose to represent the data visually in terms of the most characteristic elements -images of prototypes-and all other data items in terms of dissimilarity to those prototypes. The dissimilarity to visually represented prototypes is visualized together with the results of the classification, and allow interactive exploration of costs of classification. In particular, we focus on supporting interactive exploration by representing the dissimilarity to prototypes in various visualizations. Those visualizations aim at highlighting different aspects of the dissimilarity to prototypes space and relation between dissimilarity space and features. We have shown how the existing techniques can be tightly coupled in a structured and highly interactive way, revealing patterns in terms of similarities to visually represented prototypes.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Classification in dissimilarity space. Since we propose to represent prototypes visually, we use images of prototypes (ie: pictures of people).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>An example to illustrate how a dissimilarity scatterplot is constructed. (a) Data elements from a multi-dimensional dataset are represented in a 2D scatterplot of a sub-set of two numerical variables. (b) Two of the selected prototypes are chosen. Based on the dissimilarities of all the data items to prototype 1 (on the X-axis) and the dissimilarities of all the data items to prototype 2 (on Y-axis) a scatterplot is created. The prototypes are represented by the associative images on the axes.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 :</head><label>3</label><figDesc>The dissimilarity plot matrix, with images of the prototypes on the diagonal.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 :</head><label>4</label><figDesc>Projection of the dissimilarity space using MDS. The prototypes are represented by images. The data items are assigned color, according to the original label. They are assigned shape, according to the result of classification. The circular dots are correctly classified examples and triangles are misclassified examples. The approximation of the classifier, trained on the actual similarities, is plotted in the projection space.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 5 :</head><label>5</label><figDesc>Starplot of actual dissimilarities of selected item to all the visually represented prototypes. The selected element is plotted in the center of the plot. The color and shape indicate the accordingly original and predicted label. The colors of the circumference for each of the prototypes indicates the original label of the prototype, where a blue color indicates the one class, and the red color the other.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 6 :</head><label>6</label><figDesc>Details-on-demand revealing the contribution of the individual features to the similarity. (a) Regular textual details and image of the inspected data item; (b) Bars showing difference in dissimilarities between two prototypes and selected item for each feature; (c) Heatmap showing difference in dissimilarities per prototype, for selected item, for each feature.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>For visualization purposes 2 -</head><label>2</label><figDesc>or 3-dimensional projections can be calculated and directly displayed in a comprehensible way for the expert. The representation of an MDS-mapping in 2D includes the projected prototypes, visually represented as images. The projected elements of the entire dataset are represented as dots. The axis of the MDS-mapping are meaningless. The distances between the projected elements and their relative position are what represents the structure of the data. The interpretation of the MDS-mapping is supported by the visual representation of prototypes (images), which are known elements for the expert. It allows an expert to link prior knowledge to the geometry of the projection. The distances in MDS projection are approximated to represent the dissimilarity space. The expert can visually assess the quality of the projection by referring to the prototype matrix. Each projected distance in the MDS map can be visually compared with the actual dissimilarity.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 8 :</head><label>8</label><figDesc>Screenshot of the system.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Similarity measure for different types of variables, as proposed in</figDesc><table /><note></note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Spotfire</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Similarity clustering of dimensions for an enhanced visualization of multidimensional data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ankerst</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Berchtold</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename><surname>Keim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Symposium on Information Visualization</title>
		<imprint>
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">DataJewel: Integrating Visualization with Temporal Data Mining</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ankerst</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Tjoelker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Lecture Notes in Computer Science</title>
		<imprint>
			<biblScope unit="volume">4404</biblScope>
			<date type="published" when="2008" />
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Incremental multidimensional scaling method for database visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Basalaj</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Visual Data Exploration and Analysis VI, SPIE</title>
		<meeting>Visual Data Exploration and Analysis VI, SPIE</meeting>
		<imprint>
			<date type="published" when="1999" />
			<biblScope unit="page" from="149" to="158" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Investigating and reflecting on the integration of automatic data analysis and visualization in knowledge discovery</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Bertini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lalanne</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGKDD Explorations</title>
		<imprint>
			<date type="published" when="2009-12" />
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="9" to="18" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Combining dissimilarity based classifiers for cancer prediction using gene expression profiles</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Blanco</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Martin-Merino</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>De Las</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Rivas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">8</biblScope>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
	<note>Suppl</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Protovis: A graphical toolkit for visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bostock</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Heer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Trans. Visualization &amp; Comp. Graphics (Proc. InfoVis)</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">A new initialization method for categorical data clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Expert Syst. Appl</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="10223" to="10228" />
			<date type="published" when="2009-09" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Graphical Methods for Data Analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Chambers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">S</forename><surname>Cleveland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Kleiner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">A</forename><surname>Tukey</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1983" />
			<publisher>Wadsworth</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Visual human+machine learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Fuchs</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Waser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gröller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TVCG</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1327" to="1334" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">A general coefficient of similarity and some of its properties</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">C</forename><surname>Gower</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biometrics</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="857" to="871" />
			<date type="published" when="1971" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Visual cluster validity for prototype generator clustering models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">J</forename><surname>Hathaway</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">C</forename><surname>Bezdek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recogn. Lett</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="1563" to="1569" />
			<date type="published" when="2003-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">A tour through the visualization zoo</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Heer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bostock</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Ogievetsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Commun. ACM</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="59" to="67" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Choices, values and frames</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kahneman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Tversky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">American Psychologist</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="341" to="350" />
			<date type="published" when="1984" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Visual analytics: Scope and challenges</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Keim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Mansmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schneidewind</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ziegler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Lecture Notes in Computer Science</title>
		<imprint>
			<biblScope unit="page" from="76" to="90" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Fuzzy clustering of categorical data using fuzzy centroids</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D.-W</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recogn. Lett</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="1263" to="1271" />
			<date type="published" when="2004" />
			<publisher>August</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kruskal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Wish</surname></persName>
		</author>
		<title level="m">Multidimesional Scaling. Sage</title>
		<imprint>
			<date type="published" when="1978" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Visual exploration of classification models for risk assessment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Migut</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Worring</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on VAST</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Interactive search by direct manipulation of dissimilarity space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">P</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Worring</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">W M</forename><surname>Smeulders</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Multimedia</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1404" to="1415" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Dissimilarity measures for detecting hepatotoxicity in clinical trial data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">E</forename><surname>Otey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Parthasarathy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">C</forename><surname>Trost</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SDM</title>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Dissimilarity representations allow for building good classifiers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Pekalska</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">P W</forename><surname>Duin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recogn. Lett</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="943" to="956" />
			<date type="published" when="2002-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Prototype selection for dissimilarity-based classifiers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Pekalska</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">P W</forename><surname>Duin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Paclík</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recogn</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page" from="189" to="208" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Extending gower&apos;s general coefficient of similarity to ordinal characters</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Podani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Taxon</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="331" to="340" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Towards effective visual mining with cooperative approaches</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Poulet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Visual Data Mining: Theory, Techniques and Tools for Visual Analytics</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="389" to="406" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Reprinted in Readings in Cognitive Science. A Perspective from Psychology and Artificial Intelligence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Rosch</surname></persName>
		</author>
		<editor>A. Collins and E.E. Smith</editor>
		<imprint>
			<date type="published" when="1978" />
			<biblScope unit="page" from="27" to="48" />
		</imprint>
	</monogr>
	<note>Principles of Categorization</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Polaris: A system for query, analysis, and visualization of multidimensional relational databases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Stolte</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Hanrahan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="52" to="65" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Ggobi: evolving from xgobi into an extensible framework for interactive data visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">F</forename><surname>Swayne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">T</forename><surname>Lang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Buja</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Cook</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Statistics and Data Analysis</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="423" to="444" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">A Global Geometric Framework for Nonlinear Dimensionality Reduction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">B</forename><surname>Tenenbaum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Silva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">C</forename><surname>Langford</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">290</biblScope>
			<biblScope unit="issue">5500</biblScope>
			<biblScope unit="page" from="2319" to="2323" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Illuminating the Path: The Research and Development Agenda for Visual Analytics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Cook</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005" />
			<publisher>IEEE CS Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Dissimilaritybased detection of schizophrenia</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ulas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Duin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Castellani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Loog</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bicego</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Murino</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bellani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Cerruti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Tansella</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Brambilla</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Brain Decoding: Pattern Recognition Challenges in Neuroimaging (WBD), 2010 First Workshop on</title>
		<imprint>
			<date type="published" when="2010-08" />
			<biblScope unit="page" from="32" to="35" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Xmdvtool: integrating multiple methods for visualizing multivariate data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">O</forename><surname>Ward</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">VIS &apos;94: Proceedings of the conference on Visualization</title>
		<imprint>
			<date type="published" when="1994" />
			<biblScope unit="page" from="326" to="333" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Visual Thinking for Design</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Ware</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
			<publisher>Morgan Kaufmann Publishers</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Toward a deeper understanding of the role of interaction in information visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Stasko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Jacko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1224" to="1231" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Visual data mining of multimedia data for social and behavioral studies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Visualization</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="56" to="70" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
