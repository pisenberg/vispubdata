<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/pisenberg/grobid/grobid-0.6.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Visual Analytic Roadblocks for Novice Investigators</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brian</forename><surname>Fisher</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ji</forename><surname>Soo</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Purdue University</orgName>
								<orgName type="institution" key="instit2">Simon Fraser University Purdue University</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">IEEE Symposium on Visual Analytics Science and Technology October</orgName>
								<address>
									<addrLine>23 -28, Providence, Rhode Island</addrLine>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Visual Analytic Roadblocks for Novice Investigators</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2021-02-19T19:56+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Visual analytics</term>
					<term>investigative analysis</term>
					<term>cognitive model</term>
					<term>framework</term>
					<term>roadblock</term>
					<term>qualitative experiment H.1.2 [Models and Principles]: Human Information Processing J.4 [Social and Behavioral Sciences]: Psychology -Experimentation</term>
				</keywords>
			</textClass>
			<abstract>
				<p>We have observed increasing interest in visual analytics tools and their applications in investigative analysis. Despite the growing interest and substantial studies regarding the topic, understanding the major roadblocks of using such tools from novice users&apos; perspectives is still limited. Therefore, we attempted to identify such &quot;visual analytic roadblocks&quot; for novice users in an investigative analysis scenario. To achieve this goal, we reviewed the existing models, theories, and frameworks that could explain the cognitive processes of human-visualization interaction in investigative analysis. Then, we conducted a qualitative experiment with six novice participants, using a slightly modified version of pair analytics, and analyzed the results through the open-coding method. As a result, we came up with four visual analytic roadblocks and explained these roadblocks using existing cognitive models and theories. We also provided design suggestions to overcome these roadblocks.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>INTRODUCTION</head><p>We have recently seen increasing interest in visual analytics tools and their applications in investigative analysis. Recognizing the effects of visual analytics tools and visualizations in various intellectual activities, researchers have attempted to understand the potential benefits of such systems in investigative analysis <ref type="bibr" target="#b0">[1]</ref>. Many visual analytics systems, such as Jigsaw <ref type="bibr" target="#b1">[2]</ref> and INSPIRE <ref type="bibr" target="#b2">[3]</ref>, have been developed and evaluated to provide analysts with insight-gaining platforms. In addition, many scholars have proposed theories, frameworks, and models to understand the interaction between human and visualization systems. Such studies proposed interaction models <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b4">[5]</ref>, analytic activity models <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b5">[6]</ref>, and cognitive models <ref type="bibr" target="#b6">[7]</ref><ref type="bibr" target="#b7">[8]</ref><ref type="bibr" target="#b8">[9]</ref><ref type="bibr" target="#b9">[10]</ref>. There was also a qualitative study <ref type="bibr" target="#b10">[11]</ref>.</p><p>Despite a plethora of such studies, we still do not know what kinds of roadblocks novice users face while interacting with visual analytics tools to solve difficult problems in investigative analysis. In particular, investigative analysis, such as terrorism prevention, requires developing hypotheses, performing sensemaking tasks, and building stories, which is beyond identifying trends in graphical representations <ref type="bibr" target="#b0">[1]</ref>. Thus, it is difficult to grasp what kinds of problems novice analysts struggle with when using visual analytics tools for their analytic activities, which we define "visual analytic roadblocks" (henceforth roadblocks).</p><p>Therefore, we were motivated to investigate this uncharted area. We would like to answer the following research questions in this study:</p><p>•</p><p>What is the cognitive model of interaction between human users and visual analytics tools in the context of investigative analysis? •</p><p>What are the cognitive roadblocks when people conduct investigative analysis using a visual analytics tool? •</p><p>What are the proper solutions to reduce/remove the roadblocks?</p><p>To answer these questions, we reviewed the theories, frameworks, and models that explain the cognitive process of interaction between human users and visual analytic tools in the context of investigative analysis (see <ref type="bibr">Section 2)</ref>. Then, we designed a qualitative experiment to find out the roadblocks of using a visual analytics tool, Jigsaw, in investigative analysis (see Section 3). In particular, we studied how human subjects use Jigsaw in a fictitious investigative analysis scenario. To analyze the cognitive process in the investigative analysis setting, we engaged in deep conversation with the participants during the experiment. We analyzed the recorded conversation along with screen activities, created a list of roadblocks, and compared them against relevant models (see <ref type="bibr">Section 4)</ref>. Based on the results, we attempted to substantiate the human cognitive models of interaction between human users and visual analytics tools in the context of investigative analysis (see <ref type="bibr">Section 5)</ref>. In this article, we review our procedures and results; then, we discuss the implications of our findings and discuss the limitations and future works (see Sections 6).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORKS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Cognitive Models of Visual Analytics</head><p>We found two models that describe cognitive processes of investigative analysts. One is the sense-making loop developed by Pirolli and Card <ref type="bibr" target="#b11">[12]</ref>. Their model introduces two major loops: an information-foraging loop and a sense-making loop. The final outcome, a story, is derived from the iterative analysis across both loops in this model. Green et al. <ref type="bibr" target="#b9">[10]</ref> focused on higher-level tasks of reasoning process, such as decision-making and problem solving, and discussed how interface designs of information visualization systems should be made to facilitate the process. Though these two models helped us understand the cognitive process of investigative analysts using visual analytics tools, they do not cover roadblocks in the process. Thus, we expanded the scope of literature review, not being limited to investigative analysis, but including general cognitive processes in human-visualization interaction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Potential Visual Analytic Roadblocks</head><p>Many models, theories, and frameworks have been proposed to explain the interaction between users and visualization techniques. Through them, we could collect a list of potential roadblocks. Roadblocks may be found in low-level interactions. Yi et al. <ref type="bibr" target="#b3">[4]</ref> investigated the role of interaction techniques in information visualization. One interesting aspect of their study is the emphasis on e-mail: kwonb@purdue.edu, bfisher@sfu.ca, yij@purdue.edu users' intents. They used users' intents to categorize various interaction techniques, which shows that there is a common set of intents that users would like to achieve. Thus, when users' intents fail to be realized by given interactions, users may be frustrated. Lam <ref type="bibr" target="#b4">[5]</ref> proposed a framework of interaction costs in information visualization. Her framework includes seven categories of interaction costs that impact the user interface and information visualization use. The costs articulated in her study, such as decision costs and visual-cluttering costs, could be potential roadblocks for users. However, these models tend to focus on low-level interactions between users and visualization systems, but not on the users' high-level intelligence activities.</p><p>The study of Amar and Stasko <ref type="bibr" target="#b5">[6]</ref> may provide notion of highlevel cognition. They focused on the analytic gap, which refers to troubles encountered by users while using visualization systems to perform analytic activities such as decision-making and learning. In this study, they suggest two different kinds of gaps: the Rationale Gap and the Worldview Gap. The Rationale Gap is "the gap between perceiving a relationship and actually being able to explain confidence in that relationship and the usefulness of that relationship" (p. 114); the Worldview Gap is "the gap between what is being shown and what actually needs to be shown to draw a straightforward representational conclusion for making a decision" (p. 114). These gaps could prevent users from conducting analytic tasks properly while using visual analytics tools and, thus, can be identified as roadblocks. The study is useful to understand the users' challenges though it was not fully dedicated to the context of investigative analysis.</p><p>Additional roadblocks may exist in the interaction between internal visualization and external visualization. Liu et al. <ref type="bibr" target="#b6">[7]</ref> proposed distributed cognitions as a theoretical framework for information visualization. They claim that cognition is not a property of the human mind, but an emergent property of interaction. Using their framework, they described how humans distribute cognitions around visual representations and process them to achieve the users' goal. This framework indicates that we may be able to find some roadblocks by observing how visual systems are adjusted or modified, which actually reflects human cognition. Ziemkiewicz and Kosara <ref type="bibr" target="#b8">[9]</ref> modeled human-visualization interaction as the shaping of information by visual metaphors. They claimed that understanding visualization involves the interaction between the external visual representations and the users' internal knowledge representations; when these two representations are in conflict, user roadblocks may occur. In addition, visual metaphors can affect the level of understanding visualizations. Therefore, users consistently interact with visual metaphors using users' internal representations while conducting investigative analysis. Thus, a user can struggle with visualizations in cases where the visual metaphors used in the visualizations do not accord with the users' internal knowledge representation. Liu and Stasko <ref type="bibr" target="#b7">[8]</ref> suggested the mental model-based reasoning in information visualization. They examine the process of interplay between internal representations and external representations. Their results demonstrate that interaction in information visualization systems could be interpreted as the following: external anchoring, information foraging, and cognitive offloading. Therefore, investigative analysis may proceed under the tight interplay between the user's mental model and external visualizations. In other words, users may meet roadblocks when the mental model conflicts with the visual analytics tools.</p><p>In addition to the roadblocks identified in mental models, we also can identify roadblocks in the process of selecting visualizations for given tasks. Grammel et al. <ref type="bibr" target="#b10">[11]</ref> studied the challenges novice users had while attempting to construct visualization while exploring data sets. The major roadblocks-barriers in their term-they found were "translating questions into data attributes, designing visual mappings, and interpreting the visualizations" (p. 947). Although what they found is relevant and similar to the purpose of our study, the study was not conducted in the context of investigative analysis. In addition, they intentionally did not allow their participants to directly interact with the tool, but we believe that direction observation of user interaction would be essential to understand roadblocks. Thus, to extend their findings in the investigative analysis setting, we felt that additional empirical study in the context of investigative analysis is needed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Qualitative Research Methods</head><p>We surveyed a number of research methods before settling on a variation of pair analytics. Protocol analysis, often called "thinkaloud" method, is sometimes suggested in visual analytics studies <ref type="bibr" target="#b12">[13]</ref>. Protocol analysis reveals participants' thinking process by verbal reports given while performing specific tasks. However, a major disadvantage of this method is that verbal reporting could affect the performance of tasks and vice versa <ref type="bibr" target="#b12">[13]</ref>. There is an alternative protocol, called insight-based study <ref type="bibr" target="#b13">[14]</ref>, which addresses this issue. The process requires users to keep a journal that records insights gained from using information visualizations to their routine analysis works over a period of time. Although this process is less intrusive than protocol analysis, it can miss some issues that can emerge from the cognitive process of using information visualizations. As an alternative, Arias-Hernandez et al. <ref type="bibr" target="#b14">[15]</ref> proposed the pair analytics method to study the interaction and cognition in visual analytics. The pair analytics method requires pairing a dyad of participants, one subject matter expert (SME) and one visual analytics expert (VAE), and to generate dialogue between two while performing a visual analytics task together. This method can elicit the cognitive process of individuals in a more natural and less intrusive way than protocol analysis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">EXPERIMENTAL METHODS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Participants</head><p>Six university students (5 male) were recruited for this study through fliers and a mailing list. All of them were engineering students (two of them majoring in industrial engineering, one in electrical computer engineering, one in biomedical engineering, and two in undecided engineering). They were compensated $20 for 2-hours of participation. Although we could not recruit actual investigative analysts, we explicitly described the study goals and provided a simulated context as an investigative analyst to our participants as Kang et al. did <ref type="bibr" target="#b0">[1]</ref>. Thus, we believe that our participants were fully motivated and reasonably performed investigative analysis tasks. Since we are also particularly interested in the hurdles encountered by novice users, we believe that university students are reasonable alternative population for professional investigative analysts for our research goal. We will discuss the areas that we want to investigate further with experienced investigative analysts in Section 6.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Equipment</head><p>A desktop computer with Microsoft Windows XP, a microphone, and two 19" LCD displays with standard peripheral devices (a keyboard and a mouse) were used for this study. Participants were asked to use Jigsaw <ref type="bibr" target="#b1">[2]</ref> (see Section 3.5 for more details) to conduct investigative analysis. A screen capturing software called Camtasia <ref type="bibr" target="#b15">[16]</ref> was also used to record user activities on both displays as well as the dialogue between participant and experimenter. After experiments were done, a qualitative data analysis software, called "ATLAS.ti" <ref type="bibr" target="#b16">[17]</ref>, was also used to code the recorded screen activities and dialogues.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>3.3</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Procedure</head><p>When a participant arrived to the usability lab, an experimenter introduced the purpose, the procedure, and the benefits of this experiment to participants. They were also informed the voluntary nature of the experiment and signed the consent form. Then, the experimenter informed the participant of how to use the system. The features of each view of Jigsaw were thoroughly explained and demonstrated based on the manual of Jigsaw 0.3. To avoid the variation in instruction, we read a scripted instruction to participants in the order that was used in the manual as appeared in <ref type="figure" target="#fig_0">Figure 1</ref>. Then, the participant was allowed to explore each view for 5 minutes, but most of them ended up using much less than the allotted time. After experiencing each view, the participant rated the perceived difficulty of each view in 5-point Likert scale (1: Easy to use, self-explanatory, 2: Clear, possible to use, 3: Somewhat clear, hard to use, 4: Not clear, hard to use, and 5: Totally incomprehensible). We collected the difficulty ratings to see the relationship between the perceived difficulty at the introduction session and the performance during the experiment. It took about 30 minutes to finish this introduction session. At the end of introduction, we asked participants about their first impressions of the views.</p><p>After the introduction session, each participant was asked to accomplish three mini tasks and five investigative analytic tasks listed in Section 3.4. While participants complete the tasks, the participant's interaction on the computer screen and the participant's comments were recorded. We employed a slightly modified version of pair analytics method <ref type="bibr" target="#b14">[15]</ref>. In the original version of pair analytics, a dyad of participants, one subject matter expert (SME) and one visual analytics expert (VAE), performed a task together while generating dialogue. However, through our pilot studies, we found that roadblocks were more apparent when we allowed a participant to directly interact with Jigsaw while an experimenter passively guided the participant through how to use the tool. Thus, we decided to let an experimenter provide guidance only when participants requested it. The leading author takes the role of the experimenter for all participants to maintain consistency. During the experiment, the experimenter actively listened to the concerns and problems as well as findings from their analysis and clarified the points made by them. The experimenter also initiated dialogue in case that participants elicited frustrations in words (e.g., participants murmured, "I think I am stuck.") or in actions (e.g., participants shook their head).</p><p>After the experiment session, the participant was asked to fill out a simple demographic survey questionnaire. The whole experiment took approximately two hours. The recorded screen shots and discourse were subsequently transcribed and coded by two independent coders, which is detailed in Section 3.6.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Experimental Scenario and Tasks</head><p>We used the same scenario used by Kang et al. <ref type="bibr" target="#b0">[1]</ref>. This scenario includes 50 fictitious agency reports, each of which describes a terrorist event with time, places, and people involved. With the 50 reports, the participant was asked to perform three mini-tasks and five investigative tasks. Mini-tasks were designed to provide simple and easy questions that a participant can answer easily without in-depth understanding of the given scenario. We provided these mini-tasks to observe participants' basic understanding of Jigsaw.</p><p>• T1: Name the largest social network (Network: a group of organizations or people are connected).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>•</head><p>T2: Name the smallest social network. • T3: How many reports mention "Los Angeles?"</p><p>Upon completion of mini-tasks, participants were asked to perform relatively longer but guided investigative tasks. We did not want to make these tasks too complicated, so we created five serial tasks so that participants could only focus on one major terrorist plot by following these five related tasks. In particular, we provided the keyword "U-Haul" to make the investigative analysis even easier. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Experimental Software</head><p>As previously mentioned, we used Jigsaw 0.3 <ref type="bibr" target="#b1">[2]</ref> for our experiment. We chose Jigsaw because it provides 11 different kinds of visualizations: Document, List, Document Cluster, Graph, Document Grid, Calendar, Timeline, WordTree, Scatterplot, Circular Graph, and Shoebox (renamed as Tablet in Jigsaw 0.4) Views, where we can examine different roadblocks caused by different visualizations. We expected that some of visualizations were more difficult to understand than others. Among the 11 views available in Jigsaw, we did not use the Shoebox View because this view would allow too much freedom to build participants' own visualizations. It could take more than two hours for a participant to grasp its value. However, we recognize its value in a long-term usage, so we will consider studying its role when longitudinal studies are conducted.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.6">Coding Procedure and Analysis</head><p>Two independent coders, the leading author and an external expert, coded video clips together. A video clip is a unit that refers to a meaningful, mutually exclusive segment of video excerpted from one entire video file per participant. We focused on finding evidence that reveal the moments that participants encountered roadblocks or were troubled. We first searched for the moments that participants struggled the most. However, those moments were not easily detected because participants often built up frustration over time, so it was often unclear which point, exactly, was a frustrated moment. Therefore, as an alternative, we searched for more distinguishable moments that could result from such troubles. After extensive reviews of all video records, we identified two distinguishable moments: view-switching moments and leaning moments. View-switching moments refer to the moments that participants switched from one view to another. Leaning moments are the moments that participants leaned upon the experimenter to ask for direct or indirect aids on their tasks. Reviewing the entire video records, we marked those moments as view-switching and leaning clips, and coded what happened in these clips.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.6.1">View-Switching Moments</head><p>View-switching moments refer to when a participant deactivates the current view (e.g., minimizing the window, closing the window, and bringing the current window backward by prompting another window front) and activates another view (e.g., opening a new view, recovering the window size, and prompting the window front). There was one exception that we did not consider as view-switching moments. When a participant organized two or three views in the dual screens to control and read multiple visualizations at once, those views were considered as one view pool. More specifically, we defined a view pool as a current set of activated, readily viewable views in screens without any substantial occlusion from one another. Thus, we did not count the moments that participants switched from one view to another in their view pools as view-switching moments. After collecting all view-switching moments into 56 separate clips, the two coders reviewed the clips and generated codes from the clips. In this process, we focused on why the participant left a particular view or a view pool and selected another view or create a view pool. We observed speech and activity before and after the view-switching moments. We used a Grounded Theory-based approach, so we let the codes emerge from the data. Following the coding strategy in <ref type="bibr" target="#b14">[15]</ref>, the two coders tried to capture cognitive and behavioral phenomena by constructing agreed codes. We also did same for leaning moments in Section 3.6.2. The two coders coded randomly selected 25% of all view-switching moments (14 clips) and finalized the definitions of the codes together. A coder, the leading author, coded the rest of 42 clips afterward. Then, the two coders reviewed the codes and made agreement together. The process was repeated until codes are stabilized.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.6.2">Leaning Moments</head><p>Leaning moments are moments that a participant directly or indirectly asks for help from the experimenter. We collected the video clips where the participant asked for help in the experiment. We collected 33 clips in total. In this process, we thoroughly exam-ined the conversation and the screen activity in those video clips. Based on the concerns and questions raised by the participant, we coded what kinds of roadblocks participants went through in the moment. During the process, we found similar patterns with the view-switching moments. In addition to the existing codes, we found some evidence that the preconceived mental model of the participant impeded the process of adapting to existing views. We added this code and other miscellaneous troubles and iteratively coded all clips. After the leading author coded the entire clips, an external coder thoroughly examined the codes, and the two reached agreement together.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.7">Limitations</head><p>We acknowledge that the design of this qualitative experiment is not ideal. The number of participants might not be sufficient to gain in-depth and comprehensive insights into all the potential roadblocks. All of participants were university students, so they are not only novice visual analytics tool users, but also novice investigative analysts. The lack of expertise in the intelligence activity might influence the results of this study. We only used Jigsaw as a tool and let participants perform investigative analysis with a fictitious scenario. To generalize our findings, we should employ various tools, scenarios, and contexts. However, despite these limitations, we believe that this study is an interesting first step that may raise the awareness of novice investigative analysts, and the methodological lessons from this study would be interesting to someone in the visual analytics community.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">RESULTS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">The Introduction Session</head><p>We collected and organized the difficulty ratings on the ten views in <ref type="table" target="#tab_1">Table 1</ref>. The average difficulty ratings indicate that participants perceived all views between "Easy to use, self-explanatory (1)" and "Somewhat clear, hard to use <ref type="bibr" target="#b2">(3)</ref>." However, we also observed that there are individual differences in the ratings. For example, P2 rated Scatterplot View as 4, but P4 and P5 rated it as 1. P5 rated all views as 1, but others rated different visualizations in various levels. Even though the difficulty ratings were very low in general, we observed quite a few problems encountered by participants during the introduction session. Some participants reported that some views have limited capabilities. Some other participants complained that certain views were difficult to read or understand because of poor presentations and lack of visual cues. On the other hand, some other participants reported that the views were unfamiliar or unclear to them. Some participants reported that some views were not useful because those views can only show limited information. P1 said that the Document Grid View seemed not useful because it only showed the number of entities in different colors. P2 also said, in regards to the Scatterplot View, "I mean it makes sense, but it doesn't do much. I think other ones you showed [the List View] a lot better at correlating things." P1 and P2 said that the WordTree View could be useful only when they searched words properly. P4 said that the Document Grid and Cluster seemed easy-to-use but not useful. P5 said the Calendar View shows "less information than the Timeline View." Some other participants felt that visual representations were difficult to read and interact with due to visual clutter, lack of visual cues, or other problems in visual elements in certain views. P2 found the Graph View was more difficult to understand because entities could be clustered. P2 found that it is difficult to track what kinds of entities were expanded in the Calendar View because there is no visual cue that shows the history of expansion and the entities are visualized as a very small item. P4 could not interpret the Timeline View easily because the stacks do not have text labels. For the same reason, P4 did not like the Calendar View. P4 thought the Scatterplot View was overwhelming when too many entities were drawn simultaneously. P5 thought that the List View was better than the Graph View because the Graph View did not provide the immediate connection between entities, but only through central entities, the documents. P5 also thought that the Circular Graph is redundant with the Graph View, and preferred the Graph View because it is more spacious. P5 said about the Scatterplot View was not useful because of "large spatial separation" between entities in x-axis and y-axis. P6 commented about the List View, "I guess personally this isn't my type of tool. Especially, since it can get messy quickly." Some participants could not understand how or why they use some views because the views are unfamiliar or unclear to the participants. P1 said that the Scatterplot View was somewhat unclear. P3 stated, "I think I am less familiar…[with this view]." P3 also said "I don't really understand what the Document Grid View will be used for." P3 also added, "Again, at this time not immediately clear to me why you would use it… Here, there's even less organization than the Document Grid View. So, you are just seeing a cluster of documents." For similar reasons, P6 disliked the Document Cluster View because of "how everything is just thrown into a cluster like this… I think just a simple list view would be easier to pick out which document you're looking for…" P6 also disliked the WordTree View because P6 was "not really sure how it's determining to show this string."</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">General Usage Patterns</head><p>We observed common usage patterns. The most salient pattern is that participants used only a subset of the 10 possible views as their view pools for investigative analysis questions. Participants tried multiple views at the early stage. We observed many instances of view-switching in mini-tasks (T1 -T3). However, most participants narrowed down to the List View and two or three more views for their final view pools after starting the guided investigative tasks (T4 -T8). Different participants tended to use different sets of views as well. Besides the List View, P1, P2, and P3 used the Graph View and the Circular Graph View more often; P4 primarily used the Document View; P5 and P6 used the Timeline View plus all the above views. No participant opened the Calendar View. In response to the question about why only a small set of views was used, P5 stated, "Some views are redundant and some others are not relevant to tasks." P2 and P4 reported that they were not familiar with Jigsaw, so they used what they could understand and use easily. Especially, P2 used the List View frequently and P2 stated, "I really like the searched connection because this is how my brain works." This limited usage patterns are in line with what Grammel et al. <ref type="bibr" target="#b10">[11]</ref> reported.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Visual Analytic Roadblocks</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.1">R1: Failure to choose appropriate views</head><p>It is essential for analysts to choose appropriate views that are able to represent the information needed to accomplish the task objectives. However, participants sometimes could not choose appropriate views that can provide the information they were looking for. This often led to unnecessary view-switches.</p><p>We observed a number of incidents where people struggled to find the proper views in their verbal reports and screen activities. When answering T2, P1 was looking at some entities in the Circular Graph View. While struggling in the view, P1 admitted, "I just feel like having a hard time to choose the best display for this kind of question." P1 apparently understood the task objective by the comment, "I just want to see which ones have the least connection would be smallest network." However, P1 could not effectively use the List View. P2 also ran into a similar roadblock. When answering T3, P2 did not use the Document View to see which documents include the right answer; rather P2 stayed on views like the List View or the Circular Graph View, which mainly show the relationships between entities. Similarly, P4 also chose the Document Grid View, which only provides the number of entities in documents, while answering T1, which requires viewing the relationship of entities.</p><p>In some cases, some participants left a certain view even though the current view was appropriate to answer a particular question. While answering T1, P6 left the List View and wandered around with the Circular Graph View and the Graph View. For the same task, P3 also left the List View and chose the Graph View. While answering T4, P5 was trying to show relationships between three given names in the Graph View. P5 could have expanded entities by double-clicking, but P5 closed this view and chose the List View.</p><p>In other cases, some participants wishfully expected a certain view could provide the information they want to retrieve. P5 was trying to find evidence that supports a hypothetical story found from relationships between entities. P5 opened the Word Tree View and searched terms. However, P5 could not find sufficient information from there because the Word Tree View can only show excerpts that include searched terms. P5 also tried to find a story from the Timeline View in T8, but the story cannot be revealed until P5 looked up the actual documents in the Document View later.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.2">R2: Failure to execute appropriate interactions</head><p>To display information in a view, a participant should execute an appropriate set of interactions. Participants sometimes chose the correct view, but could not execute the appropriate interactions to display the information needed for given tasks. For example, P4 struggled to use the List View while working on T1. P4 said, "I am trying to figure out a way that I can see all the connections to everything or at least see them… put in order of connections." In order to do this, P4 needed was to press the "Add all" button. However, P4 failed to find the appropriate action in menu immediately. P6 had the same problem. Additionally, P2 was looking for entities with the most connections in the List View. P2 misused an interaction because P2 was confused by the term "sort of frequency." P2 misinterpreted "sort by frequency" as the amount of connections, but it refers to the frequency of entities in documents. P2, later, could not figure out how to search an entity and highlight the documents that include the entity in yellow in the Document Grid View. P3 also had similar problems with "sort by connection strength."</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.3">R3: Failure to interpret visualizations</head><p>Failure to read and understand visualizations often interrupted the investigative analysis process. Participants sometimes faced difficulty with the perception of visual items by clutters. In some other cases, they failed to interpret visualizations, so they could not grasp information represented by visualizations. Visual clutters in particular views impeded most of our participants. P5 was trying to see entities by expanding a document in the Graph View. P5 found that there are many entities from one document. P5 said, "Just from the interface respective, it might be useful to check occlusions. I gave here... the information is colliding here on the graph that's hard to use." P5 later made mistakes in interpreting connections in the Graph View as shown in <ref type="figure" target="#fig_1">Figure 2</ref> (top). P5 thought there was a line drawn between two entities, but there was no line. Because of similar clutters in the List View, P6 miscounted the number of connections of an entity because P6 took some neighboring irrelevant entities into account as well (see <ref type="figure" target="#fig_1">Figure 2</ref> (bottom)). P6 said, "I don't know why I thought this… but these (irrelevant items) were connected to different groups… and I kinda took these account … I should have only taken the highlighted into account." Some participants did not understand how to read and interpret the displayed information in certain views. While answering T3, P2 could have answered a question easily on the Time Line View because there were four bars, each of which represents a docu-ment (so, the answer is four), in the view. However, P2 did not know that each bar represents a stack of entities in each document. P3 also stated, "I was trying to get an idea of the Time Line View, but it's hard." P3 interestingly chose the Scatter Plot View with xaxis as time and y-axis as entities. This indicates that what P3 wanted was, indeed, a temporal visualization, but the Timeline View did not make sense to P3. P6 mistakenly read the number next to entities in the List View as the number of connections, but it was frequency.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.4">R4: Failure to match expectations and functionality</head><p>Participants' expectations sometimes do not match with the actual functionalities of some views, which slowed down the investigative analysis process. We observed some incidents where participants' expectations of views sometimes did not align with existing views from Jigsaw. They kept trying to find the best matching view for themselves, but they gradually adapted to existing views. Many participants wanted to start the analysis by loading all entities into views like the Graph View, the Circular Graph View, the Scatterplot View, and the Timeline view. This is interesting to us because attempting to see the overview is in line with visual information seeking mantra, "Overview first, zoom and filter, then details-on-demand" <ref type="bibr" target="#b17">[18]</ref>. Even though it is not possible to do so without loading each item one-by-one, participants scanned through menu items to try to perform the overview action. Their strategy seemed to start with full entities and to remove irrelevant items in those views ("filter"). This also suggests that participants wanted to load their memory off to visualizations by removing irrelevant entities from the view <ref type="bibr" target="#b7">[8]</ref>.</p><p>Some participants had specific expectations about how views should work. For example, P3 wanted to see the organization with most connections in the List View. However, when P3 realized that the List View is not automatically sorted in the order of the connection frequency, P3 got confused and frustrated. However, there are individual differences between these expectations. For example, P6 expected that whenever a new view was opened up, the new view should be automatically synchronized with other already-opened views by deriving all the entities from those views. On the other hand, P1 thought that an interaction with one view should only affect the view.</p><p>One might argue that this roadblock is a superset or a root cause of the other roadblocks (R1, R2, and R3). However, we decided to keep this issue as a separate roadblock because we noticed that the other roadblocks were easily overcome by subtle nudges, but R4 appears to be more persistent through the experiment. We experienced that R4 is not matter of simple misunderstanding (e.g., interpreting "sort by frequency" as "sort by the amount of connections") but a relatively serious collision between the way in that participants' minds work and the way in that Jigsaw works.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.5">Other issues</head><p>Other issues are reported and observed:</p><p>• Some participants had difficulties in understanding terms used in tasks and the scope of a task. We believe that these difficulties are caused by a lack of expertise in investigative analysis though this is one of rather salient difficulties that we observed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>•</head><p>It was interrupting to have to close all the views and reopen to start a new analysis. P3 wanted to have the 'clear' button to remove all entities in a view.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>•</head><p>It is difficult to learn how to use Jigsaw in two hours. P2 could not familiarize with Jigsaw enough to use it for investigative analysis during the experiment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>•</head><p>Investigative analysis was difficult. P5 had difficulty in creating stories from information found in views.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>! ! •</head><p>The scenario had much information. P1 thought that there was too much information to follow.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Special Observations From P5</head><p>We gathered interesting observations from P5, who rated all views with 1 in difficulty ratings and used more diverse views than others. P5 used special ways to learn the tool during the introduction session. P5 repeatedly commented about the view that P5 was interacting with, what the displayed information meant, and how the view generated information. P5 verbalized all the actions and results in the introduction session. While learning how to use the List View, P5 said, "Click on a person and obviously clearly indicates that which organization they belong to in the list and vice versa." P5 also tried to understand what the experimenter explained by repeating P5's own words. When the experimenter explained that there was a small pane on the right side, which showed the entity names in the selected stack, P5 stated, "Yeah, as you select the different stacks, it changes the view, got it." P5 maintained this attitude during the introduction session. After then, P5 did not have any notable issues with R4 from mini-tasks to guided investigative analysis tasks. Thus, P5 used more views for analysis than other participants.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">DISCUSSION</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Roadblocks Characteristics</head><p>Four different roadblocks emerged from our analysis: Failure to choose appropriate view (R1); Failure to execute appropriate interactions (R2); failure to interpret visualizations (R3); and Failure to match expectations and functionality (R4).</p><p>We initially hypothesized that R2 and R3 would be major roadblocks because we introduced the ten new visualizations to participants within half an hour. However, we found that other roadblocks, such as R1 and R4, are also substantial. We observed that many problems encountered by participants were beyond understanding what visual elements were supposed to mean. Even after they understood such basic elements, they had difficult time in combining information on visualizations with stories in their minds. Designers should consider methods to support users' abilities to overcome such troubles in the investigative analysis process. One important lesson from this study is that we should not forget what the visual analytics tool is intended to do: help users solve problems in investigative analysis. This calls for much more attention to the study of the actual cognitive tasks that investigative analysts deal with. We should shed light on the full spectrum of investigative analysis tasks and confirm the results in this study by revisiting our taxonomy and model in the context.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Roadblocks and Other Cognitive Models</head><p>The roadblocks we unearth here are interesting because various cognitive studies done in information visualization and visual analytics already describe the exact same or similar notions. R1. Lam <ref type="bibr" target="#b4">[5]</ref> also identified "Choosing amongst interface option" as an interaction cost. The examples in Lam's paper are not exactly in line with R1, but the general description aligns with this roadblock. "Visual mapping barrier" described by Grammel et al. <ref type="bibr" target="#b10">[11]</ref> is almost in line with this roadblock. They also demonstrate that participants switch back and forth between multiple views, which is the exact behaviors we observed in our study.</p><p>R2. We found that these roadblocks are more usability issues than others. Various heuristic evaluation principles, such as "visibility," are in line with roadblocks <ref type="bibr" target="#b18">[19]</ref>. However, we also noticed that participants have certain intentions for what to do while they interact with different views, and they got frustrated when views do not serve their intentions. Yi et al. <ref type="bibr" target="#b3">[4]</ref> investigated potential user intentions, which can be applied directly to roadblocks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>R3.</head><p>The closest description to this roadblock in literature is the "World View Gap" in Amar and Stasko <ref type="bibr" target="#b5">[6]</ref>. Again, there is a gap between what people expect and what they see in the visualization, which demonstrates the problem experienced in this roadblock. Another explanation may be problems of "interpreting visualizations" reported by Grammel et al. <ref type="bibr" target="#b10">[11]</ref>.</p><p>R4: The roles of mental models (internal representation or visual metaphor) have been discussed in Liu and Stasko <ref type="bibr" target="#b7">[8]</ref> and empirically shown in Ziemkiewicz and Kosara <ref type="bibr" target="#b8">[9]</ref>. Our observation of mismatch between expectations and functionality is in line with those findings. We believe that our study helps emphasize the importance of mental model in analyzing visual analytic roadblocks.</p><p>One common theme that we observed is that users have a certain expectation (or mental model or internal representation) for each particular view. If the expectation is not matched with actual behaviors of a view, a participant runs into many problems. In some sense, R1-R4 happened in different phases of investigative analysis in different levels of seriousness, but their root cause might be common: ill-structured mental model. We observed that participants often had these kinds of mismatches (shown through R1-R4) at the beginning stage, and they went through an adaptation period that eventually made them work with certain sets of views. We also found that providing a simple tutorial does not necessary help this issue.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Individual Differences</head><p>Even though we minimized inconsistency among participants in this study, we observed different behavior patterns among them as Kang et al. did <ref type="bibr" target="#b0">[1]</ref>. More specifically, we thoroughly covered the features of Jigsaw in the introduction session, and we made sure that six participants had no previous exposure to visual analytics tools. However, participants still had different initial mental models and their preferences toward different views. Thus, we could speculate that other factors, such as cognitive styles and prior knowledge, may affect the establishment and adaption of a mental model. In particular, we should examine 1) what kinds of cognitive styles influence the establishment of the mental models, 2) how we can see the exact picture of one's mental model, and 3) how we can help one adapt to existing views or even how visual analytics tools can adapt to the person. First, cognitive styles may affect the mental model conflicts. According to <ref type="bibr">Richardson [20]</ref>, people can be divided into two groups: visualizers who rely on imagery for cognitive performance and verbalizers who rely on verbal analytical strategies. We believe that visual analytics require both types of cognitive styles to some extents. P5's case supports this idea. In the introduction session, P5 could successfully learn all visualizations by translating the visual information into verbal information and vice versa. Visual analytics require users to derive the task objective, to apply it into visualizations, and to read the displayed information iteratively. Therefore, the cognitive style of investigative analysts may need to be more flexible so that they can constantly integrate one type of information into another.</p><p>Second, internal visualization activities may impact the process of understanding how to use external visualizations for investigative analysis. Internal visualization is the ability to mentally represent objects, events and abstract information <ref type="bibr" target="#b20">[21]</ref>. In particular, spatial visualization ability is known as the ability to comprehend, encode and mentally manipulate spatial forms <ref type="bibr" target="#b21">[22]</ref>. A skilled viewer automatically forms a link between these visual chunks and the interpretation of the data <ref type="bibr" target="#b22">[23]</ref>. However, participants who lacked such visualization ability might face difficulty in adapting to existing visualizations. One can improve internal visualization ability by experiencing many external visualization techniques <ref type="bibr" target="#b20">[21]</ref>. Therefore, the tutorial session like we had in the introduction session is important.</p><p>Third, prior knowledge in the context may also be important to effective interactions with visual analytics tools. A novice in a certain field can have difficulty in understanding graphic data on the subject <ref type="bibr" target="#b23">[24]</ref>. Thus, the level of experience in investigative analysis may play a role in visual analytics. This also suggests that the tutorial session for visual analytics tools should be done in the context of investigative analysis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Methodological Lessons</head><p>We found that a simple survey cannot predict the level of user understanding. The difficulty ratings for all views in <ref type="table" target="#tab_1">Table 1</ref> indicate that participants thought that they had no problem with understanding how to use the ten views. However, we have seen a decrease in the number of views in the usage pattern and many roadblocks in investigative analysis. That is because 'using a visual analytics tool' requires more than simply 'understanding what representations in visualizations mean.' We could identify that every single step in the entire cognitive process requires different aspects of knowledge and skills of a visual analytics tool. Therefore, a user should know what views are able to provide the information required to complete the task, and the user should be able to interact with the view. Instead, we found that a variation of pair analytics and opencoding analysis revealed the deeper cognitive process of using visualizations, so they can be used in many other visual analytics studies. We used the modified version of pair analytics to run this study. We found several advantages of this protocol over the 'think-aloud' protocol. Conversation between the experimenter and participants reveal how users actually think more easily. Since it is conversation, not like talking to oneself, participants tend to organize their thoughts more carefully before speaking about them. With some modifications, this method can also be used to identify some design-specific roadblocks for visual analytics tools. Thus, we recommend pairing a participant with an experimenter or another participant.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5">Potential Solutions</head><p>Based on the results, we established the following design suggestions to overcome roadblocks based on our findings. These suggestions are not meant to provide ultimate solutions but to suggest initial ideas to promote more discussion.</p><p>• R1</p><p>• Create a default view and let participants explore other views gradually as the Martini Glass Structure suggested <ref type="bibr" target="#b24">[25]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>•</head><p>The next views can be recommended by an automated selection mechanism like the "Show Me" function in Tableau <ref type="bibr" target="#b25">[26]</ref> until participants are able to select the appropriate views with full confidence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>• R2</head><p>• Foremost, the labels of buttons and menu items should be intuitively designed. One can simply ask a potential user what would be the most appropriate label for an interaction after the user thoroughly gets through the particular interaction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>•</head><p>An interactive and in-situ help tip could prompt where participants hover around. For example, when a user hovers a mouse cursor over the "Add All" button, a small help tip saying "Show all of the connections in the People column" could popup around the mouse cursor. Note that this help tip is tailored for the People column that the user interacts with, which clarifies what the interaction does.</p><p>• The idea of ScentedWidgets <ref type="bibr" target="#b26">[27]</ref> could be utilized. It provides visual navigation cues, which were created from the data, so that users can easily explore the data by following those cues. This similar approach can be used to provide visual interaction cues instead, which can result in the most probable and suitable interaction lists for users.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>• R3</head><p>• Many existing techniques (see <ref type="bibr" target="#b27">[28]</ref> for a taxonomy of such techniques) could be implemented to avoid visual clutter and confusion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>•</head><p>The interactive and in-situ help tip could be useful here as well. For example, when a user hover a mouse cursor over a number 20 next to the U-Haul entity, a help tip shows up and clarifies "U-Haul appears 20 times in all documents. 20 doesn't mean that U-Haul has 20 connections with other entities." • R4</p><p>• Design suggestion: An interface agent could play a role of the experimenter in this study to guide and reinforce the tool's capability. The mental model can be adapted to the existing views more easily if the agent can closely observe, track, and capture the mental model by the history of interaction and task failures and employ treatment immediately.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>•</head><p>Tutorial suggestion: Practicing on actual tasks while speaking about how views work in participant's own words could overcome the conflict between the mental model and the existing views earlier. We can adapt to P5's strategy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">CONCLUSIONS</head><p>In this study, we investigated the roadblocks that novice users face while they are conducting investigative analysis using a visual analytics tool. We found several roadblocks that exist in understanding task objective, choosing, using, and reading views properly. We also proposed a human cognitive model that describes the process of investigative analysis using a visual analytics tool. We also recommend using pair analytics to study more in-depth cognitive process in using visual analytics tools. However, to make the cognitive model fully useful for future studies, we need confirmation from actual investigative analysts. The main limitation of this study is that we used university students instead of investigative analysts as our experiment participants. As discussed by Pirolli and Card <ref type="bibr" target="#b11">[12]</ref>, expert analysts have expertise schemas built from expertise and experience, so that they can make sense of information and perform actions quickly. They also collect more relevant information more quickly than non-experts. University students hired for this experiment might have faced more analytic challenges, so they could meet unnecessary roadblocks more often. Another limitation is that we only used Jigsaw for this study, so some of roadblocks may look more prominent due to the peculiar design of Jigsaw. Even though these could be limitations in our study, it could also be an opportunity to compare the results between novice users and investigative analysts as well as between Jigsaw and other visual analytics systems in future studies.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>The ten views of Jigsaw used in this study. (Top row) Document, List, Document Cluster, Graph, Document Grid; (Bottom row) Calendar, Timeline, WordTree, Scatterplot, Circular Graph. Figures are captured from (http://www.cc.gatech.edu/gvu/ii/jigsaw/views.html).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>P5 mistakenly thought there was a line between two entities (top). P6 could not see clearly which entities are connected with which entities because of clutter in the List View (bottom).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc></figDesc><table><row><cell>Views \ Participants</cell><cell cols="6">P1 P2 P3 P4 P5 P6</cell><cell>Avg.</cell></row><row><cell>Circular Graph View</cell><cell>1</cell><cell>2</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>1.17</cell></row><row><cell>Graph View</cell><cell>2</cell><cell>2</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>1.33</cell></row><row><cell>Document View</cell><cell>1</cell><cell>2</cell><cell>2</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>1.33</cell></row><row><cell>Timeline View</cell><cell>1</cell><cell>3</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>1.33</cell></row><row><cell>List View</cell><cell>1</cell><cell>3</cell><cell>2</cell><cell>1</cell><cell>1</cell><cell>2</cell><cell>1.67</cell></row><row><cell>Document Cluster View</cell><cell>1</cell><cell>1</cell><cell>3</cell><cell>3</cell><cell>1</cell><cell>1</cell><cell>1.67</cell></row><row><cell>WordTree View</cell><cell>2</cell><cell>2</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>3</cell><cell>1.67</cell></row><row><cell>Calendar View</cell><cell>1</cell><cell>3</cell><cell>3</cell><cell>3</cell><cell>1</cell><cell>2</cell><cell>2.17</cell></row><row><cell>Document Grid View</cell><cell>2</cell><cell>4</cell><cell>3</cell><cell>2</cell><cell>1</cell><cell>2</cell><cell>2.33</cell></row><row><cell>Scatterplot View</cell><cell>3</cell><cell>4</cell><cell>3</cell><cell>1</cell><cell>1</cell><cell>2</cell><cell>2.33</cell></row></table><note>Difficulty ratings on the ten views of Jigsaw. The ratings were collected from 5-level Likert scale in the introduction session (1: Easy to use, self-explanatory, 2: Clear, possible to use, 3: Somewhat clear, hard to use, 4: Not clear, hard to use, and 5: To- tally incomprehensible). The rows are ordered by the average diffi- culty rating.</note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGEMENTS</head><p>This work is partially supported by a seed grant awarded by Visual Analytics for Command, Control, and Interoperability Environments (VACCINE) at Purdue University. We would also like to acknowledge gratitude to Linda T. Kaastra, who guided and supported the project throughout the entire process. We also thank John Stasko, Sung-Hee Kim, and all the reviewers for their excellent reviews that help in shaping the final version of this paper.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Evaluating visual analytics systems for investigative analysis: Deriving design principles from a case study</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Görg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">T</forename><surname>Stasko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">presented at the IEEE Symposium on Visual Analytics Science and Technology</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="139" to="146" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Stasko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Görg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Singhal</surname></persName>
		</author>
		<title level="m">Jigsaw: Supporting Investigative Analysis through Interactive Visualization,&quot; presented at the IEEE Symposium On Visual Analytics Science And Technology (VAST)</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="131" to="138" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Pnnl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Online</surname></persName>
		</author>
		<ptr target="http://in-spire.pnl.gov/" />
		<imprint>
			<date type="published" when="2011-03" />
			<biblScope unit="page">21</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Toward a Deeper Understanding of the Role of Interaction in Information Visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">S</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">T</forename><surname>Stasko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Jacko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1224" to="1231" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">A Framework of Interaction Costs in Information Visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1149" to="1156" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A Knowledge Task-Based Framework for Design and Evaluation of Information Visualizations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Amar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">T</forename><surname>Stasko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Symposium on Information Visualization</title>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="143" to="150" />
		</imprint>
	</monogr>
	<note>presented at the</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Distributed Cognition as a Theoretical Framework for Information Visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Nersessian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">T</forename><surname>Stasko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1173" to="1180" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Mental Models, Visual Reasoning and Interaction in Information Visualization: A Top-down Perspective</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">T</forename><surname>Stasko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="999" to="1008" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">The Shaping of Information by Visual Metaphors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Ziemkiewicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Kosara</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1269" to="1276" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Visual analytics for complex concepts using a human cognition model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">M</forename><surname>Green</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Ribarsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Fisher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">presented at the IEEE Symposium on Visual Analytics Science and Technology (VAST)</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="91" to="98" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">How Information Visualization Novices Construct Visualizations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Grammel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Tory</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Storey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="943" to="952" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
	<note>Visualization and Computer Graphics</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">The sensemaking process and leverage points for analyst technology as identified through cognitive task analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Pirolli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Card</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Intelligence Analysis</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Beyond Usability: Evaluation Aspects of Visual Analytic Environments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Scholtz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">presented at the IEEE Symposium on Visual Analytics Science And Technology (VAST)</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="145" to="150" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">An evaluation of microarray visualization tools for biological insight</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Saraiya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>North</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Duca</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Symposium on Information Visualization</title>
		<meeting>the IEEE Symposium on Information Visualization</meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Arias-Hernandez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">T</forename><surname>Kaastra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">M</forename><surname>Green</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Fisher</surname></persName>
		</author>
		<title level="m">Pair Analytics: Capturing Reasoning Processes in Collaborative Visual Analytics,&quot; presented at the Hawaii International Conference on System Sciences (HICSS)</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="1" to="10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Camtasia</surname></persName>
		</author>
		<ptr target="http://www.techsmith.com/camta-sia/" />
		<imprint>
			<date type="published" when="2011-03" />
			<biblScope unit="page">21</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Atlas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ti</surname></persName>
		</author>
		<idno>Ac- cessed: 23</idno>
		<ptr target="http://www.atlasti.com/" />
		<imprint>
			<date type="published" when="2011-03" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">The Eyes Have It: A Task by Data Type Taxonomy for Information Visualizations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Shneiderman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">presented at the IEEE Symposium on Visual Languages</title>
		<imprint>
			<date type="published" when="1996" />
			<biblScope unit="page">336</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Usability Analysis of Visual Programming Environments: A &apos;Cognitive Dimensions&apos; Framework</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">R G</forename><surname>Green</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Petre</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Visual Languages &amp; Computing</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="131" to="174" />
			<date type="published" when="1996-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Verbalizer-visualizer: A cognitive style dimension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Richardson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Mental Imagery</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="109" to="125" />
			<date type="published" when="1977" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Diagrams in the mind and in the world: Relations between internal and external visualizations,&quot; presented at the Diagrammatic Representation and Inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hegarty</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="1" to="13" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Human cognitive abilities: a survey of factoranalytic studies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">B</forename><surname>Carroll</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1993" />
			<publisher>Cambridge University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">A Theory of Graph Comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Pinker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Artificial intelligence and the future of testing</title>
		<imprint>
			<publisher>Psychology Press</publisher>
			<date type="published" when="1990" />
			<biblScope unit="page" from="73" to="126" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">CaMeRa: A computational model of multiple representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">J M</forename><surname>Tabachneck-Schijf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">M</forename><surname>Leonardo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">A</forename><surname>Simon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognitive Science</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="305" to="350" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Narrative Visualization: Telling Stories with Data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Segel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Heer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1139" to="1148" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
	<note>Visualization and Computer Graphics</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Show Me: Automatic Presentation for Visual Analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Mackinlay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Hanrahan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Stolte</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1137" to="1144" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Scented Widgets: Improving Navigation Cues with Embedded Visualizations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Willett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Heer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Agrawala</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1129" to="1136" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">A Taxonomy of Clutter Reduction for Information Visualisation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Ellis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Dix</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1216" to="1223" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
