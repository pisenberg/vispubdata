<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/pisenberg/grobid/grobid-0.6.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A Visual Navigation System for Querying Neural Stem Cell Imaging Data</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ishwar</forename><surname>Kulkarni</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shanaz</forename><forename type="middle">Y</forename><surname>Mistry</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brian</forename><surname>Cummings</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Department of Anatomy and Neurobiology</orgName>
								<orgName type="institution">University of California</orgName>
								<address>
									<settlement>Irvine</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gopi</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="department">IEEE Symposium on Visual Analytics Science and Technology October</orgName>
								<address>
									<addrLine>23 -28, Providence, Rhode Island</addrLine>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">A Visual Navigation System for Querying Neural Stem Cell Imaging Data</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2021-02-19T19:55+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Neuroscience</term>
					<term>stem cell segmentation</term>
					<term>tracking</term>
					<term>cell imaging</term>
					<term>data management</term>
					<term>visual analytics</term>
					<term>navigation</term>
					<term>exploration</term>
					<term>query processing</term>
				</keywords>
			</textClass>
			<abstract>
				<p>Cellular biology deals with studying the behavio r of cells. Current time-lapse imaging microscopes help us capture the progress of experiments at intervals that allow for understanding of the dynamic and kinematic behavior of the cells. On the other hand, these devices generate such massive amounts of data (250GB of data per experiment) that manual sieving of data to identify interesting patterns becomes virtually impossible. In this paper we propose an end-to-end system to analyze time-lapse images of the cultures of human neural stem cells (hNSC), that includes an image processing system to analyze the images to extract all the relevant geometric and statistical features within and between images, a database management system to manage and handle queries on the data, a visual analytic system to navigate through the data, and a visual query system to explore different relationships and correlations between the parameters. In each stage of the pipeline we make novel algorithmic and conceptual contributions, and the entire system design is motivated by many different yet unanswered exploratory questions pursued by our neurobiologist collaborators. With a few examples we show how such abstract biological queries can be analyzed and answered by our system.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Cellular biological experiments typically include culturing different types of cells in a controlled environment. Observation of such cultures includes observing the life processes of the cells for expected and unexpected developments among the cells. Earlier, images of these cultures were taken at distant time intervals to understand the start and end states of the experiment. Only a few characteristics like cell proliferation can be understood from these images. But experiments such as those concerning drug screening involve altering the conditions of the cultures to affect changes in dynamic responses of the cells. These responses of the cell can include metabolism, motility (motion), mutation, migration, proliferation rate and rate of apoptosis and other higher level details such as abnormal protein aggregation and cell-cell interaction. In order to observe these kinematic and dynamic properties of the cells, the images have to be taken often during the entire course of the experiment. Current confocal laser microscopes can take time-lapse images of the culture at a pre-determined frequency to enable such observations of dynamic responses. But, as a result, the amount of data produced by these devices is so massive (approximately 250GB of image and sensor data per experiment) that it is virtually impossible to manually sift through the data, track many cells, compute statistical quantities like area, speed etc., find conditions when various events happen, or identify patterns and correlations among patterns. Such information is used by neurobiologists to answer questions like how many cells undergo mitosis during a period of time; and to test hypothesis like whether the cell's metabolism decreases during division. Hence automation in terms of data processing, data management, visual interaction for navigating through the data, and querying the system for data exploration, are absolutely unavoidable for scientists to quickly frame and test their new hypotheses on various cellular behaviors. In this paper, we propose such an enabling system that opens up new frontiers for neuroscience research.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1">Main Contributions</head><p>We present an end-to-end system to automate different stages of the data capturing, management and usage in the context of experiments on human neural stem cells (hNSC). Following are the main contributions of the paper:</p><p>We present novel algorithms for image processing for cell identification, segmentation, and tracking. Our algorithm can also robustly find the boundary of the cells that enables accurate computation of other statistical parameters like area of the cell.</p><p>We propose a hybrid data representation, storage, and management technique that can handle statistical data, image data and semantic data. Our data management technique is specifically designed to provide fast query processing, efficient data integration for visualization, navigation, and exploration.</p><p>We provide data navigation techniques that take semantics of the data into account and enable the users with contextual responses and navigation. The visualization and navigation techniques involve the user in a tight feedback loop using context menus, tooltips and hyperlinked charts.</p><p>We introduce a new querying methodology that is designed based on the objects and attributes that are used in our application, and use set operations to explore patterns and correlations in the data.</p><p>In the course of the above process, we take the data through different levels of semantic abstraction for data visualization, correlation and hypothesis formulation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.2">Images and the Imaging System</head><p>Our imaging system uses Olympus VivaView Incubator Fluorescent Microscope. This system allows time-lapse imaging of cell cultures. It also captures images at different focal depths on the culture dish by illuminating the dish with four different laser wavelengths.</p><p>The cells in the images are human neural stem cells cultured in different media and substrates. The cells are 10-20µm in size on an average (excluding the branches). The images capture an area of 433.5µm × 330µm. The cells are marked with fluorescent proteins so that when an appropriate laser is used during imaging, only those cells are visible in the images, which would help in image processing for detecting and tracking these cells. In our experiments, we use Green Fluorescence Protein (GFP) that exhibits fluorescence when irradiated with light of wavelength 488nm. A typical experiment would have images taken at 2-10 minutes interval, and the experiment can run for one to two weeks. Experimental conditions can change in the middle -new media can be added, the CO 2 level or temperature can be changed, etc.</p><p>The captured images are 16-bit grayscale images of intensity values ranging from 0 to 4096 (12 bits of actual data). The images are of dimensions 1024×1344 pixels. A typical image is shown in 1 in <ref type="figure" target="#fig_0">Figure 2</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Related work in Segmentation and Tracking</head><p>The problem of cell segmentation has been worked upon for many years, and a large number of methods and techniques have been proposed. This is largely because cells are dynamic entities that vary widely in appearance and exhibit varied types of behavior, therefore methods developed for one type of cell are not applicable to other cell types.</p><p>A common approach for segmentation and tracking is using edge detection and morphological operators. Various combinations of these techniques are used in <ref type="bibr" target="#b0">[1]</ref> and <ref type="bibr" target="#b14">[15]</ref>, but for neural stem cells these methods do not always produce accurate results due to presence of edges with very low contrast.</p><p>Some techniques use the level-set segmentation method. This method used by <ref type="bibr" target="#b15">[16]</ref> with success on leukocytes, uses a zero-set of implicit energy functional, that traces a smooth boundary around cells. Another popular approach to cell segmentation is the Active Contour Model, proposed in <ref type="bibr" target="#b6">[7]</ref>. These models take a combination of cell features such as cell boundary, internal pixel values etc. and minimize energy to 'wrap' a contour around the cell. Due to lack of sharp contrast at boundaries and non-uniform shapes of neural stem cells, these methods do not produce satisfactory results with our images.</p><p>Model based segmentation methods are an important class of segmentation techniques that identify cells in images and image sequences based on certain well defined assumptions about spatial or temporal attributes of cells and their motion. Methods such as <ref type="bibr" target="#b18">[19]</ref> use size and shape based contours to identify cells. Methods such as the one proposed in <ref type="bibr" target="#b19">[20]</ref> use motion patterns on leukocytes in images of blood streams to identify cells.</p><p>The watershed approach is a commonly used segmentation technique and is the one we use as a step in our segmentation procedure. Our method is largely inspired from <ref type="bibr" target="#b22">[23]</ref> where the authors proposed a method of segmentation based on Ultimate Eroded Point. The method uses two erosion structures one for coarse and other for fine erosion successively. This method makes two assumptions: firstly the shape of structure for erosion captures the shape of the cells, and secondly, the topography of the cell image (or the height field) needs to be smooth enough for erosion to a single point to produce a seed.</p><p>Methods that track cells by shape matching predominantly use shape descriptors (proposed in <ref type="bibr" target="#b1">[2]</ref>). They represent shapes of cells as a number of binned histograms for each point on the outline of the shape and perform graph matching. This method is computationally expensive and also not suitable for highly concave shapes.</p><p>Our segmentation method is largely based on watershed algorithm. The problem with watershed generally comes in the form of under and over segmentation of a region, which is to be avoided if statistically correct segmentation is to be achieved. For this we used the technique of seed-point similar to the one suggested in <ref type="bibr" target="#b22">[23]</ref>. We produce the seed points using intensity maxima of an enhanced image while avoiding false detection, rather than UEPs as in that paper because cells in our image lack a shape to derive the eroding structure elements from. The method of segmentation is described more fully in Section 4.1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Related Work in Visual Analytics</head><p>Visual navigation plays an important role as the first step in data exploration and knowledge creation from large multi-dimensional data. Navigation refers to the process of traversal of the user view from one aspect or representation of data to another. Generally, the data collected from biological experiments is multi-modal: it consists of image data as collected from microscopes, textual data from annotation and numerical data from various measurements and calculations. Navigation of the data, thus helps the user correlate such modal data <ref type="bibr" target="#b4">[5]</ref>. In general Visual Analytics is the approach of combining visualization, human factors and data analysis <ref type="bibr" target="#b7">[8]</ref>.</p><p>An important aspect of any visualization and navigation system is the existence of the human element in the exploratory process. As stated in <ref type="bibr" target="#b8">[9]</ref>, the importance of data navigation and exploration comes from the vast repertoire of data created in short period of time by scientific experiments, using large computational power that is at our disposal. The author further states that the raison d'Être of such systems is not to find correlations in data (as <ref type="bibr" target="#b3">[4]</ref> does) but to represent the data in a fashion that the existence of correlations becomes apparent to the human user.</p><p>Applying visual data navigation and exploration techniques to biological data has seen interesting work such as <ref type="bibr" target="#b9">[10]</ref>. The authors developed MassVis, a system to analyze mass spectrometer data on protein complexes. Another important contribution in the direction of cell tracking visualization is <ref type="bibr" target="#b13">[14]</ref>, where the authors develop a single cell tracking visualization scheme seeCell. A similar tracking visualization method for dendritic cells in stream of microscopy images has been proposed in <ref type="bibr" target="#b21">[22]</ref>. We propose a system that not only tracks but also correlates the various attributes of the cell life processes. To the best of our knowledge our system is the first to have an end-to-end module that segments the cells, tracks their motion, identifies interesting events and represents the statistical and semantic data visually.</p><p>The work done by <ref type="bibr" target="#b17">[18]</ref> explores non-temporal data of breast cancer tumors. In this work, the raw data taken as input for the system is in the form of MRI scans and other 'raw' visual data, and the authors develop a system to extract the 3-Dimensional representation to present to user for exploration. Imaris <ref type="bibr" target="#b2">[3]</ref>, a commercially available software, works with grayscale cell images to segment and track cells. The segmentation is done via blob detection. The 4D data is analyzed by identifying 3D blobs that have sizes above a user provided threshold. Tracking in Imaris is done by associating cells in spatial neighborhood and by extent of overlap. 'Trails of cells' are provided to the user, who then corrects the mismatch, in contrast to our system, which performs matching based on generic shapes.</p><p>Successful visual data navigation and exploration systems generally employ a series of operations as proposed in <ref type="bibr" target="#b20">[21]</ref>. The author describes that a visual representation system first gives an overview, then allows for zooming into items of interest from such an overview, filters out irrelevant details and then provides details of the interesting items on demand. The author also expands the idea into exploration of patterns by representing correlation of datasets and maintaining history of actions (annotations) to extract patterns. This technique for visual representation of data is very widely acknowledged in literature as the mantra for a good representation of multi-dimensional data.</p><p>Another important feature of a good Visual Analytic system is allowing effective user queries. As far as user queries are concerned, <ref type="bibr" target="#b4">[5]</ref> provides a path querying system, where the user draws a desired path and a hyperlabel, which displays information on the objects found around the path. Our system on the other hand allows users to click on individual cells or select multiple cells based on which information pertaining to that cell or group of cells can be generated via a context menu.</p><p>The method proposed by <ref type="bibr" target="#b9">[10]</ref> provides users with the ability to customize their queries by providing them with drop downs and search boxes. In this case, the user has to manually pick what they wish to view. In our system, we propose hyperlinked charts, where <ref type="figure">Figure 1</ref>. Block diagram of the system. Our system gets the time lapse images of live cellular biology experiments from the microscope. From these images the segmentation and tracking module (in orange) extracts semantic and statistical information from these images. Such collected and computed data is efficiently stored, managed and accessed by the data storage and access module (in light gray). The user is provided with a set of effective visualization entities (in yellow) to pictorially see the data, while the navigation module (in purple) lets the user to visually traverse through the hierarchy of data and the attributes. Finally we also propose a query system (in blue) that the user can use to query the underlying database.</p><p>the user can just click on a plot to create a different image associated with the chosen point on the plot. We also allow the capability of drill-down plots, such that a new plot can be created in real-time when the user chooses on a range in a plot he is currently viewing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">SYSTEM OVERVIEW</head><p>An overview of the system is shown in <ref type="figure">Figure 1</ref>. The visual data from the microscope consists of raw images, void of any semantic information. Thus, segmentation of images is required to identify the parts of images that make up a cell and those that make up the background. Segmentation is a process of grouping pixels across boundaries of the cell as foreground and background. Similarly, tracking groups such identified regions of cells across time. As the images are time-lapse sequences of the snapshots of the state of cells, associating cells over time is important.</p><p>The information generated thus is stored in the database as statistical data related to cells, frames and experiments, and the semantic information is stored in flat files. The data present in the relational database, the image data and flat files are accessed by a central module called the consolidator, which uses the wrapper modules to access different types of data. Such a storage of hybrid data allows for easy and quick access. We have described this data storage and access system in Section 6. The consolidator also accesses image files using the Image Wrapper module. The consolidator essentially acts as an interface between the data storage and access module and the navigation, visualization and query modules described below.</p><p>In visual analytic systems there exists a loop between visualization and navigation which involves the user accessing and navigating the data through visual representations. This process iterated by a domain expert helps in the discovery of knowledge via hypothesis framing and validation. This tight-knit loop is shown in the visualization and navigation module in <ref type="figure">Figure 1</ref>. These actions of the user span a graph where the edges are formed by the actions for navigation initiated by the user and the vertices are the visualization entities. We describe this view for navigation and visualization in Section 7.</p><p>The validation of hypothesis also involves the user querying the system at a semantic level. In order to facilitate such an interaction with the system in terms of higher level semantics, we develop a query analysis subsystem depicted as such in the <ref type="figure">Figure 1</ref>. This type of interaction with the system requires storage and access of underlying data in a manner that can satisfy the requests for visualization and semantic queries. This query system has been described in detail in Section 8.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">SEGMENTATION AND TRACKING</head><p>In this section we describe the process of segmenting and tracking raw microscopy images to derive higher level semantic meaning from the images. This involves marking pixels that form the cell interior and the cell boundary (i.e. segmentation), matching cells between frames (i.e. tracking) and detecting interesting events in the cells. A detailed description of this process and how it differs from existing methods of segmentation and tracking has been given in our recently published work <ref type="bibr" target="#b12">[13]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Segmentation</head><p>Segmentation is the process of dividing the image into cell regions and background. We carry out the segmentation in two steps: robust cell center marking (identified by high brightness) and detection of the cell boundary (around the identified cell centers). The output of the first step is used in the second step. Robustness of detection of cell centers is an important criterion for determining the quality of segmentation. In order to identify the center of the cell, we first identify the regions that are certain to be cells with high confidence by performing a contrast enhancement operation. This gives a consistent high response within the core of cell and a low response to regions outside. We use convolution with the Difference of Gaussians (DoG) kernel as the contrast enhancement technique (2 in <ref type="figure" target="#fig_0">Figure 2</ref>). Difference of Gaussians is applied by convolving the original image with Gaussian kernels twice -once with large sigma and again with small sigma, then subtract the result of the latter from that of the former. This operation specifically, is invariant to local intensity variations that are common within a cell. The output of this operation is a bright region in the core of the cell. The boundaries of these bright regions are found by applying a few morphological operators, like dilation, erosion and open operations, to remove the effects of spurious intensity maximas, followed by edge detection (3 in <ref type="figure" target="#fig_0">Figure 2</ref>). The weighted centroid of that region, together with the intensity maxima gives the location of the cell. With cell centers correctly identified, accurate cell boundaries that encompass the whole cell, including the branches of the neurons, need to be identified. We use the watershed segmentation algorithm <ref type="bibr" target="#b16">[17]</ref> to split regions into as many cells as there are maxima points (cell centers). The Watershed algorithm considers the image as a height-field and partitions the image into regions of watershed -a partition refers to a region where, when water falls it flows to the same basin. The original image is complemented so that the high intensity cell centers become low intensity basins. A minima suppression operation is applied to remove noise, make the regions which are not part of the cell as plateaus, and remove over-segmentation. Then the watershed is applied to this image to partition it into multiple regions. The corresponding regions found which contain the cells are matched against cell centers. Every region (a basin in the watershed algorithm) which contains a cell center defines the entire extent of that cell (4 in <ref type="figure" target="#fig_0">Figure 2</ref>). This segmentation enables computation of cell parameters like the area of the cell, total florescent protein (GFP) content, and other static parameters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Tracking by Graph Matching</head><p>The goal of tracking is to match cells in one image to those in another ( <ref type="figure" target="#fig_1">Figure 3</ref>). We build a weighted graph with nodes as cells and edges between cells from two different images. The edge weights are computed as a function of different parameters including pixel overlap between the cells when the images are overlaid one over the other, difference in the cell area, difference in total brightness and Euclidean distance between their centroids in the pixel space.</p><p>Given this weighted graph, the graph matching that matches cells in adjacent frames is done using Hungarian Bipartite Matching <ref type="bibr" target="#b11">[12]</ref> which is enhanced to include dummy nodes that handle one-to-many matching arising due to mitosis. In the event of the mitosis only one of the daughter nodes is associated to the parent node in the previous frame, while the other daughter cell is left unassociated. The unassociated daughter cell will be very close to the parent cell in 'distance' and 'pixel-overlap' attributes. Such situations characterize the event of mitosis (cell division). The event of cell death is said to have occurred when the cell is possibly left unassocaited (because its GFP content will have decayed below threshold or it died and moved too fast as to avoid any association). Thus tracking implicitly allows for detection of important cell events. Tracking, in general, aids computation of further parameters like speed of the cell, and first order statistics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Event Detection</head><p>The detection of interesting events that occur in the lifetime of a cell is particularly useful to biologists who frame hypothesis on these events. Questions like which substrate enhances cell division or death can be answered by observing such events.</p><p>Cell Division or Mitosis is said to have occurred when a cell in an image captured at time t is invariably mapped to two different cells in the image at time t + ∆t, and each of the new cells differ greatly in area to the parent cell. Also, it can be noticed that the cell's total intensity just before mitosis equals the sum of cell intensities of the daughter cells. This is true because the brightness of the cell is proportional to GFP protein content of the cell, and when the cell undergoes mitosis the protein content is divided among its daughter cells.</p><p>Cell Death: When a cell suffers apoptosis in a culture, it loses its branches and floats away in the medium. This floating is similar to Brownian motion and has much higher velocity than the firmly rooted live cells. Thus, when a cell dies, the cell tracking algorithm usually returns no match. The best match will have a large distance from the cell in previous image. Statistically, we term this event as cell death. Thus, a cell death is also characterized by its swift mobility -when its speed is far greater than the average speed of the other cells.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Evaluation of results</head><p>We evaluated our system for its ability to segment images accurately. As <ref type="figure" target="#fig_0">Figure 2</ref> shows, the method clearly delineates the cells (including their branch like structures) and our neurobiologist collaborators were satisfied with the quality of segmentation. On the quantitative assessment side of our method for segmentation, comparison was made with the methods based on morphological operations (as described in <ref type="bibr" target="#b0">[1]</ref> and <ref type="bibr" target="#b14">[15]</ref>). The low contrast in our image were not apt for segmentation ( <ref type="figure" target="#fig_2">Figure 4</ref>), and were undersegmented. Similar results were found with MRF segmentation method. We tested our method by counting cells manually and tabulating them against the results found by the segmentation module. The results are summarized in the following table <ref type="table">(Table 1)</ref>. We can see that our module performs well across the image types (low, medium and high density of cells in the image). However, increase   The accuracy of tracking is directly affected by the temporal density of frames. Large time gaps between the snapshots generally lets cells change more in the unrecorded time, and this low rate of sampling of the state of cells causes the tracking to perform poorly. If a cell A in a frame at time t is associated with cell B in frame at time t + ∆t, such an association is labelled a 'mismatch', and if a cell at time t goes unmatched to any cell at time t + ∆t, we label it as 'missed'. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">SEMANTIC INTERPRETATION OF SPACE</head><p>Attaching semantic labels to syntactic data starts with classifying if a pixel in the input raw image belongs to a cell or not through the image segmentation process as described in the previous section.</p><p>Once the pixels are classified, they are labelled with an integer index denoting a specific cell. All pixels that have the same label collectively represent a semantic cell. Using this semantic interpretation, parameters like area of the cell, perimeter, total brightness and other physical parameters of the cell that may have biological meaning can be computed.</p><p>The second level of semantics comes from the time domain. A cell can move between two consecutive images taken at two different time instances. All the pixels belonging to these two corresponding cells, as identified by tracking, in these two frames are given the same label. Using this semantic labelling through time, parameters like speed of the cell, cell division (mitosis), cell death (apostosis), rate of change of area and other first derivative statistical data that have biological meaning can be computed.</p><p>In other words, images represent the two spatial dimensions and a stack of images collected over time represents the temporal dimension (refer to <ref type="figure" target="#fig_3">Figure 5</ref>). Cells, when they move in space over time, sweep a volume in this spatio-temporal space. A point inside this volume belongs to the cell, and those outside do not. Thus, every point in this spatio-temporal space has semantic meaning representing if it belongs to a particular cell or not.</p><p>The third level of semantics is a supplementary labeling of the points in this spatio-temporal space that defines an event. An event is an interesting phenomenon that occurs for a short period of time and usually is localized in space. For example, the events that we are interested in are cell divisions and cell deaths. These events are localized in the space in the neighborhood of the cells and can span a short time interval. Hence a point in this spatio-temporal space can have multiple semantic labels -those belonging to a cell and those belonging to an event. The above formalization provides us with a framework that allows data representation, data management, and query processing to be centered around these four semantic elements: experiments, frames, cells, and events. Data management can create a hierarchy of data using these elements, all computed parameters can be associated with one of the above four semantic elements, and the query system can provide mechanisms to explore these four elements.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">DATA MANAGEMENT</head><p>Following the segmentation and tracking, various statistical parameters of the cell and frame are computed including area, perimeter, speed of motion, and total brightness of every cell, number of cells in every frame, etc. Data management systems in the context of visual analysis do not only try to optimize storage and access, but also have to be designed to optimize the navigation, exploration, and query processing as demanded by a typical user.</p><p>There are two kinds of data used in our system -first is the data that is used only for visualization like the raw image data that does not have semantic meaning but only has indexing, and the second kind of data like the statistical and computed data that has semantic meaning and hence will be queried upon. The former is usually the output of sensors and is stored in its native formatfor example, the microscope output image is stored as image files (JPEG, TIFF, etc.). The computed data that has semantic meaning is stored in relational database management system (RDBMS) for ease in querying. But the efficiency of such RDBMS systems depends on the size of the data set. We improve the efficiency by identifying entropy reducing patterns in the computed data set using the following observation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Semantic Statistical Data:</head><p>For interactive visual analytics, fast and accurate data access is essential for unobstrusive interaction with the system. We use a relational database management system to store and query the computed, statistical data. The design of the RDBMS follows the application specific observation and needs of the data organization and query patterns. From the spatio-temporal analysis of our data set (Section 5) it is clear that the data can be classified in a hieararchical manner consisting of database tables for experiments, frames, cells, and events. The structure of the database is shown in <ref type="figure" target="#fig_4">Figure 6</ref>.</p><p>Semantic Partitions: Even within the computed data, there are special subsets of data that are all related to each other in the sense that all have the same semantic meaning and common usage-for example, after segmentation of the image, all collection of pixels belonging to the same cell will have the same semantic association, and all these pixels will be accessed and used together in any further querying or visualization. We call such data sets partitions. These 2D data sets, such as cell boundaries and cell-pixel association lists cannot be efficiently encoded in the form of a table in RDBMS. Further querying one data within a partition is equivalent to querying all data within the partition. So we store these individual partitions in different file formats -images or flat files, as is required by the nature of the data, and use meta links from the RDBMS systems to access the complete data.</p><p>These data in the flat files need to be formatted for use into the visual analytics system. For this, we have proposed the model of wrapper classes that read data from flat files, attach semantic meaning to the raw bytes and pass the information to the visual analytic system. This hybrid system of storing access information in RDBMS and lower (pixel) level details in flat files gives rise to an efficient data model that is also easy to implement. Further, such a system design can be queried on numerical data (statistical data) and answer visual (i.e. spatial) queries efficiently.</p><p>Semantic Images: The image data acquired from the microscopy system is a two dimensional spatial slice in the semantic space as described in Section 5. Visualization of images is achieved by first gathering the image data and attaching semantic meaning to the images from the data stored in partition files. The partition file consists of segmentation information in the form of pixel-cell association represented as image masks, also called as 'cell overlays'. The boundaries of the cells are stored as flat files as a sequence of (x,y) pixel coordinates. From an implementation point of view, our system has an image wrapper, which reads the image files, composes and formats them to show cell overlays and boundaries. The flat files are stored as length delimited array dumps, i.e. they contain raw bytes representing the lists of pixels prefixed with length of the following array and the identifier for the cell whose boundary is formed by that array. Caching and transfer from the hard disk is implemented using API buffers. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">VISUALIZATION AND NAVIGATION</head><p>As we have seen in the earlier sections, data used in our system exists at multiple levels of hierarchy like experiments, frames and cells and in multiple formats like image and statistical data. Visual representation of this data in a way that communicates the semantic meaning is termed as visualization. Using one form of data visualization to access other data through possibly different levels of hierarchy or different attributes is termed navigation. A visual analytics system integrates these two, so that a user can recognize patterns in the correlating parameters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1">Visualization Entities</head><p>The goal of a successful visualization system is to allow easy cognition. A user must be able to derive certain meaning from the visual representation of raw data. As human perception is tuned to finding relations, providing visualization methods that allow for easy projection of such inter-relation is the key to good analytics. Data in our system can be categorized into two formats -raw data including the microscopy images that serve as the input to the system, and semantic or statistical data like attributes of a cells and events, which are derived from processing the input data. Our visualization entities should handle data of these formats. Further, since the input images are time-lapse images, our visualization system should also handle dynamic and kinematic properties of various objects.</p><p>Using the above mentioned classification, our system presents the following visualization entities: Frame Animation: In order to provide users with the ability to visualize time-lapse data sets, for example, how cells change or move across time, we present an Image Animator <ref type="figure" target="#fig_5">(Figure 7)</ref>, which is a time-delayed sequence of images that the user can interact with. This sequential display of images is essentially the slicing of the 3D space described in Section 5. The user can select (multiple) cells to visualize their motion in time in a new animation frame. Animations are a natural visualization mechanism to show 2D time-lapse data.</p><p>Visualization Charts: Statistical data in our system is predominantly time-varying. Line charts (as in <ref type="figure" target="#fig_5">Figure 7)</ref> are widely regarded as a good visualization technique for 1D time-varying data <ref type="bibr" target="#b5">[6]</ref>. We have also provided the functionality by which a user can view multiple attributes at the same time using multi-line charts (as in <ref type="figure" target="#fig_5">Figure 7</ref>). Through such visualization techniques, the user can easily correlate different time-varying data. Further, we also label the charts at appropriate time instances with events in order to show further correlation between events and statistical parameters ( <ref type="figure" target="#fig_5">Figure 7</ref>).</p><p>Tabular View: The tabular view is an alternative visualization method for statistical data, and is considered the best presentation technique when precise information about the data is required (as in <ref type="bibr" target="#b5">[6]</ref>). We present the user with numerical data in a tabular form on demand <ref type="figure" target="#fig_5">(Figure 7</ref>). The tabular representation of data allows a user direct visualization of the parameters associated with one or more cells.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2">Navigational Entities</head><p>Navigation is described as the process of moving between one visual representation of the data to another through user interaction with the purpose of finding patterns in the data. An efficient navigation system unobtrusively and interactively fetches, composes and formats the data to present the next view of the data being analyzed. The general principle of a visual analytics system is to present data that is essential for understanding of patterns etc., in the most uncluttered manner with the concept of 'details on demand'. This principle ensures that the user is not overwhelmed with the numerical or otherwise highly precise data when he is simply looking for an abstract view of the model. Further the navigation process requires that the visualization entities be cognizant of the semantic meaning of the entities being displayed. In our system we attach semantic meaning to the display primitives using data entities like cell masks through which every pixel of the image is aware of the cell it belongs to. This allows us to query the attached statistical parameters of the cells when the user interacts with the pixel.</p><p>There are two types of navigational data in our system -hierarchical data and attribute data. The hierarchical data, as represented in the RDBMS (Section 6), has four levels including experiments, frames, cells, and events. The attribute data defines the attributes of each of the objects in the above hierarchical levels. The system should be able to navigate to each level in the hierarchy as well as the attributes contained in each level. In order to navigate through the hierarchy we use two navigational entities, namely contextual menus and hyperlinks in charts. In order to navigate among attributes, we use ToolTips. Contextual Menus: Contextual menus offer a set of navigation choices based on the current state of the system. Normally, the menu of choices corresponding to the selected object on which the contextual menu is invoked is generated on-the-fly. This gives a precise framework to implement navigation through the hierarchical data. One set of contextual menus has been implemented at the frame level, where a user can click on a cell or multiple cells to visualize information pertaining to the selected cells <ref type="figure" target="#fig_6">(Figure 8)</ref>. The second set is at the visualization chart level where a user can select a time instant or a range and view an aggregated information related to the selected time frame. For example, a user can right click on any cell and view the average area of the cell using the context menu. Hyperlinks in Charts: Using hyperlinked charts, a user can navigate from a chart that describes one or more time-varying attributes of a cell, to a specific frame just by choosing a point in the chart at that corresponding time instance. This then links to frame animations where the new image animator starts from the selected point in time. Thus hyperlinked charts provide users with the ability to navigate up the data structure hierarchy. The user can also select a time range on the chart and use the context menu to either generate cell statistics for that time range or drill down further into a new line chart which represents different cell parameters over the selected time range. This concept is also termed as zooming in <ref type="bibr" target="#b10">[11]</ref>. This new chart or animation can further interactively lead to other part of data and types of visualization thus providing inter navigability between the multiple modes of visualization. For example, a user can click on the Mitosis tag in the chart <ref type="figure" target="#fig_5">(Figure 7</ref>, center) and view the image where the cell undergoes mitosis. Tool-Tips: A tooltip is an element in which when the user places the cursor at a particular visualized object and a small hover box displays information about the object. We extend the concept of tooltips by making them contextual in nature. In our system, when a user hovers the cursor over a cell, information about that cell such as when it divides, its area in the current frame, etc. are shown in the hover box <ref type="figure" target="#fig_6">(Figure 8)</ref>, while when the cursor is over a chart, parameters like the time and the value are shown. This requires quick fetching of data for formatting and display which is made possible by our hybrid data storage described in Section 6.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">SEMANTIC QUERYING</head><p>An effective visual analytic system should not only be capable of representing and visualizing multi-modal data on request, it should also be capable of aggregating data to solve queries asked at abstract semantic level. The responses to these queries are generally required to be generated on the fly and thus elicit a conversion between the semantic queries to the low level queries that derive data from the data store.</p><p>In that direction, here we propose a model of querying language suited specifically for querying the large database of images, its semantics and the statistical data associated with the entities, all related to the cellular experimental data in neuroscience.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.1">Query Space Formulation</head><p>We observe that the queries are typically related to the objectsframes, cells, and events, and their attributes. We assign unique integer ids to frames, cells, and events. The query space can now be thought of as an integer grid of the three dimensional space spanned by the frames, cells and events axes. A discrete point P i, j,k exists in this space if there is an event k associated with cell j in frame i, <ref type="figure" target="#fig_8">(Figure 9, top)</ref>. A scenario with no event is tagged with a special event with id 0, <ref type="figure" target="#fig_8">Figure 9</ref>, bottom. In this formulation, the cellframe plane (with event id 0) shows the life of the cells through time except the points where events happen. Many biological queries can be answered by finding the points in a subspace of this 3D space. The formulation of such queries starts with specifying a subset in each dimension and computing the space resulting through union or intersection of these subsets.</p><p>For example, let the frame-subset S f be subsets of frames that are of interest in frame axis. Similarly let S c and S e denote the subsets of interest in the cell and event axes. Then the points in the union or intersection of these subspaces are returned respectively by the query functions</p><formula xml:id="formula_0">EVAL UNION(S f , S c , S e ) = {P i, j,k |(i ∈ S f ) ∨ ( j ∈ S c ) ∨ (k ∈ S e )} EVAL INTER(S f , S c , S e ) = {P i, j,k |(i ∈ S f ) ∧ ( j ∈ S c ) ∧ (k ∈ S e )}</formula><p>Pictorial illustrations of these operations are shown in <ref type="figure" target="#fig_9">Figure 10</ref>. We can extract the indices of just one of the axes -frames, cells, or events, by projecting the resulting points in the appropriate axes. Such a projection can be achieved by a simple type casting syntax. For example, the set of all cell indices T c of a point set P is given by: T c = (cell)P = { j|P i, j,k ∈ P}. Such type casting can be used, not only to get the indices of the objects, but also to get the attributes of the objects. The union, intersection and set difference queries along the same dimension are addressed using stand-alone set-operation functions.</p><p>For example, if S c and T c denote two sets of cell indices, then their union, intersection and differences can respectively be computed using the function:</p><formula xml:id="formula_1">SET UNION(S c , T c ) = {P i, j,k |( j ∈ S c ) ∨ ( j ∈ T c )} SET INTER(S c , T c ) = {P i, j,k |( j ∈ S c ) ∧ ( j ∈ T c )} SET DIFF(S c , T c ) = {P i, j,k |( j ∈ S c ) ∧ ( j / ∈ T c )}</formula><p>Similarly sets on frames and events will work with indices i and k. Many biologically relevant queries can be converted to these basic abstract query functions, and can be a powerful tool for hypothesis framing and hypothesis testing by the biologists.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.2">Query Example</head><p>In this section we show how the theory of queries as formulated in the preceding sub section can be used to evaluate simple biologically relevant queries. To calculate the average area of a cell c within a range of frames f 1 to f 2 , the query sequence will look as follows: Let F = { f 1 , . . . , f 2 }, and U be the universal set in that particular domain. Set of all query points that belongs to cell c between the range of frames is given by,</p><formula xml:id="formula_2">P = EVAL INTER(F, {c}, U)</formula><p>The set of all areas of c in the given frame range is A s = (area)P, and the average area is given by A = average(A s ).</p><p>As a second example, let us find the set of all cells in which each cell undergoes both mitosis (cell divisions) and apostosis (cell deaths) in a given time interval (frame range). Note that mitosis and apostosis are event attributes, and can be used as a type casting, similar to area on a set of query points, to return a set of events that are of given type.</p><p>Let F be the set of all frames that are of interest. Let E m and E a be the set of events within the frame range of interest F that are labelled mitosis and apostosis respectively.   Let C m and C a be the set of cells that undergo mitosis and apostosis respectively within the frame range of interest. So,</p><formula xml:id="formula_3">C m = (cell)(EVAL INTER(F, U, E m )) C a = (cell)(EVAL INTER(F, U, E a ))</formula><p>Finally, set of all cells in which each cell undergoes both mitosis and apostosis is given by,</p><formula xml:id="formula_4">C res = SET INTER(C m ,C a )</formula><p>Similarly many simple yet biologically significant queries can be answered by our query system. But there are complex queries that need lists data structure instead of sets. Further, nested structures like list of lists and sets of sets become important while computing functions like 'average area of each of the cells in a range of frames' that would return a list of numbers instead of a single number. We will strengthen our query system to handle such complex data structures and queryies, and implement the relevant access functions.</p><p>In our current implementation, we have provided a limited querying capability that would implement aggregate functions like count, average, stddev and the set function, EVAL INTER, on three dimensions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9">EVALUATION OF OUR SYSTEM</head><p>The system, being an end to end pipeline, helps neurobiologists perform experiments and analyze the results. The proposed visualization and querying methods help them derive higher level biologically relevant knowledge from experiments. For example, one biologically important statistical pattern that the biologists observed using our system is that when a cell is about to undergo mitosis, it contracts, loses its branches and it's protein content aggregates. It can be seen from the chart in <ref type="figure" target="#fig_5">Figure 7</ref>, that at the time of mitosis (marked by M), the area of the cell shrinks rapidly. From our system, the biologists also noticed the decrease in cell metabolism in terms of GFP content and production just before, during and just after mitosis, as seen in the chart in <ref type="figure" target="#fig_5">Figure 7</ref>. Our collaborators could assess the time required for the the rate of GFP production to return to normal, accurately. Such discoveries of cellular behavior will be later used in other experiments to control cell divisions, mobility, metabolism and other processes.</p><p>Our neurobiologist collaborators enjoyed using the system and its fluidity in navigation through different data representations. They could visually corroborate the hypotheses and surmises that they had about the cell activities. Currently the query system is limited to what could be achieved through pull-down menus. A more powerful querying system will enable much more involved interaction of the users with the system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="10">FUTURE WORK</head><p>The modular design of our system allows for it to be modified in multiple ways to achieve scalability in functionality. In stem cell research itself, a type of analysis that biologists perform is fate analysis, where they analyze what the fate of a stem cell is. Stem cells change via the process of mitosis and metabolism, and finally become specific cellular tissue (like neurons or skin cells). It is useful to identify which stem cell ended up as a particular type of cell and whether the initial stem cell could actually produce multiple types of tissue. The segmentation and tracking module could be changed to allow identification of different types of cells based on their fluorescence under different conditions. From the data provided by the segmentation and tracking module, the visual analytics system can be extended to provide graphs that allow the user to see how different cells change thus allowing them to perform fate analysis.</p><p>We can also extend the existing system to allow recognition of cells other than the stem cells. The visual analytics system as it exists currently can take in such multi-cellular data and save them as different experiments. Due to our modular design, our system can be used in a different lab setup with very minor changes to only the Segmentation and Tracking parameters.</p><p>The current query system can be extended to provide higher level queries. A more formal representation of the query language can allow for a wider range of biological queries to be answered. Further, we are also working on visual query system that is as powerful as a textual query system. All the above mentioned extensions can allow for a robust Visual Analytic system that can provide immense analytical capability to cellular biologists.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="11">CONCLUSION</head><p>In this paper, we explore the methods and implementation of a visual analytics system for biological data. We have developed methods of segmentation and tracking of human neural stem cells and built a visual analytical system of the data collected from such a tracking system while giving importance to ease of use of visualization and intuitive navigation. We have also developed an interpretation of the spatio-temporal space in order to explore the possibility of querying the system for regions of interest in such a space. We demonstrate the capability of the querying language by phrasing biologically relevant queries in abstract form. Such an interpretation also requires a fast access to layered and hierarchical data which is enabled by our hybrid data management model that satisfies the requirement of interactivity of the visualization system and the requirement of precision of a query system.</p><p>In essence, we have an end-to-end system that acquires image data, demarcates the semantic entities, provides visualization of the dynamics of those entities and allows users to navigate between many visualization entities, and finally gives a framework for solving many biologically relevant queries.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 .</head><label>2</label><figDesc>Segmentation: Clockwise from Top-Left: 1. Original Image, 2. Image after DoG contrast enhancement, 3. Cell centers and cell regions (after some morphological operations), 4. Final image after watershed.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 .</head><label>3</label><figDesc>Tracking: Clockwise from Top-Left : Cell at time 1, Cell at time 15, Cell at time 25, Cell at time 46</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4 .</head><label>4</label><figDesc>This gives the result of segmentation of our images using various techniques. The image on the left is result of segmentation with morphological operations described in<ref type="bibr" target="#b0">[1]</ref>. Image in the middle is the original image. The last image is MRF segmentation with manual initialization in density of cells cause some branches to overlap giving false positives in cell center identification, causing over-segmentation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 5 .</head><label>5</label><figDesc>This image shows different semantic labels of the space using an actual data collected during an experiment. The entire 3D spatio-temporal space defines an experiment, a slice in the time domain defines a frame, the swept volume as shown in the figure defines a cell, the event is shown as a split in the swept volume.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 6 .</head><label>6</label><figDesc>Entity-Relationship Diagram of the Database.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 7 .</head><label>7</label><figDesc>Visualization Entities: Tabular representation, Charts (showing how area and GFP content of a cell changes over time and a Mitosis event labelled M), Frame animation</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 8 .</head><label>8</label><figDesc>Navigational Entities: Tooltips and context menus.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head></head><label></label><figDesc>For example, the set of areas of the cells A c of the query point set P is given by A c = (area)P = {cell[ j][i].area|P i, j,k ∈ P}, where cell[ j][i].area gives the area of cell j at frame i. Specifically, we use multisets to allow repetition of values in the set which would enable easy computation of statistics on the values such as average and standard deviation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 9 .</head><label>9</label><figDesc>The Query space. The figure on top shows the three dimensional space spanned by cells, time and events. Each dot (green or orange) describes an event for cells with respective 'cell ids'. The bottom figure shows the cell-time plane of no event, (event id = 0), which represents the life line of cells.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 10 .</head><label>10</label><figDesc>Left to Right, Illustration of EVAL INTER, EVAL UNION, SET INTER and SET UNION.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head></head><label></label><figDesc>E m = (mitosis)(EVAL INTER(F, U, U)) E a = (apostosis)(EVAL INTER(F, U, U))</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2</head><label>2</label><figDesc>summarizes the results in tracking sub-system.</figDesc><table><row><cell>Cell's trail length in</cell><cell cols="2">Total number of</cell><cell>Average</cell><cell>missed</cell></row><row><cell>frames</cell><cell>mismatched</cell><cell>cell</cell><cell cols="2">cells per frame</cell></row><row><cell></cell><cell>pairs</cell><cell></cell><cell></cell></row><row><cell>0-5</cell><cell cols="3">(Missed all, debris) NA</cell></row><row><cell>5-10</cell><cell>None</cell><cell></cell><cell>NA</cell></row><row><cell>10-15</cell><cell>None</cell><cell></cell><cell>NA</cell></row><row><cell>15-20</cell><cell>4</cell><cell></cell><cell>1.25</cell></row><row><cell>20-25</cell><cell>7</cell><cell></cell><cell>1.75</cell></row><row><cell>25-30</cell><cell>6</cell><cell></cell><cell>1.2</cell></row><row><cell>30-50</cell><cell>39</cell><cell></cell><cell>1.95</cell></row></table><note>Table 2. Tracking results: Time delay 20 min</note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Cell segmentation with median filter and mathematical morphology operation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Anoraganingrum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of International Conference on Image Analysis and Processing</title>
		<meeting>International Conference on Image Analysis and Processing</meeting>
		<imprint>
			<date type="published" when="1999" />
			<biblScope unit="page" from="1043" to="1046" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Shape matching and object recognition using shape contexts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Belongie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Puzicha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="509" to="522" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<ptr target="http://www.bitplane.com/go/products/imaris" />
		<title level="m">Bitplane Scientific Software. Imaris: 3d and 4d real-time interactive data visualization</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Unsupervised pattern recognition: an introduction to the whys and wherefores of clustering microarray data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">C</forename><surname>Boutros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">B</forename><surname>Okey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Briefings in bioinformatics</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="331" to="343" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Braingazer-visual queries for neurobiology research</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bruckner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Solteszova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">E</forename><surname>Groller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hladuvka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Buhler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">Y</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">J</forename><surname>Dickson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1497" to="1504" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Improve Your Vision and Expand Your Mind with Visual Analytics. Perceptual Edge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Few</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Snakes: Active contour models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kass</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Witkin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Terzopoulos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="321" to="331" />
			<date type="published" when="1988" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Keim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Mansmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schneidewind</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ziegler</surname></persName>
		</author>
		<title level="m">Visual analytics: Scope and challenges. Visual Data Mining</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="76" to="90" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Information visualization and visual data mining</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename><surname>Keim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="8" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Massvis: Visual analysis of protein complexes using mass spectrometry</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Kincaid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Dejgaard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Symposium on Visual Analytics Science and Technology</title>
		<meeting>the IEEE Symposium on Visual Analytics Science and Technology</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="163" to="170" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Glossary of terms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Kohavi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Provost</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning</title>
		<imprint>
			<date type="published" when="1998" />
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="271" to="274" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">The hungarian method for the assignment problem</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">W</forename><surname>Kuhn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Naval research logistics quarterly</title>
		<imprint>
			<date type="published" when="1955" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="83" to="97" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Robust segmentation and tracking of generic shapes of neurostem cells</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Kulkarni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Mukherjee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Sontag</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Cummings</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gopi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Symposium on Healthcare Informatics, Imaging, and Systems Biology</title>
		<meeting>the IEEE Symposium on Healthcare Informatics, Imaging, and Systems Biology</meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Visualization and tracking dedicated to cell analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Mange</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>De Heras Ciechomski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Swartz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Innovations in Information Technology</title>
		<meeting>the International Conference on Innovations in Information Technology</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="707" to="711" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Morphological segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Meyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Beucher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of visual communication and image representation</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="21" to="46" />
			<date type="published" when="1990" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Level set analysis for leukocyte detection and tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Mukherjee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Ray</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">T</forename><surname>Acton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="562" to="572" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Watershed of a continuous function</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Najman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Schmitt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Signal Processing</title>
		<imprint>
			<date type="published" when="1994" />
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="page" from="99" to="112" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">A visual analytics system for breast tumor evaluation. Analytical and quantitative cytology and histology/the International Academy of Cytology</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Petushi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Marker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Breen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">U</forename><surname>Garcia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">American Society of Cytology</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page">279</biblScope>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Tracking leukocytes in vivo with shape and size constrained active contours</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Ray</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">T</forename><surname>Acton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Ley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Medical Imaging</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1222" to="1235" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Automatic extraction and measurement of leukocyte motion in microvessels using spatiotemporal image analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Sato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">A</forename><surname>Zoroofi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Harada</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Tamura</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Shiga</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Biomedical Engineering</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="225" to="236" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">The eyes have it: A task by data type taxonomy for information visualizations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Shneiderman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Symposium on Visual Languages</title>
		<meeting>the IEEE Symposium on Visual Languages</meeting>
		<imprint>
			<date type="published" when="1996" />
			<biblScope unit="page" from="336" to="343" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Intuitive visualization and querying of cell motion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Souvenir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kraftchick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Shin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Visual Computing</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="1061" to="1070" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Nuclei segmentation using markercontrolled watershed, tracking using mean-shift, and kalman filter in time-lapse microscopy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Circuits and Systems I: Regular Papers</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2405" to="2414" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
