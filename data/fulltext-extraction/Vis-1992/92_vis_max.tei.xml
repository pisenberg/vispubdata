<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/pisenberg/grobid/grobid-0.6.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Visualizing Wind Velocities by Advecting Cloud Textures</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nelson</forename><surname>Max</surname></persName>
							<email>max2@llnl.gov</email>
							<affiliation key="aff0">
								<orgName type="institution">Dean Williams Lawrence Livennore National Laboratory Livermore</orgName>
								<address>
									<postCode>9455</postCode>
									<region>California</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roger</forename><surname>Crawfis</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Dean Williams Lawrence Livennore National Laboratory Livermore</orgName>
								<address>
									<postCode>9455</postCode>
									<region>California</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">O</forename><surname>Box</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Dean Williams Lawrence Livennore National Laboratory Livermore</orgName>
								<address>
									<postCode>9455</postCode>
									<region>California</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Visualizing Wind Velocities by Advecting Cloud Textures</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2021-02-19T20:28+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>advection</term>
					<term>3-0 texture</term>
					<term>volume visualization</term>
					<term>vectorjeld</term>
					<term>wind</term>
					<term>clouds</term>
					<term>climate modeling</term>
				</keywords>
			</textClass>
			<abstract>
				<p>In order to visualize both clouds and wind in climate simulations, we have rendered clouds using a 3-0 texture which is advected by the windjlow.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Introduction</head><p>The Program for Climate Model Diagnosis and Intercomparison at Lawrence Livermore National Laboratory (LLNL) is comparing different climate models which give differing predictions of global warming. Clouds have a significant influence on global temperatures, because they reflect the short wave radiation from the sun, and also absorb and reflect the longer wave radiation re-emitted by the earth. It is not certain which of these effects is larger, hence the influence of clouds is an open research problem. Clouds are the least understood aspect of climate models; it is not even known whether global warming will cause an increase in cloudiness. Cloud response to climate perturbations has the capability to magnify the climate change or to reduce its severity.</p><p>Visualization is an important tool for analyzing and understanding climate simulation output, and we have developed algorithms for visualizing scalar climate data, including cloud density. It is also important to visualize wind velocity, which is a vector field. When a time sequence of cloud data is viewed in animation, motion of the cloud density gives information about the prevailing winds. However there are conditions, for example at the leeward side of a mountain range, where clouds sit in a standing wave. The wind blows air through the cloud region, with moisture condensing at one side and evaporating at the other. Thus the motion of overall cloud density does not give any indication of the wind velocity for this case.</p><p>We have therefore added texture to the clouds, using the method of <ref type="bibr">Gardner [4]</ref>, and advected the texture with the wind. We used a 3-D volume texture, defined as a function of texture coordinates (u,v,w) and evaluated on a contour sur-face of cloud density. The three texture coordinates are advected according to the wind, meaning that the texture coordinates assigned at the beginning of the simulation are carried along by the wind flow. This will cause the cloud textures in turn to move with the wind. In addition to helping visualize the wind, the resulting realistic cloud textures will aid in portraying climate modeling research results to the general public.</p><p>Other work by <ref type="bibr">Helman and Hesselink [61,</ref><ref type="bibr">and Globus et al. [SI,</ref><ref type="bibr">shows singularities</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>The simulation</head><p>The climate simulation was run on a Cray 2 at the National Energy Research Supercomputer Center at LLNL. The computational grid was defined by 320 evenly spaced longitudes, 160 unevenly spaced latitudes, and 19 unevenly spaced vertical levels. This results in nearly a million grid points. The surfaces of constant vertical level were not at constant altitude, but curved over the mountains, so that the bottom level corresponds to the height of the terrain.</p><p>The partial differential equations for weather propagation were solved in the spatial frequency domain, and the resulting spherical harmonic expansions of the climate variables were sampled at the computational grid. The solver only output the requested data variables at one hour intervals, and we interpolated this output to produce animation frames every fifteen minutes.</p><p>Among the variables which can be output are temperature, pressure, humidity, wind velocity, short wave and long wave radiation, and cloud density. Since the grid cells are 1.125 degrees on a side, or about 100 kilometers square at the equator, the cloud density variable does not represent the density within individual clouds, but rather the percent cloud cover at a particular altitude level. The cloud rendering method of <ref type="bibr">Gardner [4]</ref> creates transparency where the texture function is below a threshold, and can thus create partial cloud cover detail within a single grid element. It therefore gives a more faithful representation of the meaning of the cloud density variable in the simulation than does the direct volume rendering in</p><formula xml:id="formula_0">Max [Q].</formula><p>We found that when the original cloud density from the simulation was contoured, the surface was too rough and bumpy, as in figure 1. Therefore we applied a 3 x 3~3 smoothing kemel to the density before contouring, giving figure 2. The corresponding textured clouds are shown in figure 3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Rendering</head><p>The volume rendering system described in Max et al.</p><p>[8] was enhanced to include the cloud texture. This system composites in back-to-front order both volume cells with density, and semi-transparent contour surface polygons. When a volume cell is intersected by a contour surface, it is split into two pieces, so that one piece can be composited before the surface, and one after. Details of the general back-to-front sorting algorithm are given in <ref type="bibr">Max [9]</ref>, together with a particular adaptation to our climate model geometry.</p><p>The 3-D texture coordinates (u,v,w) range from 0 to 1, and are initialized proportional to longitude, latitude, and altitude, respectively. The longitude wraps around at the Greenwich meridian, which corresponds to both U = 0 and U = 1. The next section explains how these texture coordinates are advected by the wind to produce, for each frame of the animation, new (u,v,w) coordinates at each of the grid vertices. Once these are known, they can be interpolated across grid edges to the vertices of a contour polygon, and then across the polygon during scan conversion, texturing, and shading. As in Gardner 141 and Max [71, we generated a "poor man's fractal texture" as a sum of a small number of 3-D plane sine waves. As suggested by Gardner, we perturbed the phase of each of these waves by another sine wave of longer wavelength in a perpendicular direction, to break up the regularity in the texture pattem. The texture function is thus of the form</p><formula xml:id="formula_1">f( U, U, w ) = aicos ( b p + civ + diw + 4,)</formula><p>where the phase perturbation is</p><formula xml:id="formula_2">qi = 2 -sin (0.56,~ -0 . 5~~~)</formula><p>Gardner's texture function was rendered only on the front-facing surfaces of the ellipsoids. It was used for opacity as well as for shading, with the cloud becoming completely transparent when the function decreases below a threshold. To make the clouds become transparent at the edges of his ellipsoidal cloud volumes, Gardner set the basic transparency threshold so that the functionf(u,v,w) was almost always below it, and decreased the threshold proportional to the length of the viewing ray inside the ellipsoid, to give more opacity to the thicker regions. Since our surface polygons are sorted from back to front, we can do an equivalent computation on our contour surfaces, using a z-buffer. When an opaque terrain polygon or a back-facing contour polygon is scan converted, the z-buffer is set to the polygon's depth at each pixel. Then when a frontfacing contour polygon is rendered, its depth can be subtracted from the depth in the z-buffer to get the length of the viewing ray inside the volume bounded by the contour surface.</p><p>The texture is drawn on the front-facing polygons of the contour surface where the interpolated cloud density takes a specified value, for example, 15% cloud cover in the figures shown here. But points inside the contour surface could have a much larger value, up to 100%. We can visualize the full volume density inside the surface with the texturing technique if we use the integral of the density along the ray segment to modify the 3-D transparency threshold, instead of using just the segment length, as in figure 3. One method of approximating this integral is to sample densities along the ray, interpolated from the grid vertex densities. However it can be computed much more efficiently with the system of Max et al.</p><p>[8], by scan converting both the volume cells and the contour polygons in back-to-front order. For densities which are linearly interpolated along viewing rays, the density integral along the segment of a ray in a cell is just the length of the segment, multiplied by the average of the two densities at the segment's endpoints. We accumulate the integrated density into a raster density buffer. The buffer is initially set to zero, and is incremented as each volume cell inside the contour is scan converted. (Cells outside the contour surface, with densities less than the contour value, are skipped. Since these cells are usually in the majority, this saves a lot of time.) When a front-facing contour polygon is scan converted, the accumulated density is used to modify the transparency threshold, and the buffer is reset to zero. <ref type="figure">Figure 4</ref> was produced in this way.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Advection of texture coordinates</head><p>It is difficult to represent contour surfaces as parametrized surfaces, since their position, shape, and topology change from frame to frame in an animation. Therefore we used a 3-D volume texture. When the surfaces change and deform, we wanted this texture to follow along. Wyvill et al. [lo1 have implemented such a deforming texture for "soft object" contour surfaces of a density which is the sum of density clouds centered at "key points", but their method does not work for more general functions. Two films in the Siggraph '91 Film and Video Show, "Festival" by Kawaguchi and "Lost Animals" by NHK HDKG New York, also put texture on deforming soft objects, by dissolving between separate textures for each key point, but the result looks a little strange on their overlap, especially when the key points move.</p><p>The best way we discovered to create a texture which would move appropriately as our clouds deformed in the wind, was to advect the cloud texture coordinates by the wind. When the cloud surface is being pushed by the wind, the texture and geometry will move coherently, while in a standing wave at a mountain range, the texture will move across the cloud, indicating the wind velocity. However when a cloud grows quickly as in a thunderstorm, or in the daily rain cycle over the Amazon rainforest, it will spread through the 3-D texture space, causing a "boiling" appearance.</p><p>Initially, in frame 1 of an animation, the three texture coordinates at a grid vertex are proportional to the longitude, latitude, and altitude indices, and vary between 0 and 1. The Euler method for integrating ordinary differential equations can be used to move the grid vertices forward along the streamlines of the wind flow field. To move a vertex to its position in the next frame, we just add to its coordinates the velocity multiplied by the time interval between frames. We multiplied the simulation velocities by a factor to convert from meters per second into grid units per frame. For the longitude velocity component, we also divided by the cosine of the latitude, to account for the squeezing together of the longitude lines near the poles. In frames after the fist, grid vertices move into the interiors of grid cells, so the velocity must be interpolated from the eight surrounding grid vertices.</p><p>Since the advected grid becomes distorted, the texture coordinates must be resampled into the standard fixed grid at which the other simulation data is defined. Unless the inverse of the advection mapping is known, it is hard to decide which distorted cell contains a given grid vertex. In fact, the grid cells could become so distorted that their surfaces self-intersected, making the decision even more difficult. We therefore computed the inverse advection mapping for each grid vertex, instead of the forward mapping. For each grid vertex P in frame n, we found the point Q in frame 1 which would end up at P, by integrating backwards along the streamline through P. The texture coordinates at P are then proportional to the longitude, latitude, and altitude at Q.</p><p>Inaccuracies in the integration, caused by the coarse grid and large time steps, could move P below the ground, or above the atmosphere, where the velocity is undefined. If this happens, we use the velocity at the nearest point R inside the atmosphere. We can use the coordinates of Q itself for the texture, since our 3-D texture function is defined for all coordinate values. (If we used the texture coordinates for the point R, a 3-D cell above the atmo-sphere would get its texture squashed into 2-D.) On the other hand, if we used forward integration, the same sorts of errors might mean that a grid point P did not lie inside any distorted grid cell, in which case we could not find any texture coordinates for it. It does not matter whether a grid cell integrated back in time is distorted or self-intersecting, since the geometry is not used. Only the texture coordinates are interpolated onto and across the contour surfaces.</p><p>The streamlines through the grid points for frame n do not pass through the grid points for frame n-1, so a separate backwards integration is needed for each frame. This makes the number of steps in the Euler integration quadratic in the number of frames. It is also necessary to have the velocities for all the time steps available to compute the backwards integration for the last frame. This was impractical for us, since the data output for each 24-time-step day takes 380 megabytes. In addition, the wind will eventually twist and stretch the cloud texture until it contains only high spatial frequencies, which will spoil the intended visual effect.</p><p>For all these reasons, we used each set of texture coordinates for only 24 hours of simulation time. To keep a continuous appearance, we rendered the clouds using a linear combination of 3-D textures computed from two sets of coordinates. We increased the weight of each set from zero to one in 12 hours, and then back to zero in another 12, so that a new set replaced an old one every 12 hours. For hour n of a 12 hour cycle, one set of coordinates is obtained by integrating backwards for n-1 steps along the streamlines, and the other by integrating along the same streamlines for a further 12 backward steps. These integrations took an hour of CPU time, but were done only every four frames; we interpolated the coordinates in between.</p><p>If we had used linear interpolation between two shaded cloud images, the overlap of cloud patterns would have been obvious. Instead, we combined the two 3-D textures before applying the non-linear transparency threshold, so only one cloud pattern will be visible.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Haze effects</head><p>Raleigh scattering in the atmosphere gives a blue tinge to distant objects, and this aerial perspective provides a distance cue which aids in depth perception. To add this extra depth cue to our cloud visualizations, and also to enhance their realism, we computed this atmospheric haze effect.</p><p>Assuming the perfect gas law that density is proportional to pressure, one can write and solve a differential equation for air density as a function of altitude, and conclude that atmospheric density decreases exponentially with altitude. We wanted to compute such exponentially decreasing haze, and tried two different methods.</p><p>In the first method, we rendered all the volume cells with the blue exponential haze, and composited them together with the textured cloud polygons in back-to-front order, using the system described in <ref type="bibr">Max et al. [8]</ref>. This took a long time, since almost a million volume cells have to be rendered for our climate model.</p><p>A second more efficient method is to integrate the exponential volume density analytically. Carpenter [23 described such an integration method, which was used to render the atmosphere in the Genesis Demo sequence for the movie "Star Trek 11: The Wrath of Kahn", and our technique is similar.</p><p>We replaced the linear exponential decay of density with altitude by a quadratic exponential</p><formula xml:id="formula_3">d(a) = c exp(-g n2)</formula><p>where a is the distance from the center of the earth, and c and g are constants for adjusting the density at sea level, and its rate of decay with altitude. If the thickness of the atmosphere is small compared with the radius of the earth, this quadratic exponential decay will be close to the linear exponential one.</p><p>Let v(t) be a viewing ray, parametrized by distance from the viewpoint, and let v(t0) be the point whose distance r from the center of the earth is the smallest. Then by the Pythagorean theorem, the distance from any other point v(t) to the center of the earth is given by  <ref type="figure">d ( a ( r )</ref> ) and changing variables to</p><formula xml:id="formula_4">x = &amp; ( t -t O )</formula><p>The integral of exp(-2) is closely related to the normal distribution "~ITo~" integral, for which tables and subroutines exist. We created a table for this integral, over the range -3 &lt; x &lt; 3, and could thus integrate the density over any ray segment with two table lookups, one exponential, and various other arithmetic operations.</p><p>A special haze depth buffer was initialized to a large positive depth, and was updated whenever an opaque terrain polygon was rendered. Before a semitransparent cloud was composited, the haze was first composited over the background, using the optical depth integrated from the cloud polygon to the saved haze depth. The haze depth was then updated to the current polygon depth. After the whole scene was rendered, an extra pass added the haze between the viewpoint and the haze depth buffer distance remaining at each pixel. Haze was added by this method to all the figures. <ref type="figure">Figure 1</ref> shows the 15% cloud cover contour surface for noon on January 5, the fifth day of output data on a 320x160~19 grid from a medium-range weather forecast simulation. <ref type="figure">Figure 2</ref> shows the same contour surface after the data had been smoothed by a 3 x 3~3 filter kernel. <ref type="figure">Figure</ref> 3 shows this contour surface with the cloud texture described in this paper, using cloud thickness to adjust the transparency threshold. These three 640x480 resolution images took about 28 wall clock minutes each, on a SGI Personal Iris 4D135. <ref type="figure">Figure 4</ref> is similar to figure 3, except that the transparency threshold was adjusted using the integral of the cloud cover variable inside the contour surface, and took about 40 minutes. <ref type="figure" target="#fig_6">Figure 5</ref>, at 1920x1035 HDTV resolution, using cloud thickness to adjust the transparency threshold, and the derivatives of the texture function f <ref type="bibr">(u,v,w)</ref> to provide bumpmapped shading, took 47 minutes. All of these frames used the haze effect, and none of the times include advection computations. When the advection computations were included on a HDTV animation of 10 days of simulation, the average time per frame was 45 minutes. (As mentioned above, we rendered four frames per one hour simulation output file, by interpolating the cloud cover and texture coordinates between the hourly key frames, so the advection cost is prorated over four frames in this average.)     </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>, flow lines, and flow ribbons of vector fields in a diagrammatic but less realistic manner. Crawfis and Max [3] also show a mixture of cloud densities and vector segments which can be rendered more rapidly, but the objects drawn do not actually move with the flow. Yaeger et al. [ l l ] have advected a 2-D atmospheric texture on Jupiter.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>t)) = c exp(g 2) exp(-g (t-to)2). The total optical depthfalong the ray between r1 and r2 is 4 f = P d ( a ( r ) ) d t fl where k is the optical depth per unit length per unit density. The transparency is then exp(-f. (See Blinn [l].) After substituting for</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>Figure 1.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>Figure 2.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>Figure 3. Figure 4.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>Figure 3. Figure 4.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 5 .(</head><label>5</label><figDesc>See color plates, p. I x 1</figDesc></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>This work was performed under the auspices of the U.S. Department of Energy by Lawrence Livermore National Laboratory under contract number W-7405-ENG-48, with specific support from the High Performance Computing and Communications Program directed to Visualization For Global Climate Modeling. The terrain was rendered using subroutines of Michael Allison and Chris Anderson, and data from Brian Cabral. The simulation output came from Bob Mobly and Chris Anderson. Gene Cronshagen laid out and printed the figure page, and recorded the video. We wish to thank the reviewers for suggesting improvements in the explanations.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Light Reflection Functions for Simulation of Clouds and Dusty Surfaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>B L I~</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics Vbl</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="21" to="29" />
			<date type="published" when="1982" />
		</imprint>
	</monogr>
	<note>82 proceedings</note>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Carpenter</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1982" />
		</imprint>
	</monogr>
	<note>personal communication</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Direct Volume Visualization of Three-Dimensional Vector Fields</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Crawfis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Max</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1992 Workshop on Volume Visualization</title>
		<meeting>the 1992 Workshop on Volume Visualization<address><addrLine>NY</addrLine></address></meeting>
		<imprint>
			<publisher>Kaufman and Lorensen</publisher>
			<date type="published" when="1992" />
		</imprint>
	</monogr>
	<note>ACM SIGGRAPH</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Visual Simulation of Clouds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Gardner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Siggraph &apos;85 Proceedings</title>
		<imprint>
			<date type="published" when="1985" />
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="297" to="303" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">A Tool for Visualizing the Topology of Three-Dimensional Vector Fields</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Globus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Levit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lasinski</forename><forename type="middle">T</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Visualization &apos;91</title>
		<editor>Nielson and Rosenblum</editor>
		<meeting>Visualization &apos;91</meeting>
		<imprint>
			<publisher>IEEE Computer Society Press</publisher>
			<date type="published" when="1991" />
			<biblScope unit="page" from="33" to="40" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Visualizing Vector Field Topology in Fluid Flows</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Helman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Hesselink</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE CG&amp;A Ml</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="36" to="46" />
			<date type="published" when="1991" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Light Diffusion through Clouds and Haze</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Max</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision, Graphics, and Image Processing</title>
		<imprint>
			<date type="published" when="1986" />
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="280" to="292" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Area and Mlume Coherence for Efficient Visualization of 3D Scalar Functions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Max</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Hanrahan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Crawfis</forename><forename type="middle">R</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="27" to="33" />
			<date type="published" when="1990" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Sorting for Polyhedron Compositing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Max</surname></persName>
		</author>
		<editor>Book&quot; Hagen H., Muller H. and Nielson G.</editor>
		<imprint>
			<date type="published" when="1992" />
			<publisher>Springer Verlag</publisher>
			<pubPlace>Berlin</pubPlace>
		</imprint>
	</monogr>
	<note>Scientific Visualization Seminar</note>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Wyvill</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Solid Texturing of Soft Objects</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Wyvill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Mcpheeters</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE CG&amp;A</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="20" to="26" />
			<date type="published" when="1987" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Combining Physical and Visual Simulation: Creation of the Planet Jupiter for the Film &apos;</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Yaeger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Upson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Myers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="85" to="93" />
			<date type="published" when="1986" />
		</imprint>
	</monogr>
	<note>Siggraph &apos;86 Proceedings</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
