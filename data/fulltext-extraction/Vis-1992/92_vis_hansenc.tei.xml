<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/pisenberg/grobid/grobid-0.6.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Massively Parallel Isosurface Extraction</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charles</forename><forename type="middle">D</forename><surname>Hansen</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Advanced Computing Laboratory Los Alamos National Laboratory Los Alamos</orgName>
								<address>
									<postCode>87545</postCode>
									<region>New Mexico</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Hinker</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Advanced Computing Laboratory Los Alamos National Laboratory Los Alamos</orgName>
								<address>
									<postCode>87545</postCode>
									<region>New Mexico</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Massively Parallel Isosurface Extraction</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2021-02-19T20:27+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
				<p>We describe ezperiences during the investigation of parallel methods for faster isosurface generation on SIMD machines. A sequential version of a well known isosurfacing algorithm is algorithmically enhanced for a particular type of SIMD architecture. The SIMD implementation takes full advantage of the data parallel nature of the algorithm and ezperiments have proven the implementation to be highly scalable. A parallel tool, which can generate 170K polygons /second, gives scientists the means to ezplore large 3D scalar or vector fields interactively. &apos;Nearest neighbor communications is the fastest type of intraprocessor communications available on the CM-2. It is also called NEWS communications.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>One of the most common methods for the visualization of 3D scalar fields is through the reconstruction of constant valued surfaces. These fields can be scalar components of vector fields; a scalar computed from the vector components; 3D medical imaging data; seismic data; or a plethora of other types of data[l, 2, 31. Typically, this process treats the 3D scalar field as gridded, possibly non-uniform, point samples and for a given constant value, interpolates intersections between neighboring pairs of these samples. Connecting these intersections will approximate a surface at some given constant value.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1">Background</head><p>Visualizing these isosurfaces interactively can give the scientists a great deal of information about the underlying structure contained within the field. Interactive viewing of these surfaces enhances the interpretation of this structure. Unfortunately, the size of the fields generated from supercomputer models is usually very large. This limits the interactiveness of isosurfacing algorithms due to the amount of time spent generating the surface of constant value. In this paper, we describe our experiences with a SIMD solution to this problem.</p><p>Isosurface generation can be accelerated through the use of table lookup <ref type="bibr">[l]</ref>. Using this method, known as Marching Cubes, the vertices of each voxel' are compared against the contouring value. If they are greater, a corresponding bit is set in a mask representing that voxel. This mask is used as an index into a la voxel, volume element, is compoaed of 8 point samples forming a cube hinkerQac1. lanl .gov table describing which edges contain the intersection. Although much faster than the brute-force method of testing every edge, it is still necessary to interpolate the points of intersection on the corresponding voxels. This interpolation is typically performed many times which slows the process down.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.2">Other Approaches</head><p>Researchers have studied hierarchical data structures to help address thie problem. One such data structure is the octree <ref type="bibr" target="#b3">[4]</ref>. Researchers have used octrees in medical imaging to avoid transparent spatial regions <ref type="bibr" target="#b4">[5]</ref>. Others have addressed faster isosurface generation through the use of octrees[3 . This noting the upper and lower values contained within the region. This speeds the isosurface generation procedure by only applying the algorithm to voxels within pertinent regions.</p><p>These methods assume the entire 3D field is resident on the machine generating the isosurface. In medical imaging, this assumption is valid since the scanning device is not usually the same as the visualization device and the data is usually visualized as a post-processing step. The transfer, possibly through a network, of the sampled data is typical in this scenario. However, in scientific computing the simulation models are running on a high-performance computer and the sire of the fields (up to 1G byte per time step) make transferring the raw data to the visualization device very time consuming. This limits interactively isosurfacing the data to monitor running models. One approach to this problem is to generate the isosurface on the same machine which is running the model and either render the geometry locally or send the geometry to a high speed rendering device such an an SGI 380/VGX.</p><p>At this time, it is well known that the original Marching Cubes algorithm presented by Lorrensen and Cline can produce holes in the resultant isosurface. The algorithm presented in this paper does not specifically address the problem of holes caused by the ambiguity of the Marching Cubes Algorithm. Two well known, yet different, solutions to this problem have been presented by <ref type="bibr">Wilhelms</ref>  We have chosen to investigate parallel methods for faster isosurface generation. This paper describes the results we have obtained through experiments with a SIMD parallel version of marching cubes <ref type="bibr">[l]</ref>. We examine the SIMD method, why we chose the particular algorithmic approach and present results obtained utilizing a 64K CM-2. We then discuss the conclusions of our findings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">SIMD APPROACH</head><p>The architecture targeted for the SIMD version of the marching cubes algorithm is a 64K processor Thinking Machines Connection Machine (CM-2). Although the marching cubes algorithm maps well to the hardware, some tuning was required to achieve the expected performance from the code.</p><p>Even though there are 65536 physical processors, each processor can simulate many virtual processors'(vps). This allows us to assign a vp to each voxel and, in concept, concurrently determine the surface geometry for each voxel.</p><p>Simply stated, marching cubes extracts a list of polygons from volume data. A voxel is bounded by eight data points located on two adjacent slices. Each vertex is coded as either inside or outside the object relative to the surface defining threshold. Based on the configuration of vertices that lie inside and outside the object, a surface within the cube is triangulated creating a portion of the surface. The algorithm breaks into the following discrete steps : </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Creating a bit-mapped index</head><p>The first step is to create a bit-mapped index into the marching cubes lookup tables. In our implementation of the algorithm, the data points of the volume are located a t the lower-left-forward corner of each voxel. To complete the description of each voxel, point samples (vp values) are needed for the other seven corners of the voxel. A choice must be made between storing all eight point samples 'in-processor' or communicating that information as needed. If corner information is stored in-processor, then interpolated edge 'Each physical processor can simulate one or more virtual processors by sequentially executinginstructions for each virtual processor.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>v7 V6</head><p>Index =IV71V61V51V41V31V2lVll VO On the surface, doing communications and conserving memory seems to be the best solution. It is not, however, because although all communications involved in the polygon construction step are nearest neighbor communications3, the C-Star compiler does not have enough information about the parallel indexing and cannot use NEWS communications. In this case, polygon construction would use general (via router communications which is an order of magnitude sower. 1 It is for this reason point samples and edge information are stored in-processor.</p><p>When building the cell index each vp communicates with its nei hbors and assigns values to an eight position paralfel array V[O:7] that describes the point sample values at each of its eight vertices (See <ref type="figure" target="#fig_1">Figure 1)</ref>.</p><p>Determining the bit-mapped index requires no communications since point sample data for the eight vertices resides in-processor. The index is constructed by setting the bits corresponding to the vertices which are greater than or equal to the value being surfaced.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Interpolating Edge / Gradient Values</head><p>Once the bit-mapped index is created, we calculate the gradient information along the x, y and z axis to use in the shading model when the time comes to render the surface. The gradient can be found by interpolating at the point of intersection. The gradient vector at the surface of interest is calculated by first estimating gradient vectors at the cube vertices using the operator : Next, the voxel edge intersections are calculated along the three coordinate axes by using linear interpolation. To handle non-uniform grids, this interpolation will use voxel coordinate information instead of assuming unit cube voxel sizes. Gradient values at surface intersection points are calculated in much the same way during this step. In the SIMD architecture, each vp can determine its location along any of the computational axes. This is accomplished with the pcoord() (C-Star) function or the MY-NEWS-COORDINATE (C-Paris) function.</p><formula xml:id="formula_0">Delta = IsoValue -V[O]</formula><p>For (I = 0 ; I &lt; 3 ; I++)</p><p>For (J = 0 ; J &lt; 3 ; J++)</p><formula xml:id="formula_1">Edge[I][J] = pcoord(J);</formula><p>x-Axis:</p><formula xml:id="formula_2">Edge[O][O] = (Delta / (V[1] -V[O])) + pcoord(0) Y-Axis: Edge[l][l] = (Delta / (V[3] -V[O])) + pcoord(1) Z-Axis: Edge[2][2] = (Delta / (V[4] -V[O])) + pcoord(2)</formula><p>Some of the edges calculated are not useful but because of the lock step nature of the SIMD hardware, all vps must wait until the last vp is finished. So, the overhead of choosing and eliminating useless edge calculations turns out being more expensive than doing the interpolation for every edge. Now we have intersection and gradient information for the twelve edges which make up each voxel. By doing NEWS communication with neighboring voxels, we pick up the nine edges interpolated by the neighboring vps.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Constructing triangles</head><p>It is necessary for each vp that contains a portion of the surface to have access to the lookup table when constructing polygons. There are two widely used forms for this table. One form has a unique entry for each possible value of the bit-mapped index (i.e. 256 entries). The other form reduces the table size by applying rotations and symmetry to 14 base surface intersection configurations[ 13.</p><p>The full sized lookup table is used because the reduced table method generates special cases. Voxels with bit-mapped indices, which are not one of the 14 base cases, require additional handling (reflection, Iotation or both). The lock step nature of the CM-2 hardware makes this an expensive proposition since all processors are given the same instruction whether they are active or not. The vps doing base case or rotational case or reflective case construction are handled while all other vps sit idle. Using the full table means that every index value is treated alike and a higher processor utilization is achieved.</p><p>It would be prohibitively expensive to store the entire lookup </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">RESULTS</head><p>Before we discuss the results obtained by the algorithm, there are a few points to address.</p><p>First, this version of the Marching Cubes algorithm was developed to generate isosurfaces for data which *The vp ratio describes the number of virtual processors that are being emulated by each physical processor.</p><p>was created on the CM-2. Without a high speed network connection, data transport time far exceeds isosurfacing time for data created elsewhere.</p><p>Second, in most cases the performance of this algorithm is nearly constant, within 15%, regardless of the number of triangles generated for a given volume. The performance of this algorithm is bounded by the maximum number of triangles in any given voxel. The algorithm will exhibit worst case performance if any voxel contains maximum possible number of triangles.</p><p>Presented timings reflect worst case performance. It should be noted that most real-world data sets contain at least one voxel having the maximum allowable number of trian les. Thus, for this algorithm, isosurface generation for dense volumes proceeds as quickly as for sparse volumes.</p><p>The times given in <ref type="table">Table 1</ref> were gathered using a Sun 41490 front-end and the number of processing elements (PES) specified in the first column. All times are in milliseconds. Each timing is the average of three runs using different isosurface values. Changing the value to be surfaced had little effect on execution time. This is as expected since the time spent in each virtual processor (vp) remains constant regardless of the number of polygons within its voxel. A close look a t the timings shows that doubling the number of PES reduces the time needed to generate the surface by roughly half while multiplying the number of voxels in the volume by eight roughly increases the execution time by that same amount. As the vp ratio (number of virtual processors being emulated by each physical processor) increases, efficiency is increased. This explains why the speedup (with respect to vp ratio) seems to be slightly better than linear (See <ref type="figure">Figure 2)</ref>. The speedup is slightly less than linear when more PES are applied to the same data set(See <ref type="figure">Figure 3)</ref>. The reason for this is fairly straightforward, when the vp ratio is high, more communication takes place on the Sprint Nodes. There is also a microcode startup cost that is significant when the vp ratio is low. This startup cost is overcome as vp ratio increases. Note that the speedup curves are only for the massively parallel version and do not include the best serial version.</p><p>Some readers may think the times shown in Table l are slower than would be expected. First, the data sets we are using, from a CFD origin, contain a large number of polygons. For example, the 12g3 volume generates over 155,000 triangles per surface. The 2563 volume over 1.24 million triangles. The algorithm outlined here will generate on the order of 170,000 triangles per second. This is close to the rendering speed of disjoint Goraud shaded poly on8 on the fastest commercially available hardware &amp;GI VGX with MultiB~ffer).~ Colorplates 1-3 show the results of this algorithm on three timesteps from a 3D hydrodynamics problem. This simulation shows three micrometeoroids (gold spheres) impacting the bumper shield (brass sur-bVendor quoted benchmarka for SGI and HP require triangle meshes or triangle strips. We are quoting empirically obtained timings not vendor specs.</p><p>face) meant to protect the skin of the spacecraft (aluminum surface). These polygons were flat shaded at the request of the scientist to illustrate the grid resolution.</p><p>Colorplates 4-6 show the results of this algorithm applied to oil resevoir recovery. The 1283 data set was generated using lattice boltzmann techniques. The simulation shows how a wetting fluid (blue surface) flows through the pores (transparent surface) of a digitized core sample (red surface).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">CONCLUSION AND FUTURE WORK</head><p>As the shown in <ref type="figure">Figures 2 and 3</ref> isosurface extraction, with a data parallel architecture such as the CM-2, is highly scalable. The massive size of data sets currently computed makes the issue of isosurface extraction an important one. This investigation's results are based on isosurfacing without using spatially hierarchical data structures. It is unclear whether such an approach would improve performance of this particular implementation due to the lock step nature of the SIMD architecture, This is clearly a direction for further research. Another issue not addressed specifically by this paper is the rendering of the generated polygons. As previously mentioned, it is desirable to generate the isosurface on the machine where the raw data is produced to reduce the required network bandwidth to interactive levels. For a 2563 volume of floating point data, the raw data requires 530Mbits per time step. Considering that dynamic simulations contain hundreds of time-steps, this is too much raw data to transport in the typical visualization process. If lOOK polygons (triangles) are extracted, the data shipped over the network is reduced to 28Mbits. While this is a reduction of almost 19 times, it is still twice maximal ethernet bandwidth. However, the CMIO bus to VME adapter can be utilized to accomplish the network transport. Another solution would be to make use of the HIPPI channel via a HIPPI-VME adapter. If the polygon count increases an order of magnitude, rendering the polygons on the CM-2 becomes the best solution.</p><p>The current area of focus is in attempting to reduce the number of triangles generated by this code. One method would be to merge coplanar polygons. This effort met with resistance on several fronts since part of the method is stubbornly serial in nature (retransversal of merged polygons). Also, very complex polygons are generated when many polygons are merged (polygons with multiple holes, nqn-unique segments, etc.) And finally, there is a performance penalty when trying to render complex polygons (a opposed to triangles or quads) on z-buffered hardware such as an SGI VGX.</p><p>In the paper, a technique for the implementation of isosurface extraction on a data flow SIMD architecture is discussed. It is shown that near linear speedups, and in some cases superlinear speedups, are possible on a real-world, well known algorithm. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>0</head><label></label><figDesc>Create bit-mapped index 0 Interpolate edge intersections &amp; gradients 0 Construct triangles</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 :</head><label>1</label><figDesc>Cube Numbered Vertices and Edges and gradient information would also need to be stored in-processor .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>(Figure 2 :Figure 3 :</head><label>23</label><figDesc>See wlor plates, p . CP-Superlinear Speedup for Increased Virtual Processors I I I I I I I 1 I. -1 Marching Cubes Speedup ( 1 2 P 3 cells) Marching Cubes Speedup ( 64A3 cells) Sublinear Speedup for Increased Physical Processors</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>and Gelder and by Nielson and Hamann 6, 71. Wilhelms and Gelder investigated</head><label></label><figDesc>multiple met 6 ods for disambiguation including modifying the case table and fitting a low de-method hierarchically subdivides the 3D sca ! ar field gree polynomial to obtain estimates of gradients of neighboring voxels. Nielson and Hamann approached the problem by using an interpolant based on bilinear variation to determine if the verticies should be joined. Either of these methods could be easily applied to the algorithm presented in this paper.</figDesc><table><row><cell>The</cell></row><row><cell>communication required is nearest-neighbor at worst</cell></row><row><cell>and non-existent in the best case. Nielson's method</cell></row><row><cell>does not require nearest neighbor communication thus</cell></row><row><cell>is particularly well suited for the algorithm presented</cell></row><row><cell>in this paper.</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>table in each vp's memory space. For example, the lookup table requires 3328 bytes of storage. Memory for each physical processor is divided evenly between the vp's associated with that physical processor. Each physical processor has 256K of memory. A vp ratio4 of 2 means that each vp is allocated 128K of memory. Storing the entire lookup table on each vp is not a problem when working with small vp ratios (i.e. small volumes). A medium sized volume of 1283 requires a vp ratio of 64. Storing the table on each vp means that the lookup table would use 81.25% of the available physical processor memory (3328 bytes * 64 = 208K). It also means that even though the CM-2 is equipped with 8 GB of RAM, we could not surface a volume of greater than 1283 cells because the memory required for the table alone would be greater than 8 GB.One solution is to store the table on the CM frontend machine as a scalar array and broadcast the table entries to the CM as needed during the polygon construction stage of the algorithm. Unfortunately, there are two penalties to having the table in scalar form on the front-end. First, the communication time accounts for a significant portion of the entire runtime of the algorithm. Also, since the table is a scalar array, it cannot be accessed by the CM hardware in a parallel manner. This means a large number of vps are idle during much of the polygon construction stage. It is necessary to loop over all possible index values (256) and activate the corresponding vps to do their polygon construct ion.A more reasonable solution for the problem is storing the table once for every 32 physical processors instead of once for every vp. aset32shared instructions allow us to use part of the RAM on the Sprint Node as a shared memory accessible by any physical processor on the Sprint Node and any virtual processor associated with those physical processors. Storing the lookup table in this manner requires a constant amount of memory per physical processor (i.e. tubZesise/32). This allows us to store the full sized table in CM memory and access it in a parallel manner.</figDesc><table><row><cell>A CM-2 is made up of some large number of serial-bit processors (4K, 8K, 16K, 32K, 64K . T h</cell></row><row><cell>ing point math chips and memory are grouped into</cell></row><row><cell>has a Weitek math chip, 32 bit processors, routing</cell></row><row><cell>hardware and (in our CM-2) 32 M-bits of RAM. The</cell></row><row><cell>aref32~hared &amp;</cell></row></table><note>cessors (along with routing hardware, Lv eitek ese float-pro- what are called Sprint Nodes. B ach Sprint Node</note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>This work was performed under the auspices of the Department of Energy and was paritally funded by Department of Engry High Performance Computing Grant KC0701 and NSF STC-CPRC CCR-912008.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A high resolution 3d surface contruction algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Lorensen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Cline</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Graphics</title>
		<imprint>
			<date type="published" when="1987" />
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="163" to="169" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Distributed scientific video movie-making</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">E</forename><surname>Johnson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Suprtcomputing Conference</title>
		<meeting>Suprtcomputing Conference</meeting>
		<imprint>
			<date type="published" when="1988" />
			<biblScope unit="page" from="156" to="162" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Octrees for faster isosurface generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wilhelms</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Van Gelder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGGRAPH Workshop on Volume Visualization</title>
		<imprint>
			<date type="published" when="1990" />
			<biblScope unit="page" from="57" to="62" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Geometric modeling using octree encoding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Meagher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Efficient ray tracing of volume data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Levoy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions of Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="1990-07" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Topological considerations in isosurface generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wilhelms</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Van Gelder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGGRAPH Workshop on Volume Visualization</title>
		<imprint>
			<date type="published" when="1990" />
			<biblScope unit="page" from="79" to="86" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">The asymptotic decider: Resolving the ambiguity in marching cubes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Nielson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bern</forename><surname>Hamann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Visualization &apos;92</title>
		<imprint>
			<date type="published" when="1982" />
			<biblScope unit="page" from="129" to="147" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
