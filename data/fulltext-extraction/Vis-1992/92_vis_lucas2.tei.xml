<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/pisenberg/grobid/grobid-0.6.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A Scientific Visualization Renderer</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bruce</forename><surname>Lucas</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">IBM T . J . Watson Research Center</orgName>
								<address>
									<postBox>P.O. Box 704</postBox>
									<postCode>10598</postCode>
									<settlement>Yorktown Heights</settlement>
									<region>NY</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">A Scientific Visualization Renderer</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2021-02-19T20:28+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
				<p>While scientific visualization systems share many requirements with other graphical applications, they also pose special requirements that make solutions based on standard rendering hardware or software not entirely satisfactory. This paper illustrates those requirements b y describing the renderer used in a production scientific visualization system, Data Explorer [l]. W e begin by setting forth the requirements for a visualization renderer derived f r o m our experiences. W e then describe implementation techniques used to meet the requirements of parallelism, volume rendering of irregular data, clipping, and integration of rendering modalities. The renderer described is a software renderer, but it as hoped that the requirements and implementation described here might influence the design of future generations of rendering hardware.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Requirements</head><p>The design of computer graphics systems has heretofore largely been guided by applications such as computer aided design, virtual environments (such as flight simulators) , and communications. The requirements of these applications have led to certain software system design decisions and to the incorporation of certain rendering support into hardware. This section represents a modest step towards identifying the specific requirements of a growing graphics application area, scientific visualization. These requirements are not all unique to visualization applications, but the identification of the requirements important to visualization is a step whose necessity is demonstrated by the difficulty encountered in trying to fully meet the rendering needs of a scientific visualization system with today's graphics software and hardware systems.</p><p>A primary requirement of a visualization renderer has to do with the typically very large quantity of data to be visualized: to a scientist, there is no such thing as sufficient resolution in a simulation. Gigabytes or tens of gigabytes of data with multiple time steps and multiple variables are the norm. On the other hand, interactive, and still better, smooth-motion frame rates in and of themselves constitute a visualization tool. The renderer must therefore be designed to exploit parallelism, particularly when a software solution is adopted to provide the flexibility not available in today I s graphics hard w are.</p><p>(Very large databases are also encountered in applications such as flight simulators and photorealistic renderers, but in those areas generally performance is either deemed to be of absolutely paramount importance (in the former case) and flexibility is sacrificed, or of very little consequence (in the latter case) and interactivity is lost. Neither extreme is appropriate for interactive exploration of large scientific data sets.)</p><p>A second requirement for a visualization renderer derives from the fact that scientific data frequently deal with observation or simulation of real-world phenomena, and therefore the data to be visualized are volumetric, that is, three-dimensional and spacefilling. An important tool for the visualization of volumetric data is the use of translucency, both in the form of translucent volumes and translucent surfaces. Volume rendering has enjoyed a great deal of research activity in the past few years, and the utility of translucent surfaces (such a5 isosurfaces) is well-established.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>(An example of each is shown in Figures 3 and 4.)</head><p>Another important tool in the study of volumetric data is the ability to clip away parts of a scene to reveal hidden objects (see <ref type="figure" target="#fig_2">Figures 3 and 5</ref>). While clipping can be accomplished geometrically in object space, this has the obvious disadvantage of potentially replicating nearly all of a very large data set: consider for example clipping away just a small part of a voxel array that nearly fills memory. Render-time clipping, as described for example by <ref type="bibr">Epstein et al. [3]</ref>, avoids this problem while at the same time is easier to implement and avoids well-known numerical problems of object-space clipping.</p><p>An additional requirement derives from the great variety of data representations used in scientific applications. Some simulations may be carried out over very large regular grids of points, while others are carried out over relatively smaller space-filling collections of irregularly sized and shaped interpolation elements such as tetrahedra, hexahedra, and so on. Observational data tend to be sampled over irregular grids of points, or perhaps regular grids with missing observations. The renderer must be prepared to handle all of these cases, or at least a sufficient subset of them that translating the others into the cases that are handled is feasible. For example, volume rendering of both regular voxel arrays and of irregular collections of t e t r a hedra and hexahedra would seem to be a minimum requirement.</p><p>Finally, much of science is the study of cause and effect, guided by observations of correlations between variables. The demands of correlative analysis require bringing together into one image multiple variables each visualized in a modality appropriate for the variable. This requires that the renderer be capable not only of rendering all data types individually but in combination as well. It must be possible for example t o combine translucent volume renderings of regular voxel arrays or irregular hexahedral or tetrahedral volume elements, with opaque and translucent isosurfaces and contours, with vector and tensor glyphs, with streamlines, axes, and so on.</p><p>In addition to the visualization-specific requirements described above, a visualization renderer must also handle much of the range of traditional opaque surface graphics, lighting models, and so on. On the other hand, data presentation, not photorealism, is the goal. A number of the features that have been very important for CAD, virtual environments, and communications applications seem less important in visualization. For example, texture mapping as usually formulated requires a surface with an imbedded twodimensional coordinate system; but this is not possible on an arbitrary surface, such as an isosurface. Specular highlighting is useful for showing surface shapes; but in many visualization applications, the resolution of the surface description is high enough that a moderate degree of specularity can often be displayed without sophisticated shading techniques (such as Phong shading), simply by using Gouraud linear interpola tion combined with a moderate specular lighting computation at the vertices (see <ref type="figure" target="#fig_2">Figure 3)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Parallelism</head><p>The Data Explorer renderer is designed to take advantage of parallelism. A very general model of parallelism is assumed, making the renderer portable to a variety of platforms. Any computer with a shared global memory will be a suitable target for the renderer. Coarse-grain parallelism is used, so very fast locking primitives are not required. A nonuniform memory architecture, where each processor has some amount of fast-access local memory managed by the application (as opposed to a hardware-managed cache), can be used effectively but is not required. The parallelization method is driven by several considerations that affect the overall structure of the renderer, as described in the following paragraphs.</p><p>Two general approaches to graphics systems have been adopted. "Display-list" style renderers, exemplified by PHIGS, operate by traversing a data structure stored in memory that represents the scene to be displayed. "Immediate-mode" systems, exemplified by GL, provide a set of procedure calls for presenting rendering primitives to be interpreted as they are received. Several aspects of our system argue for a display-list style renderer. Primarily, the need to handle translucent volumes and surfaces requires processing the rendering primitives in a viewpoint-dependent order, precluding an immediate-mode interface.</p><p>There is also typically a high degree of sharing of vertices in many kinds of data sets. For example, in meshes of cubical (or hexahedral) volume elements each vertex is shared by eight cubes. If we imagine the same data set with each hexahedron subdivided into the minimum required five tetrahedra, and take this as representative of tetrahedral data sets, the number rises to twenty tetrahedra incident on each vertex. (This estimate corresponds closely to typical numbers in tetrahedral meshes we have seen.) This argues very strongly for performing per-vertex operations, such as transformations and lighting, once per vertex, storing the results, and re-using the result for each primitive that shares the vertex. This possible only with a display-list style interface; an immediate-mode interface must repeat the per-vertex calculations for each time the vertex is used in a different primitive. (Tricks such as triangle strips that allow vertices to be re-used between adjacent triangles do not generalize.)</p><p>These considerations lead to a two-pass design for the renderer: the per-vertex calculations such as transformation and lighting are performed in the first pass, while the scan conversion of the primitives is performed in the second pass. The two passes parallelize differently, but in both passes partitioning of the input data is important.</p><p>Partitioning Parallelism in Data Explorer is generally achieved by data partitioning [l]. Consider a typical example of a three-dimensional volumetric data set, or field. Immediately after importing the data into the system, the field is partitioned into nonoverlapping spatial regions. This partitioning is explicit, that is, the data is rearranged into a collection, or composite field, of partitions, each of which is itself now a field. (The data model assumed here has been described in more detail by Haber et al. <ref type="bibr">[2]</ref>).</p><p>Partitioning of regular grids is straightforward, and is done simply by dividing each edge of the bounding box of the data into some number of pieces such that the product of the number of divisions along each edge is approximately the desired number of partitions. For irregular data the algorithm is more complicated and involves recursively subdividing the data (along the longest axis each time). In either case the result is a set of non-overlapping spatially local partitions. The partitions are all self-contained; for example, primitives such as triangles within each partition contain vertex indices that refer to vertices only within that partition.</p><p>This explicit partitioning makes parallelization of most modules trivial. For example, the Isosurface module simply assigns a different processor to each input partition and constructs a partitioned isosurface, where each output partition contains the portion of the isosurface that passes through one of the input partitions. Most of the visualization modules operate in a similar way. Thus, the input scene to the renderer is generally already partitioned by virtue of the initial partitioning of the input data.</p><p>First pass In the first pass of the renderer, pervertex calculations such as point and normal transformation and lighting are performed. This pass parallelizes in the same way as most of the visualiza tion modules, that is by scene partitions; as discussed above, the operation of the system naturally leads to the input to the renderer already being partitioned. The transformed and lit vertices are left (still in partitioned form) in global memory to be used in the second pass.</p><p>Each primitive is represented by a set of integer indices into the vertices. For example, a triangle is represented by three vertex indices, a tetrahedron by four indices, and so on. Within each partition the transformed and lit vertices are kept in the same order as the input vertices, so that the vertex indices used by the primitives to refer to the vertices are valid both for the untransformed, unlit vertices and for the transformed, lit vertices; thus the primitives remain unchanged by the first pass.</p><p>Second pass The second pass parallelizes by screen partitions, and performs the scan conversion of primitives (triangles, quads, tetrahedra, hexahedra, and SO on), using the transformed and lit vertices from the first pass.</p><p>The screen is logically divided into non-overlapping rectangular regions, and each processor handles one or more of the screen patches. Processing a screen patch consists of looking at each partition of the scene and determining by a quick bounding box check whether that scene partition is visible in the screen patch being processed. Most scene partitions will be rejected quickly by this test. For the remaining scene partitions, all primitives in the partition must be checked against the bounds of the screen patch. Again, many primitives will be rejected quickly by a simple bounding box check. The remaining primitives are clipped against the z = near plane (in the case of perspective), and scan converted.</p><p>The scan conversion is done in the second pass by a z-buffer algorithm, augmented by enhancements for features such as irregular volume rendering and clipping. As each processor completes its screen patch, it may copy the result into a reassembled image in global memory (discarding the z buffer), or it may directly pass the screen patch off to the display if an output image in global memory is not needed.</p><p>Performance The performance of this algorithm, and in particular the speedup achievable, depends on finding optimal (within a broad range) values for the fineness of the partitioning of the scene and of the screen. Partitioning the scene too finely increases the overhead due to t,he fact that the boundary vertices of each partition must be replicated in the adjoining partition. Partitioning either the scene or the screen too coarsely results in inability to get good load balance between the processors. For example, if there are fewer partitions than processors, some processors must sit idle. Partitioning the scene too coarsely, or the screen too finely, results in increased overhead due to each scene partition's bounding box overlapping more screen patches, and therefore more work being done to look through the partitions to find the primitives that are actually visible in each screen patch. An example of the tradeoff of these effects is shown in the following Regular voxel arrays are particularly important for example in medical imaging applications. Volumetric data defined in the form of a space-filling mesh of polyhedra (such as tetrahedra or hexahedra) is also important: many scientific simulation methods operate on this sort of mesh. For example, simulation of an airflow across a wing is often done by on a collection of irregular hexahedra that arise from "warping" a regular grid to conform to the surface of the wing. In such cases the data is frequently defined at the vertices of the polyhedra that form the mesh. The volume rendering of such irregular meshes has not been as widely studied.</p><p>Resampling such data onto a regular grid is one alternative, although it tends to be undesirable: such data sets tend to vary in resolution from one part of the space to another, depending on the needs of the simulation. Therefore, resampling the data onto a regular grid sufficient to match the resolution of the highest-resolution part of the data can result in a very large increase in the size of the data set and a corresponding increase in processing time. (This is of course one of the reasons simulations are done on irregular grids rather than a regular grid.)</p><p>Raytracing is another approach that has been proposed (for example, <ref type="bibr">Kajiya [6]</ref> and <ref type="bibr">Garrity [7]</ref>). In general, however, raytracing methods are slower than object-based methods due to the expense of finding objects, calculating ray-object intersections, and calculating interpolated colors and opacities. Objectbased scan-conversion methods generally do the equivalent computations more efficiently because they readily take advantage of coherence: adjacent pixels usually intersect the same object, and the interpolated color of one pixel is easily computed from the interpolated color of the adjacent pixel.</p><p>One viable object-based approach has been explored by <ref type="bibr">Wilhelms [8]</ref> for regular grids and extended by <ref type="bibr">Shirley [9]</ref> to tetrahedral grids. In this approach, the polyhedra are considered in sorted order, front to back. Each element is broken down into viewpointdependent polygonal regions determined by the projection of the polyhedron's outline, as illustrated in <ref type="figure" target="#fig_0">Figure 1</ref>. Within each region, the variation in thickness between vertices is linear, and so the varying opacity and luminance of each polygon can be approximated easily given the opacity and luminance at the vertices. However, this approach has a drawback that  <ref type="figure">C; D , E , F )</ref> .</p><p>determining the polygonal regions for a given irregular polyhedron from a given viewpoint is both complex and computationally expensive. This problem is less significant for tetrahedra and regular hexahedra, but it becomes more acute as the complexity of the polyhedra increases, as illustrated in <ref type="figure" target="#fig_0">Figure 1</ref>. We describe here a different technique, illustrated in <ref type="figure">Figure 2</ref>. The faces of all the polyhedra (for example the four triangular faces of a tetrahedron or the six quadrilateral faces of a hexahedron), rather than the polyhedra themselves, are sorted back to front. Each face is then scan converted in turn by a standard technique, linearly interpolating the vertex color, opacity, and z values across the face, resulting in a set of color values C f x e , opacity values Oface, and z values zface for each pixel in the projection of the face.</p><p>Each face is "composited" with the scene by a technique that takes into account the distance At between the current face at the current pixel location and the face immediately behind the current one at the current pixel location. The Az value is available because when the face behind the current face was composited,</p><p>its z values were recorded in a z buffer. The Az value is used to modify the opacity and color values, accounting for the thickness of the volume that the light ray has passed through between the previous face and the current one. Thus the algorithm for updating the color Cbuf and z value Zbuf stored in the frame buffer given the current interpolated face color cface, opacity oface, and z value zfXe is</p><p>Generally Az is small enough that 1 -Oface x Az is a sufficient approximation for exp(-oface x Az). Note that this is not compositing in the sense normally supported by rendering hardware, because of the incorporation of Az into the calculation. However, this "com-image plane <ref type="figure">Figure 2</ref>: Face-compositing algorithm for irregular volume rendering is illustrated in a top view in which faces of the volume elements are represented by lines such as PQ and PR. As each face PQ is scanconverted, the distance A t = zlzo between it's depth z1 at any given pixel X and the depth zo of the face P R behind it is incorporated into the compositing.</p><p>positing" operation could be provided as a primitive in a hardware rendering system. We have found that sorting the faces by the z values of their centroids produces good results for typical data. Generally this results in relatively few missorted pixel-face intersections. The face compositing algorithm is able to accommodate a small amount of mis-sorting. Mis-sorted faces result in negative Az values, and while the compositing algorithm is not exactly reversible (because of the way Az enters into the opacity calculation), it is approximately so for small negative Az. A more exact translucent face sorting algorithm (such as A-buffer <ref type="bibr">[lo]</ref>) could be used if desired.</p><p>These formulas assume the "dense emitter" model of volume rendering, in which the rendered color Cbuf of any pixel on the frame buffer is given by an integral along the viewing ray originating at that pixel:</p><p>In this formula, C(Z) and O(Z) represent the color and opacity values at all points along a viewing ray. The C f X e and Oface values in the compositing formula above are samples of C(Z) and o(z) at the face locations Zfme. The units of these color and opacity values are the instantaneous rate of emission and absorption of light per unit distance travelled. This model readily accommodates other volume rendering models. For example, the color values that are the input to this model could be obtained by applying an external lighting source to the volume at the element vertices, taking into account the gradient of the volume data.</p><p>Examples of a scenes rendered using the face-based volume rendering method are shown in Figures 4 and 6.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Clipping</head><p>The volumetric nature of typical scientific data makes the ability to clip away portions of a scene a particular asset. This is illustrated in <ref type="figure" target="#fig_2">Figures 3 and 5</ref>.</p><p>As discussed above, clipping is a kind of constructive solid geometry operation, and can be accomplished in object space by standard CSG algorithms. However, object-space clipping has the disadvantages cited above, primarily the need to replicate large amounts of data if a small portion of a volume is clipped away.</p><p>Therefore, the Data Explorer renderer uses a render-time clipping algorithm. The general idea of render-time CSG is discussed in great detail by <ref type="bibr">Epstein et al. [3]</ref>. In that report, very general techniques for arbitrary CSG union and intersection operations are described. Data Explorer implements a subset of the algorithms described there, allowing any object to be clipped at render time by an arbitrary convex three-dimensional shape.</p><p>The general render-time CSG algorithms require multiple z buffers or multiple rendering passes. On the other hand, the convex-region clipping provided by the renderer described here can be implemented in one pass with only one additional z buffer. The basis for this algorithm can be easily understood by considering that a standard single z buffer can be used to clip away the back of an object, simply by initializing the z buffer to the z values representing a surface behind which the scene is to be clipped away. The normal z comparison used in standard polygon rendering then causes the portions of the scene behind those initial z values to be clipped away.</p><p>Clipping by an arbitrary convex shape requires an additional z buffer to record the front surface of the object to clip against. The standard z-buffer rendering algorithm is modified to compare against the front z buffer as well as the back z buffer. Letting Cface and %face denote the interpolated polygon color and z value, and Cbuf, Zback and zfront denote the color stored in the frame buffer and the z values stored in the front and back z buffers, the frame buffer update algorithm is if %front &gt; zface and Zface &gt; Zba&amp; then</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Zback Zface</head><p>Cbuf + cface fi Note that the back buffer Zback plays the same role in this algorithm as the standard z buffer (for example, it is updated with the object z value to provide standard z-buffer hidden surface elimination), while zfront is the additional z buffer required by the algorithm. This algorithm can be extended in an obvious way to accommodate more complex color update algorithms, such as translucency.</p><p>The front and back z buffers are initialized as follows. First, the back z buffer is initialized to -00, and the front z buffer is initialized to +CO. Then, the polygons defining the boundary of the convex clipping volume are scan-converted, computing only their in- At the end of this process, the front and back z buffers record the front and back extremes of the clipping volume at each pixel. This causes the rendered object to be clipped by the clipping volume when the frame buffer update algorithm described above is used. Note for example that for pixels not contained in the screen projection of the clipping volume, %front is left at +CO and Zback is left at -00, causing the object to be completely clipped away at those points. An illustration of the application of this algorithm is shown in Figures 3 and 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Integrated Rendering</head><p>As discussed above, combining rendering modalities in a single image is an important feature of a visualization renderer. This is illustrated by <ref type="figure" target="#fig_2">Figures 3 , 4</ref> , and 6. Because of the general use of t-buffer algorithms and a display-list list approach in the renderer described here, combining opaque and translucent, clipped and unclipped, points, lines, surfaces and volumes in a single image is straightforward. The general approach is as follows.</p><p>During the first pass of the renderer (as described in section 2), several characteristics of the scene are noted for later use. These include the presence and nature (regular or irregular) of translucent surfaces and volumes, and whether or not clipping is applied to the translucent objects. The presence of clipping or irregular-grid volume rendering triggers the creation of an extra z buffer for the second pass. Then, the second pass begins by first rendering all opaque objects. As each opaque object is rendered, any clipping object to be applied to it is first rendered (using only z values), and the clipping algorithm is used on that object.</p><p>Then, if translucent objects were detected by the first pass, another pass is made to gather and sort the translucent faces. They are then rendered backto-front, using a standard translucent compositing algorithm (for surfaces) or the volume face compositing algorithm (for faces of volume elements) as described above. Before beginning this, any clipping region to be applied to the translucent faces is rendered ( z values only). This implies a limitation that all translucent objects in the scene must have the same clipping object; this is required because the faces of different translucent objects can be intermingled after sorting in any order. During the rendering of the translucent faces, the z values recorded in the z-buffer during the rendering of the opaque and clipping objects are used for visibility and clipping purposes. If the only translucent element in a scene is a single regular array of voxels, a more efficient regular volume rendering algorithm is used. Otherwise, for multiple volumes or irregular volumes, the face-based irregular volume rendering algorithm described above is used.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>The renderer described in this paper demonstrates the feasibility of incorporating into a single renderer several elements we feel are required for scientific visualization: support for parallelism, volume rendering of irregular grids, clipping, and integration of all these elements in a single image. While the renderer described is software-based, it is hoped that setting forth the requirements here may contribute toward support for these algorithms in future generations of rendering hardware.    </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Element-compositing algorithm for tetrahedron and two irregular hexahedra. Tetrahedron may have zero or one intersection(such as A ). Hexahedron may have many intersections( B ,  </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>terpolated z values. The front and back buffers are updated for each interpolated z value by if trace &gt; tfront then if .%face &lt; Zback then Zfront + Zface %back %face</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>A cllpped opaque isosurface of a thunderstorm simulation is combined with a translucent whole isosurface. Also illustrates moderate specularity using linear shading with small triangles. Data courtesy NCSA.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Electron charge density of silicon lattice with interstitial bridge oxygen atom. Volume rendering is combined with opaque mapped plane. Data courtesy MIT.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 :</head><label>5</label><figDesc>Another visualization of sllicon lattice with impurity, illustratlng render-time clipping by a plane.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 6 :</head><label>6</label><figDesc>Simulation of a shape-charge explosion. Volume rendering of irregular tetrahedral grid using irregular-grid face-based algorithm. Volume is combined with opaque color-mapped plane. Data courtesy Los Alamos National Laboratory.(See color plates, p. CP-26.)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>table . I 10 15 20 25 30 4'= 16 6 ' = 3 6 8 ' = 6 4 l o 2 = 100 12'= 144 328 .328 .329 .326 .330 .193 .189 .189 .188 .190 .178 .173 m] .170 .175 .207 .185 .185 .176 .178 .228 .202 .197 .192 .194 3 Irregular Volume Rendering A B</head><label>.</label><figDesc>Volume rendering of regular arrays of voxels has been widely studied and a number of algorithms are known (for example, the work ofLevoy [4]  and Westover<ref type="bibr" target="#b5">[5]</ref>).</figDesc><table /><note></note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Lucas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Abram</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Collins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Epstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">An Architecture for a Scientific Visualization System</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Gresh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mcauliffe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Visualization &apos;92</title>
		<meeting>IEEE Visualization &apos;92</meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A Data Model for Scientific Visualization with Provisions for Regular and Irregular Grids</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Haber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Lucas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Collins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Visualization &apos;91</title>
		<meeting>IEEE Visualization &apos;91</meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Research Report RC-15182, IBM T.J. Watson Research Center</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Epstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Jansen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Rossignac</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1989-11" />
			<pubPlace>Yorktown Heights, NY</pubPlace>
		</imprint>
	</monogr>
	<note>Z-Buffer Rendering from CSG: The Trickle Algorithm</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Efficient Ray Tracing of Volume Data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Levoy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Dansactions on Graphics</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="1990-07" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Footprint Evaluation for Volume Rendering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Westover</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. SIGGRAPH &apos;90</title>
		<meeting>SIGGRAPH &apos;90</meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Ray Tracing Volume Densities</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kajiya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">Von</forename><surname>Herzen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. SIGGRAPH &apos;84</title>
		<meeting>SIGGRAPH &apos;84</meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Raytracing Irregular Volume Data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Garrity</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">5</biblScope>
			<date type="published" when="1990-11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A Coherent Projection Approach for Direct Volume Rendering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wilhelms</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Van Gelder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. SIGGRAPH &apos;91</title>
		<meeting>SIGGRAPH &apos;91</meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">A Polygonal Approximation to Direct Scalar Volume Rendering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Shirley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Tuchman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">C o mputer Graphics</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">5</biblScope>
			<date type="published" when="1990-11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">The A-buffer, an Antialiased Hidden Surface Method</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Carpenter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. SIGGRAPH &apos;84</title>
		<meeting>SIGGRAPH &apos;84</meeting>
		<imprint/>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
