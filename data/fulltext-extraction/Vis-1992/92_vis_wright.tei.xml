<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/pisenberg/grobid/grobid-0.6.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A Voxel-Based, Forward Projection Algorithm for Rendering Surface and Volumetric Data</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><forename type="middle">R</forename><surname>Wright</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julia</forename><forename type="middle">C L</forename><surname>Hsieh</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hughes</forename><surname>Training</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><roleName>CA</roleName><forename type="first">Inc</forename><surname>West Covina</surname></persName>
						</author>
						<title level="a" type="main">A Voxel-Based, Forward Projection Algorithm for Rendering Surface and Volumetric Data</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2021-02-19T20:28+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
				<p>In this paper we present a voxel-bared, forwardprojection algorithm with apipelinearchitecwe forreal-timeapplicawns. The multi-sensor capabilities (electro-optical, or visual, and infrared) currently implemented in sofnvare have also been applied to non-real-time imaging applications on workstations andminicomputers. Most suitedfor terrain basedapplications. the system features haze, imbedded targets, moving objects, smooth shading, and specular reflections.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Introduction</head><p>For the past several years our group at Hughes Aircraft Co., and later Hughes Training, Inc., has been developing voxelbased algorithms for the rendering of surface and volumetric data. This work was originally intended to be used in the construction of real-time image generation systems for use in flight simulatorsandother demanding applications. It has since grown to include non-real-time imaging applications on Workstations and minicomputers. Some of our earlier work was similar to methods presented by Devich and Weinhaus <ref type="bibr">[ 11 but</ref> has been enhanced to offer true perspective from any viewing angle. The rendering algorithm provides several features applicable to flight simulators, such as haze, repositionable target models, smooth shading, and specular reflections, and is designed for implementation on a pipelined processorforreal-timeapplications. 1naddition.theterrainand object databases are implemented using voxels, or volume elements, to provide greater resolution and scene content than is normally available in polygon-based systems. The eyepoint is specifiable with six degrees of freedom as are the positions of the objects. The rendered image is a perspective projection of the voxels to the screen along rays from the database to the eyepoint, This puts it in the class of forward projection algorithms with similarities to the cell by cell pmessiig discussed by Upson and Keeler <ref type="bibr" target="#b1">[2]</ref>. Multiple objects are processed fn&gt;m backto front and range resolvedwi tha modified Z-buffer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Definitions</head><p>The Hughes rendering algorithm uses two types of voxels. calledcase 11 and case III. A case 11 voxel is used torepresent terrain and surface data and is a rectangular solid represented by four comer posts with a surface stretched between them. Each comer has an accompanying height and color which are bilinearly inteqolatd across the surfax. The comer posts are shared between the four neighboring voxels so the surface is contiguous. Normally.only the top of a case I1 voxel is visible. If the side is visible, it w i l l be a constant color. For v d c a l surfaces with some variety, case III voxels are used. A case III voxelcontainsaheightandacolor. whichrepresentabase,and a pointer to a vertical stack of segments, called a pattem, which make up the vertical information resting on top of the base. Eachsegmentin thestackcontainsaheight,orlength,andaleft andrightcolor. The left and rightcolors provide forinteplatim in situations where color varies across thevolumeof the voxel. It also contains surface normal information, for shading and specularity, and some flags. The segments may be opaque, transparent, or translucent, In fact, all voxels can have an opacity anywhere between transparent and opaque. All refexences to color later in this paper include an accompanying opacity and specularity. Repositionable object, such as tanks, trucks, ships,aircraft, explosions, etc., arecomposed of case III voxels. A tenain database may contain embedded case III objects, such as buildings and trees, surrounded by case II voxels. Most of the case 111 objects we have used were voxellized (scanconverted to voxels) from polygon models using techniques developed by <ref type="bibr">Kaufman[3,</ref><ref type="bibr">4.5]</ref>, and Cohen and Kaufman <ref type="bibr" target="#b5">[6]</ref>.</p><p>A database is composed of several layers, each containing a particular type of information such as elevation, color, flags, pattem numbers, etc. The layers are broken up into rectangular regions which represent an area of the database at a given resolution. All the layers within a reaon are correlated with each other through various orthorectification and image mosaicking steps during data-creation. Many of the steps involved are presented by Whiteside <ref type="bibr" target="#b6">[7]</ref>. Multiple resolution levels are generally available for each region providing for lower resolution data over a wide area with high resolution inserts for approaches and other low altitude operations. Each database also has a corresponding pattern segment table con-</p><formula xml:id="formula_0">0-81862897-9/92 SU3.W Q 1992 IEEE eyepoint i ' v p i t 3 to horizon ----_ -_ _ _ _ X Flgure 1 -Six Degrees of Freedom</formula><p>tainiig the pattems for all case III voxels in all regions in the database. Eachdatabaserestsonabaseplanewhichis the(x.y) plane at an elevation (z) value of zero.</p><p>A database can be visual, with an RGB layer, or infrared (IR) with an intensity layer. During the creation process, an IR databasebeginsasmulti-spectralimages Thesemulti-spectral imagesaresegmentedintoareasofsimilarcharacteristicsand the material typesof the areas aredemined. The thermal parameters, such as albedo, emissivity, and conductivity, are then used, along with the sun position and surface normal. to detemine the thermal radiance for each voxel in the database.</p><p>The radiance layer is then rendered the Same as an RGB database. The process for generating these IR databases is discussed by Quarato, et al[81. This method provides for correlatedsensordatabases. Similardatabasescanbeusedfor synthetic ape", real beam, or millime wave RADAR or LASER RADAR (LADAR) imaging. The algorithms for rendering would be somewhat different, however. Brown, et al <ref type="bibr" target="#b11">[9]</ref>, discuss the use of IR simulation algorithms for voxel target models.</p><p>The eyepoint, as well as the positions of moving objects, are specified with six degrees of freedom: x, y, z, roll, pitch, and yaw. The x, y, and z values are specified relative to the origin of the database (e.g. the southwest comer). Yaw is rotation about the z (vertical) axis measured relative to the x axis of the database. Pitch is rotation about the y axis above or below the horizon. Rollisrotationaboutthexaxiswhichistheboresight.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Overview</head><p>The rendering algorithm is divided into two separate pipelineable sections, the voxel pipe and the pixel pipe. Each pipeconsistsofseveralmoduleswhichperform theapproPriate calcuons. The voxel pipe ~ccesses the database voxels along a straight line which is the current column of pixels projected onto the baseplane of the datab9se. This column of voxels is mapped ontothe pixel column which is then processed bythepixelpipeintoacolumnofpixelsacmstheframebuffer. A column of voxels is generated by starting at the nadir, which is the point of the database immediately below the eye, andsteppingoutalongastraghtline. Thestepsa"ined by projecting a pixel column to the baseplane and computing the angle between the line thus generated and the axes of the database. The delta x and delta y are found using the sine and cosine of the computed angle. This fixed pattem of accessing the database means that the rendering time is relatively independent of scene complexity. Each step lands on a voxel which may be either of the two types listed above. If the voxel is case IT, the height and color are b i l i i l y interpolated from the four comers to the step point within the voxel. If the voxel is acase III voxel, the corresponding pattem is located and each segment in thepattem becomesanothervoxelin the column. At this point, each voxel consists of a height, color, and ground range from the eye. From the height of the voxel, the height of the eye, and the ground range to the step point, the depmion angle to the top of the voxel is calculated. This is the angle above orbelow the horizon with the nadir being Wdegrees, the zenith being -90 degrees, and the horizon being zero.</p><p>Knowing the depresion angle to the voxel, as well as the depression angle to the top and bottom of the screen for the current column, it is possible to calculate the fraction of the column being covered by the voxel. Ifa case III voxel is Wi ng processed, the depression angle of both the top and bottom of each pattem segment are used to calculate the coverage. The column isdividedintopixelswitheachpixeloccuWingaf~~ angular portion of the column. Therefore, a voxel is converted to pixels by computing which pixels, or portions of pixels, are coveredbythevoxelthroughsimpleangularcomparisons. The voxels are accumulated into pixels in a front to back d e r .</p><p>Once the entire column of pixels has been generated it goes intothepixelpipe. "laepixelpipetakeseach angularpixeland calculates a screen, or frame buffer, location for it. This is done by usingthede-ion angleof thepixeland theanglebetween the current column and the column at the center of the screen and doing a polar to flat screen coordinate transformation. At the same time, it performs the roll calculation, rotating the pixels to their final (x,y) position. The pixel pipe then performs It is important to note that the voxel columns are projected as planes passing through the eyepoint and the nadir such that they are always perpendicular to the baseplane of the database being rendered. This means that all segments of a vertical pattem will be projected into the same column. However, a column of pixels will not necessarily be parallel to any edge of the screen or even to any other column. In fact, the columns formaradialspokepattem withthenadirorzenithatthecenter, as shown inFigure3. The radial scan technique is similar to that presented by Pa&amp;, et al[lOl. columns needed to complete a subframe within the scan limits previously determined. These are the sine and cosine of the ground column angle (the angle between the projection of the column to the baseplane and the projection of the boresight column), the angle to the bottom and top of the screen (or trim angle) for that column, the delta x and delta y and the diagonal step size. Given the ground column angle, the CPG computes the pitch angle to the top and bottom of the screen for the particular column. Because of the radial scan and roll, the column may actually intersect the sides of the screen instead of topandbottom. TheCPGdetermineswhichsidesofthescreen the column intersects. Using the aspect ratio of the screen, the CPG computes the pitch of the intersection of the column and the edges of the screen. If the nadir is on the screen, then the bottom angleissetto+!Wdegrees. Similarly,if theuppernadir, orzenith,isonthescrwn, then the topangle is setto-Wdegrees.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Details of the Algorithm</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>The Voxel Pipe</head><p>The Coordinate Generator module uses an initial x and y starting position and a delta x and y to generate a series of voxel addresseswhich stepacrossthedatabase. Foreachxand y step, the Coordinate Generator c hecks avalid region table to find the best resolution data available at that (x,y) position. The best resolution is the finestresolutiondataavailablewhich isatleast as coarse as the desired resolution level, determined by slant range. Once it has determined the resolution level of the best data available, it locates the address of that data within the database memory.  The other major function of the Voxel Processor is the planning scan. When the pipeline processor begins to pmas a column, it begins by doing a planning scan at a coarse resolution to determine the correct hierarchies to access for each region. The Voxel Processor computes the desired hierarchies during the planning scan. The correct hierarchy is determined by requiring the system tochoose voxels which are wider than the distance between neighboring columns at that slant range. This causes the algorithm to select coarser and coarser resolution data as it rendem data further from the eyepoint. To find this distance the following formula is used: distance = sin (column angle) x slant range Once this distance is known the appropriate size voxels can be selected. Voxels entering the Pixel Buffer are accompanied by a color, an opacity, a slant range, a depression angle, and some flags. The Pixel Buffer compares the current depression angle andthepreviousdepressionangletotheangularpositionsofthe pixels to determine which whole and partial pixels are covered by this voxel. The whole and partial pixels may be handled two differentways. Abit mapmaybeusedtodeterminetheporrjon of the pixel which has been filled in. This conserves column buffer memory but does not handle translucent pixels well. If a larger column buffer is not a problem, all pixels may be subdivided intosubpixels,eachofwhichactsasasingle, whole pixel in the column buffer. Within each subpixel, the opaque and translucent sections are accumulated independently with each portion coming in being attenuated by the already accumulated translucent portion. The voxels are accumulated into the pixels in a front to back order. Once an opaque voxel fills in a pixel, the pixel is marked as filled and no further contributions are made to it. As pixels are filled in, the Pixel Buffer maintains the depression angle to the top of the filled-in portion of the column. When that angle reaches the top of the screen the column is finished. Then the pixel column is output to the pixel pipe, with each group of n subpixels being accumulated (averaged) into a single output pixel.</p><p>In addition, the Pixel Buffer module performs specularity calculations for the pixels. Since a given voxel, with a specific surface normal, may cover several pixels, the specularity must be computed for each pixel individually. To perform the specularity calculation, the Pixel Buffer uses the depression angle of the pixel and the column angle to compute the vector from the voxel to the eyepoint. Then it uses that vector, along withthevectortothesun,tocomputethebisectingvector. Then the cosine of the angle between the bisecting vector and the surface normal isused,along withthespecularity,orshininess, of thevoxel, tocompute the amountof sunlight being reflected toward the eye. The sunlight is then combined with the smooth shaded intensity computed by the pattern processor to give the final color which this voxel imparts to this particular pixel. Note that the opacity of the specularreflection is dependent on the intensity of the specular highlight, not the opacity of the voxel. Thus,transpmntglasscan haveabrightreflectivespot which masks anything behind it.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>The Pixel Pipe</head><p>Once the entire column of pixels is complete, it must pass down the pixel pipe. The first module is the Pixel Mapper which maps each pixel from polar coordinates to flat screen coordinates. The polar coordinates are repmented by the ground column angle and the pixel's depression angle. Using the pitch. roll, screen size, and fieldof view, the pixel is mapped toan (x.y)positionon thescreen. Then,therollangleasapplied about the center of rotation.</p><p>For improved performance, the calculations are performed with a folded algorithm, as follows:</p><formula xml:id="formula_1">x = k l -k2 tan fi + x-center k3+k4tan0 ,=U-k7tanfi + y-center k3+k4tan8</formula><p>The kn values are subframe and column constants which are computed by the CPG for each column and 0 is the pixel pitch.</p><p>The other function of the pixel Mapper is to implement a hazealgorithm. Thehazeappearsasarepkmentofsomeof the pixel's intensity, in IR or RGB, with some haze intensity. The amount of the pixel's intensity remaining is a function of slant range, pitch, and haze density as follows when pitch # 0 w = ,A.BZ.ye (1 -e%Bsin@itch))/Bsin@itch) and when pitch = 0</p><p>where Rs is slant range from the eye to the pixel, Zeye is the elevation of the eyepoint, pitch is the depression angle of the pixel from the horizon, and A and B are the haze density and vertical distribution parameters, respectively. The haze and origid pixel are combined as follows:</p><formula xml:id="formula_2">I , = I* * WO + * (1.0 -WJ</formula><p>Note that for moving objects it is expected that the haze densitywilleithernotvary significantlyacross them (ithey are far away they should be small) or not be very dense (if they are close the haze should be thin) so the pitch to the centmid of the object is used insteadofthe pixel pitch. This isbecause the pixel pitchofobjectsisintof thesubfiamecoordinatespace,not the terrain coordinate space where the haze exists.</p><p>The Frame Buffer module accepts a column of pixels and blasts them into the frame buffer by accumulating the pixel into eachof the fourcomerpixelsaround theincoming pixel's (x,y) position. The Pixel Mapper module performs the mapping function to a higher degree of accuracy than would be r e q u i d tosimplyfmdtheappmp&amp;e(x,y)positim. 'Iheextramlutim is used to determine the mapped pixel's position within the destination pixel. The accumulation into the four neighboring comer pixels is weighted by the inverse of the distance of the mapped pixel position from each comer. This technique is similar to that presented by Westover[ 121 known as splatting. Each pixel accumulates the sum of the weights of incoming pixels and the sum of theproductsof weight and intensity. 'Ihe weighted pixels are then range resolved in a standard 2-buffer implementation.</p><p>The h e buffer is the primary place where translucent pixels are combined, although it is also done in the pixel baer.</p><p>The algorithm for attenuating colorsvisiblebehinda translucent material can bediffmnt for diffmntapplications. The transport equation defines how background information is attenuated by non-opaquevoxelsinfmnt. Inthevisualband(EO),translucent material is treated as an aerosol. Thus, the more opaque the Theobjectsarerangeordeml from far to near for rendering so the frame buffer can properly range resolve the pixels. This is because the h e buffer does not store opacities, only range and color. Therefore, if a pixel already has a contribution, it is assumed to be opaque. To ensure that this condition matches the actual pixel ordering, the terrain is rendered fmt which fills the screen with opaque pixels. Then each object is rendered and range-resolved with the opaque terrain. The objects may have translucent portions which attenuate the background via the transport equation but the attenuated pixel will still be opaque in the frame buffer. Forexample, when generating acolumn ofpixels, the pixelsare supersampled in the vertical direction and multiple pixels are combined into a single pixel before passing into the pixel pipe.</p><p>Thiscauses the horizontaledgesofobjects tobemoreaccurately sampled to prevent popping from one pixel to the next as well as reducing jaggies along the edge.</p><p>Anotheranti-aliasingtechniqueusediscalledverticalfeature anti-aliasing. Ifa column intersects a vertical feature, such as a wall, at ashallow angle,adjacent voxelcolumns may intersect the wall several voxelsaway. Then, as the eyepoint moves, the columns move over to intersect voxels they missed before and the wall appears to shimmy and flicker. This p b l e m is reduced by combining the contributions of all voxels along the wall which the column passes through. The algorithm uses the angle between the column and the surface normal of the wall to determine how many steps it will take for the column to pass from the front of the wall to the back. Then the opacity of the voxel is modified (reduced) proportionately to how many steps remain. The last voxel remains opaque to make sure the wall doesn't appear translucent. This technique is equivalent to supersampling the wall voxels without the cost of extra pixels or columns. <ref type="figure" target="#fig_7">Figure 5</ref> illustrates this technique.</p><p>Ofcourse, this technique assumes that the horizontal distance between two columns is less than the width of a voxel. This is handled by the&amp;"teGeneratorby selectingtheappmpriate resolution voxels based on the slant range from the eye to the voxel. This process also performs an additional anti-aliasing function in that no voxels can be missed by adjacent columns. If voxels could be missed, flickering would occur as voxels were hit and then missed as the eyepoint moved.</p><p>Another technique, discussed previously, is blasting, or splatting,intheframebuffer. hapixelenters the framebuffer, it contributes to four adjacent pixels ppodonately to the inverse of its distance from the comers. This prevents edges from popping from one pixel to the next. In addition to blasting, the edges of moving objects, or subftames, are detected and blended with thebackground pixels for smoother edges with fewer jaggies and less popping.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head><p>Here are some examples of images generated using the Hughes rendering algorithm. The resolution is approximately 30 meters per voxel with the original image source data being Landsat photos. <ref type="figure">Figure 8</ref> is a model of the San O n o h nuclear power plant inserted in a terraindatabaseofupstateNew York. Thepowerplantmodel has a resolution of about four feet per voxel while the terrain resolution is about six inches per voxel. The model has been scaled to one-fourth of its normal size, relative to the terrain. Note the smooth shading on the domes. <ref type="figure" target="#fig_13">Figure 9</ref> shows a "'72 tank model simng behind a case III tree model. The tank was voxellized at three inch resolution from a polygon model. 'Ihe tree was grown fractally and then v o x e l l i i <ref type="figure" target="#fig_14">Figure 10</ref> shows a view of the Camp Pendleton Marine Base in southem Califomia showing haze. The algorithm has also been used to render smoke cubes, missile plumes, and a rotating helicopter rotor blade.</p><p>TheHughesalgorithm hasbeenimplementedinC,onaSun      <ref type="figure" target="#fig_9">plates, p. CP-36,)</ref> hardwareisaboutthreeordersofmagnitudefasterthanthe Sun for this algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conclusions</head><p>The Hughes rendering algorithm produces high quality images both for terrain and threedimensional models. It can beimplementedinsoftwareorspecial-p~hasdware which can deliver real-time performance. It provides several feahues considered important for flight simulation applications but is also useful for non-real-time applications, such as mission planning, imagery for hardwm in the loop testing, and virtual reality. It can render multiple sensor images of correlated databases with high resolution in the output image. Its pipelineable, modular design suggests that it could perform well on a massively parallel architecture.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>The boresight is defined as a line passing through the eyepoint and the center of the screen.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure</head><label></label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>Theprojectionofvoxelstothe~,ratherthantheprojection ofpixels to the database, is thehahakof a forward projection algorithm. Figm 2 illusbates the perspective projection of voxels to the screen.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 2 -</head><label>2</label><figDesc>Perspectlve Projection and Resolution Selection a Z-buffer range resolution function by discarding pixels behind those already on the screen and then integrates the visible pixels into neighboring positions in the frame buffer.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 Figure 3 -</head><label>43</label><figDesc>contains a block diagram of the modular structure of the rendering algorithm implementation. The modules included in the diagram will be discussed in more detail individually.The Initialize System module initializes the system, loads the database, and initiates the Erame rendering. The database load function,deservesabitofexplanation.Thebasic function istoloadadatabaseregionandtoupdatethevalidregiontables for the Caordinate Generator module. The valid region tables contain the information about what regions,at what resolution levels, are valid for which areas of the database. Multiple regions,whichmaypartiallyorfdlyoverlap, maybeloadedfor a given resolution level. The Render Frame module performs some frame initialization calculations. reads in the eye and object positions for the frame, and then renders the subframes by initiating the appr0priar.e modules. In particular, the frame initialization includes sorting the moving objects based on range. 'Ihe subframes are rendered terrain fKst (if any), and then any moving objects from far to near. This ordering is important because the pixels must enter the frame buffer in a far to near order for proper accumulation and attenuation if translucencies are involved. The Initialize Subfmne module then performs the subframe initialization tasks such as determining object visibility, scan limits, trim angles, and pixel subtend angle, and transforming the eye position in world coordinates to the eye position in subframe coordinates. The scan limits calculation insures that all pixels on the screen are generated, yet minimize the number of columns and pixels per column, it is desirable to trim the columns at the edges of the screen, or at the l i m i t s of the object, prior to generating the pixels. To do this, it is necessary to use the screen parameters (width, height, field of view, pitch, roll, etc.) to generate the appropxiate column parameters. The rendering of a single frame is broken down into the rendering of multiple subframeS. Each subframe consists of rendering a single database, meaning the terrain, or a single object. The rendering of a subframe is done under the control of the Column Parameter Generator (CPG) module. The CFG generates various parameters for the processing of each of the Radial Scan 8cBn</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>TheVoxelProcessoracceptsastrm ofvoxelswhichhave been prepared by the Pattem Processor and calculates the depression angle and slant range to each. The slant range and depression angle are calculated from the ground range from the eye to the voxel (as determined by the number of step taken to get there), the height of the voxel above the base plane, and the height of the eye above the base plane. Voxels are procesd as rectangular solids so they have theappmpriatecross-section at any viewing angle.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 2 Figure 4 -</head><label>24</label><figDesc>illustrates the selection of approPriate sized voxels based on slant range. To avoid a large processing database . ) pattern + voxel ) . Modular Composition of Rendering Algorithm overhead for the planning scan, the voxel data several levels of resolution coarser than expected shall be used for the plan, if available. This method allows us to determine the desired hierarchy for the voxels but does not allow us to locate hidden regions or determine the number of steps to the first voxel visible on the screen.The Pixel Buffer is one of the most sophisticated functions in the renderer. It accepts voxels from the Voxel Processor module and produces pixels which are stored in the column buffer. The column buffer is included within the Pixel Buffer module. Theincomingvoxelshaveaslantrangeanddepression angle which the Voxel Processor calculated. The depression angle and the voxel's color and opacity are the primary values used when generating pixels.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Flgure 5 -</head><label>5</label><figDesc>Top Vlew of Vertlcal Feature Antl-allaslng (a) WRhout Vertical Feature Antl-allaslng(b) Wlth Vertlcal Feature Anti-allaslng material, the more of it will be seen and the less of the background If the material is transparent, it provides no color to the pixel at all. In contrast, in the infrared (IR) band, the transmissivityand theemissivity ofamaterial may berelatively independent. Therefore,amaterialcouldbe totally transparent, andthuspassthroughallthebgckgroundcontribution,andstill emitinthesamewaveband,thuscontributingadditionalintensity to the pixel. The actual transport equations are:Ip = Ifg * ofg + Ibg * (1.0-ofg) for Eo Ip = Ifg + I b * (1.0 -Ofg) for IRwhere Ip is the final pixel intensity, Ifg is the foreground materialintensity,Ibgisthebackgroundmaintensity,Ofg is theopacity of the foreground material,and 0, is theopacity of the background material. Note that the di#erence in the equations is that the intensity contribution of each material is a function of its own opacity in theE0 equation but not in the IR equation.TheDisplaymodulenormalizestheaccumula~intensiti~ in the frame buffer by dividing by the accumulated weights to generate the final image. If the desired image is to be in thevisualband, threechaMels(red.green,andblue)areprocessed, while a single channel is processed for infrated. When rendering moving objects. each object is mdered as anindividualsub~andthepixelimagesare~ge-resolved andmergedwithiithefhmebuffer. Eachobjectisrepresented as an individual database and rendered independently. 'Ihe initialize subframe module transforms the eyepoint in world coordinatesandtheobjectpositioninworld~~tesintoan eyepointinobjectcoordinates,relativetotheoriginandaxesof the object database. Multiple objects may be rendered in each frame, and multiple copies of the same object, in different positions, mayalsoberendered.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head></head><label></label><figDesc>Thus, theobjectsmustbemdered from far tonear toensure the proper accumulation of aanslucent colors. This back to front processing is similar to that presented by k b m , et al[131. Anti-aliasing Aliasing is a significant p b l e m in real-time rendering applications. Problems which are invisible in a single frame becomeghingwhenasequenceofframesaredisplayedinreal time. Thm temporal aliasing problems include flickering, swimming, strobing, and other anomalies. Of course, spatial aliasing problems, such as jaggies, need to be controlled as well. The Hughes rendering algorithm employs several techniques for controlling both spatial and temporal aliasing.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 6</head><label>6</label><figDesc>is a rendered image of Yosemite valley showing Cathedral Rocks. The Yosemite database is courtesy of Geospectra Corpomion. The terrain resolution is about eight feet per voxel. Figure 7 is a rendeml image of Orange County, Califomia, looking east from the ocean. 'IhisdatabaseisalsocowofGeoSpectraCorporation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head></head><label></label><figDesc>SPARCStation2 with20megabytesofmemoryandrunningX windows, and in special purpose hadware. The hardware development effort, the REALSCENE" program, implemented the algorithm using a pipelined architecture virtually identical to figure 4. Each module was implemented as a separate board in a custom backplane chassis. This hardware implementation has been extensively simulated in FORTRAN. The C version is significantly faster than the FORTRAN simulation because it does not try to emulate the low-level hardware details. For a 384 by 384 pixel image, the following rendering rimes have been mor&amp; this comparison, no case III voxels were present in the database, nor were any moving objects present.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Figure 6 :</head><label>6</label><figDesc>Cathedral Rocks, Yosemite Valley.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Figure 7 :Figure 8</head><label>78</label><figDesc>Orange County, California. Power plant.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Figure 9 :</head><label>9</label><figDesc>T72 tank and fractal tree.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>Figure 10 :</head><label>10</label><figDesc>Camp Pendleton, California. (See color</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>The Database Memory module accepts a column of voxel addresses and accesses its memory to retrieve the color and elevation information forthe four neighbor comers. Ifthevoxel isoftypecaseII,thefourcornersarethen bilinearly inteplated incolorandelevationandafdvoxelisproduced. Ifthevoxel is III, the appmpriate data is retrieved. access the pattem memory to retrieve the vertical color and elevation information above the base voxel. Each piece of vertical information, called a segment. becomes a separate voxelwithinrhevoxelmys. Toensurethepoperaccumulation of voxels into pixels, the httem Processor module will output the stack of segments from the eye elevation up and then down.This ensures that all voxels will contribute to pixels from the nearest to the farthest. Within the voxeVpixel column, the voxels are processed from front to back. Certain flags must be set to ensure that the voxels going up and those going down are</figDesc><table><row><cell>Thehttem~modulehandlesthevoxels processed appp&amp;ly.</cell></row></table><note>whichare case III. The case III voxelscause t h e F " Processor moduletoIn addition, the h a e m Processor performs smooth shading calculations for the case III voxels. Each case III pattem segment has a horizontal and a v d c a l orientationvalue. Usingthesunposition,thePattemProcessor computestheincidentsunangleforeachsegmentandcombines the sunlight color, the ambient light color, and the voxel color using the following formula: I, = I,, * ( I , + I, * cos (incident angle)) Theformulaiscomputedforeachchanne1,onceforIRorthree times for RGB. This is a standard formula as discussed by FoleyandVan DamUlI.</note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>The authors wish to thank Tom Ellis, Andy Roman, and many other Hughes people who contributed to thedevelopment of this algorithm and the varied implementations of it.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Rural Image Perspective Transformations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="middle">R N</forename><surname>Devich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="middle">F M</forename><surname>Weinhaus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of SPIE</title>
		<meeting>SPIE</meeting>
		<imprint>
			<date type="published" when="1981" />
			<biblScope unit="volume">303</biblScope>
			<biblScope unit="page" from="54" to="66" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">VBUFFER: Visible Volume Rendering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Upson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="middle">M</forename><surname>Keeler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of SIGGRAPH</title>
		<meeting>SIGGRAPH</meeting>
		<imprint>
			<date type="published" when="1988-08" />
			<biblScope unit="page" from="59" to="64" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">3DScan-ConversionAlgorithms for Voxel-Based Graphics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kaufman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Andshimony</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 1986 ACM WorkshoponInteractive3DGraphics</title>
		<meeting>1986 ACM WorkshoponInteractive3DGraphics</meeting>
		<imprint>
			<date type="published" when="1986-10" />
			<biblScope unit="page" from="45" to="76" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Efficient Algorithms for 3D ScanConversion of Parametric Curves, Surfaces, and Volumes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="middle">A</forename><surname>Kaufman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">proceedings of SIGGRAPH</title>
		<meeting>SIGGRAPH</meeting>
		<imprint>
			<date type="published" when="1987-07" />
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="171" to="179" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">An Algorithm for 3D ScanConversion of Polygons</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kaufman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">FkoCeeh gs EUROGRAPHICS</title>
		<imprint>
			<date type="published" when="1987-08" />
			<biblScope unit="page" from="197" to="208" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">3D ScanConversion Algorithms for Linear and Quadratic Objed&apos;, Volume Visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kaufman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1990" />
			<publisher>IEEE Comp~ter Soci~ty Press</publisher>
			<biblScope unit="page" from="280" to="301" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Whiteside</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Preparing DataBases For Perspective Scene Generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">E</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceediigs of SPIE. vol. 1075 Digital Image Processing Applications</title>
		<meeting>eediigs of SPIE. vol. 1075 Digital Image essing Applications</meeting>
		<imprint>
			<date type="published" when="1989" />
			<biblScope unit="page" from="230" to="237" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="middle">J</forename><surname>Quarato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="middle">S</forename><surname>Brown</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Nguyen</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">VoxelTerrain Material Database and Synthetic IR Scene Generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Malpass</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="middle">W</forename><surname>Thursby</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Andhester</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Ground Target Modelling and Validation Conference</title>
		<meeting>Ground Target Modelling and Validation Conference</meeting>
		<imprint>
			<date type="published" when="1991-04" />
			<biblScope unit="page" from="68" to="88" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">VoxelBased IRTarget Signature and Scene Generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Quarato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="middle">J</forename><surname>Wright</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Malpass</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Thursby</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Andhester</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Ground Target Modelling and Validation Conference</title>
		<meeting>Ground Target Modelling and Validation Conference</meeting>
		<imprint>
			<date type="published" when="1991-04" />
			<biblScope unit="page" from="89" to="103" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Patz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="middle">P</forename><surname>Gatt</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Real Scan Evolution&quot;, report prepared for Naval Training Equipment Center</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Becker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Richie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Leblanc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Coulter</surname></persName>
		</author>
		<idno>80-D-0014-2</idno>
		<imprint>
			<date type="published" when="1982-02" />
		</imprint>
	</monogr>
	<note>This report is in the public domain and should be available through the University of Central Floridaor the Naval Training Equipment Center</note>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Fundamentals of Interactive Computer Graphics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Foley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Van Dam</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1982" />
			<publisher>Addison-Wesley</publisher>
			<pubPlace>Reading, Mass</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Footprint Evaluation for Volume Rendering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="middle">L</forename><surname>Westover</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of SIGGRAPH</title>
		<meeting>SIGGRAPH</meeting>
		<imprint>
			<date type="published" when="1990-08" />
			<biblScope unit="page" from="367" to="376" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
