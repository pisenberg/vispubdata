<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/pisenberg/grobid/grobid-0.6.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Volume Rendering of Fine Details Within Medical Data</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Feng</forename><surname>Dong</surname></persName>
							<email>fdong@dmu.ac.uk</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gordon</forename><forename type="middle">J</forename><surname>Clapworthy</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mel</forename><surname>Krokos</surname></persName>
							<email>melk@dmu.ac.uk</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer &amp; Information Sciences</orgName>
								<orgName type="institution">De Montfort University</orgName>
								<address>
									<country key="GB">U.K</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<address>
									<addrLine>Kents Hill, Milton Keynes</addrLine>
									<postCode>MK7 6HP</postCode>
									<country key="GB">United Kingdom</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<address>
									<settlement>San Diego</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Volume Rendering of Fine Details Within Medical Data</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2021-02-19T20:44+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>I.3.3[Computer Graphics]: Picture/Image Generation -Viewing Algorithms; I.3.7[Computer Graphics]: Three Dimensional Graphics and Realism -Color</term>
					<term>shading</term>
					<term>shadowing</term>
					<term>and texture Volume Rendering</term>
					<term>Fine Details</term>
					<term>Medical Visualization</term>
					<term>Image Processing</term>
					<term>Volume Textures</term>
				</keywords>
			</textClass>
			<abstract>
				<p>This paper presents a method concerning the volume rendering of fine details, such as blood vessels and nerves, from medical data. The realistic and efficient visualization of such structures is often of great medical interest, and conventional rendering techniques do not always deal with them adequately. Our method uses preprocessing to reconstruct fine details that are difficult to segment and label. It detects the presence of fine geometrical structures, such as cracks or cylinders that suggest the existence of, for example, blood vessels or nerves; the subsequent volume rendering then displays fine geometrical objects that lie on a surface. The method can also show structures within the volume, using a special &quot;integration sampling&quot; scheme to portray reconstructed volume texture, such as that exhibited by muscle fibers. By combining the surface structure and volume texture in the rendering, realistic results can be produced; examples are provided.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Volume rendering has become an important approach to data visualization. It is capable of producing images of great quality in many applications, and has been applied particularly successfully in medical visualization.</p><p>Compared with the alternative of surface rendering, the major advantage of volume rendering is that it can make use of data from both the surface of an object and within it, instead of being constrained only to show data associated with a surface identified by thresholding. This is particularly valuable in medical visualization, where the dataset often contains many complex objects with a wide range of sizes, and where relationships between objects that are vastly different in size can be of critical importance. In such circumstances, a simple set of iso-surfaces will usually fail to portray all of the detail that is required. However, though great progress has been made in volume rendering research, most of the current technologies are still not fully competent to exhibit fine, detailed structures within the volume, such as blood vessels, muscle textures or nerves.</p><p>Currently, the most common approach to handling the display of tiny structures is to pay extra attention to labeling the associated data during segmentation, and then to display them in a straightforward way during the rendering stage. However, this does not always work well because of particular circumstances:</p><p>• the need to segment the data before rendering means that prior knowledge is required about all the subjects inside the volume, which implies that the image cannot show tiny objects or structures whose presence is not anticipated in advance; • this pre-segmentation method cannot be applied to features such as muscle textures, since it is impossible to perform segmentation on them. This paper addresses these problems. It considers the rendering of two forms of fine details that are present in anatomical data:</p><p>• fine geometric structures such as blood vessels, nerves, and small cracks on the muscle surface; these objects are characterized by being long and relatively narrow -often only a few voxels wide. • textures such as those found within muscles.</p><p>Visualization of fine geometric structures is handled through the gradients at the voxels. This is based on the observation that gradients change rapidly around tiny objects. A single preprocessing stage is applied to the volume data to estimate the gradients at two different levels. One level generates smooth gradients; these are used in place of normals in rendering the smooth underlying object with all the fine details removed. The other level identifies tiny structures from gradients based on a more local estimate and adds these to the smooth surface.</p><p>Muscle textures are formed by the muscle fibers that lie inside the volume. These are sampled from the volume data within the surface. Direct volume data sampling was found to produce poor results. The algorithm presented here adopts 3D image processing to identify the orientations of the muscle fibers within the volume; then integration sampling, a data-sampling method, is used during the rendering to portray the muscle texture.</p><p>This approach is objective since we need not know in advance where the tiny structures are situated, which is important as this can often vary from subject to subject. And it can provide greater information by allowing the visualization of objects that would otherwise have been ignored or incompletely displayed.</p><p>The performance of the algorithm is controlled by a set of parameters: smSize, bWidth, sLength, sWidth and hWinSize, which will be explained in Sections 4 and 5. The complete algorithm consists of several stages, during each of which some of these parameters are employed to control the results. As these parameters are independent of each other, the outcome of the parameter modification at a particular stage can be assessed immediately, without waiting for the completion of the whole algorithm. This makes it easier to determine the parameters that are appropriate for a particular dataset.</p><p>The method presented here provides a general strategy for displaying fine detailed structures, and is especially suitable for those lying upon a base object or that exhibit textures, which are both common scenarios in medical data. While the data used in this paper were colored anatomical cross-section images from the Visible Human project of the National Library of Medicine, the method is not particular to the Visible Human data, and it could also be applied to CT &amp; MRI data.</p><p>The paper is organized as follows: Section 2 introduces related work, Section 3 gives an overview of the algorithm, Sections 4 and 5 provide the details of the algorithms, the results are given in Section 6 and, finally, conclusions are drawn in Section 7.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK</head><p>Volume rendering has always been particularly attractive in the medical field, and many algorithms have been formulated to improve its quality and speed.</p><p>A commonly-used strategy has been to re-sample the discrete volume data and present them in a 2D image. These approaches have included casting rays and re-sampling data along the rays: Levoy <ref type="bibr" target="#b10">[11]</ref>, Tiede et al. <ref type="bibr" target="#b19">[20]</ref>, Wan et al. <ref type="bibr" target="#b21">[22]</ref>; constructing and splatting kernels at each voxel: Westover <ref type="bibr" target="#b22">[23]</ref>, Laur &amp; Hanrahan <ref type="bibr" target="#b9">[10]</ref>, Mueller et al. <ref type="bibr" target="#b15">[16]</ref>, Mueller &amp; Crawfis <ref type="bibr" target="#b14">[15]</ref>, Swan et al. <ref type="bibr" target="#b18">[19]</ref>; or projecting cells on to a image: Wilhelms &amp; Van Gelder <ref type="bibr" target="#b23">[24]</ref>.</p><p>Considerable efforts have also been made to reduce the computational cost, using Fourier domain rendering: Totsuka &amp; Levoy <ref type="bibr" target="#b20">[21]</ref>; shear warp: Lacroute &amp; Levoy <ref type="bibr" target="#b8">[9]</ref>; and hardware texture mapping: Cabral <ref type="bibr" target="#b2">[3]</ref>. Alternatively, multiresolution or wavelets can be used to display the data at different levels of detail: Gross et al. <ref type="bibr" target="#b7">[8]</ref>, Dong et al. <ref type="bibr" target="#b5">[6]</ref>, Pan et al. <ref type="bibr" target="#b17">[18]</ref>. Based on various rendering methods, several visualization systems have been built, examples are VolVis, Avila et al. <ref type="bibr" target="#b0">[1]</ref>; VolumePro, Meißner et al. <ref type="bibr" target="#b11">[12]</ref>; and Volumizer, Eckel <ref type="bibr" target="#b6">[7]</ref>.</p><p>As far as data re-sampling is concerned, most of the existing methods construct the data using local schemes that perform interpolation using linear, quadratic, cubic or even higher-order functions in areas neighboring each voxel. However, the objects of interest are not necessarily small in all directions, for example, blood vessels are very narrow but quite long. Local data resampling schemes provide no guarantee of keeping the consistency of these fine details over the full length of the object. It may be possible to label these details, though this is often difficult, or to use some special treatment to highlight them such as the Maximum Intensity Projection, Mroz et al. <ref type="bibr" target="#b13">[14]</ref>, Cai &amp; Sakas <ref type="bibr" target="#b4">[5]</ref>, though this requires that the data values of the object of interest can be easily distinguished from those of the surrounding tissues.</p><p>This also holds true when estimating gradients in the volume data. The gradients, which are often used in place of surface normals, are of great importance in displaying fine details. Many authors have produced work on normal (or gradient) estimation, for example, Neumann et al. <ref type="bibr" target="#b16">[17]</ref> and Moller et al. <ref type="bibr" target="#b12">[13]</ref>. Neumann's method was based on 4D linear regression. The basic idea was to fit an approximate function to the density in a local neighborhood with a 3D regression hyperplane. Moller et al. compared the performances of four possible normal-estimation schemes in volume rendering in terms of their numerical accuracy and efficiency. They showed that inexpensive schemes may, in fact, be more accurate than high-order methods. However, these locally-based estimation schemes do not support accurate reconstruction of the arrangements of the normals around fine, detailed structures such as blood vessels or nerves.</p><p>The algorithm presented in this paper focuses on gradient estimation and the presentation of volume data in a manner most appropriate for the rendering of fine details contained in medical data. It can, by the use of volume data, both extract tiny structures lying on a surface, and display volume textures that lie beneath the surface. These techniques are effective in depicting tiny structures contained in the data, in spite of their narrowness and the presence of some noise; they also greatly improve the realism of tissues such as muscles.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">OVERVIEW</head><p>The algorithm is performed in several phases. Two pre-processing steps are involved:</p><p>• searching for fine geometrical structures is performed by reconstructing the normals around these tiny structures using a two level scheme (Sections 4.3 &amp; 4.4) • identifying volume textures using 3D image processing, including edge detection and Hough transform (Section 5.1); texture orientations are expressed in terms of a vector field. It is necessary to perform the pre-processing steps only once. Independent parameters are used to control their performance. The results of setting individual parameters can be assessed separately, which is a great advantage.</p><p>Once the fine geometrical structures and volume textures have been identified, the rendering, which is based on ray-casting, makes use of them to display the data from different view directions. The normals are used to depict the geometry. A vector field representing the texture orientation is created by a data sampling scheme called "integration sampling" and is used to portray the volume textures. This will be described in Section 5.2</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">RENDERING OF FINE DETAILS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Geometrical Tiny Structures</head><p>The geometrical tiny structures of interest here are fine objects in medical data, such as blood vessels, nerves, etc. They can be rendered if the data gradients (or normals) around them are correctly reconstructed, but it is difficult to decide how to accomplish this. A delicate rendering approach will retain all of the detailed tiny structures but may produce artifacts because of noise in the data, while coarser approaches may produce smooth results but lose some, or even all, of the desired tiny structures. <ref type="figure">Figure 1</ref> shows examples of rendering a muscle (rectus femoris)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 1. Rendering with Different Approaches to</head><p>Constructing the Gradients from the Visible Human data using two different gradientreconstructing approaches. In the left image, the data gradient at each voxel is reconstructed using a large neighboring volume (9×9×9), while in the right image, it is reconstructed using a smaller volume (3×3×3). The left image has lost most of the fine details, while the right image displays too many artifacts; neither is satisfactory. The basic idea of the method described in this section springs from the observation that many tiny objects can be regarded as small items lying on a smooth base surface. Thus, the object can be identified as a small localized aberration from an overall, relatively smooth, pattern by comparing the general characteristics within a region to the detailed local behavior.</p><p>The basic procedure is, firstly, to extract the base object with the smooth surface and then to add the detailed structures on top of it. Correspondingly, a two-level scheme is employed to tackle the gradient (or normal) estimation problem. The lower level gives the smooth gradients (Section 4.3), and the higher level adds detailed tiny structures or objects (Section 4.4). Both of these levels are based on the estimation of local gradients (Section 4.2). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Local Gradients</head><formula xml:id="formula_0">-1 -2 -2 -1 -4 -2 -1 -2 -1 2.b 1 2 1 2 4 2 1 2 1 Z -1 -2 -1 -2 -4 -2 -1 -2 -1 0 0 0 0 0 0 0 0 0 2.c</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 2. 3D Gradient Operator</head><p>The local gradients at each voxel are calculated by a 3D operator in a 3 ×3×3 neighboring sub-volume. The three components of the 3D operator used are shown in <ref type="figure">Figure 2</ref>. Each cell represents a voxel in the sub-volume, and the number shown is the weight associated with the cell during the operations. The sub-volume is drawn in three separated columns to enable the weights to be seen. Figures 2a, 2b and 2c are used to compute the x, y and z components of the gradient, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Lower Level: Smooth Gradients</head><p>The local gradients produced by the above gradient operator are fed into a module that uses principal component analysis to find a smoothed gradient for each voxel, as described below.</p><p>Assume that V is a voxel whose gradient is about to be smoothed. NeighborSet (V) is a set containing all the voxels in a neighboring volume of V of size smSize, where smSize is an adjustable control parameter. To compute the smoothed gradient at V, the covariance matrix of NeighborSet (V) is formed. </p><formula xml:id="formula_1">∑ ∈ ⊗ = ) ( ) ( V t NeighborSe k k k M M V Matrix r r</formula><p>Here, the ⊗ denotes a product vector operator, which forms a 3×3 matrix from two vectors as follows: the (p,q) entry of the matrix is The smSize parameter is used to control the size of the region within which the normals are smoothed.</p><p>During the rendering, viewing rays are cast into the volume until their associated accumulated opacity reaches 1.0. Throughout this process, the smooth gradients produced in the last step can be interpolated at the sampling points along the cast ray and normalized, for use in the illumination model when computing the lighting at each sampling point. These are then summed up to determine the final contribution of the cast rays.</p><p>This leads to an image of a smooth surface with, however, the loss of the detailed tiny structures, the inclusion of which will be addressed in the next section.</p><p>In practice, one would try several values for smSize and compare the results visually, retaining the appropriate value for the next stage in the processing. A typical value would be 9 voxels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Higher Level: Add Tiny Structures</head><p>This algorithm searches in the space of the local gradients generated in Section 4.2 for two kinds of geometrical tiny structures:</p><p>• cylinders, such as produced by blood vessels and nerves • cracks, such as occur on a muscle surface and adds them to the smooth surface. <ref type="figure" target="#fig_3">Figure 3</ref> shows 2D cross-sections for a cylinder and a crack. The black arrows illustrate the arrangements of the normals around a cylinder and a crack, respectively. Notice that there are normals under the surface of cracks/cylinders. This is because the cracks/cylinders are often semi-transparent.  To detect the cracks/cylinders, we identify the arrangement of their normals, using the local gradients created in Section 4.2.</p><p>To do this for the entire volume dataset would be very time consuming, since the number of voxels, each of which has a local gradient, is usually quite large.</p><p>However, the cracks/cylinders occur either on the surfaces of organs, or at boundaries between different materials and these areas constitute a relatively small subset of the overall number of voxels.</p><p>Thus, before we commence the search for the cracks/cylinders, we construct a boundary set of voxels lying within a specified distance, bWidth, of the object boundary. We check each voxel of the object in a neighboring sub-volume bWidth× bWidth× bWidth. If any neighboring voxel lies outside the object, this voxel is identified as a member of the boundary set. The distance, bWidth, is used as a control parameter and is normally set to be 3-4 voxels, though the user can increase this if it is believed that the crack/cylinder is deeper.</p><p>The subsequent search for the cracks/cylinders is then restricted to the boundary set.</p><p>The arrangement of normals around cracks/cylinders, as shown in <ref type="figure" target="#fig_3">Figure 3</ref>, enables them to be identified. The common characteristic of cracks/cylinders is that each has a central skeleton on which the unit normals are the same as the unit normal of the base object. As we move away from the skeleton, the normals move outwards (for a cylinder) or inwards (for a crack), as shown in <ref type="figure" target="#fig_3">Figure 3</ref>.</p><p>Thus, if we subtract the unit normal of the base object from the local unit normals of a tiny structure, the resultants on the skeleton are zero, while around the skeleton the resultant vectors point away from the skeleton (for a cylinder) or towards it (for a crack).</p><p>It should be borne in mind that the use of the smooth gradients calculated in Section 4.3 effectively flattens the cracks/cylinders on to the base surface. Their 3D form is restored by use of the local gradients. That is, when we require gradients, for the base surface we use the smooth gradients, while for the tiny objects we use the local gradients.</p><p>To identify the cracks/cylinders within the boundary set, we first find the skeletons, which are expressed in terms of arrays of voxels in the central areas. We then search in the neighboring voxels of the skeletons to find the other voxels in these structures. <ref type="figure" target="#fig_5">Figure 4</ref> illustrates the procedure, for each voxel V from the boundary set, to determine whether V belongs to a skeleton, where v s n n r r , are, respectively, the smooth and local gradients for V, and r n r is their difference.  This produces the candidate skeletons of the tiny structures. For each of these, all of the neighboring voxels are checked to see if they unanimously point towards, or away from, the skeleton. If so, a cylinder or crack has been identified. Then, all the remaining voxels next closest to the skeleton are checked. This continues until the vectors at the new set of voxels do not unanimously orient any more. All the identified tiny structures are stored.</p><p>This procedure identifies the cracks/cylinders in which the normals orient unanimously towards/away from the skeleton. This is robust and does not require the fine details to form perfect cylindrical shapes. Small bumps in blood vessels can be detected as long as all their normals have the same orientation towards/away from the skeleton.</p><p>Two parameters are used to describe the size of a crack/cylinder -sLength denotes the length of the skeleton, and sWidth denotes the width, which is the distance from the skeleton to the most outlying voxel in the cylinder/crack.</p><p>Thresholds for sLength and sWidth are introduced to control the size of the cracks/cylinders to be displayed.</p><p>The local gradients associated with the identified cracks/cylinders that extend beyond these thresholds are added to the smooth gradients. This results in the correct arrangements of normals for cracks/cylinders. As this process is restricted to the volume surrounding the tiny structures, it does not introduce artifacts into the remainder of the volume.</p><p>The rendering, which shows the fine details on top of the smooth surface, is used to judge if the thresholds have been set appropriately. Higher thresholds result in the display of fewer tiny structures, while lower ones lead to more, though some of these may be artifacts. If the results are unsatisfactory, the thresholds are re-set and the tiny structures are re-selected.</p><p>A typical example of volume texture is in muscles. Each muscle has a unique texture, formed by the muscle fibers. We can see the muscle textures in the colored images of the Visible Human dataset slice by slice.</p><p>The conventional way of sampling the Visible Human data in the volume produces very poor results in muscle rendering -the image shows hardly any muscle fiber orientation and texture, see <ref type="figure">Figure 5</ref>.</p><p>The algorithm presented in this section employs 3D image-processing techniques to determine the fiber orientation at each voxel. This is performed as pre-processing and has to be done only once for a volume dataset. Integration sampling, a special datasampling scheme, is used during rendering, to sample the volume data at each sample point on the cast rays. This technique is borrowed from flow visualization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Fiber Orientations</head><p>Three steps are taken to find the fiber orientations, which are expressed in terms of vectors: (i) rough calculations provide the approximate direction of fiber orientation at each voxel, (ii) a 3D-edge operator is applied to the whole volume data to find the data points for fibers, (iii) direction-limited Hough transforms are carried out to find the exa ct fiber orientations. For each voxel, the Hough transform just searches straight lines in limited directions around the approximate fiber orientation found in the first step. This is a more efficient approach than the original Hough transform, which searches the whole space.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.1">Search for Possible Directions</head><p>This is a quick search in which we try to find a rough direction for the fiber orientation at each voxel. It provides a base direction around which the Hough transform will be performed in step (iii). In other words, only directions falling into ranges around the results from this quick search are regarded as possible fiber orientations.</p><p>For a particular voxel, V, the 26 neighboring voxels are checked to find which has the color closest to that of V. This is straightforward for greyscale data since there is only one value to be compared at each voxel. However, in a color-image dataset, as used in this paper, each voxel has three color components. Each component must be compared at different weights since one component may dominate and others may contribute less to colors, for example, muscle data are mainly red in color. In order to do this, three mean values, r ave , g ave and b ave are calculated for the red, green and blue colors, respectively, over the subject, and three coefficients λ red , λ green and λ blue are calculated as: These three coefficients are then used to compare the color in terms of the following empirical formula: <ref type="table">b  a  blue  b  a  green  b  a  red   B  B  G  G  R  R  −  ×  +  −  ×  +  −  ×  λ  λ  λ</ref> where R, G, B are red, green and blue color components, and a, b are subscripts denoting the two voxels being compared. For muscles, expected values would be λ red = 0.8, λ green = λ blue = 0.1, approximately.</p><formula xml:id="formula_2">λ red = r</formula><formula xml:id="formula_3">| | | | | |</formula><p>Once the neighboring voxel that has the closest color to that of V is selected, the direction from V to the selected voxel is regarded as the approximate fiber orientation for step (iii).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.2">3D Edge Detection</head><p>A 3D Gaussian smoothing operator G <ref type="figure">(x,y,z)</ref>, is applied to the volume: where σ is a parameter of the filter. This is followed by the Laplace operator ∇ 2 which gives the second derivative. In fact, the combination of the Gaussian smoothing operator and the Laplace operator is the 3D Marr-Hildreth edge operator, which detects the zero-crossings of the second derivative, exploiting the fact that a step edge corresponds to an abrupt change in the colors of voxels in the volume. This detection needs to be done only once. The advantage of the Marr-Hildreth operator over the others is that the noise, which normally affects the edge operation, is smoothed before edge detection.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.3">Hough Transform</head><p>The results of the edge detection are unorganized data points that conceptually form edge points. They are fed into the Hough transform, which is used to identify the lines formed by the unorganized data points.</p><p>The Hough transform, Ballard <ref type="bibr" target="#b1">[2]</ref>, searches among the edge points for a main direction line starting from each voxel. This line implies the fiber orientation. The number of unorganized data points produced from the edge operation is generally quite large. As a result, the standard Hough transform will encounter difficulties because of the number of lines that may be detected and the computational time involved.</p><p>To resolve this problem, the search at each voxel takes place amongst only neighboring voxels within a (three-dimensional) window centralized at that voxel. The size of the window, hWinSize, can be modified. It gives the size of the physical space in which the Hough transform is performed.</p><p>In fact, the selection of the value for hWinSize is not unique. We could choose a bigger value than necessary since this just means that the Hough transform is performed in a larger physical space; as a result, it influences the speed rather than the actual outcome.</p><p>In this sense, the selection of hWinSize value is not sensitive. It was found that a value of 21 gives good results for all the data used in this paper. This is good as the Hough transform takes time and an insensitive hWinSize implies that there is no need to implement the Hough transform many times to select an appropriate value for hWinSize.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 5. Direct Data Sampling</head><p>Further, the Hough transform carries out the 3D search only within a certain 3D angle around the base orientation found in step (i), which greatly reduces the amount of computation. The search is to find the line that passes through the greatest number of edge points within the window; this is selected to form the fiber orientation at this voxel.</p><p>The above is applied to every voxel and results in a vector field that gives the fiber orientation throughout the volume.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Rendering with Integration Sampling</head><p>Once the vector field representing the fiber orientation is established, integration sampling is used to portray the volume texture.</p><p>Integration sampling is borrowed from the line integral convolution (LIC) technique, which works well in the representation of 2D flow fields in flow visualization -see Cabral &amp; Leedom <ref type="bibr" target="#b3">[4]</ref>. The basic procedure of line integration in a vector field is to generate a noise field, and then integrate in the vector field to produce curves in the noise field. These curves are colored according to their paths in the noise field, which are determined by the vectors.</p><p>Similarly, in our method, before rendering begins, a 3D white noise field is assigned to the volume data. Rendering is based on ray casting, and several points are sampled for each ray cast. At each sampling point, an integral is performed. It starts from the sampling point, and integrates in the vector field. Throughout this process, it interpolates the noise value, v, and the red, green, blue components, r, g, b, at each integration step and sums as:</p><formula xml:id="formula_4">∑ ∑ ∑ × = × = × = j j j total j j j total j j j total b v b g v g r v r</formula><p>where the sum is over all the integration steps, j. The integration results, r total , g total , b total , are assigned to the sampling point as the result of data sampling at that point.</p><p>We take sample values at all the sampling points on the ray. These values are summed and used as the final contribution of this ray.</p><p>The results of the rendering in this section, which concentrates more on volume effects, are combined with the outcomes of Section 4, which focuses more on surfaces, to produce the final images, which will be described in Section 6.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">RESULTS</head><p>The volume data used in this work is from the Visible Human dataset and has voxels of size 0.3×0.3×1.0mm arranged on 1878 data slices; each slice has 1760×1024 pixels. The data is roughly segmented; major organs and muscles are labeled, but fine detailed structures are not.</p><p>The methods were implemented on a Pentium III 666MHz PC with 256 MB of RAM.</p><p>Before rendering, any "uninteresting" data can be discarded in a straightforward manner, so the actual sizes for the datasets used for <ref type="figure">Figures 6, 7, 8, 9</ref> are 207×150×520, 200×160×530, 250×200×500, 130×120×130, respectively. However, the remaining data still contains many tiny structures that cannot be labeled, such as nerves on a muscle surface, blood vessels on the heart surface, and muscle textures. <ref type="figure">Figures 6 &amp; 7</ref> show results of muscle rendering. <ref type="figure">Figure 6</ref> is half of the human upper body, approximately from the chest to the abdomen, including muscles such as the pectoralis and the rectus abdominis. <ref type="figure">Figure 7</ref> is the rear view of the upper leg. These figures demonstrate not only the cracks on the muscle surfaces, but also the textures. <ref type="figure">Figure 8</ref> illustrates muscles together with the nerves. It is the front view of the upper leg and the nerves are lying at the front of the leg. The muscle in the centre, with two nerves on its surface, is the rectus femoris, which is also rendered using traditional methods in <ref type="figure">Figures 1 &amp; 5</ref>. From the comparison we can see that the rectus femoris in <ref type="figure">Figure 8</ref> possesses a smooth surface with the geometrical adjuncts (nerves) on it, and the rendering explicitly illustrates the fibers via textures. <ref type="figure">Figure 9</ref> depicts the heart and includes the heart muscles and the blood vessels; the left coronary artery, the right coronary artery and their small branches are clearly visible. <ref type="table" target="#tab_1">Table 1</ref> provides the timing results for the main parts of the implementation of the examples listed above. Although the paper deals mainly with rendering quality, this table gives a hint of the time complexity of the proposed methods. Bear in mind that the processing can be divided into several phrases, each of which is assessed independently. "Geometry" concerns the detection and rendering of the geometrical tiny structures, which is associated with Section 4, and "Texture" concentrates on the texture presentation, which is the issue in Section 5.</p><p>As far as the geometrical tiny structures are concerned, three results are given. "LowL" and "HighL" denote the lower and higher levels in the estimation of normals. "Ren1" means the rendering with the geometrical fine details. We can see that finding the smooth gradients (LowL) is more time consuming than the other steps. The results were produced with smSize having a value of 9. This step may have to be repeated several times to find the best value for smSize.</p><p>The most time-consuming parts for the volume texture are the Hough transform, which is denoted as "HT" in <ref type="table" target="#tab_1">Table 1</ref>, and integration-sampling based rendering, which is "Ren2" in the <ref type="table">Table.</ref> The Hough transform was performed with the parameter hWinSize at a value of 21. In practice, we found this value worked well for all four examples.</p><p>As mentioned in Section 4, LowL, HighL and HT belong to the pre-processing stage, which is performed only once, before rendering commences (Ren1 and Ren2). Compared with the high quality rendering work performed by Tiede et al. <ref type="bibr" target="#b19">[20]</ref>, the work presented in this paper portrays more volume effects. The key idea of their work was to calculate the object boundary accurately, thus enabling a more precise computation of the grey-level gradient yielding the surface normal. Consequently, the rendering can produce only surfacelike results and lacks volume information. The location of the object boundary was calculated under local interpolation scheme.</p><p>A feature of our work is to employ distinct methods to identify the fine details that it is desired to display during rendering. These methods are global in the sense that they are not just carried out in areas neighboring each voxel. The fine geometrical structures are identified by searching the whole dataset; volume textures are visualized through a vector field that can express the texture information of the whole dataset. Thus, medical details that are not dealt with well under a local interpolation scheme are displayed realistically.</p><p>Of course, the rendering quality is achieved at the cost of extra time spending on the pre-processing and rendering <ref type="table" target="#tab_1">(Table 1)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">CONCLUSION</head><p>Small, fine objects and structures are frequently important, and sometimes critical, in medical visualization. Often, they are very difficult to segment and display.</p><p>The methods described in this paper can detect and display two kinds of tiny structures contained in medical data without the need for pre-labeling and segmentation. One is a tiny object on a surface, such as a crack or a blood vessel. The other is volume texture as found within muscles.</p><p>The presence of these tiny objects is displayed by properly constructing the gradients for the underlying base objects, then identifying and adding fine details on top of the base. The search for the tiny objects is carried out by matching the pattern of gradients normally exhibited by such structures to patterns exhibited within the data.</p><p>The volume texture is reconstructed using 3D image-processing techniques, and is expressed in terms of the unit vectors at each voxel. During the rendering, a special data-sampling scheme, "integration sampling" is used to depict the texture.</p><p>Future work aims to achieve results over a wide range of soft tissues. We expect to focus on the rendering of soft tissues such as fat, liquid, and their mixtures with muscles and bones in medical complexes, which can produce more realistic images containing more accurate medical information. We shall also consider approaches to speed up the pre-processing and rendering. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>If k N r is the local gradient at voxel k within NeighborSet (V), average N r is the unweighted average vector over all the voxel gradients in NeighborSet (V), and covariant matrix is defined by:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>M</head><label></label><figDesc>is the x, y, or z component of k M r if p is 1, 2 or 3, respectively, and q k M is defined similarly. Among the three eigenvectors of Matrix(V), we choose the one on to which the sum of projections of the k M r over NeighborSet (V) is the smallest. This vector gives the smoothed gradient for V.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 .</head><label>3</label><figDesc>Normals around a Cylinder(above) and a Crack (below)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 4 .</head><label>4</label><figDesc>The Algorithm to Identify Skeletons</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head></head><label></label><figDesc>ave / (r ave + g ave + b ave ) λ green = g ave / (r ave + g ave + b ave ) λ blue = b ave / (r ave + g ave + b ave )</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 6 .Figure 7 .Figure 8 . 9 .</head><label>6789</label><figDesc>Rendering of Muscles Rendering of Muscles Muscles &amp; Nerves Figure Muscles &amp; Blood Vessels</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 .</head><label>1</label><figDesc>Timing Results (seconds)</figDesc><table><row><cell>Fig.</cell><cell></cell><cell>Geometry</cell><cell></cell><cell cols="2">Texture</cell></row><row><cell></cell><cell cols="3">LowL HighL Ren1</cell><cell>HT</cell><cell>Ren2</cell></row><row><cell>6(436×842)</cell><cell>353</cell><cell>7</cell><cell>56</cell><cell>321</cell><cell>102</cell></row><row><cell>7(422×842)</cell><cell>382</cell><cell>16</cell><cell>63</cell><cell>352</cell><cell>126</cell></row><row><cell>8(454×722)</cell><cell>552</cell><cell>18</cell><cell>91</cell><cell>506</cell><cell>156</cell></row><row><cell>9(466×474)</cell><cell>56</cell><cell>3</cell><cell>12</cell><cell>47</cell><cell>36</cell></row></table><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">ACKNOWLEDGEMENTS</head><p>This research is supported by the Information Society Technologies Programme of the European Commission within the project VAKHUM (IST-1999-10954).</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Volvis: A Diversified Volume Visualization System</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Avila</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kaufman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Pfister</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Silva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Sobierajski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Visualization &apos;94</title>
		<imprint>
			<publisher>IEEE Computer Society Press</publisher>
			<date type="published" when="1994" />
			<biblScope unit="page" from="31" to="38" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Generalizing the Hough Transform to Detect Arbitrary Shapes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">H</forename><surname>Ballard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="111" to="122" />
			<date type="published" when="1981" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Accelerate Volume Rendering and Tomographic Reconstruction Using Texture Mapping Hardware</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Cabral</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ACM/IEEE Symposium on Volume Visualization</title>
		<meeting>ACM/IEEE Symposium on Volume Visualization</meeting>
		<imprint>
			<date type="published" when="1994" />
			<biblScope unit="page" from="91" to="97" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Imaging Vector Fields using Line Integral Convolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Cabral</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">C</forename><surname>Leedom</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. SIGGRAPH&apos; 93</title>
		<meeting>SIGGRAPH&apos; 93</meeting>
		<imprint>
			<publisher>Addison Wesley</publisher>
			<date type="published" when="1993" />
			<biblScope unit="page" from="263" to="270" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Maximum Intensity Projection Using Splatting in Sheared Object Space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Sakas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics Forum</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="113" to="124" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Fast Volume Rendering and Data Classification Using Multiresolution Min-Max Octrees</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Krokos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">J</forename><surname>Clapworthy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics Forum</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="359" to="369" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">OpenGL Volumizer Programmer&apos;s Guide</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Eckel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Silicon Graphics Computer Systems</title>
		<imprint>
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">A New Method to Approximate the Volume Rendering Equation Using Wavelet Bases and Piecewise Polynomials</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Lippert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Dreger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Koch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computers &amp; Graphics</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="47" to="62" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Fast Volume Rendering Using a Shear-Warp Factorization on the Viewing Transformation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Lacroute</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Levoy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. SIGGRAPH&apos; 94</title>
		<meeting>SIGGRAPH&apos; 94</meeting>
		<imprint>
			<publisher>Addison Wesley</publisher>
			<date type="published" when="1994" />
			<biblScope unit="page" from="451" to="458" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Hierarchical Splatting: A Progressive Refinement Algorithm for Volume Rendering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Laur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Hanrahan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="285" to="288" />
			<date type="published" when="1991" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Efficient Ray Tracing of Volume Data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Levoy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer Graphics &amp; Applications</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="29" to="37" />
			<date type="published" when="1988" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Volume Visualization and Volume Rendering Techniques</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Meißner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Pfister</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Westermann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">M</forename><surname>Wittenbrink</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In : Tutorials</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<date type="published" when="2000" />
		</imprint>
	</monogr>
	<note>Eurographics</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">A Comparison of Normal Estimation Schemes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Moller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Machiraju</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Mueller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Yagel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Visualization &apos;97</title>
		<imprint>
			<publisher>IEEE Computer Society Press</publisher>
			<date type="published" when="1997" />
			<biblScope unit="page" from="19" to="26" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Interactive High-Quality Maximum Intensity Projection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Mroz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Hauser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Gröller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics Forum</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="341" to="350" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Eliminating Popping Artifacts in Sheet Buffer-based Splatting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Mueller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Crawfis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Visualization &apos;98</title>
		<imprint>
			<publisher>IEEE Computer Society Press</publisher>
			<date type="published" when="1998" />
			<biblScope unit="page" from="239" to="245" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Splatting Without The Blur</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Mueller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Moller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Crawfis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Visualization &apos;99</title>
		<imprint>
			<publisher>IEEE Computer Society Press</publisher>
			<date type="published" when="1999" />
			<biblScope unit="page" from="363" to="370" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Gradient Estimation in Volume Data Using 4D Linear Regression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Neumann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Csebfalvi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Konig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Gröller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics Forum</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="351" to="358" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Level of Details and Multiresolution Modeling for Virtual Prototyping</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Image and Graphics</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1" to="15" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">An Anti-Aliasing Technique for Splatting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">E</forename><surname>Swan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Mueller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Moller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Shareef</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Crawfis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Yagel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Visualization &apos;97</title>
		<imprint>
			<publisher>IEEE Computer Society Press</publisher>
			<date type="published" when="1997" />
			<biblScope unit="page" from="197" to="204" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">High Quality Rendering of Attributed Volume Data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Tiede</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Schiemann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">H</forename><surname>Höhne</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Visualization &apos;98</title>
		<imprint>
			<publisher>IEEE Computer Society Press</publisher>
			<date type="published" when="1998" />
			<biblScope unit="page" from="255" to="262" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Frequency Domain Volume Rendering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Totsuka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Levoy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. SIGGRAPH&apos;93</title>
		<meeting>SIGGRAPH&apos;93</meeting>
		<imprint>
			<date type="published" when="1993" />
			<biblScope unit="page" from="271" to="278" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">High Performance Presence-Accelerated Ray Casting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kaufman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bryson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Visualization &apos;99</title>
		<imprint>
			<publisher>IEEE Computer Society Press</publisher>
			<date type="published" when="1999" />
			<biblScope unit="page" from="379" to="386" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Footprint Evaluation for Volume Rendering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Westover</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="367" to="376" />
			<date type="published" when="1990" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">A Coherent Projection Approach for Direct Volume Rendering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wilhelms</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Van Gelder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="275" to="284" />
			<date type="published" when="1991" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
