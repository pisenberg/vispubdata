<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/pisenberg/grobid/grobid-0.6.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Lagrangian-Eulerian Advection for Unsteady Flow Visualization</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bruno</forename><surname>Jobard</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gordon</forename><surname>Erlebacher</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Yousuff Hussaini</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">School of Computational Science and Information Technology</orgName>
								<orgName type="institution">Florida State University</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<address>
									<settlement>San Diego</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Lagrangian-Eulerian Advection for Unsteady Flow Visualization</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2021-02-19T20:45+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
				<p>In this paper, we propose a new technique to visualize dense representations of time-dependent vector fields based on a Lagrangian-Eulerian Advection (LEA) scheme. The algorithm produces animations with high spatio-temporal correlation at interactive rates. With this technique, every still frame depicts the instantaneous structure of the flow, whereas an animated sequence of frames reveals the motion a dense collection of particles would take when released into the flow. The simplicity of both the resulting data structures and the implementation suggest that LEA could become a useful component of any scientific visualization toolkit concerned with the display of unsteady flows.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Traditionally, unsteady flow fields are visualized as a collection of pathlines or streaklines that originate from user-defined seed points <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b7">8]</ref>. More recently, several authors have developed techniques based on dense representations of the flow to maximize information content <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b9">[10]</ref><ref type="bibr" target="#b10">[11]</ref><ref type="bibr" target="#b11">[12]</ref>. The fundamental challenge faced by this class of algorithms is to produce smooth animations with good spatial and temporal correlation.</p><p>In this paper, we propose a new visualization algorithm based on dense representations of time-dependent vector fields. The method combines the advantages of the Lagrangian and Eulerian formalisms. A dense collection of particles is integrated backward in time (Lagrangian step), while the color distribution of the image pixels are updated in place (Eulerian step). The dynamic data structures normally required to track individual particles, pathlines, or streaklines are no longer necessary since all information is now stored in a few two-dimensional arrays. The combination of Lagrangian and Eulerian updates is repeated at every iteration. A single time step is executed as a sequence of identical operations over all array elements. By its very nature, the algorithm takes advantage of spatial locality and instruction pipelining and can generate animations at interactive frame rates.</p><p>The rest of the paper is organized as follows. Section 2 gives an overview of related work. The general approach is described in Section 3 while the algorithm is examined in Section 4. Postprocessing options are proposed in Section 5. Timing results are presented in Section 6. Conclusions are drawn in Section 7.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>Several techniques have been advanced to produce dense representations of unsteady vector fields. Best known is perhaps UFLIC (Unsteady Flow LIC) developed by Shen <ref type="bibr" target="#b11">[12]</ref>, and based on the Line Integral Convolution (LIC) technique <ref type="bibr" target="#b1">[2]</ref>. The algorithm achieves good spatial and temporal correlation. However, the images are difficult to interpret: the paths are blurred in regions of rapid change of direction, and are thickest where the flow is almost uniform. The low performance of the algorithm is explained by the large number of particles (three to five times the number of pixels in the image) to process for each animation frame.</p><p>The spot noise technique, initially developed for the visualization of steady vector fields, has a natural extension to unsteady flows <ref type="bibr" target="#b2">[3]</ref>. A sufficiently large collection of elliptic spots is chosen to entirely cover an image of the physical domain. The position of these spots is integrated along the flow, bent along the local pathline or streamline, and finally blended into the animation frame. The rendering speed of the algorithm can be increased by decreasing the number of spots in the image. The control of pixel coverage is done by assigning a fixed lifespan to each spot.</p><p>Max and Becker <ref type="bibr" target="#b9">[10]</ref> propose a texture-based algorithm to represent steady and unsteady flow fields. The basic idea is to advect a texture along the flow either by advecting the vertices of a triangular mesh or by integrating the texture coordinates associated with each triangle backward in time. When texture coordinates or particles leave the physical domain, an external velocity field is linearly extrapolated from the boundary. This technique attains interactive frame rates by controlling the resolution of the underlying mesh.</p><p>A technique to display streaklines was developed by Rumpf and Becker <ref type="bibr" target="#b10">[11]</ref>. They precompute a two-dimensional noise texture whose coordinates represent time and a boundary Lagrangian coordinate. Particles at any point in space and time that originate from an inflow boundary are mapped back to a point in this texture.</p><p>More recently, Jobard et al. <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b5">6]</ref> extend the work of Heidrich et al. <ref type="bibr" target="#b3">[4]</ref> to animate unsteady two-dimensional vector fields. The algorithm relies heavily on extensions to OpenGL proposed by SGI, in particular, pixel textures, additive and subtractive blending, and color transformation matrices. They pay particular attention to the flow entering and leaving the physical domain, leading to smooth animations of arbitrary duration. Excessive discretization errors associated with 12 bit textures are addressed by a tiling mechanism <ref type="bibr" target="#b4">[5]</ref>. Unfortunately, the graphics hardware extension this algorithm relies on most, the pixel texture extension, was not adopted by other graphics card manufacturers. As a result, the algorithm only runs on the SGI Maximum Impact and the SGI Octane with the MXE graphics card.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Lagrangian-Eulerian Approach</head><p>We wish to track a collection of particles i p , along a prescribed time-dependent velocity field, that densely covers a rectangular region. If we assign a property i P p to the th i particle i p , the property remains constant as the particle follows its pathline. At any given instant t , each spatial location x has an associated particle, labeled t p x . One expresses that the particle property is invariant along a pathline by 0</p><formula xml:id="formula_0">t t t P p P p t w w x v x x<label>(1)</label></formula><p>The property attached to each particle takes on the role of a passive scalar. Its value is therefore not affected by diffusion or source terms (associated with chemical or other processes). This equation has two interpretations. In the first, the trajectory of a single particle, denoted by</p><formula xml:id="formula_1">t p x</formula><p>where p tags the particle, satisfies ( ) ,</p><formula xml:id="formula_2">t t t d p p dt x v x<label>(2)</label></formula><p>In this Lagrangian approach, the trajectory of each particle is computed separately. The time evolution of a collection of particles is displayed by rendering each particle by a glyph (point, texture spot <ref type="bibr" target="#b2">[3]</ref>, arrows). Except for recent work of Jobard et al. <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b5">6]</ref>, current time-dependent algorithms are all based on particle tracking, e.g. <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b11">12]</ref>. While Lagrangian tracking is well suited to the task of understanding how dense groups of particles evolve in time, it suffers from several shortcomings. In regions of flow convergence, particles may accumulate into small clusters that follow almost identical trajectories, leaving regions of flow divergence with a low density of particles. To maintain a dense coverage of the domain, the data structures must support dynamic insertion and deletion of particles <ref type="bibr" target="#b11">[12]</ref>, or track more particles than needed <ref type="bibr" target="#b2">[3]</ref>, which decreases the efficiency of any implementation.</p><p>Alternatively, an Eulerian approach solves (1) directly. Particles lose their identity. However, the particle property, viewed as a field, is known for all time at any spatial coordinate. Unfortunately, any explicit discretization of (1) is subject to a Courant condition <ref type="bibr" target="#b0">1</ref> , so that in practice, the numerical integration step is limited to at most 1-2 cell widths. In turn, this imposes a maximum rate at which flow structures can evolve.</p><p>In our approach, we choose a hybrid solution. Between two successive time steps, coordinates of a dense collection of particles are updated with a Lagrangian scheme whereas the advection of the particle property is achieved with an Eulerian method. At the beginning of each iteration, a new dense collection of particles is chosen and assigned the property computed at the end of the previous iteration. We refer to the hybrid nature of this approach as a Lagrangian-Eulerian Advection (LEA) method.</p><p>To illustrate the idea, consider the advection of the bitmap image shown in <ref type="figure" target="#fig_1">Figure 1a</ref> by a circular vector field centered at the lower left corner of the image. With a pure Lagrangian scheme, a dense collection of particles (one per pixel) is first assigned the color of the corresponding underlying pixel. Each particle advects along the vector field and deposits its color property in the corresponding pixel in a new bitmap image. This technique does not ensure that every pixel of the new image is updated. Indeed, holes usually appear in the resulting image ( <ref type="figure" target="#fig_1">Figure 1b)</ref>.</p><p>A better scheme considers each pixel of the new image as a particle whose position is integrated backward in time. The particle position in the initial bitmap determines its color. There are no longer any holes in the new image ( <ref type="figure" target="#fig_1">Figure 1c</ref>). Repeating the process at each iteration, any property can be advected while maintaining a dense coverage of the domain.</p><p>The core of the advection process is thus the composition of two basic operations: coordinate integration and property advection. </p><formula xml:id="formula_3">h h t i j i j i j d 9 9 9 ³ x x v x<label>(3)</label></formula><p>at a previous time step. h is the integration step,</p><formula xml:id="formula_4">, i j 9 x</formula><p>represents intermediary positions along the pathline passing through , t i j x , and 9</p><p>v is the vector field at time 9 .</p><p>An image of resolution W H u , defined at a previous time t h , is advected to time t through the indirection operation</p><formula xml:id="formula_5">&gt; &gt; , 0 , 0 , , user-specified value otherwise t h h h t i j W H i j u° ®°I x x I<label>(4)</label></formula><p>which allows the image at time t to be computed from the image at any prior time t h</p><p>. This technique was used by Max <ref type="bibr" target="#b9">[10]</ref>.</p><p>However, instead of integrating back to the initial time to advect the same initial texture <ref type="bibr" target="#b9">[10]</ref>, we choose h to be the interval between two successive displayed images and always advect the last computed image.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Algorithm</head><p>With our Lagrangian-Eulerian approach, a full per-pixel advection requires manipulating exactly W H u particles. All information concerning any particle is stored in two-dimensional arrays with resolution W H u at the corresponding location , i j . Thus, we store the initial coordinates  N is then prepared for the next iteration by subjecting it to a series of treatments (left column in <ref type="figure" target="#fig_3">Figure 2</ref>). Care is first taken to ensure that no spurious artifacts appear at boundaries where flow is entering the domain (Section 4.5). This is followed by an optional masking process to allow for non-rectangular domains (Section 4.6). A low percentage of random noise is then injected into the flow to compensate for the effects of pixel duplication and flow divergence (Section 4.7). Finally, the coordinate arrays are reinitialized to ready them for the next iteration (Section 4.8). The right column in the flowchart describes the sequence of steps that transform the second advected noise array a N into the final image. a N is first accumulated into b N via a blending operation to create the necessary spatio-temporal correlation (Section 4.9). Two optional post-processing phases are then applied to b N before its final display: a line integral convolution filter removes aliasing effects (Section 5.1) and features of interest are emphasized via an opacity mask (Section 5.2).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Notation</head><p>Array cell values are referenced by the notation , i j A with i and j integers in ^`^0,.., 1 0,.., 1 W H u . We adopt the convention that an array , x y A with real arguments is evaluated from information in the four neighboring cells using bilinear interpolation. A constant interpolation is explicitly noted</p><formula xml:id="formula_6">, x y « » « » ¬ ¼ ¬ ¼ A</formula><p>, where x « » ¬ ¼ is the largest integer smaller than or equal to x . To simplify the notation, array operations such as A B apply to the entire domain of ( , ) i j . </p><formula xml:id="formula_7">The indirection operation , , , , i j r i j s i j A B C D ,</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Coordinate and Noise Initialization</head><p>We first initialize the coordinate arrays x C , y C and the noise arrays N and b N . Coordinates are defined as , r a n d1 , r a n d1</p><formula xml:id="formula_8">x y i j i i j j °® °C C<label>(5)</label></formula><p>where rand(1) is a real number in &gt; 0,1 . The random offset distributes coordinates on a jitter grid to avoid regular patterns that might otherwise appear during the first several steps of the advection. Note that the integer part of the coordinates identifies the cell.</p><p>N is initialized with a two-valued noise function (0 or 1) to ensure maximum contrast and its values are copied into b N . Coordinates and noise values are stored in floating point format to ensure sufficient accuracy in the calculations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Coordinate Integration</head><p>A first order discretization of Equation (3) is used to integrate the particle coordinates. After discretization with a constant time step h over the entire domain, (3) becomes</p><formula xml:id="formula_9">max max / , / , V V V V x x x W x H y y y y W x H y h V r r h V r r c °® c °C C V C C C C V C C<label>(6)</label></formula><p>where max V is the maximum velocity magnitude in the whole dataset, The velocity arrays at the current time are linearly interpolated between the two closest available vector fields. Therefore, h represents the maximal possible displacement of any particle over all iterations. The actual displacement of a particle is proportional to the local velocity and is measured in units of cell widths.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">/</head><formula xml:id="formula_10">V W V</formula><p>A useful property of a first order formulation is that the velocity is never required outside the physical domain. We have implemented a second order discretization, but found no noticeable effect due to the small extent of the spatio-temporal correlations in the final display.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Noise Advection</head><p>The advection of noise described by Equation <ref type="formula" target="#formula_5">4</ref>is applied twice to N to produce two noise arrays c N and a N , one for advection, one for display. c N is an internal noise array whose purpose is to carry on the advection process and to re-initialize N for the next iteration. To maintain a sufficiently high contrast in the advected noise, c N is computed with a constant interpolation. Before c N can be used in the next iteration, it must undergo a series of corrections to account for edge effects, the presence of arbitrary domains, and the deleterious consequences of flow divergence. </p><formula xml:id="formula_11">a Wx Hy i b j b i j b i j b i j r i j b r i j b c c c « » « » ¬ ¼°¬ ¼ ® c c °N N C C N N C C<label>, , , , , x y</label></formula><p>for all ^`^, 0,. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Edge Treatment</head><p>A recurring issue with texture advection that must be addressed is the proper treatment of information flowing into the physical domain. Within the context of this paper, we must determine the user-specified value in Equation (4). To address this, we recall that the advected image contains a two-valued random noise with little or no spatial correlation. We take advantage of this property to replace the user-specified value by a random value (0 or 1). At each iteration, we simply store new random noise in the buffer zone, at negligible cost.</p><p>At the next iteration, N will contain these values and some of them will be advected to the interior of the physical domain by Equation <ref type="formula" target="#formula_12">7</ref>. Since random noise has no spatial correlation, the advection of the surrounding buffer values into the interior region of c N produces no visible artifacts.</p><p>To treat periodic flows in one or more directions, the noise values are copied from an inner strip of width b along the interior edge of c N onto the buffer zone at the opposite boundary. As a result, particles leaving one side of the domain seamlessly reappear at its opposite side. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6">Incoming Flow in Arbitrary Shaped Domains</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.7">Noise Injection</head><p>In this Section, we propose a simple procedure to counteract a To illustrate the source of noise duplication, we consider an example. <ref type="figure">Figure 4</ref> shows the evolution of property values and particle positions for four neighboring pixels during one integration and one advection step. The vector field is uniform, is oriented at 45 degrees to the x axis, and points towards the upper right corner. At the start of the iteration, each particle has a random position within its pixel <ref type="figure">(Figure 4a</ref>). To determine the new property value of each pixel, the particle positions are integrated backwards in time <ref type="figure">(Figure 4b</ref>). The property value of the lower left corner pixel is duplicated onto the four pixels (worst-case sce-  <ref type="figure">(Figure 4c</ref>). The fractional position of each particle is then re-initialized for the next iteration.</p><p>Over time, the average size of contiguous constant color regions in the noise increases. This effect is undesirable since lower noise frequency reduces the spatial resolution of the features that can be represented. This duplication effect is further reinforced in regions where the flow has a strong positive divergence.</p><p>To break the formation of uniform blocks and to maintain a high frequency random noise, we inject a user-specified percentage of noise into c N . Random cells are chosen in c N and their value is inverted (a zero value becomes one and vice versa). The number of cells randomly inverted must be sufficiently high to eliminate the appearance of pixel duplication, but low enough to maintain the temporal correlation introduced by the advection step.</p><p>To quantify the effect of noise injection, we compute the energy content of the advected noise in N at different scales as a function of time. Although the Fourier transform would appear to be the natural tool for this analysis, the two-valued nature of the noise image suggests instead the use of the Haar wavelet (linear combination of Heaviside functions). We perform a twodimensional Haar wavelet transform and compute the level of energy in different bands (the spatial scale of consecutive bands vary by a factor of two). The two-dimensional energy spectrum is reduced to a one-dimensional spectrum by assuming that the noise texture is isotropic at any point in time. (The smooth anisotropic flow result from blending multiple noise textures.) The energy in each band is scaled by its value after the initial noise injection. Ideally we would like to preserve the initial spectrum at all time. <ref type="figure" target="#fig_8">Figure 5</ref> illustrates the influence of the noise injection on the time evolution of the energy spectrum. Without injection, the energy in the larger scales (regions of pixel duplication) increases rapidly without stabilizing. This comes at the expense of some energy loss in the smaller scales (which decreases in the figure). As the percentage of noise injection increases, the spread of the scaled spectrum decreases continuously towards zero (the ideal state). However, excessive injection deteriorates the quality of the temporal correlation.</p><p>The necessary percentage of injected noise is clearly a function of the particular flow and depends on both space and time. It should be modeled as the contribution of two terms: a constant term that accounts for the duplication effects at zero divergence, and a term that is a function of the velocity divergence. In the interest of simplicity and efficiency, we use a fixed percentage of two to three percent, which provides adequate results over a wide range of flows.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.8">Coordinate Re-Initialization</head><p>The coordinate arrays are re-initialized to prepare a new collection of particles to be integrated backward in time for the next iteration. However, coordinates are not re-initialized to their initial values. The advection equations presented in Section 3 assume that the particle property is computed at the previous time step via a linear interpolation. Unfortunately, the lack of spatial correlation in the noise image would lead to a rapid loss of contrast, which justifies our use of a constant interpolation scheme. However, the choice of constant interpolation implies that a property value can only change if it originates from a different cell. If the coordinate arrays were re-initialized to their original values at each iteration, subcell displacements would be ignored and the flow would be frozen where the velocity magnitude is too low. This is illustrated in <ref type="figure">Figure 6</ref>, which shows the advection of a steady circular vector field. Constant interpolation without fractional coordinate tracking clearly shows that the flow is partitioned into distinct regions within which the integer displacement vector is constant <ref type="figure">(Figure 6a</ref>).  To prevent this from happening, we track the fractional part of the displacement within each cell. Instead of re-initializing the coordinates to their initial values, the fractional part of the displacement is added to cell indices ( , ) i j :</p><formula xml:id="formula_13">, ,<label>, , , , x x</label></formula><formula xml:id="formula_14">x y y y i j i i j i j i j j i j i j c c « » ¬ ¼°® c c « » °¬ 1 C C C C C C<label>(8)</label></formula><p>The effect of this correction is shown in <ref type="figure">Figure 6b</ref>.</p><p>The coordinate arrays have now returned to the state they were in after their initialization phase (Equation (5)); they verify the relations</p><formula xml:id="formula_15">, x i j i « » ¬ ¼ C and , y i j j « » ¬ ¼ C .</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.9">Noise Blending</head><p>Although successive advected noise arrays are correlated in time, each individual frame remains devoid of spatial correlation. By applying a temporal filter to successive frames, spatial correlation is introduced. We store the result of the filtering process in an array b N . We have found the exponential filter to be convenient since its discrete version only requires the current advected noise and the previous filtered frame. It is implemented as an alpha blending operation</p><formula xml:id="formula_16">(1 ) b b a , , N N N (9)</formula><p>where , represents the opacity of the current advected noise array. A typical range for , is &gt; @ 0.05,0.2 . <ref type="figure" target="#fig_11">Figure 7</ref> shows the effect of , on images based on the same set of noise arrays.</p><p>The blending stage is crucial because it introduces spatial correlation along pathline segments in every frame. To show clearly that the spatial correlation occurs along pathlines passing through each cell, we conceptualize the algorithm in 3D space; the x and y axes represent the spatial coordinates, whereas the third axis is time. To understand the effect of the blending operation, let's consider an array N with black cells and change a single cell to white. During advection, a sequence of noise arrays (stacked along the time axis) is generated in which the white cell is displaced along the flow. By construction, the curve followed by the white cell is a pathline. The temporal filter blends successive noise arrays a N with the most recent data weighted more strongly. The temporal blend of these noise arrays produces the projection of the pathline onto the x y plane, with an exponentially decreasing intensity as one travels back in time along the pathline. When the noise array with a single white cell is replaced by a two-color noise distribution, the blending operation introduces spatial correlation along a dense set of short pathlines.</p><p>Streamlines and pathlines passing through the same cell at the same time are tangent to each other, so a streamline of short extent is well approximated by a short pathline. Therefore, the collection of short pathlines serves to approximate the instantaneous direction of the flow. With our LEA technique, a single frame represents the instantaneous structure of the flow (streamlines), whereas an animated sequence of frames reveals the motion of a dense collection of particles released into the flow.</p><p>The filtering phase completes one pass of the advection algorithm. The image b N can be displayed to the screen or stored as an animation frame. c N is used as the initial noise texture N for the next iteration. It is worthwhile to mention that each iteration ends with data having the exact same property as when it started. In particular, the coordinate arrays satisfy , ,</p><formula xml:id="formula_17">x y i j i i j j « » ¬ ¼ « » ¬ ¼ C C</formula><p>and N contains a two-color noise without degradation of contrast.</p><p>In the next section, we describe several optional post-processing steps to enhance the display of the animation frames, both in terms of quality and in terms of content.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Post-Processing</head><p>A series of optional postprocessing steps is applied to b N to enhance the image quality and to remove features of the flow that are uninteresting to the user. We present two filters. A fast version of LIC can be applied to remove high frequency content in the image, while a velocity mask serves to draw attention to regions of the flow with strong currents.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Directional Low-Pass Filtering (LIC)</head><p>Although the temporal filter (noise blending phase) converts high frequency noise images into smooth spatially-correlated images, aliasing artifacts remain visible in regions where the noise is advected over several cells in a single iteration. As a rule, aliasing artifacts become noticeable where noise advect more than one or two cells in a single time step (see Figure8 bottom). Experimentation with different low-pass filters led us to conclude that a Line Integral Convolution filter applied to b N is the best filter to remove the effect of artifacts while preserving and enhancing the directional correlation resulting from the blending phase. This follows from the fact that temporal blending and LIC bring out the structure of pathlines and streamlines respectively, and these  curves are tangent to one another at each point. Although the image quality is often enhanced with longer kernel lengths, it is detrimental here since the resulting streamlines will have significant deviations from the actual pathlines. The partial destruction of the temporal correlation between frames would then lead to flashing effects in the animation. A secondary effect of longer kernels is decreased contrast.</p><p>While any LIC implementation can be used, our algorithm can advect an entire texture at interactive rates. Therefore, we are interested in the fastest possible LIC implementation. To the best of our knowledge, FastLIC <ref type="bibr" target="#b12">[13]</ref> and Hardware-Accelerated LIC <ref type="bibr" target="#b3">[4]</ref> are the fastest algorithms to date, and both are well suited to the task. However, we propose a simple, but very efficient, software version of Heidrich's hardware implementation to postprocess the data when the highest quality is desired.</p><p>Besides the input noise array b N , the algorithm requires two additional coordinate arrays Cxx and Cyy, and an array LIC N to store the result of the line integral convolution. The length of the convolution kernel is denoted by L . For reference, we include the pseudo code for Array-LIC in <ref type="figure">Figure 9</ref>.</p><p>In general, L h | produces a smooth image with no aliasing.</p><p>However, large values of h speed up the flow, with a resulting increase in aliasing effects. If the quality of the animation is important, L must be increased with a resulting slowdown in the frame rate. The execution time of the LIC filter is commensurate with the timings of FastLIC for 10 L . Beyond 10, a serial</p><p>FastLIC <ref type="bibr" target="#b12">[13]</ref> should be used instead. An OpenMP implementation of our ALIC algorithm on shared memory architectures is straightforward. Results are presented in Section 6. As shown in <ref type="table" target="#tab_6">Table 1</ref>, smoothing the velocity field with LIC reduces the frame rate by a factor of three across architectures. We recommend exploring the data at higher resolution without the filter or at low resolution with the filter.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Velocity Mask</head><p>To fade out high frequency noise in b N occurring in low velocity regions, we construct an opacity map, referred to as a velocity mask, that we store in an alpha layer. With a partially transparent noise layer, a background image such as a geographical map (see color plates) can greatly enhance the information content provided by the flow by providing additional context. For maximum control, b N should become more transparent in regions of low intensity. Regions of the flow with strong currents can be emphasized further by maximizing the opacity where the velocity magnitude is high. Once computed, the velocity mask is combined with b N into an intensity-alpha texture that is blended with the background image (see color plate). We compute the opacity map </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Results</head><p>The next section presents timings of our algorithm. We conducted experiments to evaluate the efficiency of the algorithm at four resolutions ( 2 300 through 2 1000 pixels). We present in <ref type="table" target="#tab_6">Table 1</ref> timings in frames/second, using several of the available options. Three different computers were used.</p><p>The organization of the algorithm as a series of array operations makes it particularly straightforward to parallelize on shared memory architectures. Furthermore, operations on the array elements only make accesses within h rows or columns. For small h , the locality of these accesses is sufficient not to produce cache misses on a CPU with a cache of moderate size (e.g., 512 kbytes). <ref type="table" target="#tab_6">Table 1</ref> also includes timings from an OpenMP implementation running on four processors of an Onyx2. Loop over pixels i,j Cxx(i,j)=i; Cyy(i,j)=j for k = 0 to L2 Loop over pixels i,j //Coordinate integration Cxx(i,j)= ( Cxx(i,j) + sgn*Vx(rWv*Cxx(i,j),rHv*Cyy(i,j))+W)%W Cyy(i,j)= ( Cyy(i,j) + sgn*Vy(rWv*Cxx(i,j),rHv*Cyy(i,j))+H)%H</p><p>Loop over pixels i,j // Noise advection // and Accumulation N LIC (i,j) += r*Nb(rW*Cxx(i,j),rH*Cyy(i,j)) end for sgn = -1/Vmax end for return N LIC <ref type="figure">Figure 9</ref>. Pseudo-code for ALIC (Array LIC). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Options Resolutions</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Conclusion</head><p>This paper describes an algorithm to visualize time-dependent flows based on an original per-pixel Lagrangian-Eulerian Advection approach. A noise image is advected from a time step to the next. The color of every pixel in the current image is determined in two steps. A dense collection of particles (one per pixel) is first integrated backward in time for a fixed time interval (Lagrangian phase) to determine their positions in the previous frame. The color at these positions determine the color of each pixel in the current frame (Eulerian phase). We described how to seamlessly handle regions where the flow enters the physical domain. A temporal filter is applied to successive images to introduce a good level of spatio-temporal correlation. Thus, every still frame represents the instantaneous structure of the flow, whereas an animated sequence of frames reveals the motion of a dense collection of particles released into the flow. When necessary, spatial correlation is enhanced through a fast LIC algorithm. A post-processing filter has been described to control the contrast between regions of high and low velocity magnitude. The advected noise is controlled by the percentage of noise injection, while the final image is influenced by the temporal blending coefficient and the LIC parameters. Although fixed default parameters gives good results for any vector field, these parameters can be chosen interactively, to generate images suitable to the user. Transparency makes it possible to view a background image through the flow; this leads to our current work on multiple layer texture advection. We demonstrated the efficiency of the algorithm on a variety of computers, including a multiprocessor workstation. The interactivity made possible by this work has made it possible to explore 2-D unsteady flows in real time, and suggests that in the near future interactive three-dimensional texture advections will become a reality.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 .</head><label>1</label><figDesc>Rotation of bitmap image about the lower left corner. (a) Original image, (b) Image rotated with Lagrangian scheme, (c) Image rotated with Eulerian scheme.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>,</head><label></label><figDesc>x and y coordinates after integration. A first order integration method requires two arrays x V and y V that store the velocity field at the current time. Similarly to LIC, we choose to advect noise images. Four noise arrays N , c N , a N and b N contain respectively the noise to advect, two advected noise images, and the final blended image.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 2</head><label>2</label><figDesc>shows a flowchart of the algorithm. After the initialization of the coordinate and noise arrays (Section 4.2), the coordinates are integrated (Section 4.3) and the initial noise array N is advected (Section 4.4). The first advected noise array, c</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 2 .</head><label>2</label><figDesc>Flowchart of LEA algorithm.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>aN</head><label></label><figDesc>serves to create the current animation frame and no longer participates in the noise advection. It is computed using linear interpolation of N to reduce spatial aliasing effects. a N is then blended into b N (Section 4.9).A straightforward implementation of Equation(4)leads to conditional expressions to handle the cases when exterior to the physical domain. A more efficient implementation eliminates the need to test for boundary conditions by surrounding N and c N with a buffer zone of constant width. From equation(6), cx refers to cells located at a maximum distance of b h ª º « » cell width away from the array borders. An expanded noise to ensure that out of bound array accesses do not occur (seeFigure 3). The advected arrays c N and a N are computed according to , , ,</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head></head><label></label><figDesc>duplication effect that occurs during the computation of c N in Equation (7). Effectively, if particles in neighboring cells of c N retrieve their property value from within the same cell of N , this value will be duplicated in the corresponding cells of N . Single property values in N may be duplicated onto neighboring cells in c have identical integer values.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head></head><label></label><figDesc>Figure 3. Noise arrays c N and a N are expanded with a surrounding region ª º « » b = h cells wide.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 5 .</head><label>5</label><figDesc>Energy content of the flow at different scales based on a 2D Haar wavelet decomposition of the twovalued noise function (assumed to be isotropic). The energy in each band is scaled with respect to its initial value.Results are shown for injection rates of 0%, 2%, 5% and 10%.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 6 .Figure 4 .</head><label>64</label><figDesc>Circular flow without and with accumulation of fractional displacement (h = 2) . Noise duplication. A single noise value is duplicated into four cells in a uniform 45 deg flow.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Figure 7 .</head><label>7</label><figDesc>Frames obtained with different values of . .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head></head><label></label><figDesc>of a function of local velocity magnitude and a function of the noise intensity. Higher values of the exponents m and n increase the contrast between regions of low and high velocity and low and high intensity respectively. When 1 m n , equation (10) takes the linear form b A N V .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Figure 8 .</head><label>8</label><figDesc>Frame without (bottom) and with (top) LIC filter. A velocity mask is applied to both images. float* ALIC(const float* Vx, const float* Vy, int Wv, int Hv, const float* N b , int W, int H int L, float* N LIC ) rWv = Wv/W ; rHv = Hv/H rW = W /(W-1); rH = H /(H-1) L2 = L div 2 r = 1/(2*L2+1) Loop over pixels i,j { N LIC (i,j) = r*Nb(i,j) } sgn = 1/Vmax for n = 1 to 2 // Forward and backward advection</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 1 : Timings in frames/second as a function of op- tions and resolutions. Each configuration has been tested on four different configurations: O2 1 (upper left), Oc- tane 2 (upper right), Onyx2 3 (lower left) and Onyx2 with four processors</head><label>1</label><figDesc></figDesc><table><row><cell></cell><cell cols="2">Advection</cell><cell cols="2">Advection +</cell><cell cols="2">Advection +</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="2">Velocity Mask</cell><cell cols="2">Velocity Mask</cell></row><row><cell></cell><cell></cell><cell></cell><cell>m n</cell><cell>3</cell><cell cols="2">+ ALIC filter</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>L</cell><cell>6</cell></row><row><cell>300 × 300</cell><cell>3.4</cell><cell>14.0</cell><cell>2.2</cell><cell>8.8</cell><cell>0.8</cell><cell>3.0</cell></row><row><cell></cell><cell>16.3</cell><cell>39.0</cell><cell>10.4</cell><cell>27.0</cell><cell>3.6</cell><cell>11.6</cell></row><row><cell>500 × 500</cell><cell>1.2</cell><cell>4.7</cell><cell>0.8</cell><cell>3.1</cell><cell>0.3</cell><cell>1.0</cell></row><row><cell></cell><cell>6.3</cell><cell>18.0</cell><cell>3.7</cell><cell>10.5</cell><cell>1.3</cell><cell>4.5</cell></row><row><cell>1000 ×1000</cell><cell>0.3</cell><cell>1.2</cell><cell>0.2</cell><cell>0.7</cell><cell>0.07</cell><cell>0.2</cell></row><row><cell></cell><cell>1.4</cell><cell>4.1</cell><cell>0.9</cell><cell>2.7</cell><cell>0.3</cell><cell>1.1</cell></row></table><note>(lower right).</note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">If the discrete time step exceeds some maximum value, severe numerical instabilities result.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">SGI O2, R5000, 200MHz, 64MB, 1MB L2 cache, 64KB L1 cache<ref type="bibr" target="#b1">2</ref> SGI Octane, R12000, 300MHz, 2GB, 2MB L2 cache, 64KB L1 cache<ref type="bibr" target="#b2">3</ref> SGI Onyx2, R12000, 300MHz, 2GB, 8MB L2 cache, 64KB L1 cache</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.">Acknowledgments</head><p>We would like to thank David Banks for lively discussions in all areas of visualization, including several valuable suggestions to improve the quality of this paper. Some of the datasets used to illustrate the techniques presented in this paper were provided courtesy of Z. Ding (FSU), J. O'Brien (COAPS, FSU), J. Quiby (MeteoSwiss, Switzerland), and R. Arina (Ecole Polytechnique of Turin, Italy). We acknowledge the support of NSF under grant NSF-9872140.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Unsteady Flow Volumes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">G</forename><surname>Becker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename><surname>Lane</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">L</forename><surname>Max</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings IEEE Visualization &apos;95</title>
		<editor>G.M. Nielson and D. Silver</editor>
		<meeting>IEEE Visualization &apos;95</meeting>
		<imprint>
			<publisher>IEEE Computer Society Press</publisher>
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Imaging Vector Fields Using Line Integral Convolution. Computer Graphics Proceedings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Cabral</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">C</forename><surname>Leedom</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Annual Conference Series</title>
		<editor>J.T. Kajiya</editor>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="1993-08" />
			<biblScope unit="page" from="263" to="269" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">C</forename><surname>De Leeuw</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Van Liere</surname></persName>
		</author>
		<title level="m">Spotting Structure in Complex Time Dependent Flow</title>
		<imprint>
			<date type="published" when="1998-09" />
		</imprint>
		<respStmt>
			<orgName>CWI -Centrum voor Wiskunde en Informatica</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Heidrich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Westermann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H.-P</forename><surname>Seidel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Ertl</surname></persName>
		</author>
		<title level="m">Applications of Pixel Textures in Visualization and Realistic Image Synthesis. ACM Symposium on Interactive 3D Graphics</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="1999-04" />
			<biblScope unit="page" from="127" to="134" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Tiled Hardware-Accelerated Texture Advection for Unsteady Flow Visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Jobard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Erlebacher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">Y</forename><surname>Hussaini</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000-08" />
			<biblScope unit="page" from="189" to="196" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Hardware-Accelerated Texture Advection for Unsteady Flow Visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Jobard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Erlebacher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">Y</forename><surname>Hussaini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings Visualization</title>
		<editor>T.E. Ertl, B. Hamann, and A. Varshney</editor>
		<meeting>Visualization</meeting>
		<imprint>
			<publisher>IEEE Computer Society Press</publisher>
			<date type="published" when="2000-10" />
			<biblScope unit="page" from="155" to="162" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">UFAT -A Particle Tracer for Time-Dependent Flow Fields</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename><surname>Lane</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings IEEE Visualization &apos;94</title>
		<editor>R.D. Bergeron and A.E. Kaufman</editor>
		<meeting>IEEE Visualization &apos;94</meeting>
		<imprint>
			<publisher>IEEE Computer Society Press</publisher>
			<date type="published" when="1994" />
			<biblScope unit="page" from="257" to="264" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Visualizing Time-Varying Phenomena In Numerical Simulations Of Unsteady Flows, NASA Ames Research Center</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename><surname>Lane</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1996-02" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Flow visualization using moving textures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Max</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Becker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICASE/LaRC Symposium on Visualizing Time Varying Data</title>
		<editor>D.C. Banks, T.W. Crockett, and Stacy Kathy</editor>
		<meeting>ICASE/LaRC Symposium on Visualizing Time Varying Data</meeting>
		<imprint>
			<date type="published" when="1996" />
			<biblScope unit="volume">3321</biblScope>
			<biblScope unit="page" from="77" to="87" />
		</imprint>
	</monogr>
	<note>NASA Conference Publication</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Flow visualization using moving textures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Max</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Becker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Data Visualization Techniques</title>
		<editor>Bajaj</editor>
		<imprint>
			<publisher>John Wiley and Sons, Ltd</publisher>
			<date type="published" when="1999" />
			<biblScope unit="page" from="99" to="105" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Visualization of Time-Dependent Velocity Fields by Texture Transport</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Rumpf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Becker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eurographics Workshop on Scientific Visualization &apos;98</title>
		<meeting>the Eurographics Workshop on Scientific Visualization &apos;98</meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="1998" />
			<biblScope unit="page" from="91" to="101" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">A New Line Integral Convolution Algorithm for Visualizing Time-Varying Flow Fields</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H.-W</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">L</forename><surname>Kao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="98" to="108" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Fast and Resolution Independent Line Integral Convolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Stalling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H.-C</forename><surname>Hege</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of SIGGRAPH &apos;95</title>
		<meeting>SIGGRAPH &apos;95</meeting>
		<imprint>
			<date type="published" when="1995" />
			<biblScope unit="page" from="249" to="256" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
