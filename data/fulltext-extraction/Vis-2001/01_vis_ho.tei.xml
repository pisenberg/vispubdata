<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/pisenberg/grobid/grobid-0.6.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Compressing Large Polygonal Models</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Ho</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kuang-Chih</forename><surname>Lee</surname></persName>
						</author>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Kriegman</surname></persName>
							<email>kriegman@uiuc.edu</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Beckman Institute</orgName>
								<orgName type="institution" key="instit2">University of Illinois at Urbana-Champaign</orgName>
								<address>
									<postCode>61801</postCode>
									<settlement>Urbana</settlement>
									<region>IL</region>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<address>
									<settlement>San Diego</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Compressing Large Polygonal Models</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2021-02-19T20:45+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>I.3.5 [Computer Graphics]: Computational Geometry and Object Modeling-object representations</term>
					<term>I.3.6 [Computer Graphics]: Methodology and Techniques-graphics data structures and data types</term>
					<term>E.4 [Coding and Information Theory]: Data compaction and compression compression algorithms</term>
				</keywords>
			</textClass>
			<abstract>
				<p>We present an algorithm that uses partitioning and gluing to compress large triangular meshes which are too complex to fit in main memory. The algorithm is based largely on the existing mesh compression algorithms, most of which require an &apos;in-core&apos; representation of the input mesh. Our solution is to partition the mesh into smaller submeshes and compress these submeshes separately using existing mesh compression techniques. Since a direct partition of the input mesh is out of question, instead, we partition a simplified mesh and use the partition on the simplified model to obtain a partition on the original model. In order to recover the full connectivity, we present a simple scheme for encoding/decoding the resulting boundary structure from the mesh partition. When compressing large models with few singular vertices, a negligible portion of the compressed output is devoted to gluing information. On desktop computers, we have run experiments on models with millions of vertices, which could not be compressed using standard compression software packages, and have observed compression ratios as high as 17 to 1 using our technique.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>With the recent and rapid advances in digital acquisition technology, meshes with millions if not billions of vertices are becoming increasingly common. The most celebrated examples are the range scans of Michelangelo's sculptures, made by Stanford's Digital Michelangelo project, which contain up to two billion triangles. These massive datasets pose great challenges to virtually all existing mesh processing tools such as rendering, editing, simplification, and compression. The large memory requirement for handling these datasets renders many of these mesh-processing tools ineffective on a computer with modest size RAM (i.e. a desktop PC). Existing mesh compression and, to a lesser extent, decompression algorithms are only effective if a representation of the mesh's entire topological and geometric structures (and other attributes) is small enough to fit 'in-core'. Yet for a mesh with a few million vertices, one faces the possibility that there is insufficient memory on a desktop computer for the entire model.</p><p>Our approach toward compressing these large models is straightforward: to partition the mesh into submeshes of smaller sizes, depending on the available local memory, and then to compress them separately using the existing mesh compression algorithms. Extra effort is also needed to encode and decode the connectivity information that glues (or stitches) the various boundaries resulted from the mesh partition. Certainly, there are many ways to partition a mesh. However, from the compression standpoint, it is desirable that 1) each region of the partition is "localized" somewhere in the model, and 2) the boundary of each region is as simple as possible. The motivation is that submeshes within a localized region would share similar geometry and therefore, minimize the size of the compressed geometry output code. The simple boundary assures that the boundary encoding would also be minimized. In addition, the partition should in general be balanced in the sense that each patch of the partition should contain roughly the same number of vertices or faces, or other geometric primitives. Since the original mesh is assumed to be too large to be represented in-core, we are faced with the problem of how to produce partitions that satisfy these criteria. One obvious partitioning approach is to use the coordinate axes or other linear functions of the ambient space to partition the mesh. However, without knowing the approximate shape or geometry of the model, a direct approach is generally quite hazardous. We propose the simple idea of using a weighted graph, which is derived from a simplified mesh of the input model, as a guide for partitioning the original mesh. Therefore, the compression starts with an initial pass over the input file so that this weighted graph can be computed. It is assumed that the weighted graph is small enough to partition it directly. If N is the ratio between the size of the model representation and the locally available memory, we partition the weighted graph into N parts and use the partition on the graph to induce a partition on the input model. We make another N passes over the input file such that each submesh (region of the partition) is reconstructed and compressed separately.</p><p>To encode/decode the full connectivity, we propose an encoding/decoding scheme for the boundaries resulting from the partition. The problem is similar to the one studied in <ref type="bibr" target="#b4">[5]</ref>, but with several important differences. The idea is simple. Because of the partition, most of the vertices that need to be identified are the boundary vertices of the submeshes. Using this as the working hypothesis, our method is similar to the variable-length method described in <ref type="bibr" target="#b4">[5]</ref> and is optimized for our particular circumstance.</p><p>Since the compression algorithm requires N + 1 passes over the input file, its performance in speed is dominated by disk I/O. This becomes rather unattractive if N and the file size are both large. The decoder, on the other hand, only makes one pass over the compressed file, which is assumed to be smaller than the original file; therefore, its speed is less effected by the size of the original file. This makes the compression algorithm asymmetric, although it is generally preferable to have a faster decoder.</p><p>For mesh simplification, the recently introduced out-of-core simplification technique <ref type="bibr" target="#b12">[13]</ref> provides an elegant solution for memoryless simplifications. The out-of-core method makes one pass over the input mesh data file and it only retains the data needed for computing the simplified mesh; therefore, the memory used in processing the mesh is kept at minimum. The usual text-based compression techniques such as the GZIP or <ref type="bibr" target="#b20">[21]</ref> also share this characteristic. These compression methods usually make one or two passes on the input file, depending on whether the compression statistics is extracted from the document before the compression. The memory usage for these methods are generally small and for GZIP or LZW compression method, it depends on the size of the windows used in computing predictions. Comparing with the two cases above, the situation for mesh compression is considerably more complicated. The out-of-core simplification ignores the local connectivity information. However, local connectivity is one of the properties that is to be encoded (or decoded) by the mesh compression algorithm. The prediction used in text-based compression is simply unidirectional, i.e. toward the end of the file. For the mesh compression, which involves the 3D geometry, the relation between the primitives, i.e. the vertices and faces, is multi-directional. In an abstract sense, all existing mesh compression algorithms aim to produce some type of linear ordering (based on spatial proximity) on the mesh (vertex or face traversals); this requires a both global and local structure of the model and hence a large in-core representation of the mesh.</p><p>This paper is organized as follows. In the next section, we briefly review some of the major work in mesh compression. In section three, we describe our partition and glue schemes, and experimental results are reported in the concluding section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">PREVIOUS WORK</head><p>The process of compressing a mesh generally consists of two steps: a preprocessing step and the actual compression. Since virtually all the existing mesh compression algorithms (with the exception of <ref type="bibr" target="#b0">[1]</ref>) require the input mesh to be a manifold, a preprocessing step is necessary to detect singular points on the input model (if they exist) and convert a non-manifold input mesh into a manifold one.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Converting Non-Manifold Meshes</head><p>The method for converting non-manifold meshes into manifold meshes is studied in <ref type="bibr" target="#b5">[6]</ref>. The main idea is to separate the local branches at each singular vertex by duplicating it. The resulting manifold mesh will have the same number of (non-degenerate) triangles as the original mesh but with more vertices. In addition, the manifold mesh will typically have more than one connected component. Each regular vertex in the original mesh corresponds to one vertex in the manifold mesh while each singular vertex corresponds to more than one vertex in the manifold mesh. The correspondence is recorded in a vertex clustering array. In <ref type="bibr" target="#b4">[5]</ref>, two efficient methods for encoding/decoding this vertex clustering array were proposed: a stack-based method, which directly encodes and decodes the array and a variable-length method, which is more efficient if the vertex clustering array contains long chains of (singular) vertices with consecutive decoding orders of traversal.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Mesh Compression</head><p>Many mesh compression algorithms have been proposed and investigated in the past five years. They differ mainly in the way the mesh connectivity is encoded/decoded. Due to its discrete nature, the connectivity encoding is generally combinatorial in nature and different algorithms give different recipes for visiting each triangle or vertex of the mesh. The idea of using triangle strips for compression appeared in Deering's work <ref type="bibr" target="#b2">[3]</ref>. It was later generalized and extended in various directions <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b6">7]</ref>, which includes the IBM's topological surgery <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b18">19]</ref> and Rossignac's Edgebreaker <ref type="bibr" target="#b14">[15]</ref>. Somewhat differently, Touma and Gotsman's method gives a recipe for making a vertex traversal. They encode the valences of the vertices and record the merging and splitting of the boundary of the region the algorithm has visited. As a by-product of the mesh traversal, all of the methods cited above produce an ordering of the vertices, the decoding order.</p><p>Using the decoding order defined by the connectivity encoding, a predictive coding can be developed for compressing mesh geometry and other attributes. Typically, a bounding box for the model is used to define the coordinate quantization. The bounding box is divided into uniform grid cells, and the positions of the vertices are normalized within each cell. Using the decoding order of traversal, the position of a vertex can be predicted by the positions of previously decoded vertices. The difference between the actual position and the predicted position is encoded as an integer. The most successful prediction rule so far is the parallelogram rule of Touma and Gotsman <ref type="bibr" target="#b19">[20]</ref>, which predicts the position of a vertex as the fourth vertex on a parallelogram formed by the vertex and three of its "neighboring" vertices. The size of the output code is further reduced by the use of an entropy encoder, which is applied to all data, namely connectivity, geometry and other properties.</p><p>The work cited above all faithfully encode the connectivity of the mesh while its geometry is encoded in a lossy way with error controlled by the coordinate quantizations. However, recently there emerges a new type of "appearance-based" mesh compression <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b7">8]</ref>. These methods generally involve re-meshing the input model into a semi-regular mesh. Standard multi-resolution signal processing tools, such as wavelets, are used to compress the geometry and other attributes. Therefore, both the connectivity and geometry are compressed in a lossy way; however, the main concern here is the fidelity of the compressed model's appearance. A more radical departure from traditional mesh compression is the Qsplat data structure of <ref type="bibr" target="#b16">[17]</ref>. The data structure is used for rendering a massive mesh data file, and it can be considered as a form of mesh compression where all the connectivity information is ignored. In this paper, we follow the more traditional type of mesh compression where the mesh connectivity is encoded losslessly.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">COMPRESSING LARGE MESHES</head><p>The mesh compression algorithm presented here builds on existing mesh compression algorithms, in particular <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b14">15]</ref>. Our solution to compressing meshes too large to fit in-core is to partition the input mesh into submeshes small enough to apply an existing mesh compression algorithm <ref type="bibr" target="#b19">[20]</ref>. If the complete connectivity is required, our method also provides a simple and efficient scheme to encode/decode the information needed to glue various submeshes together to recover the full connectivity. Our main contributions are: 1) a simple partitioning scheme, using a simplified mesh graph, which produces good partitions for compression, and 2) an encoding/decoding scheme for gluing the submeshes.</p><p>The recent work of Karni and Gotsman <ref type="bibr" target="#b8">[9]</ref> appears to be the first time that mesh partitioning was used in mesh compression. However, the functionality of the partition in their work is different. In <ref type="bibr" target="#b8">[9]</ref>, the connectivity is encoded and decoded separately from the geometry, and it is used to define a mesh partition such that the geometry of each submesh is encoded and decoded independently using a spectral method based on the mesh Laplacian. Furthermore, since connectivity is used to compute the partition, there is no need to glue submeshes. In our case, it is not possible to use the full connectivity to define the partition; in fact, the partition is only defined on a simplified mesh graph. On the decoding side, we need to glue the submeshes together in order to recover the full connectivity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Mesh Partitioning</head><p>The main goal of the mesh partitioning is to divide the input mesh into submeshes of roughly equal size. The size of course depends on the available memory and the amount of memory required by algorithms being used to compress the individual submeshes, and the later differs with different implementations. However, from a. b.</p><p>c. : After the partition, the boundary of S1 contains both the vertices on the cut boundary and the vertices on the actual boundary. When gluing S1 and S2 together to recover the original mesh, only the vertices on the cut boundary are identified.</p><p>the compression standpoint, it is also desirable that 1) the resulting boundary structure should be simple, and 2) each region of the partition should be localized in the model. A direct partitioning of the model using for example the coordinate axes or other linear functions of the ambient space generally does not have this property. See <ref type="figure" target="#fig_0">Figure 1</ref>. By partitioning the mesh into N parts, we mean that each vertex of the mesh can be assigned a number, its region index, from 1 to N . The assignment for the vertices induces an assignment for the triangles: the region index for each triangle is defined as the minimum of the region indices of its three vertices. The K th submesh SK is simply the union of all triangles with region index K, and SK does not contain any vertex with region index less than K. See <ref type="figure">Figure 2</ref>. The intersection of two submeshes is either empty or consists of just vertices and edges, and we call these non-empty intersections the cut boundaries to distinguish them from the real boundary.</p><p>The geometry of the input model can be condensed into a weighted graph G using spatial vertex clustering. The result is a map from the set of the vertices to the nodes of G. The weight at each node simply counts the number of vertices mapped to the node while the weight on each edge counts the number of triangles with vertices mapped to the edges' two nodes. If G is small enough, we can directly partition G, and in turn, the partition of G induces a partitioning on the input mesh.</p><p>The vertex clustering algorithm that we use is similar to the one in <ref type="bibr" target="#b15">[16]</ref>. It requires a bounding box for the input mesh, and the same bounding box is used to define the global coordinate quantization that is applied to all submeshes. The bounding box is divided into a number of uniform grid cells. Given a triangle t from the input mesh, we obtain its vertex coordinates. For each vertex, we determine the grid cell that the vertex falls in. If this cell has not been visited, a new node in G is created. If two of the triangle's vertices belong to the same cell u and the other vertex belongs to a different cell v, a weight on the edge uv in G is increased by 1. If all the vertices of t belong to the same node, the node's weight is also increased by 1. G should be as small as possible; however, our pri-mary concern is to have a balanced partition on the input mesh. If G is too coarse, the induced partition on the input mesh may not be appropriately balanced. In our implementation, the bounding box is divided into 64 to 128 equal parts in each coordinate axis, and G typically contains fewer than 40000 nodes.</p><p>After the initial pass, we have a weighted graph G that records roughly the spatial distribution of the vertices of the input mesh. The weighted graph can be partitioned using a standard graph partitioning package such as METIS <ref type="bibr" target="#b9">[10]</ref>. The result of applying METIS to G is a balanced partition of G with small (but not minimal) edge cuts. A balanced partition for G means that the sum of the weights of all nodes in the different regions are approximately the same. Since the weight of the nodes simply counts the number of triangles collapsed into the cell, the balanced partitioning on G translates into a balanced partitioning on the input mesh. A partition of G with small edge cuts also translates into a partitioning of the input mesh with "simple" boundary structure. <ref type="table">Table 1</ref> shows two different partitions of David from the Digital Michelangelo Project, and the number of vertices on the cut boundaries.</p><p>The data structure for the partitioning of G will remain throughout the entire encoding process. We make another N passes over the input file, and each time a submesh Si is constructed in-core. Again, given a triangle t, we obtain its three vertices and identify the nodes of the graph these vertices belong to. A vertex's region index is simply the region index of its parent node in G. If t is determined to have a region index equal to i, it is retained; otherwise, it is discarded. After Si has been compressed, we free the memory holding the structure for Si and proceed to compress Si+1.</p><p>At this point, we have two options, we can proceed directly to compress each submesh independently and hence ignore the cut boundaries or we can proceed to encode the cut boundaries and hence compress each submesh separately but not independently. The main difference between the two approaches is that the positions of the vertices on the cut boundaries are encoded multiple times if each submesh is compressed independently. If the number of submeshes is small, the vertices on the cut boundaries are usually less than 1% of the total number of vertices. Of course, there will always be some unfortunate cases where a small number of submeshes results in a large number of vertices on the cut boundaries. However, our partitioning scheme is specifically designed, for most cases, to have a small number of vertices on the cut boundaries, as shown in <ref type="table">Table 1</ref>. If the submeshes are compressed independently, the compressed output represents a triangular mesh M which contains the same number of triangles as the original mesh M but with more vertices. Since G is determined only by the triangles, the G for M and M are identical. Hence, if we compress M with N partitions, the compressed output this time will faithfully represent M , i.e. the number of vertices will not increase as long as N is the same. Therefore, on the same desktop PC, repeatedly compressing and decompressing the input model will not increase the number of vertices indefinitely.</p><p>Partition N = 14 N =5</p><p>x 19063 57435 y 22371 6123 z 98081 31066 G 13870 6332 <ref type="table">Table 1</ref>: The number of vertices on the cut boundaries. Comparisons between partitions using the coordinate axis and the weighted graph G. The partitions using weighted graph are shown in <ref type="figure" target="#fig_0">Figure  1</ref> of the color plate.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Gluing the Cut Boundaries</head><p>If the full connectivity is required, we are obliged to encode/decode the cut boundary structure, i.e. how the vertices on the various cut boundaries should be identified. A straightforward method is to directly encode the gluing. If v and u are vertices that should be identified and u is decoded after v, we can associate with u an integer index that identifies which previously decoded vertices should u be identified with. Since the input mesh is supposed to contain millions of vertices and the number of vertices on the cut boundary are usually more than a few thousand, the integer index would require more than 10 bits to code. Therefore, hard coding the gluing is not likely to produce results better than encoding the vertices multiple times. Since the cut boundaries are the direct result of mesh partitioning, most of the vertices on the cut boundaries are in fact on the boundary of the submeshes containing them. As can be seen from <ref type="figure" target="#fig_0">Figure 1</ref>, the cut boundaries are usually very long, and this suggests some type of variable-length encoding is appropriate. For vertices that do not belong to a submesh's boundary, we simply encode them directly. The gluing (or stitching) problem has been studied previously in <ref type="bibr" target="#b4">[5]</ref>, and there are differences between Gueziec's case and ours. First, in <ref type="bibr" target="#b4">[5]</ref>, the vertices that need to be identified are the singular vertices, and they generally reside on the interior of the mesh rather than on the boundary. Therefore, the only ordering of the vertices that can be used for the variable-length encoding is the decoding order of the vertices. In our case, an ordering for most of the vertices on the cut boundaries can be provided by the orientations of submeshes' boundaries. Second, in <ref type="bibr" target="#b4">[5]</ref>, at the time of encoding, the complete information on how to cluster vertices is available (the vertex clustering array in <ref type="bibr" target="#b4">[5]</ref>) while in our case, the information on vertex identifications is only revealed incrementally.</p><p>Since we are using the boundary information to encode the gluing, this requires that, on the decoding side, the connectivity is decoded before the gluing can start. On the decoding side, the connectivity is decoded first, and this is followed by gluing. The geometry is decoded last, following the same traversal as the connectivity decoding. A table containing the structure of the mesh partition is encoded as a function p(k) for 1 ≤ k ≤ N , and it is placed at the beginning of the compressed file. For each 1 ≤ k ≤ N , the number p(k) is defined as the largest integer such that the intersection between submeshes S k and S k+p(k) is non-empty.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Cut Boundaries Encoding</head><p>Suppose we are encoding an input mesh that has been partitioned into N parts. Let S1 • • • SN denote the resulting submeshes, and we compress them in this order. When compressing a submesh, we need to 1) identify vertices in the current submesh that are glued to vertices in the previous submeshes and 2) identify vertices in the current submesh that will be glued to vertices in the forthcoming submeshes.</p><p>At any moment, a list of vertices, CL, is maintained. These are the vertices which are "waiting to be glued". Using the cut boundaries, we can impose extra geometric structure on CL so that it describes a collection of line segments, close loops and single points. See <ref type="figure">Figure 3</ref>. In the actual implementation, CL is a collection of doubly-linked lists of vertices and lists with a single vertex.</p><p>The data structure for the vertices contains the following fields:</p><p>1. rID denotes the region it belongs (according to the weighted graph G),</p><p>2. cID denotes the last submesh it is on, <ref type="bibr" target="#b2">3</ref>. dID denotes the decoding order of the given vertex in submesh ScID. <ref type="figure">Figure 3</ref>: The evolution of CL: after S1 is processed, only the vertices on its boundary are retained. At this moment, CL consists of these vertices. After S2 is processed, CL consists of two segments. Each segment is a part of the cut boundary of S1 or S2. After S3 is processed, CL again consists of two segments. The cut boundary of S1 has been processed and its boundary structure is deleted from the memory.</p><p>For each submesh S k , let V k denote the set of its vertices. Let P k denote the set of vertices in V k that have to be glued to some vertex in a previous mesh Si with i &lt; k. We also let N k denote the vertices in V k that will be identified with some future vertices. See <ref type="figure">Figure 2</ref> of the color plate. The intersection N k ∩ P k is generally non-empty.</p><p>To identify N k is easy, they are the vertices in V k with rID &gt; k. P k , by definition, is simply V k ∩ CL.</p><p>Before connectivity encoding, the boundary structure of S k is computed. A vertex v is on the boundary of S k if a small neighborhood of v in S k is homeomorphic to the half disc and a boundary edge is an edge in S k shared by only one triangle, whose orientation induces an orientation on the edge. Let ∂S k denote the set of boundary vertices of S k . By computing the boundary structure of S k , we mean that the set ∂S k can be partitioned into disjointed subsets such that u and v belong to the same subset if there exists a sequence of (oriented) boundary edges {e1, ...en} connecting u and v. Geometrically, each subset (with the connecting edges) forms a line segment or a closed loop, or a single point. The boundary structure induces a geometric structure on the sets N k and P k , i.e. we can form line segments, loops with vertices in N k and P k . Similar to CL, in our implementation, N k and P k are collections of doubly-linked lists and lists with single vertex.</p><p>Next, we identify vertices in P k which are "essential" to gluing S k to the previous submeshes. See <ref type="figure">Figure 4</ref>. By definition, each vertex v in P k will be identified with a vertex v in CL. The correspondence is one-to-one, i.e. no two vertices in P k will be glued to the same point in CL. If v ∈ P k but not in ∂S k , we simply find the corresponding vertex v in CL, and we record five integers for v. The first two are the cID dID of v , and the other three are all zeros. We remove v from the set P k and put it into a list T . Once a vertex in CL has been selected for gluing, it is removed from CL, and the corresponding geometric structure it belongs to is modified. <ref type="figure">Figure 4</ref>: Gluing two cut boundaries. Vertices v1 and v3 are boundary points of S1. v2 is not a boundary point according to our definition. The circles can be glued together by specifying only 1) the pair v1 and v 1 , 2) the number of vertices on the circle (excluding v2) and 3) the orientations of the circles. The line segments containing v3 and v 3 can be coded similarly. The pair v2 and v 2 is coded directly.</p><p>For instance, if v belongs to a loop, v is removed from CL, and the loop is changed to a line segment.</p><p>For each v ∈ P k ∪ ∂S k , let v be the vertex in CL that is to be identified with v. If LP k and LCL are the line segments in P k and CL containing v and v , we simply find the longest (oriented) line segment L in LCL containing v such that by traveling down L, we can identify vertices on L with vertices on LCL. For v, we record the following five numbers: the first two numbers identify the vertex v , the cID dID of v . The next two number are the forward length f l and backward length bl. These are the topological distance between v and the two endpoints of L (recall that L is oriented, so starting at v, we can travel forward and backward on L according to its orientation). If L is a loop, bl is set to −1. The last number compares the orientations between L and LCL, it is 1 if they are compatible and −1 otherwise. v is removed from P k and added to the list T . We remove all other vertices u on L from P k and their corresponding vertex u is also removed from CL without further processing. The process is terminated when P k is empty.</p><p>During the mesh traversal phase of the compression, these records are inserted into the symbol sequence at the appropriate places. In Rossignac's Edgebreaker, there are five symbols for connectivity encoding: S(S*), R, L, E, C. We add two more, GLUE1 and GLUE2. The symbol GLUE1 is followed by 5 integers while GLUE2 stands by itself.</p><p>Whenever a vertex v in the list T is first encountered during mesh traversal, GLUE1 is inserted into the symbol sequence. The five integers that follows are the five numbers we described above. Whenever, a vertex v ∈ N k and v / ∈ ∂S k is first encountered, GLUE2 is inserted. The functionality of GLUE1 has been explained above. The functionality of GLUE2 will be explained later.</p><p>After compression is finished, all vertices in S k are deleted except those belonging to N k . For each v ∈ N k , its cID is changed to k and dID is changed to v's decoding order on S k . And finally, N k is appended to CL.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Decoding the Cut Boundaries</head><p>On the decoding side, the process is reversed. For each S k , its connectivity is decoded first. After the boundary of S k has been computed, we do the gluing, and geometry decoding follows in the same traversal as the connectivity decoding. During the connectivity decoding, any vertex marked by GLUE1 and GLUE2 is put into a list T . These are the vertices needed for gluing. A list of vertices a.</p><p>b. c. CL, which contains vertices that will be identified later, is maintained throughout. After the connectivity of S k has been decoded, we compute its boundary structure. For every vertex in S k marked by GLUE2, we use the five integers described above to identify vertices in S k with vertices in Si with i &lt; k. The geometry is decoded after the gluing is finished. After S k has been decoded, we delete all its vertices (and faces) from the memory except those that will be used in the future for gluing. These vertices are the vertices on its boundary and those marked by GLUE2. The main point is that, on the decoding side, we do not recover the exact N k . Instead, N k is defined as the union of the vertices on the boundary of S k and the vertices marked by GLUE2. Therefore, there are vertices in N k that will not be glued to anything; however, all the vertices that will be needed for gluing are in N k . This may create a problem if N is large and hence many boundary vertices have to be kept in memory. The problem can be greatly reduced by using the function p decoded at the beginning. Vertices created during the decoding of S k can be deleted once the the submesh S k+p(k) has been decoded since, by definition, the intersection between S k and Si is empty if i &gt; k + p(k)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">RESULTS AND DISCUSSION</head><p>For compressing submeshes, We have used Rossignac's Edgebreaker <ref type="bibr" target="#b14">[15]</ref> for connectivity encoding and the parallelogram rule of Touma and Gotsman <ref type="bibr" target="#b19">[20]</ref> for geometric prediction. In our implementation, an "in-core" representation of an input mesh requires approximately 172 byes per vertex. This includes the data structures needed for compression and converting a non-manifold mesh into a manifold one. The output from the geometry and connectivity encodings are entropy encoded using the arithmetic compression software of <ref type="bibr" target="#b20">[21]</ref>. The results reported in <ref type="table" target="#tab_1">Table 2</ref> were gathered on a 450 MHZ machine with 256 MB of RAM. We limit the size of each submesh to about one million vertices. All three models can't be compressed using Virtue3D's Virtuoso Optimizer on a 850MHZ PC with 516MB of RAM. In this early and non-optimized implementation, the running times for compressing David and Lucy are approximately 1.5 hours and 8 hours, respectively. The performance in speed is dominated mostly by the disk I/O. The running times for decompressing both models are approximately 8 and 30 minutes, respectively. The gluing scheme described in the previous section is quite effective on these large models since the cut boundaries are usually long and contain mostly regular boundary points. Only a few vertices are marked with GLUE1 and GLUE2. These are mainly the results of singular points and small holes in the models. Due to their large number of vertices, we have set the coordinate quantizations to be at least 16 bits per coordinate. For the three models listed in <ref type="table" target="#tab_1">Table 2</ref> vertices, the models that we used here are generally several orders of magnitude larger than those used in mesh compression literature in the past (e.g. <ref type="bibr" target="#b19">[20]</ref>). Therefore, the quantizations required for our test models are more refined (more bits per vertex, typically 17 bits per vertex) than those used in reporting compression results before (typically 10 bits per vertex). Mesh compression and mesh simplification have been hot topics for research in the past few years and both fields have reached a certain degree of sophistication. The algorithm we proposed in this paper can be considered as a "simplification-based" mesh compression. The way we use the simplified mesh is to partition it and use the partition on the simplified mesh to induce a balanced partition on the input mesh, which is our primary goal. Therefore, we have completely ignored the geometry of the simplified mesh. It is interesting to see if the geometry of the simplified mesh can be used to further reduce the compressed geometry of the input model. Perhaps, non-linear prediction rules, based on the curvature of the simplified mesh, can be developed to more efficiently compress the geometry. To proceed further in this direction, a more refined and geometry-oriented partition scheme, such as <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b13">14]</ref>, is probably required.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Examples of mesh partition. a. This partition is induced from a simplified mesh; b, c. Partitions using z and y axes, respectively. The original model is the statue of David from Stanford's Digital Michelangelo Project Figure 2</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>, the geometry is compressed to about 16 bits per vertex at 16 bits per coordinate quantization. Note that with millions of Compression Results. Numbers in Parenthesis are bits per vertex. David contains 8,254,152 triangles and 4,129,614 vertices. Lucy contains 28,055,742 triangles and 14,027,872 vertices. St. Matthew (IV) has 36,550,076 triangles and 18,306,508 vertices</figDesc><table><row><cell></cell><cell>Uncompressed</cell><cell></cell><cell>Compressed</cell><cell>Compressed</cell><cell></cell><cell>Compression</cell></row><row><cell>Model</cell><cell>File Size</cell><cell cols="2">Quantization Connectivity</cell><cell>Geometry</cell><cell>Total</cell><cell>Ratio</cell></row><row><cell>David</cell><cell>173.3MB</cell><cell>16</cell><cell>1.34MB (2.6)</cell><cell cols="2">8.7 MB (16.8) 10.1MB</cell><cell>17</cell></row><row><cell>David</cell><cell>173.3MB</cell><cell>18</cell><cell cols="2">1.34MB (2.6) 11.7MB (22.8)</cell><cell>13 MB</cell><cell>13</cell></row><row><cell>Lucy</cell><cell>533MB</cell><cell>16</cell><cell>4.9MB (2.8)</cell><cell cols="2">30.7MB (17.5) 35.6MB</cell><cell>15.2</cell></row><row><cell>Lucy</cell><cell>533MB</cell><cell>18</cell><cell>4.9MB (2.8)</cell><cell>41.0MB (23.4)</cell><cell>46 MB</cell><cell>11.5</cell></row><row><cell>St. Matthew(IV)</cell><cell>768MB</cell><cell>16</cell><cell cols="3">6.18MB (2.7) 37.7MB (16.5) 43.9MB</cell><cell>17.86</cell></row><row><cell>St. Matthew(IV)</cell><cell>768MB</cell><cell>18</cell><cell cols="2">6.18MB (2.7) 49.8MB (21.8)</cell><cell>56MB</cell><cell>13.7</cell></row></table><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">ACKNOWLEDGEMENT</head><p>The authors would like to thank Marc Levoy for providing the David and St. Matthew datasets. The first author was supported by the National Science Foundation under grants EIA 00-04056 and CCR 00-86094. These findings do not necessarily reflect the views of NSF.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Single resolution compression of arbitray triangular meshes with properties</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Bajaj</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Pascucci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Zhuang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Data Compression Conference</title>
		<meeting>the Data Compression Conference<address><addrLine>Snowbird</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Optimized geometry compression for real-time rendering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Chow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Visualization 97</title>
		<imprint>
			<date type="published" when="1997" />
			<biblScope unit="page" from="415" to="421" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Deering</surname></persName>
		</author>
		<title level="m">Geometric compression. Proc. SIGGRAPH</title>
		<imprint>
			<date type="published" when="1995" />
			<biblScope unit="page" from="13" to="20" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Multiresolution analysis of arbitrary meshes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Eck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Derose</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Duchamp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Hoppe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of SIGGRAPH 95</title>
		<meeting>SIGGRAPH 95</meeting>
		<imprint>
			<date type="published" when="1995" />
			<biblScope unit="page" from="173" to="182" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Efficient compression of non-manifold polygonal meshes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gueziec</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Rossen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Taubin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Silva</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Visualization 99</title>
		<imprint>
			<date type="published" when="1999" />
			<biblScope unit="page" from="73" to="80" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Converting sets of polygons to manifold surfaces by cutting and stitching</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gueziec</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Taubin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Lazarus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">P</forename><surname>Horn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Visualization 98</title>
		<imprint>
			<date type="published" when="1998" />
			<biblScope unit="page" from="383" to="390" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Real time compression of triangle mesh connectivity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gumhold</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Strasser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of SIGGRAPH 98</title>
		<meeting>SIGGRAPH 98</meeting>
		<imprint>
			<date type="published" when="1998" />
			<biblScope unit="page" from="133" to="140" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Normal meshes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Guskov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Vidimce</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wim</forename><surname>Sweldens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Schroder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of SIGGRAPH 00</title>
		<meeting>SIGGRAPH 00</meeting>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="page" from="95" to="102" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Spectral compression of mesh geometry</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Karni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Gotsman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of SIGGRAPH</title>
		<meeting>SIGGRAPH</meeting>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="page" from="279" to="286" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Karypis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Kumar</surname></persName>
		</author>
		<ptr target="http://www-users.cs.umn.edu/karypis/metis/index.html" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Progressive geometry compression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Khodakovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Schroder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wim</forename><surname>Sweldens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of SIGGRAPH 00</title>
		<meeting>SIGGRAPH 00</meeting>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="page" from="271" to="278" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Progressive coding of 3D graphics models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">C</forename><surname>Kuo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE</title>
		<meeting>the IEEE</meeting>
		<imprint>
			<date type="published" when="1998" />
			<biblScope unit="page" from="1052" to="1063" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Out-of-core simplification of large polygonal models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Lindstrom</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of SIGGRAPH 00</title>
		<meeting>SIGGRAPH 00</meeting>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="page" from="259" to="262" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Interactive texture mapping</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Maillot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Yahia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Verrous</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of SIGGRAPH 93</title>
		<meeting>SIGGRAPH 93</meeting>
		<imprint>
			<date type="published" when="1993" />
			<biblScope unit="page" from="27" to="34" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Edgebreaker: Connectivity compression for triangle meshes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Rossignac</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transaction on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Multi-resolution 3D approximations for rendering complex scenes. Modeling in Computer Graphics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Rossignac</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Borrel</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1993" />
			<biblScope unit="page" from="455" to="465" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Qsplat: A multiresolution point rendering system for large meshes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Rusinkiewicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Levoy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of SIG-GRAPH 00</title>
		<meeting>SIG-GRAPH 00</meeting>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="page" from="343" to="352" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Geometry coding and vrml. IEEE Special Issue on multimedia signal processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Taubin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Horn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Lazarus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Rossignac</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Course on 3D geometry compression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Taubin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Rossignac</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of SIGGRAPH</title>
		<meeting>SIGGRAPH</meeting>
		<imprint>
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Triangle mesh compression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Touma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Gotsman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Graphics Interface&apos;98</title>
		<meeting>Graphics Interface&apos;98</meeting>
		<imprint>
			<date type="published" when="1998" />
			<biblScope unit="page" from="26" to="34" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Managing Gigabytes:Compressing and Indexing Documents and Images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">H</forename><surname>Witten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Moffat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">C</forename><surname>Bell</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999" />
			<publisher>Morgan Kaufmann Publishing</publisher>
			<pubPlace>San Francisco</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
