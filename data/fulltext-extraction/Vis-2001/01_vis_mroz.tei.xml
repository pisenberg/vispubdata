<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/pisenberg/grobid/grobid-0.6.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">RTVR -a flexible Java library for interactive volume rendering</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lukas</forename><surname>Mroz</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Helwig</forename><surname>Hauser</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">VRVis Research Center</orgName>
								<address>
									<settlement>Vienna</settlement>
									<country key="AT">Austria</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<address>
									<settlement>San Diego</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">RTVR -a flexible Java library for interactive volume rendering</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2021-02-19T20:45+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>interactive volume visualization</term>
					<term>Internet-based visualization</term>
					<term>Java</term>
				</keywords>
			</textClass>
			<abstract>
				<p>This paper presents several distinguishing design features of RTVR-a Java-based library for real-time volume rendering. We describe, how the careful design of data structures, which in our case are based on voxel enumeration, and an intelligent use of lookup tables enable interactive volume rendering even on low-end PC hardware. By assigning voxels to distinct objects within the volume and by using an individual setup and combination of look-up tables for each object, object-aware rendering is performed: different transfer functions, shading models, and also compositing modes can be mixed within a single scene to depict each object in the most appropriate way, while still providing rendering results in real-time. While providing frame rates similar to volume visualization using 3D consumer hardware, the approach utilized by RTVR offers much more flexibility and extensibility due to its pure software nature. Furthermore, due to the memory-efficiency of the data representation and the implementation in Java, RTVR can be used to provide volume viewing facilities over low-bandwidth networks, with almost full control over rendering and visualization mapping parameters (clipping, shading, compositing, transfer function) for the user. This paper also addresses specific problems which arise by the use of Java for interactive Visualization.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Volume visualization has proven to be a valuable tool for exploration, analysis, and presentation of data from numerous fields of application, such as medicine, geo sciences, or mathematics, for example. Within the visualization process, interactivity is not only crucial for efficient exploration and analysis of data; the communication of visualization results to a viewer also benefits from the ability to manipulate the visualization output while viewing, especially if complex 3D interrelations have to be understood. Data exploration and interactive presentation with low demands on computational and/or networking resources has been one of the driving factors for the development of the RTVR library. ¡ Mroz@VRVis.at, Hauser@VRVis.at Volumetric data-sets contain a variety of structures with different characteristics. With respect to the structure of the data and the goal of the visualization, different visualization techniques are appropriate for different objects to best convey the nature of the data. The most common approaches are surface rendering <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b12">13]</ref>, opacityweighted blending (direct volume rendering, DVR) <ref type="bibr" target="#b9">[10]</ref>, or maximum intensity projection (MIP) <ref type="bibr" target="#b22">[23]</ref>. The second motivation for the development of RTVR is to provide the user with means for individually selecting the best-suited combination of visualization parameters -transfer function, shading model, and compositing technique -for each object (i.e. part) of a volume, while still providing interactive frame rates.</p><p>RTVR integrates and extends several previously published techniques for interactive rendering <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b14">15]</ref> and efficient data transmission <ref type="bibr" target="#b13">[14]</ref> into a flexible framework which can be utilized to provide volume visualization on PC-hardware.</p><p>A common approach to the acceleration of software-based volume rendering is to employ techniques for efficiently avoiding the processing (projection) of irrelevant parts of the volume, i.e., empty (transparent) space, or interior parts of entirely opaque objects. Numerous techniques and data structures for this purpose have been published, utilizing, for example, octrees <ref type="bibr" target="#b10">[11]</ref>, distance volumes <ref type="bibr" target="#b2">[3]</ref>, or run-length encoding <ref type="bibr" target="#b10">[11]</ref>. Based on the observation, that for some compositing techniques, like MIP, parts of the volume which are relevant for the visualization result are strongly intermixed with irrelevant parts <ref type="bibr" target="#b14">[15]</ref>, a different approach for empty space leaping has been chosen for RTVR. By pre-filtering the volume data, voxels which may be of relevance for the visual representation of objects are identified and stored into a derived data structure -an enumeration of possibly relevant voxels -which is well-suited for fast rendering <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b15">16]</ref>. Although a similar strategy has been already introduced for shell rendering <ref type="bibr" target="#b21">[22]</ref>, our approach exhibits several advantages: ¢ The derived data is always traversed in a sequential (memoryaligned) order during rendering, thus increasing the efficiency of the processor cache.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>¢</head><p>Due to the projection technique we use (a fast shear-warp approach), no strictly spatially ordered traversal of the data is required, allowing reordering of data for efficient skipping of entire blocks of irrelevant voxels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>¢</head><p>Extracted voxels can be reordered in a way which allows efficient encoding, compression, and transmission of the data by exploiting spatial coherence. Rendering can be performed without restoring the original arrangement <ref type="bibr" target="#b13">[14]</ref>.</p><p>The above property makes RTVR well-suited for providing volume visualization over low-bandwidth networks, either for interactive presentation of data which has been generated off-line, or within a split client/server approach for on-line visualization. The challenge of interactively presenting images of volumetric data over networks, which also can be manipulated interactively on standard desktop-hardware, has been addressed by several approaches. The simplest way to display objects contained within volumetric datasets is to extract a polygonal surface representation of the object and to render a sufficiently simplified version of the model at the client (via a VRML browser, for example). Although current consumer 3D hardware is already quite powerful, it is still not possible to render highly detailed models from real-life data-sets at interactive frame rates. To overcome this problem, Engel et al. <ref type="bibr" target="#b6">[7]</ref> place the data-set on a server and use progressive transmission and progressive refinement to allow interactive surface extraction and viewing. They also presented an approach for providing direct volume rendering (DVR) at low-end clients <ref type="bibr" target="#b5">[6]</ref>. First a small, subsampled version of the data-set is transmitted to the client. During interactions which influence the rendered image, the local copy of the data is rendered using texture-mapping capabilities of consumer 3D hardware. After finishing the interaction, a high-quality rendering of the full-resolution data-set is computed on a server and transmitted to the client. Although these approaches work well for a limited number of users who share the same server, they can not be applied if an interactive visualization is published to a large group of viewers, for example over the Internet.</p><p>An approach which is better suited for "public" distribution of visualization results has been presented by Höhne et al. <ref type="bibr" target="#b19">[20]</ref>. A multi-dimensional array of images is rendered and stored in an extended Quicktime-VR format. The viewer can browse through different views of the data, imitating an interactive rotation, dissection, or segmentation, for example. While this approach provides high-quality images <ref type="bibr" target="#b20">[21]</ref> on low-end hardware, the user interaction is restricted by the "hidden" browsing mechanism (inbetween precomputed views). Furthermore, the size of even small-scale movies already becomes a limiting factor for viewing over low-bandwidth networks. The necessity to transmit an entire volume over the network is also the limiting factor to the approach of Hendin et al. <ref type="bibr" target="#b8">[9]</ref>. They introduced a VRML-based viewer, which performs volume rendering by the means of texture-mapping, displaying a set of axisaligned, textured polygons.</p><p>The approach implemented by the RTVR library is located inbetween the methods discussed above. The amount of data which actually is transmitted to the client for visualization is very low (about the size of several images), especially in comparison to the Quicktime-VR approach. The viewer is not restricted to precomputed views and has full control over visualization parameters. The only restriction for rendering is that just those parts of the volume which have been pre-selected (extracted) for presentation and transmission can be rendered. As usually just limited intervals of transfer function parameters produce meaningful results for a given visualization task, this restriction has proven not to be problematic.</p><p>Volume rendering by the use of special purpose hardware like the VolumePro board <ref type="bibr" target="#b16">[17]</ref>, or using 3D consumer hardware <ref type="bibr" target="#b17">[18]</ref>, achieves highly interactive frame-rates, allowing fast and efficient tuning of visualization parameters for entire volumes. Unfortunately, neither the VolumePro board, nor recent approaches based on textured polygons, allow to work with segmented data and to specify parameters on a per-object basis.</p><p>When used in a distributed client-server scenario, the softwareonly rendering approach of RTVR provides much more flexibility in terms of rendering parameters than volume previewing using texture mapping hardware, still at comparable or even lower costs in terms of bandwidth requirements.</p><p>In contrast to volume visualization toolkits like VolVis <ref type="bibr" target="#b0">[1]</ref> or VTK <ref type="bibr" target="#b18">[19]</ref>, which cover a very broad range of data representations and applications, RTVR is focused on fast visualization of isotropically spaced rectilinear volumes, with flexible handling of rendering parameters. The restriction to isotropical spacing is required to ensure comparable rendering quality regardless of the viewing direction. Data defined on other types of grids has to be resampled for rendering (this can be done on the fly, during the extraction of relevant voxels).</p><p>In the following we describe some of the distinguishing design issues of RTVR which are responsible for its excellent efficiency with respect to real-time volume rendering as well as its flexibility in terms of rendering parameters. Section 2 gives an overview over the basic concepts behind RTVR, as well as an overview over rendering features and visualization techniques which are realized on this basis. Section 3 presents RTVR's internal data structure, performance-relevant issues, and the rendering algorithms used. Timings for typical application scenarios are given in section 4, followed by the presentation of sample applications, which are based on the RTVR library (section 5). Interactive visualizations with RTVR corresponding to the images of this paper can be found at http://www.VRVis.at/vis/research/rtvr/</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Concepts and Capabilities</head><p>From a visualization-user's point of view, a volumetric data-set rarely resembles a monolithic block of data. Usually the data is assumed to be composed of a collection of spatial structures, i.e., objects, which have to be rendered or omitted from rendering to achieve the desired visualization goal. An obvious consequence of this observation, is to treat those structures within the volume individually during rendering, allowing separate adjustment of their visualization and rendering parameters (see <ref type="figure" target="#fig_0">Fig. 1</ref> for an example). Providing more degrees of freedom for the individual parameter adjustment allows better fitting of the visualization method to the inherent properties of the visualized objects. Consequently, within RTVR each voxel of the input volume is assigned to an object having a common set of rendering parameters, consisting of opacity and color transfer functions, a shading model, and a compositing method (for example MIP or DVR) for combining the voxels of an object during rendering.  Depending on the chosen set of rendering parameters, voxels of an object may or may not contribute to a rendering of the object. Especially if MIP is used for compositing, relevant and non-relevant voxels are strongly intermixed, making the usual approaches for skipping non-relevant data (octrees or distance volumes) inefficient. On the other hand, for most scenarios only a small percentage of an object's voxels contribute to an image. Considering this facts, overhead for skipping irrelevant voxels during rendering can be entirely avoided at moderate memory cost if potentially relevant voxels are extracted from the volume and stored within a derived enumeration data structure. For rendering, just this data structure, which contains a high percentage of relevant voxels, has to be considered.</p><p>Consequently, the basic rendering primitive of RTVR is a voxel, i.e., a single data-sample from the volume. As no spatial neighborhood information is available within the derived data, no interpolation can be performed inbetween samples without accessing the original volume. To avoid this expensive operation, the extracted voxels are projected individually. A method well-suited for fast rendering of such "sparse" voxel data is shear-warp projection, with nearest-neighbor interpolation within the base-plane. For objects with sharp opacity transitions, this rendering method allows zoom factors up to two with sufficient image quality (i.e. an image size of</p><formula xml:id="formula_0">£ ¥ ¦ § for ¦ § © § data sets, or £ ¤ ¦ for £ ¥ ¦</formula><p>volumes, see <ref type="figure" target="#fig_1">Fig. 2</ref>). For fuzzy objects even higher zoom factors are acceptable.</p><p>The visualization procedure using the above techniques is a twostep process <ref type="figure" target="#fig_2">(Fig. 3</ref>). During a segmentation and data extraction step, voxels which actually are relevant for the user-defined visualization goal are identified and extracted. The segmentation information which is required to distinguish objects within the data may be obtained together with the volume data itself from an external data source, or interactively computed using threshold-based segmentation. The actual selection of voxels can be balanced between a radical elimination strategy, which just selects voxels relevant for a specific parameter setting (for example, just the surface voxels of an entirely opaque object), and the selection of all voxels of an object, on the other extreme. Although the latter approach at the first glance seems to be useless as an acceleration of rendering, it allows to freely adjust the transfer function during rendering. For the chosen shear-warp based rendering technique, the order of projecting voxels which share the same distance ( ) to the base-plane is not relevant. Thus it is possible to shuffle such voxels without any restriction. By arranging voxels with the same into two sub-groups which contain voxels relevant, respectively irrelevant to the current transfer function, efficient skipping of irrelevant parts within the extracted data is achieved. Using specific voxel sorting schemes for different types of transfer functions and compositing modes allows to skip voxels irrelevant for the current parameter settings without resorting <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b14">15]</ref>. If, for example, voxel opacity is chosen to correspond to gradient magnitude, and voxels are ordered according to this attribute, entire blocks of voxels can be skipped as soon as the first entirely transparent voxel within a group is encountered.</p><p>The voxel extraction step usually leads to a significant data reduction, as only a small portion of the original volume actually belongs to objects of interest. Especially for surface-like structures, the extracted voxel data can be efficiently compressed exploiting coherence among voxel positions and attribute values. The resulting compact representation of the volume can be used to store visualization results for later interactive viewing, or for transmission and on-line viewing over low-bandwidth networks <ref type="bibr" target="#b13">[14]</ref>.</p><p>For performing the actual visualization and rendering, the extracted voxels are assigned to distinct objects and inserted into a scene graph. Using a fast, look-up table based approach (see section 3.4 for details), not only opacity and color, but also the shading model can be defined individually for each object. This allows to combine rendering using standard shading models like Phong shading with objects that are rendered by the use of non-photorealistic shading <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b4">5]</ref>. Such combination is, for example, useful to provide context and shape information almost without occlusion (see <ref type="figure" target="#fig_3">Fig. 4</ref>).</p><p>Most volume rendering packages only allow to render a whole data-set using either the usual opacity-blended compositing (DVR) <ref type="bibr" target="#b9">[10]</ref>, and surface rendering <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b15">16]</ref>, or maximum intensity projection (MIP) <ref type="bibr" target="#b14">[15]</ref>. RTVR allows to separately define the compositing mode within each object (DVR, MIP, or summation), as well as an inter-object compositing mode (two-level volume rendering <ref type="bibr" target="#b7">[8]</ref>). This allows to choose the most appropriate compositing technique for each object, depending on the structure of the data and the goal of the visualization (see <ref type="figure" target="#fig_4">Fig. 5</ref>, color plate d).</p><p>Among other "standard" techniques, RTVR supports the clipping of volumes or sets of individual objects at planes and more complex structures. Clipped parts of objects can be omitted from rendering -which is the most common approach -or rendered using a different set of rendering parameters (see color plate e). By using for example Phong shading for non-clipped voxels and a contour-only rendering for clipped parts, insight into an object can be given, while still providing a sketch of the most significant features of the clipped part as a context (see <ref type="figure" target="#fig_0">Fig. 1, skin)</ref>.</p><p>Another feature of RTVR is the support for visualization of time series of volumetric data and of multi-dimensional parameter-series of volumes from simulation. The large memory demands of such data are compensated by the fact, that data extracted from a volume and used by RTVR for rendering is usually much smaller than the original volume. Only extracted data of the currently displayed volume has to be kept in memory for rendering, remaining parts of the volume and data which belongs to other time (parameter) steps can be kept on disk.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Intrinsics and Implementation</head><p>For each voxel identified during the extraction as potentially relevant for rendering, the coordinates and a set of attributes, like data value, gradient direction, and magnitude are stored in the derived data structure. For rendering, a subset of the attributes is selected as an information source for visualization mapping, and transformed into a compact representation which is well-suited for fast rendering.</p><p>The attribute values are used to index look-up tables to obtain and modulate color and opacity values in a way which is defined by the selected rendering mode. The look-up tables allow to implement different transfer functions and shading models in a very effective way.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">The RenderList as Data Representation</head><p>The voxel extraction is performed by scanning the volume slice by slice, producing for each slice of each object a so-called rendered using object properties rendered using clipped properties not contributing due to transfer func.  RenderListEntry, containing the object's relevant voxels within the slice <ref type="figure" target="#fig_5">(Fig. 6</ref>). The RenderListEntrys of each object are grouped into an array -a RenderList. Thereby, the original (implicit) spatial arrangement of data values within the 3D array is sacrificed for an object-aware enumeration scheme of arbitrarily arranged voxels. All the attributes of a voxel are stored in separate arrays, the RenderListEntry itself just stores additional information which is required for rendering: The "blocking" of voxels into non-contributing, clipped, etc., as shown in <ref type="figure" target="#fig_5">figure 6</ref>, is achieved by simply reordering the voxels within RenderListEntrys during clipping and optimization operations. The optimization, i.e., identification and reordering of currently non-relevant voxels within RenderListEntrys is performed by a background thread, which is activated whenever the application is idle and no rendering is performed. No effort has to be spent on skipping those voxels during following rendering passes. The background optimization is especially useful for accelerating the rendering of "fuzzy" objects, where no exact information about the relevance of voxels is available at the time of extraction.</p><p>For fast rendering, position and attribute information for each voxel is fitted into a single 32 bit integer. The ! and " coordinates of the voxel are stored using 8 bit each, the coordinate is identical for all voxels within a RenderListEntry as they are all extracted from the same slice of the volume and thus it is stored just once. The common coordinate stored at the RenderListEntry for all voxels is referred to as for reasons of simplicity. In fact, three copies of the data and thus three RenderLists are required for the shear-warp algorithm -each one grouped and sorted by one of the three coordinates. Using just 8 bits per coordinate limits the maximum extent of an object to ¦ voxels. Larger volumes and objects are internally split into ¦ § © § pieces and the missing high bits of the coordinates are encoded into an offset, which is also stored once at the RenderListEntry. The remaining 16 bits are typically split into a 12 bit and a 4 bit field which store the data attributes used for rendering as previously described. This "renderable" voxel representation is attached as an additional array to each RenderListEntry, and is actually the only per-voxel information accessed during rendering.</p><p>Although the limitation to two voxel attributes with an overall of 16 bit for rendering is clearly a limitation with respect to flexibility and accuracy, the compact representation is perfectly suited for very fast rendering. In combination with the ability to re-order voxels within a RenderListEntry the rendering process turns into a "streaming" of sequential chunks of voxels -an optimal scenario for caching and prefetching as implemented by recent processors. The problem of the low bit resolution of data attributes for rendering can be addressed by applying intelligent remapping when copying voxel attribute data into it's renderable form: instead of clipping low bits of an attribute, a logarithmic remapping can be performed, or a certain sub-range of attribute values can be mapped to the range of values available for rendering. For scenarios which require more than two attributes for evaluating a voxel's contribution, special rendering modes can be defined which use more than 32 bit of information per voxel, at the cost of slower rendering of the affected object. Java Peculiarities -due to the specific way of memory management as employed by current Java virtual machines (VM), a special data handling and caching functionality is used by RTVR to support the visualization of huge data-sets (series of dozens to hundreds of volumes), which are produced, for example, by numerical simulation applications <ref type="bibr" target="#b1">[2]</ref>. The maximum amount of memory which is available to a VM has to be fixed at initialization time. As the garbage collection and object allocation mechanism sweeps through the entire address space of the VM, allocating more memory to the VM than physically available would lead to excessive paging and strong performance degradation. Instead of allocating sufficient memory to fit even the largest data-sets, RTVR uses a separate memory and disk cache for space-demanding parts of it's data structures, i.e., the original volume data, the extracted voxel attributes, and the renderable voxel data. Data, which is currently not used for rendering, is placed into the memory cache and thereby potentially written to disk by a background thread. Requests for recently used data can usually be satisfied out of the memory cache, whereas reading less recently accessed data may require to fetch it from disk. The cache feature is used when large data-sets are visualized locally, and is disabled when RTVR is used within a webbrowser.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">The RTVR Scene Graph</head><p>After extraction, the RenderLists and attribute data of volumetric objects are encapsulated into VolumeObjects and added to a common scene graph for rendering <ref type="figure" target="#fig_7">(Fig. 7)</ref>. A common task of all types of nodes within the scene graph is to deliver up-to-date RenderLists which represent the content of their subgraphs. In the following a short overview over the most important types of nodes is given: Each node is responsible for tracking changes of parameters which affect it's content and for performing appropriate actions according to changes. The actual update of renderable data to reflect parameter changes is carried out as late as possible, i.e., when a request for the affected voxel data is issued for rendering (lazy evaluation). Keeping just the currently visible data up-to-date improves the responsiveness of the visualization during interactive parameter changes # significantly.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">User Interaction</head><p>The philosophy of data manipulation within RTVR is objectoriented. One of the objects within the currently displayed scene is selected to be the "active" object, for example by pointing into the rendered scene. The most important properties of the active object can be changed by pressing one of the mouse keys and dragging over the image. Transfer function contrast (color and alpha), opacity, and color can be changed directly within the 3D view. Furthermore, camera position, light source position, and zoom factor can be set within the view. The mapping of mouse actions to parameter changes is performed by an InteractionHandler component, which can be adapted to meet the needs of specific applications (for example to implement stream line integration from the position of a mouse click for a flow visualization application).</p><p>As a supplement to parameter manipulation within the rendered view, all parameters of the active object can be adjusted using standard user-interface components which are automatically generated by RTVR. This parameter panel allows an explicit selection of the active object and adjustment of its parameters, and can (but does not have to) be used within any application which utilizes RTVR for visualization. Java Peculiarities -for Java-based graphical user interfaces, basically two APIs are available: the AWT, available in its present form since Java version 1.1, and the more sophisticated SWING 1.1, which is part of the Java runtime since version 1.2. The front end (GUI and rendering output) of RTVR is provided using both, either AWT or SWING. As most web browsers currently provide a 1.1 virtual machine only, an AWT implementation is provided for compatibility reasons, despite of all its inconveniences and deficiencies. The rendering performance of the SWING implementation benefits, for example, from a faster image handling (BufferedImage) introduced in Java 1.2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Rendering</head><p>To achieve interactive rendering rates even on standard desktop hardware, a fast shear-warp based parallel projection is used. Rendering to the base-plane is performed using back-to-front compositing of voxels by the use of nearest-neighbor interpolation. The warp step of the algorithm, which especially for large image sizes may be more time-consuming than the voxel projection itself, can also be carried out by texture mapping using OpenGL. In comparison to a previously published version of this fast algorithm <ref type="bibr" target="#b15">[16]</ref>, RTVR includes an extended version, which provides more flexibility for mapping voxel attributes to color and opacity. Three lookup tables (LUTs, typically 1x4 bit, 2x12 bit) are available at each RenderListEntry for implementing shading and transfer function mapping. A set of combination patterns for the voxel attributes and look-up tables is provided by RTVR (See <ref type="figure" target="#fig_8">Fig. 8</ref>) and selected by choosing an appropriate rendering mode for an object. This scheme of combining LUTs allows efficient processing while still enabling various ways of selectively applying visualization techniques to objects within the data. The RenderListEntry can also be extended to provide user-defined rendering functionality for it's voxels, which finally allows to implement any desired operation on voxel attributes and look-up tables.</p><p>Shading operations are performed using an approach which is based on look-up tables, with a 12-bit representation of the gradient vector as an index. Two shading models are provided by RTVR: a Phong shading table (color plate a), a non-photorealistic shading table which enhances the contour of an object <ref type="bibr" target="#b4">[5]</ref>  <ref type="figure" target="#fig_3">(Fig. 4)</ref>, and a combination of both (color plate b). The shading tables have to be re-computed after every change of viewer or light source position, which is not time-critical due to their small size (4096 entries). For rendering, the shading table is placed into LUT2 <ref type="figure" target="#fig_8">(Fig. 8)</ref>, and indexed by the 12 bit data-channel which contains the gradient vector. The output of the look-up is an intensity value, which is then used to access the color transfer function in LUT3. Splitting shading into two stages allows to reuse the same shading table for objects with different color transfer functions.</p><p>The opacity of a pixel is influenced by several sources. An allobject opacity value is always included into the computation and can be used to tune the overall opacity of entire objects. The individual opacity of each voxel is modulated by various combinations of data channel and look-up operations. In the following, a few sample color and opacity calculation setups will be discussed, which implement different volume rendering approaches. ¢ display of (iso-)surfaces <ref type="figure" target="#fig_8">(Fig. 8a)</ref>: the surface voxels of an object have to be shaded and blended using the object opacity. A Phong shading table is put into LUT2, the resulting intensity value is used to access a color transfer function in LUT3. The transfer function is a ramp of object color values starting with the color of the highlight (white) and evolving towards maximum saturation and minimum lightness (object color, ambient light, see color plate a). By just rendering a thin layer of voxels which form the surface, the object opacity can be used to influence the transparency of the surface in the same way as an alpha-value influences the appearance of a polygonal surface model. ¢ non-shaded DVR <ref type="figure" target="#fig_8">(Fig. 8b)</ref>: LUT3 contains the color and opacity transfer function and and is indexed by the 12 bit data value <ref type="figure" target="#fig_4">(Fig. 5, brain)</ref>. Optionally, voxel opacity can be modulated by the content of LUT1 accessed, for example, by gradient magnitude encoded in the 4 bit data field. ¢ Bright object outlines <ref type="figure" target="#fig_8">(Fig. 8c</ref>): LUT2 is loaded with a shading table which maps the angle between viewing direction and gradient direction to intensity. LUT3 contains a color transfer function which is used to tune contrast and color for the specific object. If the result of the LUT2 look-up is also used as voxel opacity, the object becomes almost entirely transparent -except for the contours which remain opaque (color plate c, skin).</p><p>The implementation of object-aware compositing requires the use of two separate pixel buffers, one for compositing within an object and one for compositing of the global image <ref type="figure" target="#fig_8">(Fig. 8)</ref>. Scenes which require only a single compositing mode (within and inbetween objects) do not require two pixel buffers and are rendered more efficiently with the usual single-buffer approach.</p><p>If pure MIP is used, voxels can be sorted and grouped into RenderListEntrys by value instead of the coordinate <ref type="bibr" target="#b14">[15]</ref>. In this case, projecting sorted voxels from lowest valued to highest valued ones eliminates the need for maximum search. However, if MIP is combined with other compositing techniques within the scene, back-to-front rendering and thus sorting by the coordinate is required also for objects composited by MIP, as they may interleave with other objects rendered with different techniques.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Performance</head><p>High responsiveness of a visualization system to user actions is a crucial factor for the effectivity of data exploration and analysis. The rendering times for the surface rendering <ref type="bibr" target="#b15">[16]</ref>, MIP <ref type="bibr" target="#b14">[15]</ref> and two-level rendering approach <ref type="bibr" target="#b7">[8]</ref> used by RTVR have been published in previous work. Thus, instead of broadly surveying the behavior of each method, a comparison of the measured times for rendering the same data-set with RTVR using various methods is given in table 1. The measurements have been carried out on a PII/400MHz PC using the virtual machine of JDK1.3 from Sun and the AWT front-end of RTVR. The size of the rendered images is £ ¥ ¦ §</p><p>. The first row shows timings for the data-set shown in figure 4. Skin, bones, and vessels are represented by their surface voxels. The rendering is carried out using MIP, DVR, a gray-scale DVR view, and a combination of DVR for the vessels and MIP for bones and skin. The last column contains the times for rendering the same scenes using texture mapping and OpenGL for the warp step of the projection. In contrast to software warp, which for large images (</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>£ ¤ ¦</head><p>) usually is already the dominant factor for rendering time, GL based warp is insensitive to the size of the output image, and takes 10-20ms on most current consumer graphics cards. The second row displays timings for the head data shown in color plate a, with vessels and skin displayed as additional surfaces. The dataset in row 3 is similar to the one depicted in color plate f. The basin is represented by its surface voxels, the chaotic attractor has a highly complex internal structure, and is thus considered a volumetric object.</p><p>The pure rendering time reflects the rendering performance for most interactions. These include interactive changes of the viewing parameters (viewer position and zoom), changes to content of lookup tables (moving light source, changing transfer function), and changes to the parameters and rendering modes of objects. Clipping operations require scanning and reordering of object voxels. During simple clipping of all objects at an axis aligned plane, the response time increases by approximately 40% compared to when changing viewer position. Time required for clipping at more complex objects depends on the complexity of the test which has to be performed for each voxel. Clipping of a complex scene at an oblique plane, for example, can be done with 1-2 frames per second. During browsing through large (time or parameter) series of volumes, voxel data may have to be fetched from disk cache, thus increasing the response time by the time required to read the data. Depending on the size of the scene, this may range from few milliseconds, to more than one second. The time for extraction of new objects from a volume depends on the complexity of the segmentation criteria and on the amount of voxels selected (gradient computation). The extraction of an iso-surface from a ¦ volume for example requires approximately 1.5 seconds, including gradient computation.</p><p>The choice of the virtual machine used to execute the application has severe impact on the performance. Among the tested runtime environments, fastest execution and rendering has been observed for the VMs <ref type="figure" target="#fig_0">(1.1.6++, 1.2, 1.</ref>3) from Sun on Windows and (1.1.8, 1.2, 1.3) from IBM on Windows and Linux. Virtual machines provided by web-browsers are in general slower, probably due to additionally performed security checks. Worst results are obtained by the VM which is used by Netscape browsers (Version $ 4.7.4) on Linux -more than ten times slower than the timings in table 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Sample Applications of RTVR</head><p>The RTVR library has been successfully used to provide volume visualization functionality within two projects. The first application is a volume viewer which can be used for fast volume data exploration and analysis in the field of medical data. Visualization results created within the viewer (extracted objects and visualization parameters) can be stored using a compact representation (typically just a few hundred kilobytes) for later interactive viewing or for publication on the Internet. An applet version of the viewer which provides the same functionality, except for the extraction and creation of new objects, can be used to view previously stored data within web pages (interactive versions of this paper's images can be found at http://www.VRVis.at/vis/research/rtvr/).</p><p>A second application which makes use of the capabilities of RTVR is a visualization and analysis system for 3D dynamical systems (discrete non-invertible maps) <ref type="bibr" target="#b1">[2]</ref>. The application is used to analyze and visualize structures and events within the phase space of the systems. For this application, objects of interest are attractors (often complex and chaotic), their basins of attraction (i.e., the set of all system states which are attracted by them) and surfaces which separate regions with different properties (color plate f). Events (bifurcations) can be caused by contacts between structures as some parameter of the dynamical system is changed. The process of visualization is split into two parts. A volumetric representation of the structures within phase space is computed offline ( ¦ § © volumes) and stored in a space-efficient form. For the analysis of bifurcations, sequences of up to hundreds of volumes are computed for different values of the bifurcation parameter. For investigation the data produced by the simulation is loaded into the viewer (the diskcache is extremely useful for large sequences of volumes) which provides application specific functionality, like the shooting of trajectories by pointing with the mouse at the start position. To ease the detection of contacts between objects, distance information can be mapped to voxel color, as shown in color plate f. The feature of mixing MIP with other compositing methods has proven to be especially useful for visualizing chaotic attractors. Their complex internal structure is well captured using MIP while producing little occlusion. At the same time, the attractor's basin of attraction can be rendered as a shaded surface.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusions</head><p>Using an efficient data representation and a fast rendering method volumetric data can be displayed at an average desktop PC at frame rates which are comparable with those which are achieved for volume rendering by consumer 3D hardware, while providing significantly more flexibility, like object-wise transfer functions, shading  <ref type="table">Table 1</ref>: Timings for various data-sets and rendering modes models and compositing methods (MIP, DVR, ...). Taking into account peculiarities of Java, all those capabilities can be made available to users with standard desktop hardware using different operating systems. Using a compact volume representation, the RTVR library can be also exploited to provide highly interactive and flexible presentations of visualization results over networks, like the Internet.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>RTVR allows the assignment of shading and compositing methods on a per-object basis. The combination of Phong shading (objects 1a, 2, 5, 8) with non-photorealistic methods (1b, 5, 7, 8), of surface rendering (1, 2, 5, 7), DVR (9), MIP (3, 8), and summation (x-ray) rendering (4 and 6) is done in real-time.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Rendering quality:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Volume data flow within RTVR: first, voxels with actually contribute to the visualization are extracted, then this representation of volumetric objects is used for fast and flexible rendering.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Combination of different shading models: Phong lighting for bones and vessels, contour rendering for the skin.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 :</head><label>5</label><figDesc>Combination of different compositing modes: DVR for the brain, summation for the surrounding bone and tissue.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 6 :</head><label>6</label><figDesc>Volumetric object representation: voxels which are relevant for rendering an object are extracted slice by slice from the volume and stored into RenderLists.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>¢</head><label></label><figDesc>an object-level opacity value for clipped and regular voxels ¢ look-up tables for mapping of clipped and regular voxels ¢ specification of rendering and compositing modes for clipped and regular voxels ¢ a reference to an array which contains a renderable representation of voxel data (derived from voxel attributes). Within this array, voxels between first and firstClipped belong to the regular part of an object, voxels between first-Clipped and lastInSlice belong to the clipped part. Only voxels between first and last, respective first-Clipped and lastClipped have to be rendered, voxels between last and firstClipped, and lastClipped and lastInSlice are not relevant for the current transfer function and rendering mode.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 7 :</head><label>7</label><figDesc>RTVR scene graph and user interaction handling ¢ VolumeObject: holds the RenderList of a single object as well as information on all parameters which affect the appearance and visualization mappings for this object.¢GroupNode: the shear-warp renderer performs a back-tofront rendering of RenderListEntrys. In addition to providing a simple way of handling multiple objects, the main purpose of the GroupNode is to merge and sort the RenderLists of its sub-graphs into a single list which is sorted by the current main viewing axis ( ).¢ Depending on the value of a selection parameter, the SwitchNode provides the RenderList of one of it's children. SwitchNodes allow to browse through multidimensional arrays of volumes, like time series, or parameterdependent simulation results.¢ ClipNodes filter and reorder the voxels of it's child nodes to implement clipping.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 8 :</head><label>8</label><figDesc>Sample LUT combinations during voxel rendering within RTVR: a) shaded surface b) non-shaded DVR c) contour rendering. An overall of 4 combination schemes for voxel opacity and 9 combination schemes for voxel color are available.</figDesc></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Acknowledgements</head><p>This work has been carried out as part of the basic research on visualization at the VRVis Research Center in Vienna, Austria (http://www.VRVis.at/vis/), which partly is funded by te Austrian Kplus research program. The medical data-sets depicted in this paper are property of Tiani Medgraph, Vienna, Austria. The authors want to thank Meister E. Gröller, Csébfalvi Balázs, and the team of Tiani Medgraph.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0" />			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">VolVis: A diversified volume visualization system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Avila</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kaufman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Pfister</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Silva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Sobierajski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings IEEE Visualization &apos;94</title>
		<meeting>IEEE Visualization &apos;94</meeting>
		<imprint>
			<date type="published" when="1994" />
			<biblScope unit="page" from="31" to="39" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Studying basin bifurcations in nonlinear triopoly games by using 3D visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G.-I</forename><surname>Bischi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Mroz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Hauser</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>Accepted for publication in the Journal of Nonlinear Analysis</note>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Proximity clouds -an acceleration technique for 3D grid traversal. The Visual Computer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Sheffer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1994" />
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="27" to="38" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Fast visualization of object contours by non-photorealistic volume rendering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Csebfalvi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Mroz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Hauser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>König</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Gröller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EUROGRAPHICS 2001</title>
		<meeting>EUROGRAPHICS 2001</meeting>
		<imprint>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Volume illustration: nonphotographic rendering of volume models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ebert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Rheingans</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings IEEE Visualization</title>
		<meeting>IEEE Visualization</meeting>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="page" from="195" to="202" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Combining local and remote visualization techniques for interactive volume rendering in medical applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Engel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Hastreiter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Tomandl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Eberhardt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Ertl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings IEEE Visualization</title>
		<meeting>IEEE Visualization</meeting>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="page" from="449" to="452" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Isosurface extraction techniques for web-based volume visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Engel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Westermann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Ertl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings IEEE Visualization &apos;99</title>
		<meeting>IEEE Visualization &apos;99</meeting>
		<imprint>
			<date type="published" when="1999" />
			<biblScope unit="page" from="139" to="146" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Two-level volume rendering -fusing MIP and DVR</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Hauser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Mroz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G.-I</forename><surname>Bischi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Gröller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings IEEE Visualization</title>
		<meeting>IEEE Visualization</meeting>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="page" from="211" to="218" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Medical volume rendering over the www using VRML and Java</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Hendin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>John</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Shochet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of MMVR</title>
		<meeting>MMVR</meeting>
		<imprint>
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Ray tracing volume densities</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">T</forename><surname>Kajiya</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACM SIGGRAPH &apos;84</title>
		<meeting>ACM SIGGRAPH &apos;84</meeting>
		<imprint>
			<date type="published" when="1984" />
			<biblScope unit="page" from="165" to="174" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Fast volume rendering using a shear-warp factorisation of the viewing transform</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Lacroute</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Levoy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACM SIGGRAPH &apos;94</title>
		<meeting>ACM SIGGRAPH &apos;94</meeting>
		<imprint>
			<date type="published" when="1994" />
			<biblScope unit="page" from="451" to="459" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Display of surfaces from volume data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Levoy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer Graphics &amp; Applications</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="29" to="37" />
			<date type="published" when="1988-05" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Marching cubes: a high resolution 3D surface construction algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">E</forename><surname>Lorensen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">E</forename><surname>Cline</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACM SIGGRAPH&apos;87</title>
		<meeting>ACM SIGGRAPH&apos;87</meeting>
		<imprint>
			<date type="published" when="1987" />
			<biblScope unit="page" from="163" to="189" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Space-efficient boundary representation of volumetric objects</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Mroz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Hauser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Joint EUROGRAPHICS -IEEE TCVG Symposium on Visualization</title>
		<meeting>the Joint EUROGRAPHICS -IEEE TCVG Symposium on Visualization</meeting>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="page" from="193" to="202" />
		</imprint>
	</monogr>
	<note>Data Visualization</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Real-time maximum intensity projection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Mroz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>König</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Gröller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Data Visualization &apos;99, Proceedings of the Joint EUROGRAPHICS -IEEE TCVG Symposium on Visualization</title>
		<imprint>
			<date type="published" when="1999" />
			<biblScope unit="page" from="135" to="144" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Mastering interactive surface rendering for java-based diagnostic applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Mroz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Wegenkittl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Gröller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings IEEE Visualization</title>
		<meeting>IEEE Visualization</meeting>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="page" from="437" to="440" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">The volume pro real-time ray-casting system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Pfister</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hardenbergh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Knittel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Seiler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACM SIGGRAPH&apos;99</title>
		<meeting>ACM SIGGRAPH&apos;99</meeting>
		<imprint>
			<date type="published" when="1999" />
			<biblScope unit="page" from="251" to="260" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Interactive volume rendering on standard PC graphics hardware using multi-textures and multi-stage rasterization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Rezk-Salama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Engel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Greiner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Ertl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of SIGGRAPH/EUROGRAPHICS Graphics Hardware Workshop</title>
		<meeting>SIGGRAPH/EUROGRAPHICS Graphics Hardware Workshop</meeting>
		<imprint>
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">The visualization toolkit. In An Object-Oriented Approach to 3D Graphics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Schroeder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Lorensen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1996" />
			<publisher>Prentice Hall</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Interactive volume visualization using intelligent movies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Schubert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Pflesser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Pommert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Preiesmeyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Riemer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Th</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Schiemann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Tiede</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Steiner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Höhne</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings Medicine Meets Virtual Reality</title>
		<meeting>Medicine Meets Virtual Reality</meeting>
		<imprint>
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">High quality rendering of attributed volume data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Tiede</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Schiemann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">H</forename><surname>Hohme</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings IEEE Visualization &apos;98</title>
		<editor>D. Ebert, H. Hagen, and H. Rushmeier</editor>
		<meeting>IEEE Visualization &apos;98</meeting>
		<imprint>
			<publisher>IEEE Computer Society Press</publisher>
			<date type="published" when="1998" />
			<biblScope unit="page" from="255" to="262" />
		</imprint>
	</monogr>
	<note>Rendering</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Shell rendering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">K</forename><surname>Udupa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Odhner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer Graphics &amp; Applications</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="58" to="67" />
			<date type="published" when="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Techniques for speeding up high-quality perspective maximum intensity projection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">J</forename><surname>Zuiderveld</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">H J</forename><surname>Koning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Viergever</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition Letters</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="507" to="517" />
			<date type="published" when="1994" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
