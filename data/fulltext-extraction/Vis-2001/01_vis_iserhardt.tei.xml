<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/pisenberg/grobid/grobid-0.6.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Case Study: Medical Web Service for the Automatic 3D Documentation for Neuroradiological Diagnosis</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Iserhardt-Bauer</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Visualization and Interactive Systems Group</orgName>
								<orgName type="institution">University of Stuttgart</orgName>
								<address>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Hastreiter</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution" key="instit1">Neurocenter</orgName>
								<orgName type="institution" key="instit2">University of Erlangen-Nuremberg</orgName>
								<address>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Ertl</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Visualization and Interactive Systems Group</orgName>
								<orgName type="institution">University of Stuttgart</orgName>
								<address>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Eberhardt</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Division of Neuroradiology</orgName>
								<orgName type="institution">University of Erlangen</orgName>
								<address>
									<settlement>Nuremberg</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Tomandl</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Division of Neuroradiology</orgName>
								<orgName type="institution">University of Erlangen</orgName>
								<address>
									<settlement>Nuremberg</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<address>
									<settlement>San Diego</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Case Study: Medical Web Service for the Automatic 3D Documentation for Neuroradiological Diagnosis</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2021-02-19T20:45+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Medical visualization</term>
					<term>segmentation</term>
					<term>automatic web service</term>
					<term>video generation</term>
				</keywords>
			</textClass>
			<abstract>
				<p>This case study presents a medical web service for the automatic analysis of CTA (Computer Tomography Angiography) datasets. It aims at the detection and evaluation of intracranial aneurysms which are malformations of cerebral blood vessels. To obtain a standardized 3D visualization digital videos are automatically generated. The time-consuming video production caused by the manual delineation of structures, software based volume rendering, and the interactive definition of an optimized camera path is considerably improved with a fully automatic strategy. Therefore, a previously suggested approach [11] is applied which uses an optimized transfer function as a template and automatically adapts it to an individual dataset. Furthermore, we introduce hardware-accelerated morphologic filtering in order to detect the location of mid-size and giant aneurysms. The actual generation of the video is finally integrated into a hardware accelerated off-screen rendering process based on 3D texture mapping ensuring fast visualization of high quality. Overall, clinical routine can be considerably assisted by providing a web based service combining automatic detection and standardized visualization.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Motivation</head><p>The increasing capabilities of magnetic resonance imaging (MRI) and multislice spiral computed tomography (MSCT) to acquire volumetric data with near isotropic voxels makes three dimensional postprocessing a necessity, especially in studies of complex structures like intracranial vessels.</p><p>While interactive use of 3D visualization is often helpful it holds the danger of being user dependent and thus leading to inaccurate results <ref type="bibr" target="#b7">[8]</ref>. Therefore, standardized visualization procedures which generate well defined video sequences can be evaluated for sensitivity and specificity and should more and more replace individual interactive 3D visualization in the future. Due to the significant effort, the required high technical and medical background and the avoidance of user dependency, the video sequences should be generated fully automatically. This relates not only to the video production but also to the complete preprocessing part, including segmentation and visualization.</p><p>Hardware supported 3D texture mapping is a common approach for interactive visualization which can be used also for producing the video sequences. The drawback of this approach is the need for expensive graphics workstations. To avoid these costs remote visualization using the internet is a necessary approach. One approach is that large volume data sets will be rendered on the server-side and a stream of resulting images is sent back to the client <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b1">2]</ref>. On the client side only a 2D viewer is required to display the received images. As an advantage of this approach expensive high-end graphics hardware is efficiently used from different locations. Besides, there are further applications which use VRML-plug-ins to render the data set in a web browser <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b8">9]</ref> where the user can manipulate the data set directly.</p><p>In this case study a web service is presented to generate digital video sequences for 3D documentation automatically. The complete process is split into several subtasks, like defining the camera path, segmentation, detecting the aneurysm and rendering, which are described in Section 2. After a brief overview of the used web architecture in Section 3, some results are discussed which show the usefulness of the presented application in Section 4. Finally Section 5 presents conclusions and ideas for future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Automatic video generation</head><p>In this case study the automatic generation of digital video sequences is integrated into a web service in order to avoid requiring expensive graphics hardware on the user side. The complete process, which is shown in <ref type="figure" target="#fig_1">Figure 1</ref> is separated into several tasks. The web service is responsible for most of the tasks, including segmentation, rendering and video generation. The physician only has to provide the medical data together with some parameters. All tasks on the server side are performed automatically which will be shown in the following section.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Segmentation</head><p>Generating high quality digital video sequences requires a number of segmentation tasks. Typically CT data sets contain a lot of noise and irrelevant information. In order to get a high quality visualization it is necessary to reduce the unwanted information. We decided to use transfer functions for this task. Segmentation is also used to detect the position of the aneurysm. This information is used to define the camera path. There are mainly two parameters for the camera path which depend on the position of the aneurysm. One is the view point of the camera, the other one is the distance between camera and aneurysm. To detect the position of the aneurysm we use a simple threshold operation and the morphologic erosion operator. The following subsection describes the two segmentation methods in more detail.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.1">Transfer functions</head><p>The need for the use of transfer functions <ref type="bibr" target="#b4">[5]</ref> is obvious: It allows to reduce the information and it enables semi-transparent rendering of volume data sets. The drawback of this technique is that the definition of the transfer function requires high technical and medical experience. To avoid these requirements it is necessary to integrate an automatic approach for generating optimized transfer functions. For this part an existing approach from Kindlmann <ref type="bibr" target="#b9">[10]</ref> and a modification by Rezk-Salama <ref type="bibr" target="#b10">[11]</ref> is used. The idea is to use a reference data set and a transfer function as templates to generate an optimized transfer function for the specified volume data set. The so called position function of the reference data set, which describes the average distance of a data point to a boundary, will be computed by a non-linear distortion for optimal alignment for both position functions. Depending on the parameters of the transformation different information is given (see <ref type="figure" target="#fig_2">Figure 2</ref>). The left image demonstrates the complete size of the aneurysm, showing predominantely the thrombosis, while the right image demonstrates the blood filled parts of the aneurysm. Both aspects are necessary for optimized therapy planning. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.2">Detection of the aneurysm</head><p>To make sure that the video records the aneurysm from a suitable position (the camera should not be inside the aneurysm and not be too far away) and that it always points into the direction of the center of the aneurysm, it is necessary to detect the intracranial aneurysm. The detection of intracranial aneurysm is mainly based on visual inspection of the generated video sequences. In some patients more than one aneurysm is found and the size may vary ranging from 2 mm to more than 20 mm. This makes automatic detection difficult. In such cases where a large aneurysm with a size of more than 15mm is present, an automatic approach which finds the position of the aneurysm and calculates its size has been integrated. By doing so two image processing methods are combined : a simple thresholding and the morphologic erosion <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b3">4]</ref>.</p><p>Most of the CT data sets contain bones whose intensity values are found in the highest intensity regions. In order to allow the erosion to remove the bone, a simple thresholding is used with the threshold chosen from a predefined region of high values. The advantage of this thresholding is that, after removing the bone, we can assume that the aneurysm is one of the largest objects in the volume data set. However, it is required that the intensity values of the data set are transformed by the generated transfer function.</p><p>In order to reduce the complete volume data set down to the aneurysm a 3D erosion operation is used. A 3D filter manipulates the data by testing if all elements inside the filter fulfill a defined criterion. Thereby all intensity values of the image, which are covered by the filter mask, will be added to the respective filter value. The intensity values, which are covered by the center of the mask, are set to the minimum of all these values. The result is that irregular or small structures are removed by the filter. If we apply the filter several times, the largest and homogenous objects, with regard to the structure, are preserved. To speed up the filtering process we integrate the hardware based approach by Hopf <ref type="bibr" target="#b6">[7]</ref>, where the morphological operations are performed in the frame buffer of the graphics hardware. We use a diamond shaped filter which can be split into 3 one-dimensional filters.</p><p>Assuming that just a small number of objects are retained in the data set after the filtering, the object with the largest extent has to be searched. For this purpose we have to look for objects whose intensity values are above a specified threshold. All these points represent a seed point for the following volume growing method on the eroded data set.</p><p>Finally, if the largest object and its position has been found we assume that this is the aneurysm. For further processing we additionally compute the bounding box of this object. To obtain the original diameter of the object it is necessary to consider the structure of the filter and the number of filtering iterations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Standardized Camera Path</head><p>To generate a video documentation automatically, it is necessary to use a standardized camera path to observe the aneurysm. The experience of physicians is necessary to define an appropriate camera path. Usually, clinicians examine individual patient data in a similar way. At first, an overview of the complete data set is used for the purpose of orientation and in order to search for pathological regions. The camera follows several predefined circular paths around the complete volume. It starts with a posterior overview of the aneurysm followed by a lateral overview. <ref type="figure">Figure 7</ref> shows this idea.</p><p>To get a more detailed view it is necessary to take an overview from a closer distance. To find an optimal viewing distance to the aneurysm it is necessary to get as close as possible to the aneurysm. At this point bounding box as computed before is used. The distance from the camera to the aneurysm is limited by the edges of the bounding box which is somewhat larger than the aneurysm itself. We span a circular path around the small bounding box from which we obtain an optimized view of the aneurysm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Hardware supported rendering</head><p>Hardware supported rendering is one of the most prominent variants for interactive direct volume rendering. Using 3D texture mapping allows interactive manipulation due to the high frame rates which can be achieved by using this technique, even if the limited size of the texture memory might require bricking of the data set.</p><p>In the presented application 3D texture mapping is used for the rendering process as well as for the segmentation by using morphological operators. 3D graphics, however, is mainly used in interactive screen based applications. In order to obtain hardware accelerated off-screen rendering for our web service approach we employ a special OpenGL/GLX extension: The pbuffer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Architecture</head><p>This section describes the architecture of the complete process which covers the data transfer, the segmentation and rendering and the video generation. All these processes are embedded into a web service for physicians.</p><p>First of all the user enters several data parameters into a webfrontend, which is built from dynamically generated HTML-pages. For this purpose JavaServer Pages (JSP) are used, which offer easy handling and platform independence and are used very frequently. Additionally, JSP engines are available for virtually any platform. The flexibility of web servers and JSP engines is important because we do not want to run the web server on the SGI render server thus avoiding unnecessary web traffic on the graphics machine. In our application a Linux machine serves as a web server.</p><p>Using two different machines requires communication between these two machines. Data is sent via HTTPS from the users local machine to the web server. The data is then forwarded to the render server. In order to communicate between these two machines Java RMI (Remote Method Invocation), a convenient way to support communication between several processes, is used. Integrated into the JSPs, the RMI starts the visualization process from the Linux web server on the SGI machine. <ref type="figure" target="#fig_3">Figure 3</ref> shows the communication process. The automatic video generation starts with the segmentation, next the camera path has to be adapted to the volume data set according to the local bounding box of the aneurysm. The following rendering process is controlled by a special node of the scene graph library OpenInventor, on which the existing rendering tool is based. The engine class allows to animate parts of the scene in a convenient way. In the presented application a camera engine which animates the described camera path is used. Inside the engine class the single positions of the camera, depending on the elapsed time, are calculated. Additionally there is a special node in the scene graph which generates single images and combines them to a video stream. After converting the single images to a digital video the user will be informed by email from where the video can be downloaded.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Results</head><p>This section presents comparisons with respect to the quality and the time requirements of the presented application and describes the evaluation in a clinical context. The achievable quality depends on the generated transfer function and how good the position of the aneurysm could be detected. The time requirement depends mainly on the size of the volume data set. <ref type="figure" target="#fig_4">Figure 4</ref> shows a 512 512 121 volume data set which contains an aneurysm with a diameter around 16 mm close to the base of the skull. The first image (A) of the series shows the original data set, (B) shows it after applying the generated transfer function. The reduction of noise and unimportant information is clearly visible. This forms the starting point which will be used for rendering later. (C) and (D) show the data set after using simple thresholding and after the filtering process.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Quality</head><p>For the erosion several filter kernel sizes have been tested and a filter of size of 9 with filter values -164 0 0 0 0 0 0 0 -164 was used to remove the small blood vessels and the rest of the bone structure. The figures 5 and 6 show results in the volume rending tool during the various segmentation steps.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Time requirements</head><p>The segmentation and rendering process was performed using an SGI Octane with an EMXI graphics board and 4MB texture memory.</p><p>The following table shows the elapsed time of the different sub tasks for producing a digital video of 600 frames from a volume of 256 256 64 voxels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Sub task</head><p>Computational time Generation of Transfer functions 30 sec Segmentation of aneurysma 30 sec Rendering time incl. saving 330 sec Rendering time without saving 50 sec Video conversion 280 sec <ref type="table">Table 1</ref>: Elapsed time of the different sub tasks of the automatic video generation process.</p><p>Above all, the total time of the procedure is within an acceptable range and suggests the practical use of this web service. The time for the individual sub tasks is also of interest and provides information for potential improvement of the algorithms.</p><p>To generate and segment the data set only 60 seconds are needed. This compares well to the manual adjustment of transfer functions which usually needs significantly more time than our automatic approach.</p><p>The actual rendering time itself is relatively short which indicates a high rendering performance. This has been achieved by using hardware supported techniques not only for the volume rendering but also partly for the segmentation. Obviously the overall processing time is dominated by writing and reading data to and from the disk. We will try to reduce this in the future by converting the images directly from the memory.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Evaluation</head><p>Our clinical cooperation partner at the University of Erlangen compared their existing interactive visualization tool to our web service for several patient data sets. The most important feature for them was the reproducibility of the diagnosistic evaluation of the radiological structures. Until now the comparison of diagnosis in clinical studies is difficult due to the different procedures. Using the automated approach the results are comparable between different users. The approach represents an extremely time and cost saving process which supports the physicians in various ways. The produced video sequences are also easily integrable into the existing environment. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusions and Future Work</head><p>The presented approach is a first step towards the standardized and reproducible 3D visualization of medical volumentric data. The approach is integrated into a web service to avoid the need of expensive graphics hardware. The fully automated approach, including segmentation, rendering and video generation, offers a convenient and fast way to produce video sequences of large volume data sets with high quality and good response times for the physicians. Due to the time required and the difficulty of manual adjustment of transfer functions the automatic generation of this implicit segmentation is a great advantage for the physicians. The automatic detection of a certain class of aneurysms notably improves the overall procedure. Therefore inaccurancy of the automatic segmentation process can be tolerated. Further tests show that a minimum size of the aneurysm is required for our approach. Small aneurysms (around 7 mm) are removed by the erosion filtering. In some cases the aneurysm resides close to the skull base and cannot be visualized clearly and segmented by transfer functions. We will try to solve this problem by using a volume growing method or a watershed transformation.</p><p>Compared to interactive visualization tools many parameters are fixed by our approach and cannot be changed by the user. The main advantage of the standardization is a consistent presentation which can be exchanged between several physicians. Therefore all parameters like the camera path which can affect the quality of the videos or which could occlude the view of the aneurysm or other interesting regions have to be fixed. However the representation of the blood vessels (transparent or opaque) can be selected by the user, because this parameter is not error-prone.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 :</head><label>1</label><figDesc>Process flow of the complete web service. The task of the user is reduced to providing the volume data together with different parameters, like video format and length of the video. The web service is responsible for segmentation, rendering and video generation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Automatic generation of transfer functions. The visible results depend on the different parameters for the transformation. Using the transfer function without adaptation (A), with histogram adaption (B) and with adaption based on gradient derivation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 :</head><label>3</label><figDesc>Architecture of web service</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 :</head><label>4</label><figDesc>(A)  shows the original data set, (B) after applying the generated transfer function, (C) after thresholding and (D) after erosion</figDesc></figure>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0" />			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Texture-based Volume Visualization for Multiple Users on the World Wide Web</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Engel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Ertl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">5th Eurographics Workshop on Virtual Environments</title>
		<imprint>
			<date type="published" when="1999" />
			<biblScope unit="page" from="115" to="124" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Combining Local and Remote Visualization Techniques for Interactive Volume Rendering in Medical Applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Engel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Hastreiter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Tomandl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Eberhardt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Ertl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Visualization</title>
		<meeting>Visualization</meeting>
		<imprint>
			<publisher>IEEE Comp. Soc. Press</publisher>
			<date type="published" when="2000" />
			<biblScope unit="page" from="449" to="452" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Mathematical Morphology</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">M</forename><surname>Haralick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Tutorial 2, IEEE International Conference on Image Processing</title>
		<meeting><address><addrLine>Austin, TX</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1994" />
			<biblScope unit="page" from="532" to="550" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Image Analysis Using Mathematical Morphology</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">M</forename><surname>Haralick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">G</forename><surname>Shapiro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhuang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE (PAMI)</title>
		<imprint>
			<date type="published" when="1987" />
			<biblScope unit="page" from="532" to="550" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Fast Analysis of Intracranial Aneurysms based on Interactive Direct Volume Rendering and CT-Angiography</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Hastreiter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Rezk-Salama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Tomandl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Eberhardt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Ertl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. MICCAI, Lect. Notes in Comp. Sc</title>
		<meeting>MICCAI, Lect. Notes in Comp. Sc</meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1998" />
			<biblScope unit="page" from="660" to="669" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Medical volume rendering over the WWW using VRML and JAVA</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Hendin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">W</forename><surname>John</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Shochet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Medicine Meets Virtual Reality:6 IOS Press and Ohmsha</title>
		<meeting><address><addrLine>Amsterdam</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Accelerating Morphological Analysis with Graphics Hardware</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hopf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Ertl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Workshop Vision, Modeling, and Visualization (VMV)</title>
		<meeting>Workshop Vision, Modeling, and Visualization (VMV)</meeting>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="page" from="337" to="345" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Automated 3D Video Documentation for the Analysis of Medical Data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Iserhardt-Bauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Rezk-Salama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Ertl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Hastreiter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Tomandl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Eberhardt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. BVM (Bildver. f. d. Med.), GI, Informatik aktuell</title>
		<meeting>BVM (Bildver. f. d. Med.), GI, Informatik aktuell</meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2001" />
			<biblScope unit="page" from="409" to="413" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Web based 3-D medical image visualization on the PC</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">H</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">J</forename><surname>Cho</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Medinfo: Proceedings of the Ninth World Congress on Medical Informatics</title>
		<editor>B. Cesnik, A.T. McCray, and J.R. Scherrer</editor>
		<meeting><address><addrLine>Amsterdam</addrLine></address></meeting>
		<imprint>
			<publisher>IOS Press</publisher>
			<date type="published" when="1998" />
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="1105" to="1110" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Semi-Automatic Generation of Transfer Functions for Direct Volume Rendering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Kindlmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Durlin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ACM Symp. on</title>
		<meeting>ACM Symp. on<address><addrLine>Vis</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1998" />
			<biblScope unit="page" from="79" to="86" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Automatic Adjustment of Transfer Functions for 3D Volume Visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Rezk-Salama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Hastreiter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Scherer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Greiner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">cooperation with IEEE Sig. Proc. Soc. and Gesell. f. Informatik (GI)</title>
		<meeting><address><addrLine>Augustin</addrLine></address></meeting>
		<imprint>
			<publisher>Infix Verlag St</publisher>
			<date type="published" when="2000" />
			<biblScope unit="page" from="357" to="364" />
		</imprint>
	</monogr>
	<note>Proc. Workshop Vision, Modeling, and Visualization (VMV)</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
