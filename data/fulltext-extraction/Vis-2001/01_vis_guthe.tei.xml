<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/pisenberg/grobid/grobid-0.6.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Real-time Decompression And Visualization Of Animated Volume Data</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Guthe</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wolfgang</forename><surname>Straßer</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">WSI/GRIS University of Tübingen</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<address>
									<settlement>San Diego</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Real-time Decompression And Visualization Of Animated Volume Data</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2021-02-19T20:45+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Time critical Visualization, Compression for Visualization, Volume Rendering CR Categories: E.4 [Coding and Information Theory]: Data compaction and compression</term>
					<term>I.0.3 [Computer Graphics]: General</term>
					<term>I.3.3 [Computer Graphics]: Picture and Image Generation-Viewing algorithms</term>
				</keywords>
			</textClass>
			<abstract>
				<p>Interactive exploration of animated volume data is required by many application, but the huge amount of computational time and storage space needed for rendering does not allow the visualization of animated volumes by now. In this paper we introduce an algorithm running at interactive frame rates using 3d wavelet transforms that allows for any wavelet, motion compensation techniques and various encoding schemes of the resulting wavelet coefficients to be used. We analyze different families and orders of wavelets for compression ratio and the introduced error. We use a quantization that has been optimized for the visual impression of the reconstructed volume independent of the viewing. This enables us to achieve very high compression ratios while still being able to reconstruct the volume with as few visual artifacts as possible. A further improvement of the compression ratio has been achieved by applying a motion compensation scheme to exploit temporal coherency. Using these scheme we are capable of decompressing each volume of our animation at interactive frame rates, while visualizing these decompressed volumes on a single PC. We also present a number of improved visualization algorithms for high quality display using OpenGL hardware running at interactive frame rates on a standard PC.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The large datasets generated by today's applications need to be compressed. This is especially the case if the dataset changes over time. The visualization of animated volume data is very interesting for applications like geologic simulations, or captured medical volume data that change over time.</p><p>To compress these datasets as high as possible, we chose a lossy compression scheme. This scheme is split into several steps: the coding of an individual volume dataset using wavelet transforms, the quantization and compression of the resulting wavelet coefficients and finally the coding of a whole sequence of volume datasets. To maximize the compression ratio while minimizing the £ Email:{sguthe/strasser}@gris.uni-tuebingen.de reconstruction error and the decompression time, we investigated a couple of different approaches for each of these steps.</p><p>Our algorithm is the first one capable of decompressing and visualizing animated volume data at interactive frame rates, utilizing state-of-the-art video compression algorithms such as wavelet transforms and motion compensation that have been adapted to 3d volume data. We also implemented two high quality visualization algorithms. The first algorithm is based on a shear-warp factorization using OpenGL hardware. It has been modified using register combiners <ref type="bibr" target="#b23">[24]</ref> to fix some serious drawbacks of previous approaches with texture hardware. The second algorithm uses 3d textures or register combiners to simulate them.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1">Related Work</head><p>Wavelet based image compression: A wavelet based image compression has first been proposed and investigated by DeVore et. al. <ref type="bibr" target="#b10">[11]</ref> and by Antonini et. al. <ref type="bibr" target="#b1">[3]</ref> by simply extending the one dimensional wavelet transforms for higher dimensions using tensor product wavelet transforms. An overview of the field of wavelet based image compression can be found in Vetterli et. al. <ref type="bibr" target="#b25">[26]</ref> or in Villasenor et. al. <ref type="bibr" target="#b26">[27]</ref>, while a more general overview is given by Stollnitz et. al. <ref type="bibr" target="#b24">[25]</ref>.</p><p>Wavelet based volume compression: The wavelet transformation and compression of non-animated volume datasets has been thoroughly discussed during the last few years, resulting in on the fly decompression using the Haar wavelet and a single 3d wavelet transform <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b15">16]</ref> or multiple 2d wavelet transforms <ref type="bibr" target="#b21">[22]</ref>. Although these compressions allow for fast reconstruction of any single sample point and therefore random access within the dataset, they yield fairly good compression ratios but tend to produce blocky images at compression ratios close to or beyond 100:1. In contrast our approach can do compression ratios of up to 200:1. Wavelet coefficient encoding: Recently developed volume compression algorithms use run-length encoding, zerotrees introduced by Shapiro <ref type="bibr" target="#b22">[23]</ref> or schemes similar to zerotrees that use significance maps to encode wavelet coefficients. Since we do not need to access each single sample point, but rather the whole volume dataset at once, we are not constrained to pure zerotrees, but also some combinations using run-length encoding and other, more general, encoders. For comparison between different encoders, we combined the zerotrees with a final step of arithmetic encoding <ref type="bibr" target="#b18">[19]</ref>, run-length encoding with arithmetic coding and run-length encoding with LZH compression <ref type="bibr" target="#b28">[29]</ref>.</p><p>Compression of animated data: For compressing animated volume datasets we can apply some kind of motion prediction and compensation similar to MPEG <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b14">15]</ref>. Although the MPEG motion compensation works very well if applied to the blocks used for the discrete cosine transformation it leads to some severe problems if applied unmodified to wavelet transformed images as discussed by Watanabe and Singhal <ref type="bibr" target="#b27">[28]</ref>. Their modified motion compensation, the windowed motion compensation, will be used because of its significant lower reconstruction error the resulting compression ratio and its small overhead. These previous 2d algorithms were adapted for the 3d case for this paper.</p><p>Volume visualization: There have also been various approaches to the visualization of volume datasets needed in the final step of our algorithm. The visualization using a shear-warp factorization by Lacroute and Levoy <ref type="bibr" target="#b16">[17]</ref> has been adapted to modern graphics hardware using 2d textures by Brady et. al. <ref type="bibr" target="#b3">[4]</ref> to achieve interactive frame rates. A different approach using 3d textures by Akley <ref type="bibr" target="#b0">[2]</ref> has until recently only been available on graphics workstations, but is starting to show up on standard PC graphics hardware, e.g. the ATI Radeon graphics adapter. Rezk-Salama et. al. <ref type="bibr" target="#b20">[21]</ref> used standard PC graphics hardware. In this case the NVidia GeForce graphics adapter is used to implement the tri-linear interpolation that is needed to simulate 3d textures. We will later use this trilinear interpolation to implement the shell rendering proposed for the ATI Radeon [1] on a GeForce graphics adapter using its register combiners <ref type="bibr" target="#b23">[24]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.2">Paper Overview</head><p>The algorithm is split into three steps to encode or decode a sequence of volumes and an additional step for visualizing each decoded volume. In section 2.1 we take a closer look at the wavelet transforms used, the computational time and the reconstruction error after applying some quantization to the wavelet coefficients that will be discussed in section 2.2. Afterwards we will investigate some compression schemes for these quantized wavelet coefficients in section 2.3. Section 3 will be discussing several ways to encode a sequence of volumes and compare their compression ratio, decompression time and reconstruction error. In section 4 we will discuss improved visualization methods using standard PC hardware.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Single Volumes</head><p>The compression of single volumes consists of three steps: the wavelet transform, the quantization of the wavelet coefficients and their compressed encoding. A three dimensional wavelet transform of the whole volume at once, instead of a block-wise wavelet transform <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b12">13]</ref>, was chosen to maximize the compression ratio for any given quality and avoid blocking artifacts for higher order wavelets. The quantization uses different accuracies for each kind of wavelet coefficients to minimize the information to be compressed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Wavelets</head><p>The wavelet transform of a 1d signal can be regarded as the filtering of this signal with both the wavelet © and the scaling functionä nd the downsampling of the resulting signals by a factor of 2 (see <ref type="figure" target="#fig_0">figure 1)</ref>. The wavelet is a high pass filter and the scaling function a low pass filter. Note that the total amount of information is not modified. It is just a change of the basis of the function space. The part of the wavelet transform up to now is called analysis of the signal, while the following part is called synthesis. The values of H and L are called wavelet coefficients in the discrete case. The reconstruction upsamples the transformed signals again, filters them using © ¼ for the high sub band, the wavelet coefficients representing high frequencies and¨¼ for the low sub band, the wavelet coefficients representing low frequencies. The two resulting signals are added together and reproduce the original signal without any loss. To transform signals of higher dimension, we apply the 1d wavelet transform in all three dimensions separately, resulting in a 3d tensor product wavelet transform <ref type="bibr" target="#b24">[25]</ref> as seen in the left part of figure 2. After the first wavelet transform of the whole volume, we apply the 3d wavelet transform to the low sub band recursively. We repeat this step four times to get the sub bands seen in the right part of figure 2. Any further wavelet transforms does usually not reduce the size of the compressed volume, but rather introduce more visual artifacts.</p><p>Previous approaches of volume compression used the simple Haar wavelets. Higher order wavelets on the other hand have some properties that make them very suitable for implementation of a compression algorithm, such as more than one vanishing moment, i.e. polynomials that map to a single wavelet coefficient only. The Daubechies wavelets <ref type="bibr" target="#b6">[7]</ref> are the wavelets with maximum vanishing moments at a given support. But there is also a major drawback when using higher order wavelets due to their longer support. If we want to reconstruct a signal using a wavelet of support greater than 2, we need a periodic extension of the original signal and therefore for each of the sub bands as this is the only way to maintain the same number of wavelet coefficients for any family of wavelets regardless of their support. Although this might seem to solve all our problems with higher order wavelets, we have to keep in mind that our volume is not of periodic nature and may therefore have very high contrast between its opposite surfaces.</p><p>A better way of extending our signal for higher order wavelets would be a symmetric extension, i.e. the signal is mirrored at it's borders. Although this removes our border problem, we now need symmetric wavelets <ref type="bibr" target="#b8">[9]</ref>. Yet constructing a symmetric wavelet is not possible, as we require the wavelet to be orthonormal to guarantee a change of the basis of the functional space. Although it is possible to construct wavelets that are as symmetric as possible, i.e. the Coiflets proposed by Coifman and later constructed by Daubechies <ref type="bibr" target="#b9">[10]</ref>, they can still not be used with symmetric extension. However, if we use a different filter for reconstruction, we can construct symmetric, so called bi-orthogonal wavelets. The CDF wavelets introduced by Cohen, Daubechies and Feauveau <ref type="bibr" target="#b5">[6]</ref> are the most widespread bi-orthonormal wavelets used for image encoding and will also be used in addition to Haar wavelets, Daubechies Wavelets and Coiflets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Quantization</head><p>After the wavelet transform, the complete volume is represented by wavelet coefficients in floating point values, enabling us to reconstruct the original volume correctly. To reduce the data to be stored while maintaining a minimum error in Ä ¾ norm, we first have to choose the dead zone <ref type="bibr" target="#b25">[26]</ref>, i.e. the range that will be mapped to zero, for each different region of wavelet coefficients seen in figure 2 to cut down the number of non-zero wavelet coefficients. The remaining coefficients then have to be scaled and quantized appropriately for the further compression. To take the sensitivity of the human visual system for different frequencies into account, we use level LLH LHH HHH dead zone as large as the difference between two quantized values. The maximum number of coefficients and the relative size of the dead zone for the remaining regions of wavelet coefficients within the range of ½ ½ can be seen in table 1. The dead zone and the quantization steps have been adapted to represent similar amounts of visual contrast depending on the underlying frequency, according to the threshold contrast sensitivity function <ref type="bibr" target="#b11">[12]</ref> that represents the sensitivity of the human visual system for contrast at different frequencies. </p><formula xml:id="formula_0">0 ¼ ¼ ¼ ¼ ¼ ¼ ¼ ¿¿ 1 ¼ ¼ ¼ ¼ ¼ ¼ ¼ ¼ 2 ¼ ¼ ¼ ¼ ¼ ¿¼ ¼ ¼ 3 ¼ ¿¼ ¼ ¾¼ ¼ ½ ¼ ¼ 4 ¼ ½¿ ¼ ¼ ¼ ¼ ½ ¼¼</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Encoding</head><p>After the quantization step we have to encode the wavelet coefficients to store them using as few memory and decompression time as possible. To choose the right type of compression, we first have to take a close look at the data to be compressed. The goal of the quantization was to cut as many coefficients as possible down to zero, so the most simple and fastest compression can be achieved by run-length encoding all zeros. To produce as few overhead as possible, we just compress a run of Ò zeros by storing ¼ followed by Ò ½. Therefore a single ¼ becomes a sequence of ¼ ¼ and is therefore the only way that the compressed data will expand.</p><p>If Ò exceeds the number of possible quantization steps, the run is split into several compressed sequences. We also have to specify a traversal order through the regions of the wavelet coefficients. The fastest way to encode and decode the wavelet coefficients is to store each line within a region of wavelet coefficients individually (see figure 3a). While this already produces long runs of zeros, there is a more sophisticated methods for achieving even longer runs. Similar to the zero trees <ref type="bibr" target="#b22">[23]</ref>, we use a depth first traversal through an octree that holds all our wavelet coefficients within each region of wavelet coefficients separately (see figure 3b). As regions of zero coefficients are more likely to be stored in a single run, this delivers even longer runs of zeros. However the non-linear memory access results in a severe loss of decoding speed. This already results in fairly good compression ratios while needing very little time for decompression, but there is still a very simple and effective way to further improve the compression. The LZH algorithm <ref type="bibr" target="#b28">[29]</ref> compresses a repeating sequence of different values by storing the reference to the last appearance of the same sub string. While the compression, due to the searching for matching strings within a given range of previously compressed coefficients, takes quite long, the additional time needed for decompression is nearly not noticeable. Reading the compressed data may even be slightly faster than reading uncompressed data due to the reduced amount of disc access.</p><p>The compression ratios up to now are quite good, but for storing an animated volume dataset, we have to achieve compression ratios beyond 100:1 for single volumes. The aim of arithmetic coding is basically to store a sequence of intervals using as few bits as possible by storing the shortest bit string within this interval. The main part of every compression using arithmetic coding is the model that translates the incoming symbols into intervals and vice versa. As these models can be very powerful, they can be used to implement any compression algorithm.</p><p>The most simple model presented by Moffat, Neal and Witten <ref type="bibr" target="#b18">[19]</ref> that can be applied for encoding our wavelet coefficients is the adaptive model. At the beginning of each region of wavelet coefficients, the intervals of each quantized coefficient are of equal size and the counter of their references is set to one. After encoding a coefficient, the corresponding counter is increased by one and all intervals are resized accordingly. As the counters are organized in a binary tree, the intervals are only to be computed if the corresponding coefficient is encoded. The time needed for the computation of these intervals and therefore the compression or decompression time needed for a single coefficient is Ç´ÐÓ ´Òµµ with Ò being the number of possible coefficients. Therefore the decompression gets faster as the number of possible wavelet coefficients decreases.</p><p>There is also a way to implement an optimized kind of runlength encoding into the model. After a zero is encoded, the model switches to zero mode. While in zero mode, the arithmetic coder always receives the interval between 0 and 1, i.e. it does not encode anything, as long as the coefficients that are to be compressed remain zero. After receiving a non-zero coefficient, the arithmetic coder receives a combined interval representing the number of zeros received and the new wavelet coefficient. The number of zeros is stored similar to the run-length encoding. Up to Ò zeros are stored using only a single interval, while values beyond Ò are stored by an interval that notifies Ò• zeros. Using a value of 127 for Ò showed up to be very good for nearly all datasets and quantizations, resulting in 128 intervals for run-length encoding that are updated using the same adaptive scheme as used for the wavelet coefficients. Therefore the length of each run is compressed in a more optimal way than by a run-length encoding prior to the arithmetic coding. An additional optimization is to store a bit-pattern, that is also encoded arithmetically using only two symbols, to mark unused wavelet coefficients. This results in the compression of a region consisting of zeros to this previously stored bit-pattern only.</p><p>The last method of compressing the wavelet coefficients is the zerotree coding of Shapiro <ref type="bibr" target="#b22">[23]</ref> combined with an arithmetic en- coder using an adaptive model. Although this might seem the most natural way to exploit the huge amount of zeros and the hierarchical nature of the wavelet coefficients, this turns out not to be the best encoder most of the time and also by far the slowest one.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Volumetric Animation</head><p>To store animated volumes rather than single volumes effectively requires to exploit the temporal coherency between consecutive volumes. The most simple way to exploit the temporal coherency is storing the difference between the current and the previous volume rather than the current volume. Although this already reduces the compressed data significantly, it is not sufficient for storing large volumetric animations, therefore we have adapted the motion compensation used for video encoding.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Motion Compensation</head><p>The easiest way is to store differential volumes only, as seen in figure 4 (shown for 2d images for clarification). As this is not very effective for our wavelet compression scheme, we implemented a simple motion prediction and compensation. The motion prediction is done by simple block matching of ¿ blocks between the two volumes. The motion compensation is done before the differential encoding to reduce the differential content. A block of high similarity, i.e. minimum mean square error, in the previous image is computed by searching this minimum starting from a motion vector of length ¼ using ½ steps in all three directions. This is similar to finding the correct motion vector using optical flow methods. This results in ¿½ ¿ possible motion vectors that have to be stored using some kind of encoding. The search for the local minimum meansquare error guarantees that most of the resulting motion vectors will be of zero length or at least close to zero length making an arithmetic encoding with a simple adaptive model the best choice as encoder.</p><p>The usual, i.e. MPEG, method for computing a motion compensated image is to map each block of the to be constructed volume onto a block of the previous volume as seen in figure 4 for two dimensional images. However in combination with wavelet transformation, this results in severe problems if the motion vectors of two neighboring blocks are different, i.e. regions of high contrast are present. Using wavelet transformation, these high contrasts result in large wavelet coefficients in regions that correspond to high frequencies and therefore low compression ratios. There is another drawback using this simple approach. Due to the nature of the quantization scheme applied to the differential images these wavelet coefficients will be quantized very strong and therefore result in a large error.</p><p>The solution to this problem is the windowed motion compensation introduced by Watanabe and Singhal <ref type="bibr" target="#b27">[28]</ref>. The blocks are extended to ½¾ ¿ overlapping blocks and filtered by a function with a cosine falloff at both ends (see <ref type="figure">figure 5</ref>) in all three directions as the sum of all neighboring window scaling functions and therefore the sum of all voxel weights with the window is already one. Although the computational overhead introduced by these overlapping blocks is with a theoretical value of ¾ ¿ very high, it shows up that this has no severe impact on the performance in practice, due to the higher number of cache hits if the volume is reconstructed voxel by voxel, rather than block by block. The volume that has to be encoded using wavelet transforms does no longer have regions of high contrast, as seen in figure 4 and therefore less wavelet coefficients differ from zero.</p><p>Similar to the naming conventions of the MPEG compression <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b14">15]</ref>, a wavelet compressed volume is called I-volume (see figure 6). We use two different ways to reconstruct an individual volume using motion compensation. The P-volume is reconstructed by using a motion compensated version of the previous I-or P-volume and wavelet compression of the difference between this predicted and the actual volume. The B-volume is reconstructed by using a weighted average between a motion compensated version of the last and the next I-or P-volume similar to the compression scheme used in MPEG compression as seen in <ref type="figure">figure 6</ref>. There is no fixed sequence of I-, P-and B-volumes but any sequence of P-or Bvolumes between two I-volumes can be defined. Note that the volumes are not stored in their original order, but in the order of their first usage, i.e. the B-volumes are stored after the next P-or Ivolume. In our experiments, we analyzed various sequences for compression ratio and visual impression. It turned out that using the popular MPEG sequence (figure 6c) delivers the best results. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Playback</head><p>The single volumes of the animation are decompressed in their storage order rather than in the order of playback. To compensate the different times needed for the decompression of an individual volume, we have to take a closer look at the decompressed volumes for each new time step. For this we choose the third sequence in <ref type="figure">figure 6</ref>. In a setup step, the first I-volume and the first P-volume are decoded to make sure that all the volumes for interpolation of the next volume (a B-volume) are present. The second and the third volume are decoded without any special treatment. Reaching the fourth volume, the already decoded P-volume, we decode the next P-volume as this one is needed for the next B-volume. After decoding the next two B-volumes, we start decoding the next sequence, starting with it's I-volume. Before displaying the first volume of this new sequence, we decode the next P-volume and reach the same state as at the beginning of our decoding. Thus we only have to decode one volume at a time, resulting in smoother playback of our volumetric animation. To achieve an on the fly decompression in real time, we have to further optimize the decompression. Using LZH coding the bottleneck of the algorithm is writing the decoded wavelet coefficients into their correct position, therefore we restrict our self to storing them line by line rather than in the octree depth first order. Most of the time this reduced the compression ratio slightly but makes better usage of the write cache and thus speeds up the decompression significantly. Using the arithmetic coding, we have an integer multiplication and an integer division as part of the main interval coder and therefore no need to optimize the writing of the wavelet coefficients in terms of cache hits, as this does not result in any noticeable speedup.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Visualization</head><p>We still need a high quality visualization in real-time to display our decoded volume data. The fastest way of visualizing a volume using standard pc hardware is the usage of a texture stack along the main viewing direction as proposed by Brady et. al. <ref type="bibr" target="#b3">[4]</ref>. This stack of textures is combined using planes along each texture and alpha blending hardware. As we need a stack of textures for each of the main viewing directions, this results in storing the volume three times in texture memory. However, during playback of a volumetric animation, the viewing direction only changes between different volumes and therefore a single stack of textures is sufficient. The usage of textures also enables us to easily define a transfer function between the values stored in the volume and the ones stored in the texture stack. Although this gives a good first impression of the dataset (see <ref type="figure" target="#fig_5">figure 7a)</ref>, modern pc hardware allows for more sophisticated algorithms, that do not produce as many artifacts as this approach.</p><p>Up to now we ignored the effects seen in figure 8 that lead to some severe problems if we change from one texture stack to another, or if we rotate a dataset, as the opacity of the volume seams to change. The register combiner of the GeForce GPU from NVidia allows us to modify the opacity of the volume data depending on the angle between the surface normal and the vector pointing from the viewing location to a point on the surface and therefore allows for better visualization algorithms. Due to the exponential behavior of the opacity and the lack of this kind of operation within the combiner, we have to simulate this exponential falloff. The main idea for the approximation is to interpolate between the opacity and the squared opacity at each pixel of the display. In order to do so, we build a texture to look up suitable weights for the linear and squared « values using the angle between the viewer and the surface normal. A first approach for generating this lookup texture is to store the distance minus one ½ between two slices as weight for the squared opacity. Although this roughly represents the correct alpha values, there is still a large error for small values, i.e. very transparent regions, as seen in figure 9. Since a large error in a very transparent region produces much more visual artifacts than a large error in a very opaque region as the error is accumulated in regions of high transparency, we optimize the lookup texture to minimize the relative mean square error (´ ÖÖÓÖ ÓÖ ÐÔ µ ¾ ), by storing Ø´ µ instead of ½. The relative mean square error is given by</p><formula xml:id="formula_1">¾ ½ ½ « ¼´½ Ø´ µµ« • Ø´ µ« ¾ « « « or (1) ½ « ¼´½ Ø´ µµ« • Ø´ µ« ¾ « « «<label>(2)</label></formula><p>for a specific value of . Since we don't have to specify Ø´ µ but only need its values for a limited number of distances and with a limited accuracy we can minimize the previous equation numerically by trying all 256 possible values for Ø´ µ. As already mentioned this reduces the error for all but the very opaque regions. The approximation of the exponential falloff now only produces the error seen in <ref type="figure" target="#fig_0">figure 10</ref>. The resulting visualization can be seen in figure 7b. Although this approach removes most of the problems mentioned above, there are still some small visual artifacts if we move from one texture stack to another. The easiest way to remove this effect is to render the volume from all three directions and combine the resulting images using a weighted average. This can also be done very effectively using texture hardware. The major drawback of this approach is that we have to transfer all three texture stacks to the graphics adapter, resulting in a severe loss of speed.</p><p>Another way to render the dataset with correct transparencies is to utilize 3d textures and shells (small subsections of a sphere) which completely avoids the switching of texture stacks and perspective distortion. Unfortunately among the consumer hardware only the ATI Radeon, that has also been used for testing purposes, is able to handle 3d textures in hardware. On the other hand, the GeForce is able to do tri-linear interpolation between any two slices of our dataset, as shown by Rezk-Salama et al. <ref type="bibr" target="#b20">[21]</ref>, so all we have to do is make sure that no polygon needs any interpolation between three or more slices during their construction as seen in figure 8. Using this simple but very effective trick, we are able to simulate 3d textures on a GeForce graphics adapter.</p><p>There is still one problem left, the undersampling along the viewing axis. We only sample at the resolution equal to the distance between two slices, as seen in figure 7c. The undersampling can only be removed by using more shells which is not very effective due to the limited precision of the frame buffer or by using raycasting. Although raycasting produces the best results (as seen in <ref type="figure" target="#fig_5">figure 7d</ref>), it can not be used for interactive visualization of our animated datasets using standard PC hardware due to the time consuming calculations that have to be carried out. Another option is to use a special purpose hardware within a standard PC such as the Vizard II <ref type="bibr" target="#b17">[18]</ref> or the VolumePro <ref type="bibr" target="#b19">[20]</ref>. However special purpose hardware is not as widely spread as the need for volume visualization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Results</head><p>All tests have been carried out on an AMD K7 running at 800 MHz using a GeForce 2 graphics adapter (first configuration) or on an AMD K7 running at 1000 MHz using a Radeon graphics adapter (second configuration).</p><p>As expected the usage of higher order wavelets does not only reduce the size of the compressed volumes while enlarging the Peak-Signal to Noise Ratio (PSNR) as seen in table 2, but does also significantly improve the visual impression as seen in <ref type="figure" target="#fig_0">figure 11</ref>    better preserves features. The original volume can be seen in the color plates. The PSNR of I-and P-volumes also depends on the compression ratio as seen in <ref type="figure" target="#fig_0">figure 12</ref>. The quality of the B-volumes on the other hand does only roughly depend on this quality setting (see <ref type="figure" target="#fig_0">figure 12</ref>), as these volumes are not reconstructed using wavelet transforms but using motion compensation only.</p><p>As already mentioned, the decompression times achieved using arithmetic encoding depend on the quantization used, as both the number of zeros increases and the depth of the tree that has to be updated dynamically decreases. Using LZH encoding, neither of these two properties does have any effect on the decompression times as seen in table 3. The LZH encoding performs a lot better than the arithmetic encoding in terms of speed (up to two times faster using high quality settings) but worse in terms of compression ratio (about 30% more compressed data at moderate to high quality). This allows for about 4 frames per second regardless of the chosen quality. Note that the speed on the second configuration is not limited by the decompression time, but rather by the memory bandwidth during the 3d wavelet transform.</p><p>As seen in figure 13 the PSNR of the B-volumes (the dotted line) is significantly lower for high quality volume animations. Removing the motion compensation at these high quality settings results in an improvement of the PSNR but also increases the size of the compressed data, as seen in table 4. At a lower quality setting, the PSNR increases if we use motion compensation again while also decreasing the size of the compressed data. Testing different qualities and sequences demonstrated that the popular MPEG sequence (the first sequence in <ref type="figure" target="#fig_3">figure 4)</ref>   <ref type="table">Table 3</ref>: Comparison regarding compression ratio and frames per second (using 2d textures on system 1 and 2) between different encoders using various qualities, the popular MPEG like sequence and the CFD wavelet with support 2/6.</p><p>exception. If we desire a nearly lossless compression of every volume, rather than every third volume, we should use only I-volumes or I-volumes and P-volumes as this will result in the highest possible PSNR. Although the 2d textures are a lot faster on both configurations than the 3d textures (see table 5), we still get interactive frame rates on both configurations that do not have a heavy impact on the playback speed of a compressed volume animation. On the other hand, the optimized 2d textures running on the GeForce2 graphics adapter do not need any additional time and sometimes even produce less visual artifacts as the 3d textures (see volume borders in <ref type="figure" target="#fig_0">figure 14</ref>).</p><p>If we wish to compress a volume animation without generating too many noticeable visual artifacts that will playback at interactive frame rates of about 4 frames per second on our testing configurations, we achieve compression ratios of about 50:1 using CDF wavelets, a quality setting of about 127, the popular MPEG sequence and LZH encoding. If we need high compression ratios rather than fast visualization, we are able to reach a ratio of about 75:1 by replacing the LZH encoding by arithmetic encoding with-    <ref type="table">Table 5</ref>: Time needed for visualization of a static volume dataset on the two different configurations (without any decompression).</p><p>out any additional loss of data. Using a transfer function of high contrast will emphasize visual artifacts. Our example animation (figure 11) has an absolute derivative of 5 in the alpha component of the transfer function. A transfer functions of lower contrast will allow for a compression ratio of 100:1 and beyond without visual artifacts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion &amp; Future Work</head><p>In this paper we have shown a very efficient approach to decompress and visualize animated volume datasets in real time on standard pc hardware. The favored compression scheme uses a quality setting of 63 and the popular MPEG sequence with either arithmetic or LZH coding. The presented algorithm does not exploit the possibility for parallelization of the wavelet transform or the motion compensation and therefore leaves a lot of room for further optimization using a single processor (3DNow or SSI instructions) and multiple processors. Although the sole visualization of each volume is quite fast, this part can also be split up into several subvolumes that are to be rendered using a cluster of standard PCs. Replacing the wavelet transform with the corresponding lifting steps according to Daubechies and Sweldens <ref type="bibr" target="#b7">[8]</ref> is a further possible optimization that also enables us to implement a lossless compression scheme using integer wavelet transforms as supposed by Calderbank <ref type="bibr" target="#b4">[5]</ref>. However lifting steps only pay off for wavelets with longer support that have not been examined in our experiments by now.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Wavelet transform of a 1d signal S.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Single step of three dimensional translation (L=low pass filtered, h=high pass filtered) and complete recursive decomposition.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Order of traversion within a region of wavelet coefficients.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Previous image and current image (upper row). Differential image, standard motion compensation and windowed motion compensation (lower row).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 :Figure 6 :</head><label>56</label><figDesc>Scaling function used for the cosine windowed motion compensation with neighboring windows. Reconstruction and storage order for different types of volumes and sequences, similar to MPEG. a) motion compensated differences b) motion compensation only, c) popular MPEG order</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 7 :</head><label>7</label><figDesc>Visualization using stack of textures with uniform transparency (a), register combiner (b), 3d texture (c) and raycasting (d).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 8 :</head><label>8</label><figDesc>Different distances between textures introduced by different viewing points and perspective distortion and correction of these differences using 3d textures.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 9 :Figure 10 :</head><label>910</label><figDesc>Resulting absolute error introduced by using a simple lookup texture. Resulting absolute error in the range of 0 to 255 introduced by using an optimized lookup texture, to produce less relative error ( ÖÖÓÖ ÓÖ ÐÔ ).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 11 :</head><label>11</label><figDesc>Static volume compressed at a ratio of about 40:1 using Haar wavelet , Daubechies wavelet (b, support 4), Coiflets (c, support 6) and CDF wavelet (d, support 2/6) wavelets.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 13 :</head><label>13</label><figDesc>PSNR of each kind of volume of the first 500 volumes of a 2000 volume animation (CDF wavelet with support 2/6, maximum quality and popular MPEG like sequence).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Factors for quantization ( £Ñ ÜÉÙ ÒØ) and dead zone (½ • £ Ñ Ü ) of different levels and regions of the wavelet coefficients, resulting in ¾ £ Ñ ÜÉÙ ÒØ • ½ possible quantized values per wavelet coefficient. individual dead zones and scaling factors with different regions of the transformed volume after all coefficients have been normalized to a range of ½ ½ .</figDesc><table /><note>There is only one region of wavelet coefficients ÄÄÄ¼ that has been transformed using the low pass filter only. At each of the five recursion levels there are three regions that have been filtered through the high pass filter once ÄÄÀ /ÄÀÄ /À Ä Ä , three re- gions that have been high pass filtered twice ÄÀÀ /À Ä À /À À Ä and only one region that has been high pass filtered three times À À À . Since we treat all three directions equally only the num- ber of high or low pass filters applied to each region are of interest. This delivers a total of 16 different regions of wavelet coefficients. With a user defined global maximum Ñ ÜÉÙ ÒØ for the num- ber of coefficients and a global maximum dead zone Ñ Üthe dead zones and quantization steps are defined as follows. For ÄÄÄ¼the interval ¼ ½ is split into Ñ ÜÉÙ ÒØ steps while the dead zone is defined as ½ • ½ Ñ Ü</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>The user defines Ñ ÜÉÙ ÒØ ½¾ • ÕÙ Ð ØÝ £ ½¾ and Ñ Ü ¾ ¼ £´¾ ÕÙ Ð ØÝµ ¾ by specifying the ÕÙ Ð ØÝ parameter in the range ¼ ¾ to easily define the compression ratio while trying to minimizing the visual loss and drop in PSNR.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 :</head><label>2</label><figDesc>PSNR comparison between different wavelets using maximum quality, the popular MPEG like sequence and arithmetic compression.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head></head><label></label><figDesc>should always be used with only one</figDesc><table><row><cell></cell><cell>55</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>50</cell><cell></cell><cell></cell><cell></cell></row><row><cell>PSNR</cell><cell>30 35 40 45</cell><cell></cell><cell></cell><cell></cell><cell>I-Volumes P-Volumes B-Volumes</cell></row><row><cell></cell><cell>25</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>20</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0.04</cell><cell>0.08</cell><cell>bpv</cell><cell>0.16</cell><cell>0.32</cell></row><row><cell cols="6">Figure 12: Average PSNR of each different kind of volume against</cell></row><row><cell cols="6">bits per voxel (CDF wavelet with support 2/6 and popular MPEG</cell></row><row><cell cols="3">like sequence).</cell><cell></cell><cell></cell></row><row><cell cols="5">quality arithmetic fps1 fps2</cell><cell>LZH</cell><cell>fps1 fps2</cell></row><row><cell cols="2">255</cell><cell>34.28:1</cell><cell cols="2">1.58 1.77</cell><cell>25.89:1</cell><cell>3.23 3.62</cell></row><row><cell cols="2">127</cell><cell>77.28:1</cell><cell cols="2">2.06 2.34</cell><cell>56.10:1</cell><cell>3.25 3.62</cell></row><row><cell>63</cell><cell></cell><cell>109.69:1</cell><cell cols="2">2.35 2.74</cell><cell>82.32:1</cell><cell>3.25 3.62</cell></row><row><cell>31</cell><cell></cell><cell>150.34:1</cell><cell cols="3">2.64 3.01 134.59:1 3.27 3.62</cell></row><row><cell>15</cell><cell></cell><cell>173.64:1</cell><cell cols="3">2.80 3.17 171.15:1 3.28 3.62</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 4 :</head><label>4</label><figDesc>Comparison between different sequences using CDF wavelet with support 2/6, arithmetic encoding and maximum (intermediate) quality.</figDesc><table><row><cell>configuration</cell><cell cols="2">2d textures 3d textures</cell></row><row><cell>GeForce2, AMD K7 800 MHz</cell><cell>78.62 fps</cell><cell>12.03 fps</cell></row><row><cell>Radeon, AMD K7 1000 MHz</cell><cell>116.26 fps</cell><cell>10.01 fps</cell></row></table><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Acknoledgemets</head><p>This work has been funded by the SFB grant 382 of the German Research Council (DFG). The bob dataset is courtesy of Dr. Jörg Schmalzl, Intitute of Geophysics, Münster University.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">RealityEngine graphics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Akeley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Annual Conference Series</title>
		<imprint>
			<biblScope unit="page" from="109" to="116" />
			<date type="published" when="1993" />
		</imprint>
	</monogr>
	<note>Computer Graphics</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Image coding using wavelet transform</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Antonini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michel</forename><surname>Barlaud</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierre</forename><surname>Mathieu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ingrid</forename><surname>Daubechies</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="205" to="220" />
			<date type="published" when="1992-04" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
	</analytic>
	<monogr>
		<title level="m">Comparison between different kinds of visualization using 2d textures (a), optimized 2d textures (b), 3d textures (c) and raycasting (d)</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Two-phase perspective ray casting for interactive volume navigation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><forename type="middle">L</forename><surname>Brady</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenneth</forename><surname>Jung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thinh</forename><surname>Ht Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Nguyen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Visualization &apos;97</title>
		<imprint>
			<date type="published" when="1997-10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Wim Sweldens, and Boon-Lock Yeo. Wavelet transforms that map integers to integers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Calderbank</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ingrid</forename><surname>Daubechies</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1996" />
		</imprint>
		<respStmt>
			<orgName>Department of Mathematics, Princeton University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Biorthogonal bases of compactly supported wavelets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Albert</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ingrid</forename><surname>Daubechies</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean-Christophe</forename><surname>Feauveau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comm. Pure Appl. Math</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="page" from="485" to="560" />
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Orthonormal bases of compactly supported wavelets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Daubechies</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comm. Pure Applied Math</title>
		<imprint>
			<biblScope unit="issue">41</biblScope>
			<biblScope unit="page" from="909" to="996" />
			<date type="published" when="1988-11" />
		</imprint>
	</monogr>
	<note>XLI</note>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Factoring wavelet transforms into lifting steps</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Daubechies</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Sweldens</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1996" />
			<publisher>Lucent Technologies</publisher>
		</imprint>
		<respStmt>
			<orgName>Bell Laboratories</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Ten Lectures on Wavelets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ingrid</forename><surname>Daubechies</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CBMS-NSF Regional Conference Series in Applied Mathematics. Society for Industrial and Applied Mathematics</title>
		<imprint>
			<biblScope unit="volume">61</biblScope>
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Orthonormal bases of compactly supported wavelets: II. variations on a theme</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ingrid</forename><surname>Daubechies</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM J. Math. Anal</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="499" to="519" />
			<date type="published" when="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Image compression through wavelet transform coding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronald</forename><forename type="middle">A</forename><surname>Devore</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Björn</forename><surname>Jawerth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bradley</forename><forename type="middle">J</forename><surname>Lucier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Information Theory</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="719" to="746" />
			<date type="published" when="1992-03" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">The threshold contrast sensitivity function in strabismic amblyopia: Evidence for a two type classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">F</forename><surname>Hess</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">R</forename><surname>Howell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Vision Research</title>
		<imprint>
			<date type="published" when="1977" />
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="1049" to="1055" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Wavelet-based 3D compression scheme for very large volume data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Insung</forename><surname>Ihm</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanghun</forename><surname>Park</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Graphics Interface</title>
		<imprint>
			<date type="published" when="1998-06" />
			<biblScope unit="page" from="107" to="116" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">MPEG-1 coding of moving pictures and associated audio for digital storage media at up to about 1,5 mbit/s. ISO/IEC 11172</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Iso/Iec</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">MPEG-2 generic coding of moving pictures and associated audio information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Iso/Iec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ISO/IEC 13818</title>
		<imprint>
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">An efficient wavelet-based compression method for volume rendering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Shin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In Proceedings Pacific Graphics</title>
		<imprint>
			<biblScope unit="page" from="147" to="157" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Fast volume rendering using a shear-warp factorization of the viewing transformation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philippe</forename><surname>Lacroute</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Levoy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="451" to="458" />
			<date type="published" when="1994-07" />
			<publisher>Annual Conference Series</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">VIZARD II: A PCIcard for real-time volume rendering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Meißner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Kanus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Straßer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eurographics / Siggraph Workshop on Graphics Hardware (EUROGRAPHICS-98)</title>
		<editor>Stephen N. Spencer</editor>
		<meeting>the Eurographics / Siggraph Workshop on Graphics Hardware (EUROGRAPHICS-98)<address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="1998-09-01" />
			<biblScope unit="page" from="61" to="68" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Arithmetic coding revisited</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alistair</forename><surname>Moffat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><forename type="middle">H</forename><surname>Neal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Witten</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Information Systems</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="256" to="294" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">The volumepro real-time ray-casting system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanspeter</forename><surname>Pfister</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><surname>Hardenbergh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jim</forename><surname>Knittel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hugh</forename><surname>Lauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Larry</forename><surname>Seiler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Annual Conference Series</title>
		<editor>Alyn Rockwood</editor>
		<meeting><address><addrLine>Los Angeles; Addison Wesley Longman</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Siggraph</publisher>
			<date type="published" when="1999" />
			<biblScope unit="page" from="251" to="260" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Interactive volume rendering on standard PC graphics hardware using multi-textures and multi-stage rasterization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Rezk-Salama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Engel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Greiner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Ertl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2000 SIGGRAPH/EUROGRAPHICS Workshop on Graphics Hardware</title>
		<editor>Stephan N. Spencer</editor>
		<meeting>the 2000 SIGGRAPH/EUROGRAPHICS Workshop on Graphics Hardware<address><addrLine>N. Y.</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2000" />
			<biblScope unit="page" from="109" to="118" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Wavelet based 3D compression with fast random access for very large volume data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Rodler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings Pacific Graphics</title>
		<meeting>Pacific Graphics</meeting>
		<imprint>
			<date type="published" when="1999" />
			<biblScope unit="page" from="108" to="117" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">An embedded hierarchical image coder using zerotrees of wavelet coefficients</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jerome</forename><forename type="middle">M</forename><surname>Shapiro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings DCC&apos;93 (IEEE Data Compression Conference)</title>
		<editor>James A. Storer and Martin Cohn</editor>
		<meeting>DCC&apos;93 (IEEE Data Compression Conference)<address><addrLine>Snowbird, UT, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1993-04" />
			<biblScope unit="page" from="214" to="233" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Geforce 256 register combiners</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Spitzer</surname></persName>
		</author>
		<ptr target="http://www.nvidia.com/Developer/" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Wavelets for Computer Graphics: Theory and Applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><forename type="middle">J</forename><surname>Stollnitz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tony</forename><forename type="middle">D</forename><surname>Derose</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><forename type="middle">H</forename><surname>Salesin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1996" />
			<publisher>Morgann Kaufmann</publisher>
			<pubPlace>San Francisco, CA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Wavelets and Subband Coding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Vetterli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jelena</forename><surname>Kovačević</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1995" />
			<publisher>Prentice Hall</publisher>
			<pubPlace>New Jersey</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Wavelet filter evaluation for image compression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><forename type="middle">D</forename><surname>Villasenor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Belzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Judy</forename><surname>Liao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1053" to="1060" />
			<date type="published" when="1995-08" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Windowed motion compensation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Watanabe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Singhal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. SPIE&apos;s Visual Comm. and Image Proc., volume 1605</title>
		<meeting>SPIE&apos;s Visual Comm. and Image ., volume 1605</meeting>
		<imprint>
			<date type="published" when="1991" />
			<biblScope unit="page" from="582" to="589" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Original engine dataset Compression ratio 200:1, Haar wavelet Compression ratio 200:1, CDF wavelet Original lobster dataset Compression ratio 100:1, CDF wavelet Original</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ziv</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lempel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Inf. Theory, IT</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="337" to="343" />
			<date type="published" when="1977-05" />
		</imprint>
	</monogr>
	<note>A universal algorithm for sequential data compression</note>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">compression ratio 31:1, I-Volume P-only sequence, quality 63, compression ratio 50:1, P-Volume MPEG sequence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I-Only</forename><surname>Sequence</surname></persName>
		</author>
		<imprint>
			<biblScope unit="volume">63</biblScope>
		</imprint>
	</monogr>
	<note>compression ratio 110:1, B-Volume</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
