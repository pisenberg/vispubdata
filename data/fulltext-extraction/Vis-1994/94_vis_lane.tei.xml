<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/pisenberg/grobid/grobid-0.6.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">UFAT -A Particle Tracer for Time-Dependent Flow Fields</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><forename type="middle">A</forename><surname>Lane</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Computer Sciences Corporation</orgName>
								<orgName type="institution" key="instit2">NASA Ames Research Center</orgName>
								<address>
									<addrLine>M/S T27A-2 Moffett Field</addrLine>
									<postCode>94035</postCode>
									<region>CA</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">UFAT -A Particle Tracer for Time-Dependent Flow Fields</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2021-02-19T20:31+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
				<p>Time-dependent (unsteady) flow fields are commonly generated in Computational Fluid Dynamics (CFD) simulations; however, there are ve y f e w flow visualization systems that generate particle traces in unsteady flow fields. Most existing systems generate particle traces in time-independent flow fields. A particle tracing system has been developed t o generate particle traces in unsteady flow fields. The system was used t o visualize several 3 D unsteady flow fields from real-world problems, and it has provided useful insights into the time-varying phenomena in the flow fields. In this paper, the design requirements and the architecture of the system are described. Some examples of particle traces computed by the system are also shown.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Particle systems were introduced in [14] to model fuzzy objects like fire, clouds, and water. For this type of particle system, the motion of the particle is based on some stochastic model. Extensions to this type of particle system have included modeling of snow, grass, smoke, and fireworks. In CFD, particle traces can be used to visualize several time-varying phenomena in the flow field. For example, vortex shedding, formation, and separation <ref type="bibr" target="#b4">[15]</ref>. When particle traces are used in this context, the motion of the particle is based on the physical velocity from the flow field.</p><p>An instantaneous streamline is a curve that is tangent to the vector field at an instant in time. In timeindependent (steady) flow, instantaneous streamlines are computed from the flow field at an instant in time. A streakline is a line joining the positions at an instant in time of all particles that have been released from a fixed location, called the seed location. In unsteady flow, streaklines are computed from several thousand time steps. Streaklines are commonly simulated by releasing particles continuously from the seed locations at each time step. In hydrodynamics, streaklines are simulated by releasing hydrogen bubbles rapidly from the seed locations. Instantaneous streamlines and streaklines are identical in steady flow fields.</p><p>In this paper, I introduce a particle tracing system called Unsteady Flow Analysis Toolkit (UFAT), which generates particle traces in unsteady flow fields. UFAT differs from existing systems in that it computes streaklines from a large number of time steps, performs particle tracing in flow fields with moving grids, provides a save/restore option, and supports playback. Preliminary results of UFAT were presented in <ref type="bibr">[ l o ]</ref> . This paper describes the design requirements and the architecture of UFAT. First, the basic problem of particle tracing in unsteady flow fields is described. The design requirements and the particle tracing algorithms of UFAT are then described. Examples of streaklines computed for three real-world problems are shown, and the performance of UFAT is analyzed. Finally, future enhancements for UFAT are discussed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Particle Tracing</head><p>The basic problem of particle tracing can b," stated as follows: assume that a vector function V ( p , t ) is</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>defined for all p in the domain D and t E [ t l , t n ] ,</head><p>where n is the number of time steps in the unsteady flow. For any particle p E D, find the path of p . The path of p is governed by the following equation:</p><formula xml:id="formula_0">$ = ? ( p , t ) .</formula><p>The path of p can be found by numerically integrating Equation ( 1 ) . Several schemes can be used to integrate the above equation. A common scheme is the second-order Runge-Kutta integration with adaptive stepsizing. Let po be the initial point (the seed location) of the particle p and k = 0. Then, where h = c / m a z ( v ( p k ) ) , mar() is the maximum velocity component of ? ( p k ) , and 0 &lt; c 5 l . The constant c controls the step size of the particle. If c is small, then the particle will traverse many steps in the grid cell. Small values of c should be used for grid regions with rapidly varying velocity. Otherwise, the particle p may advance out of the domain in just a few steps. The integration scheme stated above can be performed in the physical coordinate space or in the computational coordinate space. If the integration is performed in computational space, then it is simple and fast. During the integration, a cell search operation is performed to determine the grid cell that pk+1 lies in. Since the grid domain D is rectilinear in computational space, the grid cell can be easily determined by taking the integer computational coordinates of p k + l . For example, if the computational coordinates of pk+l are (&lt;, q, C), then pk+l lies in grid cell (int(&lt;), int(q), int(()). In the physical coordinate space, the grid domain D is curvilinear. The cell search operation usually requires performing an iterative algorithm to find the cell that p k + l lies in. A common algorithm used is the Newton-Raphson method. Although particle integration can be done faster in the computational coordinate space than in the physical coordinate space, integrating in computational space may be inaccurate if there are singularities in the grid. For computational space integration, physical velocities are transformed into computational velocities. Singularities in the grid could result in infinite transformed velocities <ref type="bibr" target="#b5">[4]</ref>. For this reason, UFAT performs particle integration in physical space.</p><p>If the grid is moving in time, then p k + l is likely to be in a grid cell different from the cell that pk lies in. To determine the cell that p k + l lies in, the cell search operation discussed above is performed. If the grid consists of several blocks (a type of grid known as a multi-block g r i d ) , then pk+l may lie in a block different from the block that pk lies in. If pk is near the boundary of a block, then it is necessary to check if p k + l will be in a different block. This also requires a cell search operation. For a detailed discussion of the basic problems in particle tracing, see <ref type="bibr" target="#b7">[5]</ref> and <ref type="bibr" target="#b16">[13]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Related Work</head><p>Presently, many systems are available for steady flow visualization. However, most of these systems only provide instantaneous visualization of the flow data. For example, instantaneous streamlines, isosurfaces, and slicing planes. Several effective techniques were recently developed for interactive interrogation of instantaneous flow fields. Some of these techniques are described in <ref type="bibr" target="#b8">[6,</ref><ref type="bibr" target="#b11">8,</ref><ref type="bibr">11]</ref>. To date, there are very few particle tracing systems that can generate streaklines using a large number of time steps from unsteady flow fields. Two of these are Virtual Wind Tunnel (VWT) [3] and pV3 <ref type="bibr" target="#b9">[7]</ref>. VWT provides interactive visualization of particle traces in a virtual environment using a stereo head-tracked display and a data glove. Although VWT is an effective interactive tool for unsteady flow visualization, it requires a preprocessing of the flow data, and the number of time steps that the user can visualize is determined by the memory size of the system. pV3 allows interactive animation of unsteady flow data by looping through an input file that contains the names of the flow data files. This is similar to an interactive scripting approach. pV3 does not save the visualization results, hence, playback is not supported and re-calculation is required to repeat the animation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Requirements</head><p>It is common to generate several thousand time steps of flow data in a CFD simulation; however, it is presently impossible to visualize flow data from all these time steps at one time. Scientists sometimes use one of the following approaches: (1) visualize the data at some snapshots in time or (2) save every nth time step of the data and then visualize the subset of data. Regardless of the approach used, there are usually hundreds of time steps that need to be visualized [ l o ] . A requirement for UFAT is that it must be able to compute streaklines from a large number of time steps.</p><p>A complex grid usually consists of several grid blocks. For some grids, one or more grid blocks may move as a function of time, a characteristic of grids with rigid-body motion. Moving grids are commonly used in pitching airfoils, oscillating flaps, rotating turbine fans of combustion engines, and rotating helicopter blades. Another requirement for UFAT is that it must be able to compute particle traces in unsteady flow with moving grids.</p><p>The ability to visualize a scalar quantity in the flow data can be crucial for some flow analysis. Quantities that are commonly computed are temperature, pressure, mach number, and density. A requirement for UFAT is that it must assign a color to each particle based on the value of a specified quantity sampled at the particle's location. The color of the particle can also be based on its position, the time at which it was released, or the seed location where it was released.</p><p>Interactive visualization of large time-dependent flow fields is difficult or nearly impossible due to the data size. Sometimes, a scripting approach is used to save the visualization results from each time step, and the visualization results are then played back at a later time. In some visualization systems, interactive visualization is feasible by using one of the following approaches: (1) preprocess the data so that a number of time steps can be stored in memory or (2) sample the flow data at a lower resolution so that the data can be stored in memory. By storing the flow data in memory, the data can be interactively visualized. The latter approach is usually not desirable because the accuracy of the flow data is lost when the data is sampled at a lower resolution. With either approach, the size of the physical memory dictates how much flow data can be visualized interactively. Although these two approaches can provide interactive visualization, important features may not be detected because of the reduced representation of the flow data. Using a scripting approach, the entire flow data can be analyzed. Furthermore, once the visualization results have been saved, the scientist can play back the results repeatedly without any additional computation. Visualization playback is another requirement for UFAT.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Unsteady Flow Analysis Toolkit</head><p>UFAT was developed to compute streaklines using a large number of time steps in 3D unsteady flow fields.</p><p>It handles single and multi-block curvilinear grids, and the grid may have rigid-body motion. Particles are released continuously from the specified seed locations at each time step. The particles are advected through all time steps until they leave the grid domain. UFAT saves the current positions of the particles at each time step; thus, the particle traces can be played back at a later time. Particles are colored according to a scalar quantity. The quantity may be a physical quantity of the flow (e.g. pressure, temperature, and density), a position coordinate (x, y, or z) of the particle, the time at which the particle was released, or the seed location where the particle was released. UFAT uses an adaptive-time integration scheme to advect the particles in the physical coordinate space. The integration scheme can be of second or fourth order. UFAT also allows particles to be traced along the grid surface. This type of particle trace simulates oil flow on a surface. Sometimes, the available disk on a system may not be able to store all time steps of flow data. UFAT provides a save/restore option so that particle tracing can be performed in several run sessions. This allows particle traces to be computed from many time steps without requiring all time steps to be online at one time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Data Structure</head><p>In order to advect particles through all time steps, UFAT stores the two most recent time steps of the flow data in memory. Particles are successively advected from the current time step to the next time step. The particle traces are stored in a two-dimensional array of size N, x N t , where N , is the number of seed locations and Nt is the number of time steps. Each entry in the array is a structure that contains the physical and computational coordinates of the particle and the time at which the particle was released from the seed location. There is also an array of size N , that stores the number of particles in each trace. is decremented by one.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Algorithm</head><p>This section outlines the particle tracing algorithm in UFAT. The following procedures in the algorithm are described:</p><p>Step-Through-Time(), Advect-Trace(), and A d v e c t P a r t i c l e O . Procedure S t ep-Through-Time () steps through all time steps in the given flow data and calls Advect-Trace(). The main task of procedure Advect-Trace() is to advect the active particles in all traces from the current time step to the next time step. The actual particle integration is performed in <ref type="figure">procedure  A d v e c t -P a r t i c l e ( )</ref> . For brevity, let current-time denote the current time step and next-time denote the next time step. For each procedure, a description is given followed by the pseudocode of the procedure.</p><p>Procedure S t ep-Through-Time ( ) begins by loading the first two time steps of the flow and grid data into memory. If the grid is fixed, then only one grid is loaded into memory. Then, it steps through all time steps in the flow data. For each time step, the following tasks are performed: (1) Call procedure Advect-Trace( to advect particles in every trace from current-time to next-time. (2) Write the current particle traces to the trace file. A frame marker is also written to denote the end of each time step.</p><p>(3) Read the next time step's flow. If the grid is moving in time, then read the next time step's grid. The pseudocode for this procedure is given below: (1) Copy all particles in the trace to a working trace array w . (2) Call procedure A d v e c t S a r t i c l e ( ) to advect each particle in the working trace w from current-time to nezt-time. If the particle is inside the grid domain D after the advection, then the particle is saved to the trace. Otherwise, the particle is considered to be inactive and it is discarded. (3) Release a new particle from the trace's seed location and save the particle in the trace. The pseudocode for this procedure is as follows:  <ref type="formula">2</ref>and is based on a predictor-corrector algorithm used in PLOT3D <ref type="bibr" target="#b7">[5]</ref>. The flow data is only given at some number of time steps. If t # ti for i = 1,. . .,IVt, then an interpolation in time is performed. Since the velocity is known only at discrete points in the grid, when p does not coincide with a grid point, a trilinear interpolation in physical space is also performed. Following are the steps in procedure Although the pseudocode shown above only provides a second-order integration scheme, a fourthorder integration scheme has also been implemented in UFAT. Procedure Interpolate-Velocity(), which is not shown, interpolates velocity in time followed by a trilinear interpolation in the physical space. When a new position for p is computed, a cell search step is performed to determine the grid cell that p lies in (see Section 2).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Animation</head><p>The most effective method to view streaklines is to animate the particle traces. UFAT saves streaklines at each given time step to a trace file, which can then be animated with a visualization system. Although particles may traverse in non-uniform time steps, the positions of the particles are sampled at uniform time steps (i.e. the given time steps). The particle trace file contains basic graphics primitives such as points and lines. These basic primitives can be written in a format so that they can be easily read by other visualization systems such as AVS, IRIS Explorer, and</p><p>FAST <ref type="bibr" target="#b1">[2]</ref>. The only requirement for the visualization system is that it must be able to animate the streaklines through a given sequence of time steps.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Distributed Visualization</head><p>It is common that an unsteady flow data set is too large to be stored locally on a graphics workstation. The flow data set is often stored on a remote system with a large disk capacity. The computation is then performed on the remote system while the results are sent over the network to the graphics workstation for interactive visualization. The data transfer rate on the network must be fast enough so that the image on the graphics workstation can be updated at least 15 frames per second for a reasonable animation. The size of the particle traces at each time step is relatively small compared to the size of the grid file. Thus, the particle traces at each time step can be sent over the network in a reasonably short period of time. If the grid is moving in time, then a new grid must also be sent over the network at each time step. It may take several seconds to transfer a grid consisting of several million grid points, depending on the speed of the network. Hence, distributed flow visualization is practical if the data transfer rate of the network is fast enough to handle the amount of data that will be sent over the network.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Results</head><p>This section shows some streaklines that were computed by UFAT for three unsteady flow data sets. Al-though the examples shown in this section are only from CFD applications, other applications with timedependent flow data can easily use UFAT to generate streaklines. The input data must consist of the grid geometry and the flow quantities sampled at the grid points. Currently, UFAT only supports curvilinear grids.</p><p>The first data set is a clipped Delta Wing with control surfaces, which oscillate at a frequency of eight where the particles were released. It can be seen that there is vortical separation from the leading edges of the wing. Frqm the simulation, it was found that the symmetric oscillation produces higher lift than the anti-symmetric oscillation <ref type="bibr" target="#b15">[12]</ref>.       The third data set is the proposed airborne observatory known as the Stratospheric Observatory For Infrared Astronomy (SOFIA). SOFIA is a modified Boeing 747SP transport with a large cavity that holds a three-meter class telescope. The CFD scientists want to assess the safety and optical performance of a large cavity in the 747SP <ref type="bibr">[l]</ref>. SOFIA would be the successor to the Kuiper Airborne Observatory (KAO), which is the only aircraft in the world that currently provides this type of infrared observing capability. SOFIA consists of approximately four million points in 41 grids. A total of 50 time steps were saved for the visualization. <ref type="figure" target="#fig_9">Figure 5</ref> shows streaklines surrounding the SOFIA airborne observatory at time step 40. In the figure, the telescope (partially visible) inside the cavity of the jet is colored in cyan. The particles are colored by the time of their release from a rake positioned in the aperture of the cavity. Blue represents the earliest time and orange represents the most recent time. <ref type="figure" target="#fig_10">Figure 6</ref> shows a close-up view of the telescope without the aircraft body. The floating object (colored in gray) above the telescope is the secondary mirror of the telescope. The cavity is represented by the semitransparent surface enclosing the telescope. Note that some particles are trapped inside the cavity, while some have escaped and passed the empennage.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Performance</head><p>The performance of UFAT depends on three factors: (1) the grid size, (2) the number of time steps, and (3) the number of seed locations. At each time step, UFAT reads the flow data file (and the grid file if the grid is moving in time). Depending on the disk 1/0 rate and the grid size, it could take from several seconds up to several minutes to read the flow and grid files at each time step. For example, if the disk 1 / 0 rate is 10 megabytes per second, then it would take approximately 1.2 seconds to read a grid file with one million grid points, assuming that there are three physical coordinates (x, y, and z) for each grid point. If the flow data file (solution file) contains five scalar quantities, then it would take approximately 2.0 seconds to read the file. Thus, it would require a total of 3.2 seconds per time step to read the grid and solution data. The number of particles that UFAT advects at each time step increases linearly. If there are 100 seed locations and 1,000 time steps, then the maximum number of particles that UFAT can advect at time step 1,000 is 100,000 particles. Using the clipped Delta Wing as an example, it took approximately 2.3 seconds to read a grid file and 3.0 seconds to read a solution file at each time step on a Silicon Graph-ics 320 VGX graphics workstation. The size of the grid file is four megabytes and the solution file is five megabytes. It took approximately 21 minutes to compute streaklines from 100 time steps and with 36 seed locations using a single 33-megahertz processor on the VGX graphics workstation. This includes the time to read the grid and solution files at each time step.</p><p>The size of the trace file generated by UFAT is 2.5 megabytes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9">Future Work</head><p>A disadvantage of the current version of UFAT is that it performs particle tracing sequentially. Particle tracing is an "embarrassingly" parallel application. It would be ideal to take advantage of multiple processors to perform particle tracing in parallel since each particle trace can be computed independently. A parallel version of UFAT has been developed on the Cray C90, Convex C3240, and SGI systems. The initial results indicate that the performance can be improved by several factors, depending on the number of processors used. Another enhancement that is currently being investigated is how to distribute the particle tracing task to a cluster of heterogeneous systems using a message passing library. An issue to be worked out is how to minimize the amount of data that each system needs for particle trace computation. The goal is to have a distributed parallel version of UFAT that would provide interactive particle tracing in large-scale unsteady flow fields.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Let</head><label></label><figDesc>Trace-Length[s] denote the number of particles in trace s , and it is initialized to zero. At each time step, a new particle is released from the seed location and Trace-Length[s] is incremented by one. When a particle in trace s leaves the grid domain, Trace-Length[s]</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Procedure</head><label></label><figDesc>Step-ThroughTime() Read first tvo time steps of f l o v and grid data For t = 1 t o Nt -1 do Advect-Trace(t, t + 1) Write current traces t o the trace f i l e Read the next time s t e p ' s f l o p data If moving grid then Read the next time s t e p ' s grid End for Procedure Advect-Trace (1 advects particles in every trace from current-time to nett-time. The procedure performs the following steps for each trace:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Procedure</head><label></label><figDesc>Advect-Trace(current-time, next-time) For s = 1 t o N , do Copy trace s t o vorking trace w W-Length = Trace-Length[s] Remove a l l particles i n trace s Trace-Length[s] = 0 For i = l t o W-Length do p = the i t h particle i n vorking trace w AdvectSarticle(current-time, next-time, Procedure A d v e c t S a r t i c l e ( ) advects the given particle p from current-time to next-time. The pseudocode shown below uses the second-order Runge-Kutta integration scheme given in Equation</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>4 V{{</head><label>4</label><figDesc>A d v e c t S a r t i c l e ( ) :(1) Initialize t to current-time. The variable t is incremented at each advection and the procedure exits when t = next-time or when the particle h y left the grid domain D.<ref type="bibr" target="#b1">(2)</ref> Interpolate the velocity V at p .<ref type="bibr" target="#b2">(3)</ref> Compute the time increment h, where h = c / m a t ( V) and c is a fraction of the grid cell that each particle must take inside the cell. The constant c can be considered as a normalized stepsize and 0 &lt; c &lt; 1. For example, if the particle must traverse five steps in a cell, then let c = 0.2.(4) Increment t by h. (5) Compute the predictor p * . (6) Interpolate the velocity f * at p * . (7) Compute the corrector, which is the position of p after the advection. Below is the pseudocode for procedure A d v e c t S a r t i c l e ( ) . Procedure AdvectSart i c l e (current-time, next-time, p) t = current-time While ( t &lt; nezt-time AND p E D ) do = Interpolate-Velocity(p, t , current-time, n e x t l i m e ) h = c / m a x ( C ) If ( t + h &gt; next-time) h = nezt-time -Predictor step } p ' = p + h * C V* = Interpolate-Velocity(p*, t + h, Rotal = (P + P ) / 2 current-time, next-time) { Adaptive stepsizing } If ( h * max(eot,l) &gt; c ) then Corrector step } End vhile p = p + h * (C + C y 2</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>Hertz (Hz) and with an amplitude of 6.65 degrees. Each oscillation cycle consists of 5,000 time steps. For visualization purpose every 50th time step is saved, for a total of 100 time steps per cycle. The clipped Delta Wing grid consists of 250 thousand points in seven blocks. For this CFD simulation, the scientists evaluated a new zoning method called "virtual zones," which is used for grids with time-varying boundary conditions. Virtual zones simplify the grid generation problem for complex geometries and for timedependent geometries [9]. Figure 1 shows the seed locations, which are colored by position, at the leading edge of the clipped Delta Wing. Figure 2 shows streaklines at time step 7, where the control surfaces have deflected 2 degrees up. The evenly spaced particle traces (colored in cyan) near the center of the wing indicates that the flow is relatively steady in that region. However, the flow is very turbulent near the tip of the wing. Figure 3 shows the streaklines after the control surfaces have completed one oscillation. At this time, the control surfaces have deflected 5 degrees up. This figure shows that some particles (colored in red), which were released from the outer part of the leading edge of the wing, have moved toward the tip of the wing due to the control surfaces. This behavior can be seen clearly in an animation of the streaklines. The second data set is an arrow wing configuration of a supersonic transport in transonic regime. Transonic flutter is known as a design problem on this configuration. Scientists want to develop a computational tool to examine the influence of control surface oscillations on the lift of the transport for the suppression of the flutter. The arrow wing grid consists of approximately one million points in four blocks. The control surfaces oscillate at a frequency of 15 Hz and with an amplitude of 8 degrees. Figure 4 shows streaklines surrounding the transport at time steps 25 and 175. The particles are colored by their seed locations,</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 1 .</head><label>1</label><figDesc>Seed locations on the leading edge of the clipped Delta Wing. Particles are colored by position.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 2 .</head><label>2</label><figDesc>Streaklines at time step 7. The control surfaces have deflected up by 2 degrees.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 3 .</head><label>3</label><figDesc>Streaklines at time step 112. The control surfaces have deflected up by 5 degrees.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 4 .</head><label>4</label><figDesc>Streaklines from a supersonic transport at time steps 25 and 127.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 5 .</head><label>5</label><figDesc>Streaklines surrounding the cavity of a modified Boeing 747SP, which is an airbome observatory.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 6 .</head><label>6</label><figDesc>A close-up view of streaklines near the telescope (colored in cyan) inside the cavity of the observatory.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>(</head><label></label><figDesc>See color plates, page </figDesc></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>The flow data sets were provided by Chris Atwood, Goetz Klopfer, Steve Klotz, and Shigeru Obayashi. This work was supported by NASA under contract NAS 2-12961.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Flowfield Simulation about the Stratospheric Observatory for Infrared Astronomy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Atwood</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Van Dalsem</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">AIAA Journal of Aircraft</title>
		<imprint>
			<biblScope unit="page" from="719" to="727" />
			<date type="published" when="1993-09" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">FAST: A Multi-Processed Environment for Visualization of Computational Fluid Dynamics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Bancroft</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Merritt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Plessel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Kelaita</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Mccabe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Globus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Visualization &apos;90</title>
		<editor>A. Kaufman</editor>
		<meeting>Visualization &apos;90<address><addrLine>San Francisco, California</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1990-10" />
			<biblScope unit="page" from="14" to="27" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">The Virtual Wind Tunnel</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bryson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Levit</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer Graphics &amp; Applications</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="25" to="34" />
			<date type="published" when="1992-07" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Particle Systems -A Technique for Modeling a Class of Fuzzy Objects</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Reeves</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transaction on Graphics</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="91" to="108" />
			<date type="published" when="1983" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Schlichting</surname></persName>
		</author>
		<title level="m">Boundary Layer-Theory</title>
		<imprint>
			<publisher>Mc</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Sources of error in the graphical analysis of CFD results</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Buning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Scientific Computing</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="149" to="164" />
			<date type="published" when="1988" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Graw</forename><surname>Hill</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1979" />
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Buning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Steger</surname></persName>
		</author>
		<title level="m">Graphics and Flow Visualization in Computational Fluid Dynamics, 7th Computational Fluid Dynamics Conference</title>
		<meeting><address><addrLine>Cincinnati, Ohio</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1985-07" />
			<biblScope unit="page" from="85" to="1507" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>De Leeuw</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Van Wijk</surname></persName>
		</author>
		<title level="m">A Probe for Local Flow Field Visualization</title>
		<editor>G. Nielson and D. Bergeron</editor>
		<meeting><address><addrLine>San Jose, California</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1993-10" />
			<biblScope unit="page" from="39" to="45" />
		</imprint>
	</monogr>
	<note>Proceedings of Visualization &apos;93</note>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Haimes</surname></persName>
		</author>
		<title level="m">pV3: A Distributed System for Large-scale Unsteady CFD Visualization</title>
		<imprint>
			<biblScope unit="page">92</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Aerospace Sciences Meeting and Exhibit</title>
		<imprint>
			<date type="published" when="1994-01" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Visualization of Turbulent Flow with Particles</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Hin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Post</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Visualitation &apos;99</title>
		<editor>G. Nielson and D. Bergeron</editor>
		<meeting>Visualitation &apos;99<address><addrLine>San Jose, California</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1993-10" />
			<biblScope unit="page" from="46" to="52" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Virtual Zone Navier-Stokes Computations for Oscillating Control Surfaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Klopfer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Obayashi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">11th Computational Fluid Dynamics Conference</title>
		<meeting><address><addrLine>Orlando, Florida</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1993-07" />
		</imprint>
	</monogr>
	<note>AIAA 93-3363-CP</note>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lane</surname></persName>
		</author>
		<title level="m">Visualization of Time-Dependent Flow Fields</title>
		<editor>G. Nielson and D. Bergeron</editor>
		<meeting><address><addrLine>San Jose</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1993-10" />
			<biblScope unit="page" from="32" to="38" />
		</imprint>
	</monogr>
	<note>California</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Flow Volumes for Interactive Vector Field Visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Max</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Becker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Crawfis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Visualization &apos;93</title>
		<editor>G. Nielson and D. Bergeron</editor>
		<meeting>Visualization &apos;93<address><addrLine>San Jose, California</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1993" />
			<biblScope unit="page" from="19" to="24" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Navier-Stokes Computations on Full-Span Wing-Body Configuration with Oscillating Control Surfaces, A I A A Atmospheric Flight Mechanics Conference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Obayashi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Chui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Guruswamy</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1993-08" />
			<biblScope unit="page" from="93" to="3687" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Fluid Flow Visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Post</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Van Walsum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Focus on Scientific Visualization</title>
		<editor>H. Hagen, H. Mueller, and G. Nielson</editor>
		<meeting><address><addrLine>Berlin</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1993" />
			<biblScope unit="page" from="1" to="40" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
