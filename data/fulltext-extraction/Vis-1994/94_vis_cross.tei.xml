<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/pisenberg/grobid/grobid-0.6.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Virtual Reality Performance for Virtual Geometry</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><forename type="middle">A</forename><surname>Cross</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Indiana University Bloomington</orgName>
								<address>
									<postCode>47405</postCode>
									<region>IN</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><forename type="middle">J</forename><surname>Hanson</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Indiana University Bloomington</orgName>
								<address>
									<postCode>47405</postCode>
									<region>IN</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Virtual Reality Performance for Virtual Geometry</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2021-02-19T20:30+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
				<p>We describe the theoretical and practical visualization issues solved in the implementation of an interactive real-time four-dimensional geometry interface for the CAVE, an immersive virtual reality environment. While our specific task is to produce a &quot;virtual geometry&quot; ezperience by approzimating physically correct rendering of manifolds embedded in four dimensions, the general principles ezploited by our approach reflect requirements common to many immersive virtual reality applications, especially those involving volame rendering. Among the issues we address are the classification of rendering tasks, the specialized hardware support required to attain interactivity, specific techniques required to render 4 0 objects, and interactive methods appropriate for our 40 virtual world application.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>In this paper we describe how we have combined general requirements for a broad class of virtual reality applications with the capabilities of special-purpose graphics hardware to support an immersive virtual reality application for viewing and manipulating fourdimensional objects. We present general issues concerning the application of virtual reality methods to scientific visualization, discuss how the resulting requirements are reflected in fundamental rendering tasks, and point out where hardware features have crucial roles to play. The proving ground for our general observations is the design and implementation of an application for visualizing a 4D mathematical world through interaction with 3D volume images. We introduce a task independent rendering paradigm through which, with proper hardware support, we can produce complex realistic images at interactive speeds. 4D Visualization. There have been a variety of systems devoted to the general problem of 4D visualization, ranging from the classic work of Banchoff [2, 1 3 to geometry viewers such as Geomview <ref type="bibr" target="#b19">[17]</ref>, our local "MeshView" 4D surface viewer, and specialized high-performance interactive systems such as that of Banks <ref type="bibr" target="#b2">[3]</ref>. Our virtual-reality-oriented work builds on these previous efforts and adds new features of 4D rendering (see, e.g., <ref type="bibr" target="#b23">[20,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr">141)</ref> that have only recently become technically feasible to exploit interactively <ref type="bibr">[ll]</ref>. Such systems are valuable tools for mathematical research <ref type="bibr" target="#b18">[16]</ref> as well as for volume and flow-field visualization applications <ref type="bibr" target="#b15">[13,</ref><ref type="bibr">151</ref>. One of our goals is to 1070-2385/94 $04.00 0 1994 IEEE develop techniques applicable to a real-time demonstration of 4D and volume-based 3D rendering applications in the CAVE [SI. In its present configuration, the CAVE is a Silicon Graphics Onyx/4 Reality Engine' with multiple graphics channels driving projectors for two wall displays and the floor, with simulator support for workstation code development.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Virtual Reality and Visualization of Geometry</head><p>In this paper we emphasize the visualization of challenging classes of mathematical objects through 3D volumetric rendering. This section outlines our viewpoints on the general issues involved in creating a virtual reality for such domains. Mental models. Philosophers have long wrestled with the question of the nature of reality: we consider reality to be embodied in our personal mental models that derive from experience with natural phenomena and allow us to cope with the qualitative physics of everyday life. Virtual reality, then, is achievable in one of two ways: we may create simulated experiences that involve the subject by exploiting ezisting mental models and perceptual expectations; or we may attempt, by simulating phenomena with no real-world correspondence, to create new classes of mental models, thereby extending the human experience. Necessary features. The basic features of the virtual reality systems that concern us here are:</p><p>1. Immersion. The system must physically involve the user by responding to viewer motions and actions, e.g., using a head-tracker, flying mouse, wand, etc. Regardless of whether the display medium is a simple through-the-window view or a CAVE, this intensifies the intuition-building experience.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Interaction.</head><p>The virtual environment must respond to the participant's actions a t a high frame rate and provide smooth and accurate tracking of the input devices to support realistic feedback to the viewer. The user must be able to make changes and observe immediate results in order to draw intuitive conclusions about the structure and behavior of the simulated environment.</p><p>3. Visual realism. Redundant realistic visual cues are needed to involve the participant, so we should strive to include effects such as perspective, attenuation with distance, specular and diffuse shading, shadows, motion parallax, and occlusion. Providing such cues creates a more satisfying visual experience, in addition to providing qualitative intuitive information at a preconscious level <ref type="bibr" target="#b8">[7]</ref>.</p><p>Anticipating the future. One task of the virtual reality developer is to avoid the pitfalls of shortsightedness. In this respect, our philosophy is to extend our attention also to approaches that are not feasible in terms of current performance, but could be drastically accelerated in future hardware generations. Indeed, the development of appropriate algorithms to keep up with the rapid evolution of the hardware may be viewed as one of the most serious challenges we face: we may become imagination-limited long before the limits of the hardware technology are reached.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Interactive Realism</head><p>The goals of interactivity and realism are contradictory; we must apparently compromise between the speed of scan-conversion approximations and physically accurate but time-consuming ray-tracing methods. Here we present the fundamentals of a rendering semantics that has the potential to support an acceptable compromise.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">The Toolbox</head><p>The following image-level abstractions form a set of fundamental tools in terms of which we can express a remarkable number of complex geometric rendering effects: z-buffer. The z-buffer tests and optionally replaces a geometric value normally representing an object's distance seen through the pixel; complex effects can be achieved by selecting appropriate tests and replacement rules.</p><p>Frame buffer and accumulation buffer mathematics. Frame buffers support operations that act selectively on images and include addition, multiplication, logical operations, convolution, and histograms.</p><p>The accumulation buffer, which is separate from the frame buffer, is dedicated to image addition and sealing and usually has more bits per color component than the frame buffer. Typical applications involve averaging a number of images, as in Monte-Carlo integration.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Static and dynamic textures.</head><p>A static texture is a common surface or volume texture map, while a dynamic texture is one that may vary between frames. For instance, we might simulate a window as a plane with the current outside view mapped onto it; as the scene outside changes, so does the texture map. In addition to storing surface color, texture maps may also serve as lookup tables for reflectance or shading functions.</p><p>Automatic texture vertex generation. Given a texture map containing a lookup table for a function, we may not know in advance what portion of the texture map is required. Texture vertices can be generated automatically by supplying a (possibly projective) transformation function from the geometry to the texture space. For example, given a volumetric woodgrain texture, the system automatically chooses the correct woodgrain to map onto a slice through the virtual block. For a more complete discussion of texture mapping operations, see [ti].</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">First-order Effects</head><p>We consider a first-order effect to be one that requires a fixed, environment-independent number of primitive operations per scene element. In this section, we describe a set of useful first-order techniques that can be used to approximate rendering effects. Planar reflection. The reflections from a flat surface can be defined by rendering the environment from a virtual viewpoint placed on the opposite side of the reflecting surface; this image is then mapped onto the surface, giving the impression of a mirror. Non-planar reflection. An environment map is defined as the image of a perfectly reflecting sphere located in the environment when the viewer is infinitely far from the sphere. Given the view direction and normal a t each vertex of a polygon, we can use automatic texture vertex generation to choose texture coordinates; this gives an approximation of infinite focal length reflection <ref type="bibr" target="#b9">[8]</ref>. Shading maps. Texture maps can also be used as repositories for pre-computed reflectance functions (e.g., diffuse, Phong, Cook-Torrance, etc.). This method produces much better behavior than hardware lighting (i.e., Gouraud shading), which defines colors only a t the vertices, and so cannot place specularities inside a large polygon. Physically based luminaires. A diffuse emitter can be approximated by placing a projection point behind the planar emitter and using projective textures to shine a pre-computed cosine distribution texture map into the environment. The diffuse light thus emitted is multiplied by each surface's diffuse light color coefficient. Other distributions can be approximated by projecting different lookup tables. If we use shading maps to approximate the cosine term and distance attenuation at target polygons, we can approximate physical luminaires.</p><p>Shadows. Areas lit by a particular light can be defined as areas that that light "sees"; i.e., for sharpedged shadows, we test whether a particular point can describe an unobstructed path to the luminaire. Using the z-buffer, we can define a depth texture map from the light's point of view. By projecting this texture map into the environment and z-buffering from the eye's point of view, we can compare the distanceto-the-light values of visible surfaces to the projected nearest-to-the-light value. If the eye sees a surface whose distance to the light is larger than the indicated minimum, it must be in shadow; if not, it is lit. If this function is applied over all pixels to define a binary black-white image, this can be multiplied by an image containing a shadowless lit image to construct a final image including appropriate shadows <ref type="bibr" target="#b20">[18,</ref><ref type="bibr">191</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Second-order Effects</head><p>Second-order effects provide more sophisticated image features, and involve iteration or multiple samples to generate a single image. These methods are sufficiently expensive, at present, to preclude their use in most interactive applications. However, these methods greatly increase visual satisfaction and hardware improvements will make them increasingly practical. Multiple samples. The accumulation buffer allows an elegant implementation of Monte-Carlo methods over entire images. Thus, dynamic images such as shadow maps or reflection images can be defined by probabilistic sampling, producing smooth shadows or blurred reflections. Psychological research indicates that smooth shadows, in particular, are important for visual realism <ref type="bibr" target="#b8">[7]</ref>. Iterated diffuse and specular reflection. If we approximate diffuse emission from a single polygon and produce an image of the incident light at another, we can then emit some of this light back into the environment. When this process is iterated, it becomes an approximation to radiosity and global illumination. This method has the advantage of being much faster than similar precomputations and has lower algorithmic complexity while maintaining important visual features. Participating media. Approximate volume images may be produced by cutting multiple additive slices through the viewed space. By projecting lighting distributions and shadows onto these slices, we can approximate the scattering of light as it passes through a foggy environment, producing visible beams and similar volume-rendering effects.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Hardware Support</head><p>At present, only the simplest of the above techniques are viable in a software-only interactive system with a complex environment. As our needs for realism increase, so do our needs for graphics hardware support. For example, if we require Phong shading, but must implement it in software, the complexity of environments with which we can interact will be severely limited. However, given hardware texturemapping support, we can precompute a lookup table to support an implementation of specular reflectance functions; the hardware can wrap this texture around the objects, interpolating between computed points to produce correct images of specular objects.</p><p>Our virtual geometry applications are designed to take full advantage of the hardware support of the Silicon Graphics Onyx Reality Engine'. Its support for high-speed texture mapping, in particular, enables us to map large portions of our graphics computations directly onto hardware-supported primitives. For example, dynamic texture mapping and automatic texture vertex generation allow us to interactively simulate bizarre physical illumination models such as 4D light. Effectively, we have transformed the mathematical rendering model into a form expressible in terms of our hardware-supported high-speed toolbox. The exploitation of such transformations can greatly enhance user comprehension through improved feedback and perceived visual realism.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Visualization Effects Design</head><p>The particular system that we have implemented to explore virtual reality paradigms focuses on mathematical visualization in higher dimensions [ 111. We create the illusion that the participant is immersed in the 3D, volumetric retina of a 4D cyclops interacting with objects in a 4D world. Among the issues we must address to achieve this are the following: 4D Depth. Perceiving 4D depth requires binocular fusion of a pair of distinct 3D volume images; a 3D human would effectively need 2 pairs of 3D eyes to see these images at the same time (and could not fuse them anyway). Thus we need to obtain 4D depth cues from other sources such as motion, occlusion, or depth color codes. For example, occlusions of surfaces by surfaces can be emphasized for visibility by painting or cutting away the more distant of two surfaces around an illusory intersection in a particular projection. 4D Motion Cues. Motion is an important factor in our ability to perceive 3D structure monocularly; either constant-angular-velocity rigid 3D rotation or periodic rocking is an adequate substitute for a stereo display. We use rigid 4D rotations to generate motion cues for our 4D monocular world that resemble familiar 3D motion cues. 3D Depth. Typical objects that we project out of 4D produce volume images, though our rendered images of thickened surfaces are simplified since we use a thin-surface approximation to achieve acceptable rendering performance. Thus seeing the 3D opaque exterior of our objects is not enoughwe want to see inside the projected shape. This causes a problem: if we make a surface transparent but featureless, like a highly inflated balloon, there are not enough distinct features in the image to activate 3D stereo perception except along the outer edges of the object. Similarly, for volumetric objects whose interior is made of smooth internal "jellylike" solids, it is difficult to produce a strong impression of what may be a very complex internal 3D structure. Texture. For human binocular vision to perceive a full 3D structure in one glance, smooth rendering methods are often deficient; they do not generate the image gradients necessary for the edge matching process used in stereo depth reconstruction. One technique to circumvent this problem is to spice up the featureless jelly with surface or volumetric textures. Such textures, which can be as simple as a set of grid lines or a regular or random lattice of points, provide a richer collection of image gradients to drive the stereographic matching process. No Slices. A common approach to representing 4D objects is to slice them up and consider them as a sequence of 3D objects, often presented as a timesequenced animation. We insist on holistic images for our imaginary 4D retina; humans are not adept at perceiving 3D objects from a time sequence of 2D slices, so we do not expect that 3D slices of 4D objects will be any easier.</p><p>Lighting. In everyday life, we are able to perceive 3D shapes in static photographs and drawings. We make certain assumptions about the nature of the objects and lighting conditions, and apparently infer the 3D structure using what is known in computer vision as a %hape from shading" algorithm. We see objects whose structure is revealed by the intensity gradations reflected from the object and by its cast shadows. Diffuse and specular highlights reveal additional information about the directions of surface or volume patches that is more specific than, for example, gradient or isosurface information. 4D lighting permits a similar holistic depiction of a 4D object, and the structure of the lighting in the 3D projection contains many subtle clues about the 4D structure and its orientation relative to the 4D lights and camera. Shadows. To enhance the scene perception experience, we can provide auxiliary cues such as 3D shadows to supplement 3D stereo perception. One can also generate 4D shadow volumes to help reveal hidden 4D structure <ref type="bibr" target="#b14">[12]</ref>. Occlusion. We exploit occlusion information to infer structure in 2D drawings representing the 3D world; a typical mathematical application would be the "crossing diagram" showing the unique 3D structure of a knotted loop of string using over/under crossing markings on a 2D diagram alone. Similar phenomena occur in 4D; non-intersecting surfaces in 4D may appear to intersect in a curve when projected to 3D, just as 3D lines may appear falsely to intersect when projected to 2D; pieces of 4D volumes may completely block out other 4D volumes in the 3D projection, just as 3D surfaces block occlude) one another in 2D imagsions, and so can be easily rendered using back-face culling. For 4D multiple-object scenes and non-convex objects, we can provide occlusion handling, crossing markings or depth-cued colors to emphasize the occurrence of 4D occlusion. This is not always possible to achieve interactively, since processing occlusions may be a memory-intensive or combinatorially explosive process. Depth Coding. A number of techniques have been proposed to provide a sense of depth in 4D graphics (see, e.g., [Z]); these include pseudocolor coding of depth, application of depth-dependent static or moving textures, and 4D-depth dependent opacity or blurring. Redundancy. Typical 3D terrain maps and graphs have redundant coding of properties such as elevation. Pseudocolor, isolevel contours, ruled surface markings, and oblique views exhibiting occlusion, illumination effects, and shadows may all be combined in a single representation. 4D data representations also profit from such redundancy, so we add multiple 4D cues when possible.</p><p>In summary, the family of visual effects that we wish to achieve involves a wide variety of issues and representation technologies. The common thread is this: we examine holistic perceptual processes such as lighting and motion that serve us well in dealing with our 3D world, and exploit the 4D analogs of those ing. Single convex 3 b and 4D objects have no occlu-processes to encode relevant information in the 3D volume image perceived by our hypothetical 4D being.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Interactive Interface Design</head><p>Our philosophy of 4D interaction is based on several fundamental assumptions about how human beings learn about the 3D world. We are all familiar with the fact that if we are driven around a strange town, we are much less able to find our way later than if we do the driving ourselves. Thus we seek 4D interaction modes that emphasize the involvement of the user and promote the feeling of direct manipulation, as though 4D objects were responding in some physical way to the motions of our input devices. Successful strategies should therefore significantly reduce the required user training time by exploiting analogs of familiar 3D direct manipulation.</p><p>Restricting ourselves for now to single compact objects lying in the center of our perceived CAVE space, we need several basic types of control: (1) the user moving around the 3D projected object itself; (2) rigid 3D motions of the object; (3) rigid 4D rotations (and perhaps translations) of the object; (4) 4D control of the orientation of the light ray (or rays) used in the shading and shadowing processes. The first two capabilities are standard for almost all CAVE applications.</p><p>The two 4D rotation tasks, however, require the following application-specific design considerations: 4D Orientation Control. Direct manipulation of 3D orientation using a 2D mouse is typically handled using a rolling ball <ref type="bibr" target="#b11">[9]</ref> or virtual sphere <ref type="bibr" target="#b4">[5]</ref> method to give the user a feeling of physical control. <ref type="figure">Figure la</ref> shows the effect of horizontal and vertical 3D rolling ball motions on a cube: supposing that the cube initially shows only one face perpendicular to the viewer's line of sight, moving the mouse in the positive z direction exposes an oblique sliver of the left-hand face, while motion in the y direction exposes the bottom face; reversing directions exposes the opposite faces. Long or repeated motions in the same direction bring cycles of 4 faces towards the viewer in turn. In the rolling ball method, circular mouse motions counterrotate the cube about the viewing axis; in the virtual sphere method, the mouse acts as if glued to a glass sphere, so that at a certain radius along the x-axis from the center, a vertical mouse motion causes spinning about the viewing axis.</p><p>The extension of this approach to 4D is outlined in the appendix and described in more detail in <ref type="bibr">[lo]</ref>. <ref type="figure">Figure l b</ref> is the 4D analog of Figure la: beginning with a fully visible transparent (volume-rendered) cube, which represents a single hyperface of a hypercube perpendicular to the 4D viewing vector, we move the 3D mouse along the z-axis to expose a volumetric sliver on the left; this is the oblique view of the left hyperface. Moving the 3D mouse along the y-axis exposes a volumetric sliver on the bottom; moving the 3D mouse along the z-axis exposes a volumetric sliver on the back of the original volumetric cube. Reversing directions brings up the opposite hyperfaces; long motions reveal cycles of 4 hyperfaces, but now there are three cycles, one each in the z, y, and z directions. How do we get ordinary rotations, say in the z-y plane? Moving the 3D mouse in small circles in any plane produces counter-rotations of that plane, thus giving 3 more degrees of freedom, exhausting the 6 degrees of orientational freedom in 4D. The 4D virtual sphere action follows by exact analogy to the 3D case. <ref type="figure" target="#fig_2">Figure 2a</ref> shows a schematic diagram of a method for controlling the 3D lighting vector using a 2D mouse: the unit vector in 3D has only two degrees of freedom, so that picking a point within a unit circle determines the direction uniquely (up to the sign of its view-direction component). With a convention for distinguishing vectors with positive or negative view-direction components (e.g., solid or gray), we can uniquely choose and represent the 3D direction. Control of the vector is straightforward using the rolling ball: the lighting vector initially points straight out of the screen (up in the oblique view of <ref type="figure" target="#fig_2">Figure 2b)</ref>, and moving the mouse in the desired direction tilts the vector to its new orientation, whose projection to the plane of <ref type="figure" target="#fig_2">Figure 2a</ref> is shown in the gray ellipse in <ref type="figure" target="#fig_2">Figure 2b</ref>. Rotating past 90 degrees moves the vector so its view-direction component is into the screen. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>4D Light Control.</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Examples</head><p>A classic example of a non-trivial surface embedded in 4D is a knotted sphere, and this is the central demonstration we have implemented for the CAVE; <ref type="figure" target="#fig_3">Figure 3</ref> shows the spun trefoil, the 4D knotted sphere closest in spirit to an ordinary 3D trefoil knot, while <ref type="figure" target="#fig_4">Figure 4</ref> shows the twist-spun trefoil, which, astonishingly, can be shown to bc; unknotted in 4D.</p><p>The real-time display f these ima es is made possible by replacing the tech t iques of [lj, which required up to half an hour per frame to render, with a dynamic texture map implementation of [I I], resulting in update rates of up to 30 frames/second. The texture mapping support of the RealityEngine permitted us to represent the 4D lighting distributions on the surface using a dynamic texture map; the resulting transparent volumetric image was rendered using frame buffer addition with multiplicative opacity.</p><p>Occlusion computations remain too expensive for real time, and so we precompute the occlusions for one particular viewpoint and fix them to the object; this has the curious advantage that, when the object is rotated in 4D, one can see the explicit separation of the apparent self-intersections, and convince oneself that the "side view" shows that no self-intersections exist.</p><p>In <ref type="figure" target="#fig_5">Figure 5</ref> we show a closeup of the 4D control feedback display, which reads out the current 4D light position and 4D orientation of the central knotted sphere. <ref type="figure" target="#fig_6">Figure 6</ref> is a true volume-rendered object, the hypersphere, projected from 4D to show a 3D view of its "northern hemisphere;" grid lines and a volumetric speckle texture are added within the featureless volume of this object to give a clear stereographic image, as noted in Section 4.</p><p>Finally, in <ref type="figure" target="#fig_7">Figure 7</ref>, we step back to show how our mathematical world appears in a rich virtual workspace. To illustrate some of our other capabilities for general virtual geometry, we show in <ref type="figure" target="#fig_8">Figure 8</ref> how the knotted sphere appears in a room illuminated by a light shining through foggy air. Note the satisfying effect of the 3D shadows cast in the room by the mathematical objects.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusions and Future Work</head><p>We have described a wide spectrum of issues involved in the development of an ambitious virtual reality system that attempts to immerse the viewer in a technically correct four-dimensional world. The techniques required for this system include the optimization of rendering approximations through the use of hardware graphics operations, as well as task-specific approaches to enhancing user interaction. The optimizations used in this system apply also to general virtual reality performance problems.</p><p>While adapting our software to the CAVE, we faced parallelization issues that did not arise on a single screen. In addition to parallelizing the mathematics (e.g., multi-threading the projection of four dimensions to three), we dealt with other problems involving shared memory and resources. For example, one must avoid collisions on the graphics hardware, particularly during geometry transformations.</p><p>In its present form, this project is approaching the limits of the target graphics hardware. We now face the standard bottleneck of textured polygon fill rate, for instance. Extending the features of the system will require computations for which the RealityEngine hardware has no particular advantage; for example, the 4D occlusion calculation is still too computationally expensive for adequate interactive performance, as is depth-ordered transparency. However, the addition of resources such as hardware support for large dynamic 3D textures would enable us to attack even and the NCSA CAVE personnel, as well as the members of the Electronic Visualization Laboratory a t the University of Illinois/Chicago for their support.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A 4D Rolling Ball Formula</head><p>For completeness, we list the 4D rolling ball formula derived in <ref type="bibr">[lo]</ref> that is the basis for most of our 4D controls; this natural algorithm for 4D orientation control requires exactly three control parameters, thus making it ideally suited to the "flying mouse" or CAVE "wand" 3-degree-of-freedom user interface de-      (See color plates, page  </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>XFigure 1 :</head><label>1</label><figDesc>Schematic diagram comparing (a) 2D mouse control of a 3D object, and (b) 3D flying mouse control of a 4D object.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>The analogous control system for 4D lighting, shown inFigure 2c, is based on a similar observation: since the 4D normal vector has only 3 independent degrees of freedom, choosing an interior point inside a solid sphere determines the vector uniquely up to the sign of its component in the unseen 4th dimension (the "4D view-direction component"). The rest of the control proceeds analogously. Since we cannot easily interpret 4D oblique views, we do not attempt to draw the 4D analog ofFigure 2b.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Schematic diagram comparing (a) selecting 2D point in disk to specify 3D light direction, shown obliquely in (b), and (c) 3D flying mouse control of a 4D light direction by picking 3D point inside solid sphere.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 :</head><label>3</label><figDesc>vices. Let x' = (X, Y, 2) be a displacement obtained from the 3-degree-of-freedom input device, and define r2 = X 2 + Y 2 + Z 2 . Take a constant R with units 10 or 20 times larger than the average value of T , compute D2 = R2 + r 2 , compute the fundamental rotation coefficients c = cos 0 = R / D , s = sin 0 = r / D , and then take z = X / r , y = Y / r , z = Z / r , so z2 + y2 + z2 = 1.Finally, rotate each 4-vector by the following matrix before reprojecting to the 3D volume image:1 -z y 1c) -(1-c)zy -(1 -c)zz sx -(1 -c)zz -(1c)yz 1 -z2(lc) sz-(1-c)zy 1 -y y 1 -c) -(1 -Closeup of spun trefoil knot i i t h e CAVE simulator.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 :</head><label>4</label><figDesc>Closeup of twist-spun trefoil apparent knot in the CAVE simulator.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 5 :</head><label>5</label><figDesc>4D control feedback display; single line shows light direction, wire-frame shows 4D orientation referred to a hypercube.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 6 :</head><label>6</label><figDesc>The "solid textured beach-ball" view of the hypersphere.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 7 :</head><label>7</label><figDesc>User view of knotted sphere and controls inside a rich virtual room.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 8 :</head><label>8</label><figDesc>Adding 3D light and fog to the virtual workspace.</figDesc></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>This work was supported in part by NSF grant IRI-91-06389. We thank George Francis, Chris Hartman,</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Visualising two-dimensional phenomena in four-dimensional space: A computer graphics approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">F</forename><surname>Banchoff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Statistical Image Processing and Computer Graphics</title>
		<editor>E. Wegman and D. Priest</editor>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Marcel Dekker, Inc</publisher>
			<date type="published" when="1986" />
			<biblScope unit="page" from="187" to="202" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Beyond the third dimension: Geometry, computer graphics, and higher dimensions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">F</forename><surname>Banchoff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Scientific American Library</title>
		<imprint>
			<date type="published" when="1990" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Interactive manipulation and display of two-dimensional surfaces in four-dimensional space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Banks</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Graphics</title>
		<editor>D. Zeltzer</editor>
		<imprint>
			<date type="published" when="1992-03" />
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="197" to="207" />
		</imprint>
	</monogr>
	<note>Symposium on Interactive 30 Graphics</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Shades of a higher dimension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">A</forename><surname>Carey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">P</forename><surname>Burton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">M</forename><surname>Camp-Bell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics World</title>
		<imprint>
			<biblScope unit="page" from="93" to="94" />
			<date type="published" when="1987-10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">A study in interactive 3-d rotation using 2-d control devices</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Mountford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sellen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Graphics</title>
		<imprint>
			<date type="published" when="1988" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m">Proceedings of SIGG k k AP</title>
		<meeting>SIGG k k AP</meeting>
		<imprint>
			<date type="published" when="1988" />
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="121" to="130" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Surround-screen projection-based virtual reality: The design and implementation of the CAVE</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Cruz-Neira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">J</forename><surname>Sandin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">A</forename><surname>De-Fanti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Graphics (SIGGRAPH &apos;93 Proceedings)</title>
		<editor>J. T. Kajiya</editor>
		<imprint>
			<date type="published" when="1993-08" />
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="135" to="142" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">more challenging problems in virtual geometry</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Sensation and Perception</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">B</forename><surname>Goldstein</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Haeberli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Segal</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1980" />
			<publisher>Wadsworth Publishing Company</publisher>
		</imprint>
	</monogr>
	<note>ping as a fundamental drawing primitive</note>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m">Fourth EUROGRAPHICS Workshop on Rendering</title>
		<editor>M. Cohen, C. Puech, and F. Sillion</editor>
		<imprint>
			<date type="published" when="1993-06" />
			<biblScope unit="page" from="259" to="266" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">The rolling ball</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">J</forename><surname>Hanson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Graphtcs Gems</title>
		<editor>D. Kirk</editor>
		<meeting><address><addrLine>San Diego, CA</addrLine></address></meeting>
		<imprint>
			<publisher>Academic Press</publisher>
			<date type="published" when="1992" />
			<biblScope unit="volume">111</biblScope>
			<biblScope unit="page" from="51" to="60" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Rotations for n-dimensional Tech</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">J</forename><surname>Hanson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Rep</title>
		<imprint>
			<biblScope unit="volume">406</biblScope>
			<date type="published" when="1994" />
		</imprint>
		<respStmt>
			<orgName>Indiana University graphics. Computer Science Department</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Interactive visualisation methods for four dimensions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">J</forename><surname>Hanson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">A</forename><surname>Cross</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Visualization &apos;93</title>
		<meeting>Visualization &apos;93</meeting>
		<imprint>
			<publisher>IEEE Computer Society Press</publisher>
			<date type="published" when="1993" />
			<biblScope unit="page" from="196" to="203" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Visualising the fourth dimension using geometry and light</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">J</forename><surname>Hanson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">A</forename><surname>Heng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Visualization &apos;91</title>
		<meeting>Visualization &apos;91</meeting>
		<imprint>
			<publisher>IEEE Computer Society Press</publisher>
			<date type="published" when="1991" />
			<biblScope unit="page" from="321" to="328" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Fourdimensional views of 3d scalar fields</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">J</forename><surname>Hanson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">A</forename><surname>Heng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Visualization &apos;92</title>
		<meeting>Visualization &apos;92</meeting>
		<imprint>
			<publisher>IEEE Computer Society Press</publisher>
			<date type="published" when="1992" />
			<biblScope unit="page" from="84" to="91" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Illuminating Computer Graphics and the fourth dimension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">J</forename><surname>Hanson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">A</forename><surname>Heng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Applications</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="54" to="62" />
			<date type="published" when="1992-07" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Visualisation flow with quaternion frames</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">J</forename><surname>Hanson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Visualization &apos;94</title>
		<meeting>Visualization &apos;94</meeting>
		<imprint>
			<publisher>IEEE Computer Society Press</publisher>
			<date type="published" when="1994" />
		</imprint>
	</monogr>
	<note>these Proceedings</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Interactive methods for visualizable geometry</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">J</forename><surname>Hanson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Munzner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">K</forename><surname>Francis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="73" to="83" />
			<date type="published" when="1994-07" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Geomview: An interactive geometry viewer. Notices of the Amer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Phillips</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Levy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Munzner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Math. Society</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="page" from="985" to="988" />
			<date type="published" when="1993" />
		</imprint>
	</monogr>
	<note>umn.edu, The Geometry Center, Minneapolis MN</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Rendering antialiased shadows with depth maps</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">T</forename><surname>Reeves</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">H</forename><surname>Salesin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">L</forename><surname>Cook</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Graphics (SIGGRAPH &apos;87</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">Proceedings</title>
		<editor>M. C. Stone</editor>
		<imprint>
			<date type="published" when="1987-07" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Fast shadows and lighting effects using texture mapping</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Segal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Korobkin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Van Widenfelt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Foran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">E</forename><surname>Haeberli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Graphics (SIGGRAPH &apos;92 Proceedings)</title>
		<editor>E. E. Catmull</editor>
		<imprint>
			<date type="published" when="1992-07" />
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="249" to="252" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Hidden volumes: The 4th dimension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">V</forename><surname>Steiner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">P</forename><surname>Burton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics World</title>
		<imprint>
			<biblScope unit="page" from="71" to="74" />
			<date type="published" when="1987-02" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
