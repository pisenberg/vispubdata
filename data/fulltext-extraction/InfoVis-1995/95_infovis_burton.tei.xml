<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/pisenberg/grobid/grobid-0.6.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Case Study An Empirical Investigation of Thumbnail Image Recognition</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">A</forename><surname>Burton</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">The University of Melbourne</orgName>
								<address>
									<postCode>3052</postCode>
									<settlement>Parkville</settlement>
									<region>Victoria</region>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">J</forename><surname>Johnston</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">The University of Melbourne</orgName>
								<address>
									<postCode>3052</postCode>
									<settlement>Parkville</settlement>
									<region>Victoria</region>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">A</forename><surname>Sonenberg</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">The University of Melbourne</orgName>
								<address>
									<postCode>3052</postCode>
									<settlement>Parkville</settlement>
									<region>Victoria</region>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Case Study An Empirical Investigation of Thumbnail Image Recognition</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2021-02-19T18:42+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
				<p>and noise and background texture smoothed [14]. The use of thumbnails (i.e. miniatures) in the user-interface of image databases allows searching and selection of images without the need for naming policies. Treating parent images prior to reduction with edge-detecting smoothing, lossy image compression, or static codebook compression resulted in thumbnails where the distortion caused by reduction was lessened. An experiment assessing these techniques found resulting thumbnails could be recognised more quickly and accurately than thumbnails of the same parent images that had been reduced without treatment. This pretreatment in thumbnail creation is offered as an improvement for browsing of image databases.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The increased popularity of image databases has encouraged user interface designers to use highly reduced images or thumbnails to facilitate the handling of images. Thumbnails are displayed in place of fullsized images to allow quick, preliminary visual identification.</p><p>Such reduced images require much less bandwidth for transmission; they are very common in World Wide Web pages. In databases, thumbnail use overcomes the difficult process of naming images, frees image identification from problems of language and literacy, and encourages browsing and manual organisation by related visual content.</p><p>Another approach is to use lossy image compression such as the Joint Photographic Experts Group (JPEG) method. The objective of modern lossy image compression techniques is to reduce the file size while maintaining important perceptual information. Extreme compression of an image will in effect simplify an image by removing many of the colours and textures. By taking the original image closer to an abstract iconographic form, it may be expected that such compression would suit thumbnail creation. In a perceptual study of icon designs for user interfaces, icons that were more abstract and visually simpler were identified as being easier to understand than complex images or complicated symbols <ref type="bibr" target="#b2">[3]</ref>. It is postulated that "simplified" thumbnail images will enhance a user's ability to browse, as perception has been shown to play an important role in browsing <ref type="bibr">[S]</ref>.</p><p>Because thumbnail images are such dramatic reductions of their parents (for example a 64x64 pixel thumbnail from a 1024x1024 parent) distortions, such as exaggerated textures and stepped edges, occur during the subsampling used to achieve reduction. This article investigates whether thumbnail creation could benefit from image-enhancement technology being applied before subsampling.</p><p>In the work described below, EDS, JPEG and a selforganising feature map (SOFM) were used to treat full-size images as an enhancement step before the usual subsampling that reduces their physical size. Forty-eight computer users viewed one hundred and sixty of these thumbnails in an experiment designed to explore the value of such thumbnail creation techniques in a context akin to browsing, where the viewer has some idea of what they are seeking. Section 2 presents the issues central to the selection of pretreatment processes. The design of the experiment and some key results are provided in Section 3. Section 4 includes our discussion and conclusions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Image Simplification</head><p>One approach is to apply edge-detecting smoothing (EDS) which enhances images by smoothing around, but not over, large changes in image intensity, resulting in visually simpler images with edges preserved In evaluating methods for removal of information from an image while retaining fast accurate recognition, one must consider: factors influencing object recognition; how to effect improvements on thumbnail images which might lead to better recognition performance; and the choice of measures to determine thumbnail quality.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Human object recognition</head><p>Object recognition relies on the eye successfully detecting certain parts of the object before it can be identified. Boundaries, the most important perceptual feature of an object, define for the eye where the object starts and ends and its position relative to other objects and the background <ref type="bibr" target="#b1">[2]</ref>. In images, boundaries are made up of edges, i.e. changes in local image intensity, which need careful attention <ref type="bibr">[7]</ref>.</p><p>A thumbnail image representing an object need only contain enough visual information to display the general concept of that object. It is argned that reducing the number of colours may clarify, rather than distort, representative images such as thumbnails. A biid miniature might contain the shape of a bird and a few colours, but not all the details of any specific bird. To effect a simplification that takes an object closer to its exemplifier, one might, for example, remove most of the texture of the bark from an image of a tree, but leave a few of the green colours of the leaves and the brown of the trunk. This abstracted image could be thought of as a more general exemplifier of the concept "tree".</p><p>The next section describes existing methods that not only deal with boundaries and reduce the number of image colours, but simplify texture as well.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Implementing</head><p>"simpiification"</p><p>Digital image reduction is achieved via subsampZ&amp;rg the image data -where a certain subset of pixels is chosen from the array of the source image. For example, selecting one pixel in every square block of four produces a reduced image that is one quarter the area of the original. There are many ways to subsample images <ref type="bibr">[9]</ref>, however, all such methods are p&amp;e1 neighborhood operations. That is, one pixel in the reduced image represents a block of pixels in the source image. Because of this, reduced images can be rather distorted, the most visible effect being blocking, where a straight line appears as a staircase <ref type="bibr">[7]</ref>. The effect may be compounded with further subsampling 191. It should be noted that such distortion is visible because the process of reduction removes information irrespective of perceptual features. In the sheep image in figure 2(e), blocking distortion results in the exaggeration of texture of the sheep's wool and the soil of the background, creating (relatively) large bright spots.</p><p>This paper proposes the use of compression or smoothing as a treatment for the parent image before the subsampling takes place. Standard smoothing alone will not overcome the limitations of neighborhood subsampling, but operations that re-order image blocks or smooth around image features can. For this study, JPEG, an edge-detecting smoother <ref type="bibr">[12]</ref>, and a self-organising feature map compressor <ref type="bibr">[15]</ref> were chosen.</p><p>Both subsampling and compression techniques treat an image as a series of blocks. This has its largest impact on continuous features of the image, such as the edges of objects. Of the distortion types identified in [7] that significantly affect edges, blocking was the most easily detected, and is also the main type of distortion caused by subsampling. It is expected that blocking can be reduced by exploiting the block-ordering of JPEG to minimise the differences between image blocks and hence preserve the consistency of image features such as edges. Compressed images are also visually simpler than their source images. In figure 1, the image butterfly has more than 23000 colours, its subsampled thumbnail (figure 2(i)) has 1002 colours, but the same image compressed with 3% quality in JPEG, then reduced has only 272 (figure 2(k)). The edge-detecting smoother was written by David <ref type="bibr">Mumford et al. [la]</ref>. In this approach, the image is smoothed with a kernel that changes shape according to edges in the image. The algorithm smoothes up to, but not across, edges. Its design is based on the idea that noise is less obvious to the eye in regions of the image with high detail. Strong textures such as wood or grass constitute high detail, and these are removed by this algorithm.</p><p>The self-organising feature map used for image simplification is a neural network program written by Lachlan Andrews at The University of Melbourne af-ter the work of <ref type="bibr">Zurada [15]</ref>. SOFM's undergo a type of "training" which involves a source image being divided into blocks, which are encoded by the nodes of the neural net. The training process parses image blocks into clusters of like blocks based on the meansquared error between each block and the exemplar (centre block) of the cluster. Compression is achieved by discarding most of the blocks in each cluster, and replacing them with pointers to the exemplar. The Andrews method was used as a static codebook compressor (as opposed to the dynamic JPEG). That is, the neural network was trained on an initial training image, then all subsequent images were compressed with the codebook derived from the initial training. This approach explores another possible simplification effect-replacing specific blocks from the source image with "simple" blocks from the training image.</p><p>The training image chosen for this method agglomerated some common features of general images. Typically, with decreasing image block size, most image features such as edges are only local gradations in colour intensity <ref type="bibr">[13]</ref>. Mohan et al. <ref type="bibr">[lo]</ref> have defined human visual invariants of perceived objects to consist only of curves. That is, the unique features of real world objects are encoded by humans as collections of curves, with right angles and flat surfaces being special cases. These assertions together suggest that a general training image should supply the Andrews neural net with curved graded edges. As Andrews algorithm operates in grey-scale on colour separations, a grey-scale image was chosen for training the neural net. A 256x256 image was created by applying a large Gaussian convolution (blurring) to an image of a Smith Calibration Chart, a calibration scale for television transmission.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Measuring image perceptual quaIity</head><p>Because the intended image treatment is effectively a distortion of the parent image, classical quantitative means of determining transmission fidelity, such as mean-squared error (MSE) and signal to noise ratio (SNR), are not appropriate. As our study was particularly concerned with ways to improve the perceptual quality of reduced images, it was apparent that ways to assess the benefit of simplification could not rely on other numeric methods -for two reasons.</p><p>The first is due to the enormous physical scale difference between a source image and its thumbnail. Even perceptual-numeric methods of comparison (such as perceptual MSE or log MSE) require a 1:l pixel correlation between source and target images, and hence are not appropriate. <ref type="bibr">Li</ref>   to the source scale then applying MSE tests, but only for moderate reduction rates of 50% <ref type="bibr">[9]</ref>. Thumbnails assessed in the present study were as small as 2% of the original image area. In real applications, this reduction could be even more dramatic, as many source images are larger than 256x256 pixels. The second reason for using non-numeric methods, was due to the large amount of image degradation. Source images are simplified then reduced producing image degradation at both steps. This high distortion, however favourable to the effect of simplification, rules out the use of qualitative distortion measures, such as Just Noticeable Distortion Threshold (JNDT) <ref type="bibr">[5]</ref>, and ratio and ordinal scales of quality <ref type="bibr">[S]</ref>. Both approaches involve users ranking several versions of the same image in order of clarity. Such ordering is not necessarily an indicator of the perceptual content of the image, but rather the aesthetic content.</p><p>We chose to assess the perceptual quality of the thumbnails by recording accuracy and time to recognition taken by subjects viewing thumbnails for very short durations. Detailed in the next section are the design and results of the experiment undertaken.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiment 3.1 Design</head><p>The thumbnail assessment was designed as a threshold experiment, where subjects attempted to identify an image displayed for only a few hundred milliseconds.</p><p>Response times and accuracy are an indicator of how quickly an image is recognised, not how pleasing it is to the eye. Bhatia et al. <ref type="bibr">[l]</ref> observed this to be a sound technique for assessing ability to identify images of human faces. Their experimental paradigm focussed on how dramatic image degradation affects human perception of faces. Subjects were presented with two images at the same time, and indicated which was a human face by pressing either a left or right button. Because our study was concerned with general images rather than faces, it was decided that subjects would view word-image pairs instead. We believe that this approach best simulated the browsing environment, as browsers have at least a vague idea of what they are searching for <ref type="bibr">[S]</ref>. The actual expectation of seeing objects has been shown to change the perceptual requirements for identification of an image. It is argued that pictorial perception is a state in which the viewer has some expectation of how an anticipated object will appear as a picture. In this way, one might expect a circular coin to appear as an ellipse. This is contrasted to the default state of viewing where the viewer just processes visual information without any expectation.</p><p>Words were displayed as black letters on a 128x128 pixel white background, to remove any residual image on the retina between pairs. The word stimulus was displayed for the same duration as the following image, between which there was a standard pause of 500 ms. For example, the text "light globe" was displayed in one trial for 125 ms, replaced by a blank screen for 500 ms, then one of the images from figure 2(a)-(d) was displayed for 125 ms. This constituted a "'correct" sequence. An "incorrect" sequence would be the same image preceded by the word "monkey". All word-image pairs were examined for semantic clarity in the "correct" pairings and semantic non-relatedness in the "incorrect" pairings.</p><p>Word-image pairs were displayed in random order to subjects. Subjects ranged in age from 16 to 45 years, were literate and spoke English. All stated that they had either sufficient or corrected vision. The subjects' exposure to computers ranged from data entry and word processing to postgraduate degrees in computing. Each subject saw 160 word-image pairs, 80 incorrect and 80 correct pairings, leading to over seven thousand data points. A variety of both sizes and times were used in displaying the images. The thumbnail sizes chosen were 24x24,32x32,48x48 and 64x64 pixels. Display times were 125, 250, 375 and 500ms. Subject recognition times and accuracy were expected to be better for thumbnails displayed for greater durations and at larger display sizes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Algorithm parameters</head><p>The control images were produced by straightforward subsampling of the parent image to the desired size.</p><p>JPEG was implemented as a pipe through cjpeg and djpeg with the "quality" parameter set to 2% for 24x24 thumbnails, 3% for the 32x32s, 4% for the 48x48s and 5% for the 64x64s.</p><p>The Mumford method has a number of parameters, such as the rate of blurring, the size of the gradient window (the area searched for features), and the standard deviation of image intensity. For this study, the same settings were used for all final thumbnail sizes as recommended in <ref type="bibr">[12]</ref>, except that a larger standard deviation was used (s=20, instead of s=lO) to force the algorithm to ignore very small points and single-pixel features.</p><p>The Andrews method was implemented with four weight sets generated for the four image sizes to exploit the varying code word sizes that were possible. The code word sizes were set to 4x4 pixels for the 64x64 pixel thumbnails, 5x5 for the 48x48s, 8x8 for the 32x32s and 10x10 for the 24x24s. All training was limited to the construction of a 256 codeword codebook from the image of the Smith Chart.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Apparatus</head><p>An SVGA monitor with a viewing hood and chinrest was used to display images to the subject. The subject-screen distance was set at 500mm. To record subjects' choices, a button box with buttons for "yes" and "no" answers was placed within reach of the subject. Below the computer screen, in line with each of the buttons were labels "YES" (left) and "NO" (right) as reminders. A PC compatible 80486-33 computer with 24bit graphic card was used to display wordimage pairs and record reaction time in milliseconds when either button was pressed.</p><p>In total, 160 images were obtained from the Visual Symbols CD-ROM [ll], scanned from National Geographic Magazine or photographed with a CCD camera. All images were cropped to 256x256 pixels and some noise removal was performed where necessary with Adobe Photoshop.</p><p>Of these images, 88 were "iconographic" imagestypically one object set on a white background, 72 were "natural" images of scenery and multiple objects.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Results</head><p>[ Methods ] Time I Significance 1 Forty-eight subjects (22 female, 26 male) were each allocated to one of four groups designated by the control and three methods. Seven thousand six hundred and eighty reaction times and responses were recorded. The average score over all trials was 82% correct, with the lowest at 79% and highest at 90% correct. A 3-level analysis of variance was performed for significance tests on display size, time and compression method. There was found to be a significant presentation order effect, with response times dropping slightly over the course of the trial. Response times are skewed slightly away from the mean toward lower response times. Mean reaction times for correct responses were significantly lower for the Mumford and JPEG methods than the control. Mean response times for the Andrews method, on the other hand, was found to be significantly higher than for the control. There was no significant difference between response times for the JPEG and Mumford methods (figures 3 and 4). All three methods had a higher proportion of correct responses than the control, with no difference between JPEG and Mumford (figures 5 and 6). Thumbnail display size was shown to significantly affect response times in all methods, with larger display sizes generally resulting in faster and more accurate responses (figures 7 and 8). Thumbnail display time had no significant effect on response time, but had a significant effect on total percentage of correct responses.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Methods</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Accuracy</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Discussion</head><p>An image-treatment scheme was used together with subsampling to improve the perceptual quality of thumbnail images. A perceptual threshold experiment showed the benefit of using an edge-detecting smoother or the lossy compression method, JPEG, to "simplify" images prior to spatial reduction to thumbnails. These results support the general claim in icon construction that simpler, more abstract icons are better understood <ref type="bibr" target="#b2">[3]</ref>. Both icons and thumbnails are rep resentative images and have their content abstracted from the instance of the objects they depict to the general classifier of that object. This simplification was achieved in the present work by removing many of the textures and colours in the parent image with a smoother, a lossy image encoder such as JPEG, or a neural network employed as a static codebook compressor.</p><p>Further, no significant difference was found between An unusual result is the poor performance of the overall performance on iconographic and naturalistic Andrews method subjects, whose reaction times were images. significantly worse than for the control data. This can As expected, the performance in terms of the subjects' response times and accuracy increased with increasing thumbnail size. JPEG and Mumford's EDS produced thumbnails that elicited significantly better perceptual performances than the control thumbnails.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>.19</head><p>Proceedings of the Proceedings on Information Visualization (INFOVIS '95) 0-8186-7201-3/95 $10.00 © 1995 IEEE possibly be attributed to the training image and/or the colour separation used. It was noticed by some subjects that these thumbnails often had unusual or unexpected colour noise. We believe that this was caused by the use of RGB separation. Subsequently, the effect has not been found with images separated to YUV. Contrary to our expectations, there was no significant difference in subject performance between images that were iconographic or naturalistic. This suggests that the simplification does not favour either of these image types.</p><p>Overall, this provides strong support for our assertions on image simplification for thumbnail creation. The absence of an effect of display duration on either accuracy or reaction time suggests that the display times may have been too long, or alternately masked by second-order effects. Further work should employ shorter exposure periods, closer to the actual perceptual threshold of recognition.</p><p>The optimum thumbnail size in terms of performance was the 64x64 pixel thumbnail, for which the fastest reaction times and best accuracy were observed. Where thumbnails are to be directly extracted from compressed parent images, e.g. with JPEG, decode time could be interleaved with transmission time. As images are decoded as a byte stream, the receiving end could commence display of the pixel information as it arrives. A production system based on the other methods would presumably require thumbnails to be stored along with parent images. Otherwise there is the processing overhead at run time when images are treated and then sub-sampled.</p><p>Another advantage of this scheme is that JPEG is currently public domain. Only minor adjustments are need to be made to its decoder to obtain a 118th sized image instead of the normal full sized image.</p><p>It is interesting to note that for thumbnails, at least, very coarse JPEG compression resulted in better recognition than for the control images. Although this result seems contrary to the basic intention of the JPEG "quality" setting, it highlights the relatively lower distortion caused by JPEG over subsampling alone. Because the process of reduction so distorts an image, the usual degradation caused by JPEG is relatively better for the image when both JPEG and subsampling are used together.</p><p>As an additional study in an effort to under-stand the relatively poor performance of the Andrews method, a set of training images for the SOFM was created that explored various types of circular gradations. It was found that supplying concentric circle images with differing radii gave results that appeared to be more perceptually appropriate. Further work should include an assessment not only of these training images, but also the use of other colour separationsthe more common YUV separation-as employed in JPEG. Preliminary work on the colour separations indicated that this was a contributing factor in the disappointing results from the self-organising feature map method. Lately, other lossy image compression schemes have attracted attention because of their speed and/or very high compression ratios attainable with low distortion. One of these is fractal compression. In this approach the compressed image is described not only in terms of copies of codewords, but transformations of these codewords that best match the original image features <ref type="bibr" target="#b3">[4]</ref>. Because the transforms used to describe the image are iteratively contractive, the fractal compressed image can be decoded to any spatial scale. Thus it should be simple to construct a thumbnail from an image compressed in this way, and the quality of the images should be similarly investigated.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Source image butterfly, 22586 (scaled) colours, 256x256 pixels.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>32x32 pixel thumbnails (enlarged), comparing control images with those produced as a result of the compression methods. (a),(e),(i) controls, (b),(f),(j) Andrews, (c),(g),(k) JPEG and (d),(h),(l) Mumford methods.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4 :</head><label>4</label><figDesc>Relative findings for mean response times, method vs control; difference between JPEG and Mumford methods. Key; (Y: Mean response time with respect to mean response time for control subjects.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 5 :</head><label>5</label><figDesc>Relative findings for accuracy method vs control; difference between JPEG and Mumford methods. Key; /3: Proportion of correct responses with respect to proportion of correct responses for control subjects.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 3 :</head><label>3</label><figDesc>Mean, median and mode response times for correct responses per method.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 7 :</head><label>7</label><figDesc>Mean response times for correct responses in milliseconds for the four display sizes in square pixels.</figDesc></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">Proceedings of the Proceedings on Information Visualization (INFOVIS '95) 0-8186-7201-3/95 $10.00 © 1995 IEEE</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>Thanks to: Dr. David Mumford (Harvard); Lach-Ian Andrews(Unimelb); Prof Micheal Barnsley (Oxford) for direction to David Mumford's non-linear filter; Sanjiv Bhatia (Seattle Uni.) for the main supporting work for this study; Dr. Tony Hayes, Terry Robinson and Mike Johnston (Psychology, Unimelb) for references, advice and software; and Mike Landy (NYU) for sending a stack of otherwise unavailable references from the other side of the planet.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Parameters for human face recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">K</forename><surname>Bhatia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Lakshminarayanau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Samal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">V</forename><surname>Welland</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1994" />
		</imprint>
		<respStmt>
			<orgName>University of Missouri -St. Louis</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">PhD thesis</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Parts of visual objects: an experimental test of the minima rule</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">L</forename><surname>Braunstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">D</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Saidpour</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Perception</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="817" to="826" />
			<date type="published" when="1989" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Using icons to find documents: simplicity is critical</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">D</forename><surname>Byrne</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Computer-Human Interaction</title>
		<meeting>the International Conference on Computer-Human Interaction</meeting>
		<imprint>
			<date type="published" when="1993" />
			<biblScope unit="page" from="446" to="453" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Image coding based on a fractal theory of iterated contractive image transformations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">E</forename><surname>Jacquin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE fiansactiona On Image Processing</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">51</biblScope>
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Perceptual coding of images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Jayant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Safranek</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1993" />
			<biblScope unit="volume">1913</biblScope>
			<biblScope unit="page" from="168" to="178" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Picture quality assessment: A comparison of ratio and ordinal scales</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">L</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">E</forename><surname>Marks</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SMPTE Journal</title>
		<imprint>
			<biblScope unit="page" from="1244" to="506" />
			<date type="published" when="1985-12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A distortion measure for image artifacts based on human visual sensitivity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">A</forename><surname>Karunasekera</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">G</forename><surname>Kingsbury</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Acoustics, Speech and Signal Processing</title>
		<meeting>the International Conference on Acoustics, Speech and Signal Processing</meeting>
		<imprint>
			<date type="published" when="1994" />
			<biblScope unit="page" from="117" to="121" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">A descriptive study of the functional components of browsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">H</forename><surname>Kwasnik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Engineering for HCI-IFIP WG 2.7 Wo&amp;ing Conference August 10-14</title>
		<meeting>Engineering for HCI-IFIP WG 2.7 Wo&amp;ing Conference August 10-14</meeting>
		<imprint>
			<date type="published" when="1992" />
			<biblScope unit="page" from="191" to="202" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">On edge preservation in multiresolution images. CVGIP: Graphical models and image processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1992" />
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="page" from="461" to="472" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Segmentation and description based on perceptual organisation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Mohan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Nevatia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Acoustics, Speech and Signal Processing</title>
		<meeting>the International Conference on Acoustics, Speech and Signal Processing</meeting>
		<imprint>
			<date type="published" when="1989" />
			<biblScope unit="page" from="333" to="341" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Clement</forename><surname>Mok</surname></persName>
		</author>
		<title level="m">Visual Symbols Sampler CD. Published by CMCD Inc CA USA</title>
		<imprint>
			<date type="published" when="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Filtering, segmentation and depth</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Mumford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Nitzberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Shiota</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1992" />
			<publisher>Springer Verlag</publisher>
			<biblScope unit="volume">662</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Local shading analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">P</forename><surname>Pentland</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1986" />
			<publisher>Albex Pub. Corp</publisher>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="40" to="77" />
			<pubPlace>Norwood, NJ</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Enhancing images with intensity-dependent spread functions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Reese</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Society for Optical Engineering-Human vision, visual processing, and digital display III</title>
		<editor>J. P. Allebach and B. E. Rogowita</editor>
		<meeting>the International Society for Optical Engineering-Human vision, visual processing, and digital display III</meeting>
		<imprint>
			<date type="published" when="1993" />
			<biblScope unit="volume">1666</biblScope>
			<biblScope unit="page" from="253" to="264" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Introduction to artijIcia1 neural systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Zurada</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1992" />
			<publisher>Westminster Inc</publisher>
			<pubPlace>St.Paul</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
