<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/pisenberg/grobid/grobid-0.6.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">VRMosaic: WEB Access from within a Virtual Environment</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><forename type="middle">G</forename><surname>Angus</surname></persName>
							<email>angus@atc.boeing.com</email>
							<affiliation key="aff0">
								<orgName type="institution">Boeing Information and Support Services</orgName>
								<address>
									<postBox>P.O. Box 24346</postBox>
									<postCode>7L-48, 98124-0346</postCode>
									<settlement>Seattle</settlement>
									<region>MS, WA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Henry</forename><forename type="middle">A</forename><surname>Sowizral</surname></persName>
							<email>sowizral@atc.boeing.com</email>
							<affiliation key="aff0">
								<orgName type="institution">Boeing Information and Support Services</orgName>
								<address>
									<postBox>P.O. Box 24346</postBox>
									<postCode>7L-48, 98124-0346</postCode>
									<settlement>Seattle</settlement>
									<region>MS, WA</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">VRMosaic: WEB Access from within a Virtual Environment</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2021-02-19T18:42+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Virtual Reality</term>
					<term>Mosaic</term>
					<term>User Interface Components</term>
				</keywords>
			</textClass>
			<abstract>
				<p>Virtual Reality can aid in designing large and eomplex structures such as ships, skyscrapers, factones, and aircraft. But before VR can realize this potential, we need to solve a number of problems. One of these problems: the user&apos;s need to see and interact with nongeometric information is examined in this paper. Our VR environment, RealEyes, can display largescale and detailed geometry at reasonable frame rates (&gt;&amp;OHz allowing a user to see and navigate within a f&apos; design rom a first person perspective. However, much (if not most) of the information associated with a particular design has no geometric representation. This includes information such as schematics of electrical, hydraulic, and plumbing systems; information describing materials or processes; and descriptive (textual) information of other types. Many researchers have developed a wealth of techniques for presenting such data on fiat-screen displays, but until recently, we have not had a means for naturally displaying such information within a VR environment. To make non-geometric data more available, we have implemented a version of Mosaic that functions within a fully immersive VR system. Our system, VR-Mosaic, allows a user of VR to access and display most of the data available using flat screen Mosaic. Moreover, we have made it extensible to allow for the seamless integration of specialized forms of data and interaction. This paper describes how we implemented VRMosaic using a VR-capable version of Interviews. It also describes some Mosaic-like uses of that system and some &quot;non-Mosaic-like&quot; extensions.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>For the foreseeable future, users of virtual reality systems will likely spend more of their time in the "real" environment than in a virtual environment. In the day-to-day "real" environment! users access much of their data using flat screen applications. These applications include tools such as authoring and analysis programs and even hyperlinked browsers.</p><p>We believe that users will find virtual environments more appealing if they can import their flat-screen ap-plications for use within the VR environment.</p><p>We also believe that the World Wide Web infrastructure, and supporting tools such as NCSA Mosaic <ref type="bibr">[l]</ref> and Netscape's Navigator, have become a de facto standard mechanism for both making data available and allowing for some interaction with that data.</p><p>These beliefs motivated us to develop a technolog for use in porting flat screen applications into VR [2 r . NCSA Mosaic provided us with a real application that would: 1) test our infrastructure effectively, and 2) provide a compelling application example.</p><p>We used our "2D interface in VR" infrastructure to port Mosaic into RealEyes, our VR system. Dubbed "VRMosaic" , this application allows users familiar with Mosaic to access the WEB from within an immersive VR environment.</p><p>However, VRMosaic is not just an embedded version of NCSA Mosaic, it also allows for VR specific features such as navigation within the virtual environment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Implementation</head><p>Our implementation has two major components; 1) the infrastructure we use to present a flat screen application within VR [2, 33, and 2) the modifications to NCSA Mosaic ' that enable it to operate within our infrastructure.</p><p>In part the raison d'etre for developing VRMosaic was to validate the infrastructure that we had developed earlier.</p><p>For this discussion the important features of that infrastructure are:</p><p>l We render 2D interface windows generated by flat screen applications as geometry.</p><p>l We can attach the application's "virtual" flat panel to any flat surface in the virtual environment or we can allow it to float freely in space. Currently, we place the 2D window on a computer generated virtual clipboard that is connected to a physical handle held in the immersed user's hand. Because the user holds the virtual clipboard in her hand she can increase the display's resolution by bringing the clipboard closer to her face, or she can remove the application from her field of view by putting the clipboard "away".</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Mosaic</head><p>Core 1 (HotLists) 1 (History)</p><formula xml:id="formula_0">Figure 1: VRMosaic Architecture l</formula><p>RealEyes supports real time collision detection. When the finger of the user's other hand "touches" the virtual clipboard, RealEyes generates a collision event that is translated into a mouse event, and delivered to the 2D application.</p><p>We have also experimented:</p><p>with a simulated pointer (moving only in the plane of the 2D application) controlled with a trackball mouse held in the user's other hand. l The physical handle for the virtual clipboard [2, 31 has three buttons on it. We use the buttons as modifier keys that allow the user to make a finer distinction between collision events than just "collide".</p><p>We modified the 3.1 version of the Interviews UI toolkit <ref type="bibr">[4]</ref>, to generate the 2D interface as geometry. This enables the importing of almost any Interviews application into our VR system with minimal or no changes to the application source code. This ability allowed us to rapidly incorporate and test new ideas and viewers within VR as soon as they were developed in the flat screen context. By way of example our Interviews based Mosaic application, and some of our special viewers, contain about 100K lines of C and C++. We modified only a few hundred lines to insert this version of Mosaic into our VR system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">What Did We Replace?</head><p>We reused the larger fraction of the NCSA Mosaic code. The shaded portions of <ref type="figure">Figure 1</ref> show those portions of NCSA Mosaic that we either extensively modified or replaced.</p><p>We replaced Mosaic's document viewing code with the Interviews document editor "do? <ref type="bibr">[5]</ref>. This use of "do? provided us with the added benefit that we can creating our documents with the flat screen Interviews version of Mosaic and archiving these documents in formats which are richer than HTML. The authoring capabilities of "dot" exist in VRMosaic also -we just don't know how to invoke them effectively from within VR.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="60">3 What Is Different</head><p>For VR?</p><p>Mosaic is a widely known and used application with a well earned reputation for ease of use. Because of this widespread acceptance, we wanted the VR version to behave as similarly as possible to the flat screen version.</p><p>Several aspects of VRMosaic's behavior does vary from that of the familiar flat-screen Mosaic. The fundamental differences are: l</p><p>We deal with external viewers differently and discuss this issue in detail in the following subsection.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>l</head><p>We replaced pointing with a mouse by the "virtual" touch of a finger or some other pointing device.</p><p>Effectively the flat screen cursor has been replaced by the tip of the user's finger. Because the user's finger is free to move around in the 3D world the projection of its coordinates onto the virtual flat screen would be meaningless most of the time. As a consequence we do not attempt to track (2D) motion events unless the user's finger is actually touching (colliding!) with the screen.</p><p>We introduced other differences. Two notable differences are: 1) We indentify hot links by using a different color for the text, and 2) The "backdoor" interface (see <ref type="figure">Figure 1</ref>) to Mosaic that allows other applications to control Mosaic was replaced. This was a natural consequence of fitting Mosaic into the RealEyes infrastructure.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">External and Inline Viewers</head><p>Normal Mosaic launches external viewers as completely independent processes that create their own windows. Mosaic does not control these separate windows, delegating that task to a window manager or some other system processes. External viewers are problematic in our VR system for two reasons:</p><p>1. Creating external-viewer windows within RealEyes presents one problem -where do you place the additional windows? We could potentially treat each viewers' window as if it were a separate "piece of paper" attached to a clipboard. How we finally resolve this issue will have a significant impact on the usability of VRMosaic.</p><p>2. To embed external viewers into the VR system requires they be built using our modified Inter-Views toolkit. This process is tedious but relatively straightforward.</p><p>Our experience porting existing viewers (such as mpeg-play) and Mosaic itself validates this opinion.</p><p>We avoided the problem of external viewer placement by making use of "Inline Viewers".</p><p>The following example presents a canonical "Inline Viewer". Assume the user invokes a specialized viewer (e.g., for hydraulic schematics) by following a link:</p><p>1. We dynamically load the specialized viewer's code into VRMosaic. This approach has a lot in common with that proposed for "HotJava" <ref type="bibr">[6]</ref>.</p><p>VRMosaic executes the viewer's code to process and display the data specified by the link.</p><p>VRMosaic's inserts the viewer's visual representation into the existing document view directly below the line containing the active link anchor.</p><p>VRMosaic reformats the visible page to accommodate the new "inline" viewer.</p><p>When finished with this viewer the user once again presses (touches!) the original hypertext anchor used to invoke the viewer. This dismisses the inline viewer and returns the enclosing document to its previous appearance. At first glance it appears that inline viewers will work well for objects that require a small amount of screen space and poorly for large views. This is a crucial concern because actual schematic data, as seen in airplane design does not squeeze into a small area without making it completely incomprehensible.</p><p>We expect this issue to be much less important for VR than for flat screen systems. After all, resizing the VRMosaic viewer is much easier than resizing a physical monitor -the limitation imposed by the size of flat screen monitor does not exist in the virtual environment! We can stretch the virtual screen as much as necessary to present a realistically large schematic. We can do this because the display is represented using geometry wherever possible. We are not dependent upon textures for the global structure of the flat screen interface (although we do use textures for local structure such as GIF images and individual text characters).</p><p>In our current implementation we provide four inline viewers: a simple schematic example; a form; a map of a virtual world (The interior of a Boeing 747); and, GIF images not originally displayed inline.</p><p>The following figures present several scenes of VR-Mosaic. Enlarged color presentations of these figures are included in the color section of these proceedings. In <ref type="figure">Figure 2</ref> we show the VRMosaic application as it appears in the VR system. The user's hand and finger are in the lower right quadrant of this figure.. <ref type="figure">Figure 3</ref> shows VRMosaic with the map of the Boeing 747 interior displayed. The indicator of the user's position and look direction is visible on the left hand side of the map. <ref type="figure">Figure 3</ref> shows VRMosaic with the 2D schematic viewer deployed. In <ref type="figure" target="#fig_1">Figure 5</ref> we show the same page of the document as was shown in <ref type="figure">Figure 2</ref> but with the GIF image viewer deployed.</p><p>Our mechanism for supporting inline viewers is very extensible.</p><p>New data formats can be devised, new viewers can be implemented as dynamically loadable modules, and new MIME types can be assigned to denote these formats and viewers, and VRMosaic can use these new capabilities without any modification.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Viewing 3D Geometry</head><p>For viewing 3D geometry on a flat screen, we have experimented both with using RealEyes as an external viewer (in the same fashion as WebOOGL  user follows a link that invokes a 3D viewer. We could simulate a flat screen 3D viewer in VR (subject to potential performance problems) but we believe that it would be the wrong thing to do. Why project a 3D scene onto a 2D screen in 3D when we could more easily pop up a miniature of the 3D scene? <ref type="bibr">[8]</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">VR Modes of Use</head><p>We assume that many of the things that immersed VR users will need to do are the same things they need to do in a flat screen environment. However, there may be some scenarios where the two environments differ. In particular when we compare the immersed use of VRMosaic with the flat screen use of Mosaic coupled to a 3D viewer, how do they differ?</p><p>We expect the following two types of interaction to be important within VR:</p><p>1. Select (touch) an object and have the data (page) relevant to that object brought up on the VRMosaic viewer.</p><p>2. Select (again by touch) a representation of an object in the VRMosaic viewer and either; have the associated geometry (if it is viewable somehow be highlighted, or, be transported to t h e location of that object.</p><p>We can implement the first scenario easily. When the user touches a virtual object the resultant collision event generates a "goto URL" event that RealEyes delivers to VRMosaic via the backdoor interface. This URL is then used by the normal Mosaic mechanism to access the document corresponding to that URL.</p><p>We have noticed that users tend to "bump into things" within VR. Thus we cannot allow every collision event to generate a "goto URL" message otherwise users would get very frustrated.</p><p>We eliminate these spurious "goto URL" messages by requiring the user to press one of the buttons on the clipboard's handle at the same time that she touches an object.</p><p>We have implemented one version of the second scenario. The user touches the 2D map, and the map viewer interprets this as a request to "teleport" the user to that location.</p><p>Both interaction scenarios require some mechanism for selecting a 3D object or location. How a user makes these selections differs between flat screen 3D viewing environment and the immersed VR environment. How we process such selections is common to both environments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Performance</head><p>Performance is an overriding concern in all VR systems. The RealEyes system can render realistically complex scenes at reasonable frame rates. For example, it can render a detailed CAD model of the interior of a Boeing 747 at an average frame rate of 20Hz. To be effective, interaction tools cannot degrade this performance too much. In the Boeing 747 model environment, with VRMosaic presenting a complex document, the performance degradation is somewhat less than ten percent 2. This result is very encouraging.</p><p>Our approach to embedding 2D applications in VR is to use geometry rather than texturing to represent the 2D application [2]. Our performance observations of VRMosaic's were based upon a first proof-ofconcept implementation.</p><p>Many opportunities remain for improving both the methods for generating this geometry as well as methods for rendering it efficiently. Hence we expect that the modest degradation of performance we observe is actually the worst case rather than "good luck".</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experience and Usability</head><p>VRMosaic was developed for research purposes and has not been used in production.</p><p>Nor have we attempted a formal evaluation of VRMosaic's usability or virtual 2D interfaces in general. However, based on our research experience we can make a few observations about our system as it exists.</p><p>Links are small targets on the flat screen and we are using a "blunt" pointer, the finger, to hit them. Often a user believes that he has invoked the link whereas in actuality he just missed it. This "feature" is really annoying.</p><p>VRMosaic has been a very useful stress test of our collision detection algorithms. We believe, we can modify and/or augment these algorithms to greatly reduce, or eliminate, this problem.</p><p>We have also implemented support for a trackball controlled mouse pointer where collision detection should prove inadequate. This pointing device is as accurate as a normal mouse pointer.</p><p>Less than perfect registration of the clipboard and fingers into the VR system can confuse the user. Currently we do not provide any form of tactile feedback so this has not been a major area for concern.</p><p>The current version of VRMosaic does not have either the the twirler or the status line active. This robs the user of the visual feedback of the "data is being retrieved" feedback that is familiar from flat screen Mosaic. This omission will be remedied in a future implementation.</p><p>'The demo document shown in <ref type="figure">Figure 2,Figure 3</ref>, and the video should not be construed as being a complex document There are other features of Mosaic that we have not implemented or do not take advantage of. We will discuss these issues in Section 7.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Related Work</head><p>There has been some work done in using Mosaic to launch a VR session, i.e., following a link invokes a virtual realit such a viewer 91. P viewer or a video, generated using Our work both incorporates this capability and is complementary to it.</p><p>The primary difference between our approach and others is that we deliver both the Mosaic interface inside an immersive VR system in addition to being able to use flat screen Mosaic to invoke a VR session. As an example we can launch RealEyes from a flat screen Mosaic session, don a head-mounted display, and enter the VR world with VRMosaic at our side. From within the VR system, we can use a map of that world (deployed as an inline viewer) to navigate the virtual environment. Touching the map in VR transports us between locations within the virtual world 3. This is our equivalent capability to invoking VR, or controlling a 3D flat screen viewer from Mosaic -except we are already in VR!</p><p>We are not the first to consider embedding flat screen applications, or hypertext applications, into a VR framework <ref type="bibr">[lo, 11, 12, 131</ref>; however, we believe that we are the first to deliver a working version of Mosaic into a VR system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Outstanding Issues</head><p>Most of the outstanding issues are not specific to VRMosaic but are generic to the incorporation of flat screen applications into VR.</p><p>Text input requires some thought; do we need extensive text input capabilities and if so how should this be implemented? We have limited text input capabilities with a crude keyboard (also implemented using 2D interface components).</p><p>It supports a "hunt and peck" approach to text input. As cumbersome as it is, this might be good enough for simple dialogs such as "Open URL" and other uses that only require simple forms. It is obviously not a complete solution to the problem of text input.</p><p>Most applications uses menus: how should we support menus? Our approach for embedding Interviews' applications within VR provides a complete implementation for menus in the two dimensional sense. The menu window is simply placed over the base application window as if it were a flat screen menu. This is enough to be functional, but is it the right thing to do?</p><p>Some applications provide alternate input modalities such as keyboard accelerators or sound: can we control VRMosaic with sound? We have not experimented in this area but we expect the answer to be affirmative. For links within text, a vocabulary of three words; "next", "previous", and "goto", would appear to be sufficient to provide limited control over VRMosaic.</p><p>3This capability is demonstrated in the video Many application use multiple windows. For VR-Mosaic, we temporarily finessed this issue by using inline viewers; but this is not a general solution. How are multiple windows other than the windows derived from menus or dialogs placed and managed? '1 Our VRMosaic app ication does dot implement all the functionality of the original Mosaic. However, these unimplemented functions are not vital to Mosaic's basic use and do not appear to present any specific difficulties beyond those mentioned above. One example of missing functionality is the ability to clone the current window. Implementing this capability is dependent upon how we address the issue of placing and managing the multiple windows issue.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Conclusion</head><p>We have implemented a version of Mosaic, called "VRMosaic" that is accessible and usable within RealEyes, our virtual reality system. With our implementation of VRMosaic we have demonstrated that:</p><p>All data accessible from Mosaic is also accessible from within a VR environment using a familiar interaction mechanism.</p><p>We can reuse significant amounts of existing flatscreen application code and make it available within an immersed VR environment. Such sharing reduces development cost. It also enables the rapid incorporation of changes made to the flatscreen version into the VR version.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>[7]), and with a simpler 3D viewer for inline use. An interesting question is, what should VRMosaic do if an immersed</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 5 :</head><label>5</label><figDesc>VRMosaic Home Page: GIF Viewer Deployed</figDesc></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">Proceedings of the Proceedings on Information Visualization (INFOVIS '95)</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">Proceedings of the Proceedings on Information Visualization (INFOVIS '95) 0-8186-7201-3/95 $10.00 Â© 1995 IEEE</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">NCSA Mosaic Technical Summary</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Andreessen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Embedding the 2D Interaction Metaphor in a Real 3D Virtual Environment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><forename type="middle">G</forename><surname>Angus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Henry</forename><forename type="middle">A</forename><surname>Sowizral</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SPIE</title>
		<imprint>
			<date type="published" when="1995-02" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Interacting with virtual environments using augmented virtual tools</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Henry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sowizral</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SPIE</title>
		<imprint>
			<date type="published" when="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Linton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Interviews Reference Manual</title>
		<imprint>
			<date type="published" when="1991-09" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Glyphs: Flyweight Objets for User Interfaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Paul</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><forename type="middle">A</forename><surname>Calder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Linton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">UIST</title>
		<imprint>
			<date type="published" when="1990" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Page</forename><surname>Hotjava Home</surname></persName>
		</author>
		<ptr target="http://java.sun.com/" />
		<imprint>
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Weboogl</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Randy Pausch Richard Stoakley</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><forename type="middle">J</forename><surname>Conway</surname></persName>
		</author>
		<ptr target="http://www.geom.umn.edu/docs/weboogl/weboogl.html" />
	</analytic>
	<monogr>
		<title level="m">Virtual Reality on a WIM: Interactive Worlds in Miniature. In CHI</title>
		<imprint>
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Open Virtual Reality Testbed Home Page</title>
		<ptr target="http://nemo.ncsl.nist.gov/sressler/OVRThome.html" />
		<imprint>
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">X11 in Virtual Environments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dykstra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Symp. on Research Frontiers in Virtual Reality</title>
		<imprint>
			<date type="published" when="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Using Virtual Menus in a Virtual Environment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Richard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><forename type="middle">R</forename><surname>Ellis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SPIE</title>
		<imprint>
			<date type="published" when="1992" />
			<biblScope unit="volume">1668</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Windows on the World: 2D Windows for 3D Augmented Reality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Feiner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">UIST</title>
		<imprint>
			<date type="published" when="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">A Toolset for Navigation in Virtual Environments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Darken</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sibert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">MST</title>
		<imprint>
			<date type="published" when="1993" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
