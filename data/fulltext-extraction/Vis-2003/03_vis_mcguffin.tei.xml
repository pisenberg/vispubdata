<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/pisenberg/grobid/grobid-0.6.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Using Deformations for Browsing Volumetric Data</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">J</forename><surname>Mcguffin</surname></persName>
							<email>mjmcguff@cs.toronto.edu</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liviu</forename><surname>Tancau</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ravin</forename><surname>Balakrishnan</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of Toronto</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<address>
									<settlement>Seattle, Washington</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Using Deformations for Browsing Volumetric Data</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2021-02-19T20:51+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>I.3.6 [Computer Graphics]: Methodology and Techniques-interaction techniques; H.5.2 [Information Interfaces and Presentation]: User Interfaces-interaction styles volumetric data</term>
					<term>volume data</term>
					<term>deformations</term>
					<term>browsing</term>
					<term>layers</term>
					<term>interaction techniques</term>
					<term>3D widgets</term>
				</keywords>
			</textClass>
			<abstract>
				<p>Many traditional techniques for &quot;looking inside&quot; volumetric data involve removing portions of the data, for example using various cutting tools, to reveal the interior. This allows the user to see hidden parts of the data, but has the disadvantage of removing potentially important surrounding contextual information. We explore an alternate strategy for browsing that uses deformations, where the user can cut into and open up, spread apart, or peel away parts of the volume in real time, making the interior visible while still retaining surrounding context. We consider various deformation strategies and present a number of interaction techniques based on different metaphors. Our designs pay special attention to the semantic layers that might compose a volume (e.g. the skin, muscle, bone in a scan of a human). Users can apply deformations to only selected layers, or apply a given deformation to a different degree to each layer, making browsing more flexible and facilitating the visualization of relationships between layers. Our interaction techniques are controlled with direct, &quot;in place&quot; manipulation, using pop-up menus and 3D widgets, to avoid the divided attention and awkwardness that would come with panels of traditional widgets. Initial user feedback indicates that our techniques are valuable, especially for showing portions of the data spatially situated in context with surrounding data.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Volumetric data can contain an enormous amount of densely packed data points, or voxels. Visualizing such data is challenging. While in the real world, we typically only perceive the surfaces of objects, computational visualization of volumetric data should ideally not have such a restriction. Where possible, we should be able to see the data throughout the volume simultaneously. However, this is especially difficult to achieve on a flat 2D display surface, where the user is, in some sense, forced to pick one point of view at a time, and where the number of voxels in the data can easily exceed the number of available pixels.</p><p>At least 3 general strategies exist for "peering inside" volumetric data:</p><p>1. Making some or all of the volume semi-transparent, allowing the user to see inside or through layers of data 2. Cutting away or removing portions of the data, to eliminate occlusion of inner regions 3. Spatially transforming or deforming the volume, to displace, project, break apart or separate outer portions and reveal inner portions Strategies 1 and 2 have been widely used in volume visualization systems. The control over transparency in strategy 1 is often achieved by adjusting a transfer function which maps voxel values to colour, opacity, and other properties used in rendering. Strategy 2 includes all the common boolean masks used to "carve away" parts of a volume, such as cutting planes, cutting boxes, cutting spheres, etc., and more generally includes any technique that selects and displays a subset of the data, such as showing the voxels bounded by an isosurface.</p><p>As pointed out by <ref type="bibr" target="#b5">Carpendale et al. [1997]</ref>, although transparency and removal of outer data both make inner data more visible, they also result in loss of context. This can make it difficult for users to form an integrated mental picture of the entire volume.</p><p>Strategy 3 is based on deforming the data in some manner. We use the term "deformation" somewhat loosely here, to refer not only to smooth, non-rigid transformations, but also piece-wise rigid transformations, discontinuous transformations, and combinations of these. Thus, strategy 3 includes techniques such as "exploded views" (often used in assembly manuals for mechanical devices) that simply translate parts away from each other, as well as more exotic transformations, which, apart from some recent research <ref type="bibr" target="#b6">[Carpendale et al. 1999;</ref><ref type="bibr" target="#b5">Carpendale et al. 1997;</ref><ref type="bibr" target="#b12">Kurzion and Yagel 1997;</ref><ref type="bibr" target="#b14">LaMar et al. 2001]</ref>, have remained largely unexplored for the purpose of browsing volumetric data.</p><p>Our goal in using deformations is to increase the visibility of the inner portions of the volume, without completely removing the surrounding data that normally occludes the inside. This is akin to focus+context schemes that allow a user to "zoom in" on data of interest, while using remaining screen space to show the surrounding context. Appropriately chosen deformations could, for example, split open a volume, showing displaced structures side-by-side, making it easy for the user to see how they connect, and allowing the user to mentally stitch them together into a whole. Deformations with familiar real-world analogues (e.g. cutting and peeling the skin off a fruit, or the layers off an onion) are also likely to be readily understood by users.</p><p>In this paper, we describe a prototype system that implements different metaphors for deformation-based browsing of volumetric data. Since strategy 3 above seems to be the least explored, we have focused our research mainly on it, without, for example, implementing support for transparency. However, there is no reason that the techniques in this paper could not be profitably extended to work in conjunction with strategies 1 and 2.</p><p>As will be seen, a key element of our approach is to support differential treatment of the various semantic layers in a data set.</p><p>By "semantic layers", we mean subsets of the data that are useful or meaningful to the user. These layers could be defined geometrically, for example as sections created with parallel planar cuts. More typically, layers would depend on the voxel data values, for example boundaries that are found during segmentation or isosurface extraction. In the context of medical visualization, there is at least anecdotal evidence that anatomists, for example, prefer to remove tissue layer by layer <ref type="bibr" target="#b10">[HÃ¶hne et al. 1992]</ref>, rather than making arbitrary planar cuts.</p><p>In the following sections, we review related work, identify design issues and tradeoffs to consider when choosing a deformation, describe our prototype system, report some initial user feedback, and offer conclusions and thoughts on future directions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Background</head><p>Many of our deformation techniques are inspired by surgical metaphors, where the user cuts into and opens up data. There have been attempts to create high-fidelity simulations of surgical procedures <ref type="bibr">[Pflesser et al. 1995, for example]</ref> for education, training, and rehearsal. These often involve the use of virtual reality, haptic feedback, and the simulation of the physical properties, such as elasticity and hardness, of the tissues being operated on. <ref type="bibr" target="#b3">Bruyns and Montgomery [2002]</ref> describe virtual tools that look and behave like scalpels, scissors, and forceps, allowing a 2-or 3-dimensional mesh to be cut and peeled open. While this approach has the advantage of easily understood, very literal, metaphors, it imposes an interaction style limited to what is possible in the physical world, without fully exploiting the additional capabilities of the computational medium. Our present work, in contrast, allows the user to explore and visualize volumetric data in ways that would be physically impossible. For example, in our system, users can peel away bone just as easily as skin, or change the location of an incision after the cut has been made by "swimming" the location of the cut through the volume. Because we are not concerned with simulating a physical process such as surgery, the user can browse data in a more light-weight and free-form style. We can also build intelligence into our browsing tools, so that they, for example, automatically detect boundaries between layers of data and do not cut across these boundaries.</p><p>Another difference between medical applications in general, and our work, is that medical specialists usually have a good idea of the underlying anatomy of a volume and thus can estimate where to look to find features of interest. In contrast, our techniques are designed to support general purpose exploratory browsing, and could be used with volumetric data of unknown content. This makes focus+context techniques all the more appropriate, since showing more of the data on the screen can make it easier and faster for users to find interesting data.</p><p>Looking beyond surgical applications, the deformation of volumetric data for general visualization has also been explored. For example, <ref type="bibr" target="#b13">Laidlaw [1995]</ref> segmented scans of a banana and a human hand, and created animations of their skin peeling off. Our work, however, uses deformations for real-time, interactive browsing. <ref type="bibr" target="#b12">Kurzion and Yagel [1997]</ref> describe a "discontinuous ray deflector" that gives the appearance of cutting into a volume and spreading open the voxels. This is similar to the "book" metaphor used by <ref type="bibr" target="#b6">Carpendale et al. [1999]</ref> where data are spread open like pages of a book. The same book metaphor has been used in traditional anatomical diagrams, where organs are shown cut in half and spread apart on consecutive pages of a book <ref type="bibr">[Agur and Lee 1999, for example pp. 622-623, 718, 719]</ref>. In the next section, we describe our own Hinge Spreader tool which also uses this metaphor. Our work, however, also extends the existing repertoire of deformations with other tools.</p><p>Focus+context techniques have also been proposed for volumetric data. <ref type="bibr" target="#b5">Carpendale et al. [1997]</ref> describe a visual access distor-tion technique that clears a path of visibility to a point of interest by pushing occluding data away from the line of sight. This "cleared path" remains on the line of sight as the scene is rotated, giving the appearance of a constantly shifting deformation. Thus, the rotation and deformation of the data are coupled. In our system, however, the user deforms the data in a desired way, and can then view the deformed data from any angle; i.e. rotation and deformation are separate actions. Although this introduces a risk that the user may have to rotate the scene more deliberately to gain a clear line of sight, the user also has more freedom and control to look at the deformed data in different ways.</p><p>LaMar et al. <ref type="bibr">[2001]</ref> describe a focus+context technique that magnifies a region inside a volume. This magnified region is visible to the user if the surrounding data is semi-transparent, or if a cutting plane is used to reveal the inside. As will be seen in the next section, our own Sphere Expander tool may seem similar in that it expands regions of data. However, the Sphere Expander pushes voxels away from a central point rather than magnifying data. Thus, it can be used not only to enlarge an existing cavity or hole in the data, but also to create a hole where none previously existed. Furthermore, our Sphere Expander can be applied differentially to the layers in a data set, yielding new interaction possibilities.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Approach</head><p>At the outset of our research, we imagined three main actions that might be supported by a volume browsing system: (i) selecting a region of the volume, (ii) changing the appearance (i.e. transfer function, including opacity) of the selected region, and (iii) spatially transforming or deforming the selected region. Together, these three actions could be composed to achieve the same effect of potentially any existing browsing technique. Although we have not yet implemented the full vision of these three composable actions, we have explored issues surrounding region selection and deformation of a region.</p><p>Users commonly select regions of a volume using geometric primitives, such as halfspaces (planes), spheres, or boxes. The deformation tools in our system similarly have simple geometric shapes, and are constrained to act only on voxels within these shapes. However, the features of interest within a volume may have irregular shapes. <ref type="bibr">HÃ¶hne et al.'s [1992]</ref> Anatomical Atlas supported "selective cutting" tools, that were sensitive to the layers in the data, and could be made to only act on certain layers. Thus, a cutting plane could be used to first remove skin, then bone, etc. The tools in our system are also sensitive to the layers in a data set, and can act differentially on them. Users can treat each layer separately, making selection of related voxels simpler and more implicit.</p><p>Unfortunately, the subsets of a volume data set are not always best thought of as layers -take for example the internal organs in a human body, or even vascular structures. Furthermore, volumetric data is often noisy and difficult to cleanly segment into distinctive subsets. Nevertheless, we chose to assume the existence of layers, and focus on how a user might manipulate such layers, because this inspired unique interaction techniques.</p><p>It is informative to compare the layers in a volumetric data set to a stack of cards or papers, and to consider the various ways in which these could be browsed. <ref type="bibr" target="#b15">Mander et al. [1992]</ref> describe different ways of browsing virtual piles of documents, emulating the effect of riffling or thumbing through a physical pile of paper. Beaudouin-Lafon <ref type="bibr">[2001]</ref> designed novel interaction techniques for overlapping windows. One of these allowed a user to peel back the corner of one or more windows, to take a peek at occluded windows. We identify a few other methods for manipulating layers in <ref type="figure" target="#fig_0">Figure 1</ref>.</p><p>In keeping with the layers-as-a-stack-of-cards analogy, there are three different points of view one might want of a given layer: first, a dorsal view of the back/top/outer surface of the layer; second, a ventral view of the underneath/bottom/inner surface of the layer (this is visible when the layer is flipped or turned over in some way); and third, a cross-sectional view, showing the thickness of the layer from the side, in which case it is often useful to see neighbouring layers stacked above and below the current layer.</p><p>Interactive browsing techniques that enable the various manipulations of <ref type="figure" target="#fig_0">Figure 1</ref>, and that also support dorsal, ventral, and crosssectional views -possibly simultaneously -of one or more layers, are more likely to afford the user with flexible and useful vantages. We have tried to incorporate these elements in our designs.</p><p>Figure 1 already hints at some interesting ways in which layers could be deformed for visualization. Other deformations of interest can be inspired by surgical metaphors, whereby data might be cut into and spread open in different ways. Two questions to consider when choosing a deformation are: should the deformation be rigid or non-rigid, and what kind of continuity conditions should be satisfied by the deformation?</p><p>Rigid deformations, i.e. rotating and/or translating out a piece of a layer, have the advantage of preserving lengths and volume, which could be important for performing measurements, or simply for assurance that the data being visualized has not been distorted. On the other hand, non-rigid deformations, such as curvilinear "peeling", encompass a much broader range of possibilities, and may be more realistic in medical contexts for giving an impression, if only approximate, of how tissue would deform if it were physically peeled.</p><p>Regarding continuity, one issue is how a deformed region of data should remain "connected", if at all, with the rest of the volume. We return to this question in section 4.6.</p><p>Finally, there is a risk that deformations might sometimes render data unrecognizable, or change the spatial arrangement of voxels in ways that are unfamiliar or difficult to understand. To counter this, we use smooth animations to show changes or transitions in the shape of the data. For example, if the user invokes a tool that peels back a layer, rather than suddenly "snapping" the layer into a fully peeled state, the layer is continuously peeled in real time, to show the user what is happening. The benefits of using animation for smooth transitions have been documented by others <ref type="bibr" target="#b1">[Bartram 1997;</ref><ref type="bibr" target="#b8">Grossman et al. 2001;</ref><ref type="bibr" target="#b18">Robertson et al. 1991;</ref><ref type="bibr" target="#b20">Woods 1984]</ref>. Essentially, users more easily maintain a mental model of the data across transitions, spending less time assimilating new states.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Prototype Implementation</head><p>Our prototype volume browser was implemented in C++ using OpenGL and GLUT, and runs under Linux and Microsoft Windows.</p><p>The individual voxels of the data are rendered as points (i.e. GL POINTS) whose size in screen space is chosen (via glPoint-Size()) to give the appearance that adjacent voxels are just touching. Although many techniques exist for high quality volume rendering, for example using hardware texturing and trilinearly interpolating voxel values, we chose to render individual points to keep our prototype simple and maximally flexible. Any deformation that remaps the voxel locations can be supported by our system, since each voxel is rendered on its own. This gives us the freedom to focus on exploring interaction techniques, rather than optimized, high quality rendering.</p><p>There is currently no support in our system for transparency. Although we suspect our techniques could be enhanced with good use of transparency, we wanted to first isolate and identify the qualities and issues that are unique to deformations.</p><p>On a 1.7 GHz laptop with an nVidia GeForce4 Go graphics card, 32 MB of video memory, and 512 megabytes of RAM, our system can render over 500000 voxels at 13 full screen frames per second, or over 4000000 voxels at 2 full screen frames per second. Since real time interaction is critical, our system downsamples large data sets and renders them at a lower resolution during interaction. Full resolution rendering is performed after the system has been idle for a given timeout (e.g. one second), or whenever the user explicitly requests it. An even better implementation might render different parts of the volume at different resolutions. For example, only the portion of the volume currently in the user's focus could be rendered at full resolution, without precluding real-time interaction.</p><p>To support arbitrary transformations of voxel positions, we explicitly store the position of each voxel, rather than storing a 3D bitmap. This is also more efficient for sparse data sets. Voxel positions are stored in an octree, where each node of the octree has a bounding box and a colour (black, white, or both). A dividing plane can be applied to the octree, and voxels can be quickly categorized by colouring them black or white, according to the side of the plane they lie on. Intersections or unions of halfspaces can be coloured by applying multiple planes. Operations on the octree, such as rendering voxels, deforming voxel positions, or copying voxels into a second octree, can be applied to the whole octree, or to only a subset of a given colour.</p><p>As a minor optimization, each voxel position is not stored in its own leaf node. Instead, each leaf node stores a small number (e.g. 8) of voxels in an array that can be traversed more quickly than an equivalent subtree with one voxel per leaf. Rather than storing a colour flag for each voxel, we save memory by storing black voxels in the first n elements of the array, and white voxels in the remaining elements. Changing the colour of a voxel requires swapping a single pair of elements and adjusting the value of n.</p><p>To support operations that treat each layer of data differently, each layer of voxels is stored in a separate octree. Thus, having N layers requires N octrees. This does not, however, imply using N times more memory than a single octree for all the layers would. Each layer typically exhibits some spatial coherence, and can be stored efficiently in an octree.</p><p>Each voxel has an associated normal, and is rendered with lighting to provide the user with shading cues. Voxels near a surface of the data set have a normal computed from their neighbourhoodthis computation is slow, but need only be done once, at load time. Voxels in the interior of the volume are initially not visible, and have a zero normal. However, deformations can cut or split open the volume and reveal these interior voxels. Thus, the normals of interior voxels are dynamically recomputed, in a fast but approximate way, based on the current deformation, and based on a guess of the orientation of the closest surface. Although the result is only approximate, the depth cues resulting from lighting the scene were found to be preferable over having no lighting.</p><p>The browsing tools in our system are positioned, oriented, and resized using 3D widgets <ref type="bibr" target="#b7">[Conner et al. 1992]</ref>, i.e. objects embedded in the 3D scene that can be clicked and dragged. 3D widgets are also used to control the parameters of the different deformations. Each draggable component of our 3D widgets is highlighted when the mouse cursor passes over them, to hint to the user which elements can be dragged. The shape of the widgets also suggests how to use them: arrow widgets are for translation or adjustment of a linear quantity such as the radius of a sphere; circle and arc widgets are for rotation or adjusting angles. In an early version of our prototype, we noticed perceptual problems with the visual design of our 3D widgets. We thus improved them by adding more depth cues <ref type="figure">(Figure 2</ref>). <ref type="figure">Figure 2</ref>: Example 3D widgets before and after design changes that enhanced depth cues. On the right, shading and variation in thickness are used, and intentionally exaggerated, to suggest depth. A thin halo of black pixels is also drawn to ensure contrast with whatever data may be in the background. The arrow widgets are used for translation along an axis, the circle widgets are used for rotation around an axis, and the 'L'-shaped widgets are for translation within a plane.</p><p>Another challenge encountered was that some deformations have many adjustable parameters, and if each of these is controlled with a separate 3D widget that is always visible, the screen becomes cluttered with widgets. We therefore identified situations where certain widgets were not likely to be used, and changed our prototype to only display a given 3D widget if the current state warrants it. For example, <ref type="figure" target="#fig_0">Figure 10</ref> shows a set of layers that are fanned open. Only after they are fanned open do additional 3D widgets appear, attached to each layer.</p><p>Figures 3 through 14 show our system browsing a scan of a human head that was pre-segmented into 5 layers. At any given time, only one browsing tool is active, which the user chooses from a popup radial menu <ref type="bibr" target="#b4">[Callahan et al. 1988]</ref> or Marking Menu <ref type="bibr" target="#b11">[Kurtenbach and Buxton 1993]</ref> (our menu is only one level deep, and so could be described as either a radial menu or Marking Menu). The active tool only affects the currently selected layers of the data, leaving unselected layers unchanged. When a layer is selected or unselected, an animation shows the layer's transition from one state to the other, for example, from a deformed state to an undeformed state.</p><p>Two mechanisms were implemented for selecting/unselecting layers. First, the selection state of each layer can be toggled individually through a set of hotkeys assigned to each layer -but these could just as easily be virtual check boxes in a menu. Second, there are two special items in the popup radial menu, the right and left items, that also control layer selection. These items can be invoked with quick flick gestures to the right or left, and have the effect of (a) selecting the outermost unselected layer, or (b) unselecting the outermost selected layer, respectively. Thus, the user can, for example, make 5 flick gestures to the right, causing each layer, from the outermost to the innermost, to be successively selected. If the currently selected tool peels layers away, this would have the effect of successively peeling each layer in the natural ordering.</p><p>To support this behaviour, the system needs some notion of which layers are inside or outside other layers. We manually assigned a global, fixed ordering, from outside to inside, of the layers in our head data set. This ordering is important not just for selection, but also for deformations that automatically deform layers to different degrees, such as the fanning out in <ref type="figure" target="#fig_0">Figure 10</ref>, where inner layers are rotated by a larger angle than outer layers. Although the fixed ordering is acceptable for our head data set, in general this would not be a viable solution. It is possible for the semantic layers in a data set to not have any single ordering from outside to inside. An improved prototype would compute a locally acceptable ordering of layers on the fly, given the current location and orientation of the deformation tool. Such an ordering might be computed by sampling the relevant data along parallel rays, and finding the "average ordering" of layers encountered along the rays.</p><p>No collision detection is performed between layers. Hence, layers can interpenetrate as they are manipulated or animated. However, as long as the user is manipulating a region of data where the the inside-to-outside ordering of layers is reasonably accurate, the interpenetration of layers is minimal.</p><p>The deformation tools in our system will be described in the following subsections. We also implemented more traditional cutting tools, specifically: a cutting plane, cutting hinge, cutting sphere, and cutting box. <ref type="figure" target="#fig_1">Figure 3</ref> shows two of these in action. Just as in <ref type="bibr">HÃ¶hne et al.'s Atlas [HÃ¶hne et al. 1992]</ref>, our cutting tools are sensitive to the layers in the data, and only remove voxels from the currently selected layers. Thus, they can be thought of as intelligent scalpels that cut no deeper than the innermost selected layer. An alternative way of thinking of these tools, especially the cutting box, is that they behave like 3D magic lenses <ref type="bibr" target="#b19">[Viega et al. 1996]</ref>, in that they make the currently selected layers fully transparent. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Hinge Spreader Tool</head><p>The Hinge Spreader <ref type="figure" target="#fig_2">(Figure 4</ref>) tool is a dihedral shaped object that pushes all the voxels between the hinge to either side. As mentioned in the Background section, this deformation can be used to create views of data that resemble anatomical dissections spread open like a "book" <ref type="bibr" target="#b0">[Agur and Lee 1999]</ref>.</p><p>3D widgets enable positioning and orientation of the tool, and also allow the angle of the hinge to be adjusted. Note that the cutting hinge in <ref type="figure" target="#fig_1">Figure 3 B</ref> has the same dihedral shape as the Hinge Spreader, but removes the voxels within the hinge, rather than displacing them.</p><p>As with all our tools, the Hinge Spreader only deforms voxels of selected layers. When layers are selected or unselected, an animation shows the voxels of that layer transition from a deformed state to a resting state, or vice versa. Interestingly, the Hinge Spreader can be used to create views that look like exploded diagrams <ref type="figure" target="#fig_3">(Figure 5)</ref> when applied to only a subset of the layers.  : The Hinge Spreader, acting only on layers outside the skull, has been pushed all the way through the head, and therefore spreads both halves of the skin off the skull. This provides a kind of "exploded view".</p><p>The hinge form factor of this tool, and of the cutting hinge, have interesting properties with respect to interface design. First, the positioning, orientation, and angle of a hinge could be easily controlled with a hand-held prop, much like <ref type="bibr">Hinckley et al.'s [1998]</ref> use of a cutting plane prop in their "doll's head" interface. Users have a strong mental model of the shape and function of a hinge, and would probably be able to use a hinge prop as successfully as Hinckley et al.'s cutting plane. In addition, the use of a hinge has certain advantages over a plane. A hinge opened up to 180 degrees reduces to a plane as a special case, and so is more general than a plane. Acute hinge angles allow for more context to be maintained close to a focal point. Finally, two-handed techniques are possible where a user holds two hinge props, and could make fast, compound cuts or spreads of the data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Sphere Expander Tool</head><p>The Sphere Expander tool ( <ref type="figure">Figure 6</ref>) pushes voxels away from a central point. The centre and radius of the sphere are controlled with 3D arrow widgets. Placing this tool outside and near the sur-face of a volume creates a dent in the volume, which in itself may not be useful for browsing. However, when placed inside a volume, the Sphere Expander can be used to inflate the voxels of the volume outward. Since we render each voxel as a point, sufficient inflation eventually makes the voxels sparse enough to see through -a kind of cheap transparency. The Sphere Expander can also be used to create a hole in a layer, by selecting only that layer, and by placing the centre of the sphere on the layer <ref type="figure">(Figure 6</ref>, right hand side). Interestingly, we did not initially know whether the Sphere Expander tool would turn out to be useful. After implementing it, however, we discovered that our layer-based architecture allowed for situations like that in <ref type="figure">Figure 6</ref>. <ref type="figure">Figure 6</ref>: The Sphere Expander. Left: voxels before and after deformation. All voxels contained in the solid sphere are pushed outside, compressing surrounding voxels that are within twice the sphere's radius. Right: the Sphere Expander, acting only on layers outside the skull, is centred on a point on the face above the nose. This opens up a hole in the face and lifts much of the skin off the skull, creating a kind of "window" through which we can see the skull and surrounding skin.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Box Spreader Tool</head><p>In the same spirit as the previous two deformation tools, the Box Spreader <ref type="figure">(Figure 7</ref>) pushes all voxels outside the shape of the tool, in this case a box. This tool was inspired by rib spreaders, instruments used in chest cavity surgery. The Box Spreader could be used to cut in to the virtual chest of a human data set, and spread open the outer layers of the chest, revealing internal organs. When the box is made wide enough, however, the deformation can eventually lift outer layers off a data set, as in <ref type="figure">Figure 7</ref>. <ref type="figure">Figure 7</ref>: The Box Spreader. Left: voxels before and after deformation. All voxels contained in the box are pushed sideways, compressing surrounding voxels that are within twice the box's width. Right: the Box Spreader, acting only on layers outside the skull, cuts the upper face in half and pushes each half off the skull.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Leafer Tool</head><p>The Leafer is shaped like a tray <ref type="figure" target="#fig_4">(Figure 8</ref>). The voxels above each half of the tray can be hinged open using 3D widgets. Selecting or unselecting layers causes them to smoothly rotate out or back in to place. A rapid succession of selections initiates an animation with layers temporarily spaced out, or "leaved" <ref type="figure">(Figure 9</ref>), affording the user a brief glimpse of the shape of individual layers. This style of browsing inspired the name of the Leafer tool. Note that once the animation is complete, however, all selected layers are rotated open with the same angle.</p><p>The three views of layers mentioned in Section 3 are all made available, simultaneously, with the Leafer. <ref type="figure" target="#fig_4">Figures 8</ref> shows the areas where layers are seen from a dorsal, ventral, or cross-sectional view. Selection or unselection of a single layer causes that layer to transition from one view to the other.</p><p>After hinging open the halves of the Leafer's tray, the layers that make up each half can be fanned open ( <ref type="figure" target="#fig_0">Figure 10</ref>). Fanned out layers can then be pulled out and/or flipped over, showing the components of the "dissected" voxels in context with the rest of the data set. Here, the depth of the tray has been set to zero, i.e. the axes of rotation coincide with the bottom edges of the tray, whereas in the figure on the left, the depth of the tray is non-zero. Three areas are labelled A, B, and C, to show how the Leafer provides crosssectional, ventral, and dorsal views of layers, simultaneously.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Peeler Tool</head><p>The Peeler, like the Leafer, consists of a tray that can be positioned and oriented to encompass a region of interest, and allows each half of the tray to be opened up. Unlike the Leafer, however, the Peeler uses a non-rigid, curvilinear deformation to open up the layers <ref type="figure" target="#fig_0">(Figures 11 and 12)</ref>.</p><p>As with the Leafer, selecting layers when the Peeler is active initiates an animated transition, during which the user can see in between the moving layers. However, unlike the Leafer, the Peeler also affords control over the degree of peeling for each layer independently, through arrow widgets attached to each layer. This gives the user an extra level of control, allowing the user to create spaces between the layers ( <ref type="figure" target="#fig_0">Figure 13</ref>) and keep them in this state for further browsing.</p><p>We also created a variation on the Peeler called the Radial Peeler <ref type="figure" target="#fig_0">(Figure 14)</ref>. Each voxel is peeled radially away from the axis of the tool, as if the tool were poking a hole in the volume and turning the layers inside out, somewhat like a flower opening up. <ref type="figure">Figure 9</ref>: When the user selects/unselects a layer, the Leafer animates the rotation of the layer open or back in to place. Here, the user has selected each layer in rapid succession, and the leafer is midway through an animation opening them up. In this way, the user can "leaf" through the layers, as if they were pages of a book.  <ref type="figure" target="#fig_0">Figure 12</ref> sketches the deformation for the left half of the regular Peeler, where voxels are peeled to the left. If this sketch is revolved around the vertical axis x = Ï, where Ï is the radius of the Radial Peeler, the resulting form corresponds to how the Radial Peeler deforms voxels: they are peeled away from the axis x = Ï.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6">Observations</head><p>Similarities can be seen between our set of tools and the layer browsing techniques of <ref type="figure" target="#fig_0">Figure 1</ref> An interesting tradeoff to consider is how much control to give the user. The Leafer allows users to "leaf" through layers <ref type="figure">(Figure 9</ref>) <ref type="figure" target="#fig_0">Figure 11</ref>: The Peeler. Left: voxels before and after deformation. Voxels in each half of a "tray" are peeled off the bottom of the tray. Right: the left half of the Peeler's tray is positioned to encompass the brow of the head, and this is peeled off. Notice that, above the Peeler, a thin section of the top of the head has been automatically translated upward and out of the way. using animation. This shows how animation is useful not only for helping the user maintain their mental model of the data as it deforms, but can be a browsing technique in itself. In contrast, the Peeler also allows the user to individually peel each layer by different amounts <ref type="figure" target="#fig_0">(Figure 13</ref>), giving the user more control, but this comes at the cost of more 3D widgets that clutter the screen. In general, we reduced clutter from widgets by only displaying them when the state of the deformation warrants their presence. However, additional techniques for reducing the number of widgets shown at any time, without limiting the user's power, would be valuable. One possibility is to develop a kind of popup 3D widget, that is shown only when requested by the user.</p><p>The Leafer and Peeler also shed some light on the question of how to connect a deformed set of voxels to the rest of the volume. The Leafer rigidly deforms voxels, creating a sharp "seam" at the axis of rotation. By hinging open the Leafer far enough, the user can easily see this seam where the voxels connect. However, such rigid rotation can lead to interpenetration of the deformed voxels and the rest of the volume. The Peeler, on the other hand, is more continuous in the sense that the deformed voxels connect smoothly with the rest of the volume. Interpenetration of voxels is less likely, and reduced in severity if it does occur. However, in the case of the Peeler, the seam along which peeled regions connect with the volume is much harder to see, since it is usually occluded by the peeled layers. It may or may not be important for the user to be able to see these seams or contact edges, however, it is a tradeoff to consider when choosing a deformation. <ref type="figure" target="#fig_0">Figure 13</ref>: A close up of the peeler in action. Here, each layer has been peeled to a different degree (using the small arrow widgets attached to each layer). The spacing between layers makes the interfaces between them visible. <ref type="figure" target="#fig_0">Figure 14</ref>: The Radial Peeler. Rather than peeling away two halves of a tray as in <ref type="figure" target="#fig_0">Figure 11</ref>, this tool peels away all the voxels in a cylinder. Two circles (only one of which is visible here) delimit the cylinder. Voxels are pulled through the top of the cylinder and then stretched away from the cylinder's centre. A hole along the cylinder's axis is thus opened up, allowing the user to peer inside.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Initial User Feedback</head><p>Informal trials with members of our lab led to some improvements in the visual design of the tools and 3D widgets. Furthermore, an earlier prototype of our system didn't employ animations, i.e. deformations would cause the volume to suddenly "snap" to a transformed state. During demonstrations of this prototype, people often had trouble understanding how exactly the tools were deforming voxels. Hence our incorporation of smoothly animated transitions.</p><p>More recently, we had a professional anatomist, having little experience using 3D software, try out our system during an informal, one hour session. The session consisted of a mix of designer-driven demonstration and user-driven exploration of the tools.</p><p>The anatomist found that the direct manipulation 3D widgets afforded flexible control and were easy to understand. Deforming or pulling out portions of the volume in context, with the rest of the volume still displayed, was found to be very valuable, for keeping track of "where you are in the whole". Animated transitions were also found to be valuable. The anatomist suggested that they would be very appropriate in educational settings, e.g. to show layers actually peeling back, rather than showing a sudden change of state.</p><p>The anatomist also suggested that, in some situations, after a layer has been peeled away, it may not be important to continue displaying the layer, since the user's goal may be to simply see the tissues revealed underneath. However, there were other situations were the anatomist found it important to keep all data present, for example when showing the two halves of the Hinge Spreader.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion and Future Directions</head><p>We have extended the range of deformations used for exploratory browsing of volumetric data. Our prototype demonstrates one way of integrating these deformations with differential treatment of the layers in a data set, as well as with 3D widgets and use of animation. We have identified various tradeoffs and design issues brought to light by our work. Initial user feedback suggests that our techniques are useful for helping a user understand and maintain context while exploring different regions of a data set.</p><p>One aspect not explored in our prototype is enhancing tool behaviour with transparency. For example, a hinge-shaped tool might make voxels enclosed by the hinge gradually more transparent as the hinge is opened up to a wider angle. The Leafer and Peeler tools could also make affected layers partially transparent, reducing occlusion of the immediate neighbourhood of these layers.</p><p>Our Leafer tool combined many techniques of <ref type="figure" target="#fig_0">Figure 1</ref> in one particular order, but many other orderings or combinations are possible. More flexible tools could be designed, perhaps allowing the user to "construct" their own custom deformations by combining more primitive operations or widgets.</p><p>Sophisticated deformations with many parameters can clutter the screen with 3D widgets. Ideally, a widget should only be visible when the user wants to interact with it. Popup 3D widgets, or use of gestures instead of widgets, could eliminate this problem.</p><p>Finally, the implementation of true volume rendering, possibly using graphics hardware <ref type="bibr" target="#b17">[Rezk-Salama et al. 2001]</ref>, could improve visual quality and frame rates.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Techniques for browsing the layers depicted in A. B: leafing through the layers like pages of a book. C: pulling out an individual layer. D: compressing upper layers to reveal lower layers. E: fanning layers open like a hand of cards or like a Chinese fan. F: peeling layers back. G: flipping layers over -here the user is flipping the 3rd layer from the left, and the other layers to the left are pushed along like dominoes. H: an exploded view of the layers.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 :</head><label>3</label><figDesc>Examples of cutting tools. A: a cutting sphere. B: a cutting hinge. Each cutting tool can be made to cut away all layers (as in A) or only a subset of layers (as in B).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4 :</head><label>4</label><figDesc>The Hinge Spreader. Left: a sketch of the voxels before and after deformation. Solid black lines show the hinge seen by the user. Dashed lines delimit the voxels affected by the deformation. Voxels are pushed away from the bisector of the hinge, compressing surrounding voxels that are within twice the hinge's angle. Right: a face is split down a line through the nose. Note that both halves of the nose are still present -no voxels have been removed or cut away, they have simply been pushed aside.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 5</head><label>5</label><figDesc>Figure 5: The Hinge Spreader, acting only on layers outside the skull, has been pushed all the way through the head, and therefore spreads both halves of the skin off the skull. This provides a kind of "exploded view".</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 8 :</head><label>8</label><figDesc>The Leafer. Left: voxels before and after deformation. Voxels above each half of a "tray" are (rigidly) rotated away from the centre of the tray. The top edges of the tray are the axes of rotation. Right: the Leafer is used to hinge open parts of a head.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 10 :</head><label>10</label><figDesc>A: The left half of the leafer hinges open the top of the head. B: The layers that make up the hinged-open region are fanned open. New widgets appear attached to each layer. C: A translation widget is used to pull out an individual layer. D: Rotation widgets are used to flip over layers.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head></head><label></label><figDesc>. The Hinge Spreader, Sphere Expander, and Box Spreader all non-rigidly compress and push layers to reveal data, just like Figure 1 D. The Leafer combines the techniques of Figure 1 B, E, C and G. And the Peeler, of course, corresponds to Figure 1 F. Our tools are not the only possible combinations of techniques, and extensions are possible (such as the exploded view of Figure 1 H), but we have demonstrated the applicability of layer-based techniques for browsing volumetric data.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 12 :</head><label>12</label><figDesc>The deformation on the left half of the Peeler's tray. Each point (x, y) â A is mapped to a new point (x , y ) â B. Let R be the radius at which length is preserved by the deformation. Points where x &lt; RÏ are mapped to the curved region via (x , y ) = (ây sin(x/R), y cos(x/R)). Other points are shifted and rotated with (x , y ) = (â(x â RÏ), ây).</figDesc></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Acknowledgements</head><p>Thanks to Karan Singh, Sheelagh Carpendale, Anne Agur, Gord Kurtenbach, Rafeef Abugharbieh, Nicholas Woolridge, Lloyd Burchill, Kim Chua, Joe Laszlo, Gonzalo Ramos, Glenn Tsang, and the members of the Interaction Research Group at the University of Toronto, for their help throughout this work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Supporting Material</head><p>Videos and additional screen shots of our prototype can be downloaded at http://www.dgp.toronto.edu/Ëmjmcguff/research/</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">M R</forename><surname>Agur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Lee</surname></persName>
		</author>
		<title level="m">Grant&apos;s Atlas of Anatomy</title>
		<imprint>
			<publisher>Williams and Wilkins</publisher>
			<date type="published" when="1999" />
		</imprint>
	</monogr>
	<note>10th ed. Lippincott</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Can motion increase user interface bandwidth?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bartram</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE Conference on Systems, Man and Cybernetics</title>
		<meeting>IEEE Conference on Systems, Man and Cybernetics</meeting>
		<imprint>
			<date type="published" when="1997" />
			<biblScope unit="page" from="1686" to="1692" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Novel interaction techniques for overlapping windows</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Beaudouin-Lafon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACM UIST Symposium on User Interface Software and Technology</title>
		<meeting>ACM UIST Symposium on User Interface Software and Technology</meeting>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="page" from="153" to="154" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Generalized interactions using virtual tools within the Spring framework: Cutting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">D</forename><surname>Bruyns</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Montgomery</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">MMVR Medicine Meets Virtual Reality</title>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">A comparative analysis of pie menu performance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Callahan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Hopkins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Weiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Shneiderman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACM CHI Conference on Human Factors in Computing Systems</title>
		<meeting>ACM CHI Conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<date type="published" when="1988" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Extending distortion viewing from 2D to 3D</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">S T</forename><surname>Carpendale</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">J</forename><surname>Cowperthwaite</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">D</forename><surname>Fracchia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer Graphics and Applications: Special Issue on Information Visualization</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="42" to="51" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">The Tardis: A visual exploration environment for landscape dynamics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">S T</forename><surname>Carpendale</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">J</forename><surname>Cowperthwaite</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Tigges</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Fall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">D</forename><surname>Fracchia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of SPIE Conference on Visual Data Exploration and Analysis VI</title>
		<meeting>SPIE Conference on Visual Data Exploration and Analysis VI</meeting>
		<imprint>
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Three-dimensional widgets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">B</forename><surname>Conner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">S</forename><surname>Snibbe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">P</forename><surname>Herndon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">C</forename><surname>Robbins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">C</forename><surname>Zeleznik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Van Dam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACM I3D Symposium on Interactive 3D Graphics</title>
		<meeting>ACM I3D Symposium on Interactive 3D Graphics</meeting>
		<imprint>
			<date type="published" when="1992" />
			<biblScope unit="page" from="183" to="188" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Interaction techniques for 3D modeling on large displays</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Grossman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Balakrishnan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Kurtenbach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Fitzmau-Rice</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Khan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Buxton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACM I3D Symposium on Interactive 3D Graphics</title>
		<meeting>ACM I3D Symposium on Interactive 3D Graphics</meeting>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="page" from="17" to="23" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Two-handed virtual manipulation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Hinckley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Pausch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Proffitt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">F</forename><surname>Kassell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM TOCHI Transactions on Computer-Human Interaction</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="260" to="302" />
			<date type="published" when="1998-09" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">A volume-based anatomical atlas</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">H</forename><surname>HÃ¶hne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bomans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Riemer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Schubert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Tiede</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Lierse</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer Graphics and Applications</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="72" to="78" />
			<date type="published" when="1992-07" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">The limits of expert performance using hierarchical marking menus</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Kurtenbach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Buxton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACM CHI Conference on Human Factors in Computing Systems</title>
		<meeting>ACM CHI Conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<date type="published" when="1993" />
			<biblScope unit="page" from="35" to="42" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Interactive space deformation with hardware-assisted rendering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Kurzion</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Yagel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer Graphics and Applications</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page">5</biblScope>
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Geometric Model Extraction from Magnetic Resonance Volume Data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">H</forename><surname>Laidlaw</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1995" />
		</imprint>
		<respStmt>
			<orgName>California Institute of Technology</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">PhD thesis</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">A magnification lens for interactive volume visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Lamar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Hamann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">I</forename><surname>Joy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Pacific Conference on Computer Graphics and Applications</title>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="page" from="223" to="232" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A &apos;pile&apos; metaphor for supporting casual organization of information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Mander</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Salomon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">Y</forename><surname>Wong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACM CHI Conference on Human Factors in Computing Systems</title>
		<meeting>ACM CHI Conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<date type="published" when="1992" />
			<biblScope unit="page" from="627" to="634" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Towards realistic visualization for surgery rehearsal</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Pflesser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Tiede</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">H</forename><surname>HÃ¶hne</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision, Virtual Reality and Robotics in Medicine, Proc. CVRMed &apos;95</title>
		<editor>N. Ayache</editor>
		<imprint>
			<date type="published" when="1995" />
			<biblScope unit="volume">905</biblScope>
			<biblScope unit="page" from="487" to="491" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Fast volumetric deformation on general purpose hardware</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Rezk-Salama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Scheuering</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Soza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Greiner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACM SIGGRAPH/Eurographics Workshop on Graphics Hardware</title>
		<meeting>ACM SIGGRAPH/Eurographics Workshop on Graphics Hardware</meeting>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="page" from="17" to="24" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Cone trees: Animated 3D visualizations of hierarchical information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">G</forename><surname>Robertson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">D</forename><surname>Mackinlay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">K</forename><surname>Card</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACM CHI Conference on Human Factors in Computing Systems</title>
		<meeting>ACM CHI Conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<date type="published" when="1991" />
			<biblScope unit="page" from="189" to="194" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">3D Magic Lenses</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Viega</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Conway</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Pausch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACM UIST Symposium on User Interface Software and Technology</title>
		<meeting>ACM UIST Symposium on User Interface Software and Technology</meeting>
		<imprint>
			<date type="published" when="1996" />
			<biblScope unit="page" from="51" to="58" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Visual momentum: a concept to improve the cognitive coupling of person and computer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">D</forename><surname>Woods</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Man-Machine Studies</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="229" to="244" />
			<date type="published" when="1984" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
