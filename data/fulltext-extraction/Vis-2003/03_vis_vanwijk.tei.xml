<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/pisenberg/grobid/grobid-0.6.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Image Based Flow Visualization for Curved Surfaces</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jarke</forename><forename type="middle">J</forename><surname>Van Wijk</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Technische Universiteit Eindhoven</orgName>
							</affiliation>
							<affiliation key="aff1">
								<address>
									<settlement>Seattle, Washington</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Image Based Flow Visualization for Curved Surfaces</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2021-02-19T20:52+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>I.3.3 [Computer Graphics]: Picture/Image Generation; I.6.6 [Simulation and Modelling]: Simulation Output Analysis Flow visualization</term>
					<term>texture mapping</term>
					<term>line integral convolution</term>
					<term>surface rendering</term>
				</keywords>
			</textClass>
			<abstract>
				<p>A new method for the synthesis of dense, vector-field aligned textures on curved surfaces is presented, called IBFVS. The method is based on Image Based Flow Visualization (IBFV). In IBFV twodimensional animated textures are produced by defining each frame of a flow animation as a blend between a warped version of the previous image and a number of filtered white noise images. We produce flow aligned texture on arbitrary three-dimensional triangle meshes in the same spirit as the original method: Texture is generated directly in image space. We show that IBFVS is efficient and effective. High performance (typically fifty frames or more per second) is achieved by exploiting graphics hardware. Also, IBFVS can easily be implemented and a variety of effects can be achieved. Applications are flow visualization and surface rendering. Specifically, we show how to visualize the wind field on the earth and how to render a dirty bronze bunny.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Visualization is indispensable to achieve insight in the large data sets produced by Computational Fluid Dynamics (CFD) simulations. Many methods for flow visualization have been developed, ranging from arrow plots and streamlines to dense texture methods. The latter class of methods produces clear visualizations, but its use in practice has been hampered by a poor efficiency.</p><p>Recently we have introduced Image Based Flow Visualization (IBFV) <ref type="bibr" target="#b27">[van Wijk 2002]</ref>. This method provides a single framework to generate a wide variety of visualizations of two-dimensional fluid flow, varying from moving particles, streamlines, moving textures, to topological images; it can handle arbitrary grids and unsteady flow; a high efficiency is achieved by exploiting graphics hardware; and finally the method is easy to implement.</p><p>In this article we present how IBFV can be extended to produce vector field aligned textures on curved surfaces. We named the new method IBFVS. The texture mapping is solved in line with the original method: Textures are directly generated in image space. As a * vanwijk@win.tue.nl, Department of Mathematics and Computer Science, Technische Universiteit Eindhoven, The Netherlands result, IBFVS inherits the advantages of IBFV.</p><p>The typical application domain is flow visualization, but vector field aligned textures can also be used for other purposes. We show how surface details can be depicted realistically by textures derived from and modulated by local surface curvature.</p><p>In the next section related work is discussed, in section 3 the new method is described and analyzed extensively. In section 4 applications are presented. The implementation and performance are described in section 5, in section 6 the results are discussed. Finally, conclusions are drawn.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related work</head><p>Many methods have been developed to visualize flow. Arrow plots are a standard method, but it is hard to reconstruct the flow from discrete samples. Streamlines and advected particles provide more insight, but also here important features of the flow can be overlooked.</p><p>The visualization community has spent much effort in the development of more effective techniques. Van Wijk <ref type="bibr" target="#b26">[van Wijk 1991]</ref> introduced the use of texture to visualize flow with Spot Noise. <ref type="bibr" target="#b0">Cabral and Leedom [Cabral and Leedom 1993]</ref> introduced Line Integral Convolution (LIC),which gives a much better image quality.</p><p>Many extensions to and variations on these original methods, and especially LIC, have been published. The main issue is improvement of the efficiency. Improved numerical schemes <ref type="bibr" target="#b24">[Stalling and Hege 1995]</ref>, the use of parallel processing <ref type="bibr" target="#b1">[de Leeuw and van Liere 1997;</ref><ref type="bibr" target="#b31">ZÃ¶ckler et al. 1997;</ref><ref type="bibr" target="#b22">Shen and Kao 1998</ref>], and the use of graphics hardware have been proposed <ref type="bibr" target="#b2">[de Leeuw and van Wijk 1995;</ref><ref type="bibr" target="#b18">Max and Becker 1995;</ref><ref type="bibr" target="#b7">Heidrich et al. 1999;</ref><ref type="bibr" target="#b11">Jobard et al. 2000;</ref><ref type="bibr" target="#b12">Jobard et al. 2001]</ref>. A recent method is Image Based Flow Visualization (IBFV) <ref type="bibr" target="#b27">[van Wijk 2002]</ref>. IBFV is based on warping and blending images, thereby modeling the transport, decay, and injection of ink. Moving textures are produced by insertion of scaled white noise patterns. Artifacts can be prevented by low-pass filtering the input textures in space and time. IBFV has many advantageous features, but is limited to two-dimensional fluid flow fields.</p><p>How can we use this method to visualize flow on curved surfaces? This would drastically enlarge the scope of the method. In many CFD simulations flow on curved surfaces, such as car and airplane bodies, plays an important role, and also, flow aligned textures can be used for other purposes, such as visualization of surface shape <ref type="bibr" target="#b6">[Gorla et al. 2002]</ref>.</p><p>The obvious approach is to use standard texture mapping: A texture is defined as a separate image in texture space, mapped on the surface in 3D in world space, and finally the surface is projected to image space. This route has been pursued for Spot Noise <ref type="bibr" target="#b26">[van Wijk 1991]</ref> as well as LIC <ref type="bibr" target="#b4">[Forssell and Cohen 1995]</ref>. Can we use this path also for IBFV? An exhaustive treatment of all methods for texture mapping and texture synthesis is far beyond the scope of this paper. Instead, we mention a few approaches as an illustration.</p><p>Both for Spot Noise and for LIC, textures are displayed on parametrized surfaces: The given parametrization of the surface is used to relate points on the surface with points on the texture. This requires that the distortion from parametric space to geometric space is taken into account to achieve a uniform density in geometric space. Also, CFD data often have a strongly varying density of the parametrization. Straightforward use of parameter space as texture space would then imply a waste of texture memory. Possibly a reparametrization can be used to compensate for this.</p><p>Finite element simulations often do not have a given parametrization, in which case some parametrization must be derived. This problem has been studied heavily, see for instance <ref type="bibr" target="#b3">[Floater 1997;</ref><ref type="bibr" target="#b23">Soler et al. 2002;</ref><ref type="bibr" target="#b15">Levy et al. 2002;</ref><ref type="bibr" target="#b6">Gorla et al. 2002]</ref>. Irregular topologies introduce complex problems, to find a parametrization without too much distortion requires much care. A next source of problems for the standard approach concerns the density of the texture. In an interactive session a user wants to switch from overviews to close-ups, for instance to study turbulent flow on different scales. One would prefer here that the density, i.e. the graininess of the texture is constant in image space: When zooming in, automatically a more fine grained texture in world space is shown. The standard approach leads here either to the use of very fine textures, or to ad hoc generation of texture, which requires again quite some effort to implement.</p><p>In summary, via the standard texture mapping approach "generation of texture on arbitrary surfaces in 3D should be feasible" for IBFV, quoting <ref type="bibr" target="#b27">[van Wijk 2002]</ref>, but it is not an easy route, and it is doubtful if a similar performance and generality as for the 2D case can be achieved.</p><p>We propose a different approach, based on the following observations. Firstly, the texture should be dense in image space. Secondly, the most efficient approach is to produce texture only where needed: in the image. Finally, image coherence can be exploited, also when the image shows flow on a curved surface. All these observations point in the same direction. Entirely in the spirit of the original method, let us produce the texture directly in image space, or, in other words, let texture space and image space coincide. In the next section we elaborate on this.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Method</head><p>In this section we start with a summary of 2D IBFV, with an emphasis on the synthesis of dense textures. More details are given in the original paper <ref type="bibr" target="#b27">[van Wijk 2002]</ref>. Next our new method IBFVS is described, followed by a discussion of various aspects in more detail.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">2D IBFV</head><p>Suppose we have an unsteady 2D vector field</p><formula xml:id="formula_0">v(x; t) â IR 2 v(x; t) = [v x (x, y; t), v y (x, y; t)],<label>(1)</label></formula><p>defined for t â¥ 0, and for x â , where â IR 2 . A pathline is the path of a particle, advected by the flow. This path is the solution of the differential equation</p><formula xml:id="formula_1">dp(t)/dt = v(p(t); t)<label>(2)</label></formula><p>for a given start position p(0). A first order Euler approximation gives</p><formula xml:id="formula_2">p k+1 = p k + v(p k ; t) t<label>(3)</label></formula><p>with k â I N and t = k t. In the remainder of the paper we use the frame number k to denote time. Consider a field F(x; k) that represents some property advected by the flow. Here F represents an image; hence F(x; k) is typically an RGB-triplet. The property is advected just like a particle, so a first order approximation of the transport of F, clamped to the image, can hence be given by:</p><formula xml:id="formula_3">F(p k+1 ; k + 1) = F(p k ; k) if p k â 0 otherwise<label>(4)</label></formula><p>Sooner or later most of F(x; k) will have disappeared, so at each time step a convex combination of F and another image G is taken:</p><formula xml:id="formula_4">F(p k ; k) = (1 â Î±)F(p kâ1 ; k â 1) + Î±G(p k ; k),<label>(5)</label></formula><p>where the points p k are again defined by equation <ref type="formula" target="#formula_2">3</ref>, and where Î± = Î±(x; k) â [0, 1] defines a blending mask. Equation <ref type="formula" target="#formula_4">5</ref>defines the image generation process. By varying G many different visualization methods can be emulated. To produce dense textures an interpolated grid with random values is used, i.e.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>G(x; k)</head><formula xml:id="formula_5">= i, j h(x/s â i)h(y/s â j)G i, j;k (6)</formula><p>where s is a parameter that controls the scale of the texture, where h(x) is a triangular pulse h(x) = max(0, 1 â |x|), and where the instantaneous grid values G i, j;k are defined by</p><formula xml:id="formula_6">G i, j;k = w(v g k + Ï i, j ).<label>(7)</label></formula><p>To each grid point a random phase Ï i, j is assigned; the value of G i, j;k cycles according to some periodic function w(t), for instance a square wave or a saw tooth; v g denotes the rate of image change.</p><p>The preceding equations can be mapped directly to standard graphics operations, leading to a fast algorithm. The flow field is covered with a rectangular or triangular mesh. First, a mesh is distorted and rendered, using the preceding image as a texture map; second, fresh ink is added by blending in a polygon, texture mapped with a scaled, interpolated, pre-computed pattern; third, the image is stored in texture memory for the next round; and finally additional graphics is drawn and the image is shown on the screen.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">IBFV for curved surfaces</head><p>We next consider the visualization of flow on surfaces. We use a dense triangular mesh as the geometric model for surfaces. Triangular meshes are a generic format, in the sense that almost all surface representations can be converted to triangular meshes, and by using more triangles an arbitrary level of detail can be achieved. Hence we claim that the following is applicable to arbitrary surfaces. Another advantage is obviously that triangles are a basic primitive for graphics hardware.</p><p>Suppose that for each vertex i its position</p><formula xml:id="formula_7">r i = (r i x , r iy , r iz ), a normal vector n i and a velocity vector v i = (v i x , v iy , v iz ) is given.</formula><p>Typically, this velocity is a sample of a 3D flow field. We assume that this velocity is confined to the surface (possibly by projection), i.e. v i â¢ n i = 0, later on we will discuss the more general case.</p><p>Given a composite modeling, viewing, and perspective transformation, the mesh can be projected on the screen. We denote this by</p><formula xml:id="formula_8">x = T (x), where x = (x s , y s )</formula><p>is a 2D point on the screen and where T denotes the transformation. We use apostrophes to denote projected quantities. The key to IBFVS is the simple observation that when some property is defined and advected on a surface in 3D space, equation 4 also holds after projection of this surface, i.e.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F(p k+1</head><formula xml:id="formula_9">; k + 1) = F(p k ; k) if p k â 0 otherwise (8)</formula><p>where is the projection of the surface on the image F, and where we assume that the path line p is visible. We use this to define a process for the synthesis of flow aligned texture on curved surfaces. Two further aspects must be taken care of. Firstly, fresh ink has to be added only to the projection of the surface and not to the background. Secondly, as an additional cue for the shape of the surface, a shaded image F s (., k) has to be blended in. We use a separate texture image F t (., k), which is defined on exactly the same space as the image F itself, i.e. texture space coincides with image space. The process can now be defined as follows:</p><formula xml:id="formula_10">F t (p k ; k) = (1 â Î³ (p k ))F t (p kâ1 ; k â 1) + Î³ (p k )G(p k ; k), (9) F(x ; k) = Î² F t (x ; k) + (1 â Î²)F s (x ; k),<label>(10)</label></formula><p>where Î² denotes the strength of the texture with respect to the shading, and where Î³ is introduced to constrain the fresh ink G to the projected surface. Its value is defined by</p><formula xml:id="formula_11">Î³ (x ) = Î±(x ) if x â 0 otherwise (11)</formula><p>where Î± has the same meaning as in standard IBFV.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Algorithm</head><p>Just as with standard IBFV, the preceding equations can be translated into a fast algorithm that exploits graphics hardware. The steps are as follows:</p><p>1. Initialize the texture image F t with a background color B;</p><p>2. Initialize the image F with B;</p><p>3. Calculate texture coordinates t i = (t i x , t iy ) for all vertices;</p><p>4. Render the mesh, texture mapped with F t , without shading;</p><p>5. Blend in fresh noise G;</p><p>6. Store the result in F t ;</p><p>7. Render the mesh shaded, and blend it with the image F;</p><p>8. Draw additional graphics;</p><p>9. Show the image on the screen;</p><p>10. Update state and go back to step 2. <ref type="figure">Figure 1</ref> shows the main steps (4-7) of the algorithm schematically. In the following we consider the algorithm in more detail.</p><p>Step 1 is an initialization. In step 2 the image F is cleared. This is different from standard IBFV, where the best results with respect to boundary artifacts if the image was not cleared in between. However, in this case the complete image was filled, whereas here the image is only partially filled with a projection of the mesh. Hence, we must clear the image per frame to prevent ghost images when for instance the view point is changed.</p><p>Step 3 and 4 are crucial. Here the pattern is advected in screen space by warping the texture. The texture coordinates are</p><formula xml:id="formula_12">t i = T (r i â v i t),<label>(12)</label></formula><p>in other words, as texture coordinates we use the projected position of the previous point on the path line through the vertex r i . These texture coordinates are computed in software by the central processor. As a result, the texture is slightly warped. Just like in standard IBFV, care has to be taken that the displacement in image space is below a threshold to prevent artifacts. In contrast to standard IBFV, here we prefer to warp the texture, instead of warping the mesh. We found that for time dependent flow a warped mesh gives a distracting motion of silhouette edges and extra textures on the surface. New texture coordinates only have to be calculated when the viewing transformation changes or when the flow field is dynamic, hence step 3 can be skipped for stationary flow, observed from a static viewpoint. In step 4 no shading is used, just the texture itself to maintain a high contrast and to prevent advection of shade. In step 5 fresh noise is blended in. For this the same approach as in standard IBFV is used. A sequence of small patterns is precomputed and stored in texture memory, next these patterns are texture mapped on a rectangle that covers the screen, using scaling and interpolation to prevent high frequencies. The texture has to be put only on the (projection of the) surface and not on the background. Fortunately, at this stage we already have exact information available which parts of the image are covered and which are not: in the z-buffer. We exploit this by rendering the rectangle at a great depth, just in front of the back clipping plane, and using a reversed z-buffer test: Only where the current z-value is smaller than the new value, the fresh noise has to be blended in. An alternative could be to use a stencil buffer for this purpose, but we have not explored this further.</p><p>In step 6 the intermediate image, which only contains the texture, is stored for step 4 in the next round. This intermediate image is visually not attractive, hence we enhance it in step 7 and 8. In step 7 the final image F is produced by blending in a shaded version F s of the mesh. Many options can be used for this. In the simplest way, just a shaded version is used, but also a texture mapped mesh can be used, with color representing some scalar value, or by showing for instance a geographical map. Also, Î² (the strength of the texture relative to shading) can be varied over the surface, for instance to show only texture where some variable is above a certain limit. In step 8 extra imagery can be superimposed: grids, vectors, markers, etc. When the image is ready, we show it on the screen in step 9. Finally, the state of the process is updated (user input is processed, possibly a new view transform is derived, new flow field data are obtained, etc.), and we can start with the next image.</p><p>This completes our algorithm. Can we get away with this simple approach? In the following subsections we consider various aspects in more detail. In general, the method described is indeed effective and efficient; only in section 3.7 we describe a problem where an additional measure is needed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Contrast</head><p>Lack of contrast was mentioned as a problem for standard IBFV. In 2D, the texture is all that can be seen, and hence a high contrast is attractive. For flow on surfaces, the situation is somewhat different. Here also the shape of the surface itself is important, depicted by shading, and a high contrast texture disturbs the spatial effect. We found that the use of Î² = 0.5 usually gives a good compromise between surface shade and flow texture, and that the decreased contrast is not a big problem here, a subtle texture can still be perceived well on the screen, especially when a moving texture is used. Subtle textures however sometimes do not survive printing or video recording, but here the contrast can be improved separately. For none of the images shown in this paper extra contrast enhancement was used.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Boundaries and silhouettes</head><p>Another problem of standard IBFV is boundary artifacts. In areas near the boundary, no texture is present to be advected, and the background color blends in. A partial solution for standard IBFV was to refrain from clearing the screen in between, such that areas outside the mesh are filled with texture, but, as mentioned earlier, here this solution cannot be used. Surprisingly however, we found for IBFV on surfaces these artifacts to be less disturbing, and even often absent. Several reasons can be given for this. Firstly, the contrast of the texture is less than with standard IBFV and hence also errors show up less clearly. Secondly, near boundaries and silhouette edges often high gradients occur in the shading, which draw the attention of the viewer to the geometry of the surface. Thirdly, when the flow is confined to the surface, and not normalized to a maximum displacement, a strong inflow perpendicular to the boundary does not occur. Finally, by default we use a grey background color instead of black. As this color is closer to the average value of the texture, artifacts are less visible.</p><p>As an example, figure 2 shows a landscape with the flow aligned downward with the gradient. The magnitude of the texture displacement is normalized in image space, and Î± = 0.1 and Î² = 0.4 were used. When red is used as background color, some inflow across the horizon is visible, when grey is used, no artifacts are visible.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.6">Non-uniform density</head><p>The density of the texture, i.e. the average frequency of strokes on the surface, is constant in image space. One can object that this is unnatural, a constant density in world space seems more appropriate. There are three situations where these artifacts occur. Firstly, the density does not depend on the orientation of the surface, i.e. when a surface is viewed under an oblique angle the density is the same as when viewed perpendicular. Secondly, the density is independent of the perspective, i.e. surfaces close to the viewer have the same density as surfaces far away. Consider now figure 3. Two textured cylinders are shown with flow along the axis, on the left with a uniform density in image space (produced by IBFVS), on the right with a uniform density in surface space (produced by texture mapping a noise pattern). The difference between these images is The third situation where this is visible, related to the previous one, is when we zoom in on an object. With image based texture, the density of the texture remains constant in image space. This is highly advantageous for visualization purposes, but unnatural from a physical point of view. In the real world texture is scaled when we approach an object, and other higher frequency details become visible. With computer generated imagery however, a uniform density in geometric space often leads to unnatural effects. When a textured surface is close to the viewer, the texture is scaled strongly and appears blurred, whereas surface parts far away have a high density and appear sharp. This is opposite to the natural cue that objects in front should appear sharp and with much detail, whereas objects far away should appear dimmed.</p><p>The image on the left does show another problem however (see insets). At the front edge of the cylinder, the interior texture makes a smooth transition to the exterior texture. In practice, this is a rare situation that only occurs when the flow in front of and behind a silhouette edge have the same direction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.7">Projected texture</head><p>Another way to describe our algorithm is that we project noise patterns onto the surface, which are advected by subsequent warping. When the view is changed or when the object is moved, the projection of the patterns is unaltered in viewing space, hence the viewer can observe that the texture patterns are not fixed to the surface, but are fixed in image space.</p><p>This effect is indeed visible. For moving textures the effect is less strong however, the viewer tends to follow the moving texture instead of fixing the view to a point in screen space. Furthermore, several measures can be taken to decrease this effect. Consider an interactive setting, where the user can drag, rotate, and scale the object by dragging the mouse.</p><p>First, when the user changes the view, the projection of the texture can be changed as well. We provide the option that both F t and G are translated according to the motion of the mouse pointer. This improves the perceived imagery strongly for translation, reasonably for rotation, but not for scaling. Secondly, the update of the texture image can be stopped. If we skip step 3 (calculation of new texture coordinates) and step 6 (saving the new texture), the algorithm reduces to standard texture mapping, using the last generated noise pattern as a fixed texture map. When the user stops the manipulation, step 3 and 6 are enabled again, and the last pattern is used as a start for a new animation. This method works well for scaling and dragging, but is less effective for rotation. When the object is rotated, new parts of the object appear for which not yet a sensible texture has been generated.</p><p>This last method, freezing the texture, can also be used for other purposes, for instance to produce texture maps that have to be processed in a standard way. The method gives both the texture map and the texture coordinates, but is limited to objects where the complete surface is visible in one view and where the variation in depth is not too strong. Later on we will give an example.</p><p>When the view is changed, it takes some time before the image or animation stabilizes again. For animations (v g = 0) this happens faster than for still images (v g = 0). Consider the worst case, a still image, where the intensity of a pixel has to change from 0 to 1 (the maximum value of G i, j ). The change in intensity for the N th step is than equal to Î±(1 â Î±) N . Hence, N = log( /Î±)/ log(1 â Î±). For = 0.01 and Î± = 0.1 we find N â 22, hence with a frame rate of 50 frames per second, the image stabilizes after about half a second.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.8">Non surface-aligned flow</head><p>We so far assumed that the flow was aligned with the surface. How to deal with velocities that have a component perpendicular to the surface? A simple approach is just to use exactly the same formula (eq. 12) for this. <ref type="figure">Figure 4</ref> shows the result. Both images depict a torus in a vertical flow field, on the left the velocity is projected on the surface, whereas on the right it is not. Which image is correct?</p><p>The image on the left shows the surface shape clearly, at the top of the torus the separation line is clearly visible. On the other hand, the image on the right does show the flow field better: The message that this is a simple and uniform flow field is conveyed effectively. We can consider this visualization as the result of using a wire mesh as a flow probe, where the mesh contains a lot of little hairs that all are aligned with the 3D flow. In summary, non surface-aligned flow can also be visualized, but its interpretation is more difficult than for surface-aligned flow.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.9">Texture interpolation</head><p>A final problem to be mentioned concerns texture interpolation. The scan conversion of a triangle involves interpolation of edges, colors, and also texture coordinates. Nowadays hardware offers by default the option to interpolate texture coordinates perspectively correct. Unfortunately, this causes artifacts here. The texture synthesis process works completely in 2D, assuming a linear interpolation of texture coordinates. One solution could be simply to turn off perspectively correct texture interpolation, but this hint is ignored by the drivers and hardware we used. Artifacts become visible when large triangles are rendered in perspective with a high variation in depth. Solutions are therefore to use only small triangles, and/or to switch to isometric projection when close-up views are made. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Applications</head><p>Now that we can produce texture aligned with vector fields on curved surfaces, we consider various applications. We start with flow visualization, the original impetus for this work, followed by a discussion how the perception of surfaces can be enhanced by adding texture. More examples, animations, and demo software can be found on the web <ref type="bibr" target="#b28">[van Wijk 2003]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Flow visualization</head><p>For testing purposes we have implemented potential flow fields, in line with <ref type="bibr" target="#b30">[Wejchert and Haumann 1991]</ref>. A flow field is defined by the superposition of a linear flow field and a number of fields defined by flow elements. A flow element is defined as a line. The user can interactively position these flow elements, and specify how much rotational, tangential, and repelling or attracting flow is desired. Meanwhile, the resulting flow on the surface is shown in real time. <ref type="figure" target="#fig_3">Figure 5</ref> shows an example using the Stanford bunny. The flow field is defined by two sources, a repelling and rotating line source through the eyes and an attracting and rotating line source through the legs. When we zoom in, automatically a more detailed texture is produced. Another application is shown in <ref type="figure">figure 6</ref>. Here the average wind stress field on the earth is shown for January <ref type="bibr" target="#b8">[Hellerman and Rosenstein 1983]</ref>. In the left image a map of the world is shown, and the strength of the texture is modulated with the magnitude of the stress; in the right image the magnitude is visualized via color. Various features, especially vortices, show up clearly. The user can rotate and zoom in on the globe, and view the variation of the flow over the year. Features like the monsoon in India and the circulation around Antarctica are clearly visible.</p><p>An example of topological decomposition is shown in <ref type="figure">figure 7</ref>. The geometry is a height field, defined as a B-spline surface; and a flow field aligned downward with the gradient is defined. If we <ref type="figure">Figure 6</ref>: Average wind stress in January <ref type="figure">Figure 7</ref>: Topological decomposition view the surface from top, set Î± = 0, and initialize F t with random colors, the colors are transported downhill from local maxima. After about 30-50 steps, each pixel is assigned a color that is the same as the local maximum that is reached by walking upwards as steeply as possible. Finally, we can lock the generated texture (see section 3.7) and view the surface from oblique angles. The boundaries between the areas are so-called topographic valley lines <ref type="bibr" target="#b20">[Peikert and Roth 1999]</ref>. If the direction of the flow is reversed, ridge lines are produced, the use of other flow fields can be used to produce for instance Voronoi diagrams.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Surface visualization</head><p>The rendering of surfaces can be considered as a visualization problem. How can we add cues such that we can easily understand a shape and its features? This requires first that we must be able to detect the structure and features on the surface. This topic has been studied intensively in differential geometry. We give a very brief summary. A local first-order approximation of a surface is a tangent plane. A local second-order approximation is given by two orthogonal principal directions. Along these principal directions the curvature (1/radius) of a line on the surface through the tangent point is either minimal or maximal.</p><p>Interrante and her co-workers have presented a variety of methods to visualize surface shape based on differential geometry. They have shown how valleys and ridges on the surface can be detected and emphasized by lines <ref type="bibr" target="#b9">[Interrante et al. 1995;</ref><ref type="bibr" target="#b10">Interrante 1997]</ref>, and they have studied how texture, aligned with principal directions, can aid in understanding surface shape <ref type="bibr" target="#b6">[Gorla et al. 2002]</ref>. Another approach to visualize surface features is to drop particles on the surface and let them move according to a principal direction <ref type="bibr" target="#b17">[Lum et al. 2002]</ref>.</p><p>Inspired by these results, we have studied if IBFVS can be used for this purpose as well. Moving particles can be generated by using a special setting of the input noise G. <ref type="figure" target="#fig_4">Figure 8a</ref> shows a result. We used a sequence of short spikes for w <ref type="bibr">(t)</ref>, such that only a small fraction of the grid values G i, j;k is bright white. Furthermore, to achieve a higher brightness we added the texture here instead of blending it. The flow field is aligned with the direction of Îº min .</p><p>A more standard setting of G produces a dense texture, aligned with the principal directions ( <ref type="figure" target="#fig_4">fig. 8b)</ref>. One problem here is that differential geometry only gives an orientation, and not a signed direction for the principal directions. We have experimented with several solutions for this. The best results were obtained by aligning the principal directions with a user defined vector (typically a coordinate axis), followed by a rotation over 90 degrees around the normal. However, a globally optimal perfect solution can by definition not be achieved, and for instance on the breast a separation line can be seen.</p><p>For smooth surfaces such as the torso, good results can be ob- tained, for more irregular surfaces the results are somewhat disappointing. However, an improved result is obtained when we modulate the strength Î² of the texture with respect to the shading by Îº max , and use Îº max also to modulate the color of the surface. In other words, we use a combination of two methods of Interrante et al. The images give the impression that a dirty surface has superficially been cleaned ( <ref type="figure" target="#fig_5">fig. 9a and b</ref>). It can be shown that this effect is similar to local accessibility shading <ref type="bibr" target="#b19">[Miller 1994</ref>]. An effect of eroded stone is obtained when parametrization with respect to Îº min is used. Note that the input consists only of a triangular mesh: All detail is generated automatically. We found that default settings for colors and bounds for the parametrization can be defined that give good results for a variety of geometries.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Implementation</head><p>We have implemented IBFVS in an interactive visualization system. The application was implemented in Delphi 5, using ObjectPascal. It consists of about 5,000 lines of code. All images shown are produced with this system. As input geometry we use triangular meshes: coordinates of vertices and the vertex numbers of triangles. Furthermore, time-dependent flow fields can be read in. The geometry is processed in various ways after it has been read in. Normals, curvatures and principal directions are calculated using the recommendations and method of Goldfeather <ref type="bibr" target="#b5">[Goldfeather 2001]</ref>. Optionally, the mesh can be refined by application of Loop subdivision <ref type="bibr" target="#b16">[Loop 1987]</ref>. For coarse meshes such as the cow (5800 triangles) or the torso (1400 triangles) this considerably improves the result. Furthermore, triangle strips are constructed to speed up the rendering. For meshes in the order of 100K triangles this preprocessing typically takes a few seconds.</p><p>A variety of parameters can be adjusted: colors, scales, mappings, etc. to achieve different effects. We found tuning the visualization to be relatively easy. All parameters have a natural meaning, and the effect of changes is visible immediately. Furthermore, for standard cases, such as shown in figure 9, we have defined default settings. A wide range of geometries can be visualized in such styles with a single button press. To access the graphics hardware we used OpenGL1.1. No extensions are needed. We optimized the rendering for the static case, with a constant flow field and constant projection. All rendering bulk data can be put in display lists and named textures, and hence generation of animations can be done at high speed. <ref type="table" target="#tab_0">Table 1</ref> shows performance results for the static case, and between parentheses for the dynamic case (rotating object). We varied image resolution (256 2 , 512 2 , 1024 2 ) and the resolution of the mesh (5.8K, 23.2K, and 92.8K triangles). As geometric model we used the cow, and for the rendering the base case, as shown in <ref type="figure">fig. 1</ref>. More complex cases, involving for instance modulation of Î², are in the order of 5-25 % slower. These results are representative for all images shown  Due to faster hardware and possibly a more efficient implementation, the results outperform those of the original method. Highresolution imagery is produced in real-time. For the static case the frame rate depends on the resolution of the image and the number of triangles used. The dynamic case is much slower and dominated by the number of triangles. Here per frame texture coordinates have to be recalculated and resent per frame. We found that resending vertex information took most (about 90 %) of the extra overhead. A much higher performance can possibly be achieved by delegating the texture coordinate calculation to the graphics hardware also, possibly at the cost of a decrease in portability.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Discussion</head><p>We discuss various aspects of IBFVS: Efficiency, versatility, simplicity, and novelty.</p><p>IBFVS is about two to three orders of magnitude faster than other methods for the synthesis of dense texture animations of flow on curved surfaces. Our method is the first to exploit graphics hardware for this. Similarly to IBFV, efficiency comes also from three other effects: few steps in the generation of images, exploitation of frame to frame coherence, and sampling of the flow field on the original mesh.</p><p>Concerning versatility, we can produce visualizations for arbitrary, time-dependent flow fields defined on arbitrary meshes. Similarly to the original method, various kinds of texture can be produced by variation of the scale s of the texture, the type of time profile w(t), the image variation speed v g and the blending factor Î±. By varying the strength of the texture Î² as a function of properties of the surface, a variety of special effects can be achieved.</p><p>Also with respect to simplicity IBFVS inherits all properties from standard IBFV. The method is easy to understand and implement, and does not depend on peculiar features of the graphics hardware.</p><p>Concerning the contribution of this work, we have introduced a novel approach to generate dense textures on curved surfaces. By generating these directly in image space, many problems of the standard approach for texture mapping (see section 2) are circumvented. Parametrization is reduced to a simple problem, and, very useful for visualization purposes, a uniform density in image space is achieved.</p><p>Dense flow aligned textures on surfaces, generated at high speed, are useful for many application areas. In the application sections we have not only presented examples for flow visualization, but also showed how the method can be used to depict surface detail and to generate artificial drawings. The high performance of the method invites experiments: to try different modulations and combinations of settings, and to use it for different applications.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Future work</head><p>We have used IBFVS for different applications, but it can probably also be used for other types of applications. One area where we were not successful yet, is the rendering of hair and fur. The standard textures produced look somewhat furry, but they cannot compete with existing methods for this, such as <ref type="bibr" target="#b14">[Lengyel et al. 2001]</ref>. Soft silhouettes are one of the missing features, but possibly this can be remedied. One promising application area is medical visualization: figure 9 already suggests that the method could be used to visualize surface detail of organs such as the human brain. Other possible extensions of the method are the use of multiple layers, flow fields defined by solid texturing <ref type="bibr" target="#b21">[Perlin 1985]</ref>, spatial or temporal modulation of Î±, and spatial variation of density.</p><p>Concerning flow visualization in general, another challenge is to develop a similar method for 3D volumes. In <ref type="bibr" target="#b29">[Weiskopf et al. 2001]</ref> such an approach is presented for particles, in <ref type="bibr" target="#b25">[Telea and van Wijk 2003</ref>] we present a texture based approach.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusions</head><p>We have presented a simple, efficient, effective, and versatile method for the rendering of dense, vector-field aligned textures on three-dimensional curved surfaces. Unsteady flow on arbitrary surfaces is visualized as animations of texture, at fifty or more frames per second on a PC, using standard features of consumer graphics hardware. We show that the method can be used for flow visualization and surface rendering.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>Figure 1: Pipeline IBFVS</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Boundary inflow from background</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :Figure 4 :</head><label>34</label><figDesc>Uniform density in screen (left) and in world space (right) Velocity projected on surface (left) and in 3D (right) small, and the left image does not appear unnatural. Note that the direction of the texture follows the perspective.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 5 :</head><label>5</label><figDesc>Potential flow field on bunny</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 8 :</head><label>8</label><figDesc>Moving particles (left) and a dense texture (right)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 9 :</head><label>9</label><figDesc>(a) texture modulated for Îº max ; (b) zoomed in in this paper. Rendering was done on a desktop PC with an AMD Athlon XP1700 processor, and a GeForce4 Ti200 graphics card.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Performance results for texture synthesis in frames per second. Static case, dynamic case between parentheses</figDesc><table><row><cell>Resolution</cell><cell>5.8 K</cell><cell>23.2 K</cell><cell>92.8K</cell></row><row><cell>256 Ã 256</cell><cell>600 (76.9)</cell><cell cols="2">228 (22.7) 64.0 (6.6)</cell></row><row><cell>512 Ã 512</cell><cell>290 (76.9)</cell><cell cols="2">165 (22.7) 58.8 (6.6)</cell></row><row><cell cols="4">1024 Ã 1024 88.0 (76.9) 72.4 (22.7) 40.0 (6.6)</cell></row></table><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>I thank my colleagues Ion Barosan, Robert van Liere, Alex Telea, Huub van de Wetering, and Frank van Ham (TU/e), for their inspiring and constructive support during the preparation of this paper.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Imaging vector fields using line integral convolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Cabral</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">C</forename><surname>Leedom</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACM SIGGRAPH 93</title>
		<meeting>ACM SIGGRAPH 93</meeting>
		<imprint>
			<date type="published" when="1993" />
			<biblScope unit="page" from="263" to="272" />
		</imprint>
	</monogr>
	<note>Annual Conference Series</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Divide and conquer spot noise</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">C</forename><surname>De Leeuw</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Van Liere</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings SuperComputing&apos;97</title>
		<meeting>SuperComputing&apos;97</meeting>
		<imprint>
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Enhanced spot noise for vector field visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">C</forename><surname>De Leeuw</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">J</forename><surname>Van Wijk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings IEEE Visualization&apos;95</title>
		<meeting>IEEE Visualization&apos;95</meeting>
		<imprint>
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Parametrization and smooth approximation of surface triangulations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Floater</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Aided Geometric Design</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page">3</biblScope>
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Using line integral convolution for flow visualization: Curvilinear grids, variablespeed animation, and unsteady flows</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">K</forename><surname>Forssell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">D</forename><surname>Cohen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="133" to="141" />
			<date type="published" when="1995-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Understanding errors in approximating principal direction vectors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Goldfeather</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001" />
		</imprint>
		<respStmt>
			<orgName>University of Minnesota, Computer Science and Engineering</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Tech. Rep. 01-006</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Texture synthesis for 3d shape representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Gorla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Interrante</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Sapiro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Applications of pixel textures in visualization and realistic image synthesis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Heidrich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Westermann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H.-P</forename><surname>Seidel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Ertl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM Symposium on Interactive 3D Graphics</title>
		<imprint>
			<date type="published" when="1999" />
			<biblScope unit="page" from="127" to="134" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Normal monthly wind stress over the world ocean with error estimates</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Hellerman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Rosenstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Physical Oceanography</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="1093" to="1104" />
			<date type="published" when="1983" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Enhancing transparent skin surfaces with ridge and valley lines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Interrante</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Fuchs</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M</forename><surname>Pizer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings IEEE Visualization&apos;95</title>
		<meeting>IEEE Visualization&apos;95</meeting>
		<imprint>
			<date type="published" when="1995" />
			<biblScope unit="page" from="52" to="59" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Illustrating surface shape in volume data via principal direction-driven 3D line integral convolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Interrante</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Annual Conference Series</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="109" to="116" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
	<note>Computer Graphics</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Hardwareaccelerated texture advection for unsteady flow visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Jobard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Erlebacher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">Y</forename><surname>Hussaini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings IEEE Visualization</title>
		<meeting>IEEE Visualization</meeting>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="page" from="155" to="162" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Jobard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Erlebacher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">Y</forename><surname>Hussaini</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Lagrangian-eulerian advection for unsteady flow visualization</title>
	</analytic>
	<monogr>
		<title level="m">Proceedings IEEE Visualization</title>
		<meeting>IEEE Visualization</meeting>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="page" from="53" to="60" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Real-time fur over arbitrary surfaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lengyel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Praun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Finkelstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Hoppe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM 2001 Symposium on Interactive 3D Graphics</title>
		<imprint>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Least squares conformal maps for automatic texture atlas generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Petitjean</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Ray</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Maillot</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACM SIG-GRAPH</title>
		<meeting>ACM SIG-GRAPH</meeting>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="362" to="371" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Loop</surname></persName>
		</author>
		<title level="m">Smooth Subdivision Surfaces Based on Triangles. Master&apos;s thesis</title>
		<imprint>
			<date type="published" when="1987" />
		</imprint>
		<respStmt>
			<orgName>Department of Mathematics, University of Utah</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Kinetic visualization: A technique for illustrating 3d shape and structure</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">B</forename><surname>Lum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Stompel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K.-L</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings IEEE Visualization</title>
		<meeting>IEEE Visualization</meeting>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="435" to="442" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Flow visualization using moving textures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Max</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Becker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ICASW/LaRC Symposium on Visualizing Time-Varying Data</title>
		<meeting>the ICASW/LaRC Symposium on Visualizing Time-Varying Data</meeting>
		<imprint>
			<date type="published" when="1995" />
			<biblScope unit="page" from="77" to="87" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Efficient algorithms for local and global accessibility shading</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Miller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of SIGGRAPH &apos;94, Annual Conference Series</title>
		<meeting>SIGGRAPH &apos;94, Annual Conference Series</meeting>
		<imprint>
			<date type="published" when="1994" />
			<biblScope unit="page" from="319" to="326" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">The parallel vectors operator -a vector field visualization primitive</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Peikert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings IEEE Visualization&apos;99</title>
		<meeting>IEEE Visualization&apos;99</meeting>
		<imprint>
			<date type="published" when="1999" />
			<biblScope unit="page" from="263" to="270" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">An image synthesizer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Perlin</surname></persName>
		</author>
		<idno>3. Pro- ceedings of ACM SIGGRAPH 85</idno>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<date type="published" when="1985" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">A new line integral convolution algorithm for visualizing time-varying flow fields</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H.-W</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">L</forename><surname>Kao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="98" to="108" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Hierarchical pattern mapping</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Soler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-P</forename><surname>Cani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Angelidis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACM SIGGRAPH</title>
		<meeting>ACM SIGGRAPH</meeting>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="673" to="680" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Fast and resolution independent line integral convolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Stalling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H.-C</forename><surname>Hege</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACM SIGGRAPH 95</title>
		<meeting>ACM SIGGRAPH 95</meeting>
		<imprint>
			<date type="published" when="1995" />
			<biblScope unit="page" from="249" to="256" />
		</imprint>
	</monogr>
	<note>Annual Conference Series</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">3d ibfv: Hardware-accelerated 3d flow visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">C</forename><surname>Telea</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">J</forename><surname>Van Wijk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings IEEE Visualization</title>
		<meeting>IEEE Visualization</meeting>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Spot noise: Texture synthesis for data visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">J</forename><surname>Van Wijk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings ACM SIGGRAPH 91</title>
		<meeting>ACM SIGGRAPH 91</meeting>
		<imprint>
			<date type="published" when="1991" />
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="309" to="318" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Image based flow visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">J</forename><surname>Van Wijk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACM SIGGRAPH</title>
		<meeting>ACM SIGGRAPH</meeting>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="745" to="754" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Ibfvs: examples and demo software</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">J</forename><surname>Van Wijk</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Hardware-accelerated visualization of time-varying 2d and 3d vector fields by texture advection via programmable per-pixel operations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Weiskopf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hopf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Ertl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Vision, Modeling, and Visualization VMV &apos;01 Conference Proceedings</title>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="page" from="439" to="446" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Animation aerodynamics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wejchert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Haumann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings ACM SIGGRAPH 91</title>
		<meeting>ACM SIGGRAPH 91</meeting>
		<imprint>
			<date type="published" when="1991" />
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="19" to="22" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Parallel line integral convolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>ZÃ¶ckler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Stalling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H.-C</forename><surname>Hege</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Parallel Computing</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="975" to="989" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
