<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/pisenberg/grobid/grobid-0.6.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Visualizing Industrial CT Volume Data for Nondestructive Testing Applications</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Runzhen</forename><surname>Huang</surname></persName>
							<email>huangru@cs.ucdavis.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">University of California at Davis</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kwan-Liu</forename><surname>Ma</surname></persName>
							<email>ma@cs.ucdavis.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">University of California at Davis</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Mccormick</surname></persName>
							<affiliation key="aff1">
								<orgName type="laboratory">Los Alamos National Laboratory</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><surname>Ward</surname></persName>
							<affiliation key="aff1">
								<orgName type="laboratory">Los Alamos National Laboratory</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Visualizing Industrial CT Volume Data for Nondestructive Testing Applications</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2021-02-19T20:50+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>I.3.5 [Computer Graphics]: Computational Geometry and Object Modeling-Boundary representations&apos; I.3.6 [Computer Graphics]: Methodology and Techniques-Interaction Techniques</term>
					<term>I.3.8 [Computer Graphics]: Applications-</term>
					<term>I.4.6 [Image Processing and Computer Vision]: Segmentation-Region growing Computed tomography, feature extraction, hardware-acceleration rendering, image processing, interactive visualization, nondestructive testing and evaluation, scientific visualization, surface modeling, user interface, volume rendering</term>
				</keywords>
			</textClass>
			<abstract>
				<p>This paper describes a set of techniques developed for the visualization of high-resolution volume data generated from industrial computed tomography for nondestructive testing (NDT) applications. Because the data are typically noisy and contain fine features, direct volume rendering methods do not always give us satisfactory results. We have coupled region growing techniques and a 2D histogram interface to facilitate volumetric feature extraction. The new interface allows the user to conveniently identify, separate or composite, and compare features in the data. To lower the cost of segmentation, we show how partial region growing results can suggest a reasonably good classification function for the rendering of the whole volume. The NDT applications that we work on demand visualization tasks including not only feature extraction and visual inspection, but also modeling and measurement of concealed structures in volumetric objects. An efficient filtering and modeling process for generating surface representation of extracted features is also introduced. Four CT data sets for preliminary NDT are used to demonstrate the effectiveness of the new visualization strategy that we have developed.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Computed Tomography (CT) is a noninvasive imaging technique that has been used extensively in not only medicine for diagnosis and surgical planning, but also in nondestructive testing (NDT) for many industrial applications such as mechanical part manufacturing, production of composite materials, waste container inspection and even hardwood lumber processing. The current industrial CT technology is capable of generating very high-resolution images. According to the application requirements, the resolution of the data can be in the range of 512 3 -2048 3 voxels. Such sizes present great challenges to the visualization process which involves both batch processing and interactive visual inspection. <ref type="figure" target="#fig_0">Figure 1</ref> displays volume rendering of such a CT of a mechanical toy. Due to its size, interactive viewing was achieved with a hybrid rendering approach <ref type="bibr" target="#b16">[Wilson et al. 2002]</ref>.</p><p>This application paper focuses primarily on the problems of feature extraction and modeling for NDT applications. Both an interactive method and a semi-automatic method are presented. The interactive approach is based on the use of 2D transfer functions and a 2D histogram interface <ref type="bibr" target="#b7">[Kindlmann and Durkin 1998;</ref><ref type="bibr" target="#b8">Kniss et al. 2002]</ref>, hardware-accelerated volume rendering, and a user interface mechanism that supports incremental and comparative visualization. The semi-automatic approach is based on a region growing algorithm that captures features with complex geometry or small, scattered features in noisy data. A particular interesting and unique approach is the derivation of 2D transfer functions based on the partial features extracted using region growing to visualize the full, similar features in the volume data. This is particularly useful when several features of the same type are disconnected in the volume, and thus region growing cannot capture all of them at once. We also show how to produce a boundary surface representation for the volumetric feature extracted with region growing, and how the quality of such surfaces can be improved with an efficient filtering algorithm. A prototype system has been built which incorporates all these techniques with a coherent user interface. Our experimental study on this system <ref type="bibr">IEEE Visualization 2003</ref><ref type="bibr">, October 19-24, 2003</ref>, Seattle, Washington, USA 0-7803-8120-3/03/$17.00 Â©2003 IEEE using four CT volume data sets from NDT shows that all relevant features can be quickly identified and displayed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Driving Application: Nondestructive Testing and Evaluation</head><p>Nondestructive testing (NDT) is an industrial technology commonly used to detect surface and subsurface discontinuities in material without damaging or destroying the object being tested. For example, for aircraft inspection, NDT is used to aid in the prevention of premature or inadvertent failures in various types of structures and materials. In construction engineering, NDT plays a major role by providing a means of checking compliance to applicable codes, specifications, and standards without significantly interfering with physical construction of the project. Other important NDT applications include CAD part design and quality control, explosive ordinance examination, and nuclear waste inspection.</p><p>A variety of NDT techniques are available, which include ultrasonic, radiography, dye penetrant, eddy current, and magnetic particle methods. In our work, we are mainly concerned with the problem of identifying and visualizing features of interest in volume data generated from an industrial computed tomography system. One challenge that we face is the low-contrast and noisy image characteristics of CT data. The other is the size of a typical data set. Because radiation is not an issue when scanning non-organic objects, a very large number of high-resolution images can be made available for each study.</p><p>In our preliminary study, we have applied our feature extraction and modeling techniques to four CT volume data sets obtained from the Nondestructive Testing Group at the Los Alamos National Laboratory (LANL). <ref type="figure" target="#fig_3">Figure 2</ref> displays two images for each data set. The first two data sets are rather noisy. The first one is a volume reconstruction of a block of concrete with a long glass rod off the center. The features that the scientists are after include the long glass rod and some of the surrounding small blobs. The multiple thin rings are artifacts due to volume reconstruction, which we would want to remove from the visualization. The second data set is a volume reconstruction of a small plastic part surrounded by an aluminum sleeve. The plastic was thermally shocked to produce small cracks which are the target of the feature extraction and visualization. In the images in <ref type="figure" target="#fig_3">Figure 2</ref>, the cracks are barely revealed. The third one is a Maglite flashlight. With direct volume rendering using 1D or 2D transfer functions, we can effectively depict its shape and overall internal structure, as shown on the left image. To capture a specific part, as shown on the right image, segmentation methods are often required. The last data set is a volume reconstruction of a container with a circuit board and some batteries inside. Our objective is to extract selected features in each data set and generate enhanced visualizations of the features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Feature Extraction and Visualization</head><p>The features which the scientists are interested in are generally related to some local density variation and can be either clustered or scattered. The detection of such features is further complicated by the possibly very complex structure of the volume, the low-contrast of the features, and the noise inherently present in the data.    </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Interactive Exploration</head><p>The advent of hardware-accelerated volume rendering enables interactive feature finding and visualization. Hardware accelerated volume rendering requires the loading of the volume data into the texture memory of the video card prior to rendering. The size of the volume that can be rendered interactively is thus limited by the amount of video memory present on the card and the speed at which the data can be transferred between system memory and the graphics card.</p><p>If interactive rendering is possible, data exploration is generally achieved by editing color and opacity transfer functions <ref type="bibr" target="#b13">[Pfister et al. 2001]</ref>. <ref type="bibr" target="#b7">Kindlmann and Durkin [Kindlmann and Durkin 1998</ref>] introduced an intuitive way to derive opacity transfer functions based on the fact that the derivatives of data values suggest material boundaries. They show that by looking at a two-dimensional scatterplot of data values and gradient magnitudes (i.e., a 2D histogram), opacity transfer functions can be easily defined to effectively capture features composed of boundaries between materials of relatively constant data value. <ref type="bibr" target="#b8">Kniss, et al. [Kniss et al. 2002]</ref> extended their work by introducing a set of direct manipulation widgets as the interface for defining multidimensional transfer functions for volume visualization. The concept of dual-domain interaction is particularly powerful and demonstrated with several effective visualization examples.</p><p>Our system adopts the 2D transfer function interface introduced in <ref type="bibr" target="#b7">[Kindlmann and Durkin 1998;</ref><ref type="bibr" target="#b8">Kniss et al. 2002]</ref> to assist interactive feature extraction. The user is presented with an interface displaying two-dimensional scatterplots of the volume data. The left image of <ref type="figure" target="#fig_4">Figure 3</ref> shows such an interface in which the upper left is a scatterplot of data values (x-axis) and gradient magnitudes (y-axis). The user can explore the data by interacting with the scatterplot which is superimposed with the current color map and the histogram of the data to provide additional information to the user. The trapezoid boxes, which are more general than triangular and rectangular boxes used in <ref type="bibr" target="#b8">[Kniss et al. 2002]</ref>, on the scatterplot define the classification functions used to generate the CT flashlight image shown in the right image of <ref type="figure" target="#fig_4">Figure 3</ref>.</p><p>Most of the time a feature in the data can be revealed by interactively varying the two-dimensional transfer function but often other features (or noise) in the data are also brought out, as shown in the left image of <ref type="figure" target="#fig_5">Figure 4</ref>. While in this case our goal is to extract only the long glass rod in the CT concrete data, some noises surrounding the structure also appear, which is undesirable. When applying the region growing method to be discussed next, only the long rod is  Furthermore, interactive exploration involves an iterative trial-and-error process which can be very time consuming. This process is made even more difficult as the size of the data increases; thus making the manual search for several features an impossible or unpleasant task. In order to study large volumetric data sets, automatic feature extraction techniques are desirable since it is very likely that important features are less likely to be missed. For example, the plastic data set is difficult to visualize directly. Even after some careful editing of the two-dimensional transfer function, we can barely capture the crack in the middle, as shown in the left image of <ref type="figure" target="#fig_6">Figure 5</ref>. With region growing, a more complete crack structure can be captured. The right image in <ref type="figure" target="#fig_6">Figure 5</ref> shows the region growing result in which we can see the cracks actually extend from the top to the bottom of the data set. In this particular case, the region growing calculations take under 3 seconds on a PC with a 1.8GHz Pentium 4 processor.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Region Growing Methods</head><p>In our study, we couple interactive browsing with local region growing methods <ref type="bibr" target="#b1">[Ballard and Brown 1982]</ref>. Region growing is a fundamental segmentation technique in image processing <ref type="bibr" target="#b14">[Rosenfeld and Kak 1982]</ref>. In the context of volume data segmentation, the goal of region growing is to map the input volume data into sets of connected voxels, called regions, according to a prescribed criterion which generally examines the properties of local groups of voxels <ref type="bibr" target="#b10">[Lohmann 1998</ref>]. The growing starts from a voxel in the proximity of the the seed point selected by the user. The voxel can be chosen based on either its distance from the seed point or <ref type="figure">Figure 6</ref>: From left to right: A slice of the plastic volume data, the slice was enhanced to facilitate seed picking; additional information displayed on the histogram to assist seed selection; volume rendering of the corresponding region growing result. the statistical properties of the neighborhood. Then each of the twenty-six immediate neighbors of that voxel are visited to determine if they belong to the region. This growing expands further by visiting the neighbors of each of these twenty-six voxels. This recursive process continues until either some termination criterion is met or all voxels in the volume are examined. The result is a set of connected voxels determined to be located within the region(s) of interest.</p><p>Feature finding thus becomes semiautomatic starting with an interactive seed point selection step, followed by region growing process. As a result, the user only needs to find a few representative features and lets the region growing locate all features of similar properties in the same volume data. This approach is similar to the volume seedling method introduced by Cohen et al. <ref type="bibr" target="#b3">[Cohen et al. 1992]</ref>. In their work, region growing is used to help identify fine blood vessels in MRA volume data. More recently, Hahn, et al. <ref type="bibr" target="#b4">[Hahn et al. 2001</ref>] develop a pipeline of 3D image processing steps to derive accurate models for visualization and exploration of vascular structures from radiological data. The resulting vessel models are used to study the branching patterns, for measurement, etc. Hu, et al. <ref type="bibr" target="#b5">[Hu et al. 2001]</ref> apply region growing to the segmentation of lung data to derive airway tree for surgical planning and treatment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1">Seed point selection</head><p>Region growing begins from a seed point. In our system the user picks a seed by interactively slicing through the volume data. As soon as a slice is picked the user can move the cursor into the desired region and click to complete the selection. For noisy data sets, seed point selection becomes difficult, especially when regions are small or thin. First, according to the histogram of the data values, our system can automatically map more colors to a particular value range of interest to increase the visibility of the features, as shown in <ref type="figure">Figure 6</ref>. Such enhancement can also be done by the user in an interactive manner while looking at the two-dimensional scatterplot of the data.</p><p>To further assist interactive seed point selection, some information about the seed voxel and its surrounding voxels is presented to the user. As shown in the third image from the left in <ref type="figure">Figure 6</ref>, when a point is selected, it is highlighted on the scatterplot together with its 26 neighbors. This resembles to the dual-domain interface but more information is provided to the viewer. The coordinates of each highlighted point are the corresponding voxel's scalar and gradient magnitude values. A solid line connects the current point to each of its 26 neighbors. Another very important piece of information is the red rectangle which shows the standard deviation of the data values (x-axis) and the standard deviation of the gradient magnitudes (y-axis) of the neighbors. Essentially, a tighter rectangular box suggests a region of high homogeneity. The right most image in <ref type="figure">Figure 6</ref> shows the corresponding region growing result.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2">Criteria selection</head><p>To do region growing, a set of criteria must be appropriately selected to effectively extract the regions. Possible criteria include region homogeneity and contrast with the background, strength of the region boundary, size, conformity to a desired texture or shape, and so on <ref type="bibr" target="#b14">[Rosenfeld and Kak 1982]</ref>. We have derived three criteria mainly based on region homogeneity and region aggregation using either data values or gradient magnitudes of the voxels. To make our region growing method more robust, at each voxel we also take into account some first-order statistical information about its 26 neighboring voxels.</p><p>Each criterion is defined by a cost function which is designed to extract a particular type of feature. If the value returned by the cost function is less than 1, then the voxel under consideration is within the region. Three functions are defined:</p><formula xml:id="formula_0">A. f ca = |vâvs| kÏv</formula><p>where v is the data value of the current voxel, vs is the data value of the seed voxel, k is a constant specified by the user, and Ïv is the standard deviation of the values of the 26 neighboring voxels of the seed voxel. Note that 0 &lt; k. It is used to control the strictness of the criterion, and its default value is 1. This cost function exploits the data values. It works well for capturing homogeneous regions in which gradient magnitudes are nearly zero.</p><formula xml:id="formula_1">B. f cb = |gâgs| kÏg</formula><p>where g is the gradient magnitude value of the current voxel, gs is the gradient value of the seed voxel, and Ïg is the standard deviation of the gradient values of the 26 neighboring voxels of the seed voxel. This cost function exploits gradient magnitudes and is used to capture only the boundaries of a region.</p><p>C. f cc(p) = fcap+f cb (1âp) where p is a weight specified by the user or by the system. By default, p = Ïg (Ïv +Ïg ) . As a result, this cost function exploits both the data values and gradient magnitudes. It is more flexible than fca and f cb . The left image of <ref type="figure" target="#fig_5">Figure 4</ref> was generated using fcc. <ref type="figure" target="#fig_7">Figure 7</ref> shows the results of applying each cost function to the segmentation of the flashlight data set. In this case, among the three functions, fcc gives us the desired result.</p><p>Modayur et al. <ref type="bibr" target="#b12">[Modayur et al. 1997]</ref> design an adaptive cost function which takes into account the statistical information of the region extracted so far to handle the situation where small connections between two regions should be discarded. Basically, an adjacency criterion is employed in a postprocessing step. However, their cost function does not consider the gradients of voxels which are useful for growing boundaries.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.3">Postprocessing</head><p>After region growing, a postprocessing step might be desirable to extend the results or to improve the results such as removing erroneous voxels or to fill gaps introduced by noisy data. Depending on which criteria is used, the results of feature extraction may vary. For example, due to noise it is possible for a feature to grow into another through a very thin connection one-or two-voxels wide. A postprocessing step can be performed to remove this type of erroneous connection. The three images in <ref type="figure" target="#fig_8">Figure 8</ref> show the result of applying f ca, the result after the cleanup, and the result of applying fcc. In this case, fcc works better because of the use of neighboring gradient values to verify connectivity. However, f cb alone performs poorly in this case.</p><p>Since it is easier for the user to extract one feature at a time, our system allows the user to compose multiple extracted features into a single visualization, as depicted in <ref type="figure" target="#fig_9">Figure 9</ref>. The composition is done interactively through the user interface providing the user with multiple views. In this way, the user can extract and enhance each of the features completely independent of the other features in the same data set but present them in a single visualization for other specific purpose. The multiple views also allow the user to perform comparative visualization of similar features in the same volume or two different volumes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.4">Partial region growing and transfer functions</head><p>When the cost of region growing is high or there are multiple regions, it might be desirable to perform partial region growing instead. That is, feature extraction is only done for a subset of the volume, or only a small subset of all the interested regions in the data is extracted. It is then possible to derive a two-dimensional transfer function based on the partial results of feature extraction for the visualization of other regions/features in the data.</p><p>Such a transfer function can be derived by using the average data value and average gradient magnitude value in the regions already extracted, and standard deviations of the data values and gradient values for the whole extracted region. These four values define a rectangular region on the two-dimensional scatterplot of the data values and gradient values, which is the classification function we are looking for to capture the extended features. The two average values are the coordinates of the center of rectangular region, and the two Ï values define the size of the region. The left most image in <ref type="figure" target="#fig_0">Figure 10</ref> displays a single metal screw extracted using partial region growing. The second image shows the result of applying the derived transfer function to the whole volume to reveal other screws inside the container. The third image shows the derived transfer function (in red), and two other transfer functions (in green and blue) manually defined for adding context to the visualization, as shown in the right most image.   Each feature is independently extracted through an interactive user interface providing multiple views of features. This visualization allows the user to see both the glass rod and the surrounding blobs but not the noises.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Feature Modeling</head><p>Although volume rendering can generate images of the features of interest without first extracting any geometric information from the data, a geometric representation of the features allows for evaluation beyond visual inspection. The commonly used isosurface extraction method <ref type="bibr" target="#b11">[Lorensen and Cline 1987]</ref> based on a binary decision would not work well here because the CT data are noisy and may contain small, fine features.</p><p>To construct boundary surfaces for the features, we make use of the segmented volume from region growing. A boundary tracking algorithm <ref type="bibr" target="#b0">[Artzy et al. 1981</ref>] is used to identify boundary faces. This is followed by a procedure to locate the voxels internal to the boundary identified. The resulting volumetric feature representation allows us to construct compact and hole-free boundary surfaces. The next step is to filter out high-frequency artifacts in the boundary cells. At this point, we could rendering the boundary faces directly by interpolating the faces' normals. However, this would only give us a better picture of the boundary surfaces but not the actual smoother surfaces. The more desirable boundary surfaces can be extracted by using the marching cubes method <ref type="bibr" target="#b11">[Lorensen and Cline 1987]</ref>. A reasonable isovalue used is the average values of those voxel on the boundary faces. The resulting surfaces are smooth while preserving the main topological information of the features, as shown in <ref type="figure" target="#fig_0">Figure 11</ref> for the concrete data set. <ref type="figure" target="#fig_0">Figure 12</ref> displays the extracted surface of the crack for the plastic data set.</p><p>Because of the size of the volume data, the filtering operation can become time-consuming. In this work a Box or Guassian filer is used according to the characteristics of features. To speed up the filtering operation (i.e., convolution), we have applied a set of high-performance computing techniques. Specifically, we have extended a blocked algorithm <ref type="bibr" target="#b9">[Lam et al. 1991]</ref> for our 3D filtering problem to improve the effectiveness of memory hierarchies which include virtual memory, caches, vector registers and scalar registers, and the main memory. The basic idea is to explore the localities of both program and data. The best block size to use thus depends on the volume data size and the memory architecture.</p><p>We have also followed the PHiPAC coding guidelines <ref type="bibr" target="#b2">[Bilmes et al. 1998</ref>] to achieve further performance improvement. Among the set of coding guidelines, we found that loop unrolling and register caching result in the biggest performance improvement. Our experimental results show that an overall 5-8 times speedup may be achieved depending on the size of the filter kernel used. <ref type="figure" target="#fig_0">Figure 13</ref> displays test results using a 3Ã3Ã3 filter kernel for the concrete data set with the block size = 64. The performance difference is apparent. Adding PHiPAC-based optimization is about three times faster than using blocking alone. The same PC with a 1.8GHz Pentium 4 processor was used for testing and the filtering time was cut from about 25 seconds to 5 seconds. PHiPAC coding changes the behavior of the program. According to our test results, PHiPAC coding allows us to use large block sizes leading to better performance; that is, PHiPAC coding improves the locality of the program.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusions</head><p>In this paper we have presented our preliminary results on visualizing industrial CT volume data. A prototype system has been created which allows us to experimentally study both interactive and semi-automatic techniques. Two- <ref type="figure" target="#fig_0">Figure 10</ref>: Left: The result of a partial region growing for capturing a single screw. Middel-left: Using the derived transfer function to capture other screws. Middle-right: The derived transfer function (in red) plus two manually defined transfer functions for adding context to the visualization. Right: Visualization using the three transfer functions.    dimensional transfer functions are powerful for visualizing material boundaries but often fail to completely capture complex volumetric features in noisy data. The region growing methods we have developed supplement the transfer function methods. During our experimentation using several representative CT data sets, we have found that the seed selection interface and the cost functions we have developed are very helpful and effective in accomplishing the intended tasks.</p><p>We have also applied a refined region growing based approach to medical volume data, and obtained very promising results <ref type="bibr" target="#b6">[Huang and Ma 2003]</ref>. We should point out that while these test data sets do present challenges to our study, the data sets we expect to work on for the actual nondestructive evaluation tasks will be larger and could contain multiple, more complex features.</p><p>A related project of ours has shown that by employing an intelligent system it is possible to derive a more intuitive user interface and also eliminate the typical trial-and-error process of visualization parameter specification required in complex classification and visualization tasks <ref type="bibr" target="#b15">[Tzeng et al. 2003</ref>]. We are currently incorporating an intelligent system into our NDT data visualization system.</p><p>We will also continue our study in several other directions. We plan to investigate geometrically-sensitive segmentation such that even more robust criteria can be derived for region growing. Adaptive region growing such as incorporating the statistical information about the regions already identified into cost functions is also a promising approach. Morphological operations can help to further improve the feature extraction results and should be experimentally studied. We are also interested in deriving topological information about the extracted features for region merging and splitting and to create more compact models. We have the ability to construct and display boundary surfaces for the extracted volumetric features. As suggested by the application scientists, it is helpful to render these surfaces by coloring them according to selected statistical information about the features.</p><p>The large data problem must also be addressed. Presently, realtime rendering and manipulation of the volume data is limited to only a subset of the volume since the entire volume will not fit into the texture memory of a PC graphics card. We are in the process of porting the current system to a PC cluster for not only interactive rendering of large CT volume data, but also the feature extraction and modeling tasks.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Volume rendering of a CT of a mechanical toy (512Ã512Ã2048 voxels).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Concrete</head><label></label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fire</head><label></label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 2 :</head><label>2</label><figDesc>Four test data sets obtained from the Nondestructive Testing Group at the Los Alamos National Laboratory.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 3 :</head><label>3</label><figDesc>Left: The interface for editing a two-dimensional transfer function. Right: The resulting image of the CT flashlight volume.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 4 :</head><label>4</label><figDesc>Feature extraction results. Left: transfer function. Right: region growing.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 5 :</head><label>5</label><figDesc>Left: Direct visualization of the CT plastic data using a two-dimensional transfer function that was interactively defined. The cracks revealed in this image are rather incomplete. Right: Volume rendering of the cracks extracted using region growing. The images show the cracks actually extend from the top to the bottom of the data set. captured, as shown in the right image ofFigure 4.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 7 :</head><label>7</label><figDesc>Segmenting the flashlight data set. Top: Using fca alone extracts unwanted parts. Middle: Using f cb extracts an incomplete part. Bottom: Using fcc. fcc gives us the desired result.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 8 :</head><label>8</label><figDesc>Left: the result of using fca. Middle: after cleaning up. Right: the result of using f cc.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 9 :</head><label>9</label><figDesc>Composition of two features.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 11 :</head><label>11</label><figDesc>Left: Original boundary surface. Middle: After applying 3Ã3Ã3 filter. Right: After applying 5Ã5Ã5 filter.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Figure 12 :</head><label>12</label><figDesc>A surface representation of the extracted crack features in the plastic volume data.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Figure 13 :</head><label>13</label><figDesc>Timing with and without optimization for the filtering operation.</figDesc></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>This work has been sponsored in part by the U.S. National Science Foundation under contracts ACI 9983641 (PECASE award), ACI 9982251 (the LSSDSV program), and ACI 0222991; the U.S. Department of Energy under Memorandum Agreements No. DE-FC02-01ER41202 (SciDAC program) and No. B523578; and the National Institute of Health through the Human Brain Project. Los Alamos National Laboratory released the CT data sets, which were generated using Flash CT, a software product of Hytec, Inc. The authors are especially grateful to their colleagues at the Visualization and Graphics group at UC Davis and Los Alamos for their assistance during this research.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">The theory design, implementation and evaluation of a three-dimensional surface detection algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Artzy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Frieder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">T</forename><surname>Herman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics and Image Processing</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="1" to="24" />
			<date type="published" when="1981" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Computer Vision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ballard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Brown</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1982" />
			<publisher>Prentice-Hall Inc</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">The PHiPAC v1.0 matrix-multiply distribution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bilmes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Asanovic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Demmel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Chin</surname></persName>
		</author>
		<idno>UCB/CSD-98-1020</idno>
		<ptr target="www.icsi.berkeley.edu/Ëbilmes/phipac" />
		<imprint>
			<date type="published" when="1998" />
		</imprint>
		<respStmt>
			<orgName>University of California at Berkeley.</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Tech. Rep.</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Volume seedlings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Painter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mehta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K.-L</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1992 ACM Symposium on Interactive 3D Graphics</title>
		<meeting>the 1992 ACM Symposium on Interactive 3D Graphics</meeting>
		<imprint>
			<date type="published" when="1992" />
			<biblScope unit="page" from="139" to="145" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Visualization and interaction techniques for the exploration of vascular structures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">K</forename><surname>Hahn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Preim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Selle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H.-O</forename><surname>Peitgen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Visualization 2001 Conference</title>
		<meeting>the IEEE Visualization 2001 Conference</meeting>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="page" from="395" to="402" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Automatic lung segmentation for accurate quantitation of volumetric xray ct images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">A</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Reinhardt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Medical Imaging</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="490" to="498" />
			<date type="published" when="2001-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Rgvis: Region growing based techniques for volume visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K.-L</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Pacific Graphics 2003 Conference</title>
		<meeting>the Pacific Graphics 2003 Conference</meeting>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
	<note>to appear</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Semi-automatic generation of transfer functions for direct volume rendering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Kindlmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Durkin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 1998 Symposium on Volume Visualization</title>
		<meeting>1998 Symposium on Volume Visualization</meeting>
		<imprint>
			<date type="published" when="1998" />
			<biblScope unit="page" from="79" to="86" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Multidimensional transfer functions for interactive volume rendering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kniss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Kindlmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Hansen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="270" to="285" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">The cache performance and optimizations of blocked algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Rothberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Wolf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 4th International Conference on Architectural Support for Programming Languages and Operating Systems</title>
		<meeting>the 4th International Conference on Architectural Support for Programming Languages and Operating Systems</meeting>
		<imprint>
			<date type="published" when="1991" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Volumetric Image Analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Lohmann</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998" />
			<publisher>Wiley &amp; Teubner Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Marching cubes: A high resolution 3d surface construction algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">E</forename><surname>Lorensen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">E</forename><surname>Cline</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of SIGGRAPH</title>
		<meeting>SIGGRAPH</meeting>
		<imprint>
			<date type="published" when="1987" />
			<biblScope unit="volume">87</biblScope>
			<biblScope unit="page" from="163" to="169" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Visualization-based mapping of language function in the brain</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Modayur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Prothero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Ojemann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Maravilla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Brinkley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuroimage</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="245" to="258" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">The transfer function bake-off</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Pfister</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Lorensen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Bajaj</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Kindlmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Schroeder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Sobierajski Avila</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Machiraju</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer Graphics and Applications</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="16" to="22" />
			<date type="published" when="2001-05" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rosenfeld</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Digital Picture Processing</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<date type="published" when="1982" />
			<publisher>Academic Press</publisher>
		</imprint>
	</monogr>
	<note>second ed</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A novel interface for higher-dimensional classification functions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F.-Y</forename><surname>Tzeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Lum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K.-L</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Visualization 20003 Conference</title>
		<meeting>the IEEE Visualization 20003 Conference</meeting>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
	<note>to appear</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">A hardwareassisted hybrid rendering technique for interactive volume visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Wilson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K.-L</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Mccormick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 2002 Volume Visualization and Graphics Symposium</title>
		<meeting>2002 Volume Visualization and Graphics Symposium</meeting>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="123" to="130" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
