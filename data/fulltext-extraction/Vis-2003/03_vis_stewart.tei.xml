<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/pisenberg/grobid/grobid-0.6.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Vicinity Shading for Enhanced Perception of Volumetric Data</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">James</forename><surname>Stewart</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computing Queen&apos;s University</orgName>
							</affiliation>
							<affiliation key="aff1">
								<address>
									<settlement>Seattle, Washington</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Vicinity Shading for Enhanced Perception of Volumetric Data</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2021-02-19T20:52+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>I.3.6 [Computing Methodologies]: Computer Graphics-Methodology and Techniques volume rendering</term>
					<term>shading model</term>
					<term>diffuse illumination</term>
					<term>perceptual cues</term>
				</keywords>
			</textClass>
			<abstract>
				<p>This paper presents a shading model for volumetric data which enhances the perception of surfaces within the volume. The model incorporates uniform diffuse illumination, which arrives equally from all directions at each surface point in the volume. This illumination is attenuated by occlusions in the local vicinity of the surface point, resulting in shadows in depressions and crevices. Experiments by other authors have shown that perception of a surface is superior under uniform diffuse lighting, compared to illumination from point source lighting.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>This paper describes a new illumination model for surfaces within a volumetric data set. The model, which is based upon the idea of "obscurances" <ref type="bibr" target="#b24">[Zhukov et al. 1998</ref>], produces more accurate shading than the regular "diffuse-plus-specular" Phong model <ref type="bibr" target="#b18">[Phong 1975</ref>] which is commonly used with volume rendering. The chief characteristic of the new model is that depressions, folds, and crevices are shadowed, which provides an additional perceptual cue to surface shape.</p><p>Volumetric data is typically illuminated by one or more point light sources, and the shading at each point in the volume is calculated as a sum of diffuse and specular components involving the directions of the light source, L, the viewer, V , and the surface normal (or gradient), N. This makes for a very quick shading calculation, which is simple enough to be implemented in graphics card hardware using the Blinn approximation <ref type="bibr" target="#b1">[Blinn 1977</ref>] for the specular component.</p><p>This illumination method provides good perceptual cues to the orientation of the surface that is embedded in the volume, due to the diffuse N • L term: Surfaces are bright if illuminated from directly above, and dark if illuminated from the side.</p><p>But this model gives poor cues to the relative depth of a surface. It can be difficult to determine whether one part of the surface is higher or lower than an adjacent part. The ambiguity in relative depth can be reduced by introducing shadows, which provide perceptual cues to the surface shape.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Which is it? or</head><p>Figure 1: Top: Under point-source illumination, a surface provides no cues to the relative depths of its two halves. Bottom: Under uniform diffuse illumination, the relative depths are clearer.</p><p>The usual way to provide shadows is with ray tracing <ref type="bibr" target="#b21">[Whitted 1980</ref>]: From each surface point, rays are shot to each light source and those that arrive without intersecting an object contribute to the point's illumination. But shadows from point sources and opaque objects are sharp, and introduce confusing illumination discontinuities on the surface: It can be difficult for the viewer to distinguish between a dark-to-light transition due to shadowing, and one due to a sudden change in surface orientation.</p><p>Better shadowing is provided under uniform diffuse lighting, which arrives equally from all directions, much like the illumination on a cloudy day (see <ref type="figure">Figure 1</ref>). With such lighting, the shading of a surface point is a function of the solid angle subtended by the visible part of the light source: Points in valleys don't get much light, whereas points on peaks get a lot of light. Langer and Bülkhoff <ref type="bibr" target="#b11">[Langer and Bülthoff 1997]</ref> have shown that, for a common class of surfaces, perception of shape is more accurate under such "cloudy day" lighting than under point lighting.</p><p>Distribution ray tracing <ref type="bibr" target="#b4">[Cook et al. 1984]</ref> could calculate shading under uniform diffuse lighting, but at a very high computational cost: Many rays must be sent outward from each surface point, in- <ref type="figure">Figure 2</ref>: A human skull with fractures of the checkbone in three places. Dark areas in the upper-left image correspond to more occluded vicinities. The vicinity values are combined with regular "diffuse-plus-specular" shading by multiplying the two, resulting in the bottom, vicinity shaded image. stead of the single ray used with a point light source.</p><p>This paper introduces a model of illumination for volumetric data, dubbed vicinity shading. In essence, we shade each surface point according to uniform diffuse lighting that is blocked only in the vicinity of the surface point. Vicinity shading provides better perceptual cues than the regular diffuse-plus-specular model. As shown in <ref type="figure">Figure 2</ref>, vicinity shading provides a good approximation of the shadowing that occurs in depressions and cavities.</p><p>This paper also describes a novel algorithm to compute vicinity shading for all isosurfaces in a volumetric data set. Thus, different isosurfaces can be rendered without requiring recomputation of the vicinity shading. Volumetric data poses some interesting problems and opportunities that are not present with other data representa-tions, such as polygon meshes. These problems and opportunities are addressed by the algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>The original illumination model for volumetric data was described by <ref type="bibr" target="#b13">Levoy [Levoy 1988]</ref>, and includes components for scattering and absorption: Light from a point source is reflected off of each voxel, and is attenuated due to absorption along the path from the voxel to the viewer. No absorption occurs before the ray arrives at the voxel, so no shadows are present with this model. Levoy rendered the volume by tracing rays from the eye through the volume, accumulating light from sample points along each ray. Cabral <ref type="bibr" target="#b3">[Cabral et al. 1994]</ref> introduced the use of graphics texture mapping hardware to accelerate the process.</p><p>Shadows in volumetric data have been produced by "two-pass" methods <ref type="bibr" target="#b0">[Behrens and Ratering 1998;</ref><ref type="bibr" target="#b6">Kajiya and Herzen 1984;</ref><ref type="bibr" target="#b15">Meinzer et al. 1991]</ref>. The first pass propagates point-source light through the volume, taking into account absorption, and stores in each voxel of a separate "light volume" the intensity of the arriving light. A second pass propagates light from the light volume toward the viewer, in the manner of Levoy or Cabral. Splatting has also been used to compute the light volume <ref type="bibr" target="#b17">[Nulkar and Mueller 2001]</ref> with this two-pass approach. Other methods combine the two passes using volume slices that are aligned with neither the viewer nor the light source <ref type="bibr">[Kniss et al. 2002a;</ref><ref type="bibr" target="#b22">Zhang and Crawfis 2002;</ref><ref type="bibr" target="#b23">Zhang and Crawfis 2003</ref>]. Another interesting approach <ref type="bibr">[Kniss et al. 2002b;</ref><ref type="bibr" target="#b10">Kniss et al. 2003</ref>] adds a scattering component to the lighting model. A good survey of other illumination models for volume rendering was written by Max <ref type="bibr" target="#b14">[Max 1995]</ref>.</p><p>These methods for producing shadows in volumetric data all produce shadows from point light sources, and can't achieve the effect of uniform diffuse lighting that we're looking for. However, these methods are fast, typically requiring only one rendering of the data to produce the light volume, which can then be used without recomputation until the position of the light source changes. The vicinity shading described in this paper takes substantially longer (in the order of tens of minutes) to compute its own light volume but, once computed, the shadow information from that volume can be used without ever requiring recomputation.</p><p>Vicinity shading is the volumetric version of "obscurances," <ref type="bibr" target="#b24">[Zhukov et al. 1998;</ref><ref type="bibr" target="#b5">Iones et al. 2003</ref>] which were used to achieve the same "cloudy day" illumination in polygonal scenes. The obscurance of a surface point is a measure of the empty space above the surface point, taking into account only the geometry (typically 10 to 100 polygons) within a certain distance of the surface point. More detail is provided in Section 3.</p><p>Vicinity shading applies the idea of obscurances to volumetric data, which poses challenges: For example, what characterizes those voxels that block light from arriving at a particular isosurface, and how is vicinity shading computed efficiently for all possible isosurfaces in the volume? But volumetric data also provides opportunities, such as the potential to exploit the regular and spacecoherent structure of the data. These points will be discussed in Section 3.3.</p><p>Vicinity shading and obscurances are closely related to accessibility shading. The "tangent accessibility" of a surface point is equal to the radius of the largest sphere that can touch that point without intersecting any other part of the surface. This notion of accessibility was originally introduced <ref type="bibr" target="#b12">[Lee and Richards 1971]</ref> in molecular modelling to determine what parts of one molecule are accessible to (the spherical atoms of) another molecule, in order to gain insight into chemical reactions between the molecules.</p><p>The accessibility measure (i.e. the sphere radius) can be used to modulate the intensity of a surface point, producing very appealing images of polished surfaces in which dark polish has accumulated in small, inaccessible cracks and pits <ref type="bibr" target="#b16">[Miller 1994</ref>]. Efficient algorithms to compute accessibility have exploited graphics hardware <ref type="bibr" target="#b20">[Spitz and Requicha 2000]</ref> and geometric techniques.</p><p>Accessibility gives a coarse approximation of the intensity of light arriving at a surface point, but fails in some cases. For example, the interior of a long tube will have uniform accessibility along its entire length, whereas the shading of the tube's interior should be darkest in the middle of the tube (see <ref type="figure" target="#fig_0">Figure 3</ref>). As another example, a surface point with a tiny occlusion directly above it will have low accessibility (and hence, dark shading), whereas the tiny occlusion should have almost no effect on the shading of the surface point.</p><p>Vicinity shading overcomes these problems by sampling in di- A tube has uniform accessibility on its interior, as shown by the equally sized tangent spheres. However, we would expect darker shading toward the middle. Bottom: A surface with a tiny square occluder above it has dramatically reduced accessibility right below the occluder. However, we would expect only a very slight reduction in surface illumination under the occluder.</p><p>rections outward from the surface point to estimate the amount of unoccluded light arriving at the surface. However, since vicinity shading only estimates direct "primary" illumination, it will likely produce overly dark images for surfaces with high reflectivity, on which light can reflect multiple times to arrive inside folds and depressions. For such surfaces, a more accurate (and more computationally expensive) model would be used to account for multiple scattering <ref type="bibr" target="#b19">[Rushmeier and Torrance 1987]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Vicinity Shading</head><p>We'll consider the vicinity shading at one surface point, p, leaving the question of what constitutes a surface to Section 3.3. As with the volume shading method of Levoy, we assume that light arrives at each point without attenuation due to the medium except (in our case) in the vicinity of the surface point. After being reflected from the surface, the light is attenuated in the standard way as it travels toward the viewer. The goal is to compute for p a single coefficient between zero and one that represents the reduction of light at p due to occlusions in the vicinity. The light volume consisting of all of these coefficients will later be used while rendering, in the same manner as the two-pass shadow algorithms described above.</p><p>Let N be the surface normal at p, equal to the normalized gradient of the data field at p. A variant of the rendering equation <ref type="bibr" target="#b7">[Kajiya 1986</ref>] gives the irradiance, E, arriving at p:</p><formula xml:id="formula_0">E(p) = Ω N • L(ω) dω</formula><p>where L(ω) is the radiance arriving from direction ω (written as a vector with magnitude equal to the radiance), and Ω is the set of directions above the surface -those for which N • ω &gt; 0.</p><p>This equation is evaluated by discretizing the domain Ω into k sectors of equal solid angle, ∆ω, and sampling L(ω) within each sector:</p><formula xml:id="formula_1">E(p) ≈ k ∑ i=1 N • L(ω i ) ∆ω</formula><p>Since our goal is to produce a coefficient in the range zero to one that represents the fraction of total possible irradiance arriving at p, we normalize to get E(p):</p><formula xml:id="formula_2">E(p) = ∑ N • L(ω i ) ∆ω ∑ N • L max (ω i ) ∆ω = ∑ L i cos θ i ∑ L max i cos θ i (1)</formula><p>where cos</p><formula xml:id="formula_3">θ i = N • ω i , L i is the computed scalar value of L(ω i ), and L max i</formula><p>is the maximum possible value of L(ω i ) (more on this last item below).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Discretizing the Domain Ω</head><p>The set of all directions around p can be represented by points on a Gaussian sphere centered at p. We can produce a fairly evenly distributed set of sample directions on the sphere with a commonlyused technique: Start with an icosahedron whose vertices lie on the unit sphere and subdivide each triangular face into four smaller triangles, whose new vertices are projected outward onto the unit sphere. Two or three iterations of this procedure produce a set of sample directions corresponding to vertices of the resulting polyhedron.</p><p>Each sample direction, ω i , corresponds to one sector, ∆ω i of the discretized domain. At a particular point, p, on the object surface, we only consider the sectors, i, that are outward facing:</p><formula xml:id="formula_4">N • ω i &gt; 0.</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Definitions of L i and L max i</head><p>For each sector, i, we must determine the radiance, L i . Since the light source is uniform and diffuse, the radiance arriving directly at p -if unobstructed and unreflected -is equal from all directions, making the computation of L i purely geometric.</p><p>With vicinity shading, occlusions are detected only within the vicinity of p, where the vicinity is an outward facing hemisphere of radius r centered at p. In the volumetric data set, the vicinity contains a number of voxels, each of which has been classified as interior or exterior to the surface to which p belongs (more on this below). Any interior voxel will occlude the light arriving at p.</p><p>To determine how much light arrives at p from direction ω i , we simply sample the voxels lying in that direction, up to a distance r from p. There are (at least) two ways to estimate L i :</p><p>If none of the voxels sampled in direction ω i is interior, L i = 1. Otherwise, L i = 0. This all-or-nothing method only collects light that is unoccluded as it travels from the boundary of the vicinity to p. In this case, L max i = 1.</p><p>In some situations, such as inside of a long tube, the all-ornothing method will result in too little illumination for reasonable perception of the surface. For such cases, it's useful to estimate L i according to the unobstructed distance from p in direction ω i . This partial occlusion method provides (reduced) illumination even in tight spaces, which the "all or nothing" method does not.</p><p>With the partial occlusion method, L i is set equal to the distance from p to the nearest interior voxel in direction ω i . L max i is the distance to the farthest voxel in the vicinity in direction ω i . Note that L max i ≤ r, but is usually not equal to r.</p><p>x y w i <ref type="figure">Figure 5</ref>: A 2D discrete line (shown as solid black pixels) in direction ω i with dominant direction x. Integer translations of the discrete line (shown as shades of gray) in the non-dominant y direction are sufficient to completely cover the area such that each pixel lies on exactly one of the translated discrete lines. Each X marks the start of a line enumerated by the algorithm of Section 3.3.1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Computation of L i and L max i</head><p>With vicinity shading, there's no notion of transparency: light that is directed toward a voxel, v, is either blocked, or is not. If v lies on a "surface" in the volume and has density ρ(v), it is reasonable to assume that the rest of the same surface has density greater than or equal to ρ(v). Thus, we will assume the following:</p><p>A voxel v of density ρ(v) has its incoming light blocked by any other voxel of density greater than or equal to ρ(v).</p><p>To compute v's vicinity shading, E(v), we evaluate Equation 1 by sampling in directions ω i above v's surface. A sample in direction ω i is blocked when it arrives at a voxel of density greater than or equal to ρ(v), and L i and L max i are determined by the partial occlusion method.</p><p>One approach to computing E for all voxels would be to iterate over all voxels and, for each voxel, to iterate over all sample directions. This would be prohibitively expensive: For n voxels, s sample directions, and a vicinity radius of r, the running time would be in O(n s r).</p><p>Instead, this section will describe an algorithm to compute E for all voxels in time O(n s), which removes any dependence on the vicinity radius, r. In fact, the vicinity can be arbitrarily large without affecting the running time.</p><p>The new algorithm exploits the following observation: For a fixed line through the volume in direction ω i , a voxel on that line can be blocked in direction ω i only by another voxel on that line.</p><p>Suppose that we can cover the volume with a set of parallel lines in direction ω i , such that each voxel appears on exactly one line. Then each such line can be treated independently to compute L i for all voxels on that line. This process can be repeated for each direction, ω i , and the results accumulated according to Equation 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.1">Covering the Volume with Disjoint Discrete Lines</head><p>The dominant direction of a line is the axis (x, y, or z) to which it is most parallel. In the context of a particular volume of voxels, the discrete line in direction ω i is the (finite) set of voxels enumerated by a 3D Bresenham algorithm that starts from one corner of the volume and moves in direction ω i until it exits the volume. The corner is chosen to maximize the number of enumerated voxels.</p><p>For a particular direction, ω i , assume without loss of generality that x is the dominant direction. Consider a translation of the discrete line an integer number of voxels in the non-dominant y direction, followed by an integer number of voxels in the non-dominant z direction. (See <ref type="figure">Figure 5</ref>, in which a 2D example is given: The <ref type="figure">Figure 4</ref>: A discrete line and the corresponding plot of density versus distance. The discrete line has been rotated so that the plot point corresponding to a voxel appears directly below the voxel. The voxel v j is blocked in the ω i direction by voxel v k since (in the plot) v k is the closest point to the right of v j that is above v j . dominant direction is x, and the discrete line is translated integer amounts in the non-dominant y direction.) Two observations can be made:</p><formula xml:id="formula_5">distance v k v j v k v j w i density</formula><p>1. Each voxel lies on exactly one translated discrete line.</p><p>2. No two translated discrete lines intersect (unless the translations are identical).</p><p>This means that we can "cover" the volume with a set of translated discrete lines in direction ω i , such that each voxel appears on exactly one translated discrete line, as was required in the previous section.</p><p>The following algorithm enumerates the translated discrete lines. 1 For simplicity, we've assumed that the dominant direction is x and that the discrete line starts at the (0, 0, 0) voxel.</p><p>1. Each voxel (0, y, z) on the x = 0 face of the volume is the beginning of a translated discrete line.</p><p>2. Use the 3D Bresenham algorithm to enumerate voxels on the discrete line that starts at (0, 0, 0). Let (x j , y j , z j ) be the j th voxel on the discrete line. Note that x j = x j−1 + 1 since x is the dominant direction.</p><p>(a) If y j = y j−1 , then each voxel (x j , 0, z) on the y = 0 face of the volume is the beginning of a translated discrete line.</p><p>(b) If z j = z j−1 , then each voxel (x j , y, 0) on the z = 0 face of the volume is the beginning of a translated discrete line.</p><p>For new lines that are enumerated in Steps 2a and 2b above, the state of the 3D Bresenham algorithm at the first voxel of the new line must be identical to the state of the 3D Bresenham algorithm of Step 2 at the time that the new line is enumerated. This ensures that the new line is not translated in the dominant x direction. (If it were translated in that direction, it would intersect with another line, violating our requirement that each voxel lie on exactly one line.)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.2">Computing L i for All Voxels on One Discrete Line</head><p>The preceding section described how to allocate voxels to discrete lines such that any voxel on a line can be blocked in direction ω i only by another voxel on that line. This section will describe how to determine the blocking voxels and, hence, how to compute L i for each voxel on a line.</p><p>Let the voxels on a line be v 1 , v 2 , v 3 ,... with the index increasing in the ω i direction. Voxel v j has density ρ(v j ) and Euclidean distance d(v j ) from the first voxel on the line. <ref type="figure">Figure 4</ref> shows an example of a line and the corresponding plot of density versus distance.</p><p>A voxel v j is blocked by a voxel v k in direction ω i if j &lt; k and ρ(v j ) ≤ ρ(v k ). In the plot of <ref type="figure">Figure 4</ref>, the blocking v k is found by drawing a horizontal line rightward from (d(v j ), ρ(v j )) until it arrives at a higher (i.e. denser) point.</p><p>For each voxel on the line, our algorithm must compute its corresponding blocking voxel. The algorithm maintains a stack of asyet "unresolved" voxels, for which no blocking voxel has yet been found. The top of the stack stores the unresolved voxel of minimum density, and density increases down the stack. Initially the stack is empty.</p><p>The algorithm processes the voxels by order of increasing distance, d. Upon processing the next voxel, v, two steps are taken:</p><p>1. If the voxel, u, at the top of the stack has ρ(u) ≤ ρ(v), then v is the closest blocker to u. In this case, pop u from the stack and (only if</p><formula xml:id="formula_6">N(u) • ω i &gt; 0) compute L i (u) based upon the distance d(v) − d(u) between u and v. Repeat</formula><p>Step 1 until the stack is empty or the topmost voxel has a greater density than that of</p><formula xml:id="formula_7">v. v u N(v)</formula><p>ta ng en t pl an e at v <ref type="figure">Figure 6</ref>: A gently sloping surface with a step will result in overly dark vicinity shading of the voxel, v, on the lower side of the step due to occlusion by the voxel, u, on the higher side of the step. The solution is prevent blocking by any voxel that is (a) close to v and (b) close to the tangent plane of v. The white voxels meet these criteria.</p><p>2. Push v onto the top of the stack, since v is now the minimumdensity unresolved voxel.</p><p>After all voxels on the line have been processed, any unresolved voxels remaining on the stack are unoccluded in direction ω i . For each unoccluded voxel, set L i = L max i . For a better intuition, refer to <ref type="figure">Figure 4</ref>: Suppose we are just about to process v k , and the stack contains the voxels shown as solid circles to the left of v k . When v k is processed, the first two such voxels are removed from the stack, since v k blocks them (as shown by the dashed horizontal lines). Then v k is added to the stack.</p><p>The algorithm can be modified to compute blocking pixels in both directions (ω i and −ω i ) in the same pass along the line. Note that v's closest occluder in the −ω i direction is the topmost voxel on the stack after Step 1 is completed. A Step 1.5 could be added to take advantage of this.</p><p>A problem arises due to the voxelization of volumetric data. As shown in the 2D example of <ref type="figure">Figure 6</ref>, a flat surface that is oriented close to one of the volume axes will have a number of steps. The voxel on the lower side of a step will be very much occluded by the voxel on the upper side of the step, resulting in overly dark vicinity shading of the lower voxel (which will result in dark bands in the rendered volume). To avoid this, we apply a heuristic: A voxel u does not block a voxel v if (a) u is within three voxel widths of v and (b) u is within 1.5 voxel widths of the tangent plane at v.</p><p>To implement the heuristic, Step 1 of the algorithm must be modified: If the voxel removed from the stack in Step 1 satisfies conditions (a) and (b) above, that voxel is instead put onto a separate list of "postponed" voxels. A Step 0 is added in which the new voxel v is checked against every postponed voxel, to see whether it blocks a postponed voxel. If it does, the postponed voxel is removed from the list and its L i is calculated with v as the blocker.</p><p>The first enhancement (that of processing the direction −ω i ) and the second (that of postponing some voxels) are incompatible; only one can be implemented in the algorithm. Furthermore, if we postpone some voxels, the running time of O(n s) is no longer valid, since we might, in theory, inspect a large number of postponed voxels with each new voxel on the line. In practice, however, postponing voxels was found to have very little effect on the running time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Using E(p) in Texture-Based Volume Rendering</head><p>The previous sections described how to compute L i for each voxel, given a particular direction ω i . We apply that procedure to all directions and compute the vicinity shading, E, of each voxel according to Equation 1.</p><p>The result of computing E is a "light volume" in which each voxel stores a value between zero and one, which is an estimate of the fraction of total possible illumination arriving at the voxel.</p><p>In texture-based volume rendering, each voxel in a 3D texture volume stores an RGBA 4-tuple, where the RGB are the three components of the normalized voxel gradient, and A is the voxel density. The value for A is used to index into a transfer function, which provides a colour and opacity for the voxel.</p><p>The simplest way to incorporate the light volume in the illumination calculation is to use it to modulate the RGB gradient lengths: Each normalized gradient N(p) is replaced by E(p) × N(p). The intensity of light leaving p is then computed as</p><formula xml:id="formula_8">I = k d ( EN) • L + k s (( EN) • H) n = E k d N • L + E n k s (N • H) n</formula><p>with L the direction to the point light source, H the half-angle vector between L and the direction to the viewer, and k d and k s the diffuse and specular lighting coefficients. This is not a physically correct model, because the uniform diffuse lighting should be independent of the point source lighting. This approach also tends to remove specular highlights, due to the specular exponent on E. But it is simple and does produce better perceptual cues than without vicinity shading. Its principal advantage is that it is embarrassingly easy to implement. The images in this paper were rendered with this method.</p><p>It would be better to separate the contribution of the uniform diffuse lighting from that of the point source lighting. To do so, we can encode the normalized voxel gradient in two components, RG, and encode the light volume in the third component, B. The graphics hardware can then use RG as indices into a 2D texture containing 3D gradients, and can include E (from B) as a separate term in the calculation:</p><formula xml:id="formula_9">I = k e E + k d N • L + k s (N • H) n</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experimental Results</head><p>Vicinity shading was applied to a number of volumetric data sets generated from CT scans, and to one data set generated by voxelizing a polygonized model. Two of these sets are shown in this paper. With each set, the vicinity radius was set to 100 voxel widths, but could have been set to any value without affecting the execution times. The images of this paper used vicinity shading that was computed from 1272 sample directions. <ref type="figure">Figure 2</ref> shows a skull with a fractured cheekbone. Vicinity shading provides good cues to the positions of the three fractures, and helps to distinguish the interior of the skull as seen through the eye orbit. It also brings out several small features which are not obvious with the regular shading method. <ref type="figure">Figure 7</ref> shows a cerebral cortex, which was converted to voxel data from a polygonized model. The regular diffuse-plus-specular shading produces an artificially bright image, in which deep folds are as brightly illuminated as the outer surface (except where the light direction is almost tangent to the surface of the fold). This is corrected with vicinity shading, yielding a more realistic image with better depth cues. <ref type="table" target="#tab_0">Table 1</ref> summarizes the results on a 1.8 GHz Pentium PC with 1.0 GB of memory. The running time of the vicinity computation is approximately proportional to the total number of voxels and to the number of sample directions. The running time is completely independent of the vicinity radius, r. In a 256 × 256 × 256 volume, each sampling direction requires about 2.7 seconds of computation. Despite the "efficient" algorithm, this is still a huge amount of time, and is an obvious area for future work. (Of course, we can always trade off time for accuracy by reducing the number of sampling directions.)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Discussion</head><p>Vicinity shading provides perceptual cues to relative surface depth. It does so by estimating the illumination that the surface would receive under uniform diffuse lighting. Experiments by other authors <ref type="bibr" target="#b11">[Langer and Bülthoff 1997]</ref> have shown that -for at least some surfaces -perception of shape is more accurate under such uniform, diffuse lighting than it is under point lighting.</p><p>Vicinity shading samples for occluders in a vicinity around each surface point. An algorithm was described which efficiently determines the vicinity shading of all voxels by exploiting the coherence of voxels along a number of discretely sampled directions through the volume.</p><p>An important feature of the algorithm is that it computes vicinity shading for all possible isosurfaces simultaneously, and not just for the one surface shown in the images of this paper. Thus, the transfer function can (to some degree) be manipulated without requiring recomputation of the vicinity shading.</p><p>At least two avenues of future work appear interesting. Firstly, it should be possible to accelerate the algorithm by using the functionality of graphics hardware. One potential problem, however, is that the current algorithm uses a variable-size stack, which does not have an obvious graphics card hardware implementation.</p><p>Secondly, a user study should be performed to verify that perception of shape is, indeed, superior with vicinity shading. The results of Langer and Bülkhoff only suggest that this is the case for vicinity shading, since vicinity shading only provides an estimate of the overall illumination, and is applied to a different type of surface than in the Langer and Bülkhoff study. Such an experiment might, for example, test users on their ability to distinguish peaks and valleys in images with and without vicinity shading.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 3 :</head><label>3</label><figDesc>Accessibility shading provides incorrect depth cues. Top:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Data Sets and Execution Times</figDesc><table><row><cell>Data</cell><cell>Dimensions</cell><cell cols="2">Number of Execution Time</cell></row><row><cell></cell><cell></cell><cell>Directions</cell><cell>(minutes)</cell></row><row><cell>Skull</cell><cell>256 × 256 × 203</cell><cell>312</cell><cell>14.3</cell></row><row><cell>Skull</cell><cell>256 × 256 × 203</cell><cell>1272</cell><cell>59.0</cell></row><row><cell cols="2">Cortex 128 × 512 × 256</cell><cell>1272</cell><cell>57.5</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">This program code (and the other code of the algorithm) is available by email request to the author.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Acknowledgements</head><p>The author wishes to thank Paul Bourke <ref type="bibr" target="#b2">[Bourke 1997</ref>] for the cerebral cortex data, and to thank the Department of Radiology at the University of Iowa for their publically available data sets of the foot and skull. The thoughtful comments of the anonymous reviewers were also appreciated. This work is supported in part by a grant from Communications and Information Technology Ontario.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Regular "diffuse-plus-specular" shading Vicinity shading <ref type="figure">Figure 7</ref>: Vicinity shading of a cerebral cortex using 1272 sample directions.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Adding shadows to a texturebased volume renderer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Behrens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ratering</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Symposium on Volume Visualization</title>
		<imprint>
			<date type="published" when="1998" />
			<biblScope unit="page" from="39" to="46" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Models of light reflection for computer synthesized pictures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">F</forename><surname>Blinn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics (SIGGRAPH)</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="192" to="198" />
			<date type="published" when="1977" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Modelling the surface of the human cortex</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Bourke</surname></persName>
		</author>
		<ptr target="http://astronomy.swin.edu.au/pbourke/modelling/cortex" />
	</analytic>
	<monogr>
		<title level="m">online notes</title>
		<imprint>
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Accelerated volume rendering and tomographic reconstruction using texture mapping hardware</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Cabral</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Cam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Foran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Symposium on Volume Visualization</title>
		<imprint>
			<date type="published" when="1994" />
			<biblScope unit="page" from="91" to="98" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Distributed ray tracing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Cook</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Porter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Carpenter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics (SIGGRAPH)</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="137" to="145" />
			<date type="published" when="1984" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Fast, realistic lighting for video games</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Iones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krupkin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sbert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zhukov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer Graphics and Applications</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="54" to="64" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Ray tracing volume densities</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kajiya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">V</forename><surname>Herzen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics (SIGGRAPH)</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="165" to="174" />
			<date type="published" when="1984" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">The rendering equation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kajiya</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics (SIG-GRAPH)</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="143" to="150" />
			<date type="published" when="1986" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Multidimensional transfer functions for interactive volume rendering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kniss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Kindlmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">D</forename><surname>Hansen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="270" to="285" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Interactive translucent volume rendering and procedural modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kniss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Premoze</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">D</forename><surname>Hansen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">S</forename><surname>Ebert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Visualization Conference</title>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="255" to="262" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">A model for volume lighting and modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kniss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Premoze</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">D</forename><surname>Hansen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Shirley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mcpher-Son</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="150" to="162" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Do humans perceive shape from shading better on sunny days or on cloudy days?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">S</forename><surname>Langer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">H</forename><surname>Bülthoff</surname></persName>
		</author>
		<idno>97- 130</idno>
		<imprint>
			<date type="published" when="1997" />
		</imprint>
		<respStmt>
			<orgName>NEC Research Institute</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Tech. Rep.</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">The interpretation of protein structures: Estimation of static accessibility</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">M</forename><surname>Richards</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Molecular Biology</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="page" from="379" to="400" />
			<date type="published" when="1971" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Display of surfaces from volume data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Levoy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer Graphics and Applications</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="29" to="37" />
			<date type="published" when="1988" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Optical models for direct volume rendering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Max</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">The heidelberg ray tracing model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H.-P</forename><surname>Meinzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Meetz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Scheppelmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Engelmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">J</forename><surname>Baur</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer Graphics and Applications</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="34" to="43" />
			<date type="published" when="1991" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Efficient algorithms for local and global accessibility</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Miller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics (SIGGRAPH</title>
		<imprint>
			<biblScope unit="page" from="319" to="326" />
			<date type="published" when="1994" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Splatting with shadows</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Nulkar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Mueller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Workshop on Volume Graphics</title>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="page" from="35" to="50" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Illumination for computer generated images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B.-T</forename><surname>Phong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Communications of the ACM 18</title>
		<imprint>
			<date type="published" when="1975" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="311" to="317" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">The zonal method for calculating light intensities in the presence of a participating medium</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Rushmeier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Torrance</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics (SIGGRAPH)</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="293" to="302" />
			<date type="published" when="1987" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Accessibility analysis using computer graphics hardware</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">N</forename><surname>Spitz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A G</forename><surname>Requicha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="208" to="219" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">An improved illumination model for shaded display</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Whitted</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="343" to="349" />
			<date type="published" when="1980" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Volumetric shadows using splatting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Crawfis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Visualization Conference</title>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="85" to="92" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Shadows and soft shadows with participating media using splatting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Crawfis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="139" to="149" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">An ambient light illumination model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zhukov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Iones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Kronin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Eurographics Workshop on Rendering</title>
		<imprint>
			<date type="published" when="1998" />
			<biblScope unit="page" from="45" to="56" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
