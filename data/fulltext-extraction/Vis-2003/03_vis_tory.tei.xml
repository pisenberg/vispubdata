<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/pisenberg/grobid/grobid-0.6.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Mental Registration of 2D and 3D Visualizations (An Empirical Study)</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Melanie</forename><surname>Tory</surname></persName>
							<email>mktory@cs.sfu.ca</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Graphics, Usability, and Visualization (GRUVI)</orgName>
								<orgName type="department" key="dep2">School of Computing Science</orgName>
								<orgName type="institution">Simon Fraser University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Mental Registration of 2D and 3D Visualizations (An Empirical Study)</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2021-02-19T20:52+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>H.5.2 User Interfaces -Graphical User Interfaces (GUI)</term>
					<term>Screen Design</term>
					<term>Evaluation/Methodology</term>
					<term>I.3.3 Picture/ Image Generation -Display Algorithms</term>
					<term>J. Computer Applications (e.g.</term>
					<term>CAD</term>
					<term>Medical Imaging</term>
					<term>Physical Sciences) 2D and 3D visualization</term>
					<term>mental registration</term>
					<term>slice</term>
					<term>orthographic projection</term>
					<term>empirical study</term>
					<term>experiment</term>
				</keywords>
			</textClass>
			<abstract>
				<p>2D and 3D views are used together in many visualization domains, such as medical imaging, flow visualization, oceanographic visualization, and computer aided design (CAD).Combining these views into one display can be done by: (1) orientation icon (i.e., separate windows), (2) in-place methods (e.g., clip and cutting planes), and (3) a new method called ExoVis. How 2D and 3D views are displayed affects ease of mental registration (understanding the spatial relationship between views), an important factor influencing user performance. This paper compares the above methods in terms of their ability to support mental registration. Empirical results show that mental registration is significantly easier with inplace displays than with ExoVis, and significantly easier with ExoVis than with orientation icons. Different mental transformation strategies can explain this result. The results suggest that ExoVis may be a better alternative to orientation icons when inplace displays are not appropriate (e.g, when in-place methods hide data or cut the 3D view into several pieces).</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Both 2D and 3D visualization strategies have value for tasks involving 3D spatial data. Each strategy is appropriate for different tasks. <ref type="bibr" target="#b12">Springmeyer et al. [1992]</ref> observed that 2D views are often used to establish precise relationships, whereas 3D views are typically used to gain a qualitative understanding of the data and present that understanding to others.</p><p>For example, radiologists typically view 3D medical scans as sets of 2D slices to see all the details. They may also use a 3D view (e.g., an isosurface <ref type="bibr" target="#b5">[Lorensen and Cline 1987]</ref> or direct volume rendered image <ref type="bibr" target="#b9">[Schroeder et al. 1998</ref>]) to gain an overall qualitative picture of the data, to explain their findings to other physicians, or to place slicing planes in non-standard orientations. Similarly, parts of a CAD model near the front can occlude parts at the back. For this reason, CAD models are usually displayed from several viewpoints at once, often from three standard orthogonal directions (2D orthographic views) plus one or more oblique viewpoints (to give an impression of 3D structure).</p><p>In general, 3D (perspective) displays are good for gaining an overview of a 3D space, understanding 3D shape, and navigating approximately in 3D. 2D views (i.e., slices or orthographic projections) are good for reducing occlusion, since slices through the middle of a volume can be viewed directly, and navigating or measuring distances precisely, since there is no depth ambiguity.</p><p>Since both 3D and 2D display strategies are valuable, many visualization tasks may benefit from integrating both 2D and 3D views into a single display. For example, imagine placing the cursor at an exact position in 3D space to specify a region of interest, segment a data set, position a 3D object, or find the data value(s) at that location. A 3D view may be useful to get a general idea of the current cursor position and move the cursor close to the target. A 2D view may then be valuable for fine-grained movement to place the cursor precisely at the target location. Surprisingly, although displaying both 2D and 3D views is becoming more common, little research to compare and evaluate different methods of combining 2D and 3D views has been done. Several methods are possible, specifically in-place methods (e.g., clip planes), orientation icons (i.e., completely separate 2D and 3D views), and ExoVis <ref type="bibr" target="#b16">[Tory and Swindells 2003</ref>]. Which of these methods is best? How will users know which one to choose for a given situation? Our research addresses these issues.</p><p>One important difference between 2D/3D display techniques is how easily users can relate and integrate information from different views. Users must understand relationships between views to make sense of the data. Mental registration can be defined as a mental transformation in which two or more views of the same data are aligned spatially. For example, an x-y slice of a volume can be mentally registered with a y-z slice by mentally rotating 90° around the y-axis. Mental registration can be challenging and requires cognitive resources <ref type="bibr" target="#b6">[Osborn and Agogino 1992;</ref><ref type="bibr" target="#b8">Pillay 1994</ref>]. Since mental registration is performed very often in multiview systems, displays should be designed to make it easy. One factor affecting the difficulty is the method of combining 2D and 3D views. This study investigates mental registration difficulty for different 2D/3D displays and proposes reasons for the differences. The displays are considered generically so that the results are applicable to many visualization domains.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Methods to Combine 2D and 3D Views</head><p>Three basic approaches for combining 2D slice views with a 3D view are contrasted in <ref type="figure" target="#fig_2">Fig. 1</ref>. <ref type="bibr">IEEE Visualization 2003</ref><ref type="bibr">, October 19-24, 2003</ref>, Seattle, Washington, USA 0-7803-8120-3/03/$17.00 ©2003 IEEE Clip planes show slices in their correct position relative to the 3D view (i.e., the slice is "in-place"), so mental registration should be trivial. However, a clip plane removes all data between itself and the viewer (see <ref type="figure" target="#fig_2">Fig. 1 a)</ref>. Thus, to show a slice deep within a volume, most of the 3D information is removed. The "planar brush" <ref type="bibr" target="#b17">[Wong and Bergeron 1997</ref>] also shows a cross-section "inplace". Although it does not remove sections of the 3D view, the 3D view is limited to an outline or semi-transparent surface. Another alternative to the clip plane is to open up a volume along a cutting plane <ref type="bibr" target="#b0">[Carpendale et al. 1999;</ref><ref type="bibr" target="#b1">Cowperthwaite 2000;</ref><ref type="bibr" target="#b4">Kurzion and Yagel 1997]</ref>, as illustrated in <ref type="figure" target="#fig_2">Fig. 1b</ref>. Here, 3D view information is pushed aside but not removed.</p><p>ExoVis essentially does the reverse of the cutting plane: the 3D view remains in the centre of the display and slice details are shown in the surroundings (see <ref type="figure" target="#fig_2">Fig. 1d</ref>). For a detailed introduction to ExoVis, see <ref type="bibr" target="#b16">[Tory and Swindells 2003</ref>].</p><p>In the orientation icon (OI) approach, 2D and 3D views are shown in separate windows <ref type="figure" target="#fig_2">(Fig. 1c)</ref>. The 3D view acts as an "orientation icon", helping users understand positions of the 2D views. Both orientation icons and ExoVis separate 2D and 3D views (i.e., the 2D details are "out-of-place"). However, ExoVis slices remain in their correct orientation relative to the 3D view (i.e., they are simply translated from their original position), whereas orientation icon slices are both translated and rotated from their original location. For this reason, mental registration of 2D and 3D views is expected to be easier with ExoVis than with the orientation icon.</p><p>For "out-of-place" techniques (orientation icons and ExoVis), "placeholders" within the 3D view indicate the positions and orientations of 2D slices. Placeholders are shown as semitransparent grey planes in <ref type="figure" target="#fig_2">Fig. 1 (c and d)</ref>.  Orthographic 2D views do not have positions within the 3D object so the in-place approach does not apply. Orientation icon and ExoVis methods are possible. Placeholders may be used to indicate the position of view planes relative to the 3D view; however, placeholders are less important than for slice views since only the plane's orientation (not its depth) is important. <ref type="figure" target="#fig_1">Fig. 2</ref> illustrates the orientation icon method of combining a 3D view with several 2D orthographic views (without placeholders). With ExoVis, 2D and 3D views are shown in the same window and are not rotated relative to each other, as shown in <ref type="figure" target="#fig_3">Fig. 3</ref>.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Comparisons of 2D/3D Displays</head><p>Although many studies have compared 2D and 3D displays for various tasks (e.g., <ref type="bibr" target="#b2">[Haskell and Wickens 1993;</ref><ref type="bibr" target="#b7">Park and Woldstad 2000;</ref><ref type="bibr" target="#b13">Smallman et al. 2001]</ref>), few have considered 2D/3D combination displays or how to best create them. <ref type="bibr" target="#b14">[St. John et al. 2001</ref>] compared (1) 3D views, (2) 2D views, and (3) a side-by-side combination of 2D and 3D views for a 3D route planning task. Time to complete the task was fastest with the side-by-side (i.e., orientation icon) display, indicating that combinations of 2D and 3D views are valuable. However, St. John et al. only looked at orientation icon displays and therefore did not consider the question of how to best combine 2D and 3D views.</p><p>In <ref type="bibr" target="#b16">[Tory and Swindells 2003</ref>], we heuristically compared orientation icon, ExoVis, and in-place techniques. We showed that ExoVis balances trade-offs of the other methods. In-place methods have advantages in terms of screen space and ease of relating different views, but they have limited flexibility. Thus, in-place methods are best for simple displays (e.g., to compare only a few slices, data sets, or transfer functions). Orientation icons offer flexibility (e.g., it is possible to display any combination of slices as well as multiple data sets and rendering styles). Orientation icons are also valuable if the task prohibits viewing slices obliquely, or if there are many 2D views (since many 2D views may be displayed without occlusion). However, mentally relating the views can be challenging. ExoVis offers similar flexibility to orientation icons, but 2D views are usually displayed obliquely. We hypothesized that ExoVis allows easier mental registration of the views because mental rotation is not required. This hyopthesis has not been previously testedclassic mental rotation studies (e.g., <ref type="bibr" target="#b10">[Shepard and Metzler 1971]</ref>) have not considered rotating 2D slices and projections relative to 3D views. Hence, in this paper we test our mental registration hypothesis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Study Scope and Objectives</head><p>This study is part of a larger research program investigating 2D/3D combination displays. The overall objective is to determine which 2D/3D display techniques best support specific visualization tasks (e.g., place a clipping plane, search for a target, determine spatial relationships, etc.). Our research is being done in several parts: 1. Heuristically compare the methods to come up with some hypotheses about when each technique is useful (accomplished in <ref type="bibr" target="#b16">[Tory and Swindells 2003]</ref>).</p><p>2. Refine the hypotheses generated in step 1 by testing the following assumption: Mentally registering 2D and 3D views is substantially more difficult with some 2D/3D displays than with others (addressed in this paper).</p><p>3. Test the hypotheses from steps 1 and 2 by comparing user performance at real visualization tasks with different 2D/ 3D combination display types (future work).</p><p>Specific objectives of this mental registration study are to:</p><p>1. Determine the relative cost (in time and difficulty) of mentally registering one 2D and one 3D view when (a) They are spatially separated from one another (as with both ExoVis and orientation icons), and (b) The 2D reference (placeholder) and 2D view have different orientations (as with orientation icons).</p><p>2. Determine how this cost varies with orientation of the 2D view (top, right, or front aligned 2D views).</p><p>3. Determine whether this cost is different for 2D orthographic projections as compared with 2D slices.</p><p>Although the eventual goal is to study complex situations (e.g., many different 2D views, data sets, etc.), the current study is limited to one 2D and one 3D view and only top, front, and right 2D view orientations. This allows us to isolate the factor of interest (mental registration) and avoids complicating the analysis with a large number of variables. Also, axis-aligned 2D views are very common in many applications. Future studies with more complex visualization tasks will consider more complex displays.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Method</head><p>Two experiments compared 2D/3D mental registration difficulty for different display types. Experiment 1 considered 2D orthographic projections and Experiment 2 considered 2D slices. Independent variables were display type (orientation icon, inplace, or ExoVis) and 2D view orientation (parallel to the top, right, or front of the object). Dependent variables were time, accuracy, and subjective ratings of difficulty.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Tasks</head><p>Subjects mentally registered 2D and 3D views of a block shape to identify a corresponding part. Specifically, subjects were shown one 3D view and one 2D view, combined using cutting planes, ExoVis, or orientation icon methods. Block shapes consisted of small cubes "glued together" to form a larger structure. In the 3D view, one cube was red and all others were grey. In the 2D view, all cubes were grey, and five of the cubes contained a unique uppercase letter (from A to E). Subjects identified the letter that corresponded to the red cube. The number of possible answers was limited to five to ensure all trials had the same number of possible answers. Example tasks from the slice and orthographic experiments are shown in <ref type="figure" target="#fig_5">Fig. 4</ref> and   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.1">Control Tasks</head><p>A control task was designed to estimate time required for nonregistration parts of the task (i.e., moving the mouse and choosing an answer). Subjects observed two 3D views of a block shape. One view contained one red cube and the other view had unique letters on five of the cubes (see <ref type="figure" target="#fig_7">Fig. 6</ref>). Subjects identified the letter corresponding to the red block. This control task measured the time and difficulty of doing an identification task without mentally registering 2D and 3D views. It therefore provided a baseline. The control task was included in both experiments to allow results of the two experiments to be compared. We expected participants to perform similarly on control trials and in-place trials in the slice experiment, since neither task requires 2D/3D mental registration. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Stimuli</head><p>Block shapes were modeled in Trispectives Technical version 2.0. Following <ref type="bibr" target="#b11">[Shyi and Huang 1995]</ref>, the blocks were generated by removing 2, 5, or 8 cubes from a base shape containing 27 cubes (3 x 3 x 3). Example block shapes are shown in Figures 4, 5, and 6. Removal of cubes was constrained such that:</p><p>• The resulting object remained as a single connected component and was not allowed to lose its 3 x 3 x 3 structure (i.e., no 3 x 3 slab was completely removed).</p><p>• Blocks were removed contiguously from either one or two locations, but not from more than two locations.</p><p>• Few blocks were removed from the "back" of the object where the shape's geometry would be hidden. 1</p><p>All 3D views were rendered with isometric projection to make the figures appear as small objects (e.g., toys) viewed up close. 2D views for the orientation icon case were rendered from the top, right, and front sides of the object, following the North American CAD standard (third-angle projection).</p><p>Cube-based stimuli were chosen so the identification task could not be done without mentally registering the 2D and 3D views. Specifically, the target could not be identified by simply looking for a particular shape among other shapes. The <ref type="bibr" target="#b11">Shyi and Huang [1995]</ref> shapes were selected for the following reasons:</p><p>• The shapes have interesting contours in 2D orthographic views and slice views. Block figures such as those used in <ref type="bibr" target="#b10">[Shepard and Metzler 1971]</ref> do not have interesting contours on all 2D slices.</p><p>• The number of squares on the 2D views does not vary greatly. This equalizes the number of possible answers for each trial. This possible confounding factor was also reduced by having exactly five possible answers. For views with more than five cubes, some of the cubes did not contain a letter and could not be the correct answer (e.g., see the spaces without letters in figures 4, 5, and 6).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Front View</head><p>A total of 34 block shapes were created. 30 of these were used in the experimental trials. The other 4 were used in practice trials and documentation. In the experimental trials, subjects saw each block shape 3 times (experiment 1) or 4 times (experiment 2), but never more than once with the same 2D view orientation (front, right, or top). Each shape was shown exactly once with each display type so that the collection of shapes would not be a confounding variable.</p><p>Stimuli were presented as static images. For orientation icon trials of orthographic views, the 2D view orientation was given in a text label centered above the 2D view, as in <ref type="figure" target="#fig_6">Fig. 5 (top)</ref>. In all other trials, the 2D view orientation could be inferred from the orientation of the placeholder or the 2D view itself.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Participants</head><p>Participants were recruited from various levels of the computer science student population (from first year to graduate level) at Simon Fraser University. They were paid $10 (Cdn) for participating in a 30 minute experimental session. Each participant was randomly assigned to one of the two experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.1">Experiment 1: Orthographic Views</head><p>12 university students (6 male and 6 female) participated. Participants had varied experience with computer graphics. Ten participants were in the age group 19-25 and two were 26-35.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.2">Experiment 2: Slice Views</head><p>16 university students (8 male and 8 female) participated. Participants had varied experience with computer graphics. Eleven participants were in the age group 19-25, four were 26-35, and one was 36-45. Data from one participant was incomplete and is not included in the analysis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Experimental Set-Up</head><p>Custom experimental software was written in Java and run on a Pentium laptop computer with 160 MB of memory and 800 x 600 display resolution. No other processes were run on the computer during the experimental sessions. Subjects interacted with the computer using an external mouse. The keyboard was not used.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Procedure</head><p>In experiment 1, tasks were grouped into three display types: (A): orientation icon, (B) ExoVis, and (C) control task. In experiment 2, tasks were grouped into four display types: (A): orientation icon, (B) ExoVis, (C) control task, and (D) in-place (cutting plane).</p><p>Each subject completed all conditions in one of the two experiments. To prevent order effects, order of the conditions was counterbalanced using a Latin Squares design <ref type="bibr">[VassarStats]</ref>, and an equal number of males and females participated in each order. Conditions were referred to only by letter, not by name. For each condition, subjects completed 30 trials, 10 with each 2D view orientation (front, right, or top). Orientations were in pseudorandom order to prevent subjects from simply remembering the spatial relationship between 2D and 3D views from one trial to the next. The procedure for each condition was as follows:</p><p>1. Review instructional materials that explain the views that will be used in that condition. Review example trials with correct answers. Resolve any confusion about the task.</p><p>2. Complete nine practice trials, with help if necessary.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Complete thirty experimental trials.</head><p>The experimenter helped the subject through the first practice session to ensure the subject understood the task and how to operate the software. The subject was then left alone to complete the remaining tasks (because participants in a pilot experiment felt nervous and uncomfortable when they were watched <ref type="bibr" target="#b15">[Tory 2003</ref>]).</p><p>Subjects were instructed to be as accurate as possible, but were asked not to take a break during the middle of a trial since they were being timed. Taking a break between trials was permitted. Each trial began when the subject pressed a "Ready" button and ended when they clicked one of five buttons at the bottom of the screen (labeled "A", "B", "C", "D", or "E") to select their answer. No time limit was imposed. Answers could not be changed.</p><p>Subjects filled out a background questionnaire prior to the experimental trials. In a post-trial questionnaire, they rated the difficulty of performing the study task with each display type and view orientation. Participants were then invited to ask any questions or share any comments with the experimenter.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6">Measures</head><p>For each trial, the computer recorded the subject's response and start and end times. Total time and accuracy were computed after the experiment was completed. Subjects recorded self-reports of difficulty (on a 7-point rating scale) in the post-trial questionnaire. Subjects' comments were recorded by the experimenter.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Results</head><p>Our results were analyzed using classic statistical techniques. For the statistical details, see Appendix 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Timing Data</head><p>Figures 7 and 8 show average times to complete the trial task in the orthographic projection and slice view experiments. Mental registration is significantly more time consuming with orientation icon (OI) displays than with ExoVis displays, and is fastest with in-place displays and the control task.  As shown in <ref type="figure" target="#fig_8">Fig. 7</ref>, the task took 1.3 -1.5 times as long with OI displays compared to ExoVis (with 95% confidence). When compared to the control, the task took 1.5 -2.0 times as long for OI and 1.1 -1.4 times as long with ExoVis (with 97.5% confidence).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.1">Orthographic Projection Experiment</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.2">Slice View Experiment</head><p>As shown in <ref type="figure" target="#fig_10">Fig. 8</ref>, the slice view task took 1.3 -1.9 times as long for OI compared to ExoVis, 1.8 -3.4 times as long with OI compared to in-place, and 1.2 -2.0 times as long with ExoVis compared to in-place (with 95% confidence). OI and ExoVis were significantly different from the control task, but in-place was not.</p><p>Overall, the top orientation took significantly longer than the front. However, there was also an interaction between view orientation and display type. Time to complete the task varied with view orientation in the OI case, but was relatively constant with ExoVis. This trend can be clearly seen in <ref type="figure" target="#fig_10">Fig. 8</ref>.  <ref type="figure" target="#fig_11">Fig. 9</ref> shows the percent of incorrect answers. ExoVis displays had significantly fewer errors than orientation icon displays, and eliminated errors in top views, where they were most prevalent. There were no errors for the in-place or control conditions. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Errors</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Difficulty Ratings</head><p>Figures 10 and 11 show average difficulty ratings for the two experiments. The orientation icon condition was rated significantly more difficult than ExoVis, in-place, and control conditions. <ref type="figure" target="#fig_2">Figure 10</ref>: Average difficulty ratings for the orthographic view experiment. Average rating for the control task was 1.2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.1">Orthographic View Experiment</head><p>Overall, OI was rated 0.4 -1.9 points more difficult than ExoVis (with 95% confidence). Both test conditions were significantly harder than the control. In addition, there appeared to be a significant interaction between display type and orientation, such that difficulty increased with top views for the OI display, but not for ExoVis. However, note that the 99% confidence interval for the difference with the OI display (0.0 -1.5) includes zero, so it is possible there is no difference. <ref type="figure" target="#fig_2">Figure 11</ref>: Average difficulty ratings for the slice view experiment. Average rating for the control task was 1.6.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.2">Slice View Experiment</head><p>Overall, OI rated 1.1 -2.2 points harder than ExoVis and 1.0 -3.6 points harder than in-place displays (with 95% confidence). ExoVis was not significantly different from in-place or the control.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Discussion</head><p>Our experimental hypotheses were:</p><p>1. Mental registration would be easier with more integrated views. That is, we expected the best performance with in-place, second best with ExoVis, and worst with OI.</p><p>2. With the OI display, mental registration would be more difficult for top views than for front and right views (because a larger mental rotation <ref type="bibr">[Shepard and</ref> Metzler 1971] would be required). With ExoVis and in-place displays, mental registration difficulty would be the same for all view orientations.</p><p>The data strongly supports hypothesis 1. Timing, error, and rating data all agree that mental registration is easier with more integrated views. There is better performance with the in-place display than with ExoVis, and better performance with ExoVis than with the orientation icon. Difficulty ratings also agree with this hypothesis.</p><p>Clearly, in-place techniques support the easiest mental registration. However, they are not always appropriate. Clip planes hide large portions of the data and cutting planes can cut the 3D view into many pieces, making analysis difficult. A "planar brush" through a semi-transparent surface avoids cutting, but the 2D and 3D views overlap and occlude each other. ExoVis and OI techniques avoid these problems because views are separated. Thus, views can be moved, adjusted, and managed so they do not interfere with each other. For more details on this heuristic comparison and how multiple views can be arranged, see <ref type="bibr" target="#b16">[Tory and Swindells 2003</ref>].</p><p>This experiment indicates that ExoVis may be a good choice when in-place techniques cannot be used. Since the mental registration task with OI displays took at least 1.3 times (and possibly up to 1.9 times) as long as with ExoVis, orientation icons should only be used when specifically required. Examples might be for nonoblique viewing of 2D views (e.g., for judging whether lines are parallel) or to display a very large number of 2D views (since occlusion could then become a problem with ExoVis).</p><p>Support for hypothesis 2 is less clear. Timing in the slice experiment (and to some extent difficulty ratings in both experiments) indicate that mental registration with OI displays was most difficult with top views. With ExoVis and in-place displays, times and difficulty ratings did not vary significantly with view orientation. This difference can be explained if mental rotation is used to align the 2D and 3D views. In the OI condition, a larger mental rotation is required for top views than for front or right views, but with ExoVis, no mental rotation is needed. In addition, some subjects commented that with OI top views they could not remember whether to rotate the view left or right. Although it was not significant, front views were rated most difficult for orthographic ExoVis displays. The reason for this is unclear. It is possible that it is an artifact of the questionnaire; the example given for that condition may have been particularly difficult. On the other hand, this result may merit further investigation.</p><p>Comments by subjects indicate that they used two different strategies to complete the tasks: (1) a mental rotation strategy: the views were mentally rotated until they were aligned with one another and (2) a pattern matching strategy: unique features in one view were matched with features in the other. Subjects likely combined these two strategies, as suggested by <ref type="bibr" target="#b6">Osborn and Agogino [1992]</ref>. Mental rotation will always work if you can remember which way to rotate the view but feature matching can fail when there is symmetry in the 2D view. Feature matching may be easier with orthographic views than with slices because there are inner contour lines. It is therefore possible that a feature matching strategy was preferentially used for this condition. This could explain why there was no significant difference in timing between view orientations for the orthographic view experiment. Future experiments could verify this hypothesis.</p><p>Error analysis further supports the idea that two strategies were used. Most errors in OI displays appeared to be caused by mentally rotating the view in the wrong direction, mistaking the view orientation for a different orientation, or choosing the wrong side of a symmetric 2D view. ExoVis displays eliminated these common errors, leaving only occasional side-by-side errors (choosing a letter next to the correct letter on the 2D view).</p><p>In the slice experiment, the in-place and control conditions were not significantly different from each other, as expected. However, some subjects found the in-place display condition confusing because the task seemed too easy. Although the difference was not significant, this confusion may explain why the in-place condition was rated slightly more difficult than the control condition.</p><p>As a caveat to our experiment, notice that we always used orthographic (isometric) projection to project graphic scenes to the computer screen. Other types of projection (e.g., perspective) or no projection (i.e., objects in the real world) may yield slightly different results and could be interesting to study.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Conclusion and Future Work</head><p>This experiment establishes that mentally registering 2D and 3D views is easiest with in-place displays, hardest with orientation icons, and in-between for ExoVis. There is also an interaction between display type and 2D view orientation, such that difficulty sometimes varies with 2D view orientation for orientation icons, but stays relatively constant for in-place and ExoVis displays.</p><p>Although these differences are now clear, we should not assume that in-place displays are always best and orientation icon displays are worst. This experiment tested a low-level mental registration task and is only one step in a larger research project. Real visualization tasks require mental registration (when both 2D and 3D views are used), but also include many other mental and physical operations (search, navigation, measurement, hypothesis testing, etc.). Therefore, ease of mental registration is not the only important property of a display. Other important properties inlcude low occlusion levels and display flexibility, attributes somewhat lacking in in-place displays <ref type="bibr" target="#b16">[Tory and Swindells, 2003</ref>]. The next step in our research is to find more complex visualization tasks for which 2D and 3D displays are both useful, and then match those tasks to the most appropriate display types via further user studies.</p><p>Additional future work could consider task strategy. When 2D and 3D views are both available, when and how do people use them? Protocol analysis and/or eye-tracking may help answer this question. Future studies could also extend the work to determine when mental rotation and feature matching strategies are used, test different low-level tasks such as integrating information from multiple views, test mental registration experts (e.g., experienced CAD technicians), or consider non-spatial data sets.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>Orthographic 2D views are different from slice views since they are projections from the sides of an object (seeFigures 2 and 3).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Orientation icon display (separated 2D and 3D views) of a washing machine. Top right shows a 3D image. Other panes show front, right, and top orthographic projections.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 1 :</head><label>1</label><figDesc>Methods to combine 2D slice views with a 3D view. Examples show a slice through a Magnetic Resonance Imaging head scan. (a) Clip Plane (In-place) (c) Orientation Icon (Out-of-place) (d) ExoVis (Out-of-place) (b) Cutting Plane (In-place)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 :</head><label>3</label><figDesc>ExoVis display of a washing machine. Orthographic 2D views are projected onto planes surrounding the object.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>Fig. 5respectively.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 4 :</head><label>4</label><figDesc>Sample tasks: slice view experiment. Subjects identify the letter corresponding to the red block. Top: orientation icon. Bottom left: ExoVis. Bottom right: in-place. Correct answer is A.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 5 :</head><label>5</label><figDesc>Sample tasks: orthographic view experiment. Subjects identify the letter corresponding to the red block. Top: orientation icon. Bottom: ExoVis. Correct answer is D.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 6 :</head><label>6</label><figDesc>Sample control task. Subjects identify the letter corresponding to the red block. The correct answer is B.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 7 :</head><label>7</label><figDesc>Average trial times for the orthographic view experiment. Average time for the control was 2.2 seconds. OI = Orientation Icon.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 8 :</head><label>8</label><figDesc>Average times for the slice experiment. Average for the control was 2.2 seconds. OI = Orientation Icon, IP = In-place.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Figure 9 :</head><label>9</label><figDesc>Percent of incorrect responses in the two experiments, broken down by display type and 2D view orientation.</figDesc></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">. This constraint was added because (in a pilot study) complicated hidden geometry made the task more difficult<ref type="bibr" target="#b15">[Tory 2003</ref>].</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.">Acknowledgements</head><p>Thanks to Torsten Möller, Ted Kirkpatrick, Lyn Bartram, Stella Atkins, John Dill, and Colin Swindells for their suggestions, and to NSERC for funding.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix 1: Statistical Details</head><p>For testing significance, we used analysis of variance (ANOVA) and Bonferroni corrected t-tests. These are common ways to compare more than two means without increasing the probability of reaching the wrong conclusion. A large F or t value and a small p value indicate a significant result. A significance level of 0.05 was used. For the Bonferroni correction, this value was divided by the number of t-tests; the resulting significance level is reported in brackets. Repeated measures ANOVA was used because each subject was tested in all conditions. This test assumes sphericity of the data and requires a correction if this assumption is not met; we used the Huynh-Feldt correction when necessary. For an more detailed introduction to these statistical methods, see <ref type="bibr" target="#b3">[Huck 2000</ref>].</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Timing Data</head><p>Timing data was transformed using a natural logarithm (to improve its fit to a normal curve), and then analyzed using repeated measures ANOVA.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1">Orthographic Projection Experiment</head><p>(Refer to <ref type="figure">Fig. 7</ref>.) 2 X 3 ANOVA compared OI and ExoVis displays with three orientations. The sphericity assumption was met. ANOVA showed a main effect for display type (F(1, 11) = 49.0, p &lt; 0.001). Orientation and interaction between orientation and display were not significant.</p><p>Bonferroni-corrected (p &lt; 0.025) paired-samples t-tests showed significant differences between OI and control tasks (t = 9.8, p &lt; 0.001) and ExoVis and control tasks (t = 3.6, p = 0.004).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.2">Slice View Experiment</head><p>(Refer to <ref type="figure">Fig. 8</ref>.) 3 X 3 ANOVA compared orientation icon, ExoVis, and in-place displays with three view orientations. The Huynh-Feldt correction was used. ANOVA showed a main effect for display type (F(1.68, 23.53) = 44.1, p &lt; 0.001), a main effect for orientation (F(2, 28) = 11.9, p &lt; 0.001), and an interaction between display type and orientation (F(3.75, 52.5) = 6.1, p = 0.001). Pairwise comparisons showed that all display types were significantly different from each other ( ). The top orientation took significantly longer than the front (p = 0.001).</p><p>Bonferroni-corrected (p &lt; 0.01) paired-samples t-tests showed that orientation icon (t = 10.3, p &lt; 0.001) and ExoVis (t = 5.1, p &lt; 0.001) were significantly different from the control. In-place was not significantly different from the control (t = 2.8, p = 0.013). Additional t-tests help explain the interaction between display type and orientation. Top views took significantly longer than front views with the OI display (1.1 -1.5 times as long with 99% confidence, t = 4.7, p &lt; 0.001). However, front and top views were not significantly different with ExoVis (t = 1.3, p = 0.22). <ref type="figure">Fig. 9</ref>.) Because the error data was highly skewed, the nonparametric Wilcoxon test was chosen. This test is similar to a t-test, but does not assume a normal distribution of the data. In the orthographic view experiment, one-tailed Wilcoxon tests (Bonferroni-corrected; p &lt; 0.017) showed a significant difference between OI and control conditions (Z = 2.6, p = 0.005) and between OI and ExoVis conditions (Z = 2.2, p = 0.013). ExoVis was not significantly different from the control. In the slice experiment, pairwise one-tailed Wilcoxon tests (Bonferroni-corrected; p &lt; 0.008) showed that the OI condition was significantly different from all other conditions (Z = 2.7, p = 0.004). ExoVis and in-place conditions were not significantly different from each other or the control.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Errors (Refer to</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Difficulty Ratings</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Orthographic View Experiment</head><p>(Refer to <ref type="figure">Fig. 10.)</ref> 2 X 3 ANOVA compared orientation icon and ExoVis displays with three view orientations. Assumptions about sphericity were met. ANOVA showed a main effect for display type (F(1, 11) = 11.2, p = 0.007) and an interaction between display type and orientation (F(2, 22) = 3.0, p = 0.004). Bonferroni-corrected (p &lt; 0.013) paired-samples t-tests showed that orientation icon (t = 5.8, p &lt; 0.001) and ExoVis (t = 4.2, p = 0.002) were significantly different from the control.</p><p>Additional t-tests help explain the interaction between display type and orientation. It appears that perceived difficulty increases with top views for OI displays and for front views with ExoVis (see <ref type="figure">Fig. 10</ref>). The p-values showed a significant difference between front and top orientations with the OI display (t = 3.0, p = 0.012) but not with ExoVis (t = 2.2, p = 0.054). However, the 99% confidence interval for the difference with the OI display (0.0 -1.5) includes zero, so it is possible there is no difference.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Slice View Experiment</head><p>(Refer to <ref type="figure">Fig. 11.)</ref> 3 X 3 ANOVA compared OI, ExoVis, and in-place displays with three view orientations. The Huynh-Feldt correction was used. ANOVA showed significant main effects for display type (F(1.34, 18.81) = 16.3, p &lt; 0.001) and view orientation (F(1.81, 25.36) = 4.1, p = 0.031). Pairwise comparisons showed (with 95% confidence) that OI rated 1.1 -2.2 points higher than ExoVis and 1.0 -3.6 points higher than in-place displays ( ). ExoVis was not significantly different from in-place. Bonferroni-corrected (p &lt; 0.01) paired-samples t-tests showed that the control was significantly different from OI (t = 6.6, p &lt; 0.001) but not significantly different from ExoVis or in-place displays. p 0.001 ≤ p 0.001 ≤</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">The tardis: A visual exploration environment for landscape dynamics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">S T</forename><surname>Carpendale</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">J</forename><surname>Cowperthwaite</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Tigges</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Fall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">D</forename><surname>Fracchia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Visual Data Exploration and Analysis VI, SPIE</title>
		<meeting>Visual Data Exploration and Analysis VI, SPIE</meeting>
		<imprint>
			<date type="published" when="1999" />
			<biblScope unit="volume">3643</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Occlusion Resolution Operators for Three-Dimensional Detail-In-Context. Ph.D thesis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">J</forename><surname>Cowperthwaite</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000" />
		</imprint>
		<respStmt>
			<orgName>Simon Fraser University</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Two-and Three-Dimensional Displays for Aviation: A Theoretical and Empirical Comparison</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">D</forename><surname>Haskell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">D</forename><surname>Wickens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Aviation Psychology</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="87" to="109" />
			<date type="published" when="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">W</forename><surname>Huck</surname></persName>
		</author>
		<title level="m">Reading Statistics and Research</title>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Addison Wesley Longman</publisher>
			<date type="published" when="2000" />
		</imprint>
	</monogr>
	<note>3rd ed</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Interactive Space Deformation with Hardware-Assisted Rendering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Kurzion</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Yagel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer Graphics and Applications</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="66" to="77" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lorensen W</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Cline H</surname></persName>
		</author>
		<title level="m">Marching Cubes: A High Resolution 3D Surface Construction Algorithm. Computer Graphics (Proc. SIGGRAPH)</title>
		<imprint>
			<date type="published" when="1987" />
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="163" to="169" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">An Interface for Interactive Spatial Reasoning and Visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">R</forename><surname>Osborn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">M</forename><surname>Agogino</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CHI</title>
		<meeting>CHI</meeting>
		<imprint>
			<date type="published" when="1992" />
			<biblScope unit="page" from="75" to="82" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Multiple Two-Dimensional Displays as an Alternative to Three-Dimensional Displays in Telerobotic Tasks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">H</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">C</forename><surname>Woldstad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Human Factors</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="page" from="592" to="603" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Cognitive load and mental rotation: structuring orthographic projection for learning and problem solving</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">K</forename><surname>Pillay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Instructional Science</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="91" to="113" />
			<date type="published" when="1994" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Schroeder</forename><forename type="middle">W</forename><surname>Martin K</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Lorensen</surname></persName>
		</author>
		<title level="m">The Visualization Toolkit</title>
		<meeting><address><addrLine>New Jersey</addrLine></address></meeting>
		<imprint>
			<publisher>Prentice Hall PTR</publisher>
			<date type="published" when="1998" />
		</imprint>
	</monogr>
	<note>2nd ed</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Mental rotation of three-dimensional objects</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">N</forename><surname>Shepard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Metzler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">171</biblScope>
			<biblScope unit="page" from="701" to="703" />
			<date type="published" when="1971" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Constructing Three-Dimensional Mental Models From Viewing Two-Dimensional Displays</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">C W</forename><surname>Shyi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">T T</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Chinese J. of Psychology</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="101" to="122" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">A Characterization of the Scientific Data Analysis Process</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">R</forename><surname>Springmeyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">M</forename><surname>Blattner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">L</forename><surname>Max</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Visualization</title>
		<meeting>IEEE Visualization</meeting>
		<imprint>
			<date type="published" when="1992" />
			<biblScope unit="page" from="235" to="242" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Information Availability in 2D and 3D Displays</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Smallman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>John</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Oonk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Cowen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer Graphics and Applications</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="51" to="57" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Tactical Routing Using Two-Dimensional and Three-Dimensional Views of Terrain</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>St</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>John</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">S</forename><surname>Smallman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">E</forename><surname>Bank</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">B</forename><surname>Cowen</surname></persName>
		</author>
		<idno>1849</idno>
		<imprint>
			<date type="published" when="2001" />
		</imprint>
		<respStmt>
			<orgName>SSC San Diego Technical Reports</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Mental Registration of 3D Views and 2D Orthographic Views in Orientation Icon Displays</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Tory</surname></persName>
		</author>
		<idno>SFU-CMPT- TR2003-02</idno>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
		<respStmt>
			<orgName>Simon Fraser University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Comparing ExoVis, Orientation Icon, and In-Place 3D Visualization Techniques</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Tory</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Swindells</surname></persName>
		</author>
		<ptr target="http://faculty.vassar.edu/lowry/lsqtext.html" />
	</analytic>
	<monogr>
		<title level="m">Proc. Graphics Interface</title>
		<meeting>Graphics Interface</meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="57" to="64" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Brushing Techniques for Exploring Volume Datasets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">C</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Bergeron</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Visualization</title>
		<meeting>IEEE Visualization</meeting>
		<imprint>
			<date type="published" when="1997" />
			<biblScope unit="page" from="429" to="432" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
