<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/pisenberg/grobid/grobid-0.6.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main"></title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoqiang</forename><surname>Zheng</surname></persName>
							<email>zhengxq@cse.ucsc.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Computer Science Department</orgName>
								<orgName type="institution">University of California</orgName>
								<address>
									<postCode>95064</postCode>
									<settlement>Santa Cruz</settlement>
									<region>CA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Pang</surname></persName>
							<email>pang@cse.ucsc.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Computer Science Department</orgName>
								<orgName type="institution">University of California</orgName>
								<address>
									<postCode>95064</postCode>
									<settlement>Santa Cruz</settlement>
									<region>CA</region>
								</address>
							</affiliation>
						</author>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2021-02-19T20:53+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>I.3.6 [Computer Graphics]: Methodology and Techniques-Interaction Techniques; hyperstreamlines</term>
					<term>LIC</term>
					<term>symmetric tensors</term>
					<term>anisotropy</term>
					<term>animation</term>
					<term>direct volume rendering</term>
				</keywords>
			</textClass>
			<abstract>
				<p>We introduce a new method for visualizing symmetric tensor fields. The technique produces images and animations reminiscent of line integral convolution (LIC). The technique is also slightly related to hyperstreamlines in that it is used to visualize tensor fields. However, the similarity ends there. HyperLIC uses a multi-pass approach to show the anisotropic properties in a 2D or 3D tensor field. We demonstrate this technique using data sets from computational fluid dynamics as well as diffusion-tensor MRI.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Tensor data is useful in many medical, mechanical and physical applications. Second order tensors in 3D is a 3x3 matrix that contains nine unique quantities, or six for the case of real symmetric tensors.</p><p>To help comprehend such a large volume of information remains a difficult challenge for visualization research.</p><p>In this paper, we introduce a new method for visualizing symmetric tensor fields. It works on 2D tensor fields in 2D manifolds or 3D tensor fields in 3D manifolds. 3D tensor data in 2D manifolds have to be projected to the manifolds using the tensor transformation and projection introduced later in this paper. The visualizations are specially good at showing the anisotropy in the tensor fields and the resulting images resemble those of LIC. Similar to LIC, a white noise texture is needed. Conceptually, every pixel in the resulting visualization is calculated using an area (or volume, for 3D) averaged noise texture. The shape of the area (or volume) is determined by the local tensor field. Carrying this process out on a point by point basis will result in a blurred image as this is akin to low pass filtering. A better strategy is to think of the process as placing primitives such as squares or circles in 2D, cubes or spheres in 3D, along the path of a hyperstreamline. These primitives are deformed by the tensor field, and the resulting swept area or volume identifies the parts of the noise texture that will contribute to the intensity of a pixel or voxel.</p><p>What we are seeing in the HyperLIC visualizations is the anisotropy in the tensor field. Anisotropy in 3D tensor fields can be classified into three types: (a) linear or highly anisotropic characterized by the dominance of one eigenvalue, (b) planar characterized by two roughly equal eigenvalues, and (c) spherical or isotropic characterized by three roughly equal eigenvalues. HyperLIC is particularly good at distinguishing between linear and spherical tensor regions because of the strong contrast between the sharp and smooth features respectively. Planar tensor regions do not stand out as dramatically compared to these two when viewed from different directions.</p><p>Digital images and animations can be accessed online at: www.cse.ucsc.edu/research/avis/hyperlic.html.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK</head><p>We review several classic and recent works that are related to this paper in one way or another. These are: hyperstreamlines <ref type="bibr" target="#b2">[Delmarcelle and Hesselink 1993]</ref>, adaptive filtering of noise fields <ref type="bibr" target="#b6">[Sigfridsson et al. 2002]</ref>, oriented tensor reconstruction <ref type="bibr" target="#b7">[Zhukov and Barr 2002]</ref>, direct volume rendering of diffusion tensors <ref type="bibr" target="#b5">[Kindlmann et al. 2000]</ref>, and line integral convolution <ref type="bibr" target="#b1">[Cabral and Leedom 1993]</ref>.</p><p>Hyperstreamlines were introduced by Delmarcelle and Hesselink in 1993. A tensor field is first decomposed into three eigenvector fields. Hyperstreamlines are essentially streamlines constructed from one of the eigenvector fields. The other two eigenvector fields are then encoded as changes in the cross section along the streamline. From any seed point, three hyperstreamlines can be generated using one of the three eigenvector fields for the streamlines and the other two for the cross section. In this sense, the technique does not provide a global view and users need to mentally fill in what is happening with the tensor field even in the vicinity of the seed point. Like streamlines, one cannot seed too many hyperstreamlines as clutter becomes an issue. For non-symmetric tensors, the rotational components are encoded as "wings" along the main hyperstreamlines. HyperLIC is similar to how hyperstreamlines handle the symmetric portion of the tensor field in the following manner -the volume swept out by a hyperstreamline roughly corresponds to the volume of the noise texture used by HyperLIC to calculate the intensity value at the seed point.</p><p>This brings us to the LIC algorithm for visualizing vector fields, introduced by Cabral and Leedom in 1993. Given an input vector field and a noise texture with the same dimensions, a LIC image is generated by calculating a streamline at each point, and then calculating a weighted average of the noise textures along the streamline, to produce the intensity value at the seed point. Interrante has extended LIC to 3D and presented ways to visualize flow within the 3D volume <ref type="bibr" target="#b3">[Interrante and Grosch 1997]</ref>. HyperLIC is similar to LIC in that it calculates a weighted average of noise texture values along a streamline. However, instead of simply using noise texture values along the streamline, we use noise texture values in the vicinity of the streamline as well. This local vicinity is defined by how tensors along the streamline deform the space around it. Specifically, unlike hyperstreamlines which uses only one of the eigenvector fields at a time to integrate streamlines, HyperLIC uses <ref type="bibr">IEEE Visualization 2003</ref><ref type="bibr">, October 19-24, 2003</ref>, Seattle, Washington, USA 0-7803-8120-3/03/$17.00 ©2003 IEEE both (2D) or all three (3D) eigenvector fields to define the local deformation space.</p><p>More recently, <ref type="bibr" target="#b6">[Sigfridsson et al. 2002]</ref> introduced an algorithm for visualizing symmetric tensor fields by iteratively applying an adaptive filter to directionally smear a noise texture in the frequency domain. Several discrete predefined directional filters are employed to categorize the continuous tensor anisotropy. However, the discretization of the filter orientation may be a potential drawback. If an anisotropic linear tensor falls in between a pair of oriented filters, it can only be described by their joint effects. Because of this, some contrast is lost in the result.</p><p>Recently, attention has focused on how to visualize diffusion tensor MRI images. One of the challenges is how to deal with the noisy nature of the tensor field particularly when tracing neural pathways <ref type="bibr" target="#b7">[Zhukov and Barr 2002]</ref>. Tracing essentially involves integrating a streamline using the principal eigenvector. In that method, moving least square regularization successfully overcame the noise problem and the relatively coarse grid used in the data set. Similar to hyperstreamlines, seeding is an issue that needs to be addressed in a more general fashion. Since the neural pathway tracing was to highlight regions of high anisotropy, seeds were naturally initiated where the linear tensors were high. Like hyperstreamlines, the method provides crisp visualization of streamlines along an eigenvector, but does not provide a continuous, global view of the tensor field.</p><p>One approach that does attempt to provide a continuous global view is the adaptation of direct volume rendering to tensor fields presented by <ref type="bibr" target="#b5">[Kindlmann et al. 2000]</ref>. Like <ref type="bibr" target="#b7">[Zhukov and Barr 2002]</ref>, the tensor field is first analyzed with respect to its anisotropy and classified into three continuous categories: linear (anisotropic), planar, and spherical (isotropic) tensors. This property of the tensor field is then used as barycentric coordinates of a triangular transfer function that highlights regions of different anisotropic properties. Further enhancements are then provided using lit-tensors mixed with opacity gradient shading and hue-balls combined with deflection mapping <ref type="bibr" target="#b4">[Kindlmann and Weinstein 1999]</ref>. The deflection mapping strategy seems to provide the most dramatic results, but would also depend on the granularity of the textures used.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">METHODS</head><p>In this section, we present the basic idea behind the HyperLIC algorithm, and show how it is refined to provide a more continuous representation of the anisotropy in the tensor field. This is followed by a description of how HyperLIC is actually implemented as a more efficient multi-pass approach. The descriptions are first presented for 2D tensor fields. Subsequent discussions present how the multipass algorithm can be easily extended to 3D. Other issues such as how to deal with sign indeterminacy, animation, and rendering of 3D HyperLIC results are presented in this section as well.</p><p>Before we describe HyperLIC in detail, we introduce some preparatory transformations on the data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Tensor Processing</head><p>Some preprocessing may be necessary to prepare the data for the HyperLIC algorithm. Examples include: if the data is defined in a curvilinear grid or if there is distinction between computational and physical coordinate systems; a 2D manifold is to be extracted from a 3D tensor field; or a sharper contrast is desired from the HyperLIC algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.1">Tensors in Curvilinear Grids</head><p>It is quite common for computational fluid dynamics applications to distinguish between computational space and physical space. For example, if we want to study the tensors on a wing geometry, this would correspond to a slice in computational space. Alternatively, one may want to study the tensors on a slice through physical space. In either case, 3D tensors need to be projected onto a surface. This surface can be expressed as S <ref type="bibr">(u, v)</ref>, where u and v are computational coordinates. We also need to find a transformation between tensors in physical and computational spaces. Let the three principal axes be: Q 1 = ∂S ∂u , Q2 = ∂S ∂v and Q3 = Q1 × Q2. Also define:</p><formula xml:id="formula_0">W =   Q1x Q2x Q3x Q1y Q2y Q3y Q 1z Q 2z Q 3z  </formula><p>( <ref type="formula">1)</ref>Assume the tensor is represented as P in physical space and represented as C in computational space. We want both P and C to transform a unit sphere in their own space, Sp and Sc respectively, into the same ellipsoid in physical space. Because Sp and Sc are both unit spheres, Sp = R • Sc, where R is a unitary matrix such that R T • R = I. This can be expressed as:</p><formula xml:id="formula_1">P • Sp = P • R • Sc (2) P • Sp = W • C • Sc (3)</formula><p>where we obtain</p><formula xml:id="formula_2">P • R = W • C<label>(4)</label></formula><p>and solving for C</p><formula xml:id="formula_3">C = W −1 • P • R = P OLARS(W −1 • P )<label>(5)</label></formula><p>where P OLARS(X) is the symmetric part of X in a polar decomposition. This transformation guarantees that C in computational space has the same effect as P in physical space. The justification for the transformation above is because a matrix M can always be represented as the product of a symmetric matrix T s and a unitary matrix R.</p><formula xml:id="formula_4">M = Ts • R<label>(6)</label></formula><p>And if the transformation matrix W between the physical space and the computational space is unitary, the transformed tensor C from Equation 5 is the same as that from a classical tensor transformation. When W is not unitary, a tensor resulting from a classic transformation may be asymmetric, while the tensor from Equation 5 is always symmetric.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.2">Tensor Projection</head><p>Once the tensor is in the computational space, we need to project it onto the surface, S(u, v). The first two axes, Q 1 and Q2 are on the surface while Q3 is perpendicular to this surface. So we discard all the components associated with Q3, which results in:</p><formula xml:id="formula_5">C2 = C11 C12 C21 C22<label>(7)</label></formula><p>where C2 is now a 2 × 2 tensor. Through this projection, a planar tensor along the surface is expressed as a 2D tensor without loss of information. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.3">Tensor Normalization and Rescaling</head><p>Tensor normalization and rescaling allow us to vary the contrast level of the resulting image. Before normalization, we define the largest absolute eigenvalue of a tensor as its magnitude which we denote by l. The eigenvector associated with the largest absolute eigenvalues is defined as the principal axis of a tensor. For all the tensors, we multiply them with the inverse of their magnitude, 1/l. This normalizes the largest absolute eigenvalues of all tensors to 1. We allow the user to rescale the tensor according to a user specified contrast parameter n as follows:</p><formula xml:id="formula_6">T r = T n<label>(8)</label></formula><p>where T and Tr are the original and rescaled tensors respectively. The exponentiation operation is that defined on matrices. For a general tensor T with eigenvector matrix E and diagonal eigenvalue matrix diag(λ1, λ2, λ3), the above equation can also be written as:</p><formula xml:id="formula_7">Tr = E • diag(λ n 1 , λ n 2 , λ n 3 ) • E −1 (9)</formula><p>where the contrast parameter n can be any real number. The eigenvector matrix E is constructed by columns and all eigenvector are normalized to unity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Basic Idea</head><p>Prior to visualizing the symmetric tensor fields, they are first decomposed into orthogonal eigenvector fields: E = {e1, e2, e3}. The corresponding eigenvalues are:</p><formula xml:id="formula_8">Λ = {λ1, λ2, λ2}.</formula><p>The basic idea of the 2D HyperLIC algorithm is as follows: given a 2D symmetric tensor field and an input noise field, a geometric primitive is placed over each location. This primitive is going to be deformed by the tensor field. Using the deformed primitive at each location, the noise texture values under each deformed primitive are averaged together to give the pixel value of the resulting image. This procedure is similar to the DDA algorithm described in <ref type="bibr" target="#b1">[Cabral and Leedom 1993]</ref> where the noise texture under each vector line glyph is used to calculate pixel intensities. When this process is carried out over tensor fields (as opposed to vector fields), the anisotropic properties of the underlying tensor field are revealed.</p><p>We experimented with two types of geometric primitives. The first type is a circle. In general, tensors deform circles to ellipses. An advantage of this primitive is that we do not need to decompose the tensor into component eigenvectors. Circles work best in regions with isotropic tensors. In areas with linear tensors, the resulting textures have very sharp contrast which tend to obscure the orientation of the tensors in the local neighborhood.</p><p>The second type of primitive is a square, oriented over each tensor so that the sides are aligned with the orthogonal eigenvectors - hence the need to first find the eigenvectors. The tensor deformation of these eigenvector aligned squares results in rectangles as shown in <ref type="figure" target="#fig_0">Figure 1</ref>. The scaling factors are simply the eigenvalues. Since we have normalized and rescaled the tensor so that its largest absolute eigenvalue is always 1, the longest side of the sampling strip is always a constant. We choose the size of the squares as 1/25 of the image dimension.</p><p>In regions with purely linear tensors, the square primitives are reduced to line segments and hence produce results similar to the DDA algorithm. In regions with isotropic tensors, HyperLIC is reduced to a smoothing algorithm, which averages the input texture within a local region. It produces a blurred image without sense of directions. In summary, HyperLIC maps the anisotropic properties of tensors to sharp and blurred regions in the resulting image.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Conceptual Algorithm</head><p>In LIC, the DDA is carried one step further, where the noise texture is integrated over the streamline rather than just a straight line segment <ref type="bibr" target="#b1">[Cabral and Leedom 1993]</ref>. This allows one to capture more subtle features and improve contrast. This enhancement can be carried out with HyperLIC in the following fashion: One of the eigenvector fields is selected to generate a hyperstreamline using N integration steps. This hyperstreamline acts as a skeleton of the texture sampling region. Next, we draw hyperstreamlines using the other eigenvector at each of the N points along the first hyperstreamline. As shown in <ref type="figure" target="#fig_1">Figure 2</ref>, these two steps create a sampling strip along the first hyperstreamline.</p><p>Where the tensors are highly linear, the sampling strip is essentially the primary hyperstreamline and HyperLIC reduces to LIC. With isotropic tensors, this sampling strip forms a square which acts a smoothing filter on the input image. This improved algorithm works better than its basic version just as LIC works better than the DDA version.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Multi-pass Approach</head><p>While the conceptual algorithm captures subtle details of the underlying tensor fields, it is also much more expensive than LIC. This is because for each pixel, HyperLIC needs to create a 2D integration area as opposed to 1D in LIC. Here, we describe a multi-pass approach that accelerates the computation of HyperLIC.</p><p>Let P be a point in the tensor field, In be the input noise texture image, and Io be the output HyperLIC image. Then, an output pixel is defined as:</p><formula xml:id="formula_9">Io(P ) = N i=−N N j=−N k(i, j)In(Pi,j) N i=−N N j=−N k(i, j) (10) P i,j = P i−1,j + λ 1 (P i−1,j )e 1 (P i−1,j )∆t (11) P0,j = P0,j−1 + λ2(P0,j−1)e2(P0,j−1)∆t (12) P0,0 = P (13)</formula><p>where λn(X), en(X), k(i, j), n = 1, 2 are the nth eigenvalues, eigenvectors and the weight function at point X. ∆t is the integration step. In our experiment, the joint kernel function k(i, j) is defined as the product of two kernel functions k1(i) and k2(j). k1 and k2 are constant for static images, and are defined in Equation 20 for animation sequences. If we define I 1(P ) as:</p><formula xml:id="formula_10">I1(P ) = N j=−N k2(j)In(Pj) N j=−N k2(j)<label>(14)</label></formula><formula xml:id="formula_11">Pj = Pj−1 + λ2(Pj−1)e2(Pj−1)∆t (15) P0 = P<label>(16)</label></formula><p>then, Io(P ) can also be expressed as:</p><formula xml:id="formula_12">Io(P ) = N i=−N k1(i)I1(Pi) N i=−N k1(i)<label>(17)</label></formula><formula xml:id="formula_13">Pi = Pi−1 + λ1(Pi−1)e1(Pi−1)∆t (18) P0 = P<label>(19)</label></formula><p>Equations 14 and 17 are essentially the output images of the unnormalized LIC on λ2e2 and λ1e1 vector fields with input images In and I1 respectively. Thus, we can reduce HyperLIC to a multipass unnormalized LIC. In the first pass, we apply the unnormalized LIC on λ2e2 using the input image In and kernel k2 to get an intermediate image I1. In the second pass, we use the output image from the previous pass, I1, as the input image and apply unnormalized LIC on λ1e1 with kernel k1 to generate the output image Io.</p><p>Such a two-pass approach greatly reduces the amount of redundant computation in the conceptual algorithm. In each pass, only a 1D integration is needed. To further improve performance, FastLIC is implemented in each pass. The cost of HyperLIC on 2D tensors is only twice the cost of standard LIC. This allows one to interactively explore 2D tensor fields using HyperLIC.</p><p>In the vicinity of all tensors, the first pass filters the noise texture into a LIC-like image with dense and sharp lines, if we process the large eigenvalues first. In the second pass, the intermediate image remains unchanged if the orthogonal eigenvalues are small, implying a region of high anisotropy. If the eigenvalues are very high, which means low anisotropy, it blurs out the image across the orthogonal direction. It achieves the same goal as the conceptual algorithm in a different but much faster way.</p><p>We note that the conceptual algorithm and the multi-pass improvement both depend on which eigenvector is processed first. Theoretically, the order in which the eigenvector fields are processed will affect the final image. In practice, the differences are not noticeable (see <ref type="figure">Figure 4)</ref>.</p><p>The differences are due to the spatial variation in the tensors. That is, following the major eigenvector for X steps from P and then switching to the minor eigenvector for Y steps may end up in a different location than following the minor for Y steps and then switching to the major for X steps. In symmetric tensors, the error is on the order of O(L). In our experiments, L is set to 1/25 of the size of images. Since L is relatively small for each point, the difference is negligible both theoretically and empirically. It means we can interpret the results from HyperLIC to be affected only by the underlying tensor field and not by the sequence of how the eigenvectors were processed.</p><p>Although the sequence of how the eigenvectors are processed is relatively unimportant, how the eigenvectors are classified dramatically affects the quality of the output images. That is to say, eigenvectors must be classified into major or minor fields. This algorithm produces nice results in most regions. However, because the major and minor eigenvectors may switch near critical points in the tensor field, integrating along an eigenvector field generates sudden transitions in an otherwise smooth tensor.</p><p>To avoid this problem, we label the eigenvector fields as follows: First, we find a point with high anisotropy and label its eigenvectors as first and second. Next, we iteratively label its neighbors consistently until all the points are labeled. An important point is that we set the eigenvectors as unchanged through the critical points. This labeling algorithm produces smoothly changing eigenvectors. For a smooth tensor field, there is no sudden change of major or minor eigenvectors. After we label the eigenvectors, the order of their processing is not important as we show in the results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Sign Indeterminacy</head><p>HyperLIC images show the orientation of anisotropy but it doesn't show the direction of the major eigenvector. This is because the sign of the eigenvector is indeterminate. However, we can impose a consistent direction on the eigenvectors by using the signs of the eigenvalues. The idea is inspired by the behavior of charged molecules. A positively charged molecule M in an electric field dispels all other positively charged molecules and attracts all other negatively charged molecules. In other words, we can understand the sign of each molecule in this field by observing their motion relative to M .</p><p>To generalize this idea, we first synthesize a simple interrogational vector field. We then make the eigenvector directions follow this synthetic vector field. The synthetic vector field we chose in our experiment is v(x, P ) = x − P , where P is a user-specified attracting point and x is a location in the vector field. The sign of an eigenvector e i is chosen to make λiei • v(x, P ) &gt; 0. With this direction-deciding algorithm, all eigenvectors with positive eigenvalues flow away from the attracting point while all eigenvectors with negative eigenvalues flow to the attracting point. We can easily identify the signs of the eigenvalues by observing whether the flow direction is toward or away from the attracting point.</p><p>In our experiments, a single attracting point is enough. However, for more complicated data, we may need multiple attracting points or a more complex interrogational vector field, or move the attracting point interactively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.6">Animation</head><p>After deciding the directions of eigenvectors, we propose an animation technique similar to that introduced in <ref type="bibr" target="#b1">[Cabral and Leedom 1993]</ref> by varying the kernel functions according to time T .</p><formula xml:id="formula_14">kn(w, T ) = 1+cos(cw) 2 • 1+cos(dw+βT ) 2 , n = (1, 2) (20) k(w1, w2, T ) = k1(w1, T ) • k2(w2, T )<label>(21)</label></formula><p>where c and d are two constants and β is the phase shift of the ripple function. kn(w), n = 1, 2 are kernel functions defined on each of the eigenvectors. The joint kernel function k(w1, w2) is defined as the product of k1(w1) and k2(w2). This time varying kernel function constantly shifts toward the eigenvector directions. For a linear eigenvector, only the kernel function for the major eigenvector has any effect, so HyperLIC produces a LIC-like animation flow. For an isotropic eigenvector, the kernel function is a multiplication of two simultaneously shifting kernel functions, so the flow pattern appears confused and ambiguous.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.7">Extending HyperLIC to 3D</head><p>The HyperLIC algorithm described thus far works well in 2D. It shows the anisotropic properties of the tensors as varying intensities in the output image and maps tensor magnitude to color. The signs of eigenvalues are mapped to the directions of eigenvectors and visualized through animations. Although all the information of 2D symmetric tensors are visualized, the extra information in the third dimension are lost during tensor projection.</p><p>Fortunately, HyperLIC can be easily extended to 3D. The conceptual 3D HyperLIC works by averaging the input 3D noise texture using a 3D sampling volume defined by the three local eigenvectors. The two-pass 2D HyperLIC is extended to three passes in 3D. During each pass, one set of eigenvectors is used to apply unnormalized LIC on the input volume with the corresponding kernel functions. The output volume is then passed as the input volume in the next pass. The final 3D texture volume is then rendered using direct volume rendering.</p><p>We use a 3D diffusion tensor MRI brain data to demonstrate 3D HyperLIC. In medical data, fiber traces are important features. Fibers are represented by tensors with high anisotropy. On the other hand, tensors associated with white matter are relatively isotropic. HyperLIC visualizes the fibers as sharp lines and the rest of the brain as blurred regions. The global structure is insensitive to noise in the underlying data because HyperLIC smears out the local noise. To highlight the fibrous regions, we chose to map the local variance in the output volume to transparency prior to volume rendering using the following:</p><formula xml:id="formula_15">var(P ) = (Io(P ) − Io(Pn)) 2 6<label>(22)</label></formula><p>where Pn are neighboring points around P . This form of variance gives a measure of how similar or dissimilar neighboring points are from the value at P . This measure is low in isotropic regions and high in fibrous regions. Using a transfer function that maps this variance to transparency, 3D HyperLIC can extract the fibrous regions of the brain data set. In this transfer function, the higher variances are mapped to lower transparency. In our experiments, we use a step function that maps all variances larger than 0.065 to the opacity of 0.1 and all others to 0. By choosing the right parameter, HyperLIC volumetric texture reveals the "edge" between the smooth and the sharp region. Tensor magnitudes are still mapped to hue as before while the HyperLIC volumetric texture is mapped to value in an HSV color model.</p><p>Accurate and smooth shading is crucial to visual perception. In traditional volume rendering algorithms, the normal of the surfaces are mapped to the gradient of data values. We find this to produce very noisy gradients. Instead, we apply a smoothing algorithm repeatedly to obtain a smoother normal. After each step, the cells are assigned the average of the old values in its neighboring cells. Note that we do not apply this smoothing algorithm on I 0 because it will smooth out the variance, which is critical to the extraction of the features. After smoothing out the variances during the gradient generation stage, we produce a more continuous shading on the same sharp features. The result is smoother shading on the fiber structures which greatly enhances the depth perception of the brain. An important point to note is that smoothed variances are only used to calculate the gradient for shading purposes. The transparency is still mapped to the original variances. Hence, what we are seeing accurately reflects what is in the data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">IMPLEMENTATION ISSUES</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Inverse HyperLIC</head><p>The default HyperLIC algorithm shows strong directional information about the major eigenvectors, but it does not produce a strong visual effect about the other components. To compensate, we can switch the tensors in the preprocessing stage by swapping the tensors -so the minor eigenvectors become the major eigenvectors and vice versa. As a result, the images strongly resemble the minor hyperstreamlines (see <ref type="figure">Figure 3</ref>(c)).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Storage Requirement</head><p>3D HyperLIC is computationally expensive and requires a lot of memory. For a high resolution data set, 512 3 volume of floats in our experiment, the input and output volumes take up to 800 Mb of memory. To handle this huge memory demand, we solve the problem one layer at a time.</p><p>HyperLIC is a locally based algorithm. A voxel in the output volume is only affected by voxels within a certain distance of the corresponding input voxel. Because the eigenvalues are normalized, the maximum radius of the effective area is 2N + 1 where N is the integration length. So, when we compute the output volume for layer Y , only layers from Y − N to Y + N in input volume are needed. We implemented this method with an output buffer of one layer, and an input buffer of up to 2N + 1 layers. During each step, we update the output layer with the input layers. At the end of each step, we write the output layer into a temporary file and update the next layer of the input buffer, then go to the next step.</p><p>The results of the output volume after each pass in HyperLIC is stored in a temporary file. After each pass, we use the output file in the previous pass as input in the next pass. We implement this algorithm in parallel, by computing each output layer separately. Because the input textures are read-only, they are shared by all the rendering threads. When a rendering thread for an output layer is started, only the input layer not already in memory is loaded. This strategy reduces the memory requirements and makes the implementation very amenable to parallel computation on machines with multiple processors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Rendering</head><p>3D HyperLIC produces a colored volume. In our experiment, this volume is 512 3 . Interactive exploration of this large volume is a key component to understand the structure of the tensor data.</p><p>We employ a hardware-accelerated shell rendering algorithm to render this volume. Before the rendering, three sets of volume textures are generated, each of them is sliced along one of the three texture coordinates. When rendering from a given viewpoint, we pick the set of texture associated with the axis that best faces the camera. This is determined by computing the dot product of all three candidate axes and the camera and then use the one with maximum absolute value. If there is no clear winner, the output image, I out is a weighted blend of three images. Let Vw be the camera orientation, Ni, (i = 1, 2, 3) be the three axes, Li be the length of side of a cell, Ii is the image rendered using texture slices along axis i. The output image is generated as follows:</p><formula xml:id="formula_16">Hi = Vw • Ni Li , (i = 1, 2, 3) (23) Mi = Hi 3 i=1 Hi (24) Wi = Mi − α, Mi ≥ α 0, M i &lt; α (25) Iout = 3 i=1 Wi • Ii 3 i=1 Wi (26)</formula><p>where α is a threshold parameter to choose between the smoothness and accuracy of the rendering. In our experiments, α is set as 0.3. The unoptimized implementation generates the 512 3 volume texture on the order of five minutes, and renders each image on the order of three seconds on a Dell Dimension 8100 with a single 1.5 GHz Pentium 4, 1 Gb of memory, and an nVidia GeForce2 Ultra.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">RESULTS</head><p>In this section, we present results from HyperLIC on different data sets. The first data we experimented with is the single point load data. This stress tensor data is simple and thoroughly studied and therefore an excellent data for verifying the algorithm. The second data set is strain tensors derived from the flow past a cylinder with a hemispherical cap. This data is more complicated but it has also been used to demonstrate other published tensor visualization methods. The third data set is diffusion tensor MRI of the brain. Neural pathways are represented by tensors with high anisotropies.</p><p>We present results both in 2D projection and 3D for this data. <ref type="figure">Figure 3</ref> includes 2D HyperLIC results on the single point load stress tensors from different viewpoints. <ref type="figure">Figure 3(a)</ref> is a slice from the middle of the volume and viewed from the point load direction. It is mostly composed of components from medium or minor eigenvectors. We see that the center of this slice is quite isotropic. Around the center is a ring formed by lines, which means tensors are highly anisotropic. It is the boundary where the minor eigenvalues are zero. From the animation available from the url provided in Section 1, we see flow within the ring going towards the center, while flow outside the ring going away from the center. This reveals that stress inside the ring is tensile, outside the ring is compressive, and the ring itself is free of stress away or toward the center. A little further away from the ring, we find another isotropic area. After the yellow area, the tensors are mostly represented by dense and sharp lines oriented radially that show high anisotropy in the regions.</p><p>Figures 3(b) and 3(c) are side views. <ref type="figure">Figure 3</ref>(b) contains mostly sharp lines, so eigenvalues are very large in these orientations. An interesting feature appears near the surface shown in more detail in <ref type="figure">Figure 3(d)</ref>. There we see a change of pattern. The sharp lines change directions rapidly in a very narrow strip. Further observation in the animation reveals that flow near the surface is attracted to the point load, while flow further away is repelled. It clearly shows that the stress near the surface is tensile, while it is compressive in other areas. This can be confirmed in the stress tensor equation and is hardly shown by other visualization methods. <ref type="figure">Figure 3(c)</ref> is the same view as <ref type="figure">Figure 3(b)</ref>, but shows the inverse HyperLIC which highlights the minor eigenvectors.</p><p>Images in <ref type="figure">Figure 5</ref> are two results from strain tensors in the flow past a cylinder with a hemispherical cap. <ref type="figure">Figure 5(a)</ref> is from the inner layer (closer to the geometry) and <ref type="figure">Figure 5(b)</ref> is from the middle layer (farther away from the geometry). From these two images, we can clearly see the tensor orientations on the cap as well as locations of blurred isotropic tensors. We can also observe two degenerate wedge points. One is on the cylinder, while the other is on the cap.</p><p>Images from <ref type="figure">Figure 6</ref> are from brain tensor data with different scaling parameters. Tensor normalization and rescaling is used in the preprocessing stage of HyperLIC to vary the degree and contrast in which anisotropy is depicted. The higher the scaling parameter, the more linear HyperLIC looks. In <ref type="figure">Figure 6</ref>(a), most regions except a few are blurred. In <ref type="figure">Figure 6</ref>(b), more fibers are visible. We can observe the main fiber structure in this picture. This demonstrates that tensor scaling allows the user to vary the amount of detail in HyperLIC images. <ref type="figure" target="#fig_2">Figure 7</ref> shows results from the brain tensor data using 3D Hy-perLIC. Images are from different viewpoints and rendered with shading. The light is always from the camera position. The main structures of the brain can be identified from these views. <ref type="figure">Figure 8</ref> illustrates the effect of rendering without and with shading. Finally, in <ref type="figure">Figure 8</ref>(c), we use chromadepth mapping <ref type="bibr" target="#b0">[Bailey and Clark 1998</ref>] to further enhance the depth perception with the aid of some inexpensive lens.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">CONCLUSIONS</head><p>We presented a new technique for visualizing the anisotropy in symmetric 2D and 3D tensor fields. The technique provides a global, continuous representation of the field requiring minimal user input. Furthermore, the technique can produce animations that enhances perception and our understanding of the tensor field. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Squares primitives aligned with eigenvectors.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Sampling strip defined by a primary hyperstreamline and a set of orthogonal hyperstreamlines.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 7 :</head><label>7</label><figDesc>Zoomed view of the top portion of (b) Figure 3: Single point load data from different view points. (a) Eigenvector order switched (b) Conceptual algorithm Figure 4: There are no noticeable visual differences among the multi-pass algorithm in Figure 3(b) and (a) where the minor eigenvector is processed first, and (b) using the more expensive conceptual algorithm. (a) Inner layer (b) Middle layer Figure 5: Flow past a cylinder with hemispherical cap. HyperLIC of two different computational layers of the strain rate tensor. Arrows point to locations of degenerate wedge points. (a) Scaling with n = 2 (b) Scaling with n = 8 Figure 6: A 2D slice of the brain data using different tensor scaling parameters. 3D HyperLIC on diffusion tensor MRI brain data from different view points. (a) Unshaded (b) Shaded (c) Chromadepth Figure 8: Comparison of different rendering techniques.</figDesc></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGEMENTS</head></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Using ChromaDepth to obtain inexpensive single-image stereovision for scientific visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bailey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Clark</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Graphics Tools</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="1" to="9" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Imaging vector fields using line integral convolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Cabral</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Leedom</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics Siggraph Proceedings</title>
		<imprint>
			<biblScope unit="page" from="263" to="270" />
			<date type="published" when="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Visualizing second-order tensor fields with hyperstreamlines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Delmarcelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Hesselink</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer Graphics and Applications</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="25" to="33" />
			<date type="published" when="1993-07" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Statagies for effectively visualizing 3D flow with volume lic</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Interrante</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Grosch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings IEEE Visualization &apos;97</title>
		<editor>R. Yagel and H. Hagen</editor>
		<meeting>IEEE Visualization &apos;97</meeting>
		<imprint>
			<publisher>IEEE Computer Society Press</publisher>
			<date type="published" when="1997" />
			<biblScope unit="page" from="421" to="424" />
		</imprint>
		<respStmt>
			<orgName>Case Study -Flow Visualization</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Hue-balls and littensors for direct volume rendering of diffusion tensor fields</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">L</forename><surname>Kindlmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">M</forename><surname>Weinstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Visualization</title>
		<imprint>
			<date type="published" when="1999" />
			<biblScope unit="page" from="183" to="189" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Strategies for direct volume rendering of diffusion tensor fields. Visualization and Computer Graphics 6</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Kindlmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Weinstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Hart</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="124" to="138" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Tensor field visualization using adaptive filtering of noise fields combined with glyph rendering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sigfridsson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Ebbers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Heiberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wigstrom</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Visualization 02</title>
		<meeting>Visualization 02</meeting>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="371" to="378" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Oriented tensor reconstruction: Tracing neural pathways from diffusion tensor MRI</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhukov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Barr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Visualization 02</title>
		<meeting>Visualization 02</meeting>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="387" to="394" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
