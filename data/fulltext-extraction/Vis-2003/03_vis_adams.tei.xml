<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/pisenberg/grobid/grobid-0.6.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Visualization of Steep Breaking Waves and Thin Spray Sheets Around a Ship</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<title level="a" type="main">Visualization of Steep Breaking Waves and Thin Spray Sheets Around a Ship</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2021-02-19T20:49+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>I.3.8 [Computer Graphics]: Applications</term>
					<term>J.2 [Applications]: Physical Sciences and Engineering -Engineering</term>
					<term>D.1.3 [Software]: Concurrent Programming -Parallel Programming isosurfaces, marching cubes, multilevel parallelism</term>
				</keywords>
			</textClass>
			<abstract>
				<p>The simulation of breaking of waves, the formation of thin spray sheets, and the entrainment of air around the next generation of naval surface combatants is an ongoing 3-year Department of Defense (DoD) Challenge Project. The goal of this project is a validated computation capability to model the full hydrodynamics around a surface combatant including all of the processes that affect mission and performance. Visualization of these large-scale simulations is paramount to understanding the complex physics involved. These simulations produce enormous data sets with both surface and volumetric qualities. Wave breaking, spray sheets, and air entrainment can be visualized using isosurfaces of scalar data. Visualization of quantities such as the vorticity field also provides insight into the dynamics of droplet and bubble formation. This paper documents the techniques used, results obtained, and lessons learned from the visualization of the hydrodynamics of naval vessels.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>As a ship progresses through the water, steep breaking waves are formed. Spray is shed along the crests of the breaking waves and also near the ship's bow where thin sheets of water form. Air is also entrained along the turbulent face of breaking waves and along the contact line where the free surface, which is the interface between the air and water, intersects the hull. Wave breaking and the associated droplet and bubble formation are among the most challenging problems in the field of free-surface hydrodynamics.</p><p>The Numerical Flow Analysis code provides turnkey capabilities to model breaking waves around a ship, including both plunging and spilling breaking waves, the formation of spray, and the entrainment of air. Cartesian-grid methods are used to model the ship's hull and the free surface. Following <ref type="bibr" target="#b5">Goldstein et al. [1993]</ref> and <ref type="bibr" target="#b12">Sussman and Dommermuth [2001]</ref>, a body-force method is used to enforce the boundary condition on the hull. A surface representation of the ship's hull is used as input to construct a volumetric force. The interface capturing of the free surface uses a second-order accurate, volume-of-fluid technique. At each timestep, the position of the free surface is reconstructed using piecewise planar surfaces as outlined in <ref type="bibr" target="#b11">Rider et al. [1994]</ref>. A secondorder, variable-coefficient Poisson equation is used to project the velocity onto a solenoidal field, thereby ensuring mass conservation. A preconditioned conjugate-gradient method is used to solve the Poisson equation. Details of a similar projection operator are provided in <ref type="bibr" target="#b10">Puckett et al. [1997]</ref>. The convective terms in the momentum equations are accounted for by using a slope-limited, third-order QUICK scheme as discussed in <ref type="bibr" target="#b7">Leonard [1997]</ref>. The governing equations are solved using a domain decomposition method that is based on the PARAMESH algorithm as described by <ref type="bibr" target="#b9">MacNeice et al. [2000]</ref>. Communication between processors on the Cray T3E is performed using Cray's shared-memory access library. The central processing unit (CPU) requirements are linearly proportional to the number of grid points and inversely proportional to the number of processors. The goal is to remove current ad hoc treatments of the free surface and replace them with more physically based models that are able to capture complex phenomena that will allow the Navy to optimize hull forms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Flow Regions of Interest</head><p>The breaking wave at the bow of a ship is a topologically complex interface between air and water. The interface is represented by an isosurface of a scalar function that accounts for the fraction of volume that is occupied by water. As long as sufficient grid resolution exists, water droplets in the air and air bubbles in the water can also be represented using isosurfaces. The motion of the water droplets and air bubbles provides some indication of the unsteady velocity field. The water droplets and air bubbles act as natural particle traces. However, they are insufficient for fully visualizing any features. The lack of visualization necessitates the need for exploring other techniques such as inserting particles directly. Unfortunately, the insertion points for particles are critical. Otherwise, interesting currents and eddies can be missed <ref type="bibr" target="#b0">[Bauer et al. 2002]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Visualization Technique</head><p>The primary goal of scientific visualization is insight into the data and communicating that insight to others. Numerical procedures are required to calculate the isosurfaces used to represent the breaking wave. By using the Marching Cube method, an isosurface of high quality can be constructed of polygons. Modern graphics hardware is adept at processing this type of threedimensional object. However, two significant barriers presented themselves during the investigation. <ref type="bibr" target="#b6">Law et al. [1999]</ref> discusses two opposing goals for visualization: the desire to process large data sets without loss of information and the need to allow users to quickly identify regions of interest. The first design goal presents itself as a barrier because the data consist of hundreds of gigabytes spanning over 600 time instants.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Paul Adams Douglas Dommermuth ERDC MSRC</head><p>Science Applications International Corporation paul.adams@erdc.usace.army.mil douglas.g.dommermuth@saic.com <ref type="bibr">IEEE Visualization 2003</ref><ref type="bibr">, October 19-24, 2003</ref>, Seattle, Washington, USA 0-7803-8120-3/03/$17.00 Â©2003 IEEE</p><p>An alternate approach to using isosurfaces would have been to use volume-rendering techniques. While, philosophically, using a volumetric technique on a physically based surface does not make much sense, this approach was still investigated. This investigation used the VolumePro 1000 PCI card from Terarecon on a dual 2.4 GHz Xeon with 2 GB of memory. The VolumePro 1000 does allow for interactive volume rendering in hardware up to a grid size of 512 3 . Therefore, the VolumePro card can accomplish both the processing of large data sets as well as interactively identifying regions of interest in a single data set. However, the VolumePro card suffered from one major drawback. While the VolumePro card has shown itself to be amenable to interactive volume rendering on a single time-step, loading tens of time-steps brought the overall system to a crawl.</p><p>Originally, the scientific visualization software EnSight from Computational Engineering International was used to generate the isosurfaces. EnSight is advantageous because it runs in a client/server mode. The server can run on the high-performance computing platform, where the data were located. The client can then interact with the server to investigate the data. Because the Cray T3E has no server version, the data were transferred over to an SGI Onyx 340 where it was processed to generate the isosurfaces. This process of transferring, computing, and outputting isosurfaces took several hours to complete. The number of polygons for each isosurface ranged up to 550K polygons, thus resulting in an excessive time for raytracing the resulting isosurfaces.</p><p>A new and faster approach was needed to generate the resulting surfaces rather than relying on a commercial package. The Marching Cubes algorithm <ref type="bibr" target="#b8">[Lorensen and Cline 1987]</ref> is the standard algorithm for extracting isosurfaces from volumetric data. An alternative approach would have been to use the Marching Tetrahedron algorithm <ref type="bibr" target="#b15">[Zhou et al. 1997]</ref>. The shortcoming with the Marching Tetrahedron algorithm is that it produces a larger number of polygons than the Marching Cubes algorithm. Given that this is a time-varying isosurface, a third approach would have been to use a higher dimensional isosurfacing technique <ref type="bibr" target="#b1">[Bhaniramka et al. 2000]</ref>. This approach could be investigated further, but for now, the Marching Cubes algorithm was chosen.</p><p>Since the data were generated on the U.S. Army Engineer Research and Development Center (ERDC) Major Shared Resource Center (MSRC) Cray T3E, the data were processed there making it easier to transfer a file containing one isosurface (ranging from 5 to 14 MB in size with the larger size having 272K polygons) than an entire data file (33.5 MB). The size of all the isosurfaces together was 4.2 GB, substantially less than the 127 GB of scientific data. The Cray T3E is a massively parallel machine with 1,792 computational processors. An algorithm could be developed to run each time frame of data using a serial version of the Marching Cubes algorithm on a different processor resulting in near perfect linear speedup, assuming the availability of the processors, of course. This would reduce the time to generate the isosurface down to tens of minutes, including time into and out of the queue. There are difficulties with this approach aside from just simple availability of processors. The T3E is configured with heterogeneous speed grades of processors with speeds of 450 MHz, 600 MHz, and 675 MHz. One is not guaranteed which speed grade will be received when submitting a job.</p><p>Therefore, a multilevel parallel version of the code was developed using Message Passing Interface (MPI) and OpenMP. MPI is a standard for writing message-passing parallel programs. Even though MPI can be time-consuming to write, MPI is well-suited for coarse-grained parallelism and significantly reduces the time to solution. OpenMP is an Application Programming Interface that was developed to expose multithreaded, shared-memory parallelism in both C and Fortran, on both Windows and Unix platforms. OpenMP is suited for fine-grained parallelism and is easy to code. Others <ref type="bibr" target="#b13">[Tang and Newman 1996;</ref><ref type="bibr" target="#b4">Gao and Shen 2001]</ref> have used the same algorithm and used either vectorized or parallel view dependent algorithms for large-scale isosurface extraction.</p><p>The Marching Cubes algorithm is perfectly suited to parallel programming. The premise behind the algorithm is that a continuous, volumetric scalar field can be sampled using a rectilinear, three-dimensional grid. By subdividing the scalar field into a series of small cubes and marching along each cell or cube in the grid, intersection or nonintersection of the isosurface can be discovered. Depending on how the isosurface intersects the cube, a representation can be made by a series of polygons. Each cube is independent of any other, as is each layer (IJ, JK, IK) in the grid. Using the coarse-grained parallelism of MPI, the IJ layers of the grid were assigned to different processors. The fine-grained parallelism of OpenMP can be used within the layers on the loop level.</p><p>Coding the Marching Cubes algorithm with multilevel parallelism allows the greatest flexibility in choosing the platform on which to run. The Cray T3E has no OpenMP implementation, but does have an MPI implementation. The SGI Onyx/Origin series are capable of handling multilevel parallelism having both implementations of OpenMP and MPI. <ref type="figure" target="#fig_0">Figure 1</ref> shows the speedup for the code on the 675 MHz Cray T3E, the 600 MHz SGI Onyx 340, and the 700 MHz SGI Origin 3900 processors. Several results can be summarized:</p><p>â¢</p><p>Immediately obvious is that the OpenMP-only implementation results in only a minor increase in speed (37 percent) at its best. MPI exposes the maximum amount of increase in speed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>â¢</head><p>Having just under 32 processors, the SGI Onyx scales better than the T3E. Since the Onyx is limited to 32 processors, the parallel code starts to contend with the operating system.</p><p>â¢ <ref type="figure" target="#fig_0">Figure 1</ref> accounts only for the speedup of the algorithm. It does not account for the time to solution. Even though the T3E scales better from 32 processors upwards, the CPU speed of the machine is still slower than that of the Onyx.</p><p>#pragma omp parallel default(shared) private(i,j) { #pragma omp parallel for /* For every cube in the grid... */ for(i = 0; i &lt; iDim -1; i++) { for(j = 1; j &lt; jDim; j++) { Do work</p><formula xml:id="formula_0">} } } // End OpenMP parallel section</formula><p>The result is that it takes longer to complete at 64 processors for the T3E than it does for the Onyx at 16 processors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>â¢</head><p>Dual level parallelism was generally subpar to the MPI-only implementation. The number of processors was considered to be the number of MPI processors times the number of OpenMP threads. Thus, only at 16 MPI processes along with 2 OpenMP threads was the implementation competitive in terms of scalability.</p><p>â¢ One interesting result that is not readily apparent is that the parallel implementation of the code can suffer from load imbalance. The algorithm checks for the existence of the isosurface within a cube. If the isosurface does not exist within the cube, it proceeds to the next cube without further processing. If the isosurface does exist within the cube, then the construction of the appropriate polygon takes place.</p><p>Depending on the location of the chosen isosurface within the scalar field, the possibility exists for a processor to have essentially no work to perform. This imbalance was noticeable on the two-processor MPI case using a horizontalslice version of the algorithm. A vertical-slice algorithm ensured that each processor had a portion of the isosurface, and was used in the timings for <ref type="figure" target="#fig_0">Figure 1</ref>. An improvement to the algorithm would be to use knowledge gained from previous time-steps for the construction of the isosurface in the current time-step. On the Onyx, the maximum sustained isosurface generation rate was 4 isosurfaces per second or just over a million polygons generated per second for the 512x128x128 data sets. On the Origin 3900, the maximum sustained isosurface generation rate was 8 isosurfaces per second or 2.2 million polygons generated per second. Completely generating all the isosurfaces took just a few minutes on the Onyx. At such a speed, interactive interrogation of the data field is possible. Preprocessing the data builds an index into the scalar field. At execution time only, those cells contributing to the isosurface need to be loaded into memory <ref type="bibr" target="#b2">[Bryson et al. 1999]</ref>. This would increase the interactivity of the algorithm. Therein, both design goals, the ability to process large amounts of data and to quickly identify regions of interest, were met. Raytracing techniques similar to <ref type="bibr">Enright et al. [1999]</ref> are used; however, one can note that unlike <ref type="bibr">Enright et al. [1999]</ref>, the present flow solver provides a full implementation of the governing equations. <ref type="figure" target="#fig_1">Figure 2</ref> shows the comparison of experimental data with the computed isosurface for the NACA 0024 foil. The red spheres are based on experimental measurements of the wave profile along the side of the hull. In the front, the wave profile is steady, but in the back, the wave profile is unsteady. In the rear of the foil, the upper and lower distribution of points indicates the bounds of the measured wave profile. The blue isosurface is numerical predictions at a particular instant of time. <ref type="figure" target="#fig_2">Figure 3</ref> shows the breaking wave at the front of the foil and the unsteady formation of spray. The wave spills over near the bow. <ref type="figure" target="#fig_3">Figure 4</ref> shows the air entrainment toward the rear of the foil and along the sides of the foil. <ref type="figure">Figure 5</ref> shows a wedge in the flow. The front of the wedge has a 40-degree entrance angle, and the rear has a 20-degree exit angle. The water separates at the corner where the bow and stern sections meet. <ref type="figure">Figure 6</ref> shows a bow section of a DDG-51 moving with forward speed. The water separates at the rear of the bow section. Along the sides of the hull, the diverging wave system is clearly visible.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Conclusion</head><p>A multilevel parallel Marching Cubes code that can generate over one million polygons per second and process multi-gigabyte data sets spanning hundreds of time-steps was developed. This capability allows the rapid visualization of large-scale simulations of the full hydrodynamics around a surface combatant.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Acknowledgments</head><p>The Office of Naval Research (ONR) under contract number N00014-01-C-0191 supports this research. Dr. Patrick Purtell is the ONR program manager, and Dr. Ki-Han Kim manages the Challenge Project. This work is supported in part by a grant of computer time from the DoD High Performance Computing Modernization Program at the ERDC MSRC.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>Marching Cube Algorithm Speedup</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 .</head><label>2</label><figDesc>Verification and validation using NACA 0024 foil</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 .</head><label>3</label><figDesc>Breaking wave and thin spray sheets for NACA 0024 foil</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 .</head><label>4</label><figDesc>Air entrainment for NACA 0024 foil Figure 5. Wedge in flowFigure 6. Flow about a DDG-51 bow section</figDesc></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A Case Study in Selective Visualization of Unsteady 3D Flow</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Bauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Peikert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Visualization &apos;02</title>
		<meeting>Visualization &apos;02</meeting>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="525" to="528" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Isosurfacing in Higher Dimensions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Bhaniramka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Wenger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Crawfis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Visualization &apos;00</title>
		<meeting>Visualization &apos;00</meeting>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="page" from="267" to="273" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Visually Exploring Gigabyte Data Sets In Real Time</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bryson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kenwright</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Cox</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ellsworth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Haimes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="83" to="90" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Animation and Rendering of Complex Water Surfaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Enright</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Marschner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Fedkiw</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 29th Annual Conference on Computer Graphics and Interactive Techniques</title>
		<meeting>the 29th Annual Conference on Computer Graphics and Interactive Techniques</meeting>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="736" to="744" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Parallel View-Dependent Isosurface Extraction Using Multi-Pass Occlusion Culling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H.-W</forename><surname>Shen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE 2001 Symposium on Parallel and Large-Data Visualization and Graphics</title>
		<meeting>the IEEE 2001 Symposium on Parallel and Large-Data Visualization and Graphics<address><addrLine>San Diego, California</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="page" from="67" to="74" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Modeling a No-Slip Boundary with an External Force Field</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Goldstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Handler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Sirovich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Comp. Phys</title>
		<imprint>
			<biblScope unit="volume">105</biblScope>
			<biblScope unit="page" from="354" to="366" />
			<date type="published" when="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A Multi-Threaded Streaming Pipeline Architecture for Large Structured Data Sets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Law</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Schroeder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Temkin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Visualization &apos;99</title>
		<meeting>Visualization &apos;99</meeting>
		<imprint>
			<date type="published" when="1999" />
			<biblScope unit="page" from="225" to="233" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Bounded Higher-Order Upwind Multidimensional Finite-Volume Convection-Diffusion Algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">P</forename><surname>Leonard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Numerical Heat Transfer</title>
		<editor>W.J. Minkowycz, W.J. and E.M. Sparrow</editor>
		<meeting><address><addrLine>Taylor &amp; Francis, Washington, D.C</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1997" />
			<biblScope unit="page" from="1" to="57" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Marching Cubes: A High-Resolution 3D Surface Construction Algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Lorensen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Cline</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="163" to="169" />
			<date type="published" when="1987" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Macneice</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">M</forename><surname>Olson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Mobarry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Defainchtein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Packer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">PARAMESH: A Parallel Adaptive Mesh Refinement Community Toolkit</title>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="volume">126</biblScope>
			<biblScope unit="page" from="330" to="354" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">A Second-Order Projection Method for Tracking Fluid Interfaces in Variable Density Incompressible Flows</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">G</forename><surname>Puckett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">S</forename><surname>Almgren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">B</forename><surname>Bell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">L</forename><surname>Marcus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">J</forename><surname>Rider</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Comp. Physics</title>
		<imprint>
			<biblScope unit="volume">130</biblScope>
			<biblScope unit="page" from="269" to="282" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Accurate Solution Algorithms for Incompressible Multiphase Flows</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">J</forename><surname>Rider</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">B</forename><surname>Kothe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Mosso</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">H</forename><surname>Cerutti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">I</forename><surname>Hochstein</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1994" />
		</imprint>
	</monogr>
	<note>AIAA paper 95-0699</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">The Numerical Simulation of Ship Waves Using Cartesian-Grid Methods</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sussman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">G</forename><surname>Dommermuth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Of 24 th Symp. on Naval Hydro</title>
		<meeting>Of 24 th Symp. on Naval Hydro<address><addrLine>Nantes, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="page" from="762" to="779" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">A Vector-Parallel Realization of the Marching Cubes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Newman</surname></persName>
		</author>
		<idno>TR-UAH-CS- 1996-01</idno>
		<imprint>
			<date type="published" when="1996" />
			<pubPlace>Huntsville</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Computer Science Department, Univ. Alabama in</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Free-Surface Wave-Induced Separation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Stern</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ASME J. Fluids Eng</title>
		<imprint>
			<biblScope unit="volume">118</biblScope>
			<biblScope unit="page" from="546" to="554" />
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Multiresolution Tetrahedral Framework for Visualizing Regular Volume Data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kaufman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Visualization &apos;97</title>
		<meeting>Visualization &apos;97</meeting>
		<imprint>
			<date type="published" when="1997" />
			<biblScope unit="page" from="135" to="143" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
