<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/pisenberg/grobid/grobid-0.6.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Explainable Matrix -Visualization for Global and Local Interpretability of Random Forest Classification Ensembles</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mário</forename><forename type="middle">Popolin</forename><surname>Neto</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><roleName>Member, IEEE</roleName><forename type="first">Fernando</forename><forename type="middle">V</forename><surname>Paulovich</surname></persName>
						</author>
						<title level="a" type="main">Explainable Matrix -Visualization for Global and Local Interpretability of Random Forest Classification Ensembles</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2021-02-19T20:22+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Random forest visualization</term>
					<term>logic rules visualization</term>
					<term>classification model interpretability</term>
					<term>explainable artificial intelligence</term>
				</keywords>
			</textClass>
			<abstract>
				<p>Over the past decades, classification models have proven to be essential machine learning tools given their potential and applicability in various domains. In these years, the north of the majority of the researchers had been to improve quantitative metrics, notwithstanding the lack of information about models&apos; decisions such metrics convey. This paradigm has recently shifted, and strategies beyond tables and numbers to assist in interpreting models&apos; decisions are increasing in importance. Part of this trend, visualization techniques have been extensively used to support classification models&apos; interpretability, with a significant focus on rule-based models. Despite the advances, the existing approaches present limitations in terms of visual scalability, and the visualization of large and complex models, such as the ones produced by the Random Forest (RF) technique, remains a challenge. In this paper, we propose Explainable Matrix (ExMatrix), a novel visualization method for RF interpretability that can handle models with massive quantities of rules. It employs a simple yet powerful matrix-like visual metaphor, where rows are rules, columns are features, and cells are rules predicates, enabling the analysis of entire models and auditing classification results. ExMatrix applicability is confirmed via different examples, showing how it can be used in practice to promote RF models interpretability.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Imagine a machine learning classification model for cancer prediction with 99% accuracy, prognosticating positive breast cancer for a specific patient. Even though we are far from reaching such level of precision, we (researchers, companies, among others) have been trying to convince the general public to trust classification models, using the premise that machines are more precise than humans <ref type="bibr" target="#b14">[15]</ref>. However, in most cases, yes or no are not satisfactory answers. A doctor or patient inevitably may want to know why positive? What are the determinants of the outcome? What are the changes in patient records that may lead to a different prediction? Although standard instruments for building classification models, quantitative metrics such as accuracy and error cannot tell much about the model prediction, failing to provide detailed information to support understanding <ref type="bibr" target="#b37">[38]</ref>.</p><p>We are not advocating against machine learning classification models, since there is no questioning about their potential and applicability in various domains <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b19">20]</ref>. The point is the acute need to go beyond tables and numbers to understand models' decisions, increasing trust in the produced results. Typically, this is called model interpretability and has become the concern of many researchers in recent years <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b59">60]</ref>. Model interpretability is an open challenge and opportunity for researchers <ref type="bibr" target="#b19">[20]</ref> and also a government concern, as the European General Data Protection Regulation requires explanations about automated decisions regarding individuals <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b38">39]</ref>.</p><p>Model interpretability strategies are typically classified as global or local approaches. Global techniques aim at explaining entire models, while the local ones give support for understanding the reasons for the classification of a single instance <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b18">19]</ref>. In both cases, interpretability can be attained using inherent interpretable models such as Decision Trees, Rules Sets, and Decision Tables <ref type="bibr" target="#b30">[31]</ref>, or through surrogates, where black-box models, like Artificial Neural Networks or Support Vector Machines, are approximated by rule-based interpretable mod-  <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b26">27]</ref>. The key idea is to transform models into logic rules, using them as a mechanism to enable the interpretation of a model and its decisions <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b41">42,</ref><ref type="bibr" target="#b45">46]</ref>.</p><formula xml:id="formula_0">• M.</formula><p>Recently, visualization techniques have been used to empower the process of interpreting rule-based classification models, particularly Decision Tree models <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b46">47,</ref><ref type="bibr" target="#b56">57,</ref><ref type="bibr" target="#b60">61]</ref>. In this case, given the inherent nature of these models, the usual adopted visual metaphors focus on revealing tree structures, such as the node-link diagrams <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b41">42,</ref><ref type="bibr" target="#b60">61]</ref>. However, node-link structures are limited when representing logic rules <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b36">37]</ref>, and present scalability issues, supporting only small models with few rules <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b47">48,</ref><ref type="bibr" target="#b60">61]</ref>. Matrix-like visual metaphors have been used <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b41">42]</ref> as an alternative, but visual scalability limitations still exist, and large and complex models cannot be adequately visualized, such as the Random Forests <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b6">7]</ref>. Among rule-based models, Random Forests is one of the most popular techniques given their simplicity of use and competitive results <ref type="bibr" target="#b5">[6]</ref>. However, they are very complex entities for visualization since multiple Decision Trees compose a model, and, although attempts have been made to overcome such a hurdle <ref type="bibr" target="#b60">[61]</ref>, the visualization of entire models is still an open challenge.</p><p>In this paper, we propose Explainable Matrix (ExMatrix), a novel method for Random Forest (RF) interpretability based on the visual representations of logic rules. ExMatrix supports global and local explanations of RF models enabling tasks that involve the overview of models and the auditing of classification processes. The key idea is to explore logic rules by demand using matrix visualizations, where rows are rules, columns are features, and cells are rules predicates. ExMatrix allows reasoning on a considerable number of rules at once, helping users to build insights by employing different orderings of rules/rows and features/columns, not only supporting the analysis of subsets of rules used on a particular prediction but also the minimum changes at instance level that may change a prediction. Visual scalability is addressed in our solution using a simple yet powerful compact representation that allows for overviewing entire RF models while also enables focusing on specific parts for details on-demand. In summary, the main contributions of this paper are:</p><p>• A new matrix-like visual metaphor that supports the visualization of RF models; • A strategy for Global interpretation of large and complex RF models supporting model overview and details on-demand; and • A strategy to promote Local interpretation of RF models, supporting auditing models' decisions.</p><p>Typically, visualization techniques aid in classification tasks in two different ways. One is on supporting parametrization and labeling processes aiming to improve model performance <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b37">38,</ref><ref type="bibr" target="#b52">53,</ref><ref type="bibr" target="#b54">55,</ref><ref type="bibr" target="#b56">57]</ref>. The other is on understanding the model as a whole or the reasons for a particular prediction. In this paper, our focus is on the latter group, usually named model interpretability. Interpretability techniques can be divided into pre-model, in-model, or post-model strategies, regarding support to understand classification results before, during, or after the model construction <ref type="bibr" target="#b10">[11]</ref>. Pre-model strategies usually give support to data exploration and understanding before model creation <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b40">41,</ref><ref type="bibr" target="#b42">43]</ref>. In-model strategies involve the interpretation of intrinsically interpretable models, such as Decision Trees, and post-model strategies concerns interpretability of complete built models, and they can be model-specific <ref type="bibr" target="#b43">[44,</ref><ref type="bibr" target="#b58">59]</ref> or model-agnostic <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b41">42,</ref><ref type="bibr" target="#b45">46]</ref>. Both in-model and post-model approaches aim to provide interpretability by producing global and/or local explanations <ref type="bibr" target="#b18">[19]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Global Explanation</head><p>Global explanation techniques produce overviews of classification models aiming at improving users' trust in the model <ref type="bibr" target="#b44">[45]</ref>. For inherently interpretable models, the global explanation is attained through visual representations of the entire model. For more complex noninterpretable black-box models, such as Artificial Neural Networks or Support Vector Machines, interpretability can be attained through a surrogate process where such models are approximated by interpretable ones <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b41">42]</ref>. Decision Trees <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b39">40,</ref><ref type="bibr" target="#b53">54]</ref> are commonly used as surrogate models <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b27">28]</ref>, and whether a surrogate or a classification model per se, the most common visual metaphor for global explanation is the node-link <ref type="bibr" target="#b41">[42,</ref><ref type="bibr" target="#b60">61]</ref>, such as the BaobaView technique <ref type="bibr" target="#b56">[57]</ref>. The node-link metaphor's problem is scalability <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b47">48,</ref><ref type="bibr" target="#b60">61]</ref>, mainly when it is used to create visual representations for Random Forests, limiting the model to be small in number of trees <ref type="bibr" target="#b50">[51]</ref>. Creating a scalable visual representation for an entire Random Forest model, presenting all decision paths (root node to leaf node paths), remains a challenge even with a considerably small number of trees <ref type="bibr" target="#b37">[38]</ref>.</p><p>Although the node-link metaphor is the straightforward representation for Decision Trees, logic rules extracted from decision paths have also been used to help on interpretation <ref type="bibr" target="#b36">[37]</ref>. Indeed, disjoint rules have shown to be more suitable for user interpretation than hierarchical representations <ref type="bibr" target="#b32">[33]</ref>, and a user test comparing the node-link metaphor with different logic rule representations, showed that Decision Tables <ref type="bibr" target="#b30">[31]</ref> (rules organized into tables) offers better comprehensibility properties <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b28">29]</ref>. Nonetheless, this strategy uses text for representing rules having as drawback model size <ref type="bibr" target="#b21">[22]</ref>. Similarly to Decision Tables, our method does not lean on the hierarchical property of Decision Trees. However, instead of using text to represent logic rules, we used a matrixlike visual metaphor, where rows are rules, columns are features, and cells are rules predicates, capable of displaying a much larger number of rules than the textual representations.</p><p>The idea of using a matrix metaphor to present rules is not new <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b41">42]</ref>, and it has been used before by the RuleMatrix technique <ref type="bibr" target="#b41">[42]</ref>. RuleMatrix is a model-agnostic approach to induce logic rules from black-box models, presenting rules in rows, features in columns, and predicates in cells using histograms. As data histograms require a certain display space to support human cognition, the number of rules displayed at once is reduced. Therefore, not being able to present entire or even parts of Random Forest models (notice that their focus is the visualization of surrogate rules, not models). Our approach also uses a matrix metaphor; however, we employ a simpler icon (colored rectangular shape) for the matrix cells, mapping different rule properties (e.g., predicates, class, and others), considerably improving the scalability of the visual representation. Besides the recognized scalability of matrix visualization and custom cells <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b3">4]</ref>, rows and columns order is an important principle <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b57">58]</ref>, and in our approach rules and features can be organized using different criteria, promoting analytical tasks not supported by the RuleMatrix, such as the holistic analysis of Random Forest models through complete overviews.</p><p>Worthy mentioning that different from usual matrix visual metaphors for trees and graphs that focus on nodes <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b24">25]</ref>, our approach focus on decision paths, which is the object of analysis on Decision Trees <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b36">37]</ref>, so representing a different concept.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Local Explanation</head><p>Unlike the model overview of global explanations, local explanation techniques focus on a particular instance classification result <ref type="bibr" target="#b45">[46,</ref><ref type="bibr" target="#b60">61]</ref>, aiming to improve users' trust in the prediction <ref type="bibr" target="#b44">[45]</ref>. As in global strategies, local explanations can be provided using inherently interpretable models or using surrogates of black-boxes <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b45">46,</ref><ref type="bibr" target="#b51">52]</ref>. In general, local explanations are constructed using the logic rule applied to classify the instance along with its properties (e.g., coverage, certainty, and fidelity), providing additional information for prediction reasoning <ref type="bibr" target="#b32">[33,</ref><ref type="bibr" target="#b41">42]</ref>.</p><p>One example of a visualization technique that supports local explanation is the RuleMatrix <ref type="bibr" target="#b41">[42]</ref>. RuleMatrix was applied to support the analysis of surrogate logic rules of Artificial Neural Networks and Support Vector Machine models. Local explanations are taken by analyzing the employed rules, observing the instance features values coupled with rules predicates and properties. Another interactive system closely related to our method is the iForest <ref type="bibr" target="#b60">[61]</ref>, combining techniques for Random Forest models local explanations. The iForest system focuses on binary classification problems, and for each instance, it allows the exploration of decision paths from Decision Trees using multidimensional projection techniques. A summarized decision path is built and displayed as a node-link diagram by selecting decision paths of interest (circles in the projection).</p><p>As discussed before, node-link diagrams are prone to present scalability issues. Although iForest reduces the associate issues by summarizing similar decision paths, it fails to present the overall picture of Random Forest classification models' voting committees. Our approach shows the voting committee by displaying all rules (decision paths) used by a model when classifying a particular instance, allowing insights into the feature space and class association by ordering rules and features in different ways. Also, our approach can be applied to multi-class problems, not only binary classifications, and, as iForest, it supports counterfactual analysis <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b35">36]</ref> by displaying the rules that, with the smallest changes, may cause the instance under analysis to switch its final classification.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">EXMATRIX</head><p>In this section, we present Explainable Matrix (ExMatrix), a visualization method to support Random Forest global and local interpretability.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Overview</head><p>To create a classifier, classification techniques take a labelled dataset X = {x 1 ,...,x N } with N instances and their classes</p><formula xml:id="formula_1">Y = {y 1 ,...,y N }, where y n ∈ C = {c 1 ,...,c J ≥ 2 } and x n consists of a vector x n = [x 1 n ,...,x M n ] with M features F = { f 1 ,..., f M } values,</formula><p>and build a mathematical model to compute a class y n when new instances x n / ∈ X are given as input. In this process, X is usually split into two different sets, one X train to build the model and one X test to test it. The existing techniques have adopted many different strategies to build a classifier. The Random Forest (RF) is an ensemble approach that creates multiple Decision Tree (DT) models DT 1 , ..., DT K of randomly selected subsets of features and/or training instances, and combines them to classify an instance using a voting strategy <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b53">54]</ref>. Therefore, a RF model is a collection of decision paths, belonging to different DTs, combined to classify an instance.</p><p>Aiming at supporting users to examine RF models and enable results audit, ExMatrix presents the decision paths extracted from DTs as logic rules using a matrix visual metaphor, supporting global and local explanations. ExMatrix arranges logic rules R = {r 1 ,...,r Z } as rows, features F = { f 1 ,..., f M } as columns, and rule predicates r z = [r 1 z ,...,r M z ] as cells, inspired by similar user-friendly and powerful matrix-like solutions <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b57">58]</ref>. <ref type="figure" target="#fig_0">Fig. 1</ref> depicts our method overview, composed mainly of two steps. One involving the vector rules extraction, where all decision paths of each DT k in the RF model are converted into vectors, and a second one where these vectors are displayed using a matrix metaphor to support explanations. The next sections detail these steps, starting with the vector rule extraction process.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Vector Rules Extraction</head><p>As mentioned, ExMatrix first step involves the transformation of each decision path, the path from a DT root node to a leaf node, into a vector rule representing the features' intervals for which the decision path is true. The resulting vectors present dimensionality equal to the number of features M, with coordinates composed of pairs representing the features' minimum and maximum interval values. In more mathematical terms, this process transforms, for every tree DT k , each decision path</p><formula xml:id="formula_2">p (o,d) (from the root node o to the leaf node d) into a disjoint logic rule (vector) r z . Let p (o,d) = {( f o θ o ),...,( f v θ v )} denotes a decision path,</formula><p>where each node i contains a logic test ∈ {" ≤ ", " &gt; "} bisecting the feature f i using a threshold θ i ∈ R, and that the node v is the parent of the leaf node d <ref type="bibr" target="#b60">[61]</ref>. To convert p </p><formula xml:id="formula_3">α m z = max(θ i | f i = f m , = " &gt; ") if ( f i = f m &gt; θ i ) ∈ p (o,d) min(x m |x m ∈ X) Otherwise.</formula><p>Similarly, the upper limit β m z is the minimum θ i ∈ p (o,d) for the feature f m and logic test = " ≤ ". If such combination does not exist in</p><formula xml:id="formula_4">p (o,d) , β m</formula><p>z is set to the maximum value of feature f m in X, that is</p><formula xml:id="formula_5">β m z = min(θ i | f i = f m , = " ≤ ") if ( f i = f m ≤ θ i ) ∈ p (o,d) max(x m |x m ∈ X) Otherwise.</formula><p>Beyond predicates, three other properties are extracted for each logic rule r z , being certainty, class, and coverage. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Visual Explanations</head><p>Once the vector rules are extracted, they are used to create the matrix visual representations for global and local interpretation. To guide our design process we adopted the iForest design goals (G1 -G3) <ref type="bibr" target="#b60">[61]</ref> and the RuleMatrix target questions (Q1 -Q4) <ref type="bibr" target="#b41">[42]</ref> summarized on <ref type="table">Table 1</ref>. These goals and questions consider classification model reasoning beyond performance measures (e.g., accuracy and error), focusing on the model internals. For global explanations, where the focus is an overview of a model, ExMatrix displays feature space ranges and class associations (G1 and Q1), and how reliable these associations are (Q2). For local explanations, where the focus is the classification of a particular instance x n , ExMatrix allows the analysis of x n values and features space ranges that resulted into the assigned class y n (G2 and Q3), and the inspection of the changes in x n that may lead to a different classification (G3 and Q4). <ref type="table">Table 1</ref>. ExMatrix design goals.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Global Local</head><p>G1 Reveal the relationships between features and predictions <ref type="bibr" target="#b60">[61]</ref>.</p><p>G2 Uncover the underlying working mechanisms <ref type="bibr" target="#b60">[61]</ref>. Q1 What knowledge has the model learned? <ref type="bibr" target="#b41">[42]</ref> G3 Provide case-based reasoning <ref type="bibr" target="#b60">[61]</ref>. Q2 How certain is the model for each piece of knowledge? <ref type="bibr" target="#b41">[42]</ref> Q3 What knowledge does the model utilize to make a prediction? <ref type="bibr" target="#b41">[42]</ref> Q4 When and where is the model likely to fail? <ref type="bibr" target="#b41">[42]</ref> ExMatrix implements these goals using a set of four functions: F3 -Ordering. Function L = f ordering (L, criteria,...) returns an ordered version L of a input set L following a given criterion, where L can be rules R or features F . This is used for both global and local explanations aiming at revealing patterns, a key property in matrix-like visualizations <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b57">58]</ref>, where rows and columns can be sorted in different ways, following, for instance, elements properties <ref type="bibr" target="#b31">[32]</ref> or similarity measures <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b48">49,</ref><ref type="bibr" target="#b55">56]</ref>.</p><p>F4 -Predicate Icon. Function f icon (r m z ,...) returns a cell icon (visual element) for a predicate r m z of the rule r z and feature f m . For global and local explanations, a cell icon is a color-filled rectangular element, allowing our visual metaphor to display a substantial number of logic rules at once. This is an important aspect since matrix-like visualizations can display a massive number of rows and columns relying on such icons not requiring many pixels <ref type="bibr" target="#b11">[12]</ref>. <ref type="figure" target="#fig_0">Fig. 1</ref> shows how these four functions are used in conjunction to build the visual representations for global and local interpretation. Functions F1 and F2 are used to select and map rules and features of interest. Function F3 is used to change the rows and columns order to help in finding interesting patterns, and function F4 is used to derive the predicate icon that can vary depending on the type of interpretation task (global or local). In the next section, we detail how these functions are used to build ExMatrix visual representations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.1">Global Explanation (GE)</head><p>Our first visual representation is an overview of RF models called Global Explanation (GE). Rules and features properties are also exhibited using additional rows and columns (goal Q2). The rule coverage r cov z is shown using an extra column on the left side of the table with cells' color (grayscale) and fill proportional to the coverage. The rules certainty r cert z is shown in an extra column in the right side of the table with cells split into colored rectangles with sizes proportional to the probability of the different classes. The feature importance is shown in an extra row on the top of the table with cells' color (grayscale) and fill proportional to the importance. Also, labels are added below the matrix, combining feature name and importance value. <ref type="figure" target="#fig_5">Fig. 2</ref> presents a ExMatrix GE visualization of a RF model for the Iris dataset with 3 trees with maximum depth equals to 3. In this example, the rows (rules) are ordered by extraction order, and the columns (features) follows the dataset order. The logic rule r 3 = [{6.15, 7.9}, ∅, ∅, {0.75, 1.75}] extracted from the decision path p (#0,#5) (see <ref type="figure" target="#fig_0">Fig. 1</ref>) is zoomed in. It is colored in orange since this is the color we assign to the versicolor class and it classifies 83% of the training instances as belonging to this class (17% belonging to virginica). Also, its coverage is r cov 3 = 0.28.  In addition to the coverage and certainty columns, in the ExMatrix LE/UR visualization, an extra column is added to represent the committee's cumulative voting. In this column, the cell at the i th row is split into colored rectangles with sizes proportional to the different classes' probability considering only the first i rules. In this way, given a matrix order (e.g., based on the rule coverage), it is possible to see from what rule the committee reaches a decision that is not changed even if the remaining rules are used to classify x n (indicated by a black line). Notice that this column's last cell always represents the committee's final decision regardless of rule ordering. <ref type="figure" target="#fig_2">Fig. 3</ref> presents the ExMatrix LE/UR representation for instance x 13 = [6.9, 3.1, 4.9, 1.5]. We use the same RF model of <ref type="figure" target="#fig_2">Fig. 2 with  3</ref> trees, so the RF committee uses 3 rules in the classification. The resulting matrix rows are ordered by rule coverage and columns by feature importance. The (optional) dashed line in each column indicates the values of the features of instance x 13 . According to the committee, the probability of x 13 to be versicolor is 72% and 28% to be virginica. Most of the virginica probability comes from the rule r 7 , which holds the lowest coverage. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.3">Local Explanation Showing Smallest Changes (LE/SC)</head><p>Our final matrix representation, called Local Explanation Showing Smallest Changes (LE/SC), is also designed to support results audit when classifying a given instance x n . In this visualization, for each DT k in the RF model, we display the rule requiring the smallest change to make DT k to change the classification of x n . Let r z be the rule extracted from DT k that is true when classifying (re,xn) = 0, the cell matrix is left blank. To help understand the class swapping, we add another column to the right of the table indicating the classification returned by the original rule r z , showing the difference to the similar rule r e that cause the DT k to change prediction. <ref type="figure" target="#fig_7">Fig. 4</ref> shows the ExMatrix LE/SC visualization for instance x 13 = [6.9, 3.1, 4.9, 1.5] from the same RF model of <ref type="figure" target="#fig_5">Fig. 2</ref>. Features F are ordered by importance and rules by change sum. The dashed lines represent the instance x 13 values. As an illustration, rule r 6 presents the smallest change in the feature "petal length" to replace a rule of majority class virginica for a rule of class versicolor, potentially increasing the RF original outcome of 72% for class versicolor on instance x 13 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">RESULTS AND EVALUATION</head><p>In this section, we present and evaluate our method through a usecase 1 discussing the proposed features, two usage-scenarios <ref type="bibr" target="#b22">23</ref> showing ExMatrix being used to explore RF models, finishing with a formal user test. All datasets employed in this section were downloaded from the UCI Machine Learning Repository <ref type="bibr" target="#b15">[16]</ref>, and the ExMatrix implementation is publicly available as a Python package at https: //pypi.org/project/exmatrix/ to be used in association with the most popular machine learning packages.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Use Case: Breast Cancer Diagnostic</head><p>In this use case, we utilize the Wisconsin Breast Cancer Diagnostic (WBCD) dataset to discuss how to use ExMatrix global and local explanations to analyze RF models. The WDBC dataset contains samples of breast mass cells of N = 569 patients, 357 classified as benign (B) and 212 as malignant (M), with M = 30 features (cells properties). The RF model used as example was created randomly selecting 70% of the instances for training and 30% for testing and setting the number of DTs to K = 128, not limiting their depths. The result is a model with 3, 278 logic rules, 25.6 rules per DT, and an accuracy of 99%.</p><p>An overview of this model is presented in <ref type="figure" target="#fig_10">Fig. 5(a)</ref> using the ExMatrix GE representation (see Sect. 3.3.1). In this visualization, rules are ordered by coverage and features by importance. Using this ordering scheme, it is possible to see that "concave mean", "area worst", and "radius worst" are the three most important features, whereas "smoothness std", "texture std", and "fractal dimension mean" are less important, and that the RF model used all 30 features. Also, taking only the high coverage rules and features with more importance ("concave mean' to "radius mean"), some patterns in terms of predicate ranges emerge. To help verify these patterns, low-coverage rules can be filtered out, resulting in a new visualization containing only high-coverage rules. <ref type="figure" target="#fig_10">Fig. 5(b)</ref> presents the resulting filtered visualization with rules ordered by class &amp; coverage facilitating the comparison between the two dataset classes. In this new visualization, it is apparent that low feature values appear to be related to class B whereas higher values to class M (goals G1, Q1, and Q2). In this example, filtering aids in focusing on what is important regarding the overall model behavior, removing unimportant information and reducing cluttering, relying on the so-called Schneiderman's visualization mantra <ref type="bibr" target="#b49">[50]</ref>.</p><p>The error rate of 1% in this model is due to the misclassification of only one instance of the test set. Instance x 29 was wrongly classified as class B with a probability of 55%. <ref type="figure" target="#fig_12">Fig. 6(a)</ref> shows the ExMatrix LE/UR representation (see Sect. 3.3.2) using x 29 as target instance. In this visualization, the matrix is ordered by class &amp; coverage to focus on the difference between classes, and some interesting patterns are visible. For instance, predicate ranges of both classes B and M overlap for most features, except for "fractal dimension std" and "concave std". Also, these two features, along with "symmetry std", "concave mean", "compactness std", and "symmetry mean" are more related to class B (blue) since rules of such class heavily use them and sparsely used by rules of class M (orange) showing what is actively used by the model to make the prediction (goals G2 and Q3). Besides, analyzing ExMatrix LE/SC visualization on <ref type="figure" target="#fig_12">Fig. 6(b)</ref>, one can notice that positive changes on features "concave mean" and "perimeter worst" may tie or alter the prediction of x 29 to class M since many green cells can be observed in the respective columns for rules of class M, while negative changes on "area worst" and "concavity means" increases its classification as class B since many purple cells can be observed in the respective columns for rules of class B (goals G3 and Q4).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Usage Scenario I: German Credit Bank</head><p>As a first hypothetical usage scenario, we describe a bank manager Sylvia incorporating ExMatrix in her data analytics pipeline. To speed up the evaluation of loan applications, she sends her dataset of years of experience to a data science team and asks for a classification system to aid in the decision-making process. Such dataset contains 1, 000 instances (customers profiles) and 9 features (customers information), with 700 customers presenting rejected applications and 300 accepted (here we use a pre-processed <ref type="bibr" target="#b60">[61]</ref> version of German Credit Data from UCI). For the implementation of such a system, Sylvia has two main requirements: (1) the system must be precise in classifying loan applications, and; (2) the classification results must be interpretable so she can explain the outcome.</p><p>To fulfill the requirements, the data science team builds an RF model setting the number of DTs to 32 with a maximum depth of 6. The  produced model's accuracy was 81%, resulting in 1, 273 logic rules, 38.7 rules per DT. Using the ExMatrix GE representation (omitted due to space constraints, see supplemental material), she observes that the features "Account Balance", "Credit Amount", and "Duration of Credit" are the three most important, whereas "Value Savings/Stocks", "Duration in Current address", and "Instalment percent" are the three less. Also, by inspecting the most generic knowledge learned by the system (patterns formed by high-coverage rules) using a filtered representation of the ExMatrix GE visualization on <ref type="figure" target="#fig_14">Fig. 7(a)</ref>, she notices that applications that request a credit to be paid in more extended periods (third column) tend to be rejected, matching her expectations. However, unexpectedly, customers without account ("Account Balance": 1 -No account, 2 -No balance, 3 -Below $200 , 4 -$200 or above) have less chance to have their application rejected (first column), something she did not anticipate (goals G1, Q1, and Q2). Although confronting some of her expectations and bias, she trusts her data, and the classification accuracy seems convincing, so she decides to put the system in practice.</p><p>One day she receives a new customer interest in a loan. After filling the system with his data, unfortunately, the application got rejected by the classification system. Based on the new European General Data Protection Regulation <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b38">39]</ref> that requires explanations about decisions automatically made, the customer requests clarification. By inspecting the ExMatrix LE/UR visualization on <ref type="figure" target="#fig_14">Fig. 7(b)</ref>, she notices, besides the denied probability of 65%, that even if all "approved" rules (blue) are used, very few high-certainty "denied" rules (orange) define the final decision of the model (see the Cumulative Voting and Rule Certainty columns), indicating that those rules, and the related logic statements, have a strong influence in the loan rejection. Also, she sees that the feature "Length of current employment" is the most directly related to the denied outcome since it is used only by rules that result in rejection (goals G2 and Q3). Using this information, she explains to the customer that since he is working for less than one year in the current job (2 as "Length of current employment" corresponds to less than 1 year), the bank recommends denying the application. However, analyzing the ExMatrix LE/SC representation in <ref type="figure" target="#fig_14">Fig. 7(b)</ref>, she realizes that negative changes in features "Credit Amount" and "Duration of Credit" may turn the outcome to approved (goals G3 and Q4). Thereby, as an alternative, she suggests lowering the requested amount and the number of installments. Based on the observable differences to make the rules change class, she notices that upon reducing the credit application from $1, 207 to $867 and the number of payments from 24 to 15, the system changes recommendation to "approved". <ref type="figure" target="#fig_14">Fig. 7(d)</ref>   presents the ExMatrix LE/UR visualization if such suggested values are used, changing the final classification.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Usage Scenario II: Contraceptive Method</head><p>This last usage scenario presents Christine, a public health policy manager who wants to create a contraceptive campaign to advertise a new, safer drug for long term use. To investigate married wives' preferences, Christine's data science team creates a prediction model using a data set with information about contraceptive usage choices her office collected past year (here we use the Contraceptive Method Choice dataset from UCI). The dataset contains 1, 473 samples (married wives profiles) with 9 features, where each instance belongs to one of the classes "No-use", "Long-term", and "Short-term", regarding the contraceptive usage method, with 42.7% of the instances belonging to class No-use, 22.6% to Long-term, and 34.7% to Short-term.</p><p>Since interpretability is mandatory in this scenario, allowing the results to be used in practice, the data science team creates an RF model and employs ExMatrix to support analysis. To create the model, the team set the number of DTs to 32 and maximum depth to 6, resulting in 1, 383 logic rules, 43.2 rules per DT. The RF model accuracy is 63%, and, although not ideal for individual classifications, can be used to understand general knowledge learned by the model from the dataset.</p><p>By inspecting the ExMatrix GE representation of the model (omitted due to space constraints, see supplemental material), she readily understands that the features "Number of children ever born", "Wife age", and "Wife education" are the three most relevant for defining the contraceptive method class, while "Media exposure", "Wife now working?", and "Wife religion" are the three less. Also, further exploring a filtered version of the ExMatrix GE representation on <ref type="figure">Fig. 8</ref>, to focus only on high-coverage and high-certainty rules ordered by class, she notices some interesting patterns regarding features space ranges and classes. For instance, lower values for the feature "Number of children ever born" (first column) are more related to class No-use and rarely related to class Long-term. For contraceptive method usage, higher values for the feature "Wife age" (second column) are related to class Long-term, while average and lower values are more related to class Short-term. Also, higher values for "Wife education" (third column) are more related to class Long-term (goals G1, Q1, and Q2). Based on these observations, and given the modest budget she received for the campaign, Christine decides to focus on the group of older and highly educated wives with at least one child to target the campaign's first phase.  . ExMatrix explanations of a RF model for the German Credit Data UCI dataset. Based on the most generic knowledge learned by the RF model (rules with high coverage) (a), it is possible to conclude that applications requesting credit to be paid in longer periods tend to be rejected. Analyzing one sample (instance x 154 ) of rejected application (c), it is possible to infer that it is probably rejected due to the (applicant) short period working in the current job. However, lowering the requested amount as well as the number of instalments can change the RF's decision (d) and (e). <ref type="figure">Fig. 8</ref>. ExMatrix GE representation (rules filtered by coverage and certainty) of the RF model for the Contraceptive Method Choice UCI dataset. Based on high-coverage high-certainty rules, some interesting patterns can be observed. For instance, on contraceptive method usage, older women tend to use long-term contraceptive methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">User Study</head><p>To evaluate the ExMatrix method, we performed a user study to assess the proposed visual representations for global and local explanations.</p><p>In this study, we asked four different questions based on the ExMatrix visualizations created for the use-case presented in Sect. 4.1, focusing on evaluating the goals presented in <ref type="table">Table 1</ref>.</p><p>The study started with video tutorials about RF basic concepts and how to use ExMatrix to analyze RF models and classification results through the proposed explanations. A total of 13 users participated, 69.2% male and 30.8% female, aged between 24 to 36, all with a background in machine learning. The participants were asked to analyze the explanations of <ref type="figure" target="#fig_10">Fig. 5(a)</ref>, <ref type="figure" target="#fig_12">Fig. 6(a)</ref>, and <ref type="figure" target="#fig_12">Fig. 6(b)</ref>, where each analysis was followed by different question(s) (see <ref type="table">Table 2</ref>). On the visualizations, features names were replaced by "Feature 1" to "Feature 30" and classes names by "Class A" and "Class B", aiming at removing any influence of knowledge domain in the results, since our focus is to assess the visual metaphors.</p><p>Using the ExMatrix GE representation <ref type="figure" target="#fig_10">(Fig. 5(a)</ref>), 76.9% of the participants were able to identify patterns involving feature space ranges and classes, where, for high coverage rules, low features values are more related to class B, while features with large values are more related to class M (Qst 1). Using the ExMatrix LE/UR ( <ref type="figure" target="#fig_12">Fig. 6(a)</ref>), also 76.9% of the participants were able to recognize that feature "concave std" is the most related to class B for instance x 29 classification outcome (Qst 2). Using the ExMatrix LE/SC ( <ref type="figure" target="#fig_12">Fig. 6(b)</ref>), 61.5% of the participants were able to identify that negative changes on instance x 29 features "area worst" and "concavity mean" values would better support the class B outcome (Qst 3), and 46.2% were able to identify that positive changes on features "concave mean" and "perimeter worst" values may alter the outcome from class B to class M (Qst 4).</p><p>In general, the results were promising for the first two analyses, but the participants present worse results when interpreting the ExMatrix LE/SC visualization. This is not surprising since this representation requires a much better background about RF theory. The ExMatrix GE and LE/UR visualizations are more generic and involve much fewer concepts about how RF models work internally. In contrast, the ExMatrix LE/SC requires a good level of knowledge about ensembles models and how the voting system work when making a prediction. Although most of the users self-declared with a background in machine learning, only 30% are RF experts.</p><p>We also have asked subjective, open questions, and, in general, users gave positive feedbacks about ExMatrix explanations, where the visualizations were classified as visually pleasing and useful for understanding RF models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">DISCUSSION AND LIMITATIONS</head><p>Although the natural choice to visualize a tree collection is to use tree structure metaphors, two main reasons make disjoint rules organized into tables a better option when analyzing DTs and especially RFs. First, using tree structure metaphors, the visual comparison of logic rules (decision paths) can be overwhelming since different paths from the root to the leaves define different orders of attributes, slowing down users when searching within a tree to answer classification questions <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b28">29]</ref>. An issue that is amplified in RFs, since multiple DTs are analyzed collectively. In contrast, in a matrix metaphor, the attributes are considered in the same order easing this process <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b28">29]</ref>. Second, given the constraints of usual DT inference methods (non-overlapping predicates with open intervals), features can be used multiple times in a <ref type="table">Table 2</ref>. User study questions. single decision path resulting in multiple nodes (one per test) using the same feature. Consequently, if tree structures are employed, each feature's decision intervals need to be mentally composed by the user, and nodes using the same feature can be far away in the decision path. The decision intervals are explicit in the matrix representation and can be easily compared across multiples rules and trees. Therefore, although tree structure visual metaphors are the usual choice when hierarchical structures are the focus <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b47">48]</ref>, on DTs and RFs, the decision paths are the object of analysis <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b53">54]</ref> and transforming paths into disjoint rules organized into tables emphasize what is essential (see supplemental material).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Question</head><p>Considering the above points, it is clear that scalability for RFs visualization is not just a choice of getting a visual metaphor that can represent millions of nodes, but getting a visual representation that is scalable and still properly supports essential analytical tasks (see <ref type="table">Table 2</ref>). Something much more complex than merely visualizing a forest of trees. In this scenario, ExMatrix renders a promising solution, supporting the analysis of many more rules concomitantly than the existing state-of-the-art techniques. However, it is not a perfect solution. ExMatrix covers two different perspectives of RFs, conveying Global and Local information. In the Local visualization, scalability is not a problem since one rule is used per DT, so even for RFs with hundreds or even thousands of trees, ExMatrix scales well. However, for Global visualization, scalability can be an issue since the number of rules substantially grows with the number of trees. Although we can represent one rule per line of pixels, we are limited by the display resolution, and, even when the display space suffices, ExMatrix layouts can be cluttered and tricky to explore.</p><p>The solution we adopt to address scalability was to implement the so-called Schneiderman's visualization mantra <ref type="bibr" target="#b49">[50]</ref>, allowing users to start with an overview of the model, getting details-on-demand by filtering rules to focus on specific sets of interest. Although users are free to select any subset of rules, considering that the goal of the Global visualization is to generate insights about the overall models' behavior, here we mainly explore filtering low-coverage rules since they are only valid for a few specific data instances (that is the coverage definition). Although simple, such a solution makes the analysis of entire models easier by removing unimportant information and reducing cluttering. Another potential solution is to make the rows' height proportional to coverage or certainty so that the rules with the lowest coverage or certainty are less prominent (visible) and could even be combined in less than one line of pixels. We have not tested this approach and left it as future work.</p><p>Regarding the user study, although the results were satisfactory and within what we expect for the ExMatrix GE and LE/UR visualizations, the results for the ExMatrix LE/SC representation were sub-optimal, and the XAI Question Bank <ref type="bibr" target="#b35">[36]</ref> can help us to shed some light about the reasons. According to this bank, the GE addresses the leading question "How (global)", whereas the LE/UR addresses the leading question "Why", enabling to answer inquiries such as"What are the top rules/features it uses?" and "Why/how is this instance given this prediction?". However, the LE/SC involves three leading questions, "What If ", "How to be that", and "How to still be this", where the changes on instance feature values are presented supporting hypotheses (not answers), which shown to be too complex for the users. We believe that designing visual representations to answer each of these questions individually would be more effective and may reach better results.</p><p>Nevertheless, as discussed in the User Study section, participants' low performance not only resulted from the visual metaphor but also the expertise on RF models. Among the participants, few know the RF technique in detail, indicating that people with less expertise can use ExMatrix GE and LE/UR visualizations, but the LE/SC representation is more suitable for experts. In general, despite the complexity of the questions we ask participants to solve, they acknowledged the ExMatrix potential, expressing encouraging remarks, including "... this solution ... allows a deeper understanding of how each particular rule or feature impacted on the final the decision/classification." or "I think the ExMatrix can be used in a variety of domains, from E-commerce to Healthcare...".</p><p>Although we design ExMatrix with RF interpretability in mind, it can be readily applied to DT models, such as the ones used as surrogates for black-box models as Artificial Neural Networks and Support Vector Machines, or approaches based on logic rules such as Decision Tables since the core of our method is the visualization of rules. Another compelling scenario that can be explored is the engineering of models. In this case, through rule selection and filtering, simplified models could be derived where, for instance, only high coverage rules are employed or any other subset of interest. Also, model construction and improvement can be supported. The visual metaphors we propose can be easily applied to the analysis and comparison of RF models resulting from different parametrizations, such as different numbers of trees and their maximum depth. Therefore, allowing machine learning engineers to go beyond accuracy and error when building a model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">CONCLUSIONS AND FUTURE WORK</head><p>In this paper, we present Explainable Matrix (ExMatrix), a novel method for Random Forest (RF) model interpretability. ExMatrix uses a matrix-like visual metaphor, where logic rules are rows, features are columns, and rules predicates are cells, allowing to obtain overviews of models (Global Explanations) and audit classification results (Local Explanations). Although simple, ExMatrix visual representations are powerful and support the execution of tasks that are challenging to perform without proper visualizations. To attest ExMatrix usefulness, we present one use-case and two hypothetical usage scenarios, showing that RF models can be interpreted beyond what is granted by usual metrics, like accuracy or error rate. Although our primary goal is to aid in RF models global and local interpretability, the ExMatrix method can also be applied for the analysis of Decision Trees, such as the ones used as surrogates models, or any other technique based on logic rules, opening up new possibilities for future development and use. We plan as future work to create new ordering and filtering criteria along with aggregation approaches to improve the current ExMatrix explanations and, more importantly, to conceive new ones. Another fascinating forthcoming work is creating optimized rule-based models from complex RF models, which we also intend to investigate.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Explainable Matrix (ExMatrix) overview. ExMatrix is composed of two main steps. In the first, decision paths of the RF model under analysis are converted into logic rules. Then, in the second, these rules are displayed using a matrix metaphor to support global and local explanations.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>(o,d) into a vector rule r z = [r 1 z , ..., r M z ], each element r m z = {α m z , β m z } is computed representing the intervals covered by p (o,d) if and only if f m ∈ p (o,d) . Otherwise, r m z = ∅. Considering f m ∈ p (o,d) , the lower limit α m z is the maximum θ i ∈ p (o,d) for the feature f m and logic test = " &gt; ". If such combination does not exist in p (o,d) , α m z is set to the minimum value of feature f m in X, that is</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>3 =</head><label>3</label><figDesc>The rule certainty r cert z is a vector of probabilities for each class c j ∈ C, obtained from the decision path (leaf node value). The rule class r class z is the c j ∈ C with the highest probability on the rule certainty r cert z . The rule coverage r cov z is the number of instances in X train of class r class z for which r z is valid divided by the total number of instance of r class z in X train . The vector rules extraction process results in a set of disjoint logic rules R = {r 1 , ..., r Z }, where each rule r z classifies an instance x n belonging to class r class z if its predicates r z = [r 1 z ,...,r M z ] are all true for the feature values in x n .As an example of vector rule extraction, consider the zoomed DT inFig. 1from a RF for the Iris dataset [21], with 150 instances in three classes C = {setosa, versicolor, virginica} and 4 features F = {sepal length , sepal width , petal length , petal width}. From this tree, the decision path p (#0,#5) is transformed into the vector rule r 3 = [{6.15, 7.9}, ∅, ∅, {0.75, 1.75}] with r class versicolor, since rule certainty equals to r cert 3 = [0.0, 0.83, 0.17] (leaf node #5 value), indicating that r 3 is valid for 83% of the versicolor instances and 17% of virginica instances in X train . The rule coverage r cov 3 = 0.28 as r 3 is valid for 10 out of 35 versicolor instances in X train .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>F1-</head><label></label><figDesc>Rules of Interest. Function R = f rules (R,...) returns a subset of rules of interest R ⊆ R. For global explanations f rules (R,...) returns the entire vector rules set R = R or a subset R ⊂ R defined by the user, while for local explanations f rules (R, x n ,...) returns a subset R ⊂ R related to a given instance x n . F2 -Features of Interest. Function F = f f eatures (R ,...) returns features of interest F ⊆ F considering a set of rules of interest R . For global explanations f f eatures (R ,...) returns all features used by the RF model, whereas for local explanations f f eatures (R , x n ,...) returns the features used to classify a given instance x n .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>To build this matrix, R = f rules (R,...) returns all logic rules R or a subset R ⊂ R defined by the user, and F = f f eatures (R ,...) returns all features used by at least one rule r z ∈ R . As previously explained, matrix rows represent logic rules, columns features, and cells rules predicates (icons). Rows and columns can be ordered using different criteria (L = f ordering (L, criteria,...)). The rows can be ordered by rules' coverage, certainty, class &amp; coverage, and class &amp; certainty, while columns can be ordered by feature importance, calculated using the Mean Decrease Impurity (MDI) [8]. For the ExMatrix GE visualization, the matrix cell icon representing the rule predicate r m z consists of a rectangle ( f icon (r m z ,...)) colored according to the rule class r class z , positioned and sized inside the matrix cell proportional to the predicate limits {α m z , β m z }, where the left side of the matrix cell represents the value min(x m |x m ∈ X) and the right side max(x m |x m ∈ X) (goals G1 and Q1). The cell background not covered by the predicate limits can be either white or be filled using a less saturated color. If no predicate is present, the matrix cell is left blank.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 2 .</head><label>2</label><figDesc>ExMatrix Global Explanation (GE) of a RF model for the Iris dataset containing 3 trees with maximum depth equal to 3. Rows represent logic rules, columns features, and matrix cells the predicates. Additional rows and columns are also used to represent rule coverage and certainty. One matrix row is highlighted to exemplify how the rules' information is transformed into icons.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 3 . 3 . 3 . 2</head><label>3332</label><figDesc>ExMatrix Local Explanation showing the Used Rules (LE/UR) visualization. Three rules are used by the RF committee to classify a given instance as belonging to the versicolor class with 72% of probability. The dashed line in each column indicates the features' values of the instance. Local Explanation Showing the Used Rules (LE/UR) The second visual representation, called Local Explanation Showing the Used Rules (LE/UR), is a matrix to help in auditing the results of a RF model providing explanations for the classification of a given instance x n . In this process, R = f rules (R, x n ) returns all logic rules used by the model to classify x n (goals G2 and Q3). As in the ExMatrix GE visualization, F = f f eatures (R ) returns all features used by logic rules R , f icon (r m z , X) returns a cell icon representing predicates limits, and f ordering (L, criteria) can order rules R by coverage, certainty, class &amp; coverage, and class &amp; certainty, and features F by importance.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 4 .</head><label>4</label><figDesc>ExMatrix Local Explanation Showing Smallest Changes (LE/SC) visualization. Three rules with the smallest change to make the DTs to change class decisions are displayed. The rule in the first row presents the smallest change. Small perturbations may change the RF classification decision.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head></head><label></label><figDesc>x n , in this process we seek for the rule r e from DT k with r class e = r class z that presents the minimum summation of changes to the values of x n that makes r e true and r z false, that is,Δ (re,xn) = ∑ M m=1 (Δ m (re,xn) ), where Δ m (re,xn) = min(|α m e −x m n |,|β m e −x m n |) | max(x m |x m ∈Xtrain)−min(x m |x m ∈Xtrain)| , function R = f rules (R, xn ) returns the list of logic rules that can potentially change the classification process outcome requiring the lowest changes (goals G3 and Q4), and function F = f f eatures (R , x n ) returns the features used by the rules in R . Beyond the ordering criteria for rules and features previously discussed, function f ordering (L, criteria) also allows ordering using the change summation ∑ M m=1 (Δ m (re,xn) ). Finally, function f icon (r m e , x n ) returns a rectangle positioned and sized proportional to the change Δ m (re,xn) , with positive changes colored in green and negative in purple, with the cell matrix background filled using a less saturated color. If Δ m</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head></head><label></label><figDesc>(a) ExMatrix GE visualization.(b) ExMatrix GE representation with filtered rules (only high-coverage rules).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Fig. 5 .</head><label>5</label><figDesc>ExMatrix GE representations of the WDBC RF model. In (a), giving the ordering scheme by rule coverage and feature importance, some patterns emerge in terms of predicates ranges. In (b) the low-coverage rules are filtered-out to help focusing the analysis on what is important. Low feature values appear to be more related to class B whereas higher values to class M for the most important features.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head></head><label></label><figDesc>(a) ExMatrix LE/UR for instance x 29 , showing the used rules on the classification process. (b) ExMatrix LE/SC for instance x 29 , presenting changes in the instance feature values to make the DTs to change class prediction.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Fig. 6 .</head><label>6</label><figDesc>ExMatrix local explanations of the WDBC RF model. Two different visualizations are displayed, one showing the rules employed in the classification of a target instance (a), and one presenting the smallest changes to make the trees of the model to change the prediction of that instance (b). In both cases, the target instance is the only misclassified instance.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head></head><label></label><figDesc>(a) ExMatrix GE showing rules filtered by coverage and certainty. (b) ExMatrix LE/UR for instance x 154 . (c) ExMatrix LE/SC for instance x 154 . (d) ExMatrix LE/UR modifying instance x 154 , which changes RF's decision.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>Fig. 7</head><label>7</label><figDesc>Fig. 7. ExMatrix explanations of a RF model for the German Credit Data UCI dataset. Based on the most generic knowledge learned by the RF model (rules with high coverage) (a), it is possible to conclude that applications requesting credit to be paid in longer periods tend to be rejected. Analyzing one sample (instance x 154 ) of rejected application (c), it is possible to infer that it is probably rejected due to the (applicant) short period working in the current job. However, lowering the requested amount as well as the number of instalments can change the RF's decision (d) and (e).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head>Goals Visualization Qst 1 -Qst 2 -Qst 3 -Qst 4 -</head><label>1234</label><figDesc>About features space ranges and class ASSOCIATIONS. Considering rules with HIGH COVERAGE, and features with HIGH IMPORTANCE, select your answer: (three options of associations) G1, Q1, and Q2 Fig. 5(a) Instance 29 is classified as Class A with a probability of 55%, against 45% for Class B. What feature is more related to Class A and less related to Class B? (four options of features) Select the pair of features where DELTA CHANGES on instance 29 will potentially INCREASE Class A probability, and by that may SUPPORT its classification as Class A. (four options of features pairs) Select the pair of features where DELTA CHANGES on instance 29 will potentially INCREASE Class B probability, and by that may ALTER its classification as Class A. (four options of features pairs) G3 and Q4 Fig. 6(b)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>Popolin Neto is with Federal Institute of São Paulo (IFSP) and University of São Paulo (USP), Brazil. E-mail: mariopopolin@ifsp.edu.br • F. V. Paulovich is with Dalhousie University, Canada, and University of São</figDesc><table /><note>Paulo (USP), Brazil. E-mail: paulovich@dal.ca Manuscript received xx xxx. 201x; accepted xx xxx. 201x. Date of Publication xx xxx. 201x; date of current version xx xxx. 201x. For information on obtaining reprints of this article, please send e-mail to: reprints@ieee.org. Digital Object Identifier: xx.xxxx/TVCG.201x.xxxxxxx els</note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">https://popolinneto.gitlab.io/exmatrix/papers/2020/ieeevast/usecase/ 2 https://popolinneto.gitlab.io/exmatrix/papers/2020/ieeevast/usagescenarioi/ 3 https://popolinneto.gitlab.io/exmatrix/papers/2020/ieeevast/usagescenarioii/</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS</head><p>The authors wish to thank the valuable comments and suggestions obtained from the reviewers, as well as the support received from the Qualification Program of the Federal Institute of São Paulo (IFSP). We acknowledge the support of the Natural Sciences and Engineering Research Council of Canada (NSERC).</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Weighted graph comparison techniques for brain connectivity analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Alper</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Bach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Henry Riche</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Isenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-D</forename><surname>Fekete</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, CHI 13</title>
		<meeting>the SIGCHI Conference on Human Factors in Computing Systems, CHI 13<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page">483492</biblScope>
		</imprint>
	</monogr>
	<note>Association for Computing Machinery</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Visualizing Sets and Set-typed Data: State-of-the-Art and Future Challenges</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Alsallakh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Micallef</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Aigner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Hauser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Miksch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Rodgers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EuroVis -STARs. The Eurographics Association</title>
		<editor>R. Borgo, R. Maciejewski, and I. Viola</editor>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Visual classification: An interactive approach to decision tree construction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ankerst</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Elsen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ester</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H.-P</forename><surname>Kriegel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fifth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD &apos;99</title>
		<meeting>the Fifth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD &apos;99<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="1999" />
			<biblScope unit="page" from="392" to="396" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Matrix reordering methods for table and network visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Behrisch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Bach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Henry Riche</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Schreck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-D</forename><surname>Fekete</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics Forum</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="693" to="716" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Matrix reordering methods for table and network visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Behrisch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Bach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Henry Riche</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Schreck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-D</forename><surname>Fekete</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics Forum</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="693" to="716" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A random forest guided tour</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Biau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Scornet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TEST</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="197" to="227" />
			<date type="published" when="2016-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Random forests</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Breiman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning</title>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="page" from="5" to="32" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Manual on setting up, using, and understanding random forests v3</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Breiman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">58</biblScope>
			<pubPlace>CA, USA, 1</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Statistics Department University of California Berkeley</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Classification and Regression Trees</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Breiman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Friedman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Olshen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Stone</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1984" />
			<publisher>Chapman and Hall/CRC</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Machine learning for molecular and materials science</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">T</forename><surname>Butler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">W</forename><surname>Davies</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Cartwright</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Isayev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Walsh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">559</biblScope>
			<biblScope unit="issue">7715</biblScope>
			<biblScope unit="page" from="547" to="555" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">V</forename><surname>Carvalho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">M</forename><surname>Pereira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">S</forename><surname>Cardoso</surname></persName>
		</author>
		<title level="m">Machine learning interpretability: A survey on methods and metrics. Electronics</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">8</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Matrix visualization and information mining</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-H</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H.-G</forename><surname>Hwu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W.-J</forename><surname>Jang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-H</forename><surname>Kao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-J</forename><surname>Tien</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Tzeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H.-M</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computational Statistics</title>
		<editor>J. Antoch</editor>
		<meeting><address><addrLine>Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Physica-Verlag HD</publisher>
			<date type="published" when="2004" />
			<biblScope unit="page" from="85" to="100" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Generalized association plots: information visualization via iteratively generated correlation matrices</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sinica</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Taipei</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Statistica Sinica</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="7" to="29" />
			<date type="published" when="2002-01" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">ivisclassifier: An interactive visual analytics system for classification based on supervised dimension reduction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Choo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kihm</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Park</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2010 IEEE Symposium on Visual Analytics Science and Technology</title>
		<imprint>
			<date type="published" when="2010-10" />
			<biblScope unit="page" from="27" to="34" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Applications of machine learning in cancer prediction and prognosis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Cruz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">S</forename><surname>Wishart</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cancer Informatics</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">117693510600200030</biblScope>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">UCI machine learning repository</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Dheeru</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">Karra</forename><surname>Taniskidou</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Surrogate decision tree visualization interpreting and visualizing black-box classification models with surrogate decision tree</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Di</forename><surname>Castro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Bertini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CEUR Workshop Proceedings</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">2327</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Towards simple, easy to understand, an interactive decision tree algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T.-N</forename><surname>Do</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">College Inf. Technol</title>
		<imprint>
			<biblScope unit="page" from="6" to="7" />
			<date type="published" when="2007" />
		</imprint>
		<respStmt>
			<orgName>Can tho Univ., Can Tho</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Tech. Rep</note>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Techniques for interpretable machine learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Hu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">The state of the art in integrating machine learning into visual analytics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Endert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Ribarsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Turkay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">W</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Nabney</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">D</forename><surname>Blanco</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Rossi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics Forum</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="458" to="486" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">The use of multiple measurements in taxonomic problems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">A</forename><surname>Fisher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Annals of Eugenics</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="179" to="188" />
			<date type="published" when="1936" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Comprehensible classification models: A position paper</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Freitas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIGKDD Explor. Newsl</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="10" />
			<date type="published" when="2014-03" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Supporting analysis of dimensionality reduction results with contrastive learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Fujiwara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Kwon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="45" to="55" />
			<date type="published" when="2020-01" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Vice: Visual counterfactual explanations for machine learning models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Holter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Bertini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th International Conference on Intelligent User Interfaces</title>
		<meeting>the 25th International Conference on Intelligent User Interfaces<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2020" />
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page">531535</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">A survey of multiple tree visualisation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Graham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kennedy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Visualization</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">235252</biblScope>
			<date type="published" when="2010-12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Local rule-based explanations of black box decision systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Guidotti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Monreale</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ruggieri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Pedreschi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Turini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Giannotti</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">A survey of methods for explaining black box models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Guidotti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Monreale</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ruggieri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Turini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Giannotti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Pedreschi</surname></persName>
		</author>
		<idno>93:1-93:42</idno>
	</analytic>
	<monogr>
		<title level="j">ACM Comput. Surv</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="issue">5</biblScope>
			<date type="published" when="2018-08" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">On the art and science of machine learning explanations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Hall</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">An empirical evaluation of the comprehensibility of decision table, tree and rule based predictive models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Huysmans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Dejaeger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Mues</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Vanthienen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Baesens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Decision Support Systems</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="141" to="154" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Interactive learning of ad-hoc classifiers for video visual analytics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Hferlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Netzel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hferlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Weiskopf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Heidemann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2012 IEEE Conference on Visual Analytics Science and Technology (VAST)</title>
		<imprint>
			<date type="published" when="2012-10" />
			<biblScope unit="page" from="23" to="32" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">The power of decision tables</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Kohavi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 8th European Conference on Machine Learning, ECML&apos;95</title>
		<meeting>the 8th European Conference on Machine Learning, ECML&apos;95<address><addrLine>Berlin, Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="1995" />
			<biblScope unit="page" from="174" to="189" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">A workflow for visual diagnostics of binary classifiers using instance-level explanations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Dasgupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Swartz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Aphinyanaphongs</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Bertini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2017 IEEE Conference on Visual Analytics Science and Technology (VAST)</title>
		<imprint>
			<date type="published" when="2017-10" />
			<biblScope unit="page" from="162" to="172" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Interpretable decision sets: A joint framework for description and prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lakkaraju</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">H</forename><surname>Bach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22Nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD &apos;16</title>
		<meeting>the 22Nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD &apos;16<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1675" to="1684" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">An interactive machine learning framework</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Cheng</surname></persName>
		</author>
		<idno>abs/1610.05463</idno>
		<imprint>
			<date type="published" when="2016" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Understanding the prediction process of deep networks by forests</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2018 IEEE Fourth International Conference on Multimedia Big Data (BigMM)</title>
		<imprint>
			<date type="published" when="2018-09" />
			<biblScope unit="page" from="1" to="7" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Questioning the ai: Informing design practices for explainable ai user experiences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">V</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Gruen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Miller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems</title>
		<meeting>the 2020 CHI Conference on Human Factors in Computing Systems<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2020" />
			<biblScope unit="volume">20</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Domain knowledge integration in data mining using decision tables: case studies in churn prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Lima</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Mues</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Baesens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Operational Research Society</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1096" to="1106" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Visual diagnosis of tree boosting methods</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="163" to="173" />
			<date type="published" when="2018-01" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Interpretable deep convolutional neural networks via meta-learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Matwin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2018 International Joint Conference on Neural Networks (IJCNN)</title>
		<imprint>
			<date type="published" when="2018-07" />
			<biblScope unit="page" from="1" to="9" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Fifty years of classification and regression trees</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W.-Y</forename><surname>Loh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Statistical Review</title>
		<imprint>
			<biblScope unit="volume">82</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="329" to="348" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Visual exploration of classification models for risk assessment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Migut</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Worring</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2010 IEEE Symposium on Visual Analytics Science and Technology</title>
		<imprint>
			<date type="published" when="2010-10" />
			<biblScope unit="page" from="11" to="18" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Rulematrix: Visualizing and understanding classifiers with rules</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ming</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Bertini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="342" to="352" />
			<date type="published" when="2019-01" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">An approach to supporting incremental visual data classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">G S</forename><surname>Paiva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">R</forename><surname>Schwartz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Pedrini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Minghim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="4" to="17" />
			<date type="published" when="2015-01" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Visualizing the hidden activity of artificial neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">E</forename><surname>Rauber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">G</forename><surname>Fadel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">X</forename><surname>Falco</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">C</forename><surname>Telea</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="101" to="110" />
			<date type="published" when="2017-01" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">why should i trust you?: Explaining the predictions of any classifier</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">T</forename><surname>Ribeiro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Guestrin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</title>
		<meeting>the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2016" />
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page">11351144</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title level="m" type="main">Anchors: High-precision modelagnostic explanations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">T</forename><surname>Ribeiro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Guestrin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Treevis.net: A tree visualization reference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Schulz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer Graphics and Applications</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="11" to="15" />
			<date type="published" when="2011-11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">The design space of implicit hierarchy visualization: A survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Schulz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Hadlak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Schumann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="393" to="411" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">A survey of binary similarity and distance measures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Hyuk Cha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Systemics, Cybernetics and Informatics</title>
		<imprint>
			<biblScope unit="page" from="43" to="48" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">The eyes have it: a task by data type taxonomy for information visualizations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Shneiderman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings 1996 IEEE Symposium on Visual Languages</title>
		<meeting>1996 IEEE Symposium on Visual Languages</meeting>
		<imprint>
			<date type="published" when="1996" />
			<biblScope unit="page" from="336" to="343" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Using visual interpretation of small ensembles in microarray analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Stiglic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mertik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Podgorelec</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Kokol</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">19th IEEE Symposium on Computer-Based Medical Systems (CBMS&apos;06)</title>
		<imprint>
			<date type="published" when="2006-06" />
			<biblScope unit="page" from="691" to="695" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">An efficient explanation of individual classifications using game theory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Strumbelj</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Kononenko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="1" to="18" />
			<date type="published" when="2010-03" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Ensemblematrix: Interactive visualization to support machine learning with multiple classifiers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Talbot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kapoor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">S</forename><surname>Tan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, CHI &apos;09</title>
		<meeting>the SIGCHI Conference on Human Factors in Computing Systems, CHI &apos;09<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="1283" to="1292" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<monogr>
		<title level="m" type="main">Introduction to data mining</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P.-N</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Steinbach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Kumar</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
	<note>Pearson, 1 edition</note>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Paintingclass: Interactive construction, visualization and exploration of decision trees</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">T</forename><surname>Teoh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K.-L</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Ninth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD &apos;03</title>
		<meeting>the Ninth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD &apos;03<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2003" />
			<biblScope unit="page" from="667" to="672" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Selection of proximity measures for matrix visualization of binary data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Tzeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2009 2nd International Conference on Biomedical Engineering and Informatics</title>
		<imprint>
			<date type="published" when="2009-10" />
			<biblScope unit="page" from="1" to="9" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Baobabview: Interactive construction and analysis of decision trees</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Van Den Elzen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">J</forename><surname>Van Wijk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2011 IEEE Conference on Visual Analytics Science and Technology (VAST)</title>
		<imprint>
			<date type="published" when="2011-10" />
			<biblScope unit="page" from="151" to="160" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H.-M</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Tzeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-H</forename><surname>Chen</surname></persName>
		</author>
		<title level="m">Matrix Visualization</title>
		<meeting><address><addrLine>Berlin Heidelberg; Berlin, Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2008" />
			<biblScope unit="page" from="681" to="708" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<monogr>
		<title level="m" type="main">Beyond sparsity: Tree regularization of deep models for interpretability</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hughes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Parbhoo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zazzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Doshi-Velez</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<monogr>
		<title level="m" type="main">Evaluating explanation without ground truth in interpretable machine learning. CoRR, abs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Hu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1907" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">iforest: Interpreting random forests via visual analytics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">L</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Cui</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="407" to="416" />
			<date type="published" when="2019-01" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
