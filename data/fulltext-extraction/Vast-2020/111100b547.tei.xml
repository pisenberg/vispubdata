<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/pisenberg/grobid/grobid-0.6.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">StackGenVis: Alignment of Data, Algorithms, and Models for Stacking Ensemble Learning Using Performance Metrics</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Angelos</forename><surname>Chatzimparmpas</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">are with Linnaeus University</orgName>
								<address>
									<settlement>Växjö</settlement>
									<country key="SE">Sweden</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="laboratory">Exploration Loop Data Visualization Models Best &amp; Diverse Models&apos; Selection Algorithms&apos; &amp; Parameters&apos; Exploration Data Space Models&apos; Space Predictions&apos; Space Data Preprocessing &amp; Wrangling Finding Action Verification Loop Hypothesis Insight Knowledge Generation Loop</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rafael</forename><forename type="middle">M</forename><surname>Martins</surname></persName>
							<affiliation key="aff1">
								<orgName type="laboratory">Exploration Loop Data Visualization Models Best &amp; Diverse Models&apos; Selection Algorithms&apos; &amp; Parameters&apos; Exploration Data Space Models&apos; Space Predictions&apos; Space Data Preprocessing &amp; Wrangling Finding Action Verification Loop Hypothesis Insight Knowledge Generation Loop</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kostiantyn</forename><surname>Kucher</surname></persName>
							<affiliation key="aff1">
								<orgName type="laboratory">Exploration Loop Data Visualization Models Best &amp; Diverse Models&apos; Selection Algorithms&apos; &amp; Parameters&apos; Exploration Data Space Models&apos; Space Predictions&apos; Space Data Preprocessing &amp; Wrangling Finding Action Verification Loop Hypothesis Insight Knowledge Generation Loop</orgName>
							</affiliation>
						</author>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Kerren</surname></persName>
							<email>andreas.kerren@lnu.se</email>
							<affiliation key="aff1">
								<orgName type="laboratory">Exploration Loop Data Visualization Models Best &amp; Diverse Models&apos; Selection Algorithms&apos; &amp; Parameters&apos; Exploration Data Space Models&apos; Space Predictions&apos; Space Data Preprocessing &amp; Wrangling Finding Action Verification Loop Hypothesis Insight Knowledge Generation Loop</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">StackGenVis: Alignment of Data, Algorithms, and Models for Stacking Ensemble Learning Using Performance Metrics</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<note type="submission">received xx xxx. 201x; accepted xx xxx. 201x.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2021-02-19T20:23+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Stacking</term>
					<term>stacked generalization</term>
					<term>ensemble learning</term>
					<term>visual analytics</term>
					<term>visualization G1. Human-centered Ensemble Learning G3. Supporting Verification G5. Cognitive Biases G2. Supporting Exploration G4. Interaction Guidance</term>
				</keywords>
			</textClass>
			<abstract>
				<p>Fig. 1. Constructing performant stacking ensembles from scratch with StackGenVis: (a) a panel for uploading data sets and choosing weights for performance metrics; (b) the history preservation panel with the composition and performance achieved by the user-built stored stacking ensembles; (c) the comparison of the metamodel&apos;s performance for both the active and stored stackings, based on four performance metrics (linked to view (a) with a dice glyph showing four); (d) the three exploration modes for the algorithms, data, and models; (e) the projection-based models&apos; space visualization, which summarizes the results of all the selected performance metrics for all models; and (f) the predictions&apos; space visual embedding, which arranges the data instances based on the collective outcome of the models in the current stored stack S6 (marked in bold typeface in (b)).</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Stacking methods (or stacked generalizations) refer to a group of ensemble learning methods <ref type="bibr" target="#b45">[45]</ref> where several base models are trained and combined into a metamodel with improved predictive power <ref type="bibr" target="#b63">[63]</ref>.</p><p>In particular, stacked generalization can reduce the bias and decrease the generalization error when compared to the use of single learning algorithms. To accomplish that, stacking enables the blending of different and heterogeneous algorithms and their instantiations with particular parameters, i.e., models. Other types of ensemble methods are bagging techniques, such as random forests (RF) <ref type="bibr" target="#b1">[2]</ref>, and boosting techniques, such as adaptive boosting (AdaB) <ref type="bibr" target="#b15">[16]</ref> or gradient boosting (GradB) <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b20">21]</ref>. A major difference between these ensemble methods is that stacking can use both bagging and boosting techniques in combination with simpler algorithms, stacked in different layers. It uses a meta-learner to aggregate the predictions of the last layer and obtain the best performance, which is absent in the other ensemble methods.</p><p>In numerous Kaggle competitions <ref type="bibr" target="#b19">[20]</ref>, stacking ensembles led to award-winning results. But, when studying such ensembles, it is very hard to understand why specific instances, features, algorithms, and models were selected instead of others. Indeed, one of the major challenges in stacking is to select the best combinations of algorithms and models when designing a stacking ensemble from scratch. This issue may keep machine learning (ML) practitioners and experts away from working with complex stacking ensemble methods, even though they could arguably reach very high-performance results. One question that arises from the work by Naimi and Balzer <ref type="bibr" target="#b38">[38]</ref> is: (RQ1) how to build a stacking ensemble for a given problem with a focus on avoiding such trial and error methods, and/or increasing the overall efficiency?</p><p>In spite of this challenge of hardly understanding why a specific configuration works <ref type="bibr" target="#b57">[57]</ref>, predicting the relation of supply-demand <ref type="bibr" target="#b60">[60]</ref> and anomaly/bug reports <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b18">19]</ref> are areas where stacking has been used successfully. Compelling accuracy results <ref type="bibr" target="#b59">[59]</ref> were also observed for text data, where stacking is better than alternative techniques such as voting ensembles <ref type="bibr" target="#b50">[50]</ref>. Above all, mixtures of stacked models have been deployed to increase the performance of results in medicine <ref type="bibr" target="#b29">[30,</ref><ref type="bibr" target="#b37">37,</ref><ref type="bibr" target="#b39">39]</ref>. In the case of healthcare-related problems, however, the difficulties of stacking lead to an even worse situation, because interpretability, fairness in decisions, and trustworthiness of ML models are very critical in the medical field <ref type="bibr" target="#b8">[9]</ref>. The recent survey by Sagi and Rokach <ref type="bibr" target="#b45">[45]</ref> lists the users' ability to understand how to tune the models as one of the important factors for selecting the appropriate ensemble learning method, too. Thus, another open question is: (RQ2) how to monitor and control the complete process of training stacking ensembles, while preserving confidence and trust in their predictive results?</p><p>Performance metrics, such as precision or f1-score, are typically adopted to validate if the ML results meet the expectations of the experts and the domain <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b41">41,</ref><ref type="bibr" target="#b52">52,</ref><ref type="bibr" target="#b56">56]</ref>. Multiple metrics are important to avoid the dangers of using single metrics, such as accuracy <ref type="bibr" target="#b31">[32,</ref><ref type="bibr" target="#b54">54]</ref>, for every data set. However, comparison and selection between multiple performance indicators is not trivial, even for widely used metrics <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b46">46]</ref>; alternatives such as Matthews correlation coefficient (MCC) might be more informative for some problems <ref type="bibr" target="#b7">[8]</ref>. Further open challenges of using advanced metrics are described in the literature <ref type="bibr" target="#b26">[27,</ref><ref type="bibr" target="#b42">42]</ref>. This leads to one further question: (RQ3) what performance/validation metrics fit better to a specific data set, and how can they be combined?</p><p>Stacking ensemble learning inspired us to focus on each of the three aforementioned questions that represents an open research challenge. In this paper, we present a knowledge generation model for ensemble learning with the use of visualization (derived from Sacha et al. <ref type="bibr" target="#b44">[44]</ref>), and instantiate this model as our visual analytics (VA) system for stacked generalization. Our system, called StackGenVis (see <ref type="figure">Fig. 1</ref>), tries to address the three questions described above by supporting the exploratory combination of 11 different ML algorithms and 3,106 individual models using 8 performance metrics with various modes (see the details in Sect. 4). To address those three open research challenges (RQ1-RQ3), StackGenVis supports the following workflow: (i) the selection of appropriate validation metrics, (ii) the exploration of algorithms, (iii) the data wrangling, (iv) the exploration of models, and (v) an overarching phase, where the resulting stack is traced and the performance of the stored stack is compared to the current active metamodel. In summary, our contributions consist of the following:</p><p>• the composition of a knowledge generation model (KGM) specifically adapted for ensemble learning with the use of VA;</p><p>• the implementation of a VA system, called StackGenVis, that follows the KGM mentioned above, consists of novel views that treat models and predictions as high-dimensional vectors, and supports the visual exploration of the most performant and most diverse models for the creation of stacking ensembles;</p><p>• the applicability of our proposed system with two use cases, using real-world data, that confirm the effectiveness of utilizing multiple validation metrics and comparing stacking ensembles; and</p><p>• the discussion of the followed methodology and the outcomes of several expert interviews that indicate encouraging results.</p><p>The rest of this paper is organized as follows. In the next section, we discuss the literature related to visualization of ensemble learning. Afterwards, we describe the knowledge generation model for ensemble learning with VA, design goals, and analytical tasks for attaching VA to ensemble learning. Sect. 4 presents the functionalities of the tool and, at the same time, describes the first use case with the goal of improving another stacking ensemble's results for healthcare data. Next, we demonstrate the applicability and usefulness of StackGenVis with our own real-world data set focusing on sentiment/stance in texts. Thereafter in Sect. 6, we discuss the feedback our VA system received during the conducted expert interviews by summarizing the opinions of the experts and the limitations that lead to possible future work for our approach. Finally, Sect. 7 concludes our paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK</head><p>Visualization systems have been developed for the exploration of diverse aspects of bagging, boosting, and further strategies such as "bucket of models". Stacking, however, has so far not received comparable attention by the InfoVis/VA communities: actually, we have not found any literature describing the construction and improvement of stacking ensemble learning with the use of VA. In this section, we briefly discuss previous works on bagging, boosting, and buckets of models, and highlight their differences with StackGenVis in order to substantiate the novelty of our approach.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Bagging and Boosting</head><p>EnsembleLens <ref type="bibr" target="#b65">[65]</ref> is a VA system that focuses on the identification of the best combination of models by visualizing their correlation. Specific feature subsets are chosen to train each algorithm-a technique known as feature bagging. Then, the results are combined and ranked based on the performance outcomes for anomalous cases. In contrast, our work is not limited to the anomaly detection task, and it focuses on construction of better-performing ensembles by combining multiple algorithms and using appropriate performance metrics. BEAMES <ref type="bibr" target="#b10">[11]</ref> focuses on regression tasks, and it includes four learning algorithms and a model sampling technique. The output of the system is a ranking that helps the user to decide on a model. In our approach, a metamodel automatically chooses well-performing models. BEAMES includes three performance metrics: (a) residual error, (b) mean squared error, and (c) r-squared error, which are specialized for regression problems. Interestingly, the authors suggest as future work that "there are open research questions about how best to compare multiple models directly". In our system, we address this challenge with the exploration of a finite space of solutions, employing 11 algorithms (that can be further expanded). Exploration of feature importance and instances in BEAMES involves a standard table representation and recommendation of best-performing models for specific instances. In StackGenVis, we present different ways for direct manipulation of instances, highlighting hard-to-classify instances. Three separate techniques are incorporated for feature selection, visualized by an aggregated table heatmap view.</p><p>iForest <ref type="bibr" target="#b68">[68]</ref> is a VA system that uses dimensionality reduction (DR) to summarize the predictions of each instance; other views explain decision paths of an RF. It also highlights the relationship between the features of the data set and the prediction outcomes. For a specific instance, a new DR projection can be used to show which models performed well or not, and why. The goals and challenges addressed Human Computer <ref type="figure">Fig. 2</ref>. Knowledge generation model for ensemble learning with VA derived from the model by Sacha et al. <ref type="bibr" target="#b44">[44]</ref>. On the left, it illustrates how a VA system can enable the exploration of the data and the models with the use of visualization. On the right, a number of design goals assist the human in the exploration, verification, and knowledge generation for ensemble learning.</p><p>by iForest are different than ours: it strives to open the black box of a specific algorithm, while StackGenVis uses a parallel and modelagnostic strategy accompanied by high-level monitoring of the process. Additionally, we utilize multiple validation metrics simultaneously to explore diverse models, instead of relying on decision trees only.</p><p>Similarly to iForest, BoostVis <ref type="bibr" target="#b24">[25]</ref> also uses DR and other views to compare and improve ML algorithms such as XGBoost <ref type="bibr" target="#b6">[7]</ref> or Light-GBM <ref type="bibr" target="#b20">[21]</ref>. The goal is to diagnose and debug the training process of underperforming trees, which are visualized with trajectories in a DR projection. Our work, in contrast, focuses on the appropriate selection of models to enhance-as much as possible-the prediction power of a stacking ensemble. Moreover, we use three alternative techniques to rank the most important features for several hundreds or thousands of models, and we use multiple performance metrics, with user-defined weightings, to characterize the results.</p><p>Schneider et al. <ref type="bibr" target="#b47">[47]</ref> employed both bagging and boosting ensembles in an effort to combine the data and model space. The authors applied scatterplots and DR projections for the visualization of the data space, with the goal to add, delete, or replace models from the ensemble model space. Pairs of validation metrics allow the user to select the best models (sorted by performance or similarity). A selection results in an update of the data space. Our approach of aligning the data and model spaces is influenced by this work, but we improved the process by aggregating the alternative performance metric results on top of the projections. Furthermore, we allow the users to define specific weights for each metric and focus on the models that perform well for both the entire data space and specific instances. Finally, StackGenVis does not support direct manipulation of model ensembles <ref type="bibr" target="#b47">[47]</ref>, as it focuses on exploration of a large solution space before narrowing down to specific well-performing and diverse models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Buckets of Models</head><p>In a bucket of models, the best model for a specific problem is automatically chosen from a set of available options. This strategy is conceptually different to the ideas of bagging, boosting, and stacking, but still related to ensemble learning. Chen et al. <ref type="bibr" target="#b5">[6]</ref> utilize a bucket of latent Dirichlet allocation (LDA) models for combining topics based on criteria such as distinctiveness and coverage of the set of actions performed. Pie charts on top of projections show probability distributions of action classes. Although this work is not similar to StackGenVis in general, we use a gradient color scale to map the performance of each model in the projected space. EnsembleMatrix <ref type="bibr" target="#b55">[55]</ref> linearly fuses multiple models with the help of a confusion matrix representation, while supporting comparison and contrasting for model exploration. In our VA system, the user can explore how models perform on each class of the data set, and the performance metrics are instilled into a combined user-driven value. Manifold <ref type="bibr" target="#b66">[66]</ref> generates pairs of models and compares them over all classes of a data set, including feature selection. We adopt a similar approach, but instead of comparing a large number of models in a pairwise manner, we aggregate their overall and per-class performance. Then, the user can compare a set of models against the average of all the models before deciding which ones to use.</p><p>There is also a group of works that focuses specifically on regression problems <ref type="bibr" target="#b36">[36,</ref><ref type="bibr" target="#b48">48,</ref><ref type="bibr" target="#b67">67]</ref>. For instance, the more recent tool iFuseML <ref type="bibr" target="#b48">[48]</ref> operates with prediction errors in order to present ensemble models with more accurate predictions to the users. The comparison of models is very different in our approach: we use preliminary results from performance metrics in order to select the appropriate models that will boost the final stack performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">DESIGN GOALS AND ANALYTICAL TASKS</head><p>In this section, we explain the main design goals that base the development of StackGenVis, together with a knowledge generation model (KGM) for ensemble learning <ref type="figure">(Fig. 2)</ref>. Then, we describe the analytical tasks that StackGenVis (and any other VA system) should tackle in order to support the presented KGM with regard to stacking methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Design Goals: Visual Analytics to Support Ensemble Learning</head><p>In the following, we define five design goals (G1-G5) built on top of the knowledge generation model for VA proposed by Sacha et al. <ref type="bibr" target="#b44">[44]</ref>. This original model has two core pillars: the computer <ref type="figure">(Fig. 2, left</ref>) and the human <ref type="figure">(Fig. 2, right)</ref>. On the computer side, the VA system comprises data, visualization(s), and model(s). The human side depicts the knowledge generation process, comprising the loops for exploration, verification, and knowledge generation.</p><p>Our design goals focus on the knowledge generation in ensemble learning with the use of VA, originating from the analysis of the related work in Sect. 2, our own experiences when developing VA tools for ML (e.g., t-viSNE <ref type="bibr" target="#b4">[5]</ref>), and recently conducted literature reviews <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b3">4]</ref>. We slightly extended the original knowledge generation model for VA <ref type="bibr" target="#b44">[44]</ref> to make a better fit for supporting ensemble learning with VA (cf. the description of design goal G1) and then aligned our design goals to the different model parts, see the gray boxes in <ref type="figure">Fig. 2</ref>.</p><p>G1: Incorporate human-centered approaches for controlling ensemble learning. For our first design goal, we modified the original knowledge generation model for VA <ref type="bibr" target="#b44">[44]</ref> by adding components specifically related to ensemble methods <ref type="bibr" target="#b45">[45]</ref>. Ensemble learning can be controlled in different ways. Starting from the data, visualization can be used to explore the data space <ref type="figure">(Fig. 2</ref>, upper blue arrow) <ref type="bibr" target="#b47">[47]</ref>. This offers new possibilities for direct manipulation of both instances and features. Visualization also enhances the interaction with data preparation ( <ref type="figure">Fig. 2</ref>, upper red arrow) <ref type="bibr" target="#b24">[25]</ref>. Data preprocessing and wrangling benefits from feedback provided by a VA system, for example, in the form of validation metrics that increase the per-model performance of several heterogeneous ML models used in ensemble learning. Next, VA is useful for the exploration and final selection of different algorithms that have numerous parameters leading to well-performing models <ref type="figure">(Fig. 2</ref>, lower blue arrow) <ref type="bibr" target="#b10">[11]</ref>. These models produce predictions that can be stored again as new metadata. If visualized, this predictions' space can be manipulated accordingly for raising the overall predictive performance <ref type="figure">(Fig. 2</ref>, lower green arrow). The process of ensemble learning generates a solution space of models <ref type="figure">(Fig. 2</ref>, curved green arrow) <ref type="bibr" target="#b47">[47]</ref> and more investigations can be done to choose between the best and most diverse models of an ensemble <ref type="figure">(Fig. 2</ref>, curved red arrow). The careful design, choice, and arrangement of these aspects and the balance between human-centered vs. automated approaches are essential concepts when developing a VA system <ref type="bibr" target="#b49">[49]</ref>. Moreover, the different perspectives of analysts working on a problem can push toward more efficient and effective solutions or receiving results in a shorter amount of time. Synchronous and asynchronous collaboration can empower visualizations dedicated to particular tasks <ref type="bibr" target="#b16">[17]</ref>. Building ensembles from scratch by using various ML algorithms might require expert collaboration and intervention, especially when those experts are specialized on individual algorithms. If a VA system supports asynchronous and/or synchronous communication, an individual expert can share his/her knowledge with the others, which could lead to a more desirable outcome.</p><p>G2: Support exploration. VA systems enable users to reach crucial findings and to take actions according to them. This iterative process requires a human-in-the-loop who can thus explore the data and the model through the interactive visualization <ref type="bibr" target="#b0">[1]</ref>. As the solution space for ensemble learning is more confusing compared to single ML techniques, keeping track of the history of events and providing provenance for exploring and backtracking of alternative paths is necessary to reach this goal. Furthermore, provenance in VA for ensemble learning increases the interpretability and explainability caused by the complex nature of the method. Although provenance in VA systems has been in the research focus during the past years <ref type="bibr" target="#b40">[40,</ref><ref type="bibr" target="#b43">43]</ref>, the work on utilizing analytic provenance <ref type="bibr" target="#b64">[64]</ref> is still limited.</p><p>G3: Support verification. According to the insights gained from the exploration process, users are able to formulate new hypotheses that can be efficiently tested with the help of interactive visualization. This goal is valuable especially for ensemble methods, which are harder to train and verify than individual ML models. Annotations within a visualization are used to share insights between analysts or to save information for later use. In storytelling, for example, the annotation is considered as a key element <ref type="bibr" target="#b58">[58]</ref>. Keeping notes linked to particular views of a VA system for ensemble learning could be essential for remembering key findings and core actions for reaching good performance results.</p><p>G4: Facilitate human interaction and offer guidance. During development of any VA tool, it is key to decide on concrete visual representations and interaction technologies between multiple coordinated views. It is not uncommon to find gaps between visualization design guidelines and their applicability in implemented tools <ref type="bibr" target="#b35">[35]</ref>, and providing guidance in the complex human-machine analytical process is another challenge <ref type="bibr" target="#b9">[10]</ref>. Many different facets are involved in VA for ensemble learning, ranging from diverse ML models and data sets to performance metrics. From a visualization perspective, this heterogeneity leads to multiple views. A careful visual design of the linked views that facilitate human interaction and sophisticated VA systems that guide the user to important aspects will help to disentangle the visual complexity and, in consequence, the cognitive load of the user.</p><p>G5: Reveal and reduce cognitive biases. Visualizations should be carefully chosen in order to reduce cognitive biases. Cognitive bias is, in simple terms, a human judgment that drifts away from the actual information that should be conveyed by a visualization, i.e., it "involves a deviation from reality that is predictable and relatively consistent across people" <ref type="bibr" target="#b12">[13]</ref>. The use of visualization for ensemble learning could possibly introduce further biases to the already blurry situation based on the different ML models involved. Thus, the thorough selection of both interaction techniques and visual representations that highlight and potentially overcome any cognitive biases is a major step toward realizing this design goal.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Analytical Tasks for Stacking</head><p>To fulfill our design goals specifically in the context of stacking ensemble learning, we have derived five high-level analytical tasks that should be solved by our VA system described in Sect. 4.</p><p>T1: Search the solution space for the most suitable algorithms, data, and models for the task. Some of the major challenges of stacking are the choice of the most suitable algorithms and models, the data processing necessary for the selected models, further improvements for the models, and reduction of the complexity of the stack (G1). This workflow should be assisted by guidance at different levels, including the selection of proper performance metrics for the particular problem and the comparison of results against the current stack.</p><p>T2: Explore the history with all basic actions of the stacking ensemble preserved. There is a large solution space of different learning methods and concrete models which can be combined in a stack. Hence, the identification and selection of particular algorithms and instantiations over the time of exploration is crucial for the the user. One way to manage this is to keep track of the history of each model. Analysts might also want to step back to a specific previous stage in case they reached a dead end in the exploration of algorithms and models (G2).</p><p>T3: Manage the performance metrics for enhancing trust in the results. Many performance or validation metrics are used in the field of ML. For each data set, there might be a different set of metrics to measure the best-performing stacking. Controlling the process by alternating these metrics and observing their influence in the performance can be an advantage (G3).</p><p>T4: Compare the results of two stages and receive feedback to guide interaction. To assist the knowledge generation, a comparison between the currently active stack against previously stored versions is important. In general, this includes monitoring the historical process of the stacking ensemble, facilitating interaction and guidance (G4).</p><p>T5: Inspect the same view with alternative techniques and visualizations. To eventually avoid the appearance of cognitive biases, alternative interaction methods and visual representations of the same data from another perspective should be offered to the user (G5).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">STACKGENVIS: SYSTEM OVERVIEW AND APPLICATION</head><p>Following our design goals and derived analytical tasks, we implemented StackGenVis, an interactive VA system that allows users to build powerful stacking ensembles from scratch. Our system consists of six main interactive visualization panels (see <ref type="figure">Fig. 1</ref>): (1) performance metric selection (→ T3), (2) history monitoring of stackings (→ T2), (3) ML algorithm exploration, (4) data wrangling, (5) model exploration (→ T1 and T5), and (6) performance comparison between stacks (→ T4). We use the following workflow when applying StackGenVis: (i) we choose suitable performance metrics for the data set, which are then used for validation during the entire building process ( <ref type="figure">Fig. 1(a)</ref>); (ii) in the next algorithm exploration phase, we compare and choose specific ML algorithms for the ensemble and then proceed with their particular instantiations, i.e., the models; (iii) during the data wrangling phase, we manipulate the instances and features with two different views for each of them; (iv) model exploration allows us to reduce the size of the stacking ensemble, discard any unnecessary models, and observe the predictions of the models collectively ( <ref type="figure">Fig. 1(d)</ref>); and (v) we track the history of the previously stored stacking ensembles in <ref type="figure">Fig. 1(b)</ref> and compare their performances against the active stacking ensemble-the one not yet stored in the history-in <ref type="figure">Fig. 1(c)</ref>.</p><p>StackGenVis works with 11 ML algorithms that can be further subdivided into seven separate groups/types: (a) a neighbor classifier (k-nearest neighbor (KNN)), (b) a support vector machine classifier (SVC), (c) a naïve Bayes classifier (Gaussian (GauNB)), (d) a neural network classifier (multilayer perceptron (MLP)), (e) a linear classifier ExtraT performances seem to be equal. However in (d), after resetting class optimization, ExtraT models appear to perform better overall. In view (e), the boxplots were replaced by point clouds that represent the individual models of activated algorithms. The color encoding is the same as for the algorithms, but unselected models are greyed out. Finally, the radar chart in (f) displays a portion of the models' space in black that will be used to create the initial stack against the entire exploration space in yellow. The chart axes are normalized from 0 to 100%. (logistic regression (LR)), (f) two discriminant analysis classifiers (linear (LDA) and quadratic (QDA)), and (g) four ensemble classifiers (RF, extra trees (ExtraT), AdaB, and GradB).</p><p>In the following subsections, we explain the system by using a medicine data set, called heart disease, taken from the UCI Machine Learning repository <ref type="bibr" target="#b13">[14]</ref>. The data set consists of 13 numerical features/attributes and 303 instances.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Data Sets and Performance Metrics</head><p>As mentioned in Sect. 1, the selection of the right performance metrics for different types of analytical problems and/or data sets is challenging. For example, a medical expert is usually very careful when it comes to handle false negative cases, since human lives may be at stake. In StackGenVis, we offer the option of using eight different metrics with distinct levels of contribution for each, depending on what is appropriate for each individual case. The available metrics are grouped into: threshold (→ accuracy, g-mean, precision, recall, f-beta score, and MCC); ranking (→ ROC AUC); and probability (→ log loss).</p><p>To illustrate how to choose different metrics (and with which weights), we start our exploration by selecting the heart disease data set in <ref type="figure">Fig. 1(a)</ref>. Knowing that the data set is balanced, we pick accu-racy (weight = 100%) instead of g-mean (weight = 0%), as seen in <ref type="figure">Fig. 1(a)</ref>. The positive class (diseased) is more important than the cases that are healthy, so we use precision and recall instead of ROC AUC (0%). We also decide that the reproducibility of the results is slightly more important than simply reaching high precision, so we decrease the weight of precision to 80%. For the f-beta metric, the f2-score is chosen because false negative cases should be better monitored, since they are more important for the underlying problem. MCC is a combination of all f-beta scores and shows us both the false positive and false negative results, which is especially useful for comparing it with the f2-score. Log loss penalizes outliers, and in our case, we should be aware of outliers as we have sensitive healthcare data. Finally, four of the performance metrics include one more option-they are marked with an asterisk in <ref type="figure">Fig. 1(a)</ref>-to compute the individual metric based on micro-, macro-, or weighted-average. Micro-average aggregates the contributions of all classes to compute the average metric, whereas macro-average computes the metric independently for each class and then takes the average (therefore treating all classes equally). Weightedaverage calculates the metrics for each label and finds their average weighted by support (the number of true instances for each label). The data set is a binary classification problem and contains 165 diseased and 138 healthy patients. Hence, we choose micro-average to weight the importance of the largest class, even though the impact is low because of the lack of any significant imbalance for the dependent variable. The dice glyphs visible on the right hand side of <ref type="figure">Fig. 1(a)</ref> are static and only used to indicate that specific views do not use all pre-selected metrics. For instance, the performance comparison view <ref type="figure">Fig. 1(c)</ref> only uses four metrics. After this initial tuning of the metrics, we press the Confirm button to move further to the exploration of algorithms. <ref type="figure" target="#fig_0">Fig. 3(a.1, a.</ref>2) presents the initial views of the 11 algorithms (and their models) currently implemented in StackGenVis. <ref type="figure" target="#fig_0">Fig. 3(a.1)</ref> uses boxplots to represent the performance of the currently unselected algorithms/models based on the metrics combination discussed previously. This compact visual representation provides an overview to users and allows them to decide which algorithms or specific models perform better based on statistical information. <ref type="figure" target="#fig_0">Fig. 3(a.2)</ref> displays overlapping barcharts for depicting the per-class performances for each algorithm, i.e., two colors for the two classes in our example. The more saturated bar in the center of each class bar represents the altered performance when the parameters of algorithms are modified. Note that the view only supports three performance metrics: precision, recall, and f1-score. The y-axes in both figures represent aggregated performance, while the different algorithms are arranged along the x-axis with different colors. <ref type="figure" target="#fig_0">Fig. 3(a.1)</ref> shows that KNN models perform well, but not all of them. We can click the KNN boxplot and further explore and tune the model parameters for KNN with an interactive parallel coordinates plot, as shown in <ref type="figure" target="#fig_0">Fig. 3(b)</ref>, where six models are selected by filtering. Wang et al. <ref type="bibr" target="#b62">[62]</ref> experimented with alternative visualization designs for selecting parameters, and they found that a parallel coordinates plot is a solid representation for this context as it is concise and also not rejected by the users. A drawback is the complexity of it compared to multiple simpler scatterplots. <ref type="figure" target="#fig_0">Fig. 3(c.1)</ref> indicates that, after the parameter tuning, the selected KNN models (narrow, more saturated bars) perform better than the average (wide, less saturated bars) and are thus good picks for our ensemble. Next, we perform similar steps for RF vs. ExtraT without class optimization as shown in <ref type="figure" target="#fig_0">Fig. 3(a.2, d</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Exploration of Algorithms</head><p>Such iterative exploration proceeds for every algorithm until we are satisfied, see <ref type="figure" target="#fig_0">Fig. 3</ref>(e) where six algorithms are selected for our initial stack S1 . <ref type="figure" target="#fig_0">Fig. 3(f)</ref> shows a radar chart providing an overview of the entire space of available algorithms (yellow contour) against the current selection of models per algorithm (black star plot). In brackets, we show the number of all models for each algorithm, together with its name and representative color ( <ref type="figure" target="#fig_0">Fig. 3(a.1, e)</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Data Wrangling</head><p>Pressing the Execute Stacking Ensemble button leads to the stacking ensemble shown in <ref type="figure">Fig. 1(b, S1</ref> ) with the performances shown at the end of the circular barcharts (in %) and in <ref type="figure">Fig. 1(c, S1</ref> ). Alternative designs we considered instead of the circular barcharts are standard barcharts or radial plots, but the labels of both would capture more vertical or horizontal space, respectively. In both panels, the performance of the metamodel is monitored with 4 out of the 8 metrics, which are accuracy, precision, recall, and f1-score. The line chart view is linked to the metrics of <ref type="figure">Fig. 1</ref> with a dice glyph showing four. In <ref type="figure">Fig. 1(c)</ref>, we encode the active stacking metrics with blue color and the stored stackings of <ref type="figure">Fig. 1(b, S1 -S6</ref> ) in red.</p><p>Data Space/Data Instances. <ref type="figure" target="#fig_1">Fig. 4(a)</ref> is a t-SNE projection <ref type="bibr" target="#b61">[61]</ref> of the instances (MDS <ref type="bibr" target="#b21">[22]</ref> and UMAP <ref type="bibr" target="#b30">[31]</ref> are also available in order to empower the users with various perspectives for the same problem, based on the DR guidelines from Schneider et al. <ref type="bibr" target="#b47">[47]</ref>). The point size is based on the predictive accuracy calculated using all the chosen models, with smaller size encoding higher accuracy value. Hence, we want to further investigate cases that cause problems (i.e., we have to look for large points). The parallel coordinates plot in <ref type="figure" target="#fig_1">Fig. 4(b)</ref> is used to investigate the features of the data set in detail.</p><p>The Ca attribute, for example, has a range of 0-3, but by selection we can see five points with Ca values of '4', see <ref type="figure" target="#fig_1">Fig. 4(b)</ref>. These values can be considered as unknown and should be further examined. One of these points belongs to the healthy class (due to the olive color) but is very small in <ref type="figure" target="#fig_1">Fig. 4(c.1)</ref>-meaning that it does not reduce the accuracy. Four points are part of the diseased class. One of those is rather large which affects negatively the prediction accuracy of our classification (see <ref type="figure" target="#fig_1">Fig. 4(c.1)</ref> in the upper right corner). In <ref type="figure" target="#fig_1">Fig. 4(c.2)</ref>, we select the point with our lasso interaction. We have then several options to manipulate this point as shown in <ref type="figure" target="#fig_0">Fig. 4(c.3)</ref>: we can remove the point's instance entirely from the data set or merge a set of points into a new one, which receives either their mean or median values per feature. Similarly, we can compose a new point (i.e., an additional instance) from a set of points. The history manager saves the aforementioned manipulations or restores the previous saved step on demand. For our problematic point, we decide to remove it, and the metamodel performance increases as seen in Step 1 of <ref type="figure">Fig. 1(c)</ref> for the active model in blue. We then store this new stack and get the ensemble shown in <ref type="figure">Fig. 1(b, S2 )</ref> and <ref type="figure">Fig. 1(c, S2 )</ref>. The details about the model's performance and parameters used can also be displayed with a tooltip.</p><p>Data Features. For the next stage of the workflow, we focus on the data features. Three different feature selection approaches can be used to compute the importance of each feature for each model in the stack. Univariate feature importance is identical for all models, but different for each feature. Permutation feature importance is measured by observing how random re-shuffling of each predictor influences model performance. Accuracy feature importance removes features one by one, similar to permutation, but then retrains each model by receiving only the accuracy as feedback. These last two approaches are very resource-intensive; therefore, they can be turned off for larger data sets (by disabling Detailed Feature Search in <ref type="figure">Fig. 1(a)</ref>). For our example in <ref type="figure">Fig. 5(a)</ref>, they are enabled. We normalize the importance from 0 to 1 and use a two-hue color encoding from dark red to dark green to highlight the least to the most important features for our current stored stack, see <ref type="figure">Fig. 5(b)</ref>. The panel in <ref type="figure">Fig. 5(c)</ref> uses a table heatmap view where data features are mapped to the y-axis (13 attributes, only 7 visible in the figure), and the x-axis represents the selected 204 models of stacking S2 . The available interactions for this view include panning and zooming in or out. Also, there is a possibility to check the average value of all models for each feature, serving as an overview. For our scenario, we can observe that Trestbps, Chol, Fbs, and Restecg are less important features. However, <ref type="figure">Fig. 5(c, right side)</ref> indicates that some models perform slightly better when including the Chol feature (due to the less saturated red color). Thus, we only disable the other three attributes by clicking the Average buttons in <ref type="figure">Fig. 5(c)</ref> on the right and get <ref type="figure">Fig. 5(d)</ref>. After recalculating the performance of the active stacking metamodel (Step 2 of <ref type="figure">Fig. 1(c)</ref>), we store the improved stacking ensemble cf. <ref type="figure" target="#fig_0">Fig. 1(b, c, S3</ref> ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Exploration of Models</head><p>The model exploration phase is perhaps the most important step on the way to build a good ensemble. It focuses on comparing and exploring different models both individually and in groups. Due to the page limits, we now assume that we selected the most performant models, removed the remaining from the stack, and reached S4 (see <ref type="figure">Fig. 1(b)</ref>). Stack S4 did not boost the performance due to the lack of diverse models from the KNN algorithm (cf. <ref type="figure">Fig. 1(c)</ref>). Diversity is one major component when building stack ensembles from scratch. The performance further drastically fell for S5 (see <ref type="figure">Fig. 1(c)</ref>) when we reduced the number of models even more (marked as Step 3). As Step 3 led to bad results, we decided to go back to S3 by clicking the Stacking Ensemble 3 button in <ref type="figure">Fig. 1(b)</ref> to reactivate it.</p><p>Models' Space. For the visual exploration of the models shown in <ref type="figure">Fig. 6</ref>, we use MDS projections (t-SNE or UMAP are also available). Each point is one model from the stack, projected from an 8-dimensional space where each dimension of each model is the value of a user-weighted metric. Thus, groups of points represent clusters of models that perform similarly according to all the metrics. A summary of the performance of each model according to all selected and userweighted metrics is color-encoded using the Viridis colormap <ref type="bibr" target="#b25">[26]</ref>. The boxplots below the projection show the performance of the models per metric. <ref type="figure">Fig. 6(a)</ref> presents ensemble S3 , with all models still included. <ref type="figure">Fig. 5</ref>. Our feature selection view that provides three different feature selection techniques. The y-axis of the table heatmap depicts the data set's features, and the x-axis depicts the selected models in the current stored stack. Univariate-, permutation-, and accuracy-based feature selection is available as long with any combination of them (a). (b) displays the normalized importance color legend. The per-model feature accuracy is depicted in (c), and (d) presents the user's interaction to disable specific features to be used for all the models (only seven features are shown here). This could also happen on an individual basis for every model. <ref type="figure">Fig. 6</ref>. Visual exploration of the models' space. The same MDS projection is observable in varying stages with different legend ranges and diverse colors for each instance, depending on the selected performance metric. The three steps in this figure demonstrate that we can reach both performant base models but also diverse algorithms by exploration of different validation metrics in (a) and (b). With the removal of the unselected models in (c), the performance remains stable but the complexity of the stacking ensemble reduces as more models leave the previous stack (cf. <ref type="figure">Fig. 1(b, S6 )</ref>). <ref type="figure">Fig. 6(a+b)</ref> show the same projection but with different color-encodings for two selected performance metrics: f2-score and MCC. They allow us to decide which models are vital in order to stabilize the performance of the ensemble. For the f2-score (a), the complete cluster of models in dark blue (lower part) does not show good performance results; for MCC (b), the overall performance looks much better except for a small number of models in the center. To get rid of the most underperforming models and keep model diversity at the same time, we select, with the lasso tool, the best overall performing models under consideration of the worst performing models for f2-score and MCC (see <ref type="figure">Fig. 6(a+b)</ref>). We have now a new ensemble S6 which presents the same results as S3 , but with 30 fewer models (from 204 to 174 based on six ML algorithms), see Step 4 in <ref type="figure">Fig. 1(b+c)</ref>. As such, the complexity of the stacking ensemble has been reduced, and its training can be performed faster without the identified underperforming models. In <ref type="figure">Fig. 1(b, S6</ref> ), we also display the parent stack S3 from which the final stack has been derived during the workflow.</p><p>Predictions' Space. The goal of the predictions' space visualization <ref type="figure">(Fig. 1(f)</ref>) is to show an overview of the performance of all models of the current stack for different instances. As in the data space, each point of the projection is an instance of the data set. However, instead of its original features, the instances are characterized as high-dimensional vectors where each dimension represents the prediction of one model. Thus, since there are currently 174 models in S6 , each instance is a 174-dimensional vector, projected into 2D. Groups of points represent instances that were consistently predicted to be in the same class. In <ref type="figure">Fig. 1(f)</ref>, for example, the points in the two clusters in both extremes of the projection (left and right sides, unselected) are well-classified, since they were consistently determined to be in the same class by most models of S6 . The instances that are in-between these clusters, however, do not have a well-defined profile, since different models classified them differently. After selecting these instances with the lasso tool, the two histograms below the projection in <ref type="figure">Fig. 1(f)</ref> show a comparison of the performance of the available models in the selected points (gray, upside down) vs. all points (black). The x-axis represents the performance according to the user-weighted metrics (in bins of 5%), and the y-axis shows the number of models in each bin. Our goal here is to look for models in the current stack S6 that could improve the performance for the selected points. However, by looking at the histograms, it does not look like we can achieve it this time, since all models perform worse in the selected points than in all points.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Results of the Metamodel</head><p>Recent work by Latha and Jeeva <ref type="bibr" target="#b23">[24]</ref> tried out various ensembles for this same data set, such as bagging, boosting, stacking, and majority vote, combined with feature selection. They found that majority vote with the NB, BN, RF, and MLP algorithms was the best combination achieving 85.48% accuracy. For stacking, they reached ≈83% accuracy. With StackGenVis, we reached an accuracy of ≈88%, thus surpassing both of their ensembles. This shows that our VA approach can be effective when users combine base models to produce the best, most diverse, and simplest possible stacking ensemble. The results can be exported in the JSON format ( <ref type="figure">Fig. 1(b, top-right)</ref>, Knowledge Extraction), allowing users to apply the trained stacking ensemble with new data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">USE CASE</head><p>In this section, we describe how StackGenVis can be used to improve the results of sentiment/stance detection in texts from social media, when compared to previous work from Skeppstedt et al. <ref type="bibr" target="#b51">[51]</ref>. The authors studied the automatic detection of seven stance categories: certainty, uncertainty, hypotheticality, prediction, recommendation, concession/contrast, and source. Their model performed best for the hypotheticality category, using a baseline classification approach without the application of heavy feature selection/engineering, therefore we focus on this category in our comparison. It can be considered as a binary classification problem: the presence or absence of hypotheticality. The training data set was collected using the tool by Kucher et al. <ref type="bibr" target="#b22">[23]</ref> and it consists of 2,095 instances of annotated training samples. The 300 feature vectors are based on the counts of the most frequent words in the corpus. The data set is very imbalanced, with most cases being <ref type="figure">Fig. 7</ref>. The process of exploration of distinct algorithms in hypotheticality stance analysis. (a) presents the selection of appropriate validation metrics for the specification of the data set. (b) aggregates the information after the exploration of different models and shows the active ones which will be used for the stack in the next step. (c) presents the per-class performance of all the models vs. the active ones per algorithm. <ref type="figure">Fig. 8</ref>. The exploration of the models' and predictions' spaces and the metamodel's results. (a) presents the initial models' space and how it can be simplified with the removal of unnecessary models. The predictions' space is then updated, and the user is able to select instances that are not well classified by the stack of models in (b). This leads to an updated models' space in (c), where we can even fine-tune and choose diverse concrete models. The results of our actions can always be monitored in the performance line chart and the history preservation for stacks views in (d).</p><p>on the absence side. Skeppstedt et al. <ref type="bibr" target="#b51">[51]</ref> used an SVM algorithm to train and build their baseline classifier for this task, and we are going to compare it to our stacking ensemble method in this use case.</p><p>Selection of Algorithms and Models. Similar to the workflow described in Sect. 4, we start by setting the most appropriate parameters for the problem (see <ref type="figure">Fig. 7(a)</ref>). As the data set is very imbalanced, we emphasize g-mean over accuracy, and ROC AUC over precision and recall. Log loss is disabled because the investigation of outliers is not critical for this text data set, and our computations do not have to be as precise as with medical data. Finally, due to the small number of instances in the presence of the hypotheticality class, we start with macro-average, which favors the smaller class (the previous work <ref type="bibr" target="#b51">[51]</ref> did not explicitly discuss their averaging strategy). The resulting selection of algorithms can be seen in <ref type="figure">Fig. 7(b)</ref>, where GradB is performing better than AdaB, and RF is slightly better than ExtraT. We improved the per-class performance (as shown in <ref type="figure">Fig. 7(c)</ref>) by choosing diverse ML models instead of simply the top-performing ones, since LR and RF perform well in the positive class, while other techniques such as SVC and GradB are far better in the negative class.</p><p>Optimized Models for Specific Predictions. In <ref type="figure">Fig. 8(a)</ref>, we see the initial projection of the 200 models selected up to this point (i.e., S1 ). Some models perform well according to our metrics, but others could be removed due to lower performance. However, we should try not to break the balance between performance and diversity of our stacking ensemble. Thus, we choose to remove some of the models that are positioned close together and are not performing as expected (but not all of such models). The selection of S2 leads us to 170 models, cf. <ref type="figure">Fig. 8(d)</ref>. By selecting these models, we get a new prediction space projection, shown in <ref type="figure">Fig. 8(b)</ref>. While some predictions are clearly in the positive or negative class, we focus on the unclear cases and select them using the lasso tool. The updated histogram indicates in gray that there are better models available for the selected instances. Simultaneously, the models' space is updated as well, depicted in <ref type="figure">Fig. 8(c)</ref>. Again, we try to preserve the diversity, but also reduce the complexity of the ensemble by removing the models with lower performance and low output diversity. As a result, in <ref type="figure">Fig. 8(d)</ref> we can see that the final stack S3 contains 140 models that perform better than the previous two stacks of 200 and 170 models. With 5-fold cross-validation, we reach 91%-92% performance for all our metamodel's validation metrics.</p><p>Evaluation of the Results with the Test Data Set. To confirm that our findings are solid, we applied the resulting metamodel to the same test data as Skeppstedt et al. <ref type="bibr" target="#b51">[51]</ref>, see <ref type="table" target="#tab_0">Table 1</ref>. For the hypotheticality category, the reported f1-score for the baseline approach was 66%. In our case, we reached the following results with the final stack and weighted-average: 94.46% for accuracy, 93.87% for precision, 94.46% for recall, and f1-score of 93.87%. Additionally, as an extra validation, we checked the results for the prediction category (again as a binary classification problem). Using our approach, we managed to achieve an f1-score of approximately 82% compared to 54% reported by Skeppstedt et al. <ref type="bibr" target="#b51">[51]</ref> for the baseline approach. Finally, it is important to note that, while our approach seems to perform very well for both applications described in this paper, the gain does not come only from the performance. Our system supports the exploration and manipulation of many different perspectives of a complex stacking ensemble with the help of visualizations, which is the main burden for stacking ensemble learning to become even more broadly useful. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">EVALUATION AND FUTURE WORK</head><p>In this section we discuss the experts' feedback about StackGenVis, as well as possible improvements for our VA approach.</p><p>Methodology and Information about the Participants. Following guidelines from previous work <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b34">34,</ref><ref type="bibr" target="#b65">65]</ref>, we conducted semistructured interviews with three experts to gather qualitative feedback about the effectiveness and usefulness of our system. The first expert (E1) is a senior specialist in ML and analytics platforms working in a large multinational company. He has approximately 10 years of experience with ML. Moreover, at least half of his PhD studies (2.5 years) was specifically dedicated to stacking ensemble learning. The second expert (E2) is a senior researcher in software engineering and applied ML working in a government research institute and as an adjunct professor. He has worked with ML for the past 7 years, and 2 years with stacking ensemble learning. The third expert (E3) is the head of applied ML in a large multinational corporation, working with recommendation systems. She has approximately 7 years of experience with ML, of which 1.5 years are related to stacking ensemble learning. All three experts have a PhD in computer science and none of them reported any colorblindness issues. The process was as follows: (1) we presented the main goals of our system, (2) we explained the process of improving the heart disease data set results (see Sect. 4), and (3) after that, we gave them a couple of minutes to interact with the VA system by using the simple iris data set. During this process, we asked them to think aloud, as any feedback might be vital. However, to structure the process, we explained to them the basic components of our infrastructure that we would like to receive feedback upon. Each interview lasted about one hour, during which we recorded the screen and audio for further analysis. We summarize the key findings from the interviews below.</p><p>Workflow. E1, E2, and E3 agreed that the workflow of StackGenVis made sense. They all suggested that data wrangling could happen before the algorithms' exploration, but also that it is usual to first train a few algorithms and then, based on their predictions, wrangle the data. Thus, it is considered an iterative process: the expert might start with the algorithms' exploration and move to the data wrangling, or vice versa. "The former approach is even more suitable for your VA system, because you use the accuracy of the base ML models as feedback/guidance to the expert in order to understand which instances should be wrangled", said E3. E2 stated that having an evaluation metric from early on is important for benchmarking purposes to choose the best strategy while data scientists and domain experts are collaborating. He also noted that flexibility of the workflow-not forcing the user to use all parts of the VA system for every problem-is an extra benefit.</p><p>Visualization and Interaction. E1 and E3 were positively surprised by the power of visualization regarding the possibilities of dynamically and directly interacting with the ML algorithms and models. E2 added that, after some initial training period (because the system could be a bit overwhelming in the beginning), the power of visualization in StackGenVis for supporting the analytical process is impressive.</p><p>E3 raised the question: "why not select the best, or a set of the best models of an algorithm, according to the performance, and why do we need visualization?" We answered that the per-class performance is also a very important component, and exploratory visualization can assist in the selection process, as seen in <ref type="figure" target="#fig_0">Fig. 3(b and c.1)</ref>. The expert understood the importance of visualization in that situation, compared to not using it. Another positive opinion from E3 was that, with a few adaptations to the performance metrics, StackGenVis could work with regression or even ranking problems. E3 also mentioned that supporting feature generation in the feature selection phase might be helpful. Finally, E1 suggested that the circular barcharts could only show the positive or negative difference compared to the first stored stack. To avoid an asymmetric design and retain a lower complexity level for StackGenVis, we omitted his proposal for the time being, but we consider implementing both methods in the future.</p><p>Limitations. Efficiency and scalability were the major concerns raised by all the experts. The inherent computational burden of stacking multiple models still remains, as such complex ensemble learning methods need sufficient resources. Also, the use of VA in between levels makes this even worse. We believe that, with the rapid development of high-performance hardware and support for parallelism, these challenges are due to diminish in the near future. Considering all that, E3 noted that our system could be useful in solving competition problems, e.g., on Kaggle, and for her team to run tests before applying specific models to their huge data sets. Progressive VA workflows <ref type="bibr" target="#b53">[53]</ref> could also be useful for improving the scalability of our approach for larger data sets. Interpretability and explainability is another challenge (mentioned by E3) in complicated ensemble methods, which is not necessarily always a problem depending on the data and the tasks. However, the utilization of user-selected weights for multiple validation metrics is one way towards interpreting and trusting the results of stacking ensembles. This is an advantage identified by E2.</p><p>In the first use case we presented to him, he noted that: "if you are interested in the fairness of the results, you could show with the history preservation view of the system how you reached to these predictions without removing the age or sex features, consequently, not leading to discrimination against patients, for example". The visual exploration of stacking methods that use multiple layers <ref type="bibr" target="#b27">[28]</ref> mentioned by E1 is set as another future work goal. While the experts suggested that they almost never continue to stack models into more than one layer in their practice, we can investigate the adaptations for more layers required for our workflow. Finally, as this work was the first one working with stacking and visualization, we still need to investigate further the impact of alternative metamodels on the predictive performance (mentioned by E1) and try out different modifications of stacking <ref type="bibr" target="#b33">[33]</ref>, for instance, by adapting our workflow with an extra step of visually comparing various metamodels. It is in our plans to conduct a quantitative user study to further evaluate our system in the future.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">CONCLUSION</head><p>In this paper, we introduced an interactive VA system, called Stack-GenVis, for the alignment of data, algorithms, and models in stacking ensemble learning. The adaptation of an already-existing knowledge generation model leads us to stable design goals and analytical tasks that were realized by StackGenVis. With the careful selection of multiple coordinated views, we allow users to build an effective stacking ensemble from scratch. Exploring the algorithms, the data, and the models from different perspectives and tracking the training process enables users to be sure how to proceed with the development of complex stacks of models that require a combination of not only the best performant but also the most diverse individual models. To retrieve preliminary results about the effectiveness of StackGenVis, we presented use cases with real-world data sets that demonstrated the improvements in performance and the process of achieving them. We also evaluated our approach with expert interviews by retrieving feedback about the workflow of our system, the interactive visualizations, and the limitations of our approach. Those limitations were then identified as future work for further development of our system.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 3 .</head><label>3</label><figDesc>The exploration process of ML algorithms. View (a.1) summarizes the performance of all available algorithms, and (a.2) the per-class performance based on precision, recall, and f1-score for each algorithm. (b) presents a selection of parameters for KNN in order to boost the per-class performance shown in (c.1). (c.2) illustrates in light blue the selected models and in gray the remaining ones. Also from (a.2), both RF and</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 4 .</head><label>4</label><figDesc>The data space projection with the importance of each instance measured by the accuracy achieved by the stack models (a). The parallel coordinates plot view for the exploration of the values of the features (b); a problematic case is highlighted in red with values being null ('4' has no meaning for Ca). (c.1) shows the brushed instance from the selection in (b) and (c.2) a problematic point that causes troubles to the stacking ensemble. (c.3) indicates the various functionalities that StackGenVis is able to perform for instances.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>Summary of the test data results for stance classification.</figDesc><table /><note></note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A multi-level typology of abstract visualization tasks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Brehmer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Munzner</surname></persName>
		</author>
		<idno type="DOI">10.1109/TVCG.2013.124</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2376" to="2385" />
			<date type="published" when="2013-12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Random forests</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Breiman</surname></persName>
		</author>
		<idno type="DOI">10.1023/A:1010933404324</idno>
	</analytic>
	<monogr>
		<title level="m">Machine Learning</title>
		<imprint>
			<date type="published" when="2001-10" />
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="page" from="5" to="32" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A survey of surveys on the use of visualization for interpreting machine learning models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Chatzimparmpas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">M</forename><surname>Martins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Jusufi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kerren</surname></persName>
		</author>
		<idno>doi: 10. 1177/1473871620904671</idno>
	</analytic>
	<monogr>
		<title level="j">Information Visualization</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="207" to="233" />
			<date type="published" when="2020-07" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">The state of the art in enhancing trust in machine learning models with the use of visualizations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Chatzimparmpas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">M</forename><surname>Martins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Jusufi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kucher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Rossi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kerren</surname></persName>
		</author>
		<idno type="DOI">10.1111/cgf.14034</idno>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics Forum</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="713" to="756" />
			<date type="published" when="2020-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">t-viSNE: Interactive assessment and interpretation of t-SNE projections</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Chatzimparmpas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">M</forename><surname>Martins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kerren</surname></persName>
		</author>
		<idno type="DOI">10.1109/TVCG.2020.2986996</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="2696" to="2714" />
			<date type="published" when="2020-08" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">LDA ensembles for interactive exploration and categorization of behaviors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Andrienko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Andrienko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Adilova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Barlet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kindermann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">H</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Thonnard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Turkay</surname></persName>
		</author>
		<idno type="DOI">10.1109/TVCG.2019.2904069</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">XGBoost: A scalable tree boosting system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Guestrin</surname></persName>
		</author>
		<idno type="DOI">10.1145/2939672.2939785</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD &apos;16</title>
		<meeting>the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD &apos;16</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="785" to="794" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">The advantages of the Matthews correlation coefficient (MCC) over F1 score and accuracy in binary classification evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Chicco</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Jurman</surname></persName>
		</author>
		<idno type="DOI">10.1186/s12864-019-6413-7</idno>
	</analytic>
	<monogr>
		<title level="j">BMC Genomics</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">6</biblScope>
			<date type="published" when="2020-01" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">F</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename><surname>Korevaar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">G</forename><surname>Altman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">E</forename><surname>Bruns</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">A</forename><surname>Gatsonis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Hooft</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Irwig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Levine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">B</forename><surname>Reitsma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">C W</forename><surname>De Vet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">M M</forename><surname>Bossuyt</surname></persName>
		</author>
		<idno type="DOI">10.1136/bmjopen-2016-012799</idno>
	</analytic>
	<monogr>
		<title level="m">STARD 2015 guidelines for reporting diagnostic accuracy studies: Explanation and elaboration</title>
		<imprint>
			<date type="published" when="2016-11" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">12799</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Guidance in the human-machine analytics process</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Collins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Andrienko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Schreck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Choo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Engelke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Jena</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Dwyer</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.visinf.2018.09.003</idno>
	</analytic>
	<monogr>
		<title level="j">Visual Informatics</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="166" to="180" />
			<date type="published" when="2018-09" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">BEAMES: Interactive multi-model steering, selection, and inspection for regression tasks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Cashman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Endert</surname></persName>
		</author>
		<idno>doi: 10.1109/ MCG.2019.2922592</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer Graphics and Applications</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">9</biblScope>
			<date type="published" when="2019-09" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">The relationship between precision-recall and ROC curves</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Goadrich</surname></persName>
		</author>
		<idno>doi: 10. 1145/1143844.1143874</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23rd International Conference on Machine Learning, ICML &apos;06</title>
		<meeting>the 23rd International Conference on Machine Learning, ICML &apos;06</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2006" />
			<biblScope unit="page" from="233" to="240" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">A task-based taxonomy of cognitive biases for information visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Dimara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Franconeri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Plaisant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bezerianos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dragicevic</surname></persName>
		</author>
		<idno type="DOI">10.1109/TVCG.2018.2872577</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1413" to="1432" />
			<date type="published" when="2020-02" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">UCI machine learning repository</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Dua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Graff</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">An experimental comparison of performance measures for classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Ferri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hernández-Orallo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Modroiu</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.patrec.2008.08.010</idno>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition Letters</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="27" to="38" />
			<date type="published" when="2009-01" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A short introduction to boosting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Freund</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Schapire</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Abe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Japanese Society for Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="771" to="780" />
			<date type="published" when="1999-09" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Collaborative visualization: Definition, challenges, and research agenda</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Isenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Elmqvist</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Scholtz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Cernea</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K.-L</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Hagen</surname></persName>
		</author>
		<idno>doi: 10. 1177/1473871611412817</idno>
	</analytic>
	<monogr>
		<title level="j">Information Visualization</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="310" to="326" />
			<date type="published" when="2011-10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Automated bug assignment: Ensemble-based machine learning in large scale industrial contexts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Jonsson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Borg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Broman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Sandahl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Eldh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Runeson</surname></persName>
		</author>
		<idno type="DOI">10.1007/s10664-015-9401-9</idno>
	</analytic>
	<monogr>
		<title level="j">Empirical Software Engineering</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1533" to="1578" />
			<date type="published" when="2016-08" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Towards automated anomaly report assignment in large complex systems using stacked generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Jonsson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Broman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Sandahl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Eldh</surname></persName>
		</author>
		<idno type="DOI">10.1109/ICST.2012.124</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fifth IEEE International Conference on Software Testing, Verification and Validation</title>
		<meeting>the Fifth IEEE International Conference on Software Testing, Verification and Validation</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="437" to="446" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Kaggle Competition -Otto Group product classification challenge</title>
		<ptr target="https://kaggle.com/c/otto-group-product-classification-challenge" />
		<imprint>
			<date type="published" when="2015-04-13" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">LightGBM: A highly efficient gradient boosting decision tree</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Ke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Finley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T.-Y</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 31st International Conference on Neural Information Processing Systems, NIPS &apos;17</title>
		<meeting>the 31st International Conference on Neural Information Processing Systems, NIPS &apos;17</meeting>
		<imprint>
			<publisher>Curran Associates Inc</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="3149" to="3157" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Multidimensional scaling by optimizing goodness of fit to a nonmetric hypothesis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">B</forename></persName>
		</author>
		<idno>doi: 10. 1007/BF02289565</idno>
	</analytic>
	<monogr>
		<title level="j">Psychometrika</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="27" />
			<date type="published" when="1964-03" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Active learning and visual analytics for stance classification with ALVA</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kucher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Paradis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sahlgren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kerren</surname></persName>
		</author>
		<idno type="DOI">10.1145/3132169</idno>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Interactive Intelligent Systems</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="2017-10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Improving the accuracy of prediction of heart disease risk based on ensemble classification techniques</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">B C</forename><surname>Latha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">C</forename><surname>Jeeva</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.imu.2019.100203</idno>
	</analytic>
	<monogr>
		<title level="j">Informatics in Medicine Unlocked</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page">100203</biblScope>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Visual diagnosis of tree boosting methods</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhu</surname></persName>
		</author>
		<idno type="DOI">10.1109/TVCG.2017.2744378</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="163" to="173" />
			<date type="published" when="2018-01" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Somewhere over the rainbow: An empirical assessment of quantitative colormaps</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Heer</surname></persName>
		</author>
		<idno type="DOI">10.1145/3173574.3174172</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems, CHI &apos;18</title>
		<meeting>the 2018 CHI Conference on Human Factors in Computing Systems, CHI &apos;18</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">AUC: A misleading measure of the performance of predictive distribution models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Lobo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Jiménez-Valverde</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Real</surname></persName>
		</author>
		<idno>doi: 10.1111/j. 1466-8238.2007.00358.x</idno>
	</analytic>
	<monogr>
		<title level="j">Global Ecology and Biogeography</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="145" to="151" />
			<date type="published" when="2008-03" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Impact of an extra layer on the stacking algorithm for classification problems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Lorbieski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M</forename><surname>Nassar</surname></persName>
		</author>
		<idno type="DOI">10.3844/jcssp.2018.613.622</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of Computer Science</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="613" to="622" />
			<date type="published" when="2018-05" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Explaining vulnerabilities to adversarial machine learning through visual analytics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Maciejewski</surname></persName>
		</author>
		<idno type="DOI">10.1109/TVCG.2019.2934631</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1075" to="1085" />
			<date type="published" when="2020-01" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Ensemble of machine learning algorithms using the stacked generalization approach to estimate the warfarin dose</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Khalighi</surname></persName>
		</author>
		<idno>doi: 10.1371/ journal.pone.0205872</idno>
	</analytic>
	<monogr>
		<title level="j">PLOS ONE</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1" to="12" />
			<date type="published" when="2018-10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">UMAP: Uniform manifold approximation and projection for dimension reduction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Mcinnes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Healy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Melville</surname></persName>
		</author>
		<idno>1802.03426</idno>
		<imprint>
			<date type="published" when="2018-02" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Being accurate is not enough: How accuracy metrics have hurt recommender systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M</forename><surname>Mcnee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Riedl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Konstan</surname></persName>
		</author>
		<imprint>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<idno type="DOI">10.1145/1125451.1125659</idno>
		<title level="m">Extended Abstracts on Human Factors in Computing Systems, CHI EA &apos;06</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2006" />
			<biblScope unit="page" from="1097" to="1101" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Troika -An improved stacking schema for classification tasks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Menahem</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Rokach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Elovici</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.ins.2009.08.025</idno>
	</analytic>
	<monogr>
		<title level="j">Information Sciences</title>
		<imprint>
			<biblScope unit="volume">179</biblScope>
			<biblScope unit="issue">24</biblScope>
			<biblScope unit="page" from="4097" to="4122" />
			<date type="published" when="2009-12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">ProtoSteer: Steering deep sequence model with prototypes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ming</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Ren</surname></persName>
		</author>
		<idno type="DOI">10.1109/TVCG.2019.2934267</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="238" to="248" />
			<date type="published" when="2020-01" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Formalizing visualization design knowledge as constraints: Actionable and extensible models in Draco</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Moritz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">L</forename><surname>Nelson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">M</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Howe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Heer</surname></persName>
		</author>
		<idno>doi: 10. 1109/TVCG.2018.2865240</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="438" to="448" />
			<date type="published" when="2019-01" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">A partition-based framework for building and validating regression models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Mühlbacher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Piringer</surname></persName>
		</author>
		<idno type="DOI">10.1109/TVCG.2013.125</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="1962" to="1971" />
			<date type="published" when="2013-12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Classification of microarray cancer data using ensemble approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Nagi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">K</forename><surname>Bhattacharyya</surname></persName>
		</author>
		<idno type="DOI">10.1007/s13721-013-0034-x</idno>
	</analytic>
	<monogr>
		<title level="j">Network Modeling Analysis in Health Informatics and Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="159" to="173" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Stacked generalization: An introduction to super learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">I</forename><surname>Naimi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">B</forename><surname>Balzer</surname></persName>
		</author>
		<idno type="DOI">10.1007/s10654-018-0390-z</idno>
	</analytic>
	<monogr>
		<title level="j">European Journal of Epidemiology</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="459" to="464" />
			<date type="published" when="2018-05" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">A deep learning-based stacked generalization method to design smart healthcare solution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nambiar</forename><surname>Jyothi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Prakash</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Emerging Research in Electronics</title>
		<meeting><address><addrLine>Singapore</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="211" to="222" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">A framework for provenance analysis and visualization. Procedia Computer Science</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Oliveira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">M</forename><surname>Ambrósio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Braga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Ströele</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Campos</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.procs.2017.05.216</idno>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">108</biblScope>
			<biblScope unit="page" from="1592" to="1601" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">A comparison of performance metrics for event classification in non-intrusive load monitoring</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Pereira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Nunes</surname></persName>
		</author>
		<idno type="DOI">10.1109/SmartGridComm.2017.8340682</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Smart Grid Communications, Smart-GridComm &apos;17</title>
		<meeting>the IEEE International Conference on Smart Grid Communications, Smart-GridComm &apos;17</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="159" to="164" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Evaluation: From precision, recall and F-measure to ROC, informedness, markedness &amp; correlation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">M W</forename><surname>Powers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Technologies</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="37" to="63" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Characterizing provenance in visualization and data analysis: An organizational framework of provenance types and purposes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">D</forename><surname>Ragan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Endert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sanyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<idno type="DOI">10.1109/TVCG.2015.2467551</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="31" to="40" />
			<date type="published" when="2016-01" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Knowledge generation model for visual analytics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Sacha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Stoffel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Stoffel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">C</forename><surname>Kwon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Ellis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename><surname>Keim</surname></persName>
		</author>
		<idno type="DOI">10.1109/TVCG.2014.2346481</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="1604" to="1613" />
			<date type="published" when="2014-12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Ensemble learning: A survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Sagi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Rokach</surname></persName>
		</author>
		<idno>doi: 10. 1002/widm.1249</idno>
	</analytic>
	<monogr>
		<title level="j">WIREs Data Mining and Knowledge Discovery</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">1249</biblScope>
			<date type="published" when="2018-08" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">The precision-recall plot is more informative than the ROC plot when evaluating binary classifiers on imbalanced datasets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Saito</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Rehmsmeier</surname></persName>
		</author>
		<idno type="DOI">10.1371/journal.pone.0118432</idno>
	</analytic>
	<monogr>
		<title level="j">PLOS ONE</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">118432</biblScope>
			<date type="published" when="2015-03" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Integrating data and model space in ensemble learning by visual analytics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Schneider</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Jäckle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Stoffel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Diehl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Fuchs</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename><surname>Keim</surname></persName>
		</author>
		<idno type="DOI">10.1109/TBDATA.2018.2877350</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Big Data</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Visual predictive analytics using iFuseML</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Sehgal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Rawat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Shroff</surname></persName>
		</author>
		<idno type="DOI">10.2312/eurova.20181106</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the EuroVis Workshop on Visual Analytics, EuroVA &apos;18. The Eurographics Association</title>
		<meeting>the EuroVis Workshop on Visual Analytics, EuroVA &apos;18. The Eurographics Association</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Human-centered artificial intelligence: Reliable, safe &amp; trustworthy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Shneiderman</surname></persName>
		</author>
		<idno type="DOI">10.1080/10447318.2020.1741118</idno>
	</analytic>
	<monogr>
		<title level="j">International Journal of Human-Computer Interaction</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="495" to="504" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Combining information extraction systems using voting and stacked generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Sigletos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Paliouras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">D</forename><surname>Spyropoulos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hatzopoulos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="1751" to="1782" />
			<date type="published" when="2005-11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Detection of stance and sentiment modifiers in political blogs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Skeppstedt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Simaki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Paradis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kerren</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-319-66429-329</idno>
	</analytic>
	<monogr>
		<title level="m">Speech and Computer</title>
		<imprint>
			<publisher>Springer International Publishing</publisher>
			<date type="published" when="2017" />
			<biblScope unit="volume">10458</biblScope>
			<biblScope unit="page" from="302" to="311" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">A systematic analysis of performance measures for classification tasks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sokolova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Lapalme</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.ipm.2009.03.002</idno>
	</analytic>
	<monogr>
		<title level="j">Information Processing &amp; Management</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="427" to="437" />
			<date type="published" when="2009-07" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Progressive visual analytics: Userdriven visual exploration of in-progress analytics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">D</forename><surname>Stolper</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Perer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Gotz</surname></persName>
		</author>
		<idno type="DOI">10.1109/TVCG.2014.2346574</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="1653" to="1662" />
			<date type="published" when="2014-12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Classification accuracy is not enough</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">L</forename><surname>Sturm</surname></persName>
		</author>
		<idno type="DOI">10.1007/s10844-013-0250-y</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of Intelligent Information Systems</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="371" to="406" />
			<date type="published" when="2013-12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">EnsembleMatrix: Interactive visualization to support machine learning with multiple classifiers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Talbot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kapoor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">S</forename><surname>Tan</surname></persName>
		</author>
		<idno type="DOI">10.1145/1518701.1518895</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, CHI &apos;09</title>
		<meeting>the SIGCHI Conference on Human Factors in Computing Systems, CHI &apos;09</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="1283" to="1292" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<monogr>
		<title level="m" type="main">Classification assessment methods. Applied Computing and Informatics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Tharwat</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.aci.2018.08.003</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Stacked generalization: When does it work?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">M</forename><surname>Ting</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">H</forename><surname>Witten</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fifteenth International Joint Conference on Artifical Intelligence</title>
		<meeting>the Fifteenth International Joint Conference on Artifical Intelligence</meeting>
		<imprint>
			<publisher>Morgan Kaufmann Publishers Inc</publisher>
			<date type="published" when="1997" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="866" to="871" />
		</imprint>
	</monogr>
	<note>IJCAI &apos;97</note>
</biblStruct>

<biblStruct xml:id="b58">
	<monogr>
		<title level="m" type="main">Storytelling and visualization: An extended survey. Information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Tong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Borgo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Walton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">S</forename><surname>Laramee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Wegba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Ma</surname></persName>
		</author>
		<idno>doi: 10.3390/ info9030065</idno>
		<imprint>
			<date type="published" when="2018-03" />
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page">65</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Combining MF networks: A comparison among statistical methods and stacked generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Torres-Sospedra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Hernández-Espinosa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Fernández-Redondo</surname></persName>
		</author>
		<idno>doi: 10.1007/ 11829898</idno>
	</analytic>
	<monogr>
		<title level="m">Artificial Neural Networks in Pattern Recognition</title>
		<meeting><address><addrLine>Berlin Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2006" />
			<biblScope unit="page">19</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Demand prediction using machine learning methods and stacked generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Tugay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ş</forename><surname>Gündüzögüdücü</surname></persName>
		</author>
		<idno>doi: 10.5220/ 0006431602160222</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 6th International Conference on Data Science, Technology and Applications, DATA &apos;17</title>
		<meeting>the 6th International Conference on Data Science, Technology and Applications, DATA &apos;17</meeting>
		<imprint>
			<publisher>SciTePress</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="216" to="222" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Visualizing data using t-SNE</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Van Der Maaten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="2579" to="2605" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">ATMSeer: Increasing transparency and controllability in automated machine learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ming</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Veeramachaneni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Qu</surname></persName>
		</author>
		<idno type="DOI">10.1145/3290605.3300911</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems, CHI &apos;19</title>
		<meeting>the 2019 CHI Conference on Human Factors in Computing Systems, CHI &apos;19</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Stacked generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">H</forename><surname>Wolpert</surname></persName>
		</author>
		<idno type="DOI">10.1016/S0893-6080(05)80023-1</idno>
	</analytic>
	<monogr>
		<title level="j">Neural Networks</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="241" to="259" />
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Analytic provenance for sensemaking: A research agenda</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Attfield</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">J</forename><surname>Jankun-Kelly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Wheat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">H</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Selvaraj</surname></persName>
		</author>
		<idno type="DOI">10.1109/MCG.2015.50</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer Graphics and Applications</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="56" to="64" />
			<date type="published" when="2015-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">EnsembleLens: Ensemblebased visual exploration of anomaly detection algorithms with multidimensional data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Mu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Cao</surname></persName>
		</author>
		<idno type="DOI">10.1109/TVCG.2018.2864825</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="109" to="119" />
			<date type="published" when="2019-01" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Manifold: A modelagnostic framework for interpretation and diagnosis of machine learning models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Molino</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">S</forename><surname>Ebert</surname></persName>
		</author>
		<idno type="DOI">10.1109/TVCG.2018.2864499</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="364" to="373" />
			<date type="published" when="2019-01" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">LoVis: Local pattern visualization for model refinement</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">O</forename><surname>Ward</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">A</forename><surname>Rundensteiner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">N</forename><surname>Higgins</surname></persName>
		</author>
		<idno type="DOI">10.1111/cgf.12389</idno>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics Forum</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="331" to="340" />
			<date type="published" when="2014-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">iForest: Interpreting random forests via visual analytics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">L</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Cui</surname></persName>
		</author>
		<idno type="DOI">10.1109/TVCG.2018.2864475</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="407" to="416" />
			<date type="published" when="2019-01" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
