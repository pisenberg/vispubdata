<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/pisenberg/grobid/grobid-0.6.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Visual Neural Decomposition to Explain Multivariate Data Sets</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johannes</forename><surname>Knittel</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andres</forename><surname>Lalama</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steffen</forename><surname>Koch</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Ertl</surname></persName>
						</author>
						<title level="a" type="main">Visual Neural Decomposition to Explain Multivariate Data Sets</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2021-02-19T20:22+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Visual Analytics</term>
					<term>Multivariate Data Analysis</term>
					<term>Machine Learning</term>
				</keywords>
			</textClass>
			<abstract>
				<p>Fig. 1. Visual Neural Decomposition of a chip testing measurement data set with the goal to identify cases in which the target variable (here: jitter) exhibits high values. Each node visualizes parts of the data set depending on its activation.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>visualize their relationship with the target variable individually, e.g., with a scatter plot matrix <ref type="bibr" target="#b9">[10]</ref>. However, such techniques do not scale well to many variables <ref type="bibr" target="#b4">[5]</ref>, and analysts may fail to detect more complex relationships involving three or more variables, particularly if there are multiple groups of conditions that lead to high target values. In case of the voting behavior data set example, a combination of a certain age range, level of education and personal hobbies could explain one cluster of specific votes, for instance.</p><p>Experts from a wide range of domains have to deal with such challenges, including manufacturing specialists like chip developers. In post-silicon validation, produced IC chips are tested under varying conditions to detect design bugs and to reveal sensitivities of a target variable with respect to other variables as hints for design improvements <ref type="bibr" target="#b37">[38]</ref>. We conducted a case study with a domain expert and research fellow of one of the world's largest provider of automatic test equipment to collect requirements for our approach. The automated testing of the chips often produces large high-dimensional data sets with up to hundreds of variables that capture parameters, environmental factors, and resulting error measurements. Engineers analyze the data sets to find out which parameter range combinations may lead to undesired behaviors of the chip (out-of-spec behavior), and to de-termine parameters for optimal performance (tuning), for instance, to maximize battery life of the chip. While the total number of variables is high, the actual number of relevant variables for a specific case is often less than half a dozen, according to our expert. Furthermore, most of the problems at hand can be formulated such that the goal is to find conditions under which a certain variable (e.g., error rate) has high values. However, there can be several distinct patterns involving different variables that result in high values, for instance, several bugs relating to different environmental factors. Some of these patterns may only appear in a small fraction of the data set. As of now, the analysts and engineers make heavy use of scatter plot matrices to investigate possible correlations between several subsets of variables and the selected target variable, which is time-consuming. Given a multivariate data set, the goal of our approach is to extract and visualize cases that lead to high values of a specified target variable. The output of our model guides analysts to thoroughly explore interesting combinations of variables that correlate with the target. Crucially, we aim to visually explain the behavior of the target variable with the original features, the remaining variables of the data set, because they often have a semantic meaning for analysts <ref type="bibr" target="#b49">[50]</ref>. Thus, we need a visually interpretable technique that can recognize non-linear correlations between input variables and a specified target variable of the data set. To achieve this, we first train a neural network using a novel architecture to predict the target variable based on the input of the other variables. The neural network decomposes the approximated function of the target variable into components, the neural nodes in the hidden layer. Then, we visualize the behavior of these individual neurons to explain separately for each case in which conditions the target variable adopts high values. We provide interactions to let analysts explore the found relationships in deep. In other words, we do not apply visualization to explain an AI-approach (XAI <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b11">12]</ref>), instead, we propose to use AI for visually explaining interesting relationships in data (AIX).</p><p>We make the following contributions:</p><p>• We propose a novel model based on a neural network architecture to extract and visualize conditions in which a chosen target variable adopts high values. It supports multi-dimensional and non-linear relationships, does not require analysts to pick interesting variables first, and can also recognize small-sized effects.</p><p>• We present interactive node-specific parallel coordinate plots that leverage the trained weights of the neural network's hidden nodes to show a subset of the data set with a specific axis order.</p><p>• We offer an integrated approach to load data sets, train models, and interactively explore and validate the visualized findings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK</head><p>Visual Neural Decomposition (VND) explains the behavior of a dependent variable (the target variable) with the remaining independent variables of the set, assuming that these variables have a semantic meaning for analysts (e.g., age). This is similar to input-output models in the context of visual parameter space analysis <ref type="bibr" target="#b49">[50]</ref>, but we do not aim to gain a systematic understanding of the complete input space, and depending on the use case and data set this is not even possible, for instance, regarding survey responses. Godfrey and Gashler <ref type="bibr" target="#b17">[18]</ref> introduced Neural Decomposition as a new neural network technique to decompose time-series data into sums of periodic and nonperiodic components. Similarly, we decompose the target variable into sigmoidal components based on the input variables, but we use classical neural networks with a novel regularization technique. Our main idea is to visualize the learned decomposition to understand which conditions lead to high values of the target variable.</p><p>Multivariate data visualizations such as scatter plot matrices <ref type="bibr" target="#b9">[10]</ref> and parallel coordinates <ref type="bibr" target="#b22">[23]</ref> are widely used to visualize multivariate data sets, but they do not scale well to many variables <ref type="bibr" target="#b4">[5]</ref>. Parallel coordinates have the advantage over scatter plot matrices that the required screen space only grows linearly with the number of variables, but the order of the axes, overplotting, and line-tracing are issues that have to be dealt with <ref type="bibr" target="#b20">[21]</ref>. There is ongoing research on how to improve parallel coordinates for large data sets, including drawing optimizations to reveal structures and avoid overplotting <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b42">43]</ref>, curve bundling to better reveal clusters <ref type="bibr" target="#b33">[34]</ref>, and tuple-based statistics <ref type="bibr" target="#b24">[25]</ref> as well as hierarchical aggregation <ref type="bibr" target="#b45">[46]</ref> to make the visual analysis scalable. Heinrich et al. <ref type="bibr" target="#b20">[21]</ref> provide a more thorough overview of proposed PCP techniques and open challenges.</p><p>Dimensionality reduction (DR) methods, including MDS <ref type="bibr" target="#b12">[13]</ref>, PCA <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b27">28]</ref>, t-SNE <ref type="bibr" target="#b57">[58]</ref>, and UMAP <ref type="bibr" target="#b36">[37]</ref> help to visualize multidimensional data items while still maintaining certain similarity measures between items, but the crucial question remains how analysts can relate findings to the original space. To tackle this, Fujiwara et al. proposed ccPCA <ref type="bibr" target="#b15">[16]</ref> that clusters the result of the DR method and then visualizes for each cluster which features and feature ranges distinguish the respective cluster from the others the most. Similarly to our method, the cluster-specific ranking of the features and corresponding histograms support the analysis of data sets with many variables. However, the goal of VND is slightly different, in that we want to visualize which features influence a specific target variable the most. In addition, VND calculates the (soft) clustering in the original high-dimensional space. Gleicher's approach <ref type="bibr" target="#b16">[17]</ref> projects items onto user-defined, interpretable dimensions, e.g., a linear combination of certain variables. Embeddings based on generalized barycentric coordinates such as RadViz Deluxe <ref type="bibr" target="#b10">[11]</ref> preserve the relation to the original space to some extent, but they work best if the data items have a dominant dimension.</p><p>Explorative and iterative approaches help to make the analysis of large multivariate data sets scalable. Voyager <ref type="bibr" target="#b59">[60,</ref><ref type="bibr" target="#b60">61]</ref> supports openended and focused exploration of multivariate data sets with automated recommendations and interactive chart specifications. DICON <ref type="bibr" target="#b8">[9]</ref> visualizes multidimensional clustering results for cluster interpretation and comparison. Scherer et al. <ref type="bibr" target="#b47">[48]</ref> introduced regressional feature vectors to enable visual sketch-based queries and to explore interesting scatter plots. Behrisch et al. <ref type="bibr" target="#b5">[6]</ref> propose a feedback-driven approach that iteratively learns the preferences of the user to make valuable suggestions for further explorations. Turkay et al. <ref type="bibr" target="#b55">[56]</ref> present a method to interactively generate representative factors that combine several data points across dimensions in order to reduce the number of dimensions. For geospatial data sets, specific methods were developed that facilitate maps <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b34">35]</ref>. Several approaches rank variables and pairs of variables according to statistical correlation factors <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b43">44]</ref> or classification metrics such as separability <ref type="bibr" target="#b51">[52]</ref>. Barlowe et al. <ref type="bibr" target="#b4">[5]</ref> visualize partial derivatives of the dependent variable with regard to the independent variables and analysts can iteratively explore multi-correlations. Smart-Stripes <ref type="bibr" target="#b35">[36]</ref> ranks and visualizes correlations based on partitions of the input features. Analysts can iteratively select multiple partitions to explore more complex relationships. Zhang et al. <ref type="bibr" target="#b62">[63]</ref> developed the correlation map to visualize pairwise correlations between variables in a graph. The work of Klemm et al. <ref type="bibr" target="#b29">[30]</ref> visualizes correlations of up to three variables with regard to a target variable in a 3D cube. Our proposed system can recognize and visualize non-linear correlations as well as correlations involving more than three variables.</p><p>Model building and partitioning play an important role in several approaches. INFUSE <ref type="bibr" target="#b31">[32]</ref> supports interactive model building by visualizing the predictiveness of features according to several feature selection algorithms. An integrated visual analytics approach to build logistic regression models was introduced by Zhang et al. <ref type="bibr" target="#b61">[62]</ref>. Dingen et al. <ref type="bibr" target="#b13">[14]</ref> argue that building such models should be an iterative process selecting variables one at a time, because clinicians, for instance, need sparse and justified models. They developed RegressionExplorer to let analysts build and compare different regression models. The approach of Muehlbacher and Piringer <ref type="bibr" target="#b39">[40]</ref> allows to iteratively define and validate regression models. They partition the input features into bins and visualize the target variable over binned features and pairs of features in a heatmap, ranked by their usefulness in predicting the target variable. Bernard et al. <ref type="bibr" target="#b6">[7]</ref> developed a system that operates on partitions of the input space as well, but with the goal to find multivariate relations between specific bins across attributes. They focus on detecting conditions that are statistically significant. Analysts can select one or several bins to reveal associated clusters with related bins based on pairwise mutual information. Such binning (or partitioning) strategies make the visual analysis of large data sets scalable through aggregation. Another advantage is that even linear models can express certain non-linear relationships if the atomic unit is a bin (i.e., value range) and not a global variable anymore. While uni-or bivariate metrics (e.g., Pearson correlation or mutual information) to rank features or cluster data items can offer statistically sound results, they bear the risk that analysts miss more complex multi-correlations. For instance, there are cases in which only a combination of multiple variables may explain a specific behavior of the target variable, but looking at the individual variables or pairs of variables separately would not reveal a pattern.</p><p>Subspace extraction is a promising strategy to reduce the number of dimensions that have to be processed (e.g., for subsequent clustering methods) and visualized <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b41">42,</ref><ref type="bibr" target="#b52">53,</ref><ref type="bibr" target="#b53">54,</ref><ref type="bibr" target="#b58">59]</ref>. Tatu et al. <ref type="bibr" target="#b52">[53]</ref> employ an algorithm that detects interesting subspaces which are then grouped by similarity. Parallel coordinate and scatter plots display the data set in each subspace. SubVis <ref type="bibr" target="#b21">[22]</ref> uses the OpenSubspace framework <ref type="bibr" target="#b40">[41]</ref> to first extract subspaces and then find clusters within these subspaces. They apply Multidimensional Scaling to provide a visual overview of all clusters, from which analysts can select similar subspace clusters. The aggregation table visualizes the distributions of all related dimensions of a particular cluster. SeekAView <ref type="bibr" target="#b30">[31]</ref> supports building and refining subspaces interactively, including suggestions for interesting dimensions, e.g., based on how useful the respective variable is for predicting a target variable. Our method applies a global approach for finding interesting patterns and we do not extract fixed subspaces, but analysts can use the range filter (Section 4.3.3) to define a subspace (and a cluster within that subspace) based on the most important variables of a node.</p><p>Decision trees are commonly used to visualize different outcomes of the target variable depending on different splits of the input variables. BaobabView <ref type="bibr" target="#b56">[57]</ref> allows analysts to interactively construct and refine such decision trees. Muehlbacher et al. <ref type="bibr" target="#b38">[39]</ref> focus on building paretooptimal decision trees as a trade-off between accuracy, complexity, and interpretability. Decision trees are a popular choice because they are usually easy to comprehend and interpret. However, continuous relations are difficult to model (e.g., relationship between horsepower and acceleration time) and slightly more complex patterns and 'splits' (e.g., two distinct ranges of a variable) can lead to overly complex trees, which makes it difficult for analysts to trace single paths.</p><p>Visualizing (deep) neural networks has become a popular research focus in recent years. However, in most cases the approaches focus on explaining and debugging the models, for instance, visualizing which pixel regions are most supportive for the prediction <ref type="bibr" target="#b63">[64]</ref>, explaining predictions of convolutional neural networks with surrogate decision trees <ref type="bibr" target="#b25">[26]</ref>, or visualizing activation patterns to understand deep learning models <ref type="bibr" target="#b28">[29]</ref>. Liu et al. <ref type="bibr" target="#b32">[33]</ref> provide an overview of visual analytic approaches for understanding, debugging and refining machine learning models, Choo et al. <ref type="bibr" target="#b11">[12]</ref> for explainable deep learning, and recently Sacha et al. <ref type="bibr" target="#b46">[47]</ref> for assisting machine learning. Conversely, we use neural networks to understand the relationships of the underlying data. Nevertheless, some approaches indirectly also reveal structures of the data. CNNVis <ref type="bibr" target="#b32">[33]</ref> visualizes the learned features of neurons and their interactions to analyze image-based CNNs. While the aim is to refine and debug such networks, the resulting visualizations also offer a glimpse into the structure of the training data set, including prevalent features of the images and different clusters (e.g., cats and dogs). Likewise, LSTMVis <ref type="bibr" target="#b50">[51]</ref> allows analysts to retrieve similar sentences and paragraphs in the corpus, even though the approach is about visualizing hidden states of recurrent neural networks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">METHOD</head><p>Given a multivariate data set, we want to investigate in which cases a specified target variable y adopts values in a specified range. The goal of our method is to visualize such cases separately to provide digestible visual explanations, while still supporting more complex relationships between y and the remaining variables of the data set.</p><p>Multivariable linear regression is often used to infer which independent variables x i seem to have the most influence on the dependent variable y by solving y = ∑ i a i x i + b for the coefficients a i <ref type="bibr" target="#b48">[49]</ref>. While the resulting coefficients are easy to interpret, linear regression cannot capture more complex correlations involving non-linear relationships or combinations of variables (e.g., y is only high if two input variables are both high). Neural networks, on the other hand, can approximate highly complex functions. In simplified terms, a single-output neural network essentially combines several localized quasi-regressions as represented by the hidden nodes. We assume that some of these nodes capture specific cases that lead to values of y in the desired range. Hence, the main idea of our approach is to first train a neural network predicting the target based on the other variables in the data set (input variables). Afterward, we use the hidden nodes' activations to visually explain how certain parts and variables of the data set correlate with the target. We introduce a novel regularization technique (Section 3.4) that encourages the neural network to model the relationships in a way that is easier to interpret. In other words, we use the training process to perform multiple non-linear regressions, and analysts can then further explore these in our interactive visual interface.</p><p>We are mainly interested in how our model captures the underlying dynamics, thus, the resulting accuracy of our network is less relevant. However, a consistently low accuracy indicates that there is either a very subtle or no relationship between inputs and output, because neural networks can approximate complex, non-linear functions (a particular training run may not converge nevertheless). We do not aim at debugging machine learning models to improve the model or find weak spots, we rather analyze them visually to understand the underlying data sets they were trained on. In this paper, we focus on explaining high target values for simplicity, but this does not limit the range of our approach. If analysts are interested in low-or mid-value cases, y could be transformed accordingly to fit our definition (e.g., y = −y for low-value cases). <ref type="figure" target="#fig_0">Figure 2</ref> depicts the architecture of our model. We use a fullyconnected, feed-forward neural network with one hidden layer and one output node. To compute the (scalar) output h i of a hidden node i in an artificial neural network, the dot product of the inputs x x x with the trained weights of the node w w w i i i plus a constant offset b i (the bias) is fed into a non-linear, monotonically increasing activation function σ (z):</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Basic Architecture</head><formula xml:id="formula_0">h i ( x x x) = σ ( w w w i i i • x x x + b i )<label>(1)</label></formula><p>We use the sigmoid function σ (z) = 1 1+e −z as activation function which returns values between zero and one. If the function output is close to zero, we say that the respective hidden node is inactive, otherwise, it is active (to a certain degree). Similar to linear regressions, inputs with positive associated weights (or coefficients) have a positive monotonic relationship with the output of the hidden node (i.e., higher values lead to equal or higher outputs), inputs with negative weights have a negative relationship, and inputs with weights close to zero do not significantly impact the output. However, artificial neural networks are more powerful than linear regressions, because they use non-linear activation functions. In simple terms, the activation function enables thresholds, i.e., the node's output may only start to grow significantly above zero if the weighted sum reaches a certain value, and it nearly stops to grow once it is close to one. Apart from this non-linearity, the relation of the hidden node output to its inputs as defined by the weights is still monotonic and smooth, which we exploit in our approach. Understanding the behavior of individual hidden nodes is therefore easier than understanding the model as a whole. The final output y p ( x x x) is assembled from the outputs of the hidden nodes as weighted sum:</p><formula xml:id="formula_1">y p ( x x x) = ∑ i h i ( x x x)v i (2)</formula><p>In the following, we call hidden nodes with a positive associated weight v in the final layer positive nodes (they drive the final prediction up), and nodes with a negative v in the final layer negative nodes. In contrast to a typical feed-forward architecture, we do not use the bias in the final layer to make sure that at least one positive node has to be active for high target values. We scale every variable (inputs and output) so that they are in the range [0, 1]. The lack of bias and the normalization of the output ensures that the resulting prediction of the neural network is (only) high if at least one positive node is sufficiently active and negative nodes are mainly inactive. Hence, positive nodes may offer hints which variables and conditions correlate with high target values.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Hidden Node Filtering</head><p>In our approach, each positive node acts as a filter. We assume that during training, some hidden nodes capture specific cases that lead to a high target value (high-target cases), so filtering the data according to which hidden node is active can offer insights into the cases we are interested in. This decomposition enables analysts to study the relationships between input variables and target separately for distinct conditions. In particular, the input weights of a node indicate how important each input is for the computation of this node, and analysts can focus on the most promising variables even if the total number of inputs is rather high.</p><p>However, for our analysis goal, it is often not enough to filter the data items solely based on whether a particular hidden node is active (i.e., its output h i ( x x x) is high). Say, for instance, our target variable peaks if the (single) input is in the middle at 0.5, but it is low if the input is near zero or one. One hidden node alone cannot model this case, because due to the monotonic nature of the activation function the output of the node cannot go down again after the input has reached 0.5. The neural network could use a second negative node to approximate this function, i.e., the positive node models the ramp-up to 0.5 and the negative node the ramp-down to zero again. We can say that the second, negative node inhibits the output of the positive node if the input is above 0.5. Therefore, we have to take into account the effects of such inhibitors while a particular hidden node is active. To achieve this, we visualize the data distributions of the inputs and the target output for such data items where the respective hidden node of interest is contributing and not just active, which is a smaller subset.</p><p>Regarding a data item, we say a node is contributing if this node is active and the weighted output of the node is high compared to all other weighted outputs of positive nodes and the prediction is high. In other words, we want to detect salient stimulations of hidden nodes by the input data that travel through to the final output value. More formally, let V be the set of hidden nodes, then the contribution c i ( x x x) of hidden node i regarding data item x x x is:</p><formula xml:id="formula_2">c i ( x x x) = 1 Z h i ( x x x) min(y p ( x x x), h i ( x x x)v i ) ∑ j h j ( x x x)v j , ∀ j ∈ V : v j &gt; 0<label>(3)</label></formula><p>We take the final prediction if it is lower than the weighted output of the node to ensure that the node is not suppressed by other (negative) nodes. Z is a scaling factor to retrieve a contribution of 1 for data items that stimulate the particular node the most. The advantage of filtering by contributions instead of just activations is that the resulting 'clusters' can model highly non-linear relationships. For instance, one cluster could model the case that our target variable correlates linearly with a if variables b and c are both within a specific range.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Ranking of Variables</head><p>The filtering (or clustering) helps analysts to focus on specific parts of the data set, but without a suitable ranking of the variables, it may still be tedious to gain insights into such clusters, particularly if the total number of variables is high. We want to rank the variables according to their impact on the contribution of a particular hidden node. As explained in Section 3.1, the output of a hidden node is monotonically related to the weighted sum of all inputs. On the one hand, this means that the magnitude of the weight is an indicator of the impact of the corresponding variable. On the other hand, we also have to take the distribution of the variable into account. A high positive weight is less important if the average value of the variable is close to zero, for instance.</p><p>For an input k of node i with a positive correlation (i.e., w i k &gt; 0), we calculate the average value whenever the node i is contributing and multiply it with the weight w i k . This determines which variable on average has a high share of the weighted sum while the node is contributing, and is therefore a driving force of high activations. For an input l of node i with a negative correlation (i.e., w i l &lt; 0), we determine the average value whenever the node i is not contributing and multiply it with the absolute value of the weight |w i l |. The resulting value tells us which variable has the highest impact on inhibiting the output whenever the node is not contributing, and is therefore enabling high activations if the values are low. More formally, let X be the input rows of the data set. We define the rank r i k of the variable k regarding hidden node i as follows:</p><formula xml:id="formula_3">r i k = |w i k | S ∑ x x x∈X x kĉ i k ( x x x), S = ∑ x x x∈Xĉ i k ( x x x) c i k ( x x x) = c i ( x x x), if w i k &gt; 0 1 − c i ( x x x), otherwise (4)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Homogeneous Regularization</head><p>We want to leverage machine learning to decompose the structure of the target variable into separate components depending on the input variables to explain in which cases the target variable is high. Sometimes, the resulting nodes still combine several cases that we would have liked to be represented separately, so that analysts can easily interpret the relations visually. We therefore introduce a regularization technique that encourages positive hidden nodes to be mainly active in high-value predictions, and negative nodes (inhibitors) to be mainly active in low-value predictions, i.e., we want a more homogeneous behavior of individual nodes with respect to their activation pattern. We say a hidden node i is positive/negative if the associated weight v i to calculate the final prediction is positive/negative.</p><p>Let τ be the threshold that defines the border between low-and high-value cases of our target variable. For each data item x x x and hidden node i in the batch, we define:</p><formula xml:id="formula_4">a i ( x x x, v i ) = 1, if y( x x x) ≥ τ ∧ v i &lt; 0 ∨ y( x x x) &lt; τ ∧ v i &gt; 0 0, otherwise<label>(5)</label></formula><p>In other words, a i ( x x x, v i ) is 1 if the current node i is a positive node and the current target value is below the threshold, or it is 1 if the current node is an inhibitor and the current target value is above the threshold. Let V be the set of hidden nodes. Our loss function L for a single data item ( x x x, y) with the weights W and biases B is then defined as</p><formula xml:id="formula_5">L( x x x, y,W, B) = 1 2 ∑ i∈V h i ( x x x)v i − y( x x x) 2 + 1 2 β ∑ i∈V a i ( x x x, v i )h i ( x x x) 2<label>(6)</label></formula><p>The first part of the loss function is just the typical squared loss to let the network learn accurate predictions. The second part is our homogeneous regularization term that penalizes high node activations of positive nodes for data items that ultimately result in low final outputs and high node activations of negative nodes for data items that result in high final outputs. The hyper-parameter β defines the strength of our regularization.</p><p>In general, the goal of any regularization is to train a model that is better according to some criteria (e.g., generalizability to unseen data) by limiting the solution space. In our case, we want to ensure that the neural network models the task in a 'simpler' way such that the visualized behavior of individual nodes is easier to comprehend.</p><p>For illustrative purposes, let us assume we have two input variables A and B, and the target variable Y is high if (and only if) one of the two input variables is high and the other low. A neural network could model the target function as follows: one hidden node is active if the sum A + B is sufficiently high, and the other hidden node with a negative weight is active if the sum A + B is higher than the maximum possible value of either input. In this case, the first node captures both highvalue scenarios (A is high and B is low, as well as B is low and A is high). However, the first node is also active in a low-value case, namely if A and B are both high. The final prediction is only low in this case because the second node with the negative weight inhibits the output of the first node if A and B are both high. While such a network makes perfectly fine predictions, it is more difficult to interpret visually, because one node captures both high-value scenarios. The proposed regularization, though, avoids this constellation. The network is encouraged to model the relationship in a different way with a greater specialization of each node. One hidden node would only be active if A is high and B low, and the other if B is high and A low, because this leads to a lower loss of our regularization term (while still predicting equally well). The visual representation of the resulting model can then easily explain the two conditions separately.</p><p>We performed a hyper-parameter analysis on a synthetic data set with different values for β and several network sizes. The results show that our homogeneous regularization (β ≥ 0.1) helps to extract all highvalues cases, particularly the more subtle ones. A higher number of hidden nodes also increased the likelihood of detecting the patterns we were interested in. However, the results also show that our approach is generally not very sensitive regarding the hyper-parameters. Appendix A in the supplemental material contains detailed results of our analysis.</p><p>We train the network with mini-batch gradient descent and RMSprop to iteratively derive the weights and biases. After training, we compute for all data items the respective contribution of each hidden node and rank the variables for each node. We use the contributions of a particular node to filter the data items for the histogram and parallel coordinate plots that we describe in detail in Section 4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">APPLICATION DESIGN</head><p>Our approach extracts and visually explains multivariable correlations in a data set regarding a specified target variable. After performing the neural decomposition as described in the previous section, we visualize the distributions of the input variables in relation to our target variable separately for each positive hidden node in our model, based on the calculated contributions (Section 3.2). This helps analysts to understand which variables and ranges correlate with high target values, as each cluster may represent a different group of conditions. With target variable we always refer to the actual values in the data set, not the predictions of the model. We only use the predictions to derive the clustering (Section 3.2). We developed an integrated workflow that enables analysts to load data sets, configure variables, set parameters, train the model, visualize the results, and interact with the views, all within one application. A typical workflow starts with selecting the target variable of the loaded data set. The analyst can then train a neural network that tries to predict the target value based on the other variables. After training, we visualize the resulting clustering with stacked histograms for each hidden node. They offer a compact visual representation of the conditions that lead to high target values. The histograms show the distribution of the variables for a subset of data items that stimulate the particular node. Analysts can then explore and verify the found correlations in a targeted manner with interactive, node-specific parallel coordinate plots and by using simple range filters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Variables</head><p>After loading the data set, the detected variables are listed in the respective tab as shown in <ref type="figure" target="#fig_1">Figure 3</ref>. Here, the 1983 Data Exposition data set <ref type="bibr" target="#b44">[45]</ref> has been loaded that contains a list of (rather ancient) automobiles with several properties and technical specifications, e.g., the horsepower of the car and its driving range in miles per gallon. Analysts can choose which variables should be part of the subsequent analysis process with the toggles on the very left of each row. To select the target variable, they can click on the (T) button next to the name of the respective variable. In <ref type="figure" target="#fig_1">Figure 3</ref>, Horsepower was selected as target variable, i.e., the analyst wants to explore how the other variables relate to the horsepower of the car.</p><p>Upon loading, our application automatically analyzes the given data set to determine the type of each variable (categorical or numerical) and whether a logarithmic scale should be applied. We encode each category as a number between zero and one. While this embedding allows to represent hundreds of categories with just one variable, in machine learning it is often beneficial to split categorical variables into distinct binary variables that represent whether the specific category is on, i.e., whether it is the current value of the original variable. This is also necessary if we want to designate a specific category as target. Analysts can click on the yellow fork button left to the histogram (in <ref type="figure" target="#fig_1">Figure 3)</ref> to generate said distinct variables for each category. Numeric inputs are scaled to the range from zero to one, after having transformed them to the logarithm if needed. Missing values are replaced with the respective regular minimum (0 after scaling) to avoid distortions. The middle of each row displays the type of the variable alongside statistical properties such as the number of categories or mean and standard deviation. Next to it, analysts can override the automatic decision whether a logarithmic scale should be applied or not.</p><p>To the right, a histogram provides insights into the distribution of the variable. A darker shade indicates a higher number of values around that region. For the selected target variable, a slider underneath the histogram appears which allows analysts to define a custom threshold. The percentage in brackets indicates how many data rows fit this threshold and count as high-value cases. The goal of our approach is to visually explain in which conditions the target variable is higher than said threshold. The middle value between maximum and minimum of the respective variable is the default, but in <ref type="figure" target="#fig_1">Figure 3</ref>, the analyst has changed it to the median.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Model Training</head><p>In the third tab (Neural Analysis), analysts can start the training of the model. <ref type="figure">Figure 4</ref> shows how analysts can modify the model size, duration, and the strength of the regularization with sliders located at the top. Bigger models may better capture small-sized effects in the data, <ref type="figure">Fig. 4</ref>. Meta-parameters of the neural network training, e.g., complexity of the model in terms of the number of hidden nodes, or duration in terms of the number of iterations. but take longer to train and can lead to some redundant nodes showing mostly the same information. The resulting error on the training set is depicted at the top-right corner after each run. Underneath the sliders, we show again the histogram of the selected target variable, which is helpful for comparison with the subsequent node visualizations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Node Visualization</head><p>We want to investigate under which conditions our target variable adopts values above a certain threshold (high-value cases). We call data items with a target value above the threshold high-value items. Our approach assumes that some of the positive hidden nodes in our model specialize in particular high-value cases that can then be explained visually. We distinguish between high-and low-value items and cases to improve the utility of our visualization, and it also influences the homogeneous regularization (Section 3.4). For instance, we generally associate high-value items with red, and low-value items with blue colors. However, the neural network learns to predict the actual target value irrespectively of the threshold. <ref type="figure" target="#fig_2">Figure 5</ref> shows the resulting visualizations of the positive nodes after training. We introduce for each node-defined cluster a card that shows the distribution of the data subset the respective node contributes to. We chose the card-based layout because it maps well to our neural decomposition, in that each node represents one distinct cluster of high-value cases that analysts can explore separately, with aggregated statistics for each case. At the same time, it also enables the comparison between nodes by presenting the cards in a list, with the possibility to rank nodes by their relevancy for the problem at hand.</p><p>Each card presents stacked histograms (Section 4.3.1) of the input variables, ordered by the importance of the respective variable for the cluster as described in Section 3.3. They offer a visual summary for which input ranges the node is contributing in relation to the target values. We hide variables with a very low importance score (5% of the first, most important variable per default). The actual coefficient (weight) and average activation of each input is displayed in squared brackets below the name of the variable. The gray header displays the weight, average activation (A), and average contribution (C) of the node. The red and blue bars to the right indicate how many of the highand low-value items the node covers. For instance, if the red bar is at 100% then this means that the node is contributing to all data items with a target value above the threshold. In the ideal case, the blue bars should be rather small, because if red and blue bars are both strong the respective cluster covers both low-and high-value cases.</p><p>In the middle of the gray header, a small histogram depicts the distribution of the target value whenever the node is contributing (target histogram). Users can switch to display the black node coverage instead of the target histogram using the blue toggle button on the bottom left of the window <ref type="figure" target="#fig_2">(Figure 5</ref>). While the target histogram visualizes on which regions of the target variable the node specializes, the node coverage instead shows for which high-value data items the node is contributing. This helps to understand which nodes complement one another and which cover similar data items. To compute the node coverage, we take each high-value item, sort them by which node contributes most on the respective item, assign each a running number, and then build a histogram of all the respective running numbers where the particular node is contributing, i.e., each data item is represented by a vertical line colored from white to black depending on the contribution. On the left side of the window <ref type="figure" target="#fig_2">(Figure 5</ref>), the node summary provides analysts an overview of all nodes with compact versions of the histograms and case coverages that are displayed in the respective headers. Depending on the setting, either the target histogram <ref type="figure">(Figure 6 a)</ref>) or node coverage ( <ref type="figure">Figure 6 b)</ref>) is shown.</p><p>The total number of nodes can be high. To help users focus on promising ones we show those nodes on top which explain high-value cases. We realize this ranking by multiplying the number of affected high-value items of the node with the logarithm of the total number of low-value items divided by the number of affected low-value items. Taking the logarithm of the fraction ensures that we boost nodes covering many high-value items, but relatively few low-value cases.</p><p>The target histograms in <ref type="figure" target="#fig_2">Figure 5</ref> of Node 1 and 2 are similar, so the nodes cover items with a similar distribution of the target variable. The node coverage in <ref type="figure">Figure 6</ref> b) reveals, however, that Node 2 contributes most to different data items than Node 1. Displacement has the most impact on Node 1 with a weight of 3.026, followed by Acceleration. The signs of the weights indicate a positive correlation for the Weight (bigger cars in the data set seem to have more horsepower) and a negative correlation with Acceleration (faster acceleration times seem to coincide with more horsepower). It should be noted that these nodespecific correlations do not necessarily mean that there is an overall statistical correlation with the target variable.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.1">Stacked Histograms</head><p>We want to visualize for which kind of input ranges the particular hidden node is mostly contributing. To achieve this, we generate nodespecific histograms of the input variables. Given an input variable, we divide its range into equally distributed bins and count how many items in the data set fall within each bin, weighted by the contribution of the node. This results in a histogram of the variable that only incorporates data items where the node is contributing. <ref type="figure">Figure 7 a)</ref> shows how the resulting vertical histogram could look like.</p><p>In addition, we relate the input values to the value of the target variable by showing in how many cases the target value was above or below the threshold. Hence, we count high-and low-value data items separately for each bin and display the resulting histogram as a stacked bar chart. In other words, we build two separate histograms, one for those data items in the cluster with a high target value (red bars), and one for those with a low target value (blue bars). <ref type="figure">Figure 7 b)</ref> shows that for every data item where the particular node is contributing and where the Displacement value falls into the top bin, the target value is always above the threshold (the bar is completely red). Conversely, low Displacement values are associated with target values below the threshold, because the lower bars are nearly completely blue.</p><p>Instead of just distinguishing two cases (above vs. below the threshold), we enable users to increase the granularity to multiple bins. This leads to histograms in a histogram. For each bin of the input variable (rows), we visualize the distribution of the target variable (stacked bars within the row). Analysts can choose the granularity of the histograms with two sliders at the bottom of the window ( <ref type="figure" target="#fig_2">Figure 5)</ref>. <ref type="figure">Figure 7 c)</ref> shows the resulting visualization with ten input bins and ten target bins using colors from blue to red. Within the respective cluster, Displacement has a near-linear, positive correlation with the target value (horsepower), because, starting from the bottom, the bars change from blue-ish over gray to red-ish.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.2">Parallel Coordinate Plot</head><p>We employ node-specific PCPs to let analysts explore parts of the data set at a time and investigate relationships between the variables. While the stacked histograms help to summarize which variables and ranges correlate with the target, we add the PCPs to allow for a detailed analysis how exactly the input variables relate to each other for the given case represented by the node. For instance, Node 1 in <ref type="figure" target="#fig_2">Figure 5</ref> indicates that cars in our data set with high displacement and fast acceleration time have high horsepower. The PCP shows that high displacement generally relates to low acceleration times, but in addition to the stacked histograms, it reveals that some cars with very high displacement only have average acceleration times.</p><p>One shortcoming of such plots is that it is often not obvious how the axes should be arranged, even though the order of the columns has a major influence on which patterns and correlations analysts can detect. To tackle this challenge, we use the same order for the axes as for the stacked histograms, i.e., we arrange the columns according to their importance for the respective case represented by the the node.</p><p>Initially, we only draw data items where the node is contributing (filtered data), but this can be changed with two sliders above the plot, <ref type="figure">Fig. 9</ref>. The analyst has selected several bars (green mark on the left) to build a simple range filter. The resulting histogram and statistics are shown below, which in this case indicate that heavier cars in the set built around the 1970s also exhibit above-average horsepower.</p><p>which we call node filters. The filtering mitigates occlusion issues that make it difficult to trace lines and recognize relationships for larger data sets. The first slider (filled circle) determines the general opacity of the filtered data, and the second (outline of a circle) the opacity of the remaining data. If both sliders are at zero, everything is transparent and nothing is shown. If both are at maximum, the complete data set is displayed (but with the node-specific axis order). <ref type="figure" target="#fig_4">Figure 8</ref> shows three different filter settings of one node. In all three cases, the first slider is at maximum, but the second slider changes from zero to intermediate to full. This means that we slowly fade in the remaining data, which helps to relate the specific conditions to the entire data set. In this example, the node focuses on heavy American (lowest position of Origin) cars in the early 1970s (lowest position of Model Year) that exhibit high horsepower (all lines are red). However, if we only looked at the plot of the entire data set this pattern would be hard to detect visually.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.3">Range Filter</head><p>Using the stacked histograms, analysts can build range filters to test hypotheses on interesting subsets of data items. These filters reduce the set of data items to the ones having values in the specified ranges. The stacked histograms in <ref type="figure">Figure 9</ref> indicate that the respective node specializes in ancient, heavy, fast, American cars with many cylinders and high horsepower. To validate whether most of the heavy cars around 1970 in the set have high horsepower, analysts can select the bottom bar of the first variable and the first few bars from the top of the Weight variable by clicking on them. Little green rectangles appear to the left of each selected bar, the name of the variable is marked in green, and a summary of the selected ranges (also in green) appears at the bottom of the histogram. The resulting histogram and statistics of the filter appear below in the box with the green border. Here, our range filter selects 27 cars and all exhibit horsepower above our threshold. The small red bar in the middle of the green box (above the blue bar) shows that the filter covers roughly 10% of all high-value cases. Hence, cars in the data set from around 1970 which are heavier than average also have above-average horsepower. Range filters always use the complete data set and do not depend on any node activation. The node-specific visualizations, however, guide analysts to define such range filters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">EVALUATION</head><p>In this section, we first show that our approach can detect and visualize correlations that involve more than two variables. Afterward, we will apply our method to real-world data sets to show its utility. Finally, we report on qualitative feedback on the suitability of the approach that we received from our domain expert.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Identification of High-Value Cases</head><p>We apply our approach to a synthetic data set to test its capability of identifying correlations between more than two variables. The data set contains three input variables a, b, c and 27,000 data rows that correlate with high values of a target variable under the following circumstances:</p><formula xml:id="formula_6">y(a, b, c) = min(|a − b|, |b − c|, |c − a|)<label>(7)</label></formula><p>The target value reaches its maximum of 0.5 only if one variable is 0, one is 0.5, and the third is 1. We uniformly sampled the input space a, b, c ∈ [0, 1] and generated 27, 000 rows. We designed the <ref type="figure">Fig. 10</ref>. Comparison between scatter plots (top) and our approach (bottom) to visualize a four-dimensional artificial data set containing three different high-value patterns (different variable order due to importance ranking). The target variable is mapped to a color scale from blue to red.</p><p>target function y(a, b, c) such that the resulting data set poses several challenges. First, only about 12% of the items have target values above our threshold of 0.25 and only 0.8% above 0.4, i.e., our machine learning model has few high-value samples to learn from. Second, our target highly depends on the combination of all three variables, i.e., if we plot individual variables or pair of variables against our target value, we can hardly recognize any correlation. Third, there are three different patterns that exhibit high target values, which would be occluded in a parallel coordinates plot. We consider this data set to be a benchmark for testing our method under challenging conditions. <ref type="figure">Figure 10</ref> shows the resulting stacked histograms of three hidden nodes of our trained model, and scatter plots of every combination of a, b, c for comparison. The target variable is mapped to a color scale from blue over gray to red in all plots. From the scatter plots at the top, the analyst can conclude that the target is zero if any two variables have equal values, but it is not possible to recognize the three clusters of our ground-truth. Conversely, the stacked histograms at the bottom reveal the three different patterns that lead to high values of y, namely the three permutations of a, b, c where one variable is near 0, one is near 1, and the third is around the middle. For instance, the first plot on the bottom-left indicates high target values (gray-and red-like bars) if b is low, c high, and a around 0.5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Use Cases on Real-World Data Sets</head><p>VND supports the visual analysis of high-value cases in large multivariate data sets across a wide spectrum of use cases where the number of variables can be high. Subsequently, we present two real-world use cases from different domains: IC chip testing and population surveys.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.1">Chip Testing Measurements</head><p>Detecting and understanding complex input patterns that lead to errors in chip testing is a difficult endeavor. We received a data set with measurements of a clock chip from our partner, a vendor of automatic test equipment. The goal is to explore which conditions lead to high jitter as indicated by the target variable JTotal. Hence, our target variable is continuous, and the higher the value, the worse. The set consists of 2049 data items and 43 variables including the target variable, and about 18% of the items exhibit jitter above the desired threshold. <ref type="figure" target="#fig_5">Figure 11</ref> presents the resulting top three nodes after training. These nodes mostly cover different parts of the data set according to the node coverage histograms (in black). The output histograms <ref type="figure">(Figure 1</ref> shows the compact version on the very left) reveal that Node 6 and 5 mostly contribute to lower output values (jitter) around the threshold, whereas Node 4 specializes on few very high-value cases. The Node 6-specific parallel coordinate plot is visible in <ref type="figure">Figure 1</ref> and depicts all data items where Node 6 is contributing. This plot and the applied range filter in <ref type="figure" target="#fig_5">Figure 11 (A)</ref> show that a specific combination of the two most important variables for that first node almost always leads to target values above the threshold and can explain about half of all high-value cases. For Node 4, the first variable is already enough to define 11 items with high jitter (B). However, Node 5 shows a less conclusive picture (C). The applied range filter and the red bar in the header indicate that the pattern represented by the node exhibits above-average jitter, but the node also contributes to several low-value cases. This could mean that these conditions lead to unstable behavior which is sometimes inand sometimes out-of-spec.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.2">AP VoteCast 2018</head><p>The independent social research organization NORC at the University of Chicago conducted a survey of 138,929 registered US voters in 2018 <ref type="bibr" target="#b54">[55]</ref>. To learn more about the voting behavior in the US presidential election 2016, we used the subset marked as nationally representative with 4,913 registered voters, in which the participants were asked who they voted for in 2016. 1625 respondents (33.1%) said they voted for Donald Trump, and 2129 (43.3%) for Hillary Clinton. We disabled variables associated with certain parties or politicians (e.g., whether the respondent likes politician X) to gain insights into voting behaviors based on demographics and policy attitudes. This reduced the number of variables to 67. <ref type="figure" target="#fig_0">Figure 12</ref> presents the result of our approach where we picked as target variable whether the participant voted for Donald Trump or not. The top node shows that attitudes towards the border wall project and the Affordable Care Act (Obamacare) are strong predictors for the voting behavior of the participants. Among those that are sure they voted in the presidential election (QPVVOTE), favor the border wall (IMMWALL), think that the Affordable Care Act should be at least partially repealed (HEALTHLAW), are not gay or bisexual (LGB), and do not think that the Trump campaign coordinated with Russia during the election (RUSSIA), 91.3% said they voted for Trump, which represents 72.1% of all Trump voters in the survey. Conversely, participants that oppose the border wall, think that the Care Act should be at least kept as it is, and are sure they voted in the election, 86% voted for Clinton (see Appendix B for figures).</p><p>Node 1 in <ref type="figure" target="#fig_0">Figure 12</ref> is interesting because it represents a cluster that only partially overlaps with Node 8. The range filter reveals that 84% of the female participants who are at least concerned about climate change (CLIMATE), but think that the trade policies of Trump's administration would help the national economy (TRADENATIONALECON), that Blacks have more or equally many advantages compared to Whites (RACEREL), and that they are sure they voted in the election, voted  for Trump. The percentage is significantly higher than the 29.7% of Trump voters in the rest of the data set (Fisher's exact test, p 0.001). This is an interesting finding, because if we look at some of the variables individually, we observe different trends: 29.8% of the female respondents, and 20.4% of those at least somewhat concerned regarding climate change said they voted for Trump, which is in both cases less than the data set-wide average.</p><p>To investigate whether analysts would have found this insight using related methods, we applied PCA <ref type="bibr" target="#b0">[1]</ref>, t-SNE <ref type="bibr" target="#b57">[58]</ref> and UMAP <ref type="bibr" target="#b36">[37]</ref> to the exact same data set. It turns out that our cluster of interest does not form a visual cluster in any of the projections <ref type="figure" target="#fig_1">(Figure 13</ref> depicts the result for t-SNE). Hence, with the projections it would be difficult for analysts to detect and explore a cluster comparable to the one we found with our approach (see Appendix B for the detailed analysis). This use case also shows that a particular combination of several variables can exhibit much stronger (and sometimes opposite) correlations with the target variable than individual variables or pairs, while at the same time still covering a large proportion of interesting high-value cases.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Qualitative Feedback</head><p>We presented a domain expert and research fellow of the world's largest provider of automatic test equipment an earlier version of our approach and collected preliminary feedback. We introduced the system and showed the results of the data set the company provided (Section 5.2.1). The expert was impressed that our approach was capable to detect highvalue conditions and that it supports the exploration of highly interesting combinations of variables. He was confident that this would greatly support the engineers in finding problematic conditions. However, he noted that there is a learning curve as it takes some time to understand the stacked histogram visualizations.</p><p>The expert made several suggestions on how to improve the utility of our approach. It should be possible to filter by value range of certain variables (not just by nodes), the target threshold should be customizable, and it should be possible to remove or ignore data items based on clear correlations to focus on the remaining, less-understood parts of the data set. Based on the feedback, we implemented the range filter and made the target threshold adjustable. In addition, we developed the node coverage histograms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">DISCUSSION</head><p>Visual Neural Decomposition (VND) can extract high-value conditions in multivariate data sets that contain many variables and it guides analysts to explore non-linear multi-variable relationships. Our use cases show that the approach can also reveal significant relationships that are difficult to find with related methods, e.g., approaches applying dimensionality reduction techniques or linear models. With our novel approach, analysts do not need to iteratively select one or two variables at a time to start the process. Instead, we separately visualize groups of conditions based on the original dimensions that often have a semantic meaning in multivariate data sets. Additionally, the automatic analysis does not only cluster the results, but it also provides a ranking of the most important variables of each cluster. This helps users to grasp the meaning of each cluster. The provided interaction possibilities such as the range filter or node-specific parallel coordinate plots enable analysts to validate their hypotheses and build trust in what they see.</p><p>Our proposed technique has certain limitations. While it scales to hundreds of variables, it was not designed for the analysis of very high-dimensional data sets, for instance, images with millions of pixels. However, in this case, it is often not helpful to explain certain conditions based on single pixel values. A shortcoming is that analysts have to define hyper-parameters, e.g., the number of nodes, and each run can lead to a slightly different output. Nevertheless, our analysis (Section 3.4) shows that the method is not very sensitive to the specified parameters. Generally, more nodes and longer training are better, but also computationally more expensive. In our use cases, the training only took seconds, though. The regularization constrains the solution space, but there can still be several equally valid definitions of clusters, particularly if the variables are not independent of each other. The goal of VND is to visually explain high-value cases, hence, if one input is already enough to perfectly predict the target then VND probably will not extract additional (somewhat redundant) cases. Finally, it is important to realize that our approach visualizes interesting conditions that appear in the data. If analysts want to generalize such findings, e.g., whether an observed voting behavior applies to the general population, they still need to perform statistical tests for significance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">CONCLUSION AND FUTURE WORK</head><p>We proposed a novel method to visually explain multivariate data sets using neural networks. The idea is to decompose the data set into components as represented by the hidden nodes and provide nodespecific views of the data set. For this, we developed an integrated approach to configure the data, train the model, visualize the results, and offer interaction mechanisms to let analysts validate hypotheses.</p><p>In the future, we aim to further improve the analysis workflow. We would like to support negative filters, i.e., analysts can select items based on nodes or value ranges that should be ignored in a subsequent run to encourage explanations for the remaining, less understood parts of the data set. Letting users define unions or intersections of nodes and range filters could help to quantify how many high-value cases are covered in total. Finally, providing an additional mode to align variables with those of a reference node would enable a detailed comparison of interesting subsets.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 2 .</head><label>2</label><figDesc>Architecture with inputs x x x, input weights w w w i , biases b i , hidden node outputs h i , hidden node weights v i , and prediction y p of the target.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 3 .</head><label>3</label><figDesc>All available variables of the automobiles data set with previews of the data, scale, and histogram.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 5 .</head><label>5</label><figDesc>Visualization of the resulting model. Each card represents one hidden node and visualizes the data set filtered by the contribution of the respective node. A compact overview of the nodes is shown on the left.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 6 .Fig. 7 .</head><label>67</label><figDesc>Compact overview of all positive nodes: a) node-specific histogram of target, b) node-specific coverage of high-value cases vertical histogram of one input variable target value above threshold target value below threshold Histogram of one particular input variable of a node: a) plain, b) two stacked bars per input bin for high-(red) and low-value (blue) cases, c) ten stacked bars per bin to visualize distribution of the target variable based on the input variable.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 8 .</head><label>8</label><figDesc>Node-specific PCPs with different filter settings. The columns are ordered by the importance of the inputs for the node. Top: Plot using only data items where this node is contributing. Middle: Plot includes remaining data items, but diminished. Bottom: Plot of all data items.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 11 .</head><label>11</label><figDesc>Decomposition of a chip testing data set. Higher target values (gray to red) correspond to faulty behavior of the clock device (jitter).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 12 .</head><label>12</label><figDesc>Decomposition of the AP VoteCast 2018 representative national survey data set comprising 4,913 respondents with 67 variables. Target variable is whether participants said they voted for Donald Trump in 2016.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 13 .</head><label>13</label><figDesc>t-SNE projection of the VoteCast data. Items matching our range filter of Node 1 are colored orange.</figDesc></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS</head><p>This research was partially supported by Advantest as part of the Graduate School 'Intelligent Methods for Test and Reliability' (GS-IMTR) at the University of Stuttgart, and by the German Science Foundation (DFG) as part of the project 'VAOST' (project number 392087235). In particular, we would like to thank Jochen Rivoir from Advantest for giving us access to the chip test data set and for his valuable feedback.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Principal component analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Abdi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">J</forename><surname>Williams</surname></persName>
		</author>
		<idno>doi: 10. 1002/wics.101</idno>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Subpopulation Discovery and Validation in Epidemiological Data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Alemzadeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Hielscher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Niemann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Cibulski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Ittermann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Völzke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Spiliopoulou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Preim</surname></persName>
		</author>
		<idno type="DOI">10.2312/eurova.20171118</idno>
	</analytic>
	<monogr>
		<title level="m">EuroVis Workshop on Visual Analytics (EuroVA). The Eurographics Association</title>
		<editor>M. Sedlmair and C. Tominski</editor>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Uncovering clusters in crowded parallel coordinates visualizations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">O</forename><surname>Artero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">C</forename><surname>Ferreira De</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Oliveira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Levkowitz</surname></persName>
		</author>
		<idno>doi: 10. 1109/INFVIS.2004.68</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings -IEEE Symposium on Information Visualization, INFO VIS</title>
		<meeting>-IEEE Symposium on Information Visualization, INFO VIS</meeting>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">VISA: visual subspace clustering analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Assent</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Krieger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Seidl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Emmanuel</surname></persName>
		</author>
		<idno type="DOI">10.1145/1345448.1345451</idno>
	</analytic>
	<monogr>
		<title level="j">ACM SIGKDD Explorations</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Multivariate visual explanation for high dimensional datasets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Barlowe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Jacobs</surname></persName>
		</author>
		<idno>doi: 10. 1109/VAST.2008.4677368</idno>
	</analytic>
	<monogr>
		<title level="m">VAST&apos;08 -IEEE Symposium on Visual Analytics Science and Technology, Proceedings</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Feedback-driven interactive exploration of large multidimensional data supported by visual classifier</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Behrisch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Korkmaz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Schreck</surname></persName>
		</author>
		<idno type="DOI">10.1109/VAST.2014.7042480</idno>
	</analytic>
	<monogr>
		<title level="m">2014 IEEE Conference on Visual Analytics Science and Technology</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note>VAST 2014 -Proceedings</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Visual-interactive exploration of interesting multivariate relations in mixed research data sets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bernard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Steiger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Widmer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lücke-Tieke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>May</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kohlhammer</surname></persName>
		</author>
		<idno type="DOI">10.1111/cgf.12385</idno>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics Forum</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Bertini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P.-T</forename><surname>Bremer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Oelke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Thiagarajan</surname></persName>
		</author>
		<idno>doi: 10.4230/ DagRep.9.11.24</idno>
	</analytic>
	<monogr>
		<title level="m">Machine Learning Meets Visualization to Make Artificial Intelligence Interpretable (Dagstuhl Seminar</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="24" to="33" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">DICON: Interactive visual analysis of multidimensional clusters</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Gotz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Qu</surname></persName>
		</author>
		<idno type="DOI">10.1109/TVCG.2011.188</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Scatterplot Matrix Techniques for Large N</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">B</forename><surname>Carr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">J</forename><surname>Littlefield</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">L</forename><surname>Nicholson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">S</forename><surname>Littlefield</surname></persName>
		</author>
		<idno type="DOI">10.2307/2289444</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Statistical Association</title>
		<imprint>
			<date type="published" when="1987" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">RadViz Deluxe: An Attribute-Aware Display for Multivariate Data. Processes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Mueller</surname></persName>
		</author>
		<idno type="DOI">10.3390/pr5040075</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Visual Analytics for Explainable Deep Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Choo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<idno type="DOI">10.1109/MCG.2018.042731661</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer Graphics and Applications</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Multidimensional Scaling, Second Edition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Cox</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Cox</surname></persName>
		</author>
		<idno type="DOI">10.1201/9781420036121</idno>
		<imprint>
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">RegressionExplorer: Interactive Exploration of Logistic Regression Models with Subgroup Analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Dingen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Van't Veer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Houthuizen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">H</forename><surname>Mestrom</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">H</forename><surname>Korsten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">R</forename><surname>Bouwman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Van Wijk</surname></persName>
		</author>
		<idno>doi: 10. 1109/TVCG.2018.2865043</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Making Parameter Dependencies of Time-Series Segmentation Visually Understandable</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Eichner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Schumann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Tominski</surname></persName>
		</author>
		<idno type="DOI">10.1111/cgf.13894</idno>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics Forum</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Supporting Analysis of Dimensionality Reduction Results with Contrastive Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Fujiwara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><forename type="middle">H</forename><surname>Kwon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">L</forename><surname>Ma</surname></persName>
		</author>
		<idno type="DOI">10.1109/TVCG.2019.2934251</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Explainers: Expert explorations with crafted projections</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gleicher</surname></persName>
		</author>
		<idno type="DOI">10.1109/TVCG.2013.157</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Neural decomposition of time-series data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">B</forename><surname>Godfrey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">S</forename><surname>Gashler</surname></persName>
		</author>
		<idno type="DOI">10.1109/SMC.2017.8123050</idno>
	</analytic>
	<monogr>
		<title level="m">2017 IEEE International Conference on Systems, Man, and Cybernetics</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Visualizing Multiple Variables Across Scale and Geography</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Goodwin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dykes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Slingsby</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Turkay</surname></persName>
		</author>
		<idno type="DOI">10.1109/TVCG.2015.2467199</idno>
	</analytic>
	<monogr>
		<title level="m">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">MCExplorer: Interactive exploration of multiple (subspace) clustering solutions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Günnemann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Kremer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Färber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Seidl</surname></persName>
		</author>
		<idno>doi: 10. 1109/ICDMW.2010.29</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings -IEEE International Conference on Data Mining, ICDM</title>
		<meeting>-IEEE International Conference on Data Mining, ICDM</meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">State of the Art of Parallel Coordinates</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Heinrich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Weiskopf</surname></persName>
		</author>
		<idno>doi: 10.2312/ conf/EG2013/stars/095-116</idno>
	</analytic>
	<monogr>
		<title level="m">Eurographics Conference on Visualization (EuroVis)</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Visual analytics for concept exploration in subspaces of patient groups</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hund</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Böhm</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Sturm</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sedlmair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Schreck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Ullrich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename><surname>Keim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Majnaric</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Holzinger</surname></persName>
		</author>
		<idno>doi: 10. 1007/s40708-016-0043-5</idno>
	</analytic>
	<monogr>
		<title level="j">Brain Informatics</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">The plane with parallel coordinates. The Visual Computer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Inselberg</surname></persName>
		</author>
		<idno type="DOI">10.1007/BF01898350</idno>
		<imprint>
			<date type="published" when="1985" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Pattern Trails: Visual Analysis of Pattern Transitions in Subspaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Jackle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hund</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Behrisch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename><surname>Keim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Schreck</surname></persName>
		</author>
		<idno type="DOI">10.1109/VAST.2017.8585613</idno>
	</analytic>
	<monogr>
		<title level="m">2017 IEEE Conference on Visual Analytics Science and Technology</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note>VAST 2017 -Proceedings</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Enhancing parallel coordinates: Statistical visualizations for analyzing soccer data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Janetzko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Sacha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Schreck</surname></persName>
		</author>
		<idno type="DOI">10.2352/issn.2470-1173.2016.1.vda-486</idno>
	</analytic>
	<monogr>
		<title level="m">IS and T International Symposium on Electronic Imaging Science and Technology</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Visualizing surrogate decision trees of convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<idno type="DOI">10.1007/s12650-019-00607-z</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of Visualization</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Revealing structure within clustered parallel coordinates displays</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Johansson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Ljung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Jern</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Cooper</surname></persName>
		</author>
		<idno type="DOI">10.1109/INFVIS.2005.1532138</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings -IEEE Symposium on Information Visualization, INFO VIS</title>
		<meeting>-IEEE Symposium on Information Visualization, INFO VIS</meeting>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Principal Component Analysis, Second Edition. Encyclopedia of Statistics in Behavioral Science</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">T</forename><surname>Jolliffe</surname></persName>
		</author>
		<idno type="DOI">10.2307/1270093</idno>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">ActiVis: Visual Exploration of Industry-Scale Deep Neural Network Models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kahng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">Y</forename><surname>Andrews</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kalro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">H P</forename><surname>Chau</surname></persName>
		</author>
		<idno>doi: 10. 1109/TVCG.2017.2744718</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">3D Regression Heat Map Analysis of Population Study Data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Klemm</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lawonn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Glaßer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Niemann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Hegenscheid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Völzke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Preim</surname></persName>
		</author>
		<idno type="DOI">10.1109/TVCG.2015.2468291</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">SeekAView: An intelligent dimensionality reduction strategy for navigating high-dimensional data spaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Dasgupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">D</forename><surname>Fekete</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Bertini</surname></persName>
		</author>
		<idno type="DOI">10.1109/LDAV.2016.7874305</idno>
	</analytic>
	<monogr>
		<title level="m">IEEE Symposium on Large Data Analysis and Visualization 2016</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note>LDAV 2016 -Proceedings</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">INFUSE: Interactive feature selection for predictive modeling of high dimensional data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Perer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Bertini</surname></persName>
		</author>
		<idno type="DOI">10.1109/TVCG.2014.2346482</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<idno type="DOI">10.1109/TVCG.2016.2598831</idno>
		<title level="m">Towards Better Analysis of Deep Convolutional Neural Networks. IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Weiskopf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">E</forename><surname>Kirkpatrick</surname></persName>
		</author>
		<title level="m">Cluster Visualization in Parallel Coordinates Using Curve Bundles</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">A correlative analysis process in a visual analytics environment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Malik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Maciejewski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Elmqvist</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Jang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">S</forename><surname>Ebert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Huang</surname></persName>
		</author>
		<idno type="DOI">10.1109/VAST.2012.6400491</idno>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Visual Analytics Science and Technology</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
	<note>VAST 2012 -Proceedings</note>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Guiding feature subset selection with an interactive visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>May</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bannach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Davey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Ruppert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kohlhammer</surname></persName>
		</author>
		<idno type="DOI">10.1109/VAST.2011.6102448</idno>
	</analytic>
	<monogr>
		<title level="m">VAST 2011 -IEEE Conference on Visual Analytics Science and Technology</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">UMAP: Uniform Manifold Approximation and Projection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Mcinnes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Healy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Saul</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Großberger</surname></persName>
		</author>
		<idno type="DOI">10.21105/joss.00861</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of Open Source Software</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Post-silicon validation opportunities, challenges and recent advances</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mitra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">A</forename><surname>Seshia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Nicolici</surname></persName>
		</author>
		<idno type="DOI">10.1145/1837274.1837280</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings -Design Automation Conference</title>
		<meeting>-Design Automation Conference</meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">TreePOD: Sensitivity-Aware Selection of Pareto-Optimal Decision Trees</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Mühlbacher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Linhardt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Möller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Piringer</surname></persName>
		</author>
		<idno>doi: 10. 1109/TVCG.2017.2745158</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">A partition-based framework for building and validating regression models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Muhlbacher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Piringer</surname></persName>
		</author>
		<idno type="DOI">10.1109/TVCG.2013.125</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">A framework for evaluation and exploration of clustering algorithms in subspaces of high dimensional databases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Assent</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Günnemann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Gerwert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hannen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Jansen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Seidl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Lecture Notes in Informatics (LNI), Proceedings -Series of the Gesellschaft fur Informatik (GI)</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Morpheus: Interactive exploration of subspace clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Assent</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Krieger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Jansen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Seidl</surname></persName>
		</author>
		<idno type="DOI">10.1145/1401890.1402026</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</title>
		<meeting>the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</meeting>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Outlier-preserving focus+context visualization in parallel coordinates</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Novotný</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Hauser</surname></persName>
		</author>
		<idno type="DOI">10.1109/TVCG.2006.170</idno>
	</analytic>
	<monogr>
		<title level="m">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Quantifying and comparing features in high-dimensional datasets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Piringer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Berger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Hauser</surname></persName>
		</author>
		<idno type="DOI">10.1109/IV.2008.17</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Information Visualisation</title>
		<meeting>the International Conference on Information Visualisation</meeting>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">ASA Data Exposition dataset</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Ramos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Donoho</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1983" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Enabling hierarchical exploration for large-scale multidimensional data with abstract parallel coordinates</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Richer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sansen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Lalanne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Auber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Bourqui</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CEUR Workshop Proceedings</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">VIS4ML: An Ontology for Visual Analytics Assisted Machine Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Sacha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kraus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename><surname>Keim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Chen</surname></persName>
		</author>
		<idno type="DOI">10.1109/TVCG.2018.2864838</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Retrieval and exploratory search in multivariate research data repositories using regressional features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Scherer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bernard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Schreck</surname></persName>
		</author>
		<idno type="DOI">10.1145/1998076.1998144</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM/IEEE Joint Conference on Digital Libraries</title>
		<meeting>the ACM/IEEE Joint Conference on Digital Libraries</meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Linear regression analysis: part 14 of a series on evaluation of scientific publications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Schneider</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hommel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Blettner</surname></persName>
		</author>
		<idno type="DOI">10.3238/arztebl.2010.0776</idno>
	</analytic>
	<monogr>
		<title level="j">Deutsches Arzteblatt international</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Visual parameter space analysis: A conceptual framework</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sedlmair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Heinzl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bruckner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Piringer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Moller</surname></persName>
		</author>
		<idno type="DOI">10.1109/TVCG.2014.2346321</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">LSTMVis: A Tool for Visual Analysis of Hidden State Dynamics in Recurrent Neural Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Strobelt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gehrmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Pfister</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">M</forename><surname>Rush</surname></persName>
		</author>
		<idno type="DOI">10.1109/TVCG.2017.2744158</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Combining automated analysis and visualization techniques for effective exploration of high-dimensional data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Tatu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Albuquerque</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Eisemann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schneidewind</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Theisel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Magnork</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Keim</surname></persName>
		</author>
		<idno type="DOI">10.1109/VAST.2009.5332628</idno>
	</analytic>
	<monogr>
		<title level="m">VAST 09 -IEEE Symposium on Visual Analytics Science and Technology</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Subspace search and visualization to make sense of alternative clusterings in high-dimensional data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Tatu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Maaß</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Färber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Bertini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Schreck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Seidl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Keim</surname></persName>
		</author>
		<idno>doi: 10.1109/ VAST.2012.6400488</idno>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Visual Analytics Science and Technology</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
	<note>VAST 2012 -Proceedings</note>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">ClustNails: Visual analysis of subspace clusters</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Tatu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Bertini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Schreck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Keim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bremm</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">Von</forename><surname>Landesberger</surname></persName>
		</author>
		<idno type="DOI">10.1109/TST.2012.6297588</idno>
	</analytic>
	<monogr>
		<title level="j">Tsinghua Science and Technology</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Tompson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Benz</surname></persName>
		</author>
		<idno>doi: 10.3886/ E109687V2</idno>
	</analytic>
	<monogr>
		<title level="j">AP</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Representative factor generation for the interactive visual analysis of high-dimensional data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Turkay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lundervold</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">J</forename><surname>Lundervold</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Hauser</surname></persName>
		</author>
		<idno type="DOI">10.1109/TVCG.2012.256</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">BaobabView: Interactive construction and analysis of decision trees</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Van Den Elzen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">J</forename><surname>Van Wijk</surname></persName>
		</author>
		<idno>doi: 10.1109/ VAST.2011.6102453</idno>
	</analytic>
	<monogr>
		<title level="m">VAST 2011 -IEEE Conference on Visual Analytics Science and Technology</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Visualizing data using t-SNE</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Van Der Maaten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">The Subspace Voyager: Exploring High-Dimensional Data along a Continuum of Salient 3D Subspaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Mueller</surname></persName>
		</author>
		<idno>doi: 10. 1109/TVCG.2017.2672987</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Voyager: Exploratory Analysis via Faceted Browsing of Visualization Recommendations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Wongsuphasawat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Moritz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Anand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Mackinlay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Howe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Heer</surname></persName>
		</author>
		<idno type="DOI">10.1109/TVCG.2015.2467191</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Voyager 2: Augmenting visual analysis with partial view specifications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Wongsuphasawat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Moritz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Ouk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Anand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Mackinlay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Howe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Heer</surname></persName>
		</author>
		<idno type="DOI">10.1145/3025453.3025768</idno>
	</analytic>
	<monogr>
		<title level="m">Conference on Human Factors in Computing Systems -Proceedings</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">A visual analytics approach to high-dimensional logistic regression modeling and its application to an environmental health study</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">B</forename><surname>Zhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">D</forename><surname>Brender</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">H</forename><surname>Langlois</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Barlowe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhao</surname></persName>
		</author>
		<idno>doi: 10.1109/ PACIFICVIS.2016.7465261</idno>
	</analytic>
	<monogr>
		<title level="m">IEEE Pacific Visualization Symposium</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Visual correlation analysis of numerical and categorical data on the correlation map</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">T</forename><surname>Mcdonnell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Zadok</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Mueller</surname></persName>
		</author>
		<idno>doi: 10. 1109/TVCG.2014.2350494</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Visualizing deep neural network decisions: Prediction difference analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">M</forename><surname>Zintgraf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">S</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Adel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">5th International Conference on Learning Representations, ICLR 2017 -Conference Track Proceedings</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
