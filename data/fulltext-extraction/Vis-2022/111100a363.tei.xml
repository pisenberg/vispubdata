<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A Framework for Multiclass Contour Visualization</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Sihang</forename><surname>Li</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Jiacheng</forename><surname>Yu</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Mingxuan</forename><surname>Li</surname></persName>
						</author>
						<author>
							<persName><roleName>Xiaolong</roleName><forename type="first">Le</forename><surname>Liu</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Luke</forename><surname>Zhang</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Xiaoru</forename><surname>Yuan</surname></persName>
						</author>
						<title level="a" type="main">A Framework for Multiclass Contour Visualization</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.2" ident="GROBID" when="2023-03-27T09:23+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Contour</term>
					<term>multiclass visualization</term>
					<term>visualization framework</term>
					<term>domain-specific language</term>
					<term>visualization design</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Fig. 1. Examples of some design parameter attribute under our proposed multiclass contour visualization framework. (a) Line Number: the number of contour lines in each class, 12 (1) vs. 6 (2). (b) Line Style: solid (1) vs. dashed (2). (c) Halo: contour lines without halos (1) vs. with halos (2). (d) Fill: the contours without fillings (1) vs. with fillings (2). (e) Order: multiple contours plotted by level (1) vs. by class (2). (f) Mix: multiple contours stacked with direct overlay (1) vs. with color blending (2).</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Contour plots are widely used to visualize scalar quantities and field data in many fields, such as weather analysis <ref type="bibr" target="#b1">[2]</ref>, computational fluid dynamics <ref type="bibr" target="#b0">[1]</ref>, and artificial intelligence <ref type="bibr" target="#b24">[25]</ref>. A contour plot draws a set of contour lines by setting different values and connecting points with the same value of a given attribute. We call the lines representing higher values the higher-level contour lines. The contour with contour lines of different levels shows the data attribute's value levels and helps users see its distribution and identify some essential characteristics such as extreme points. Nowadays, field data has become more complex. Visualizing and analyzing the contours of multiple variables and attributes associated with the same spatial region has become a common practice. Such contours are referred to as multiclass contours. A typical example is meteorological data, which contains attributes like air temperature, pressure, humidity, etc., and different data in different years. The multiclass contours of meteorological data are essential for meteorologists to obtain a comprehensive overview of climate change over a specific region. In addition, multiclass contours have recently been extended to other fields <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b18">19]</ref>, where they can help compare the multiple distributions.</p><p>Multiple contours can be rendered as separate displays. However, Early studies have reported that using separate displays creates more perceptual and cognitive work for viewers and significantly prevents them from discovering and analyzing patterns of multiple variables <ref type="bibr" target="#b8">[9]</ref>. Another method is to overlay the contours into a single view. However, directly overlaying these contours will inevitably lead to visual clutters. Researchers have proposed various design approaches to address this issue, including reducing the number of contour lines of individual classes and using different visual channels for portraying contours <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b36">37]</ref>. However, little research is done to consider how these approaches should be integrated holistically. On the one hand, there is a lack of summary of the existing approaches, and what design parameters can be chosen in the visualization designs of the multiclass contour is unclear. Designers are hard to explore the design parameters and possible values systematically. On the other hand, in practice, it is often difficult for users to choose appropriate multiclass contour designs for different tasks. Even for the contours from experienced visual designers, such as those in visualization research papers, the rationales behind designs are often missing. We argued that the design parameters of multiclass contour visualization must be carefully chosen to make the display more comprehensible and enable users to perform specific tasks better. The guidance of the design parameters selection strategy is essential.</p><p>With this in mind, we proposed a framework for multiclass contour visualization. This paper reports our work in constructing two components of the framework: identifying some essential design parameters and developing a declarative language to facilitate the description and design of multiclass contour visualization. To identify the design parameters, we conducted an extensive review of literature in the field of multiclass contour visualization and summarized four design parameters: Line, Fill, Order, and Mix. Each of these parameters has some attributes that can be considered in the design. Then, to streamline the design by using these parameters, we developed a declarative domainspecific language (DSL) so that users can quickly generate multiclass contour visualizations with a simple text description of samples.</p><p>We also set up a task-oriented lab study on the impacts of some design parameters on user interpretations of multiclass contours. The results of the user study, which examined how different value choices and combinations of some design parameters influence the understanding of multiclass contours, offer suggestions on the design choices of multiclass contour visualization.</p><p>In general, our research made the following contributions:</p><p>• Developed a framework for multiclass contour visualization, including a set of essential design parameters based on literature review and a declarative domain-specific language for quick generation of multiclass contour visualization.</p><p>• Provided design suggestions based on the results of a taskoriented user study on the impacts of design parameters on the understanding of multiclass contours.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK</head><p>In this section, we reviewed previous work on two areas: contour visualizations and declarative languages for visualization generation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Contour Visualization</head><p>Contour is a very common visualization method to visualize scalar fields. By setting different value thresholds, multiple closed contour lines can be obtained to represent the distribution of the values. In the visualization community, research in this direction includes the use of contour lines to represent the area with high density and outlier points <ref type="bibr" target="#b20">[21]</ref>, the combination of multiple contours to express uncertainty <ref type="bibr" target="#b34">[35]</ref>, the application of line width to encode extreme values <ref type="bibr" target="#b36">[37]</ref>, and the incorporation of contour-like strokes into the nodes of scatterplot to show global data structure <ref type="bibr" target="#b16">[17]</ref>.</p><p>Another usage of the contour is to visually enclosure objects to indicate classes explicitly. Research efforts have been made to improve contour visualizations by incorporating other visualization parameters, such as the textures and alpha blending to show intersecting sets <ref type="bibr" target="#b30">[31]</ref>, Bubble Sets to show sets and their relationships <ref type="bibr" target="#b5">[6]</ref>, and Rectangular Euler Diagrams to improve the readability of the set intersections <ref type="bibr" target="#b22">[23]</ref>.</p><p>In addition to research on new methods to enhance contour visualization, some efforts were made to adapt traditional contour visualization methods to different data types, including density maps <ref type="bibr" target="#b11">[12]</ref>, texts <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b15">16]</ref>, graphs <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b37">38]</ref>, scatterplots <ref type="bibr" target="#b31">[32]</ref>, spatial data <ref type="bibr" target="#b17">[18]</ref>, high-dimensional data <ref type="bibr" target="#b18">[19]</ref>, and medical data <ref type="bibr" target="#b28">[29]</ref>.</p><p>These novel approaches lay the foundation for our framework and suggest what design parameters should be considered.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Declarative Language for Visualization Design</head><p>A declarative language allows developers to describe the results of computation. Compared to traditional programming languages requiring developers to describe how the results should be generated, declarative languages can simplify development processes <ref type="bibr" target="#b9">[10]</ref>. Some declarative languages exist for visualization design. For example, Vega <ref type="bibr" target="#b26">[27]</ref> provided a set of fundamental abstractions for constructing visualizations, and Vega-Lite <ref type="bibr" target="#b27">[28]</ref> offered a high-level grammar that enables rapid specification of interactive data visualizations. However, these general declarative languages did not cover all types of visualization designs and could not easily accommodate the requirements in some specific domains.</p><p>In addition, some research has focused on declarative languages for specific domains. Such declarative domain-specific language (DSL) can support different types of data or visualization, such as hierarchical data <ref type="bibr" target="#b13">[14]</ref>, volume data <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b29">30]</ref>, scalable scatterplot <ref type="bibr" target="#b31">[32]</ref>, graph <ref type="bibr" target="#b10">[11]</ref>, unit visualization <ref type="bibr" target="#b21">[22]</ref>, and multiclass density map <ref type="bibr" target="#b11">[12]</ref>.</p><p>In this paper, we proposed a declarative DSL focusing on multiclass contour generation based on the design parameters and their attributes. We followed the approach of Vega, which takes JSON as the format for the DSL.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">ANALYSIS OF DESIGN PARAMETERS IN MULTICLASS CON-</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>TOUR</head><p>Multiclass contour is widely used, including some research works that have already applied multiclass contours in different application scenarios and under different research problems. However, these contours are various in design. The possible design parameters are unclear and lack guidance on making better choices for different use. We want first to propose a generalized framework for multiclass contour, which includes available design parameters. The framework development started with a survey of the literature in the visualization community that has used multiclass contours.</p><p>The papers we reviewed meet the following two criteria: 1) the contours used in a paper need to be multi-categorical so that research on a single contour can be excluded; and 2) the contours must be displayed explicitly and statically to avoid research on dynamic methods like animation. As a result, we obtained 9 papers. We then classified them according to different design parameters, and the taxonomy based on their analysis is shown in Table <ref type="table">1</ref>. Here, we classified these works on three visual parameters: Line Number, Filling, and Mix Method. Line Number refers to whether the contour in each class contains only one line or multiple lines, Filling concerns whether each contour line has filling inside or not, and Mix Method is about how contours in different classes are mixed into one view. For those contours without fillings, we excluded them from the analysis of mix methods because the mix between the lines becomes challenging to distinguish. We identified three mix methods: Overlay, Alpha Blending and Color Blending. For Color Blending, Splatterplots <ref type="bibr" target="#b20">[21]</ref> used an approach that pushed the overlapping areas toward black.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Works</head><p>In addition to the above design parameters, we also found that some researchers considered other encoding methods. Lu et al. <ref type="bibr" target="#b16">[17]</ref> added contour-like strokes to the scatterplots, which can be regarded as discontinuous contour lines. Zhao et al. <ref type="bibr" target="#b36">[37]</ref> used line width to encode distance to the location of the maximum value. Scheepens et al. <ref type="bibr" target="#b28">[29]</ref> distinguished contours with line opacity and halos. Simonetto et al. <ref type="bibr" target="#b30">[31]</ref> used textures, instead of solid colors, in the fillings. These design considerations can all be incorporated into our framework.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">OUR FRAMEWORK OF MULTICLASS CONTOUR VISUALIZA-TION</head><p>Based on the review of works and references of some basic visual channels, we developed a framework for multiclass contour visualization by first summarizing four design parameters and then developing a declarative domain-specific language (DSL) to facilitate the generation of multiclass contours. In this section, we described these two components.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Design Parameters</head><p>Here, we discussed these parameters and related attributes. In the framework, we want the design parameters to be generalized by avoiding specific visual encoding methods and letting designers choose what encoding methods to use. Here we just explained some commonly used encoding approaches.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.1">Line</head><p>The lines are the most visible visual elements in contour visualization and can strongly influence contour representation. This parameter contains several attributes that can be manipulated in design.</p><p>Line Number is one attribute that influences what a contour looks like (Fig. <ref type="figure">1(a)</ref>). As mentioned earlier, existing works used various line numbers in their designs.</p><p>Line Style is inspired by Winglets <ref type="bibr" target="#b16">[17]</ref>, which used different visual representations (e.g., points with wings) to represent equipotential surfaces of point density. Here we suggested that contours can be visualized with different line styles, such as solid or dashed lines (Fig. <ref type="figure">1</ref></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>(b)).</head><p>Line Color is very commonly used to encode information in contour visualizations. In most papers we have surveyed, it is used to distinguish different classes by assigning each class a specific color. Even within the same contour, different lines can have different colors to show the level information.</p><p>Line Width is a basic visual channel of contour and can be used to encode additional information, such as that in PhoenixMap <ref type="bibr" target="#b36">[37]</ref> that encodes the distance from the position of maximum value. For the contour with multiple lines, we can take a similar approach that relates the level with line width: the higher the line level, the wider it is. This approach can make the areas with higher values more visible.</p><p>Line Opacity is another basic visual channel. Scheepens et al. <ref type="bibr" target="#b28">[29]</ref> used different line opacities to highlight different contours. We can also relate opacity with the level, just like Line Width.</p><p>Halo is also used by Scheepens et al. <ref type="bibr" target="#b28">[29]</ref> to distinguish different contours with a good result. Here we follow its approach by adding halos to the lines (Fig. <ref type="figure">1(c)</ref>). Similar to the Line parameter, Halo can have attributes like Halo Color, Halo Width, and Halo Opacity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.2">Fill</head><p>A contour line depicts not only the line itself but also the area it covers. As shown in Table <ref type="table">1</ref>, some research had fillings inside contour lines. So we added Fill to our framework. It is an optional parameter: a contour can have fillings or no filling (Fig. <ref type="figure">1(d)</ref>). Several attributes can be considered in the design if a filling is applied.</p><p>Fill Style is similar to Line Style. Except for common standard colors, textures <ref type="bibr" target="#b30">[31]</ref> and other fill patterns can also be applied to the fillings.</p><p>Fill Color is usually used for distinguishing different classes, just like Line Color. Generally, contour lines in the same class will use the same color. However, a color scheme can also be used to distinguish different contour levels in a specific contour.</p><p>Fill Opacity is similar to Line Opacity, which can be used to indicate level information of contour lines. It can also be used to achieve Alpha Blending, which can be regarded as a stack of multiple contours with different fill opacities.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.3">Order</head><p>When drawing multiclass contours, the Order in which individual contours are rendered is essential. The most common approach is to draw contours by class. However, this method can cause the classes drawn first to be covered underneath and become invisible. In practice, we found that users tend to be more interested in the areas with high values, where the high-level contour lines are located. Thus, we adopted another drawing order: drawing contours by level (Fig. <ref type="figure">1(e)</ref>), in which the lines of the lower levels of all classes are drawn first, and then the lines of the higher levels are rendered in turn. This method will ensure that the higher-level lines will always override the lower-level lines. As a result, the areas with higher values will be more visible.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.4">Mix</head><p>As we have shown in Table <ref type="table">1</ref>, there are some different mixing methods, and they influence the final presentation. Thus, we added Mix to the framework as a design parameter to deal with areas with overlapping contours (Fig. <ref type="figure">1(f</ref>)), where Overlay, Alpha Blending, and Color Blending are all common choices.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">DSL for Multiclass Contour Generation</head><p>The first component of our framework only covers the design parameters and their attributes that can be considered and includes no specific encoding approaches in each parameter. To help the design processes of multiclass contour visualization that involves these parameters, we further developed a declarative domain-specific language (DSL) which provides some common encoding methods to facilitate the quick generation of multiclass contours. A declarative language lets users directly specify visualization contents and attributes without worrying about technical implementation details <ref type="bibr" target="#b9">[10]</ref>.</p><p>Our DSL uses the JSON format to specify the visualization of multiclass contours. Its grammar is shown in Fig. <ref type="figure">2</ref>. A specification first refers to an array of 2D points with class labels as the data input and then provides details on individual parameters. The required parameters include Line, Order, and Mix. Fill is optional, and so is Halo for line rendering.</p><p>We implemented a process with JavaScript to parse a given specification and then render multiclass contours with SVG elements. With the given data points which contain position information, our process first blurs these points into scalar fields by class according to the point density using Kernel Density Estimation (KDE) with a uniform kernel function. Then a Marching Square algorithm, a commonly used method for contour generation <ref type="bibr" target="#b19">[20]</ref>, is applied to create contours for each class. The algorithm receives a list of value thresholds and outputs the contour lines corresponding to each threshold. In this process, different canvas sizes, cell sizes, and blur radii can affect the generation of the scalar field and then further affect the contours generated by the algorithm.</p><p>Here we fix the drawing on a canvas of 256*256, with the cell size of 2 and the blur radius of 8. These parameters will be allowed to be specified in the grammar in future implementations.</p><p>The line number receives an integer as input. It is transformed into a sequence of equivariant thresholds related to the maximum value of all classes. For example, suppose the line number is k. In that case, our process gets the maximum value w within all classes, divides the interval [0, w] into k + 1 equal sub-intervals, and uses k interval values as the thresholds for contour generation. It should be noted that the same threshold list is used in all classes, so those classes that do not reach the maximum value will possibly have fewer contour lines than the given number.</p><p>The process gives two ways of encoding for the attributes with numerical values (Line Width, Line Opacity, Halo Width, Halo Opacity, and Fill Opacity). If the input is a single number, the corresponding attribute of all contour lines will have the same value. If the input is an interval, then the corresponding attribute of the lines in the same contour will take the values in the range defined by the interval. In addition, the attribute of the highest-level line will be set to the maximum value of the interval to highlight the areas with higher values, and the opposite is for the lowest-level line. The values of the other lines are obtained by interpolation. Currently, our process only "level": "normal" | "multiply" | "screen" | "overlay" | "darken" | "lighten" | "color-dodge" | "color-burn" | "hard-light" | "soft-light" | "difference" | "exclusion" | "hue" | "saturation" | "color" | "luminosity", "class": "normal" | "multiply" | "screen" | "overlay" | "darken" | "lighten" | "color-dodge" | "color-burn" | "hard-light" | "soft-light" | "difference" | "exclusion" | "hue" | "saturation" | "color" | "luminosity" } } Fig. <ref type="figure">2</ref>. Grammar of our DSL for multiclass contour generation. We added input specifications to the parameter attributes in the framework. Fill and Halo are two optional parameters.</p><p>supports linear interpolation, and other methods can be implemented as needed.</p><p>Two attributes related to color (Line Color, Fill Color) are mainly used to distinguish different classes, so we need to specify the colors of different classes. Just like the numeric attributes, we want to specify both the same color and different colors for the lines in the same contour. However, color interpolation is challenging, so our DSL grammar only supports the color specification for individual lines. It should be noted that our grammar does not support different halo colors because introducing more colors would make visual clutter worse. Thus, a universal color is set for the halo, while white is one of the most commonly used.</p><p>For the mix methods, as the contours are drawn on SVG, the process uses the mix-blend-mode CSS property to do the mixing. Our grammar supports all values of this CSS property. Two commonly used values are normal and multiply: normal is for overlay and alpha blending, while multiply is similar to what Splatterplots <ref type="bibr" target="#b20">[21]</ref> did. Also, as two different drawing orders are available, our process can distinguish two values: the mix between levels and classes.</p><p>We have mentioned that Fill Style has other choices like textures except for solid colors. However, in practice, we found that textures are indistinguishable from contour lines. Thus, we only support solid colors for the filling style in our DSL.</p><p>Fig. <ref type="figure">3</ref> shows an example of specifying multiclass contour visualization with our DSL and the visualization result generated by our process. The implementation was done upon d3-contour 1 .</p><p>1 https://github.com/d3/d3-contour { "data": "CIFAR10", "line": { "number": 10, "style": "solid", "color": [#4e79a7, #f28e2b, #e15759, #76b7b2, #59a14f, #edc948, #b07aa1, #ff9da7, #9c755f, #bab0ac], "width": [0.56, 1.27], "opacity": [0.59, 0.92], "halo": { "color": #ffffff, "width": [0.83, 1.07], "opacity": [0.69, 0.77] } }, "fill": { "style": "solid", "color": [#4e79a7, #f28e2b, #e15759, #76b7b2, #59a14f, #edc948, #b07aa1, #ff9da7, #9c755f, #bab0ac], "opacity": [0.05, 0.21] }, "order": "level", "mix": { "level": "normal", "class": "normal" } Fig. <ref type="figure">3</ref>. An example of the declarative DSL and the corresponding contour generated by it. Parameter attributes here are set to the default values got from the preliminary study.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">USER STUDY ON DIFFERENT DESIGNS</head><p>With the proposed framework, we next want to know whether different choices of these parameters and their attributes can affect the user's cognitive ability, which can be summarized as guidelines for designing multiclass contours. Using the DSL, we conducted a task-oriented user study to evaluate the effectiveness of different designs by varying the values of some design parameters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Tasks</head><p>We first need to choose representative tasks for the user study, where the validity of different multiclass contour designs can be measured. Massive literature is available to identify relevant tasks used in the visualization-based user study. After reviewing various tasks seen in the literature and examining our needs, we chose four tasks listed below:</p><p>• T1: Finding the place with the highest value of one specific class.</p><p>• T2: Finding multiple value peaks of one specific class.</p><p>• T3: Comparing values of different locations of one specific class.</p><p>• T4: Comparing values of one specific location of different classes.</p><p>In nature, these four tasks have two goals that are articulated by Roth <ref type="bibr" target="#b23">[24]</ref>: Identify and Compare. T1 and T2 fall into the category of Identify, which is about to find objects, while T3 and T4 are in the category of Compare to conduct comparisons. These tasks can also be classified according to their target objects. T1, T2 and T3 are for a specific class, and T4 is for the relationships between different classes. In addition, T2 is inspired by the task of finding clusters among different distribution areas in scatterplots by Sarikaya and Gleicher <ref type="bibr" target="#b25">[26]</ref>, which can be analogous to scalar fields.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Preliminary Study</head><p>The design parameters in the framework for the multiclass contour are too many to be tested for all possible combinations of attribute values, so we had to narrow down the scope of parameters and attributes by choosing a subset that is "important" to users. We conducted a preliminary study to learn which design parameters and attributes are "important" enough to be used in the formal study and what default values should be used for others. We implemented a system for the preliminary study. The system allows participants to freely adjust attribute values and generate the resulting contours in real-time with our DSL. The system's user interface is shown in Fig. <ref type="figure" target="#fig_0">4</ref>. It should be noted that the system does not support color adjustment. Colors of lines and fillings are set to Tableau 10 palettes, with the same color in the same contour. The system also provides the two most common mix methods: normal and multiply.</p><p>The procedure of the preliminary study includes the following steps. We first provided participants with the four tasks mentioned above and let them adjust the attribute values freely, with a goal that the generated contours would be perceived as the best for the provided tasks. Then they need to submit the attribute settings. A participant can submit multiple settings for one task. After completing the adjustments, participants were given a questionnaire on which parameters and attributes they thought would influence the tasks. We used a Likert scale (1 to 5) for each parameter attribute. The questionnaire also includes open-end questions for comments. We recruited 11 participants and obtained 50 combinations of parameter attribute settings from them. We finally selected 3 parameters and attributes for the user study: Line Number, Fill, and Halo. Line Number and Fill got the highest scores in the preliminary study (more than 4) and were regarded as the most "important". We were also interested in Halo because some participants indicated in their comments that halos could help them better distinguish different classes, especially in cases where visual clutter is severe. Thus, we also chose it to test the effectiveness of halos. Some other parameters also got high scores, such as Mix and Order. However, most participants preferred to choose the same value (normal for Mix and level for Order), showing that other value choices would not help users on these tasks, so we did not select them for the user study.</p><p>The default values for other attributes were generated as follows. For numerical intervals, we handled left and right endpoints separately. We first used KDE to smooth the values and then selected the value with the highest density. For other categorical attributes, we used the value that appeared most. Fig. <ref type="figure">3</ref> is the contour drawn based on the obtained default values of all attributes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">User Study</head><p>The study aims to examine the effectiveness of three selected parameters and attributes on four proposed tasks. First, we gave three hypotheses:</p><p>• H1: Variations of individual parameters affect the user's ability to complete the tasks. We need to state whether the changes in individual parameters affected the user's ability on both accuracy and completion time. • H2: There exist interactions between pairs of parameters. This hypothesis is based on our previous finding that filled contours tend to have only one contour line. We want to verify whether this phenomenon occurs due to a coupling between any pairs of parameters.</p><p>• H3: The number of classes in the data can influence users to complete the tasks. As well as the number of classes itself, we also want to verify if it interacts with other design parameters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.1">Data</head><p>We used the CIFAR-10 data set <ref type="bibr" target="#b12">[13]</ref> in the user study. The CIFAR-10 data set consists of 60,000 32x32 color images in 10 classes. We chose this data set because after being projected to a 2D space, each image class has several distribution centers, and there are more crossovers between classes. These features are ideal for our tasks.</p><p>Additionally, as we were interested in the impact of the number of classes on understanding multiclass contour, we further constructed two more data sets by reducing the classes of CIFAR-10 to 3 and 6 by merging some classes. Together with the original one, we had three data sets in total.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.2">Experimental Design</head><p>The study is a within-subjects design with three independent parameters: Line Number, Fill, and Halo. The dependent variables are task accuracy and completion time on the four tasks mentioned early. For Line Number, early research showed a great variety of choices on its value (Table <ref type="table">1</ref>). In this study, we selected four line numbers: 1, 4, 8, and 12. Both Fill and Halo are binary. In our study, contours were rendered with or without fillings and halos in different treatments. For other attributes, we gave them a fixed value as we got in the preliminary study.</p><p>In total, we had 16 treatment combinations (4 x 2 x 2). All participants were asked to complete 4 tasks under these 16 treatments, so each participant should do 64 trials. Although we used 3 data sets in our study, we did not fully combine them with treatments because a complete combination of data sets and treatments would result in 192 trials, which were burdensome to participants. Instead, we chose a data set for each trial in a random manner. This approach ensured that all data sets and treatment levels could be balanced.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.3">Participants and Apparatus</head><p>We recruited 17 participants. They all had knowledge of visualization but less knowledge of contour. None of them were involved in the preliminary study.</p><p>The study used a web-based system shown in Fig. <ref type="figure" target="#fig_1">5</ref>. The resolution of the screen in the study was 3,840 x 2,160 and all contours were scaled to fit the screen size. To reduce the operational burden of participants, they only needed to complete simple operations such as clicking and dragging in the system. The system then calculated the scores according to their operations and the task completion time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.4">Procedure</head><p>First, participants were briefed about the study and provided basic information about contour, common features of the contours used in the subsequent study, and details of the four tasks. Then, they were given eight warm-up tasks for exercise, including two rounds of four tasks. In the first round, we gave hints that helped users understand how to complete the four tasks. In the second round, we let the users operate independently and got familiar with the whole process. The results of these warm-up assignments were not recorded.</p><p>After the exercise, participants completed the tasks based on the prompt on the screen. The procedures of the four tasks are given below:</p><p>• T1: Participants were given a class and asked to click on the location with the highest value of that class. The score is the value at the clicked point compared to the highest value of the given class.</p><p>• T2: Participants were given a class and the number of peaks in that class. They were asked to click on the corresponding positions of the peaks. The score is the percentage of peaks that have clicked points inside. It has to be mentioned that the peaks were gotten from the contours, and different numbers of lines may cause different peaks.</p><p>• T3: Participants were given a class and three random positions on the contour and asked to drag the corresponding icons between the contour and the question to sort them according to the values on these three positions of the given class. Scores are calculated by the percentage of correct alignments.</p><p>• T4: Participants were given at most three classes and one position and asked to drag the corresponding icons to sort according to the values of the given classes on the given point. The classes were selected randomly. To avoid a large gap between the values of the three classes, we randomly generated 10 locations and selected the position with the highest minimum value. The score calculation method is the same as T3.</p><p>In addition, we randomly assigned colors to different classes in each trial to reduce the carryover effect.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">RESULTS</head><p>We analyzed the user study results, verified the validity of the proposed hypotheses, and summarized the design guidelines for contours based on the analysis results. Classes were analyzed together with the other three design parameters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Analysis of Individual Parameters</head><p>We analyzed how the changes of one single parameter affect users' ability on different tasks. Fig. <ref type="figure" target="#fig_3">6</ref> shows the results with the distribution of scores and time on different parameters and tasks. As shown in the figure, user performances varied with different values of the parameters.</p><p>We used one-way ANOVA to verify whether there exists significant differences in user performances in Line Number and Classes, which have more than two choices, and t-test for Fill and Halo. For T1, as shown in Fig. <ref type="figure" target="#fig_3">6</ref>, the accuracy under the value of 1 is significantly lower than those under 4, 8, and 12. This result suggests that using more lines helps identify the highest data values. However, even though there are no significant differences between using 4, 8, or 12 lines, an interesting observation is that the accuracy scores of using 8 lines are slightly higher than those of using 3 and 12 lines. A reasonable interpretation of this is that using 8 lines presents more details of the data distribution than using 4 lines, just as what using 12 lines is able to achieve, but induces less visual clutters than using 12 lines. It also implied that an optimal choice of line number should be able to both convey sufficient information and reduce visual complexity, while 8 lines may be a compromise option.</p><p>For T2, we can see that task accuracy drop rapidly as the line number increases when it is fewer than 8, but the accuracy under the value of 12 is nearly the same as that under 8. However, Tukey's HSD showed that the difference between them is marginally between parameter values in T2 but gets an edge value between 1 and 8 (95% CI = [-.00174, .195], p = .0563). It indicated that the sensitivity of this task to line numbers is low but might also lead to a conclusion that presenting more information by more lines prevents users from accurately identifying multiple peaks of the data distribution to a certain extent.</p><p>Line number has obvious influence on the completion time in T2 (F(3, 268) = 5.25, p = .00156) and T3 (F(3, 268) = 3.23, p = .0229). In T2, we found that the average time under the value of 8 is much higher than 1 (95% CI = [1.58, 11.7], p = .00439) and 4 (95% CI = [1.63, 11.7], p = .00401). It is unclear how this could happen.</p><p>For T3, we found that the time cost increases as the number of lines increases. The results from Tukey's HSD also showed that the difference between the values of 1 and 12 is significant (95% CI = [.809, 11.6], p = 0.0169). It confirmed that more lines increase the burden on the users to make the comparison for a particular class.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1.2">Fill</head><p>As shown in Fig. <ref type="figure" target="#fig_3">6</ref>, the accuracy scores with fillings are lower than those without in T2 and T3. Results from t-test confirmed this finding (t(270) = 2.33, p = .0207 and t(270) = 2.03, p = .0434, respectively). It can be explained that fillings make it more difficult for users to distinguish a particular class as the colors of different contours are mixed. For the completion time, the results from the quantitative analysis did not show a significant difference.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1.3">Halo</head><p>To our surprise, Halo does not significantly influence the four tasks. Both the average scores and time are almost the same. It implied that the presence or absence of a halo does not affect these tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1.4">Classes</head><p>For task accuracy, we can generally see that in T2 and T3, user performances with the 10-classes data set are worse than in the other two data sets. Results of ANOVA confirmed this observation, with F(2, 269) = 5.90, p = .00311 for T2 and F(2, 269) = 3.07, p = .0482 for T3. Post-hoc analysis indicated that in T2, accuracy performance with the 10-class data set is significantly worse than that with the 3class data set (95% CI = [.0271, .181], p = .00454), as well as that with the 6-class data set (95% CI = [.00974, 0.164], p = .0228). For T3, however, the post-hoc analysis did not show any pairwise difference, indicating the low sensitivity of this task to the number of classes.</p><p>As for the time users spent on the tasks, we found in T2 that the average completion time on the data set with the data of 10 classes is much higher than those with the other two data sets. The post-hoc analysis confirmed the difference is significant, with 95% CI = [4.04, 11.7] for 3 classes and [4.80, 12.5] for 6 classes. All p-values are less than .001.</p><p>The above findings stated that more classes in the data set could negatively influence user performances for searching value peaks of a particular class. The more classes there are, the more difficult it is for users to distinguish one specific class. Especially when there are more than 10 classes, user ability will significantly decrease. Thus, designers need to be more careful using contour or try other visualization methods when dealing with data with many classes.</p><p>In general, H1 was confirmed to some extent. Except for the Halo parameter, different choices of Line Number and Fill can influence user performances. The same is true for data with a different number of classes, which means that H3 was also confirmed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Interaction Analysis of Pairs of Parameters</head><p>We further analyzed the interactions of pairs of parameters on user performances by using two-way ANOVA. However, in the user study, we did not make a complete combination of classes in data sets and other parameters for one user, which made the results unbalanced. It is not suitable to directly apply two-way ANOVA. To address this issue, we used Type III ANOVA to analyze unbalanced data without the order of specifications. Unfortunately, we did not find any significant interaction between Line Number and Fill, which is not what we expected. However, the interactions between Line Number and Classes are significant in scores on T1 and T4, and time on T2. The results are shown in Fig. <ref type="figure" target="#fig_4">7</ref>. For T1, Line Number and Classes have significant interactions on score (F(6, 260) = 5.26, p &lt; .001). Fig. <ref type="figure" target="#fig_4">7</ref> shows that the average score of the combination of the values of 1 line and 3 classes is low, a rather strange phenomenon that cannot be reasonably explained. We then checked the look of the contour with this parameter setting. We can see that the distribution of each class in this data is sparse, as shown in Fig. <ref type="figure" target="#fig_5">8(a)</ref>. It made the completion of T1, finding the highest value, more complex, especially when using 1 line. So we assumed that the use of fewer lines in the case of a more dispersed distribution would negatively influence the search for the maximum value.</p><p>A similar situation is seen in the completion time on T2 (F(6, 260) = 3.37, p = .00323). As shown in Fig. <ref type="figure" target="#fig_4">7</ref>, the combination of 3 classes and 1 line again showed an exceptional value. We then found that one of the classes have two peaks so close in this case (Fig. <ref type="figure" target="#fig_5">8(a)</ref>). It made participants treat them as one peak and thus spend more time looking for another peak that does not exist. Some participants also had the same feedback during the experiment. Moreover, this is not the case with 4 lines and more. So we attributed this to the characteristics of the data itself rather than a general nature.</p><p>For the accuracy score on T2 (F(6, 260) = 2.18, p = .0452), Fig. <ref type="figure" target="#fig_4">7</ref> shows that when the number of lines increases from 1 to 4, there is a significant decrease in the score of the 10-class data. This phenomenon suggested that finding peaks is more sensitive to the number of lines in data with more classes. It can be explained that more data classes and more line numbers result in more visual clutter.</p><p>For the score on T4 (F(6, 260) = 2.18, p = .0450), We can see in Fig. <ref type="figure" target="#fig_4">7</ref> that, unlike the other data, the accuracy rate decreases as the number of lines rises in the data of 6 classes, which is also a strange phenomenon. After checking the data, we found that in the data of 6 classes, there is no heavy crossover between different classes (Fig. <ref type="figure" target="#fig_5">8(b)</ref>), which means that a few contour lines are enough to make the comparison between classes. Moreover, with the increase of lines, it will instead lead to visual clutters and affect the user's judgment. It is the opposite when the crossover between classes is heavy, just like the data with 3 (Fig. <ref type="figure" target="#fig_5">8(a)</ref>) and 10 classes (Fig. <ref type="figure" target="#fig_5">8(c)</ref>). This result told us that if the crossover between classes is not very serious, a few contour lines are more appropriate for comparing different classes. As the results showed, H2 was rejected, while H3 can be somewhat confirmed. There exist interactions between Line Number and Classes on the score of T2. Besides, we also found some valuable findings for further guidance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Insights</head><p>Finally, according to the previous result analysis, we gave the following general conclusions:</p><p>• Fewer contour lines do better in finding value distribution peaks, especially for data sets with more classes. They are also suitable for comparing values within one class and between different classes when the intersection is not severe. However, too few contour lines are bad for finding the highest values, especially when the value distribution is sparse, while the choice of 8 lines perhaps has the best performance. They are also inappropriate for multiclass comparison when heavy crossover exists between classes.</p><p>• Fillings can negatively influence finding peaks and comparing within one class because of the overlapping of colors.</p><p>• More classes in data can negatively affect the task of finding peaks, and the limitation may be around 10.</p><p>These findings can serve as guidance for further use. For example, suppose the goal of using multiclass contour is to show the overall distributions and roughly show some peaks. In that case, it is better to draw fewer lines, while in contrast, finding extreme values is better to use more contour lines without fillings. For comparison-related tasks, if comparisons are within a class, few contour lines with no fillings work better. If comparisons are between classes and the crossover is heavy, adding more contour lines can help. If the data has more than 10 classes, the multiclass contour may not be a suitable visualization method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">APPLICATION</head><p>In this section, we used the guidance to illustrate how it helps generate better contours for analyzing a real-life data set. The data set we used here contains NSF (Nation Science Foundation) projects. NSF supports fundamental research and education in science and engineering, and the projects funded by it are representative of advanced research. As time goes by, the directions of advanced research can change, which allows us to analyze the research directions changes.</p><p>Here we used contour to show the changes. We used projects in 2000, 2010, and 2020, and then explored how the research directions vary in these years. Each project has a title to describe its research. We first used BERT <ref type="bibr" target="#b7">[8]</ref> to embed each title into a 768-dimensional vector to represent the semantics. In this high-dimensional space, the semantics of the titles represented by the two close vectors are similar, implying that the two projects are close in the research direction. We then projected these vectors onto a 2D space with t-SNE <ref type="bibr" target="#b32">[33]</ref> and used our DSL to show the distributions.</p><p>Specific analysis goals are also needed to set appropriate attribute values. Through the contours, we want to get: 1) peaks of the distributions in 3 years, which may show the possible research directions; and 2) areas where extreme value points are possibly located, which may show the most popular direction. According to our insights from the user study, a small line number performs well on finding peaks. However, too few lines are bad for finding extreme values. To weigh these two factors, we then set the line number to 4. For fillings that are bad at finding peaks, we decided not to use them. For the halo, as we found no evident impact of it on the tasks, we chose to use it as a preference. As a result, we obtained the multiclass contour, as shown in Fig. <ref type="figure" target="#fig_6">9</ref>.</p><p>In the figure, we can easily see the peaks, representing the research directions, move towards the right as time passed. This plot provides a very intuitive representation of the general development of research over the past 20 years. More detailed, we boxed the areas where the extreme values most probably appear in 3 years, representing the most popular directions. For 2020, we drew two boxes, as we thought these two areas might have similar research popularity.</p><p>By adding more semantics information to the contour visualization, we can know precisely the contents of the research in these areas. We placed keywords from the titles on the contours according to the location of the relevant projects. The keywords in the boxed areas may give some interpretations to the semantics. For 2000, the box contains keywords like machine, system, and structure, which may relate to research on traditional engineering. For 2010, the box contains keywords like plant, molecular, and experiment, indicating that research in life science may be the most popular around 2010. For 2020, each of the two boxes represents one possible hottest direction. One of the boxes has keywords like network, system, and data that are more likely to be relevant to computer science. The keyword covid-19 appears in another box, demonstrating that the research on the COVID-19 pandemic was also popular.</p><p>In the above example, we showed how to apply our guidelines to the design of a multiclass contour for specific tasks, which let the analysts get findings more easily.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">DISCUSSION</head><p>This section discussed this work's scalability and limitations and provided some further research directions.</p><p>First, the proposed framework was developed by summarizing existing techniques in the field of multiclass contour visualization and was further investigated via a user study. The proposed framework and design guidance will help designers give better designs for specific tasks to a certain extent, especially for more and more inexperienced users, as the threshold of visualization creation is decreasing. These guidelines will also bring help to the possible future automated generation of multiclass contours. Our proposed framework and related research methods can be further applied to other methods in the scalar field, such as heatmaps <ref type="bibr" target="#b6">[7]</ref> and dots <ref type="bibr" target="#b33">[34]</ref>, or even other common visualization methods that are not very relevant. However, applying it to scenarios involving more complex tasks or data may face some challenges. Thus, more efforts are needed to enhance the framework, such as enriching the design parameters or testing it with data from more domains. At the same time, the proposed declarative DSL also needs to be further extended by supporting more visual coding channels and user interaction types. Second, in this work, our user study only examined three design parameters and attributes, and more research is needed to evaluate user performances under other parameters. Contour visualization can be used in different domains, and each domain may have its traditions and styles in visualization designs. In addition, user tasks related to multiclass contour can be diverse, way beyond those we used in our experiment, and the sensitivities of different tasks to these parameters may vary. Thus, it is necessary to investigate the effectiveness of all essential parameters on diverse tasks and their interaction effects in design. More user studies are needed, and the details of the experiment also need more thought.</p><p>Last but not least, from the application in a real-world data set, we have observed design conflicts when picking attribute values. A specific rendering configuration that enhances one task may lead to negative effects on completing another one. Such conflicts would be more evident and severe when the complexity of the tasks increased. It suggests that even a carefully constructed framework may have some limitations in guiding practical applications; there is no panacea for addressing every type of task. Thus, a fine-grained design summary oriented by task type in practice is worth thinking about.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9">CONCLUSION AND FUTURE WORK</head><p>This paper aimed to provide task-oriented guidance for the design of multiclass contour visualization. To this end, we developed a framework for multiclass contour visualization by first reviewing and summarizing existing technologies and then developing a declarative DSL for fast implementation of multiclass contour visualization. Based on the framework, a task-oriented user study was conducted to demonstrate how different choices of parameters and their attributes in the framework affect user performances in different analysis tasks. The results provided valuable guidance for choosing attribute values for constructing multiclass contour visualization. Finally, we showed how the guidance could enhance real-world analysis tasks by giving an example of NSF project data.</p><p>We will extend the framework for future work by considering more design parameters and user interaction activities and testing it with data from broader application domains. The DSL can also be further improved to support the extension of the design parameters. More experimental studies are also needed to validate other design parameters and deepen the understanding of the interaction among various design parameters. Finally, we will also make efforts to develop more comprehensive design guidelines based on the framework, including more detailed user studies and summaries.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 4 .</head><label>4</label><figDesc>Fig.4. The user interface of the system used in the preliminary study. A task is presented on the top, the interactive panel below is used to adjust the values of parameter attributes, and the contour on the right is generated based on selected attribute values. Clicking the submit button to finalize a choice on the setting. Multiple settings for one task are also allowed.</figDesc><graphic url="image-14.png" coords="5,64.26,203.03,230.92,160.58" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. The user user study. Participants received a task promptly, completed the task by clicking on the contour or dragging the icon above, and then clicked the submit button for task completion. The system then moves to the next task automatically.</figDesc><graphic url="image-15.png" coords="5,322.13,203.60,107.69,130.62" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>6. 1 . 1</head><label>11</label><figDesc>Fig. 6 shows that different choices of Line Number affect task accuracy scores and completion time. For accuracy, ANOVA showed a significant difference among four choices on T1 (F(3, 268) = 19.6, p &lt; .001) and T2 (F(3, 268) = 2.75, p = .0434). Post-hoc analysis (Tukey's HSD) indicated that for T1, significant differences exist between the value of 1 and 4 (95% CI = [.0764, .198]), 8 (95% CI = [.0995, .221]), and 12 (95% CI = [.0800, .203]). All these values are with p &lt; .001.For T1, as shown in Fig.6, the accuracy under the value of 1 is significantly lower than those under 4, 8, and 12. This result suggests that using more lines helps identify the highest data values. However, even though there are no significant differences between using 4, 8, or 12 lines, an interesting observation is that the accuracy scores of using 8 lines are slightly higher than those of using 3 and 12 lines. A reasonable interpretation of this is that using 8 lines presents more details of the data distribution than using 4 lines, just as what using 12 lines is able to achieve, but induces less visual clutters than using 12 lines. It also implied that an optimal choice of line number should be able to both convey sufficient information and reduce visual complexity, while 8 lines may be a compromise option.For T2, we can see that task accuracy drop rapidly as the line number increases when it is fewer than 8, but the accuracy under the value of 12 is nearly the same as that under 8. However, Tukey's HSD showed that the difference between them is marginally between parameter values in T2 but gets an edge value between 1 and 8 (95% CI = [-.00174, .195], p = .0563). It indicated that the sensitivity of this task to line numbers is low but might also lead to a conclusion that presenting more information by more lines prevents users from accurately identifying multiple peaks of the data distribution to a certain extent.Line number has obvious influence on the completion time in T2 (F(3, 268) = 5.25, p = .00156) and T3 (F(3, 268) = 3.23, p = .0229). In T2, we found that the average time under the value of 8 is much higher than 1 (95% CI =[1.58, 11.7], p = .00439) and 4 (95% CI =[1.63, 11.7], p = .00401). It is unclear how this could happen.For T3, we found that the time cost increases as the number of lines increases. The results from Tukey's HSD also showed that the difference between the values of 1 and 12 is significant (95% CI = [.809, 11.6], p = 0.0169). It confirmed that more lines increase the burden on the users to make the comparison for a particular class.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 6 .</head><label>6</label><figDesc>Fig. 6. Score and time distributions of different parameters on different tasks, from statistics of the user study.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 7 .</head><label>7</label><figDesc>Fig. 7. Results by using contours with different line number choices on different data.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 8 .</head><label>8</label><figDesc>Fig. 8. Contours with 1 line on the data with 3 classes (a), 6 classes (b), and 10 classes (c). For (a), the distributions are sparse, together with two closely-connected peaks for the blue one, making the accuracy score of both T1 and T2 relatively low. For (b), the crossover between classes is not severe, which makes a single line already sufficient for comparison between classes.</figDesc><graphic url="image-19.png" coords="8,64.57,284.53,77.21,77.10" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 9 .</head><label>9</label><figDesc>Fig. 9. An example of applying multiclass contour generated by our DSL and guidance into real-life data set. According to the semantics, we projected NSF projects in 2000, 2010, and 2020 into a 2D space. Contours in three years are shown on the left, each with an independent value threshold, while we used the same threshold in the middle multiclass contour. Additional keywords can provide more information on detailed semantics.</figDesc><graphic url="image-26.png" coords="9,454.58,292.35,82.83,65.39" type="bitmap" /></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS</head><p>The authors thank the participants for attending the user study and the anonymous reviewers for their valuable comments. This work was supported by NSFC No. 61872013.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Anderson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wendt</surname></persName>
		</author>
		<title level="m">Computational fluid dynamics</title>
				<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1995">1995</date>
			<biblScope unit="volume">206</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Numerical weather map analysis</title>
		<author>
			<persName><forename type="first">P</forename><surname>Bergthörsson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">R</forename><surname>Döös</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Tellus</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="329" to="340" />
			<date type="published" when="1955">1955</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">FacetAtlas: Multifaceted visualization for rich text corpora</title>
		<author>
			<persName><forename type="first">N</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">R</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Gotz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Qu</surname></persName>
		</author>
		<idno type="DOI">10.1109/TVCG.2010.154</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1172" to="1181" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Structurebased suggestive exploration: A new approach for effective exploration of large networks</title>
		<author>
			<persName><forename type="first">W</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="DOI">10.1109/TVCG.2018.2865139</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="555" to="565" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Vivaldi: A domain-specific language for volume processing and visualization on distributed heterogeneous systems</title>
		<author>
			<persName><forename type="first">H</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">M</forename><surname>Quan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">G</forename><surname>Hildebrand</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Pfister</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">K</forename><surname>Jeong</surname></persName>
		</author>
		<idno type="DOI">10.1109/TVCG.2014.2346322</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2407" to="2416" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Bubble sets: Revealing set relations with isocontours over existing visualizations</title>
		<author>
			<persName><forename type="first">C</forename><surname>Collins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Penn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Carpendale</surname></persName>
		</author>
		<idno type="DOI">10.1109/TVCG.2009.122</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="929" to="936" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Visualization of uncertain scalar data fields using color scales and perceptually adapted noise</title>
		<author>
			<persName><forename type="first">A</forename><surname>Coninx</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Bonneau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Droulez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Thibault</surname></persName>
		</author>
		<idno type="DOI">10.1145/2077451.2077462</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 8th Symposium on Applied Perception in Graphics and Visualization, APGV 2011</title>
				<meeting>the 8th Symposium on Applied Perception in Graphics and Visualization, APGV 2011<address><addrLine>Toulouse, France</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2011">August 27-28, 2011. 2011</date>
			<biblScope unit="page" from="59" to="66" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">BERT: Pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the North American Chapter</title>
				<meeting>the 2019 Conference of the North American Chapter</meeting>
		<imprint>
			<publisher>Human Language Technologies</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="4171" to="4186" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Attention and visual memory in visualization and computer graphics</title>
		<author>
			<persName><forename type="first">C</forename><surname>Healey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Enns</surname></persName>
		</author>
		<idno type="DOI">10.1109/TVCG.2011.127</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1170" to="1188" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Declarative language design for interactive visualization</title>
		<author>
			<persName><forename type="first">J</forename><surname>Heer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bostock</surname></persName>
		</author>
		<idno type="DOI">10.1109/TVCG.2010.144</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1149" to="1156" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">SetCoLa: High-level constraints for graph layout</title>
		<author>
			<persName><forename type="first">J</forename><surname>Hoffswell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Borning</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Heer</surname></persName>
		</author>
		<idno type="DOI">10.1111/cgf.13440</idno>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics Forum</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="537" to="548" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">A declarative rendering model for multiclass density maps</title>
		<author>
			<persName><forename type="first">J</forename><surname>Jo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Vernier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Dragicevic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Fekete</surname></persName>
		</author>
		<idno type="DOI">10.1109/TVCG.2018.2865141</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="470" to="480" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Learning multiple layers of features from tiny images</title>
		<author>
			<persName><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
		<respStmt>
			<orgName>University of Toronto</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">GoTree: A grammar of tree visualizations</title>
		<author>
			<persName><forename type="first">G</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Mcguffin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Yuan</surname></persName>
		</author>
		<idno type="DOI">10.1145/3313831.3376297</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Human Factors in Computing Systems</title>
				<meeting>the International Conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="1" to="13" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Galex: Exploring the evolution and intersection of disciplines</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="DOI">10.1109/TVCG.2019.2934667</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1182" to="1192" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">ContexTour: Contextual contour visual analysis on dynamic multi-relational clustering</title>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">R</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<idno type="DOI">10.1137/1.9781611972801.37</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th SIAM International Conference on Data Mining, SDM 2010</title>
				<meeting>the 10th SIAM International Conference on Data Mining, SDM 2010</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="418" to="429" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Winglets: Visualizing association with uncertainty in multi-class scatterplots</title>
		<author>
			<persName><forename type="first">M</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lanir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Fish</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Cohen-Or</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Huang</surname></persName>
		</author>
		<idno type="DOI">10.1109/TVCG.2019.2934811</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="770" to="779" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">A visual analytics approach to understanding spatiotemporal hotspots</title>
		<author>
			<persName><forename type="first">R</forename><surname>Maciejewski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Rudolph</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Hafen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Abusalah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Yakout</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ouzzani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">S</forename><surname>Cleveland</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Grannis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">S</forename><surname>Ebert</surname></persName>
		</author>
		<idno type="DOI">10.1109/TVCG.2009.100</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="205" to="220" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Clusterplot: High-dimensional cluster visualization</title>
		<author>
			<persName><forename type="first">O</forename><surname>Malkai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Cohen-Or</surname></persName>
		</author>
		<idno>CoRR, abs/2103.02992</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Geometric design and space planning using the marching squares and marching cube algorithms</title>
		<author>
			<persName><forename type="first">C</forename><surname>Maple</surname></persName>
		</author>
		<idno type="DOI">10.1109/GMAG.2003.1219671</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2003 International Conference on Geometric Modeling and Graphics</title>
				<meeting>the 2003 International Conference on Geometric Modeling and Graphics</meeting>
		<imprint>
			<date type="published" when="2003">2003. 2003</date>
			<biblScope unit="page" from="90" to="95" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Splatterplots: Overcoming overdraw in scatter plots</title>
		<author>
			<persName><forename type="first">A</forename><surname>Mayorga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gleicher</surname></persName>
		</author>
		<idno type="DOI">10.1109/TVCG.2013.65</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1526" to="1538" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Atom: A grammar for unit visualizations</title>
		<author>
			<persName><forename type="first">D</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Drucker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Fernandez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Elmqvist</surname></persName>
		</author>
		<idno type="DOI">10.1109/TVCG.2017.2785807</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="3032" to="3043" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Untangling euler diagrams</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">H</forename><surname>Riche</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Dwyer</surname></persName>
		</author>
		<idno type="DOI">10.1109/TVCG.2010.210</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1090" to="1099" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">An empirically-derived taxonomy of interaction primitives for interactive cartography and geovisualization</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">E</forename><surname>Roth</surname></persName>
		</author>
		<idno type="DOI">10.1109/TVCG.2013.130</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2356" to="2365" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">An overview of gradient descent optimization algorithms</title>
		<author>
			<persName><forename type="first">S</forename><surname>Ruder</surname></persName>
		</author>
		<idno>CoRR, abs/1609.04747</idno>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Scatterplots: Tasks, data, and designs</title>
		<author>
			<persName><forename type="first">A</forename><surname>Sarikaya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Member</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gleicher</surname></persName>
		</author>
		<idno type="DOI">10.1109/TVCG.2017.2744184</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="402" to="412" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Lyra: An interactive visualization design environment</title>
		<author>
			<persName><forename type="first">A</forename><surname>Satyanarayan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Heer</surname></persName>
		</author>
		<idno type="DOI">10.1111/cgf.12391</idno>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics Forum</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="351" to="360" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Vega-Lite: A grammar of interactive graphics</title>
		<author>
			<persName><forename type="first">A</forename><surname>Satyanarayan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Moritz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Wongsuphasawat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Heer</surname></persName>
		</author>
		<idno type="DOI">10.1109/TVCG.2016.2599030</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="341" to="350" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Contour based visualization of vessel movement predictions</title>
		<author>
			<persName><forename type="first">R</forename><surname>Scheepens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Van De Wetering</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Van Wijk</surname></persName>
		</author>
		<idno type="DOI">10.1080/13658816.2013.868466</idno>
	</analytic>
	<monogr>
		<title level="j">International Journal of Geographical Information Science</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="891" to="909" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">A declarative grammar of flexible volume visualization pipelines</title>
		<author>
			<persName><forename type="first">M</forename><surname>Shih</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Rozhon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">L</forename><surname>Ma</surname></persName>
		</author>
		<idno type="DOI">10.1109/TVCG.2018.2864841</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1050" to="1059" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Fully automatic visualisation of overlapping sets</title>
		<author>
			<persName><forename type="first">P</forename><surname>Simonetto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Auber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Archambault</surname></persName>
		</author>
		<idno type="DOI">10.1111/j.1467-8659.2009.01452.x</idno>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics Forum</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="967" to="974" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Kyrix-S: Authoring scalable scatterplot visualizations of big data</title>
		<author>
			<persName><forename type="first">W</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Battle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Stonebraker</surname></persName>
		</author>
		<idno type="DOI">10.1109/TVCG.2020.3030372</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="401" to="411" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Visualizing data using t-SNE</title>
		<author>
			<persName><forename type="first">L</forename><surname>Van Der Maaten</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2579" to="2605" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Quantitative texton sequences for legible bivariate maps</title>
		<author>
			<persName><forename type="first">C</forename><surname>Ware</surname></persName>
		</author>
		<idno type="DOI">10.1109/TVCG.2009.175</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1523" to="1530" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Contour boxplots: A method for characterizing uncertainty in feature sets from simulation ensembles</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">T</forename><surname>Whitaker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mirzargar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Kirby</surname></persName>
		</author>
		<idno type="DOI">10.1109/TVCG.2013.143</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2713" to="2722" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Evaluation of sampling methods for scatterplots</title>
		<author>
			<persName><forename type="first">J</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<idno type="DOI">10.1109/TVCG.2020.3030432</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1720" to="1730" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Phoenixmap: An abstract approach to visualize 2d spatial distributions</title>
		<author>
			<persName><forename type="first">J</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><forename type="middle">C</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">V</forename><surname>Chen</surname></persName>
		</author>
		<idno type="DOI">10.1109/TVCG.2019.2945960</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="2000">2000-2014, 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Interactive levelof-detail rendering of large graphs</title>
		<author>
			<persName><forename type="first">M</forename><surname>Zinsmaier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Brandes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Deussen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Strobelt</surname></persName>
		</author>
		<idno type="DOI">10.1109/TVCG.2012.238</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2486" to="2495" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
