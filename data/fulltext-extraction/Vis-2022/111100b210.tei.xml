<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">FlowNL: Asking the Flow Data in Natural Languages</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Jieying</forename><surname>Huang</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Yang</forename><surname>Xi</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Junnan</forename><surname>Hu</surname></persName>
						</author>
						<author>
							<persName><roleName>Member, IEEE</roleName><forename type="first">Jun</forename><surname>Tao</surname></persName>
						</author>
						<title level="a" type="main">FlowNL: Asking the Flow Data in Natural Languages</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.2" ident="GROBID" when="2023-03-27T09:17+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Flow visualization</term>
					<term>natural language interface</term>
					<term>interactive exploration</term>
					<term>declarative grammar</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Fig. 1. The interface of FLowNL. (a) shows the query input box. (b) shows the dialog box to resolve unknown terms. (c) shows the query formula of a derived object. (d) shows primitive objects and their respective derived objects. The displayed object are indicated by small squares. (e) shows the suggested queries below the input box. (f) shows the streamlet visualization corresponding to three objects "tiny spiral flow", "spiral flow", and "upward flow".</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Flow visualization has been a central topic in scientific visualization for decades. The key to a successful flow visualization is to convey the information regarding flow structures of interest in the desired way. However, the definitions of "structures of interest" and the "desired way" often vary across domains, applications, or even experts' pref-Jieying Huang, Yang Xi, and Junnan Hu are with the School of Computer Science and Engineering, Sun Yat-sen University. E-mail: {huangjy85,yangxi3,hujn3}@mail2.sysu.edu.cn. Jun Tao is with the School of Computer Science and Engineering, Sun Yat-sen University, National Supercomputer Center in Guangzhou, and Southern Marine Science and Engineering Guangdong Laboratory (Zhuhai). Email: taoj23@mail.sysu.edu.cn. He is the corresponding author. erence. The early approaches often place or select streamlines using fixed application-agnostic criteria, such as evenly-spacing between streamlines <ref type="bibr" target="#b17">[18]</ref> and maximal information conveyed <ref type="bibr" target="#b55">[56]</ref>. Other approaches target fixed types of features, such as saddles <ref type="bibr" target="#b48">[49]</ref>, critical points <ref type="bibr" target="#b34">[35,</ref><ref type="bibr" target="#b57">58]</ref>, vortices <ref type="bibr" target="#b37">[38]</ref>. These approaches are usually developed based on visualization experts' understanding of data or based on the communication between domain experts and visualization experts to determine what is desired. However, the approaches using fixed criteria may not meet the need of specific domains and applications, while the approaches targeting fixed types of features may not extend to other types of features or require significant development effort to do so.</p><p>The exploratory techniques emerge to customize the visualization for different features or applications. These approaches allow users to specify the streamlines related to the features of interest through graph-based interface <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b45">46]</ref>, pattern query <ref type="bibr" target="#b50">[51]</ref>, predicates <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b38">39]</ref>, and tangible interface <ref type="bibr" target="#b16">[17]</ref>. Among these approaches, the graphical interface is most commonly used. However, although flexible, powerful graphical interfaces often require steep learning curves and significant comprehension effort. The tangible interface provides physical feedback for experts to interact with their data in a more intuitive manner. But due to the limited degree-of-freedom in the tangible interface interaction, it could be difficult to support sophisticated queries.</p><p>Inspired by recent advancements in natural language interface (NLI) for visualizing and exploring tabular data <ref type="bibr" target="#b26">[27,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b43">44,</ref><ref type="bibr" target="#b58">59]</ref>, we propose FlowNL, a natural language interface for flow visualization, aiming to support various types of analysis tasks and reduce the learning and usage effort at the same time. FlowNL features a flexible scheme to query flow structures and explore the structures and their connections through a dialogue mechanism. Specifically, it supports the derivation of flow structures from the basic types of objects, named primitives. The primitive objects include the vector field, sampled streamlines, associated scalar fields, and other unstructured data points (e.g., critical points and geographic regions). FlowNL provides a series of simple operations to filter and combine the simple objects to derive more complicated ones. For example, the atmospherical phenomenon "typhoon" can be derived by combining "spirals" from filtering streamlines, "strong wind" from filtering the scalar field of velocity magnitude, and "in the west Pacific Ocean" from filtering the geographic locations. To derive new objects in natural interactions, FlowNL provides a dialogue mechanism. This allows users to define flow structures during a conversation, instead of defining all structures before a query. The defined flow structures are then visualized by an efficient streamlet visualization engine in an animated manner. Additionally, FlowNL supports the analysis of connections among the flow structures using a set of neighborhood operations. These operations extend the existing objects along the flow, which provides a Lagrangian view of the flow field.</p><p>Architecture. FlowNL is realized through three major components: a natural language parser, a declarative language for flow visualization, and a visualization engine. The natural language parser takes the natural language queries as input and translates the queries into specifications in the declarative language. The declarative language serves as an intermediate layer between the natural language and the flow visualization engine. It specifies how the objects should be combined to derive a new one, and how the objects should be visualized. The visualization engine performs the actual computation to derive objects and use them to guide the placement and removal of particles.</p><p>Contribution. Our contribution can be summarized as follows:</p><p>• We propose FlowNL, a natural language interface that translates the natural language queries to flow visualization results. Using the natural languages as queries is intuitive and greatly reduces the learning and usage effort. • We design a declarative language that flexibly filters and combine the primitive objects (e.g., fields, streamlines, and features) to define structures of interest. The declarative language also specifies the connections among structure allowing the Lagrangian behaviors to be observed. • We design an interface integrating the dialog box for natural language queries and the flow visualization. It also allows users to view and adjust the visualization styles of objects.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK</head><p>Interactive flow visualization. Interactive techniques assist the visual exploration of flow data and customization of visualization results, providing the flexibility to handle different tasks. Several techniques are built on the graph representation to select streamlines or other flow structures, such as the flow web <ref type="bibr" target="#b56">[57]</ref>, streamline embedding <ref type="bibr" target="#b36">[37]</ref>, Flow-Graph <ref type="bibr" target="#b27">[28]</ref>, semantic flow graph <ref type="bibr" target="#b45">[46]</ref>, and FlowNet <ref type="bibr" target="#b13">[14]</ref>. While most of these approaches <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b56">57]</ref> use distance metric to guide the generation of graph layout, semantic flow graph <ref type="bibr" target="#b45">[46]</ref> uses the semantic information to group the elements of similar attributes for exploration.</p><p>Streamline predicate <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b38">39]</ref>, IGScript <ref type="bibr" target="#b25">[26]</ref>, and tangible interface <ref type="bibr" target="#b16">[17]</ref> also adopt a similar idea but assign the semantic information in different ways. Another commonly adopted strategy for interactive flow exploration is based on pattern matching or feature detection. These approaches often rely on the similarity measure of streamlines <ref type="bibr" target="#b46">[47,</ref><ref type="bibr" target="#b50">51]</ref> and pattern matching for flow field regions <ref type="bibr" target="#b5">[6]</ref> to identify similar patterns.</p><p>More involved techniques are developed for specific applications and features, such as atmospheric front <ref type="bibr" target="#b18">[19]</ref>, PV banner <ref type="bibr" target="#b1">[2]</ref>, vortex <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b12">13]</ref>, and splat <ref type="bibr" target="#b32">[33,</ref><ref type="bibr" target="#b33">34]</ref>. Natural language interface. The natural language interface appeared in the information visualization field for around a decade. Most of the NLI approaches follow the same scheme: parsing the natural language queries, translating them into an intermediate form, such as explicit commands <ref type="bibr" target="#b44">[45]</ref>, SQL queries <ref type="bibr" target="#b8">[9]</ref>, VisFlow functions <ref type="bibr" target="#b58">[59]</ref>, and declarative specifications <ref type="bibr" target="#b31">[32]</ref>, and using the intermediate commands for visualization. Luo et al. <ref type="bibr" target="#b26">[27]</ref> followed a similar scheme, but developed a transformer-based model for the translation. Several NLI systems feature interactive dialog between users and the systems, such as Articulate 2 <ref type="bibr" target="#b20">[21]</ref>, Eviza <ref type="bibr" target="#b41">[42]</ref>, and Evizeon <ref type="bibr" target="#b15">[16]</ref>. DataTone <ref type="bibr" target="#b9">[10]</ref> targets ambiguity in natural language. It resolves the ambiguity using algorithmic disambiguation coupled with interactive ambiguity widgets. Orko <ref type="bibr" target="#b43">[44]</ref> supports multiple modalities of interaction including NLI. It uses a combination of grammar-based and lexicon-based parsing techniques to interpret the queries. The above work all support natural language query data for visualization. Cui et al. <ref type="bibr" target="#b7">[8]</ref> proposed Text-to-Viz, which generated visualization results from multiple sets of collected visual elements instead of query results. Researchers also evaluated the NLI approaches to produce guidelines for future developments. Srinivasan et al. <ref type="bibr" target="#b42">[43]</ref> designed several tasks to examine and compare five NLI systems, aiming to contrast them to reveal the challenges in designing NLIs. Tory et al. <ref type="bibr" target="#b49">[50]</ref> designed an empirical study for their system, suggested approaches to interpret and respond to users' intent, and reveal how varying levels of system understanding might affect the user experience.</p><p>Declarative language for visualization. The use of declarative language in information visualization toolkits became popular in the last decade, such as D3 <ref type="bibr" target="#b2">[3]</ref>, Reactive Vega <ref type="bibr" target="#b40">[41]</ref>, Vega-Lite <ref type="bibr" target="#b39">[40]</ref>, gg-plot2 <ref type="bibr" target="#b51">[52]</ref>, and GoTree <ref type="bibr" target="#b21">[22]</ref>. Recently, the declarative language is also used to provide computational simplicity and build visual analytic systems. For example, Li and Ma <ref type="bibr" target="#b22">[23]</ref> proposed P4, which generated WebGL programs in runtime to enable high-performance data processing and visualization. The authors later proposed P5 <ref type="bibr" target="#b23">[24]</ref> that extended the data transformation and visualization capabilities for progressive analysis and visualization, and P6 <ref type="bibr" target="#b24">[25]</ref> that used declarative language to combine interactive visualizations and machine learning.</p><p>The declarative languages also received attention from the scientific visualization community. Shih et al. <ref type="bibr" target="#b52">[53]</ref> presented a declarative grammar for customizing volume visualization pipelines. Their grammar focuses on the needs of specification of DVR-based volume visualization. Wu et al. <ref type="bibr" target="#b53">[54]</ref> designed DIVA, a declarative language for in situ data analysis and visualization, which made adaptive workflow development a simpler process. Liu et al. <ref type="bibr" target="#b25">[26]</ref> proposed IGScript, a declarative language for interactive scientific data presentations. This is different from the previous works which often target the computation or rendering stages. Similar approaches use the boolean formula to specify transfer function for features in volume <ref type="bibr" target="#b4">[5]</ref> and domain-specific language for volume processing <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b35">36]</ref>.</p><p>Comparison with the existing works. In terms of how the flow structure is represented, the semantic-based interactive approaches, such as semantic flow graph <ref type="bibr" target="#b45">[46]</ref>, streamline predicate <ref type="bibr" target="#b38">[39]</ref>, and IGScript <ref type="bibr" target="#b25">[26]</ref> is most similar to our FlowNL. Our declarative specification can be considered as creating semantic labels by filtering and composing existing labels (predicates). However, our approach also extends these approaches in the granularity of specification. These approaches select flow structures at the streamline level. Therefore, they have limited power in finding structures that are only related to streamline segments (e.g., flow in high pollution regions). Additionally, FlowNL integrates the filtering and linking across multiple spaces, while the other approaches may need additional steps for this purpose. Finally, FlowNL provides a convenient interaction scheme using natural language, which is not available in previous approaches.</p><p>In terms of natural language interface, FlowNL shares similar framework with previous techniques: translating natural language into an intermediate language that customizes the visualization. But unlike the existing techniques, FlowNL targets a significantly different domain with both structured and unstructured data. Therefore, although the framework is similar, the problem formulation, the declarative language design, and the visualization engine of FlowNL are still unique.</p><p>Similar to existing declarative languages, FlowNL customizes visualization using dictionary-like specifications. But unlike other technique, FlowNL supports operations that are designed specifically for describing structures in flow fields. For example, using the left and right neighboring operations to extend a scalar feature along the flow.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">DESIGN REQUIREMENTS</head><p>Target users and tasks. FlowNL aims at providing flexible interactions to explore flow field. It should allow users to conveniently specify structures of interest and observe their related flows. Toward this goal, it targets the common exploratory tasks for domain experts:</p><p>T1. Filtering. The experts want to identify structures in scalar attributes, features, spatial regions, and latent regions. For example, what are the flow in high temperature regions (i.e., heat transmission), and where are the spiral flows (e.g., vortices)?</p><p>T2. Compound queries. The experts want to specify structures fulfilling multiple criteria. For example, where are the upward flows with high humidity (i.e., evaporation), and where are the strong spiral flows (i.e., hurricane)?</p><p>T3. Transportation and connection discovery. The experts want to know how a structure evolves along the flow and how different structures are connected by the flow. For example, where the flow in high pollution regions goes to (i.e., pollution diffusion), and is there any pathway from the spirals to the sinks? Targeting these tasks, FlowNL is design as a lightweight tool to utilize the information in data, but it may not extract complex features that requires sophisticated computation. Its primary target users are domain experts. They can use FlowNL to examine simulated data, observe extracted features, and verify scientific hypotheses with visualization. They can also generate animated visualization easily, which helps to communicate their research work with others. FlowNL may be useful in science popularization as well. Tutors can produce visualization to explain scientific phenomenons and the audience can interact to discover more. Guided by the analysis of tasks and users, we identify the design requirements as:</p><p>R1. Easy-to-use. The tool should support users with limited visualization background. Specifically, the users should be able to use natural language queries to identify the flow fulfilling specific criteria and create customized flow visualization easily.</p><p>R2. Predictable behavior. The tool should deliver trustable visualization results, in the sense that users can expect how the system will respond to their queries. This requires the rules to understand queries and determine the system's behavior to be easily explainable.</p><p>R3. Lagrangian view of flow. The tool should support the queries of Lagrangian flow behavior. For example, it should allow users to query where the flow in a region comes from and where it goes to.</p><p>R4. Application-agnostic. The tool should be able to support the common types of flow data (e.g., flow fields and their associated scalar fields), and detected features, regardless of the specific application.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">OUR APPROACH</head><p>Our FlowNL system is designed to translate natural language queries into flow visualization results. The queries specify what are the flow structure to visualize and how each structure should be visualized. Due to the difficulty to build direction connections between natural languages and flow visualizations, we first consider how to describe flow structures in a general way. Toward this end, we designed a declarative language that filters and combines the basic types of flow data (named primitive objects) to derive the other more complicated objects (i.e., flow structures). In this way, our goal becomes translating natural language queries into declarative specifications and rendering the flow structures according to the specifications.</p><p>Framework. Figure <ref type="figure" target="#fig_0">2</ref> illustrates an example of FlowNL workflow that translates the natural language queries into animated flow visualization. The translation first parses the queries to form the declarative specifications. The declarative specifications leverage the pre-existing knowledge from either the data set ( ) or the data automatically generated by our system ( ). The pre-existing knowledge is shown on the top. The declarative specifications specify the operations ( ) to filter and combine the existing objects to derive the new ones ( ). For example, the spiral pattern is generated as a filter of the primitive object "flow pattern" (vectors in deep latent space), and the spiral flow is produced by intersecting the spiral pattern and all the streamlines. Then, an object "typhoon" is generated by taking the intersection of the spiral flow and a geographic region "west Pacific Ocean". The declarative specification also decides which objects will be sent to the visualization engine. In this section, we will formally describe the objects, the declarative language, and the natural language processing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Objects and Attributes</head><p>The objects abstract various kinds of data and flow structures, in accordance with design requirement R4. FlowNL considers two types of objects: primitive objects and derived objects. The primitive objects are basic ingredients that cannot be built from other objects, including all information provided by the data set or the system, and basic objects defined by users (e.g., geographic regions). The derived objects are generated from primitive objects or other derived objects to describe the flow structures. In this section, we describe the concept of the objects and attributes. Please refer to Section 3 for an example of specification.</p><p>Primitive objects and attributes. Two types of primitive objects are considered in our current design: structured grids and unstructured points. The primitive objects of structured grids host the flow field and scalar fields as attributes. Fields of different resolutions can be considered as attributes of different grid objects. In this paper, we consider all fields to share the same resolution for simplicity. In this case, a single primitive object "grid" is created to include all the fields. Other flow objects usually consist of unstructured points, such as critical points, sample points on streamlines, and spatial regions. Each object consists of a set of points carrying various attributes. For example, all critical points can form an object, and each point may have its own position, type, and scale. With this definition, a specific type of critical point (e.g., sinks) can be a derived object from filtering the primitive object "critical points" by type.</p><p>The primitive objects encode the essential elements and their attributes in the data. Our system can support attributes of any dimensions, such as 1D scalar values, 2D and 3D positions, and even highdimensional latent vectors from deep representation approaches. The primitive objects and their attributes are configurable using a meta file in JSON format. The dashed frames in Figure <ref type="figure" target="#fig_0">2</ref> show a typical example of primitive objects in a data set, which involves five types of data. The first type is the field data from the data set, as shown in the blue boxes. This includes a flow field and multiple scalar fields. The second type is the sampled streamlines generated by the system. The streamlines provide a Lagrangian view of the flow field, which is necessary to understand the flow behavior. To ensure the coverage of the field, an information-theoretic framework <ref type="bibr" target="#b55">[56]</ref> is used to guide the sampling. Our system will also produce several attributes for filtering desired flow features. Currently, for each sample point, we record the position of that point and generate a latent vector to describe the flow pattern. The latent vector is produced by a deep autoencoder on the distance matrix among sample points. Users can use latent vectors from other representation approaches, as our system supports high dimensional attributes. FlowNL does not produce further attributes (e.g., vorticity) and rely on users to provide them as scalar fields if needed.</p><p>The other three types of data can all be considered as spheres in different spaces: the critical points are spheres in the 3D physical space, the flow patterns are spheres in the latent space, and the geographic regions are circles in the 2D geographic space. Note that we use the spheres to approximate regions in different spaces because this strategy can easily extend to arbitrary dimensions. For example, in our current implementation, the flow patterns are spheres in 128-dimensions. For an irregular region, multiple spheres can be used to approximate a single object. However, in the scenarios where high precision is required, users may adopt other approaches to approximate the regions (e.g., mask volumes).</p><p>Derived objects. The derived objects are generated from the primitive objects or other existing derived objects. FlowNL provides two schemes to derive objects. The first scheme is filtering existing objects. For example, an object of the saddle points can be created by filtering the critical points by their types, and an object corresponding to regions of high humidity can be created by filtering the grid points based on the humidity scalar field. The second type of object is generated by combining existing objects using a suite of operations provided by our system. For example, the hurricane is the intersection of the spiral flow and the geographic region "Gulf of Mexico". We will elaborate the derivation operations in the next subsection.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Declarative Language for Flow Visualization</head><p>The declarative language specifies visualization parameters for existing objects and operations to generate new objects. For object derivation, our system represents all objects as subsets of elements of the respective primitive objects and apply the following operations to derive new ones: filtering, mapping, union, intersection, difference, and neighboring. In this section, we will elaborate on the goals and rules of the operations, but only briefly introduce the syntax with examples, as the users are supposed to interact with the system using natural language instead of the declarative language.</p><p>Filtering. The filtering selects a subset of elements from an object to form a new one based on an attribute. Note that the attribute can be 1D or high-dimensional. The high-dimensional filter is represented by a series of spheres. Each sphere is encoded by its center (i.e., highdimensional vector) and a radius.</p><p>Mapping. The mapping converts a derived object from one primitive to another using a specified attribute. For example, streamlines can be mapped to the nearest grid points based on their positions. In this way, a derived object from the primitive "flow" can be converted into an object of the primitive "grid".</p><p>Union, intersection, and difference. These operations apply respective set operations to combine the elements of two objects. When both the two objects are derived from the same primitive objects, the operations are performed directly on the indices of elements.</p><p>Operations between different primitive objects. When the two objects are derived from different primitive objects (for example, humid regions and spiral streamlines), a mapping will be performed to map the elements in the second operand to the elements in the first operand. For example, the statement "humid regions containing spiral streamlines" will map the spiral streamline segments into grid points and compute the intersection on grid points; while "spiral streamlines in humid regions" will map the grid points with high humidity to streamlines and perform the intersection on streamline points. In short, the resulting object shares the same primitive object as the first operand. Therefore, the first statement produces a region while the second one produces a series of streamline segments.</p><p>Neighboring. The neighboring operation extends the spatial coverage of an object to provide more contextual information. For grid points, the neighboring operation includes the neighboring grid points of the current ones, which is similar to the dilation in image processing. For spatial regions, the neighboring operation simply increases the radius of each circular region. For streamline segments, the neighboring operation expands the segments along the streamlines.</p><p>In accordance with design requirement R3, FlowNL facilitates the understanding of the flow field from the Lagrangian perspective. We further introduce the right neighboring and left neighboring to expand the segments along the flow direction and the opposite, respectively. These operations are particularly useful for tracking the origin-destination relationships in flow fields. Note that the objects that are not derived from streamlines do not support the these two operations. In this case, the system will automatically map the objects to streamlines, apply the operation, and map the object back to its original primitive.</p><p>Query formula. The query formula is designed to specify compound operations to simplify declarative specifications. It also serves as a brief description of a derived object and a convenient interface for users to formally define an object. The operations supported by the query formula are: union (|), intersection (&amp;), difference (−), neighboring (N(•)), left neighboring (L(•)), and right neighboring (R(•)). We do not support filtering in the query formula for simplicity, as filtering is more convenient using our filtering widgets. For example, the query "show the flow from high humidity region" in Figure <ref type="figure" target="#fig_1">3</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>can be written as "R([ f low]&amp;[highhumidity]</head><p>)" in the query formula.</p><p>Visualization. The flow-related objects (i.e., derived from streamlines) are used as seeding candidates to generate particles with a small noise applied. To avoid a particle diverging from the original object, the flow direction at the particle is compared to the direction on the original streamline. When the difference between the direction is too large, the particle will be directly recycled. A declarative specification can also specify the color and the density of particles related to an object. It can specify a scalar field for color mapping as well. The other objects are visualized as point clouds. In this way, the statement "show the flow of high humidity" will create particles in the high humidity regions, while "show the region of high humidity" will create a point cloud covering the high humidity regions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Natural Language Processing</head><p>The declarative language may still be difficult to use for domain experts without programming experience. To further enhance the usability, the FlowNL architecture is built with a natural language interface (NLI) to translate natural language queries from users to declarative language. The NLI consists of: a grammar parser that identifies the tasks, objects, and their relationships from the natural language; a derivation mechanism that generates derived concepts from existing ones; and additional features such as ambiguity resolving and autocompletion. Note that we choose semantic parser for it is easier to explain and manipulate, in response to design requirement R2.</p><p>Grammar parser. The parser of FlowNL translates a user query into declarative specifications, including tasks, objects, object relations, and visualization styles. Specifically, FlowNL uses a context-free grammar to parse the queries and form a parser tree. Since a query in natural language is likely to specify multiple tasks at the same time, the parser tree usually contains multiple layers, where each node corresponds to a declarative specification. The fundamental grammar rules of FlowNL are as follows:</p><formula xml:id="formula_0">Rule 1 : 〈Query〉 −→ 〈TaskType〉〈Object〉〈Style〉 Rule 2 : 〈Object〉 −→ 〈Object〉〈ObjectRelations〉 Rule 3 : 〈Object〉 −→ 〈Object〉〈Object〉〈ObjectRelations〉 Rule 4 : 〈Object〉 −→ 〈Attribute〉〈Object〉〈Operator〉〈Value〉</formula><p>An example of the parsing procedure. Figure <ref type="figure">4</ref> shows an example of the parsing procedure for the query "Draw the spiral flow from Pacific with velocity magnitude over 32 in dark blue". The word "draw" identifies the query to be a "visualize" task using Rule 1, although the 〈Object〉 and 〈Style〉 are not identified yet. The phrase "spiral flow from Pacific" matches Rule 3 and produces the specification (a). The phrase "velocity magnitude over 32" matches Rule 4 and produces the specification (b). With the objects corresponding to the specification (a) and (b), the third object can be created with the specification (c) using Rule 3. Given the third object, the parser can determine the 〈Object〉 of the entire query and apply Rule 1 to generate the specification (d). In this example, the 〈Object〉 of the entire query is recursively identified from the primitive objects and their attributes. This procedure allows intermediate objects to be derived during the query. It distinguishes our FlowNL from most of the existing NLI approaches for tabular data, where entities are usually predefined by the columns of tables.</p><p>Object relations. 〈ObjectRelations〉 specifies how the objects relate to each other, which is used to generate the operations in the declarative specifications. Other than the set operations such as 〈Union〉, 〈Intersection〉, and 〈Difference〉, 〈ObjectRelations〉 further introduces the following spatial relations: 〈From〉, 〈To〉, 〈FromTo〉, 〈Between〉, 〈In〉, 〈Near〉, and 〈RelatedTo〉.</p><p>The spatial relations in 〈ObjectRelations〉 enable the analysis of Lagrangian flow behaviors. These relations extend the objects along the flow using the neighboring operations. The definitions of 〈From〉, 〈To〉, 〈FromTo〉, and 〈Between〉 are relatively straightforward, and 〈In〉, 〈Near〉, and 〈RelatedTo〉 specify neighboring regions of growing sizes. 〈In〉 specifies the flow inside the object, 〈Near〉 specifies a small neighborhood of the object by extending the object along the flow, while 〈RelatedTo〉 specifies the entire region containing the streamlines passing through the object. Task identification. FlowNL uses keyword classification for task recognition. The parser will first match the words in a query sentence with the keywords in a dictionary, which lists potential keywords of our tasks. For example, "show" and "draw" will be classified as a query of the "visualize" task. If none of the keywords is matched, the synonyms corresponding to these keywords will be retrieved automatically based on word similarity. In our implementation, the similarity between words is calculated by the Wu-Palmer similarity function <ref type="bibr" target="#b54">[55]</ref>. This similarity function returns a similarity score based on the depth of the two words in WordNet classification <ref type="bibr" target="#b29">[30]</ref> and the depth of their least common substrate (LCS) of the most specific ancestor node.</p><p>Note that the task of some verbs may rely on the content of the sentence. For example, "set" and "change" may mean to adjust the color of an object (e.g., "change the color of A to red"), corresponding to the color task. In other case, they may mean to adjust the threshold of a filter (i.e., "set the wind speed of hurricane over 40"), corresponding to the adjust task. For this kind of ambiguous keywords, the system will further search the entire sentences for the actual task.</p><p>Object identification. An object in a natural query may be the name of an attribute, a primitive object, an existing derived object, and even the name of an object to be derived. We use the part-of-speech tagging (POS) tagging to recognize unknown objects and N-grams to check the existing objects, which is similar to the previous NLI approaches <ref type="bibr" target="#b41">[42,</ref><ref type="bibr" target="#b43">44,</ref><ref type="bibr" target="#b58">59</ref>]. But unlike these approaches, we do not allow approximiate matching as scientific concepts and terms often carry exact meanings. For example, "typhoon" and "hurricane" shares a large similarity value (larger than 0.9) using the Wu-Palmer similarity function <ref type="bibr" target="#b54">[55]</ref>, but they may refer to difference concepts for researchers in atmospheric science. Therefore, instead of auto-correction, we rely on users to provide the exact terms for query.</p><p>To reduce the user effort, we allow users to provide aliases for the objects. These aliases will be used in the N-gram matching in addition to the object names. Users do not need to define an alias before using it. Instead, they can provide the definition in a dialog using our derivation mechanism, which will be explained in the following paragraph.</p><p>Derivation mechanism. We introduce a derivation mechanism to resolve the undefined objects or alias. The undefined terms are identified as unrecognized noun phrase by tracking the POS tagging produced and the dependency tree using the Stanford CoreNLP toolkit <ref type="bibr" target="#b28">[29]</ref> and SpaCy <ref type="bibr" target="#b14">[15]</ref>. Figure <ref type="figure" target="#fig_3">5</ref> illustrates an example of derivation. When a user ask the system to show an unknown object "hurricane", the system will ask the user for the definition. The user may then explain that "hurricanes are spirals with wind speed larger than 32 meters per second near Gulf of Mexico". Upon receiving this explanation, the parser will parse the sentence, generate the declarative specification, and send the specification to the visualization engine to derive the new object "hurricane". With the object created, the natural language parser will recursively process the original query "show hurricane" and request the visualization engine to visualize the hurricane.</p><p>We rely on users to provide the definitions of unrecognized objects based on the existing ones, instead of querying knowledge bases such as WolframAlpha <ref type="bibr" target="#b0">[1]</ref> and WordNet's synsets <ref type="bibr" target="#b29">[30]</ref> to obtain the definition automatically. This avoids the ambiguity of scientific concepts, which could be domain-specific. For example, the wind speed to characterize a hurricane may vary across different research areas. Indeed, the Saffir-Simpson hurricane scale categorize hurricanes into five types based Fig. <ref type="figure">4</ref>. An example of parsing procedure. From top to bottom, this figure shows the natural language query, the part-of-speech (POS) tag, the object identification, and the parsing tree using grammar rules. The rules labeled by the numbers are used to produce the declarative specifications. on the wind speed. Additionally, the term "hurricane" may even be used to describe general large swirling storms without specifying the geographic location.</p><p>Resolving ambiguity. Two types of ambiguity may appear in natural language queries: semantic ambiguity and quantitative ambiguity. The semantic ambiguity occurs when objects or their attributes share the same names. For example, the term "spiral" may refer to a type of critical points, or a flow pattern, leading to semantic ambiguity. In this case, FlowNL will make a best guess based on a least recently used (LRU) strategy, assuming that an object will not be specified in multiple consecutive queries. But we should note that FlowNL does not completely rely on this strategy to determine the object referred by an ambiguous term. Instead, FlowNL will expose the ambiguity of the phrase, present all potential objects to users, and allow them to correct the default choice of object, as shown in Figure <ref type="figure" target="#fig_4">6(c)</ref>.</p><p>The quantitative ambiguity refers to the vagueness of describing quantities in natural languages. For example, in the phrase "the flow with low velocity magnitude", the word "low" implies a filter should be applied but it does not specify the exact threshold for filtering. In this case, FlowNL will use a default threshold (e.g., "high" indicates "top 5%") and bring up an interactive widget to resolve the ambiguity. For scalar value, a histogram of the corresponding attribute will be displayed for selecting a value range, as shown in Figure <ref type="figure" target="#fig_4">6 (a)</ref>. For 2D vectors (e.g., geographic regions), a 2D plot will be displayed for users to specify circular regions, as shown in Figure <ref type="figure" target="#fig_4">6</ref> (b). Specifying regions in higher dimensional space (e.g., latent spaces) will be difficult, which is not supported in our current system. A potential solution is to use dimension reduction techniques to embed the targeted space into 2D space for selection.</p><p>Auto-completion. Auto-completion reduces users' effort to type in their queries, and also provides hints to users about the tasks and queries supported by the system. FlowNL implement this mechanism through fuzzy matching and prefix matching. We design a suite of template sentences to remind the users of the typical queries supported by our system. Before users enter any information, the input box will show the template queries in a default order, as shown in Figure <ref type="figure">1</ref> (e). Once users start typing, the system will keep updating the edit distances from the templates to the user input. The edit distance measures the minimum number of operations to convert the current input to the template queries, which reflects user's intention. We use the edit distance for selecting the candidate templates to display as suggestions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Interface</head><p>The interface of FlowNL consists of: query input box, dialog box, object and attribute table, and flow visualization, as shown in Figure <ref type="figure">1</ref>.</p><p>The query input box is shown on the top of the interface. It takes the natural language queries from users and sends the queries to the back-end natural language parser. During typing, it will keep tracking the key words including the objects, attributes, and colors. It will also match the partially completed queries with templates and display the top matching templates as suggestions, as shown in Figure <ref type="figure">1 (e)</ref>. The dialog box is used to define unknown terms during conversation, as shown in Figure <ref type="figure">1 (b)</ref>. If the definition contains further unknown terms, the dialog will be expanded to define the newly appearing terms.</p><p>The flow visualization shows the flow-related objects as streamlets and the other objects as point-clouds, as shown in Figure <ref type="figure">1 (f)</ref>. It also displays the interactive widgets to edit filters for 1D/2D attributes. The flow visualization is rendered on the back-end visualization engine, and sent to the front-end web interface as a video stream.</p><p>The object and attribute table shows the derived objects and attributes associated with each primitive object. The primitive objects are shown as the table headers in bold font. When the derived objects tab is active, each cell shows a derived object, as shown in Figure <ref type="figure">1 (d)</ref>. If an object is visualized, a small glyph will appear to its left. The glyph contains a color legend at the center and a circular slider at the outer ring. The color legend indicates the color of the object or the color map used for that object. The slider can be used to adjust the "weight" of the object. For a flow-related object, the weight indicates the density of particles assigned to the object. For an object of point-clouds, the weight is used as the opacity of the points. By clicking the object name, its corresponding query formula will be displayed, as shown in Figure <ref type="figure">1</ref> (c). Users may edit the query formula to change its definition. If the object is a 1D or 2D filter, a selection widget will be displayed for users to edit the filter parameters. In Figure <ref type="figure">1</ref>, a filter object "high w" is clicked and the histogram of the attribute "w" is displayed at the bottom left corner of the flow visualization. Users may brush the histogram to determine the value range of "high w".</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">EVALUATION</head><p>We evaluate FlowNL empirically with a domain expert in cloud physics and a tutor in science popularization. Please refer to the supplementary video for the exploration of two case studies. We also conduct a formal user study to examine the learnability and usability.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Case Study by Domain Expert: BOMEX data set</head><p>We team up with an expert from Brookhaven National Laboratory to examine the effectiveness of FlowNL. The expert is a research scientist with more than 10 years of experience in cloud physics study. His research interest is ice nucleation, remote sensing, aerosol-cloud interactions, and cloud simulation. The expert provided the BOMEX data and used FlowNL to explore this data. The BOMEX data simulates the atmospheric shallow cumulus convection in a domain of 3175 × 3175 × 3980 meters. This data set includes one flow field and fourteen scalar fields. The data contains a large cloud, and the expert would like to visualize the formation of this cloud by tracking the cloud droplet activation and evaporation. In this session, we present his exploration and reproduce the key visualization results, as shown in Figure <ref type="figure">7</ref>.</p><p>The expert first examined the overall flow pattern with the randomly sampled particles, as shown in Figure <ref type="figure">7</ref> (a). In the upper layer, the flow is mostly laminar and moves at a fast speed. In the lower layer close to the ground, the flow becomes more turbulent and the flow directions are more diverse. In the middle layer, where the cloud resides, the flow pattern is more complicated and the streamlets are shorter as the flow moves slower in this region. Therefore, the randomly spawned particles are less effective in forming a continuous pattern to describe the flow behavior in this region.</p><p>To better observe the flow pattern in the cloud regions, the expert queried "show the flow of high QN", where "QN" is the "nonprecipitating condensate" including water and ice. He explained that "high QN" can be considered as the core of the cloud. The "flow of high QN" is visualized in orange in Figure <ref type="figure">7</ref> (b). To further examine the interaction between the cloud and the layers of flows close to it, the expert queried "show the flow from high QN to large z" (in green) and "show the flow from small z to high QN" (in red), where "z" is the height. He explained that the red flow and the green flow revealed how the vapor entered and escaped from the cloud core, respectively.</p><p>However, the interactions between layers of flow may not reveal the complete paths of vapors. Therefore, the expert hid the red and green flow and added the purple flow using a query "show the flow from high QN to low QN", as shown in Figure <ref type="figure">7 (c</ref>). He commented that this showed a clearer pattern of the vapor transportation path. The particles move either toward the east (from the left to the right in the screen) or the southeast (from the left to the bottom right in the screen). The expert explained that this indicated that the cloud was shearing.</p><p>Next, the expert wanted to quantify the numbers of particles moving upward and downward, respectively. But this is not supported in our current implementation. Therefore, he decided to separate the upward flows, as this was usually less common. He removed the purple flow to reduce occlusion and added the upward flow by querying "show the flow from high QN to low QN with positive w", where "w" is the vertical velocity. The corresponding flow was shown in light green in Figure <ref type="figure">7</ref> (d). The upward flow leaving the cloud core mostly move eastward. This indicates that cloud dilution, arising from the mixing between the cloud entity and the environmental air, occurs in the downwind region due to the wind shear.</p><p>Then the expert used the attribute "cloud water number concentration" (NC) to guide the exploration. He explained that NC was a better indicator of the boundary of the cloud, as this attribute is stable inside the cloud and mostly zero outside the cloud. In contrast, QN change smoothly from the boundary to the core of the cloud. The expert used a yellow point cloud to indicate the spatial coverage of the core of cloud by querying "show the grid of high QN in light yellow". This avoided the distraction from the orange streamlets. He then added the inward and outward flows by querying "show the flow from low NC to high NC" (light purple) and "show the flow from high NC to low NC" (gray), as shown in Figure <ref type="figure">7</ref> (e). He commented that the flows generated using NC better demonstrated the interactions near the cloud boundary.</p><p>The expert was particularly interested in the light purple flow (from low NC to high NC), as this flow supported the cloud. Therefore, he removed the gray flow for better observation of the light purple one, as shown in Figure <ref type="figure">7</ref> (f). Most of the light purple flow resides at the bottom of the core of cloud, supporting the base of the cloud. But the expert also found two branches of flow entering the cloud on the top, as highlighted by the red arrows. This may indicate the cloud droplet formation at cloud edge due to entrainment and mixing. The expert was curious about whether there was any other entry point from non-upward flow. He queried "show the flow from low NC to high NC that is not from large w". The query result is visualized by the red streamlets in Figure <ref type="figure">7</ref> (g), which reveals all entry points from the non-upward flow.</p><p>Finally, the expert examined the evaporation process based on NC. He brought back the orange and purple flows in Figure <ref type="figure">7</ref> (c) and queried "color the flows by NC", as shown in Figure <ref type="figure">7</ref> (h). The flow shows a clear boundary between the red and blue regions, indicating the boundary of the cloud. The expert found that a vortex appeared at the subsiding shell, as highlighted by the dashed orange circle. He commented that this vortex clearly showed the entrainment (environmental air flows into the cloud entity) and detrainment (part of cloud entity flows into the nearby environment) processes.</p><p>Overall, the expert was satisfied with the exploration using FlowNL. He commented that "FlowNL is a powerful tool to visualize the instantaneous 3D fluid motion. It helps to illustrate complex processes in a turbulence environment (e.g., atmospheric clouds), which can benefit education and research." He also stated that "I will recommend FlowNL to my colleagues and I will be interested in using the future versions. Particularly, it will be even more helpful if it can support quantification of the particles with different criteria and plot the statistics in nice visualization charts."</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Additional Case Studies</head><p>European Centre for Medium-Range Weather Forecasts (ECMWF) data set. A tutor in science popularization used FlowNL to generate an animation for scientific storytelling. She aimed at explaining the vapor transportation to China. A key visualization frame is shown in Figure <ref type="figure" target="#fig_6">8</ref> (a). She first queried "show the hurricane" and explained to the system that hurricane is "spiral flow". She showed the typhoon as the hurricane in west Pacific in green. She colored the hurricanes that were not typhoon in red. She then identified two vapor transportation paths from the Mediterranean Sea to China and from the Indian Ocean to China. She was satisfied with the video produced.</p><p>Five critical points. We used FlowNL to visualize this data set, as shown in Figure <ref type="figure" target="#fig_6">8 (b)</ref>. We first showed the saddles, sources, and spirals in yellow, red, and green, respectively. Then we showed the flow related to the saddles, the flow from the sources, and the flow from the spirals in the respective colors as the critical points. Note that there are several spiral saddles in this data set. We queried "show the flow related to the saddles but not from the spirals" to avoid overlaps.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">User Study</head><p>We conduct a formal user study to evaluate the effectiveness, usability, and learnability of our FlowNL. Through this study, we wanted to evaluate how much learning effort it costs for a user to manipulate the tool, whether a user can form correct queries for given tasks, whether a user is confident in the meaning of the resulting visualization, and how well FlowNL responds to the user queries.</p><p>Participants and experiment setup. We recruited eight unpaid participants with either computer science or scientific domain background. Two participants have PhD degrees, four have master degrees, and the other two have bachelor degrees. In terms of academic background, The key visualization results from a domain expert's exploration using the BOMEX data. The blue streamlets correspond to the background flow, which are uniformly spawned in the entire domain. The variables "QN", "NC", "z", and "w" denote "non-precipitating condensate", "could water number concentration", "height", and "vertical velocity", respectively.</p><p>(a) (b) five participants have mechanical engineering, physics, or atmosphere research experience, three participants have research or working experience in interactive techniques (including one with atmosphere background), and the other participant's research area is database. Four participants reported experience with geographic information systems, ParaView, or similar tools, but none of them have experience with interactive flow visualization system or natural language interface. The participants interacted with the system on a 32-inch 4K screen where FlowNL interface occupied an area of 2600 × 1400 pixels.</p><p>Procedure. The participants started with a demonstration video and a brief introduction (approximately 15-20 minutes). The introduction included the natural language query, query formula, interface of FlowNL, and basic knowledge about the ECMWF data set, which was used in this study. After the introduction, they could freely experiment with FlowNL to explore the ECMWF data set. They could ask questions regarding the usage of any functions of FlowNL or the data set. They were informed to take as long as they want until they feel comfortable to perform the tasks. Each of the participants was required to perform 12 tasks using the ECMWF data on a different date. Their interactions were recorded as a video by a screen capture software. They were informed that the timing would not be used to measure their performance, and they were encouraged to experiment different queries for the same task. Finally, the participants were required to answer the ten questions in SUS questionnaire <ref type="bibr" target="#b3">[4]</ref> and provide additional comments. Please refer to the supplemental materials for the introduction and questionnaire documents.</p><p>Tasks. The twelve tasks covered different types of queries, including creating derived objects, verifying query formula, hiding an object, adjusting the density of particles for an object, extending an existing object along the flow, adjusting the value range of a filter, and changing the color of objects. Five tasks were related to the object creation, including objects related to attributes, geographic regions, flow patterns, and compound relations. Table <ref type="table">1</ref>. The task performance. # first shows the numbers of queries to finish the tasks for the first time, # total shows the total numbers of queries performed, # accepted shows the numbers of accepted queries, # QF shows the numbers of query formula used.</p><p>Task performance. All the participants performed all tasks successfully, although using different number of queries. As most of the participants were willing to experiment with alternative queries to explore more, we report both the number of queries for them to complete the tasks for the first time, and the total number of queries they performed. Table <ref type="table">1</ref> summarizes the task performance.</p><p>In terms of the first time completion, the participants used 12.1 queries to perform the eight tasks requiring at least one query. We did not count the other four tasks as they could be performed with mouse operations instead of queries. For the eight tasks being counted, the possible minimum number of queries is 9, as one of the task requires at least two queries to perform. One participant (P2) used exactly 9 queries to finish the tasks and five participants used 12 queries or less to finish. P4 used 16 queries to finish the tasks, which was the most among all participants. By checking the recorded video, we found that P4 used 6 queries for Task 5, which asked the participants to create a flow-related object fulfilling three criteria. P4 used multiple queries to create additional objects, leading to extra number of queries.</p><p>The exploration time and the total number of queries varied across participants. The participants took 28.8 minutes to perform the tasks on average, ranging from 17 to 42 minutes. On average, they performed 35.6 queries with 32.4 queries accepted, leading to an acceptance rate of 90.9%. Most of the participants performed much more queries than the minimum required to finish the tasks. We found that the acceptance rate might not correlate with the exploration time. The three participants who spent the least amount of time <ref type="bibr" target="#b16">(17,</ref><ref type="bibr" target="#b17">18</ref>, and 23 minutes) actually had high acceptance rate (39/40, 18/18, and 31/32, respectively). Please refer to Section 1 in Appendix for the details of rejected cases.</p><p>Most of the participants were willing to experiment with the query formula. Four participants used the query formula to create or edit an object for more than four times, even if the query formula was not necessary to perform the tasks. Only two participants did not use the query formula at all during the exploration. To our surprise, the five participants with scientific domain background were not reluctant to try the query formula. All of them used the query formula for at least once, including one used it for five times and two used it for four times.</p><p>SUS Scores. We evaluated the learnability and usability of FlowNL using the System Usability Scale (SUS) <ref type="bibr" target="#b3">[4]</ref>. FlowNL received an overall score of 76.6 out of 100, placing it between "good" and "excellent" in SUS rating. Figure <ref type="figure" target="#fig_8">9</ref> shows the detailed survey results. Note that, since SUS alternates the tone of each item, we reverse the scores for negatively phrased items back to positive scores before the analysis.</p><p>Three questions are regarding the learnability: Q4 ("I need technical support to use this system"), Q7 ("I think most people can learn this system quickly") and Q10 ("I think there are a lot of things to learn before I can start using this system"). While Q4 received the lowest score (3.0) among all the questions, both Q7 (4.4) and Q10 (4.0) received relatively high scores of 4.4 and 4.0, respectively. It seemed that most participants believed that one could learn FlowNL in fairly short amount of time without much background, but they felt that the technical support was necessary during the learning stage.</p><p>The other questions are related to the usability. All questions except Q2 received scores of 4 or above, indicating the participants agreed that the system functioned smoothly without much irregularities. Q2 ("I find this system to be more complicated than it should be") received the lowest score of 3.75. One participant explained that it was common to analyze planar flows in atmospherical research, where static visualization was adequate.</p><p>User behaviors. We have two main observations in the user study. First, mouse versus natural language queries. The participants still preferred mouse operations for some tasks. For example, we found that only three participants used the natural language for Task 7 (adjust the density of particles) and 8 (hide a specific object). Two participants mentioned that they would use natural language if voice queries were supported. By analyzing the recorded interactions, we also found that the participants were accustomed to mouse operations. For example, one participant moved the mouse to an object after executing the natural language query to hide that object. We believe this is also related to the use of desktop in our experiment. In an immersive environment, the participants may lean to the natural language queries. Second, ambiguity in natural language. For example, four participants expected that "the flow passing through China and Japan" indicated an intersection between the flow through China and the flow through Japan, while the other four participants corresponded this query to the flow through China or through Japan. We also found that this might relate to the underlying geographic locations, as most of the participants believed that "the flow passing through China and Mexico" indicated a union. Under the design requirement R2, we always use the intersection for "and" and union for "or". We explained this rule to the participants so that the behavior of FlowNL can be predictable.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Limitations</head><p>Unsteady flow fields. The current evaluation only examines the effectiveness of FlowNL using steady vector fields and streamlines. This may be acceptable when the change of flow is much slower than the movement of particles. However, for general applications, unsteady flows and pathlines must be studied to understand the Lagrangian behavior. This is not fully supported in the current version of FlowNL. Our data engine can naturally incorporate pathlines as a primitive with 4D points, and the set and neighboring operations can apply to the pathline objects. However, the visualization engine needs further development to filter objects by time during animation, and the natural language parser needs an extension to support the navigation of time. Furthermore, the scale of unsteady fields may require more powerful devices or more advanced algorithms to manipulate objects in real-time.</p><p>Complex features. We should note that FlowNL cannot derive complex features directly from the raw flow fields. For example, vortex extraction <ref type="bibr" target="#b12">[13]</ref> may be computed by reference frame optimization <ref type="bibr" target="#b11">[12]</ref>, from trajectories <ref type="bibr" target="#b47">[48]</ref>, from surfaces <ref type="bibr" target="#b10">[11]</ref>, etc. These computations, while accurate, are application-specific, and they cannot be performed with FlowNL. Under design requirement R4, FlowNL provides a general data interface for users to provide their features.</p><p>Meanwhile, FlowNL can incorporate deep representations as attributes, which is useful with the emerging deep learning-based techniques in scientific visualization. Currently, FlowNL uses latent encoding as an attribute of streamlines to describe their shapes. We manually select typical encoding from the embedding space as flow patterns. For example, "spiral" corresponds to the streamline segments of a circular shape. Compared to the specifically designed algorithms, our encoding is less accurate and only reveals patterns of individual streamlines. But it serves as an immediately available tool for rough explorations.</p><p>Visualization and interaction techniques. FlowNL visualizes various kinds of objects in two forms: streamlet animation and point clouds. However, this may not reveal complex structures concisely. More involved techniques, such as integral surfaces, should be considered. Additionally, the scalar features may be rendered more precisely using direct volume rendering or isosurface rendering as well. The natural language parser and declarative grammar should be extended to specify visualization styles and parameters. In terms of interaction, FlowNL uses textual input, which limits its usage. Voice may be more applicable in immersive environments and enhances multimodal interactions, as voice interaction is hands-free.</p><p>Evaluation. FlowNL is evaluated by two experts through empirical evaluation, and five participants with domain backgrounds in the user study. Deploying the system to a public platform may better evaluate its performance in different applications and scenarios. For now, we provide an analysis about the supported users and tasks in Section 3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">CONCLUSIONS AND FUTURE WORK</head><p>We propose FlowNL, a natural language interface for exploratory flow visualization. FlowNL integrates a natural language parser, a declarative language designed for flow visualization, and a flow visualization engine. It supports queries of flow structures related to various kinds of scalar and flow features. We evaluate FlowNL using multiple case studies with domain experts and a user study.</p><p>While our current implementation emphasizes predictable responses for queries, we would like to explore more sophisticated approaches in understanding the fuzzy natural language queries. For example, by deploying FlowNL on supercomputers, we may collect more queries from a broader spectrum of users to train deep translators. Knowledge graphs may be used to derive unknown concepts as well. We would also like to support unsteady flows, more involved visualization techniques, and multimodal interactions, as discussed in Section 5.4.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 2 .</head><label>2</label><figDesc>Fig.2. An example of FlowNL workflow that translates the natural language queries into flow visualization results. The queries are parsed to form the declarative specification. The declarative specification specifies how to derive objects for visualization ( ) from the existing primitive objects in the data set ( ) and automatically generated data ( ). The operations used to derive the objects are shown in the green boxes ( ).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Sample declarative specifications generated by the query "show the flow from high humidity region". The four declarative specification corresponds to the tasks to filter the grid by humidity, identify the streamline segments in the high humidity region, extend the segments along the flow direction, and visualize the segments.</figDesc><graphic url="image-22.png" coords="4,314.06,73.32,230.92,120.90" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>Formally, let O be an object, 〈From〉 indicates R(O), 〈To〉 indicates L(O), 〈FromTo〉 indicates R(O a ) ∩ L(O b ), 〈Between〉 indicates (R(O a )∩L(O b ))∪(L(O a )∩R(O b )), 〈In〉 indicates O, 〈Near〉 indicates N(O), and 〈RelatedTo〉 indicates N +(O), where "+" denotes an extended neighborhood.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. An example derivation workflow to define "hurricane".</figDesc><graphic url="image-26.png" coords="6,70.24,256.79,93.61,65.27" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 6 .</head><label>6</label><figDesc>Fig. 6. Resolving ambiguity in FlowNL. (a) shows the widget to specify the value range of "low velocity magnitude" . (b) shows the widget to specify the region of "Indian Ocean". (c) shows a box to specify the primitive for an attribute named "type".</figDesc><graphic url="image-27.png" coords="6,176.07,256.79,118.52,65.27" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>Fig.7. The key visualization results from a domain expert's exploration using the BOMEX data. The blue streamlets correspond to the background flow, which are uniformly spawned in the entire domain. The variables "QN", "NC", "z", and "w" denote "non-precipitating condensate", "could water number concentration", "height", and "vertical velocity", respectively.</figDesc><graphic url="image-44.png" coords="8,71.33,170.87,85.57,86.39" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 8 .</head><label>8</label><figDesc>Fig. 8. Flow visualization results using additional data sets. (a) shows the result using ECMWF data set. (b) shows the result using five critical points data set.</figDesc><graphic url="image-62.png" coords="8,183.58,318.62,80.98,99.89" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>P1</head><label></label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 9 .</head><label>9</label><figDesc>Fig. 9. Participant responses for the ten SUS questions. The higher scores are placed closer to the bottom.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic url="image-3.png" coords="1,118.24,155.50,364.42,166.46" type="bitmap" /></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS</head><p>This research was supported in part by the National Natural Science Foundation of China through grants 61902446, 62172456, 91937302, National Key R&amp;D Program of China through grant 2021YFB0300103, and National Windtunnel Project. The authors would like to thank Dr. Fan Yang for his insightful suggestions and case study.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<ptr target="https://www.wolframalpha.com/" />
		<title level="m">WolframAlpha</title>
				<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Extraction and visual analysis of potential vorticity banners around the alps</title>
		<author>
			<persName><forename type="first">R</forename><surname>Bader</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sprenger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Ban</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Rüdisühli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Schär</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Günther</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="259" to="269" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">D 3 : Data-driven documents</title>
		<author>
			<persName><forename type="first">M</forename><surname>Bostock</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Ogievetsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Heer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2301" to="2309" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">SUS: A quick and dirty usability scale</title>
		<author>
			<persName><forename type="first">J</forename><surname>Brooke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Usability Evaluation in Industry</title>
		<imprint>
			<biblScope unit="volume">189</biblScope>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">VolumeShop: An interactive system for direct volume illustration</title>
		<author>
			<persName><forename type="first">S</forename><surname>Bruckner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Groller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE Visualization Conference</title>
				<meeting>IEEE Visualization Conference</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="671" to="678" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Moment invariants for 3D flow fields via normalization</title>
		<author>
			<persName><forename type="first">R</forename><surname>Bujack</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kasten</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Hotz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Scheuermann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Hitzer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE Pacific Visualization Symposium</title>
				<meeting>IEEE Pacific Visualization Symposium</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="9" to="16" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Vivaldi: A domain-specific language for volume processing and visualization on distributed heterogeneous systems</title>
		<author>
			<persName><forename type="first">H</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">M</forename><surname>Quan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">G C</forename><surname>Hildebrand</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Pfister</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W.-K</forename><surname>Jeong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2407" to="2416" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Text-to-Viz: Automatic Generation of Infographics from Proportion-Related Natural Language Statements</title>
		<author>
			<persName><forename type="first">W</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-G</forename><surname>Lou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="906" to="916" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Analyza: Exploring Data with Conversation</title>
		<author>
			<persName><forename type="first">K</forename><surname>Dhamdhere</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">S</forename><surname>Mccurley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Nahmias</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sundararajan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of International Conference on Intelligent User Interfaces</title>
				<meeting>International Conference on Intelligent User Interfaces</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="493" to="504" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">DataTone: Managing ambiguity in natural language interfaces for data visualization</title>
		<author>
			<persName><forename type="first">T</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Dontcheva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Adar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">G</forename><surname>Karahalios</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Annual ACM Symposium on User Interface Software and Technology</title>
				<meeting>Annual ACM Symposium on User Interface Software and Technology</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="489" to="500" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Surface techniques for vortex visualization</title>
		<author>
			<persName><forename type="first">C</forename><surname>Garth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Tricoche</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Salzbrunn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Bobach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Scheuermann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Symposium on Visualization</title>
				<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="155" to="164" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Generic objective vortices for flow visualization</title>
		<author>
			<persName><forename type="first">T</forename><surname>Günther</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Theisel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Graphics</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1" to="11" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">The state of the art in vortex extraction</title>
		<author>
			<persName><forename type="first">T</forename><surname>Günther</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Theisel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Graphics Forum</title>
				<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="149" to="173" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">FlowNet: A deep learning framework for clustering and selection of streamlines and stream surfaces</title>
		<author>
			<persName><forename type="first">J</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1732" to="1744" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">spacy 2: Natural language understanding with bloom embeddings</title>
		<author>
			<persName><forename type="first">M</forename><surname>Honnibal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Montani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Convolutional Neural Networks and Incremental Parsing</title>
				<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Applying pragmatics principles for interaction with visual analytics</title>
		<author>
			<persName><forename type="first">E</forename><surname>Hoque</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Setlur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Tory</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Dykeman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="309" to="318" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">A lightweight tangible 3D interface for interactive visualization of thin fiber structures</title>
		<author>
			<persName><forename type="first">B</forename><surname>Jackson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">Y</forename><surname>Lau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Schroeder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">C</forename><surname>Toussaint</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">F</forename><surname>Keefe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2802" to="2809" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Creating evenly-spaced streamlines of arbitrary density</title>
		<author>
			<persName><forename type="first">B</forename><surname>Jobard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Lefer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eurographics Workshop on Visualization in Scientific Computing</title>
				<meeting>the Eurographics Workshop on Visualization in Scientific Computing</meeting>
		<imprint>
			<date type="published" when="1997">1997</date>
			<biblScope unit="page" from="43" to="56" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Interactive 3d visual analysis of atmospheric fronts</title>
		<author>
			<persName><forename type="first">M</forename><surname>Kern</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Hewson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Schätler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Westermann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Rautenhaus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1080" to="1090" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Semi-automatic vortex extraction in 4D PC-MRI cardiac blood flow data using line predicates</title>
		<author>
			<persName><forename type="first">B</forename><surname>Köhler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Gasteiger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Preim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Theisel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gutberlet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Preim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2773" to="2782" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Towards a aialogue system that supports rich visualizations of data</title>
		<author>
			<persName><forename type="first">A</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Aurisano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Di Eugenio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gonzalez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Leigh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Annual Meeting of the Special Interest Group on Discourse and Dialogue</title>
				<meeting>Annual Meeting of the Special Interest Group on Discourse and Dialogue</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="304" to="309" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Gotree: A grammar of tree visualizations</title>
		<author>
			<persName><forename type="first">G</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Mcguffin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Yuan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CHI Conference on Human Factors in Computing Systems</title>
				<meeting>CHI Conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="1" to="13" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">P4: Portable parallel processing pipelines for interactive information visualization</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">K</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K.-L</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1548" to="1561" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">P5: Portable progressive parallel processing pipelines for interactive data analysis and visualization</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">K</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K.-L</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1151" to="1160" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">P6: A declarative language for integrating machine learning in visual analytics</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">K</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K.-L</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="380" to="389" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">IGScript: An interaction grammar for scientific data presentation</title>
		<author>
			<persName><forename type="first">R</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CHI Conference on Human Factors in Computing Systems</title>
				<meeting>CHI Conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="1" to="13" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Natural language to visualization by neural machine translation</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Chai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Qin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">01</biblScope>
			<biblScope unit="page" from="217" to="226" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">A graph-based interface for visual analytics of 3D streamlines and pathlines</title>
		<author>
			<persName><forename type="first">J</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C.-K</forename><surname>Shene</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Jiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1127" to="1140" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">The stanford corenlp natural language processing toolkit</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Surdeanu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Bauer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Finkel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Bethard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Mcclosky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Association for Computational Linguistics: System Demonstrations</title>
				<meeting>the Association for Computational Linguistics: System Demonstrations</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="55" to="60" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">WordNet: a lexical database for english</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">A</forename><surname>Miller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="39" to="41" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">NL4DV: A toolkit for generating analytic specifications for data visualization from natural language queries</title>
		<author>
			<persName><forename type="first">A</forename><surname>Narechania</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Srinivasan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Stasko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="369" to="379" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">NL4DV: A toolkit for generating analytic specifications for data visualization from natural language queries</title>
		<author>
			<persName><forename type="first">A</forename><surname>Narechania</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Srinivasan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Stasko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">02</biblScope>
			<biblScope unit="page" from="369" to="379" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Detection and visualization of splat and antisplat events in turbulent flows</title>
		<author>
			<persName><forename type="first">B</forename><surname>Nsonga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Niemann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Fröhlich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Staib</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gumhold</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Scheuermann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on visualization and computer graphics</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="3147" to="3162" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Analysis of the near-wall flow in a turbine cascade by splat visualization</title>
		<author>
			<persName><forename type="first">B</forename><surname>Nsonga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Scheuermann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gumhold</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ventosa-Molina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Koschichow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Fröhlich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="719" to="728" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Topologically relevant stream surfaces for flow visualization</title>
		<author>
			<persName><forename type="first">R</forename><surname>Peikert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Sadlo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Spring Conference on Computer Graphics</title>
				<meeting>Spring Conference on Computer Graphics</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="43" to="50" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">ViSlang: A system for interpreted domain-specific languages for scientific visualization</title>
		<author>
			<persName><forename type="first">P</forename><surname>Rautek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bruckner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Groller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hadwiger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2388" to="2396" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Streamline embedding for 3D vector field exploration</title>
		<author>
			<persName><forename type="first">C</forename><surname>Rössl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Theisel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="407" to="420" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Vorticity based flow analysis and visualization for Pelton turbine design optimization</title>
		<author>
			<persName><forename type="first">F</forename><surname>Sadlo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Peikert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Parkinson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE Visualization Conference</title>
				<meeting>IEEE Visualization Conference</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="179" to="186" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Streamline predicates</title>
		<author>
			<persName><forename type="first">T</forename><surname>Salzbrunn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Scheuermann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1601" to="1612" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Vega-lite: A grammar of interactive graphics</title>
		<author>
			<persName><forename type="first">A</forename><surname>Satyanarayan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Moritz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Wongsuphasawat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Heer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="341" to="350" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Reactive vega: A streaming dataflow architecture for declarative interactive visualization</title>
		<author>
			<persName><forename type="first">A</forename><surname>Satyanarayan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Russell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hoffswell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Heer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="659" to="668" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Eviza: A natural language interface for visual analysis</title>
		<author>
			<persName><forename type="first">V</forename><surname>Setlur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">E</forename><surname>Battersby</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Tory</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Gossweiler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">X</forename><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Annual Symposium on User Interface Software and Technology</title>
				<meeting>Annual Symposium on User Interface Software and Technology</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="365" to="377" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Natural language interfaces for data analysis with visualization: Considering what has and could be asked</title>
		<author>
			<persName><forename type="first">A</forename><surname>Srinivasan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Stasko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eurographics/IEEE VGTC Conference on Visualization: Short Papers</title>
				<meeting>the Eurographics/IEEE VGTC Conference on Visualization: Short Papers</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="55" to="59" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Orko: Facilitating multimodal interaction for visual exploration and analysis of networks</title>
		<author>
			<persName><forename type="first">A</forename><surname>Srinivasan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Stasko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="511" to="521" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Articulate: A semi-automated model for translating natural language queries into meaningful visualizations</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Leigh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of International Symposium on Smart Graphics</title>
				<meeting>International Symposium on Smart Graphics</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="184" to="195" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Semantic flow graph: A framework for discovering object relationships in flow fields</title>
		<author>
			<persName><forename type="first">J</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">V</forename><surname>Chawla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">H</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="3200" to="3213" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">A vocabulary approach to partial streamline matching and exploratory flow visualization</title>
		<author>
			<persName><forename type="first">J</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C.-K</forename><surname>Shene</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Shaw</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1503" to="1516" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<author>
			<persName><forename type="first">H</forename><surname>Theisel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Friederici</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Günther</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2202.09566</idno>
		<title level="m">Objective flow measures based on few trajectories</title>
				<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Saddle connectors -an approach to visualizing the topological skeleton of complex 3D vector fields</title>
		<author>
			<persName><forename type="first">H</forename><surname>Theisel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Weinkauf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H.-C</forename><surname>Hege</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H.-P</forename><surname>Seidel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE Visualization Conference</title>
				<meeting>IEEE Visualization Conference</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="225" to="232" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Do what I mean, not what I say! design considerations for supporting intent and context in analytical conversation</title>
		<author>
			<persName><forename type="first">M</forename><surname>Tory</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Setlur</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Visual Analytics Science and Technology</title>
				<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="93" to="103" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Stream line-based pattern search in flows</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Esturo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Seidel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Weinkauf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics Forum</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="7" to="18" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
		<title level="m" type="main">ggplot2: Elegant graphics for data analysis</title>
		<author>
			<persName><forename type="first">H</forename><surname>Wickham</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016">2016</date>
			<publisher>Springer</publisher>
			<pubPlace>New York, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">A declarative grammar of flexible volume visualization pipelines</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Neuroth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Igouchkine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Aditya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K.-L</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1050" to="1059" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">DIVA: A declarative and reactive language for in situ visualization</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Neuroth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Igouchkine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Aditya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K.-L</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Symposium on Large Data Analysis and Visualization</title>
				<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="1" to="11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Verbs semantics and lexical selection</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Palmer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of annual meeting on Association for Computational Linguistics</title>
				<meeting>annual meeting on Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="1994">1994</date>
			<biblScope unit="page" from="133" to="138" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">An information-theoretic framework for flow visualization</title>
		<author>
			<persName><forename type="first">L</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T.-Y</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H.-W</forename><surname>Shen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1216" to="1224" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Flow web: A graph based user interface for 3D flow field exploration</title>
		<author>
			<persName><forename type="first">L</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H.-W</forename><surname>Shen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IS&amp;T SPIE Conference on Visualization and Data Analysis</title>
				<meeting>IS&amp;T SPIE Conference on Visualization and Data Analysis</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Strategy for seeding 3D streamlines</title>
		<author>
			<persName><forename type="first">X</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Kao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Pang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE Visualization Conference</title>
				<meeting>IEEE Visualization Conference</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="471" to="478" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">FlowSense: A natural language interface for visual data exploration within a dataflow system</title>
		<author>
			<persName><forename type="first">B</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">T</forename><surname>Silva</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="11" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
