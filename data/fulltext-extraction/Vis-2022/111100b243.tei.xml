<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Striking a Balance: Reader Takeaways and Preferences when Integrating Text and Charts</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Chase</forename><surname>Stokes</surname></persName>
						</author>
						<author>
							<persName><roleName>Member </roleName><forename type="first">Vidya</forename><surname>Setlur</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Bridget</forename><surname>Cogley</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Arvind</forename><surname>Satyanarayan</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Marti</forename><forename type="middle">A</forename><surname>Hearst</surname></persName>
						</author>
						<title level="a" type="main">Striking a Balance: Reader Takeaways and Preferences when Integrating Text and Charts</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.2" ident="GROBID" when="2023-03-27T09:18+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Visualization</term>
					<term>text</term>
					<term>annotation</term>
					<term>user preference</term>
					<term>takeaways</term>
					<term>design</term>
					<term>line charts</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Fig. 1. Information displays with varying amounts of visuals and text. (a) Chart presented with no text (beyond axes and ticks), (b) Chart with a title and a single annotation, (c) Chart which displays a narrative or story around the data, annotated through text, and (d) A text-only version of the data, with the same story as displayed in (c).</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Information visualization has been defined as "the use of computersupported, interactive, visual representations of abstract data in order to amplify cognition" <ref type="bibr" target="#b3">[4]</ref>. In research, visualization is often contrasted with alternative forms of presentation such as tabular or written descriptions. However, in reality, most charts are displayed with accompanying text in the form of titles, annotations, and captions. Designers include text with charts to convey the core message of the data, draw readers' attention to specific parts of the chart, and provide explanations that readers may be unlikely to identify on their own <ref type="bibr" target="#b29">[30]</ref>. Appropriate text can provide additional context, potentially increasing the aesthetic appeal of a chart <ref type="bibr" target="#b42">[44]</ref>.</p><p>Textual descriptions have been shown to be influential over the visual components of charts. Recent research has shown that the way a title is written can be the influencing factor on how a visualization is interpreted <ref type="bibr" target="#b27">[28]</ref> and that the textual component can be the most memorable part of a visualization in a memory task <ref type="bibr" target="#b1">[2]</ref>.</p><p>Although some recent research has acknowledged the important role that textual context plays in visualizations, there is currently little scientific understanding of the best qualities, quantities, and positions of textual content within charts and graphs. Additionally, information visualization studies often omit a text-only option when comparing charts <ref type="bibr" target="#b46">[48]</ref>, despite evidence that some people prefer text over charts in certain circumstances, such as in conversation with chatbots <ref type="bibr" target="#b13">[14]</ref>.</p><p>The goal of this paper is to further our understanding of the role of text in visualizations and provide guidelines for both designers and automated systems. We examine questions around how much text people prefer on a chart, what kind of text is useful to show in terms of the semantics of that text, and how its placement affects the chart reader's understanding of the underlying data.</p><p>Text is often presented using different semantic content, ranging from descriptions of the overall data, to specific visual features, to additional context to support framing the chart <ref type="bibr" target="#b34">[35]</ref>. It is not currently known what content is best shown in the title versus in an annotation positioned near the data. It is also not known how much is too much text or if charts can stand alone with almost no annotation.</p><p>This paper contributes a novel examination of the combination of text and charts in the context of visual analysis. By choosing a subset of a large design space, we examine relatively simple visualizations that offer a useful and nuanced examination of the rich space encompassing textual and visual communication. Our empirical studies find that readers prefer a combination of text and charts over charts alone, and that a sizable minority prefer text without visualization. Our results show that the choice of semantic content and placement of annotations can influence what the readers take away from the chart and how likely they are to use the annotations in their takeaways. We provide a set of guidelines to authors for choosing the type of content and determining its placement for making the intended message most salient.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK</head><p>Our work exploring how readers integrate text with charts builds on prior work examining text for visualizations through alternative text and textual descriptions, empirical results indicating the influence of text on the reader, and considerations from systems and applications of these two modalities to visual analysis and data storytelling.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Accessibility (Blind and Low Vision)</head><p>Text is a primary means for making visualizations accessible to people who are blind or have low vision (BLV). The W3C Web Accessibility Initiative (WAI), visualization practitioners, and publishers of accessible media have produced a variety of guidelines for what these textual representations (referred to as alternative text or alt text) should seek to convey, including the chart type, axes and labels, and summaries of the overall trends <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b51">53,</ref><ref type="bibr" target="#b53">55]</ref>. Building on these guidelines, Jung et al. surveyed and interviewed BLV people to find that alt text is often the only interface to the depicted data; poor quality text can increase inequities in information access <ref type="bibr" target="#b19">[20]</ref>. The researchers further recommended that alt text should be structured to ground the textual representation in the underlying data rather than the visualized elements to reduce readers' cognitive burden.</p><p>Most related to our work is a recent paper by Lundgard &amp; Satyanarayan that began to formalize the semantic content of textual descriptions of charts <ref type="bibr" target="#b34">[35]</ref>. They developed a conceptual model that spans four levels of semantic content: enumerating visualization construction properties (e.g., marks and encodings); reporting statistical concepts and relations (e.g., extrema and correlations); identifying perceptual and cognitive phenomena (e.g., complex trends and patterns); and elucidating domain-specific insights (e.g., social and political context).</p><p>In studies with sighted and blind participants, the researchers found that these reader groups differ significantly in which semantic content they ranked as most useful. While sighted participants generally preferred descriptions that offered high-level explanations and domainspecific context, blind readers ranked this content lower and instead favored either mid-level descriptions of statistical features or perceptual trends, and expressed bi-modal preferences for low-level details about the chart's construction. Our work expands the study of the impact of these semantic levels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Role of Text in Visualizations</head><p>Stokes and Hearst advocated for text to be considered co-equal to visualization, calling for researchers to devote attention to concerns of readability and integration between these two modalities <ref type="bibr" target="#b46">[48]</ref>. In this spirit, there is a growing body of work that explores the role that text plays in visual analysis and its importance for conveying key messages to the reader <ref type="bibr" target="#b39">[41]</ref>.</p><p>For instance, through eye-tracking studies, Borkin et al. <ref type="bibr" target="#b1">[2]</ref> found that participants fixated on and were more likely to recall the textual content of and around visualizations (including titles, labels, paragraphs, etc.). Kong et al. <ref type="bibr" target="#b27">[28,</ref><ref type="bibr" target="#b28">29]</ref> evaluated how titles can impact the perceived message of a visualization to find that participants were more likely to recall information conveyed by slanted framings (e.g., emphasizing only part of a chart's message) than the chart's visuals. Troublingly, participants only flagged the slanted framing if it was especially egregious (e.g., offering a contradictory message to the chart); more subtle framings escaped unnoticed despite shaping participants' takeaways.</p><p>In contrast to these results, Kim et al. found that readers are perhaps able to mediate misalignments between text and visualization <ref type="bibr" target="#b22">[23]</ref>. Through crowdsourced studies, they found that when both the chart and text described a high-prominence feature, readers treated the doubly emphasized high-prominence feature as the takeaway. When the text described a low-prominence chart feature, readers relied on the chart and usually reported a higher-prominence feature as the takeaway.</p><p>Work by Mayer in multimedia communication provided rigorous empirical support for fifteen theory-based effects of how people learn from the combination of words and images <ref type="bibr" target="#b35">[36]</ref>. One of these was the "multimedia effect", the hypothesis that people can learn more deeply from the combination of words and images together than either alone. This work and other studies have shown that text placed in spatial proximity to explanatory images can reduce cognitive load <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b57">59]</ref>.</p><p>However, in the context of information visualization, this combination of words and images is not always preferred by a reader. Hearst &amp; Tory examined participant preferences for visualizations in conversation with chatbots <ref type="bibr" target="#b13">[14]</ref>. They found a large split in participant preferences, with almost half of the readers preferring not to see charts. For those who did prefer to see charts, they also preferred to view additional contextual data in the chart. The role of overall preference for textual or visual communication has been shown to influence reader preferences for a combination of the two and therefore, should be accounted for in this study as well.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Visualization + Text for Analysis and Storytelling</head><p>Researchers are increasingly exploring how to leverage the affordances of natural language text during visual analysis <ref type="bibr" target="#b45">[47]</ref>. For instance, systems like Articulate <ref type="bibr" target="#b48">[50]</ref>, DataTone <ref type="bibr" target="#b11">[12]</ref>, and Eviza <ref type="bibr" target="#b43">[45]</ref> demonstrate that the familiarity of natural language can provide a shallower on-ramp to visual analysis, and the ambiguity of these statements can be used to rapidly suggest candidate visualizations. Subsequent work also explored how pragmatics <ref type="bibr" target="#b16">[17]</ref>, and question-answering pipelines <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b21">22]</ref> can aid in a more conversational interaction model.</p><p>Besides serving as input or output for visual analysis, systems have begun to incorporate natural language-generated text along with their visualization responses to help describe key insights to the user. For example, a variety of research systems <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b38">40,</ref><ref type="bibr" target="#b41">43,</ref><ref type="bibr" target="#b44">46]</ref> and tools such as Tableau's Summary Card <ref type="bibr" target="#b49">[51]</ref>, and Power BI <ref type="bibr">[38]</ref> produce natural language captions that summarize statistics and trends depicted by the chart.</p><p>Data storytelling weaves data, textual narratives, and visuals together for sharing and communicating insights that are more memorable, persuasive, and engaging than statistics alone <ref type="bibr" target="#b29">[30,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b42">44]</ref>. With the growing recognition of using both text and charts for data storytelling, there is an added challenge of helping readers synthesize information from both these pieces of information in documents, especially when they are spatially separated.</p><p>Systems like Kori <ref type="bibr" target="#b30">[31,</ref><ref type="bibr" target="#b31">32]</ref> and VizFlow <ref type="bibr" target="#b47">[49]</ref> provide explicit linking strategies between the two modalities following design patterns that have emerged for data storytelling, narrative sequencing, and rhetoric <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b18">19]</ref>. While these systems demonstrate the utility of designing text and charts together, it is still unclear how to balance between the two modalities (e.g., is too much or too little text still useful?). Our work probes these research questions and provides design implications for future systems for jointly authoring text and visualization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">STUDY</head><p>In this study, we utilize the framework from Lundgard &amp; Satyanarayan <ref type="bibr" target="#b34">[35]</ref> which describes four semantic levels:</p><p>• Semantic Level 1 (L1): The first level consists of elemental or encoded aspects of the chart, such as the overall topic or a description of the content of an axis. For example, in Figure <ref type="figure">1</ref>, "President approval rating over 5 years <ref type="bibr">(2015)</ref><ref type="bibr">(2016)</ref><ref type="bibr">(2017)</ref><ref type="bibr">(2018)</ref><ref type="bibr">(2019)</ref><ref type="bibr">(2020)</ref>."</p><p>• Semantic Level 2 (L2): The second level consists of statistical or relational components, such as a comparison between two points or identification of extrema. For example, in Figure <ref type="figure">1</ref>, "Maximum".</p><p>• Semantic Level 3 (L3): The third level describes perceptual or cognitive aspects, such as an overall pattern or changes in trend. For example, in Figure <ref type="figure">1</ref>, "Steep fall slows to a steady decrease." Fig. <ref type="figure">2</ref>. Stimuli creation process. Annotations were written and placed based on the components of the chart, which were identified as visually salient using the method from Kim, Setlur, &amp; Agrawala <ref type="bibr" target="#b22">[23]</ref>. The initial chart is shown in (a). In (b), red indicates the most visually salient feature, green the second, and blue the third. In (c), paper authors created potential annotations for each salient region at each level L2-L4. L1 cannot refer to a part of the chart identified as salient, but as shown in (d), it can refer to different areas of the chart (axis, trend, and title). A 'trend' placement referred to an annotation that describes the line as a whole. L2-L4 can each be placed in the same positions, as shown in (e); they can be expressed in a point, a trend, or as the title. In step (f), an expert designer adjusted the fine details to produce a chart with a realistic layout.</p><p>• Semantic Level 4 (L4): The fourth level provides external context to the chart, such as past events which affect the topic depicted. For example, in Figure <ref type="figure">1</ref>, "President starts popular initiatives against child hunger".</p><p>We explore three primary research questions and their corresponding hypotheses, using these four semantic levels as a way to examine the content of an annotation for RQ2 and RQ3: RQ1: What are readers' preferences when viewing charts with different amounts of text? To investigate this question, participants ranked charts with varying amounts of text, including an all-text paragraph. We hypothesized the following:</p><p>• H1a: Readers with an overall preference for visual information will prefer charts with annotations compared to the all-text variant. • H1b: Readers with an overall preference for textual information will prefer the all-text variant compared to charts with little or no text. • H1c: Readers with an overall preference for visual information will prefer charts with fewer annotations. • H1d: Readers with an overall preference for textual information will prefer charts with a greater number of annotations.</p><p>In investigating these hypotheses, we created two sets of ranking stimuli. The first encompassed the 'extremes' within the range from text to visual. This included a chart with no text (except axes) to a text paragraph with no chart (see Figure <ref type="figure">1</ref>). The second set of stimuli examined more fine-grained differences, ranging from a chart with only a title to a chart with a title and two annotations (see Figure <ref type="figure" target="#fig_0">3</ref>). RQ2: How do the different semantic levels of text affect the type of information included in readers' takeaways? Further, when do readers include information in their takeaways that are not found either in the chart or the text? Which semantic levels of text do readers rely on when they form their takeaways?</p><p>Hypotheses were as follows:</p><p>• H2a: Readers' takeaways will be more likely to contain a given semantic level if the text accompanying the chart also contains that semantic level. This will be true for all semantic levels. • H2b: Readers will be more likely to include information in their takeaways that is not found in the chart or text when L1 is present in the chart. • H2c: Readers will self-report as relying less on text when the text contains L1. • H2d: Readers' will self-report as relying more on text when the text contains L4. • H2e: Readers with an overall preference for textual information will rely more on text within a chart. The feature mentioned in captions influences the amount of reader takeaways focused on a particular feature. This effect is greater when the caption includes external information (i.e., L4) <ref type="bibr" target="#b23">[24]</ref>. L1 content, on the other hand, provides the most basic information about a chart. These components motivate hypotheses H2a-H2d. Since there is evidence that readers with a lower preference for charts overall prefer to receive information through text <ref type="bibr" target="#b13">[14]</ref>, we also hypothesize that they will rely more on the textual information (H2e).</p><p>RQ3: How does the placement of text affect how the reader integrates the text with the chart? Our hypothesis was:</p><p>• H3: Readers' takeaways will be most likely to contain a given semantic level if the text containing that semantic level is positioned as a title.</p><p>When readers view a chart, they first focus on the title before moving to other textual components or the data <ref type="bibr" target="#b1">[2]</ref>. We hypothesized this position would then be the most likely for the reader to use in a takeaway.</p><p>To investigate research questions 2 and 3, participants were asked to inspect a chart with varying annotations at varying semantic levels and then provide up to three takeaways. To test these hypotheses, we designed the stimuli to systematically vary the content and location of the textual annotations. Charts displayed in this section contained either a title alone or a title with a single annotation. The semantic levels of the text content varied. See Section 3.2 for further information on development of the stimuli.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Participants</head><p>To determine the proper sample size for this study, we conducted a power analysis with G*Power <ref type="bibr" target="#b7">[8]</ref>. Based on a logistic regression with an odds ratio of 1.5 and a desired power of 0.8, the proper sample size (post exclusions) was 297, with an alpha level of 0.05. This sample size also accommodates the amount recommended from an additional power analysis on a Friedman's test.</p><p>Based on this information, we recruited 512 participants from Amazon Mechanical Turk. In order to qualify for the study, participants were required to be located in the United States and to have a 95% acceptance rate on previous tasks. We also required that they be fluent in English and complete the survey on a desktop or laptop device. We compensated participants at a rate of $15 per hour. This resulted in a $3.50 compensation for a 14-minute survey, which was raised to $4.00, due to a longer survey time than estimated. We employed comprehension checks in the first block of the survey, described further in Section 3.3. Participants were not permitted to take the survey multiple times.</p><p>After excluding participants who failed the comprehension checks as well as any who provided extremely low-quality responses (e.g., takeaways that were either unintelligible or off-topic), we ended up with 302 participants. On average, participants were 35-44, and most had completed a 4-year degree. On a scale from 1 (overall preference for textual communication) and 6 (overall preference for visual communication) <ref type="bibr" target="#b12">[13]</ref>, participants had an average score of 4.06 across the measures used (details in Section 3.3).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Stimuli</head><p>All stimuli used in this study were univariate line charts, adapted from Kim et al. <ref type="bibr" target="#b22">[23]</ref>. We considered univariate line charts for our work because they are among the most common basic charts, and because these charts contain temporal features that can be easily annotated, making them useful for exploring our hypotheses. A subset of nine charts from the original paper was selected to keep the overall design space tractable. These charts contained at most two trends (up, down, or flat), with a single feature in the positive direction. The full set of charts selected can be seen in Figure <ref type="figure" target="#fig_1">4</ref>. This design space ensured relatively realistic global shapes with sufficient variation in the stimuli while maintaining enough blank space on the chart in which to situate textual and visual annotations. We added aesthetic design updates to the charts, including lightening the gridlines and axis ticks. The data line itself was also darkened. These aesthetic changes were completed to align the stimuli to best practices as defined by practitioner guidelines <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b26">27]</ref>, therefore imitating real-world professional charts. Advice and design style was provided by a paper author who is an expert visualization designer. To provide context to the charts, we labeled the x-axis with time unit values implying that the chart represents a time series. Specifically, we selected the start and end of the x-axis from the set of years 1900, 1910, 1920,..., 2020. To label the y-axis, we randomly chose a set of domains for the y-axis and its value range from the MassVis dataset <ref type="bibr" target="#b2">[3]</ref>.</p><p>For each chart in the stimuli set, we also included an all-text variant, as advocated for by Stokes &amp; Hearst <ref type="bibr" target="#b46">[48]</ref>. Three authors created textual descriptions of the chart, incorporating the additional information chosen to accompany the chart. These three versions were then discussed and synthesized into a single paragraph with feedback from all authors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1">Annotation content</head><p>We wrote four possible textual annotations to be added to each chart. Each of the four annotations per chart contained information from one of the semantic levels outlined by Lundgard &amp; Satyanarayan <ref type="bibr" target="#b34">[35]</ref> as described at the beginning of this section.</p><p>These annotations were written by two authors to ensure that the semantic content was consistent with the descriptions for each of the four semantic levels. Annotations were not computationally generated; especially for L3 and L4, we wanted to ensure that the annotations reflected "natural sounding" language, as required by the definitions of those levels.</p><p>The annotation content was written based on the visually salient features in the line charts, as shown in Figure <ref type="figure">2</ref>. Additionally, the external context of L4 annotations was created with reference to Wikipedia articles pertaining to the topic of each chart to create plausible commentary <ref type="bibr" target="#b54">[56]</ref>. Identification of these visually salient features was computed using crowdsourced data from Kim et al. <ref type="bibr" target="#b22">[23]</ref>.</p><p>Saliency mapping utilized mouse input information for bounding boxes that participants from <ref type="bibr" target="#b22">[23]</ref> drew around features that they identified as the top three visually prominent features in the line charts. Given that the stimuli were time-series line charts, we aggregated all of the feature bounding boxes by projecting each box onto the x-axis containing time values, to form a 1D interval. We then weighted each interval inversely proportional to the ranking provided by the crowdsourced data. We then multiplied the weight assigned to each interval by a Gaussian factor centered at the interval and with standard deviation set to half the width of the interval. Summing all of the Gaussian weighted intervals, we obtained the top three visually salient regions for each line chart stimulus.</p><p>The visual salience of each semantic level was counterbalanced between the nine selected charts, such that each semantic level had the same average visual salience across the stimuli set. However, L1 did not refer to any particular point or area within the data and so could not be mapped to visually salient features. This counterbalancing was only completed for L2-L4. More detail about the stimuli creation process is shown in Figure <ref type="figure">2</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2">Annotation appearance and position</head><p>Annotations were added to the line charts with the aforementioned visually salient features. The progression from a blank chart through the full set of possible annotations can be seen in Figure <ref type="figure">2</ref>. Design practices include standard conventions <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b50">52,</ref><ref type="bibr" target="#b55">57]</ref> to prioritize focus on the line. The line color was selected to blend in with the blue used elsewhere in the survey instrument without creating a visual artifact for users with astigmatism <ref type="bibr" target="#b33">[34]</ref>. All text met at least AA guidelines under WCAG 2.0 testing <ref type="bibr" target="#b52">[54]</ref>. The placement of the annotations was guided by the following design guidelines. The overall placement of the annotations was counterbalanced across the set and between the four semantic levels. For example, each semantic level was positioned in the title or subtitle position three times. These stimuli and their annotations went through several rounds of iteration through the processes in Figure <ref type="figure">2</ref>.</p><p>An additional chart variant was created to convey the same story as the all-text variant, to preserve dynamic equivalence <ref type="bibr" target="#b36">[37]</ref>. Any additional information provided in the all-text variant, such as a current event or emphasized feature, was added in the form of an annotation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Method</head><p>Participants completed a survey with five main sections. The full survey flow can be seen in Figure <ref type="figure" target="#fig_3">5</ref>. First, participants were introduced to the study and the terminology used throughout the survey. They were instructed in how to apply the terms axis, visual, and text, with text deconstructed into title and annotation. They were then asked to answer 1-2 questions to check for understanding and were provided with an illustration of the terminology after each question. Those who answered the first question correctly were not asked the second question. If both comprehension checks were missed, the survey ended.</p><p>After this introduction, participants went on to complete the first set of ranking tasks. They were instructed: "In the next section, you will rank two sets of images. During this section, keep in mind the following instructions. Rank the images in the order you would prefer to encounter or see them. You can rank by dragging and dropping the subsequent images into a rank." The ranking tasks within this survey were designed to elicit user preferences for the amount of text paired with a chart. Prior to completing the ranking, participants viewed each stimulus individually and answered a free-response question about the qualities of the information presentation which they liked and those which they disliked.</p><p>The stimuli for the first set of charts (Set A) consisted of four items: a chart with only axis labels and tick marks (no-text), a chart with a title and an annotation (title-annotation1), a chart with a story or narrative about the data annotated (annotation+), and a paragraph of text which described the chart shown (all-text). In set A, we aimed to capture preferences for the 'extremes' between an (almost) entirely visual presentation of information and an entirely textual presentation. The second set of charts (Set B) consisted of three charts: one with only a title (title-only), title-annotation1, and a chart with a title and two annotations (title-annotation2). With this set, we examined a more detailed variation in the number of annotations, progressively increasing it within the set. Specific chart combinations within sets were also selected to best counterbalance between annotation position and content.</p><p>Following the ranking task, participants went on to complete a second comprehension check, which also provided them with some training on our definition of 'takeaway'. Takeaways were defined as "a key fact, point, or idea to be remembered after viewing the chart." In this filter task, participants were shown a chart and five example takeaways that could be drawn from the chart. Three of the five were true statements about the chart, while two were false. Participants were instructed to select those which were true. If the participant selected any options which were incorrect, their survey ended, they did not go on to the following sections, and their data was discarded.</p><p>If they selected the correct options, participants moved on to the takeaway section of the survey. In this section, participants were shown a chart and told that they would be asked to report takeaways on the following page. They were also informed that they would not be able to go back and view the chart after moving on. They selected a button to indicate they were ready to move forward.</p><p>On the page following the image of the chart, participants were asked to provide their takeaways. They were required to provide at least one but had the option to provide up to three takeaways. They were also asked to rate "Which aspect of the information did you rely on when listing your takeaways?" on a scale from 1 ("entirely text") to 5 ("entirely visual").</p><p>The fourth section of this survey was a subjective measure of graphical literacy <ref type="bibr" target="#b12">[13]</ref>. Garcia-Retamero et al. tested this subjective assessment of graphical literacy and compared its performance to an objective measure <ref type="bibr" target="#b9">[10]</ref>, finding similar and substantial predictive power. The measure also assesses preference, which is a key and central question of this paper. The measure has subsequently been used in other studies as a measure of graphical literacy <ref type="bibr" target="#b37">[39,</ref><ref type="bibr" target="#b56">58]</ref>.</p><p>Within this measure, participants were asked to report how good they considered themselves to be at working with different chart types, such as line, bar, and pie charts. They were also asked questions regarding their preference for textual or visual information, such as "When reading books or newspapers, how helpful do you find charts that are part of a story?" and "To what extent do you believe in the saying 'a picture is worth one thousand words'?". We added an additional question to this section, "To what extent do you believe in the saying, 'Reading expands the mind'?" to add a text-focused counterpart to the "thousand words" image-focused question.</p><p>Finally, participants completed the demographic section. Here, they reported their age range (e.g., <ref type="bibr" target="#b17">[18]</ref><ref type="bibr" target="#b18">[19]</ref><ref type="bibr" target="#b19">[20]</ref><ref type="bibr" target="#b20">[21]</ref><ref type="bibr" target="#b21">[22]</ref><ref type="bibr" target="#b22">[23]</ref><ref type="bibr" target="#b23">[24]</ref>, their current education level (e.g., "Less than high school"), and their experience with charts and reading. This experience was captured through both the frequency (e.g., "Every day") as well as the context in which they engaged with the material (e.g., Government reports). For reading, we inquired about the frequency of both short-form reading (e.g., text messages, tweets) as well as long-form (e.g., books, magazines).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">RESULTS</head><p>In this section, we provide results for research questions RQ1 -RQ3. Each research question is assessed in terms of a set of hypotheses as enumerated in Section 3. Analysis plans were preregistered on OSF. <ref type="foot" target="#foot_0">1</ref>Visual vs. Textual Preferences. Hypotheses below compare participants with an overall preference for visual information (the VISUAL group) and those with an overall preference for textual information (the TEXTUAL group). To calculate a preference score for each participant, we summed the Likert ratings for questions included in the measure of graphical literacy <ref type="bibr" target="#b12">[13]</ref> as well as questions regarding the frequency of reading text and viewing charts included in the demographics section.</p><p>Participants with scores in the top 25% of the set were placed in the VISUAL group, and those with scores in the bottom 25% were placed in the TEXTUAL group. Because we were primarily interested in participants with a distinct preference for visual or textual information, we did not place the middle 50% of the set into either group. These participants were not examined for the hypotheses that compared preferences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">RQ1: Preferences for Amount of Text</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>RQ1 asks: what are readers' preferences when viewing charts with different amounts of text?</head><p>Summary of Findings: Overall, we found a strong preference for the charts with a greater number of annotations. For both sets ranked, the highest performing stimulus was the chart with the most annotations. They rated the no-text variant or title-only variant consistently lowest. Further discussion on preferences for other variants can be found in Section 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Details of Analysis:</head><p>To examine this question more closely, we completed Friedman's tests for the rank-order data. We performed post-hoc Nemenyi's tests to examine pairwise comparisons <ref type="bibr" target="#b40">[42]</ref>, shown in Tables <ref type="table" target="#tab_3">2 and 3</ref>. Overall relative stimuli rankings can be seen in Figure <ref type="figure">6</ref>.</p><p>In both ranking tasks, the charts with the most annotations were ranked highest overall. In Ranking Set A, the annotation+ variant was highest ranked across VISUAL and TEXTUAL participant groups. For the TEXTUAL group, title-annotation1 did not differ from the textual paragraph. The sparse charts with minimal annotations ranked lowest across conditions -participants least preferred the no-text variant from Set A and the title-only variant from Set B. Fig. <ref type="figure">6</ref>. Ranking task results, shown for all participants (Overall) as well as the VISUAL and TEXTUAL groups. Pairwise significance can be seen in Tables <ref type="table" target="#tab_3">2 and 3</ref>. Lines within columns indicate statistically significant differences between average rankings (* = 0.05, ** = 0.01). (a) Ranking set A ('extremes'). Possible values range from 1 (ranked first) to 4 (ranked last). (b) Ranking set B ('fine-grained'). Possible values range from 1 (ranked first) to 3 (ranked last).</p><p>Hypotheses 1a and 1b refer to the rankings of the 'extremes', shown in Figure <ref type="figure">1</ref>, while 1c and 1d refer to the 'fine-grained' rankings, shown in Figure <ref type="figure" target="#fig_0">3</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.1">H1a, b: Preferences Compared to All-Text</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>H1a: Readers with an overall preference for visual information will prefer charts with annotations compared to the all-text variant.</head><p>This hypothesis was supported (χ 2 = 151.15, df = 3, p &lt; 0.01). For the VISUAL group, annotation+ variant received the highest average rating (1.37), while the all-text and no-text variants received the lowest rating (3.21, 3.23).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>H1b: Readers with an overall preference for textual information will prefer the all-text variant compared to charts with little or no text.</head><p>This hypothesis was partially supported. Overall, the average rankings for the stimuli differed (χ 2 = 50.962, df = 3, p &lt; 0.01). For the TEXTUAL group, the all-text variant (2.42) did not significantly differ from the title-annotation1 variant (2.41). Therefore, there was no significant difference between all-text and a chart with little text. However, the no-text chart was rated lowest <ref type="bibr">(3.24)</ref>. So, we find partial support for this hypothesis in comparison to the no-text.</p><p>Although most participants ranked the annotation+ chart in Ranking Set A highest, data also show that a substantial minority -42, or 14% of participants -ranked the all-text option as their first choice for Set A. Of these, 25 are identified by our analysis as TEXTUAL, 5 as VISUAL preferred. One author examined the comments participants made when discussing the all-text variant. Seven of these 42 participants indicated that they had a general preference for text over charts. Other reasons included the text being perceived as clearer, more understandable, and/or providing a better explanation <ref type="bibr" target="#b12">(13)</ref>, providing a better story or more interesting context (4), or more precise, concrete, or thorough <ref type="bibr" target="#b8">(9)</ref>. A few <ref type="bibr" target="#b14">(15)</ref> participants ranked the no-text chart highest. The most common reasons given were simple / easy to understand (9), clean/lack of clutter <ref type="bibr" target="#b4">(5)</ref>, and allowing the viewer to draw their own conclusions (4).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.2">H1c, d: Preferences For Quantity of Annotations</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>H1c: Readers with an overall preference for visual information will prefer charts with fewer annotations.</head><p>This hypothesis was not supported, though the average rankings of stimuli did differ (χ 2 = 75.25, df = 2, p &lt; 0.01). The VISUAL group most preferred charts with the greater number of annotations, rather than those with fewer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>H1d: Readers with an overall preference for textual information will prefer charts with a greater number of annotations.</head><p>This hypothesis was supported, as results were similar to the VI-SUAL group (χ 2 = 21.24, df = 2, p &lt; 0.01). The TEXTUAL group also most preferred charts with the greater number of annotations, rather than those with fewer.</p><p>Table <ref type="table">1</ref>. Detailed data about takeaways and viewed annotations, by semantic level. The rows, from top to bottom, show the total number of takeaways produced in each level, the number of annotations viewed for each level, the number of takeaways produced in each level after viewing an annotation in the given level, and the number of takeaways which matched the annotations at each level. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>L1</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">RQ2: Semantic Levels and Takeaways</head><p>RQ2 asks: How do the different semantic levels of text affect the type of information included in readers' takeaways? Further, when do readers include information in their takeaways that are not found either in the chart or the text? Which semantic levels of text do readers rely on when they form their takeaways?</p><p>Summary of Findings: Through the following analyses, we found that participants' takeaways were overall influenced by the annotations present and influenced by some semantic levels more than others. Specifically, annotations belonging to L2 and L4 had the greatest influence on the participants' takeaways, followed by L3. L1 annotations had almost no effect, in part because participants made very few L1 takeaways. Overall, participants were most likely to provide L3 takeaways. When provided with an L4 annotation in the chart, participants were more likely to include their own knowledge or experience, though they rarely did this. The semantic level of the annotation text did not affect the degree to which participants relied upon the text.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Details of Analysis:</head><p>Prior to investigating the hypotheses, two authors independently coded participant takeaways for the semantic level of the takeaway, whether the takeaway was a match to any of the provided annotations in the chart viewed, and whether the participant incorporated any information not contained in the chart and the text provided (e.g., a real-world event). In order to be considered a "match", the takeaway should contain exact or similar language as used in the annotation provided. If a takeaway contained language belonging to more than one semantic level, the higher semantic level "trumped" the lower level. The takeaway was then assigned the higher level (e.g., converting L2 to L3). This method follows the process used by Lundgard &amp; Satyanarayan <ref type="bibr" target="#b34">[35]</ref>.</p><p>Overall, inter-rater reliability was 0.818 (Kappa = 0.815 for takeaway level, Maxwell's RE = 0.727 for match, and Maxwell's RE = 0.912 for external information) <ref type="bibr" target="#b10">[11]</ref>. A third author coded the conflicts and resolved all but four, which were then discussed amongst the coders.</p><p>Overall, participants provided 736 takeaways. On average, each participant wrote 1.83 takeaways. We did not instruct participants to provide takeaways in any particular order and did not treat takeaways differently depending on how many the participant provided.</p><p>Participants provided 48 takeaways classified as L1, 132 classified as L2, 446 classified as L3, and 110 classified as L4. 245 of the 736 total takeaways (33.3%) matched the annotations provided in the chart. Further information on the takeaway levels can be found in Table <ref type="table">1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1">H2a: Semantic Alignment between Text and Takeaways</head><p>H2a: Reader takeaways will be more likely to contain a given semantic level if the text accompanying the chart also contains that semantic level. This will be true for all semantic levels.</p><p>To examine 2a, we used logistic regression to analyze the relationship between the presence of different semantic levels of text on the chart and the semantic level of the reader's takeaway. We found partial support for this hypothesis.</p><p>An example of an L1 takeaway is, "The date range was 1960 to 2020," (P68). As mentioned previously, L1 takeaways were relatively uncommon. There were no significant influences on what semantic level of annotation may predict an L1 takeaway. So, H2a was not supported for L1.</p><p>An example of an L2 takeaway is, "Sports game attendance was lower than 5000 around 2009," (P75). Participants were more likely to make takeaways containing L2 when they had viewed a chart that provided an L2 annotation, compared to all other semantic levels. They were 1.6 times as (hereafter 1.6x) likely to provide an L2 takeaway when they were provided an L2 annotation than when they were shown an L1 annotation (95% CI: [1.06, 2.40], p &lt; 0.05), 2.0x likely compared to L3 ([1.29, 2.95], p &lt; 0.01), and 1.8x likely compared to L4 ([1.44, 2.22], p &lt; 0.01). In summary, L2 takeaways were most likely to occur when the chart itself included L2 annotations. Therefore, H2a is supported for L2.</p><p>An example of an L3 takeaway is, 'The national debt fell steeply in the early 90s before quickly rising to an all-time high," (P4). L3 takeaways were the most frequently provided by participants overall. Participants were 2.2x as likely to provide an L3 takeaway when they were provided L3, in comparison to when they were provided L4 ([1.59, 3.05], p &lt; 0.01). Comparisons to other annotation levels did not affect the likelihood of making an L3 takeaway. Specifically, after seeing an L3 annotation, participants were not more likely to make an L3 takeaway compared to when they saw an L1 or L2 annotation.</p><p>Overall, participants provided mostly L3 takeaways. H2a is partially supported for L3, as the presence of an L3 annotation made it more likely that the participant would make an L3 takeaway, but not in comparison to all semantic levels.</p><p>An example of an L4 takeaway is, "The tech boom in the early 1980s lead to a huge increase in median household incomes," (P215). Participants were significantly more likely to make L4 conclusions when they were provided with an L4 annotation: 6.1x as likely than when provided with L1 ([3.82, 10.19], p &lt; 0.01); 6.2x as likely than when provided with L2 ([3.85, 10.11], p &lt; 0.01); 3.2x as likely than when provided with L3 ([2.16, 4.79], p &lt; 0.01). L4 takeaways were most likely to occur when the chart itself included L4 annotations. Therefore, H2a is supported for L4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2">H2b: L1 Content and External Takeaways</head><p>H2b: Readers will be more likely to include information in their takeaways that are not found in the visual information or text when L1 is present in the chart.</p><p>To examine 2b, we used logistic regression to analyze the relationship between the presence of different semantic levels of text on the chart and the existence of external information in the participant's takeaway. This hypothesis was not supported. Readers were more likely to include external information when L4 was present in the chart, compared to L1 ([1.15, 72.73], p &lt; 0.05). However, there were very few takeaways that incorporated external information, as indicated by the extremely wide confidence interval. It remains unclear what kinds of annotations may encourage readers to include external information in their takeaways, but it was done infrequently in this case.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.3">H2c, d, e: Preferences and Reliance on Visual vs. Text</head><p>H2c: Readers will self-report as relying less on text when the text contains L1. H2d: Readers' will self-report as relying more on text when the text contains L4. H2e: Readers with an overall preference for textual information will rely more on text within a chart.</p><p>To examine hypotheses 2c-e, we performed a one-way ANOVA with post-hoc testing with Bonferroni correction. Reliance on textual and visual components of the chart was reported by participants on a 5-point Likert scale, where 1 indicated complete reliance on text and 5 indicated complete reliance on visual components. Hypotheses 2c-d were not supported. Although there were differences between self-reported reliance on text between semantic levels (F = 5.81, p = 0.016, df = 1), follow-up pairwise testings with Bonferroni correction were not significant (p &gt; 0.05). Average reliance ratings can be seen in Table <ref type="table" target="#tab_4">4</ref>. There was a difference between the TEXTUAL and VISUAL groups; H2e was supported. The TEXTUAL group reported they relied more on the text in the chart <ref type="bibr">(3.53)</ref> than the VISUAL group (3.87, Bonferroniadjusted p = 0.012).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">RQ3: Effect of Text Placement on Takeaways</head><p>RQ3 asks: How does the placement of text affect how the reader integrates the text with the chart? Summary of Findings: Overall, the role of the placement of text varied between semantic levels. Participants were most likely to match the L3 annotation provided when it was in the 'title' position, but this effect was not true for any other level. For the other three levels, participants were more likely to match the annotation when the text was closer in proximity to the chart. For L1, this meant being anchored to one of the chart axes. For both L2 and L4, this meant being anchored to a specific point on the chart, accompanied by a visual annotation of the point.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Details of Analysis:</head><p>The method for qualitatively coding the 'position' of an annotation varied from that which was preregistered. In the preregistration, the chart was divided into quadrants (e.g., top left), and the annotations were assigned a position based on their physical position on the chart. However, the precise physical position is not as relevant to this paper as the semantic position (e.g., as a title). Therefore, we analyze the positions coded as follows.</p><p>Each annotation was assigned a 'position' during the stimuli creation stage to ensure counterbalancing of the title position. For L1, other possible positions included 'axis', with the annotation in a gray box next to the x-or y-axis, as well as 'trend', for which the annotation was positioned in an unanchored callout box. For L2-L4, positions also included 'trend,' in which the text was positioned next to an arrow or a gray band highlighting the relevant years. These levels were also positioned as a 'point', which marked the point of interest with a dot matching the line in color.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.1">H3: Position and Match of Takeaway</head><p>H3: Readers' takeaways will be most likely to match a given semantic level if the text containing that semantic level is positioned as a title.</p><p>To examine H3, we used logistic regression to analyze the relationship between the position of different semantic levels of text on the chart and whether the reader's takeaway was a match to the annotation provided in the chart. We found partial support for this hypothesis.</p><p>For takeaways that matched the L1 annotations, participants were most likely to match their takeaways to the annotation when it was positioned by an axis in the chart rather than as a title. In fact, they were 11.3x as likely to match the annotation when it was positioned as an axis than when it was a title <ref type="bibr">([3.18, 40</ref>.01], p &lt; 0.01). So, this hypothesis was not supported for L1 takeaways. Titles were matched less often, while axis comments were matched most often.</p><p>Participants were most likely to match the L2 annotations when they were positioned as points rather than titles. They were 2.0x as likely to match the annotation as a point than as a title ([1.00, 3.98], p = 0.485). Thus, H3 was also not supported for L2 takeaways.</p><p>L3 takeaways, on the other hand, were most likely to be matched by participant takeaways when they were positioned as the title. They were 0.49x as likely to be matched when positioned as a point compared to positioned as a title ([0.380, 0.620], p &lt; 0.01) and 0.38x as likely when comparing annotations positioned as a trend to those as a title ([0.293, 0.506], p &lt; 0.01). H3 was supported for matched L3 annotations.</p><p>In continuation of the overall trend, L4 takeaways were most likely to match when they were positioned as points, rather than as titles. Participants were 1.9x as likely to match the L4 annotation provided by the chart when it was positioned in the role of a point, compared to that of a title <ref type="bibr">([1.11, 3.22]</ref>, p = 0.018).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">DISCUSSION</head><p>This paper explores the effects of text placement and the various semantic levels on readers' preferences and takeaways. We discuss findings from our study and identify themes that support a better understanding of chart and text integration, along with practical guidelines for visualization tools and authoring practices. We use the notation P# when referring to participants in the discussion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Preferences for annotation</head><p>General guidelines for information sharing and presentation have shied away from adding too much text to imagery at the risk of overwhelming the viewer or not conforming to good design practices <ref type="bibr" target="#b50">[52]</ref>. However, our study shows that more annotation was not penalized and was, in fact, often preferred. Readers liked the blend of text with charts, ranking charts annotated with more text higher than their sparser counterparts. P10 indicated that, although they found the paragraph of text helpful, "the visuals of the graph + text allow me to more quickly assess the information." P31 called the combination "the best of both worlds."</p><p>Charts with the most annotations were especially preferred by those with preferences for visual information. P158 commented, "I think all the extra facts and text on the chart are excellent ways to help people really know what's going on in the chart." P45 expressed that, "the chart that combines both visual and written information... helps the widest variety of learning styles to understand the chart."</p><p>This result runs counter to concerns about the potential for such annotations to make the visual components of the chart appear cluttered. Many participants noted that they preferred the charts with more annotations despite the fact that they might appear more cluttered.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Preferences for text</head><p>Additionally, a non-trivial minority (14%) of participants preferred a textual paragraph over a visual chart. Readers found the text "Easier to understand... when written out rather than the busy graph" [P15]. Text was also a conducive medium for adding external information to support the data narrative -"Like seeing the different points explained thoroughly and written in a story-like format" [P41].</p><p>Although charts with annotations were generally preferred, the TEX-TUAL group ranked the text-only variant higher than the chart-only variant, which we did not observe in the VISUAL group. P178, who preferred the text-only variant, reported that they "like to read the words and use my own imagination for the imagery." P6 called the annotation+ chart, "ugly to look at," a sentiment which was echoed by many who ranked that variant low.</p><p>Others highlighted the distinction in preferences between TEXTUAL and VISUAL groups -"I like this because it's very clear and gives me the information I need to know. I'm content with this. A more visual learner, however, would probably prefer the graph," [P139]. This feedback adds support to findings from prior work and underscores the importance for visualization research to consider the text-only case when comparing visualization options <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b46">48]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Semantics and positions</head><p>We found that the semantic levels of text included with the chart can influence the kind of information that readers include in their takeaways. We observed that readers were more influenced by annotations belonging to L2 or L4.</p><p>Including external context to add to the narrative of the chart inspires readers to include that information in their own takeaways, but some participants would prefer to draw their own conclusions about the data, similar to Lundgard &amp; Satyanarayan <ref type="bibr" target="#b34">[35]</ref>. For instance, P258 said "I like the raw data and being able to draw my own conclusions from the data. Data doesn't lie." about their preference for the no-text variant.</p><p>We also found that the proximity of text to what it is describing in the chart influences reader takeaways. For instance, readers included L1-text in their takeaways when the L1-text was describing one of the axes as an on-chart annotation. L2-and L4-text placed near a data point on the chart that they described, were more likely to be included in the takeaway as opposed to being positioned as the title of the chart. On the other hand, readers described overall trends from L3-text when it was placed as a title in the chart. These observations highlight an interesting interplay between spatial and text semantics in charts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Visual language and aesthetics</head><p>In addition to adding text annotations, we employed a visual language consisting of shaded boxes, dots, and arrows. Some readers responded positively to this visual language, "I like the grey arrows shown next to text explaining why they are pointing in the direction they are," [P19] or even requesting that an arrow be added to a chart that lacked it [P136]. However, another participant said these features "provide unnecessary visual clutter," [P223]. Many readers also requested the use of color, improving the chart "by livening it up a bit," (P31) or by making it "more eye-catching," [P112].</p><p>Another area of conflict between reader opinions was around the simplicity of the chart. Some enjoyed the simple nature of the visualization, while others told us to make it "more interesting (think Edward Tufte)," [P28]. Readers expressed opinions about the positioning or length of text when the chart lacked a title or when the title was too long: "used to pretty short and concise titles," [P135].</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5">Design Guidelines and Implications</head><p>Designers often add text such as captions along with charts to provide additional context, and previous work indicates the benefits of having both text and charts emphasize the same information <ref type="bibr" target="#b22">[23]</ref>. However, the amount, content, and positioning of these textual components can vary widely. From the findings described in Section 4, we provide a set of guidelines for univariate line charts. These guidelines offer insight into what type of content to express and where to place text on charts to elicit desired takeaways. Future work in more complex or other chart types can serve to expand these guidelines.</p><p>Guideline 1: Rather than aiming for maximally minimalist design, annotate charts with relevant text. (H1a-d)</p><p>Appropriately designed univariate charts that contain multiple textual annotations are preferred by a majority of visually-oriented and textually-oriented readers. Higher quantities of annotations are not penalized for the 'clutter' they may cause. Rather, the provided information is seen to enhance the view of the data.</p><p>Guideline 2: The best semantic content depends on the intended message. (H2a)</p><p>The phrasing of the text can nudge readers towards certain takeaways. Depicting statistical information as textual annotations, such as identifying a maximum value or comparing two points, makes readers more likely to take away this type of information. By contrast, describing the chart's axes and encodings does not elicit takeaways of this type of information. Including external information, such as current events or sociopolitical context, makes the reader more likely to take away this type of information. Readers are likely to make takeaways concerning perceptual components of the chart; annotations with perceptual language, such as trends and peaks, may not have an effect.  A subset of the population prefers text-only over text alongside a visualization; when designing a presentation or performing studies of different visualizations, consider a version of the text that can stand on its own. This text can also be a useful starting point for story-centered textual annotation and provide accessibility benefits <ref type="bibr" target="#b19">[20]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">LIMITATIONS AND FUTURE WORK</head><p>The study results highlight the importance of text with charts and how they together influence how readers glean insights from the data. The results also point out that reader preferences are critical in determining the full experience. These observations provide theoretical and practical implications for a better understanding of text in the larger context of visual analysis.</p><p>In this work, we explore the interplay between text and univariate line charts. Limiting some of the design options was necessary since the combinatorial design space that accounts for the various semantic levels, amount, and placement of text, is large and complex to evaluate. We controlled for the amount of text in the charts by varying the presence or absence of one or more semantic levels of text. It would be useful to create a more systematic way of determining text progression, with a more consistent computation of the amount of text and visual information in charts. Future work should explore how readers integrate text with other chart types, including dashboards and other contexts such as mobile devices, print medium, and chatbot interfaces.</p><p>We employed synthetically generated line charts to control for the experimental factors but manually crafted the placement of annotations and embellishments such as arrows with the guidance of a visualization expert. The specifics of visual annotations are also a wide and varied design space that future work can explore. The line charts created clearly showed abrupt peaks and trends, which is not often the case in practice or in real examples. We also used fictional examples to decrease the influence of prior knowledge on a topic.</p><p>While the annotation process provided some ecological validity, we would need to explore other design parameters (e.g., color) and include real-world examples to better understand other influences on readers' preferences and takeaways. The absences of a text document embedding may have introduced a potential bias towards textual representations.</p><p>Additionally, the all-text variant naturally included more L4 content than some of the charts. This content was most preferred by sighted readers and may have provided an advantage to the all-text variant <ref type="bibr" target="#b34">[35]</ref>. The annotation+ chart variant also included L4 information, but the annotations were briefer than the full sentences in the paragraph. The text in the stimuli was worded in a neutral manner; results may differ if the text were worded in a manner perceived as biased.</p><p>For our analysis, we used one part of a graphical literacy measure <ref type="bibr" target="#b12">[13]</ref> that was correlated with preference, combining these responses with participants' self-reported behaviors around viewing charts and reading in long-and short-form. However, this analysis may not provide clear or rigorous insight into the overall preference a reader has toward charts or text. Future work should develop and employ a more nuanced measure to capture and compare groups with different preferences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">CONCLUSION</head><p>In this paper, we conducted a set of studies on nine examples of univariate line charts with varied amounts and types of annotations to better understand reader preferences and takeaways from those charts. Findings show that readers prefer a combination of textual and visual communication over a single medium. They also provide further evidence of preference differences and indicate that the choice of semantic content and placement of the text in a chart can influence the readers' takeaways. We propose guidelines to better design charts with text; by using placement and appropriate semantic content, visual features in the chart can be better supported by their descriptions in the text.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Example stimuli for ranking set B (fine-grained comparisons). An example of ranking set A ('extremes') appears in Figure 1.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Nine univariate charts selected for this study, with at most two trends (up, down, or flat) and a single feature in the positive direction.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>•</head><label></label><figDesc>Legibility: Avoid adding annotations too close to one another or overlapping [25, 57]. • Visual language: Add banding to depict time ranges, show arrows for trends, and dots for point-in-time references. • Spatial agreement: The label should follow the pattern of the data and be close to the referent.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. Participants completed a survey with the six sections above: terminology introduction, individual viewing of stimuli, ranking of the full stimuli set, filter task, entering takeaways, graphical literacy, and demographics. Individual viewing and ranking were completed for both ranking sets.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Guideline 3 :</head><label>3</label><figDesc>To convey a message, the best placement of the text depends on the semantic content of the text. (H3) Content describing chart axes and encodings should be positioned by a relevant axis. Statistical or numerical information should be positioned by a relevant point. Perceptual content relating to patterns or trends should be positioned in the title. Any external information or context should be positioned by a relevant point.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Guideline 4 :</head><label>4</label><figDesc>Consider a text-only variant that can stand alone. (H1a-b)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 .</head><label>2</label><figDesc>Pairwise comparisons between preference groups for the 'extremes' ranking set (A). Annotation abbreviated to 'annot'.</figDesc><table><row><cell></cell><cell>No-text, Title-annot1</cell><cell>No-text, Annot+</cell><cell>No-text, All-text</cell><cell>Title-annot1, Annot+</cell><cell>Title-annot1, All-text</cell><cell>Annot+, All-text</cell></row><row><cell>Visual</cell><cell>p &lt; 0.01</cell><cell>p &lt; 0.01</cell><cell>p = 1</cell><cell>p &lt; 0.01</cell><cell>p &lt; 0.01</cell><cell>p &lt; 0.01</cell></row><row><cell>Textual</cell><cell>p &lt; 0.01</cell><cell>p &lt; 0.01</cell><cell>p &lt; 0.01</cell><cell>p = 0.48</cell><cell>p = 1</cell><cell>p = 0.041</cell></row><row><cell>Overall</cell><cell>p &lt; 0.01</cell><cell>p &lt; 0.01</cell><cell>p &lt; 0.01</cell><cell>p &lt; 0.01</cell><cell>p &lt; 0.01</cell><cell>p &lt; 0.01</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 .</head><label>3</label><figDesc>Pairwise comparisons between preference groups for the 'finegrained' ranking set (B). Annotation abbreviated to 'annot'.</figDesc><table><row><cell></cell><cell>Title-only,</cell><cell>Title-only,</cell><cell>Title-annot1,</cell></row><row><cell></cell><cell>Title-annot1</cell><cell>Title-annot2</cell><cell>Title+two</cell></row><row><cell>Visual</cell><cell>p &lt; 0.01</cell><cell>p &lt; 0.01</cell><cell>p = 0.028</cell></row><row><cell cols="2">Textual p &lt; 0.01</cell><cell>p &lt; 0.01</cell><cell>p = 0.352</cell></row><row><cell cols="2">Overall p &lt; 0.01</cell><cell>p &lt; 0.01</cell><cell>p &lt; 0.01</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 4 .</head><label>4</label><figDesc>Average reliance scores (1 = 'entirely text', 5 = 'entirely visual') between semantic levels.</figDesc><table><row><cell>Semantic Level</cell><cell>L1</cell><cell>L2</cell><cell>L3</cell><cell>L4</cell></row><row><cell>Avg. Reliance</cell><cell>3.84</cell><cell>3.76</cell><cell>3.65</cell><cell>3.60</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0">https://osf.io/vz976/registrations</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS</head><p>This research was supported in part by a gift from the Allen Institute for AI and NSF award #1900991.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Good charts: The HBR guide to making smarter, more persuasive data visualizations</title>
		<author>
			<persName><forename type="first">S</forename><surname>Berinato</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016">2016</date>
			<publisher>Harvard Business Review Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Beyond memorability: Visualization recognition and recall</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Borkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Bylinskii</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">W</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">M</forename><surname>Bainbridge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">S</forename><surname>Yeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Borkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Pfister</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Oliva</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="519" to="528" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">What makes a visualization memorable?</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Borkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">A</forename><surname>Vo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Bylinskii</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Isola</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sunkavalli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Oliva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Pfister</surname></persName>
		</author>
		<idno type="DOI">10.1109/TVCG.2013.234</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2306" to="2315" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Using vision to think. Readings in information visualization: using vision to think</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">K</forename><surname>Card</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Mackinlay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Shneiderman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="579" to="581" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Writing Alt Text for Data Visualization. Medium blog service</title>
		<author>
			<persName><forename type="first">A</forename></persName>
		</author>
		<ptr target="https://medium.com/nightingale/writing-alt-text-for-data-visualization-2a218ef43f81" />
		<imprint>
			<date type="published" when="2020-08">Aug. 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Figure captioning with relation maps for reasoning</title>
		<author>
			<persName><forename type="first">C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Koh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Rossi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision</title>
				<meeting>the IEEE/CVF Winter Conference on Applications of Computer Vision</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="1537" to="1545" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Analyza: Exploring data with conversation</title>
		<author>
			<persName><forename type="first">K</forename><surname>Dhamdhere</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">S</forename><surname>Mccurley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Nahmias</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sundararajan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd International Conference on Intelligent User Interfaces</title>
				<meeting>the 22nd International Conference on Intelligent User Interfaces</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="493" to="504" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">G* power 3: A flexible statistical power analysis program for the social, behavioral, and biomedical sciences</title>
		<author>
			<persName><forename type="first">F</forename><surname>Faul</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Erdfelder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A.-G</forename><surname>Lang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Buchner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Behavior research methods</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="175" to="191" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Show me the numbers</title>
		<author>
			<persName><forename type="first">S</forename><surname>Few</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004">2004</date>
			<publisher>Analytics Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Graph literacy: A cross-cultural comparison</title>
		<author>
			<persName><forename type="first">M</forename><surname>Galesic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Garcia-Retamero</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Medical Decision Making</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="444" to="457" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Package &apos;irr</title>
		<author>
			<persName><forename type="first">M</forename><surname>Gamer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lemon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Fellows</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Singh</surname></persName>
		</author>
		<ptr target="https://cran.r-project.org/web/packages/irr/irr.pdf" />
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Datatone: Managing ambiguity in natural language interfaces for data visualization</title>
		<author>
			<persName><forename type="first">T</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Dontcheva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Adar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">G</forename><surname>Karahalios</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th Annual ACM Symposium on User Interface Software and Technology</title>
				<meeting>the 28th Annual ACM Symposium on User Interface Software and Technology</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="489" to="500" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Measuring graph literacy without a test: A brief subjective assessment</title>
		<author>
			<persName><forename type="first">R</forename><surname>Garcia-Retamero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">T</forename><surname>Cokely</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ghazal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Joeris</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Medical Decision Making</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="854" to="867" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Would you like a chart with that? incorporating visualizations into conversational interfaces</title>
		<author>
			<persName><forename type="first">M</forename><surname>Hearst</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Tory</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2019 IEEE Visualization Conference (VIS)</title>
				<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="1" to="5" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Tracing integration of text and pictures in newspaper reading</title>
		<author>
			<persName><forename type="first">J</forename><surname>Holsanova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Holmberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Holmqvist</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="volume">125</biblScope>
			<biblScope unit="page" from="1" to="19" />
		</imprint>
		<respStmt>
			<orgName>Lund University Cognitive Studies</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Reading information graphics: The role of spatial contiguity and dual attentional guidance</title>
		<author>
			<persName><forename type="first">J</forename><surname>Holsanova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Holmberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Holmqvist</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Applied Cognitive Psychology: The Official Journal of the Society for Applied Research in Memory and Cognition</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1215" to="1226" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Applying pragmatics principles for interaction with visual analytics</title>
		<author>
			<persName><forename type="first">E</forename><surname>Hoque</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Setlur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Tory</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Dykeman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="309" to="318" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Visualization rhetoric: Framing effects in narrative visualization</title>
		<author>
			<persName><forename type="first">J</forename><surname>Hullman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Diakopoulos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2231" to="2240" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">A deeper understanding of sequence in narrative visualization</title>
		<author>
			<persName><forename type="first">J</forename><surname>Hullman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Drucker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">H</forename><surname>Riche</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Fisher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Adar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2406" to="2415" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Communicating visualizations without visuals: Investigation of visualization alternative text for people with visual impairments</title>
		<author>
			<persName><forename type="first">C</forename><surname>Jung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mehta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kulkarni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y.-S</forename><surname>Kim</surname></persName>
		</author>
		<idno type="DOI">10.48550/ARXIV.2108.03657</idno>
	</analytic>
	<monogr>
		<title level="m">IEEE Transactions on Visualization and Computer Graphics</title>
				<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="2406" to="2415" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Chart-to-text: A large-scale benchmark for chart summarization</title>
		<author>
			<persName><forename type="first">S</forename><surname>Kantharaj</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">T</forename><surname>Leong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Masry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Thakkar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Hoque</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Joty</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2022.acl-long.277</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics</title>
		<title level="s">Long Papers</title>
		<meeting>the 60th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2022-05">May 2022</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="4005" to="4023" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Answering questions about charts and generating visual explanations</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">H</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Hoque</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Agrawala</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems</title>
				<meeting>the 2020 CHI Conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="1" to="13" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Towards understanding how readers integrate charts and captions: A case study with line charts</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">H</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Setlur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Agrawala</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems</title>
				<meeting>the 2021 CHI Conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="1" to="11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Explaining the gap: Visualizing one&apos;s predictions improves recall and comprehension of data</title>
		<author>
			<persName><forename type="first">Y.-S</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Reinecke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hullman</surname></persName>
		</author>
		<idno type="DOI">10.1145/3025453.3025592</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems</title>
				<meeting>the 2017 CHI Conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1375" to="1386" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Data visualisation: A handbook for data driven design</title>
		<author>
			<persName><forename type="first">A</forename><surname>Kirk</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016">2016</date>
			<pubPlace>Sage</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Storytelling with data: A data visualization guide for business professionals</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">N</forename><surname>Knaflic</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015">2015</date>
			<publisher>John Wiley &amp; Sons</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">So what? Storytelling with Data Blog</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">N</forename><surname>Knaflic</surname></persName>
		</author>
		<ptr target="https://www.storytellingwithdata.com/blog/2017/3/22/so-what" />
		<imprint>
			<date type="published" when="2017-03">Mar 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Frames and slants in titles of visualizations on controversial topics</title>
		<author>
			<persName><forename type="first">H.-K</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Karahalios</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems</title>
				<meeting>the 2018 CHI Conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="1" to="12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Trust and recall of information across varying degrees of title-visualization misalignment</title>
		<author>
			<persName><forename type="first">H.-K</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Karahalios</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems</title>
				<meeting>the 2019 CHI Conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="1" to="13" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Storytelling: The next step for visualization</title>
		<author>
			<persName><forename type="first">R</forename><surname>Kosara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Mackinlay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="44" to="50" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Authoring combined textual and visual descriptions of graph data</title>
		<author>
			<persName><forename type="first">S</forename><surname>Latif</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Beck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EuroVis (Short Papers)</title>
				<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="115" to="119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Kori: Interactive synthesis of text and charts in data documents</title>
		<author>
			<persName><forename type="first">S</forename><surname>Latif</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Beck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">W</forename><surname>Kim</surname></persName>
		</author>
		<idno type="DOI">10.1109/TVCG.2021.3114802</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="184" to="194" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">More than telling a story: Transforming data into visually shared stories</title>
		<author>
			<persName><forename type="first">B</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">H</forename><surname>Riche</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Isenberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Carpendale</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer Graphics and Applications</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="84" to="90" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Why dark mode causes more accessibility issues than it solves. Medium blog service</title>
		<author>
			<persName><forename type="first">H</forename><surname>Locke</surname></persName>
		</author>
		<ptr target="https://medium.com/@hlocke/why-dark-mode-causes-more-accessibility-issues-than-it-solves-d2f8359bb46a" />
		<imprint>
			<date type="published" when="2021-12">Dec 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Accessible visualization via natural language descriptions: A four-level model of semantic content</title>
		<author>
			<persName><forename type="first">A</forename><surname>Lundgard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Satyanarayan</surname></persName>
		</author>
		<idno type="DOI">10.1109/TVCG.2021.3114770</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1073" to="1083" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">E</forename><surname>Mayer</surname></persName>
		</author>
		<title level="m">Multimedia Learning</title>
				<imprint>
			<publisher>Cambridge University Press</publisher>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note>3 ed.</note>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Sign Language Interpreting: Deconstructing the Myth of Neutrality, chap. 1. Neutrality in Translation and Interpretation</title>
		<author>
			<persName><forename type="first">M</forename><surname>Metzger</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999">1999</date>
			<publisher>Gallaudet University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">End-user preference for and understanding of hurricane forecast graphs</title>
		<author>
			<persName><forename type="first">B</forename><surname>Millet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Majumdar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Cairo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Diaz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">D</forename><surname>Evans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Broad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Human Factors and Ergonomics Society Annual Meeting</title>
				<meeting>the Human Factors and Ergonomics Society Annual Meeting</meeting>
		<imprint>
			<publisher>SAGE Publications</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">65</biblScope>
			<biblScope unit="page" from="606" to="610" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Describing complex charts in natural language: A caption generation system</title>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">O</forename><surname>Mittal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Moore</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Carenini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="431" to="467" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">The curious case of combining text and visualization</title>
		<author>
			<persName><forename type="first">A</forename><surname>Ottley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kaszowska</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Crouser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">M</forename><surname>Peck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EuroVis (Short Papers)</title>
				<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="121" to="125" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Overview of friedman&apos;s test and post-hoc analysis</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">G</forename><surname>Pereira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Afonso</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">M</forename><surname>Medeiros</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications in Statistics-Simulation and Computation</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="2636" to="2653" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Generating accurate caption units for figure captioning</title>
		<author>
			<persName><forename type="first">X</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Koh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Rossi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Malik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">Y</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Web Conference 2021</title>
				<meeting>the Web Conference 2021</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="2792" to="2804" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Narrative visualization: Telling stories with data</title>
		<author>
			<persName><forename type="first">E</forename><surname>Segel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Heer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1139" to="1148" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Eviza: A natural language interface for visual analysis</title>
		<author>
			<persName><forename type="first">V</forename><surname>Setlur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">E</forename><surname>Battersby</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Tory</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Gossweiler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">X</forename><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 29th Annual ACM Symposium on User Interface Software and Technology</title>
				<meeting>the 29th Annual ACM Symposium on User Interface Software and Technology</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="365" to="377" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Augmenting visualizations with interactive data facts to facilitate interpretation and communication</title>
		<author>
			<persName><forename type="first">A</forename><surname>Srinivasan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Drucker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Endert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Stasko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="672" to="681" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Natural language interfaces for data analysis with visualization: Considering what has and could be asked</title>
		<author>
			<persName><forename type="first">A</forename><surname>Srinivasan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Stasko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eurographics / IEEE VGTC Conference on Visualization: Short Papers</title>
				<meeting>the Eurographics / IEEE VGTC Conference on Visualization: Short Papers</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="55" to="59" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Give text a chance: Advocating for equal consideration for language and visualization</title>
		<author>
			<persName><forename type="first">C</forename><surname>Stokes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Hearst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NL VIZ: Workshop on Exploring Opportunities and Challenges for Natural Language Techniques to Support Visual Analysis</title>
				<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Leveraging textchart links to support authoring of data-driven articles with vizflow</title>
		<author>
			<persName><forename type="first">N</forename><surname>Sultanum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Chevalier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Bylinskii</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems</title>
				<meeting>the 2021 CHI Conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="1" to="17" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Articulate: A semi-automated model for translating natural language queries into meaningful visualizations</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Leigh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Symposium on Smart Graphics</title>
				<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="184" to="195" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<title level="m" type="main">Tableau Software help pages</title>
		<author>
			<persName><surname>Tableau</surname></persName>
		</author>
		<author>
			<persName><surname>Tableau</surname></persName>
		</author>
		<author>
			<persName><surname>Card</surname></persName>
		</author>
		<ptr target="https://help.tableau.com/current/pro/desktop/en-us/inspectdatasummary.htm" />
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
		<title level="m" type="main">The visual display of quantitative information</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">R</forename><surname>Tufte</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1983">1983</date>
			<publisher>Graphics Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Benetech global literacy services: Working towards a &apos;born accessible&apos;world</title>
		<author>
			<persName><forename type="first">B</forename><surname>Turner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Learned Publishing</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">How to meet wcag (quick reference)</title>
		<ptr target="https://www.w3.org/WAI/WCAG21/quickref/?versions=2.0" />
	</analytic>
	<monogr>
		<title level="m">W3C</title>
				<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note>World Wide Web Consortium website</note>
</biblStruct>

<biblStruct xml:id="b53">
	<monogr>
		<author>
			<persName><surname>W3c</surname></persName>
		</author>
		<author>
			<persName><surname>Wai</surname></persName>
		</author>
		<ptr target="https://www.w3.org/WAI/tutorials/images/complex/" />
		<title level="m">Web Accessibility Tutorials: Complex Images. World Wide Web Consortium website</title>
				<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<monogr>
		<title level="m" type="main">The Wikipedia Foundation</title>
		<author>
			<persName><surname>Wikipedia</surname></persName>
		</author>
		<author>
			<persName><surname>Wikipedia</surname></persName>
		</author>
		<ptr target="https://www.wikipedia.org/" />
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<monogr>
		<title level="m" type="main">The Wall Street Journal guide to information graphics: The dos and don&apos;ts of presenting data, facts, and figures</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Wong</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010">2010</date>
			<publisher>WW Norton</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Explaining with examples lessons learned from crowdsourced introductory description of information visualizations</title>
		<author>
			<persName><forename type="first">L</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">K</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Qu</surname></persName>
		</author>
		<idno type="DOI">10.1109/TVCG.2021.3128157</idno>
	</analytic>
	<monogr>
		<title level="m">IEEE Transactions on Visualization and Computer Graphics</title>
				<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="1" to="1" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Eye tracking indicators of reading approaches in text-picture comprehension</title>
		<author>
			<persName><forename type="first">F</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Schnotz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Wagner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Gaschler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Frontline Learning Research</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="46" to="66" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
