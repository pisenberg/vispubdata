<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Visual Analysis of Neural Architecture Spaces for Summarizing Design Principles</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Jun</forename><surname>Yuan</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Mengchen</forename><surname>Liu</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Fengyuan</forename><surname>Tian</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Shixia</forename><surname>Liu</surname></persName>
						</author>
						<title level="a" type="main">Visual Analysis of Neural Architecture Spaces for Summarizing Design Principles</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.2" ident="GROBID" when="2023-03-27T09:15+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Machine learning</term>
					<term>visual analytics</term>
					<term>neural architecture search</term>
					<term>design principle</term>
					<term>knowledge discovery</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>H (270) × I (338) × J (523) × H-e7de58 93.546 4696.141s 38.799M H-2c025f 93.733 4681.342s 38.799M I-95a3e9 93.566 4822.361s 39.789M I-27df5b 93.573 4479.820s 38.956M</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Recent progress in artificial intelligence largely benefits from better neural network architecture design <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b32">33]</ref>. The successful design of these architectures relies on costly trial-and-error processes. With the development of large GPU clusters, neural architecture search (NAS) <ref type="bibr" target="#b16">[17]</ref> has been proposed to parallel the architecture design process. It automatically selects well-performing architectures in neural architecture spaces by training and evaluating a large number of architecture candidates. Since the NAS method aims to find well-performing architectures for given datasets, it depends on the evaluation of the spe-</p><p>• J. Yuan, F. Tian and S. Liu are with BNRist, Tsinghua University. E-mail: {yuanj19, tianfy21}@mails.tsinghua.edu.cn, shixia@tsinghua.edu.cn. Shixia Liu is the corresponding author. • M. Liu is with Microsoft. E-mail: mengcliu@microsoft.com cific datasets. Accordingly, the generalization ability of the searched architectures may be limited. Design principles, which describe how specific structure components, such as layers or their combinations, influence the performance of architectures, have been shown to be useful in designing more explainable architectures with better generalization ability <ref type="bibr" target="#b57">[58]</ref>. Moreover, they can be used to reduce the search space and computation cost of the NAS method. A recent study indicates that a comprehensive analysis of architecture spaces facilitates the summarization of such design principles <ref type="bibr" target="#b48">[49]</ref>. It is therefore of theoretical and practical significance to analyze these spaces for advancing our understanding of the influence of the structure on model performance.</p><p>There are two technical challenges in analyzing an architecture space. First, the number of architectures brings the scalability issue. Previous research has demonstrated that understanding the structural distances between architectures enables users to derive general design principles for architecture design <ref type="bibr" target="#b57">[58]</ref>. However, the space usually contains tens of thousands to millions of architectures <ref type="bibr" target="#b34">[35]</ref>, which leads to at least millions of distance calculation. Thus, how to efficiently calculate so many distances is still an open question. Second, it is non-trivial to identify the architectures of interest and analyze them in context for summarizing design principles. Given a large number of architectures, a scatterplot is commonly used to show the performance (e.g. , accuracy or speed) versus a numerical property associated with the architectures (e.g. , the number of parameters or floating-point operations). Although it can provide a performance overview of the architectures, it fails to reflect their structural distances. This hinders the understanding of the structural connections between architectures, and thus brings difficulty in summarizing design principles. It is therefore technically demanding to provide an interactive exploration environment where structurally similar architectures are placed together, and smooth exploration is supported to probe the architecture space from global overview to individual architectures.</p><p>In this work, we propose a visual analysis method, ArchExplorer, to facilitate the interactive analysis of an architecture space. Most neural network architectures are composed of a few sub-architectures repeated multiple times <ref type="bibr" target="#b30">[31,</ref><ref type="bibr" target="#b60">61]</ref>, each of which is a combination of multiple layers (e.g. , convolution layers and pooling layers) and their connections <ref type="bibr" target="#b14">[15]</ref>. <ref type="bibr">Zoph et al.</ref> have demonstrated that stacking well-performing sub-architectures can construct state-of-the-art architectures <ref type="bibr" target="#b76">[77]</ref>. Thus, we focus on analyzing the repetitive sub-architectures. Without loss of generality, we refer to them as architectures in the discussion below. We represent each architecture as a directed acyclic graph (DAG) and adopt the widely-used graph edit distance to measure the structural distances between them. We formulate the calculation of all pairwise structural distances as an all-pairs shortest path problem. To efficiently calculate millions of pairwise distances or even more, we decompose this problem into a set of single-source shortest path problems. They can be solved by an accelerated Dijkstra algorithm. Our distance calculation algorithm reduces the time complexity from O(kn 2 N) to O(knN). Using the calculated distances, we build an architecture cluster hierarchy to enable an efficient exploration of such a large space. An architecture visualization is then designed for better understanding the architecture space. To help efficiently identify the architectures of interest, a forcedirected layout is employed for preserving the global relationships between clusters at each hierarchy level. To facilitate the analysis of the architectures in context, a circle packing layout is developed for illustrating the local neighborhood of the architectures in each cluster (Fig. <ref type="figure" target="#fig_0">1(a)</ref>). Coupled with a set of interactions, such as zooming and comparison, this visualization enables users to summarize design principles. We conduct two case studies on two NAS benchmark datasets to demonstrate the capability of ArchExplorer in deriving design principles. A post-analysis with a state-of-the-art method, LaNAS <ref type="bibr" target="#b62">[63]</ref>, shows that the derived principles can reduce the computation cost for searching the better-performing architectures. A demo of the prototype is available at: http://archexplorer.thuvis.org.</p><p>The key technical contributions of this work are:</p><p>• The formulation of the pairwise distance calculation as solving an all-pairs shortest path problem. • An architecture visualization that preserves both the global relationships between architecture clusters and the local neighborhoods of architectures in each cluster to facilitate the identification and comparison of the architectures of interest. • A visual analysis tool to understand an architecture space and summarize general design principles through the analysis of a large number of neural network architectures.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK</head><p>We briefly review two categories of related work: explaining machine learning models and explaining automated machine learning methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Explaining Machine Learning Models</head><p>Many visual analysis methods for explainable deep learning have been developed to facilitate the analysis of machine learning models <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b52">53,</ref><ref type="bibr" target="#b73">74]</ref>. According to the analysis goal, they can be categorized into two classes: diagnosis-oriented analysis and comparative analysis <ref type="bibr" target="#b20">[21]</ref>.</p><p>Diagnosis-oriented analysis aims to explain model behaviors and diagnose models with unsatisfactory performance. Most existing efforts focus on revealing the working mechanisms of different models, such as multilayer perceptrons <ref type="bibr" target="#b49">[50]</ref>, ensemble models <ref type="bibr" target="#b37">[38,</ref><ref type="bibr" target="#b71">72,</ref><ref type="bibr" target="#b75">76]</ref>, convolutional neural networks <ref type="bibr" target="#b27">[28,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b66">67]</ref>, deep generative models <ref type="bibr" target="#b35">[36]</ref>, recurrent neural networks <ref type="bibr" target="#b40">[41,</ref><ref type="bibr" target="#b56">57]</ref>, and Transformers <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b33">34]</ref>. Despite their effectiveness in analyzing a single model, they do not support model comparison, which is essential for selecting better-performing models from a set of candidates.</p><p>To fill this blank, comparative analysis methods are developed to explain the similarities and differences between models, therefore providing guidance for model selection. Such visual analysis methods have been developed for diverse tasks, such as classification <ref type="bibr" target="#b38">[39,</ref><ref type="bibr" target="#b42">43,</ref><ref type="bibr" target="#b50">51</ref>] and question answer verification <ref type="bibr" target="#b13">[14]</ref>. For example, Murugesan et al. <ref type="bibr" target="#b42">[43]</ref> proposed DeepCompare to compare the error patterns between models. This is achieved by analyzing their differences in the neuron weights and activations. These methods facilitate model comparison, but they are less capable of revealing the full picture of an architecture space and identifying the architectures of interest. Thus, they are not efficient in selecting a well-performing architecture in a large space. In comparison, by preserving the pairwise distances between architectures, ArchExplorer provides an overview of the architecture space and also enables the analysis of individual architectures. Thus, it empowers users to summarize design principles for designing better-performing architectures.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Explaining Automated Machine Learning Methods</head><p>Automated machine learning aims to automate the tedious and iterative tasks in building a machine learning model, including data preprocessing, feature selection, architecture design, and hyper-parameter tuning <ref type="bibr" target="#b19">[20]</ref>. Accordingly, researchers have developed several visual analysis methods to analyze the automated generated results of these tasks <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b46">47,</ref><ref type="bibr" target="#b63">64,</ref><ref type="bibr" target="#b64">65]</ref> or their combinations <ref type="bibr" target="#b45">[46,</ref><ref type="bibr" target="#b61">62,</ref><ref type="bibr" target="#b67">68]</ref>.</p><p>Our work falls in the category of architecture-design-oriented works <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b12">13]</ref>. The methods seek to discover better architectures. Among these research attempts, the most relevant one is REMAP <ref type="bibr" target="#b6">[7]</ref>, which is one of the pioneering works in visually analyzing neural architecture spaces. It provides an effective iterative process for designing sequential neural network architectures. Starting from a set of random architectures, users can design new architectures by modifying the structures of the selected ones. These modifications can be recommended by the system or specified by users. REMAP can help users efficiently build a well-performing architecture. It pays less attention to summarizing design principles from a large neural architecture space. In addition, the employed MDS projection may fail to place structurally similar architectures together <ref type="bibr" target="#b58">[59]</ref>. In contrast, ArchExplorer focuses on summarizing design principles from an architecture space. To this end, we first develop an efficient distance calculation algorithm and build an architecture cluster hierarchy. Based on them, an architecture visualization is designed. It places structurally similar architectures together and allows users to analyze the architectures in the context of similar architectures.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">DESIGN REQUIREMENTS</head><p>ArchExplorer is developed in collaboration with four experts in computer vision (E 1 -E 4 ) whose research interests include image classification and object detection. In one project, they utilized the NAS method to develop an efficient image classification model for an online content tagging service. To improve the generalization of the searched architecture, the experts employed several visualizations to help them derive design principles. For example, they used a scatterplot to gain an overview of the searched architectures. The X-axis and Y-axis represent inference time and accuracy, respectively. Such visualization gives them an overall idea of the searched architectures. However, there lacks a comprehensive understanding of the structural relationships between architectures. Without such an understanding, it is difficult to link the structural differences of architectures with their performance differences. This brings difficulty in discovering design principles, such as whether a structure component in an architecture is beneficial to the performance. Thus, it is desired to develop a visual analysis tool to help summarize such design principles from a large architecture space. Fig. <ref type="figure">2</ref>: ArchExplorer overview: given the architectures in an architecture space, the architecture distance calculation module calculates the distances between them; the visualization module provides an overview of the architecture space and helps users compare architectures.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Architecture visualization</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Architectures</head><p>In the past two years, we held biweekly free-form discussions with the experts to probe the requirements and develop the tool. Based on the discussions, we summarized the following design requirements: R1. Grouping architectures based on their structural distances. All experts expressed the need to get a clear understanding of an architecture space with hundreds of thousands of architectures or even more. To analyze such a large space, the experts usually cluster the architectures into several groups. The widely used practice is to group architectures by the numerical properties such as inference time or accuracy <ref type="bibr" target="#b48">[49,</ref><ref type="bibr" target="#b72">73]</ref>. Such a grouping strategy can help find well-performing architectures. However, the experts commented that it usually hindered the discovery of design principles due to various structures in each architecture group. Recent research has shown that the structure of a neural network architecture is one important factor that influences its performance <ref type="bibr" target="#b29">[30]</ref>. Thus, the experts required to model the structural distance between architectures and build the clusters accordingly. R2. Identifying the architectures of interest and analyzing them in context. Currently, to analyze an architecture space and select the ones of interest from it, the experts plotted all the architectures in a scatterplot, where each point encodes an architecture. With this scatterplot, the experts can analyze these architectures by different numerical properties (e.g. , accuracy, inference time, the number of parameters, etc.) represented by the axes. Although such visualization can provide a numerical overview of the architectures, it fails to reflect their structural distances and hinders the discovery of similar architectures associated with the ones of interest. Thus, to discover design principles from a large space, it is demanding to provide a more informative overview that can be served as an entry point for the analysis. Once identifying the architectures of interest, it is desirable to examine the architectures in context. As explained by E 2 , "Comparing an architecture of interest with its neighbors is similar to conducting an ablation study that is useful to understand how different structure components of the architecture contribute to the performance and whether a specific structure component is beneficial to the performance or not." R3. Comparing architectures in multiple aspects. The experts commented that architecture comparison was the key to deriving design principles. This is also consistent with the findings of recent research on deep model comparison <ref type="bibr" target="#b38">[39,</ref><ref type="bibr" target="#b42">43]</ref>. The experts indicated that a design principle usually came from comparing two architecture groups with different accuracy. E 3 said, "Among computer vision researchers, there are different opinions whether layer normalization should be positioned before or after the attention block in Transformer models. To verify this, I constructed pairs of transformers with different widths and depths. In each pair, layer normalization is put before and after the attention block, respectively. By comparing their accuracy, I find that putting layer normalization before attention is overall beneficial for the classification task." In addition, the experts emphasized that making a decision on architecture design often involved multiple criteria, and they needed to compare the architectures of interest in multiple aspects. For example, besides accuracy, E 1 also wanted to compare other measures, such as inference time and the number of floating-point-operations (FLOPs). As E 1 further explained, the number of FLOPs is positively related to the performance and the energy cost of GPUs <ref type="bibr" target="#b53">[54]</ref>. Thus, he needed to compare the architectures with different numbers of FLOPs and select one that can well balance the performance and the number of FLOPs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">DESIGN OF ARCHEXPLORER</head><p>Driven by the design requirements, we develop ArchExplorer to support the interactive analysis of an architecture space and summarize design principles. It contains two main modules: architecture distance calculation and visualization (Fig. <ref type="figure">2</ref>). The former models the distances between architectures (R1). The latter first builds an architecture cluster hierarchy based on the distances, and then allows users to quickly identify the architectures of interest and analyze them in context (R2). It also facilitates the comparison of the architectures to understand which structure components are beneficial to the performance (R3).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Calculation of Architecture Distance</head><p>Since NAS algorithms aim at searching for a well-performing architecture, existing distance-based NAS algorithms only calculate the distances between each of the newly selected architectures and the previously evaluated ones <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b29">30]</ref>. However, ArchExplorer aims at grouping structurally similar architectures together (R1), which requires the pairwise distances between all architectures. Problem formulation. The appropriate structure-based architecture representation is the key to modeling the distances between architectures. There are two common schemes for representing the structure of an architecture: path-based and DAG-based <ref type="bibr" target="#b68">[69]</ref>. The path-based scheme represents an architecture as a set of paths, where each path is a sequence of layers. The DAG-based scheme represents an architecture as a directed acyclic graph (DAG), where nodes and edges represent its layers and the connections between layers. A previous study has shown that the DAG-based scheme explicitly utilizes the topological information and better reflects the performance of a neural network architecture <ref type="bibr" target="#b44">[45]</ref>. Thus, in ArchExplorer, we adopt the DAG-based scheme to represent architectures. With this representation, we adopt the widely-used graph edit distance (d) to measure the structural distances between architectures <ref type="bibr" target="#b24">[25]</ref>. The graph edit distance between two architectures is defined as the minimum cost of all possible edit paths that transform one architecture into another <ref type="bibr" target="#b51">[52]</ref>.</p><p>The A* algorithm is commonly used for calculating graph edit distances <ref type="bibr" target="#b1">[2]</ref>. Given two architectures, this algorithm finds the minimumcost edit path by iteratively exploring the architectures with one edit operation difference. Assume that there are N architectures in the whole architecture space, and each architecture can be transformed into k different architectures with one edit operation. The time complexity for calculating the graph edit distance between two architectures is O(kN). In practice, the whole architecture space can probably contain billions of architectures or even more <ref type="bibr" target="#b55">[56,</ref><ref type="bibr" target="#b59">60]</ref>, which raises difficulty in the analysis. Typically, n architectures (n &lt; N) are sampled from the whole space to ease the analysis. Given n sampled architectures, directly applying the A* algorithm for calculating the pairwise distances results in the time complexity of O(kn 2 N). This is still very time-consuming, especially for hundreds of thousands of sampled architectures.</p><p>We observe that the minimum-cost edit paths between different architecture pairs can overlap, such as the path x − v in the paths x − v − z   <ref type="figure" target="#fig_1">3(c</ref>). This indicates that the minimum-cost edit paths have the optimal substructure property, which enables the reuse of previously found minimum-cost edit paths. Motivated by such an observation, we propose to model the previously found minimum-cost edit paths and the associated nodes as a graph. Accordingly, we build an architecture graph by connecting the architectures with only one edit operation difference to represent their one-hop neighbor relationships (Fig. <ref type="figure" target="#fig_1">3(b)</ref>). For n sampled architectures, we add N − n dummy architectures to guarantee the existence of the minimum-cost edit path between any two architectures. The dummy architectures are those in the architecture space but not in the sampled architectures. Fig. <ref type="figure" target="#fig_1">3</ref>(b) shows an example architecture graph. In this graph, each solid dot represents an architecture, and each hollow dot represents a dummy one. The weight on each edge encodes the cost of the edit operation. In our implementation, we utilize the cost matrix given by Nguyen et al. <ref type="bibr" target="#b43">[44]</ref> to define the substitution cost (w e ) between different layers. The deletion (addition) cost is defined as the substitution cost between a given layer (the null layer) and the null layer (a given layer), which is set as 5 × max e w e . Thus, calculating the pairwise edit distances in this architecture graph can be formulated as an all-pairs shortest path (APSP) problem (Fig. <ref type="figure" target="#fig_1">3(c)</ref>). Algorithm. Since the number of one-hop neighbors of an architecture (k) is much smaller than the number of architectures in the whole architecture space (N), the architecture graph is sparse. Due to such sparsity, an efficient method for finding the minimum-cost edit paths is to decompose the APSP problem into a set of single-source shortest path (SSSP) problems for each source architecture (Fig. <ref type="figure" target="#fig_2">4</ref>). In each SSSP problem, we employ an accelerated Dijkstra algorithm to find the minimum-cost edit paths between the source architecture and the others. Dijkstra algorithm utilizes a greedy strategy to iteratively find the shortest paths between nodes based on the edge costs <ref type="bibr" target="#b11">[12]</ref>. The most time-consuming step at each iteration is the selection of a node that has the minimum cost to the source (O(log N)). Since the edit operations are finite (insertion, deletion, and substitution of a node/edge), the associated costs are also finite. We use this property to improve efficiency. In particular, we maintain sets of architectures, each of which consists of the architectures with the same cost to the source. These sets are organized as a sorted list based on their costs. With this sorted list, the algorithm can select an architecture with the minimum cost in constant time (O(1)) <ref type="bibr" target="#b41">[42]</ref>. Complexity analysis. As each architecture has k one-hop neighbors, our algorithm takes O(kN) time to build the architecture graph with kN edges. It runs n times of the accelerated Dijkstra algorithms, and each has an O(kN) time complexity. Accordingly, the total time complexity of our algorithm is O(kN) + n × O(kN) = O(knN). It is faster than the A* algorithm (O(kn 2 N)) with an acceleration ratio of n. For example, in the case studies, our algorithm can achieve an acceleration ratio of 423, 624 and 15, 625 on the NAS-Bench-101 <ref type="bibr" target="#b72">[73]</ref> and NAS-Bench-201 <ref type="bibr" target="#b15">[16]</ref> architecture spaces, respectively. The developed algorithm works well when N is no more than several millions. When N reaches billions or even larger, our algorithm fails because both the time complexity and space complexity are proportional to N. For example, we are unable to build an architecture graph for NAS-Bench-301 <ref type="bibr" target="#b55">[56]</ref> as it contains over 10 18 architectures. A common solution for handling such large spaces is to directly calculate the pairwise distances between the sampled architectures. The pairwise distance is the minimum matching cost among all possible matchings between the layers of the two associated architectures. The time complexity for calculating a distance is O(L!), where L is the total number of layers in the two architectures. When L &gt; 9, L! grows more than a million. It is intractable to directly compute all these distances (O(n 2 L!)). To tackle this issue, we represent all possible matchings by a weighted bipartite graph and utilize an approximation algorithm to accelerate the calculation <ref type="bibr" target="#b51">[52]</ref>. A sub-optimal matching can be found in O(L 3 ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Architecture Visualization</head><p>The architecture visualization is designed to facilitate the analysis of the architecture space from a global overview to individual architectures. Based on the calculated distances, we build an architecture cluster hierarchy in a top-down manner by iteratively applying K-medoids <ref type="bibr" target="#b47">[48]</ref>. This algorithm is widely used to cluster samples with distance measures due to its simplicity, fast convergence, and robustness to noise <ref type="bibr" target="#b2">[3]</ref>. The number of clusters is determined by a grid search, selecting the one with the minimum average distance (to the cluster center). Then we employ a cluster-aware sampling strategy <ref type="bibr" target="#b74">[75]</ref> to sample architectures from each level of the architecture cluster hierarchy for display. This sampling strategy aims to maintain the relative sizes of clusters. To preserve smaller clusters, it also guarantees sampling a minimum number from each cluster. In our implementation, we set this number as 10.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1">Architecture Space as Circle Packing</head><p>Visual design. As shown in Fig. <ref type="figure">5</ref>(a), an architecture is represented by a circle. A sequential color scheme is utilized to encode accuracy. The darker green the circle, the higher the accuracy. By default, the darkest green circles highlighted the well-performing architectures with top 1% accuracy (Fig. <ref type="figure" target="#fig_0">1I</ref>). Architectures in the same cluster are densely packed together. We employ circle packing to avoid overplotting in scatterplots and reduce the learning curve of users because it shares the same visual encoding with the widely-used scatterplots. To connect the performance to the structures of individual architectures, we select representative architectures in each cluster and visualize them with summary glyphs (Fig. <ref type="figure">5(b)</ref>) and structure glyphs (Fig. <ref type="figure">5(c</ref> We then enhance this visualization by appending structure glyphs to the representative architectures (Fig. <ref type="figure">6(c</ref>)), which helps to reveal the structural characteristics of each cluster. The widely used Kamada-Kawai layout algorithm <ref type="bibr" target="#b28">[29]</ref> is employed to place the clusters, where we use the distances between the cluster centers to represent the distances between clusters. Here, we focus on introducing the circle packing and glyph placement.</p><p>The goal of the circle packing is to preserve the local neighborhoods of architectures. However, the commonly used circle packing algorithm, the front-chain algorithm <ref type="bibr" target="#b65">[66]</ref>, pays little attention to preserving local neighborhoods. As the densest packing of identical circles is equivalent to the regular hexagonal packing on the plane <ref type="bibr" target="#b7">[8]</ref>, we transform the circle packing into a hexagonal grid layout problem. Here, the densest packing is an arrangement that maximizes the number of packed circles in a given layout area. By considering the similarity relationships between architectures globally, the hexagonal grid layout places similar architectures adjacently. The optimal layout is generated by minimizing the sum of distances between the adjacent architectures in the grid. Assume that cluster i contains N i architectures {a j } Ni j=1 , and we generate a grid containing N i grid points {x j } Ni j=1 . Let Π Ni be the set of all possible permutations of {1, 2, ••• , N i }. Then a layout can be represented by a permutation π ∈ Π Ni where a j is placed on x π( j) . Accordingly, the hexagonal grid layout problem is formulated as:</p><formula xml:id="formula_0">minimize π∈ΠN i Ni ∑ j=1 ∑ x π(l) ∈Γ(x π( j) ) d(a j , a l ).<label>(1)</label></formula><p>Here, Γ(x π( j) ) is the set of adjacent grid points of x π( j) and d(a j , a l ) is the distance between architectures a j and a l that are assigned to adjacent grid points x π( j) and x π(l) , respectively. Since this is an NPhard quadratic assignment problem <ref type="bibr" target="#b0">[1]</ref>, we propose a greedy algorithm to effectively generate an approximate layout result. Specifically, for each grid X i , we first sort the grid points by their distances to the center of X i . Then each architecture is iteratively assigned to a grid point that leads to the maximal decrease in the sum of distances to get an initial feasible result. Finally, we tune the result by swapping the architectures assigned to two grid points that can further decrease the sum of distances until no more such swaps can be performed.</p><p>To better understand the structural characteristics of the clusters, 2-5 representative architectures are selected from each cluster. To well represent the cluster and also prioritize the architectures with higher accuracy for analysis, the representative architectures are either with 1) the top-1 similarity to other architectures; or 2) the top-10 accuracy balancing accuracy and similarity. Each representative architecture is associated with a summary glyph and a structure glyph for providing more structure-level information. To uniformly pack the summary glyphs and the circles together, one summary glyph takes up seven grid points, including the grid point associated with the corresponding architecture and all its adjacent grid points (Fig. <ref type="figure">6A</ref>). In this way, packing circles and summary glyphs together can still be regarded as assigning them to the grid points and solved with the proposed layout algorithm. We then utilize the label layout algorithm <ref type="bibr" target="#b39">[40]</ref> to place the structure glyphs near their corresponding summary glyphs. Following the Gestalt law of connectedness <ref type="bibr" target="#b31">[32]</ref>, we link the structure glyph to the corresponding summary glyph to strengthen their visual connection.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2">Interactive Exploration</head><p>To facilitate the exploratory analysis of the architecture space and help users identify the architectures of interest for detailed analysis, a set of interactions is provided.</p><p>Filtering. Following the design in <ref type="bibr" target="#b9">[10]</ref>, we provide a set of scented widgets (Fig. <ref type="figure" target="#fig_0">1J</ref>) to filter out irrelevant architectures. They guide the architecture filtering by displaying their attribute distributions (e.g. , the number of FLOPs and parameters).</p><p>Selection. Two modes are provided to select the architectures of interest. Users can select the ones in a specific cluster by the cluster mode ( ) or from an arbitrary region by the lasso mode ( ).</p><p>Navigating through different levels of detail. With the architecture cluster hierarchy, users can click to zoom into a specific architecture cluster and examine the fine-grained sub-clusters or to zoom out to the previous navigation level. To keep users' mental map, the sampled architectures at the current level are preserved when zooming into a specific cluster. We also maintain the layout stability by keeping the relative position unchanged across different navigation levels.</p><p>Comparison. A comparative visualization (Fig. <ref type="figure" target="#fig_0">1(c</ref>)) is designed to enable a detailed comparison of the selected architectures in three aspects (R3). First, we use a parallel coordinates plot (PCP) (Fig. <ref type="figure" target="#fig_0">1E</ref>) to compare the attribute distributions between groups of architectures due to its effectiveness in comparing different numerical attributes <ref type="bibr" target="#b25">[26]</ref>. In the PCP, each polyline represents an architecture, and each axis represents an attribute. Second, a table is utilized to compare individual architectures (Fig. <ref type="figure" target="#fig_0">1F</ref>), which is enhanced by encoding each attribute with both a numerical value and a bar Value in one cell. Third, we enable a side-by-side comparison of architecture structures (Fig. <ref type="figure" target="#fig_0">1G</ref>), which is critical in summarizing design principles. They are visualized with the same design as the structure glyphs (Fig. <ref type="figure">5(c)</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">EVALUATION</head><p>To demonstrate the effectiveness of ArchExplorer in summarizing design principles, we conducted two case studies with the experts. To further validate the usefulness of the summarized design principles, we integrated them into a state-of-the-art NAS method. Experimental results showed that the principle-based NAS method reduced the computation cost by around 50% and achieved at least the same performance as the NAS method. The accuracy of each architecture was evaluated on the CIFAR-10 dataset, which is widely used in NAS <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b72">73]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Case Studies</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.1">Analyzing NAS-Bench-101</head><p>In this case study, we collaborated with expert E 1 to show how Arch-Explorer helps summarize design principles from a large architecture space, NAS-Bench-101 <ref type="bibr" target="#b72">[73]</ref>, which contains 423,624 architectures. The number of layers in each architecture is limited to five, and the number of connections between layers is limited to nine. The layers are chosen from: 3 × 3 convolution, 1 × 1 convolution, and 3 × 3 max-pooling. Two example architectures are shown in Fig. <ref type="figure" target="#fig_0">1G</ref>.</p><p>Overview. E 1 started the analysis by examining the global relationships between the clusters in Fig. <ref type="figure" target="#fig_0">1</ref>(a). He found that the clusters at the top had more dark green circles and shorter red arcs (max-pooling layers) than those at the bottom-left. This indicates that the architectures using fewer max-pooling layers have better performance. In particular, he saw that clusters A, B, D contained more well-performing architectures. E 1 decided to analyze them in detail. Analyzing architectures without max-pooling layers. E 1 first examined cluster A that contained the architectures without max-pooling layers. Since the accuracy variance of this cluster is large, he zoomed into it for further analysis. The well-performing architectures in cluster A are mostly located in three sub-clusters (Fig. <ref type="figure" target="#fig_0">1(b)</ref>). By examining the structure glyphs, he found that sub-cluster H used four convolution layers and the other two used five convolution layers. However, they have comparable numbers of well-performing architectures. This attracted his attention because more convolution layers usually lead to better performance. E 1 further explained, "Architectures with more convolution layers have a larger number of trainable parameters and thus a larger model capacity. Typically, a larger model capacity can better fit the data and achieve better performance." Since 40 million approaches the upper limit of trainable parameters for architectures with four 3 × 3 convolution layers, he selected such architectures from the three subclusters by using the "params" dimension of the PCP (the dashed ellipse in Fig. <ref type="figure" target="#fig_0">1E</ref>) to figure out why this phenomenon occurred. Then he sorted them by accuracy. By comparing the individual architectures in Fig. <ref type="figure" target="#fig_0">1F</ref>, E 1 found that the architectures in H had more skip-connections (the rows with orange borders). By examining their structures, he found that they resembled the structure of DenseNet <ref type="bibr" target="#b21">[22]</ref>, which had dense skip-connections between layers (the thick black lines in Fig. <ref type="figure" target="#fig_0">1G</ref>). He commented that dense skip-connections combine the outputs of multiple previous layers and thus strengthen feature propagation <ref type="bibr" target="#b21">[22]</ref>. This leads to better performance. Thus, he suggested: • Principle 1: dense skip-connections are beneficial to accuracy. Analyzing architectures with max-pooling layers. E 1 then continued to analyze other well-performing architectures in clusters B and D (Fig. <ref type="figure" target="#fig_0">1(a)</ref>). The short red arcs in the summary glyphs and the structure glyphs reveal that they only use one max-pooling layer. A nearby cluster C caught his attention. In this cluster, the red arcs of the summary glyphs have the same lengths as those in B and D, but the architectures in this cluster have much lower overall accuracy. By comparing their structure glyphs, he found that the major difference between the architectures in cluster C and clusters B and D was the position of the max-pooling layer. In B and D, the architectures have their maxpooling layers at the front (cluster B) or in the middle (cluster D) of the structure glyphs. While in cluster C, the architectures have their max-pooling layers at the end.</p><p>To understand the effect caused by the position of the max-pooling layer, we collaborated with E 1 and analyzed the activation map differences between the corresponding architectures in clusters B and C. We randomly selected two architectures a 1 (accuracy: 94.6%) and a 2 (accuracy: 93.8%) from clusters B and C and trained them on CIFAR-10. We fed each image into the trained model and obtained the feature Bird Image Prediction: Bird Frog</p><formula xml:id="formula_1">a 1 a 2</formula><p>Activation map Fig. <ref type="figure">7</ref>: The activation map differences between architectures with the max-pooling layer at the front (a 1 ) and at the end (a 2 ). a 1 generated a more precise response area on the bird than a 2 .</p><p>map with the largest response before the fully connected layer as its activation map <ref type="bibr" target="#b17">[18]</ref>. By analyzing a set of activation maps of images, each of which is predicted differently by a 1 and a 2 , he found that the response areas generated by a 1 were usually more precise than those by a 2 . This indicates that architectures with the max-pooling layers at the end probably introduce irrelevant information for prediction, leading to more misclassifications. For example, in Fig. <ref type="figure">7</ref>, a 2 misclassified a bird as a frog since it mistook the larger green background as a grassland. We further verified this by checking the activation maps of 100 random images. The results showed that although a 1 and a 2 both learned to focus on the objects in almost all images (99%), a 2 was more likely to generate imprecise response areas (49%) than a 1 (14%). Following a similar analysis, we also found that the response areas generated by the architectures with the max-pooling layer in the middle were more precise than those with the max-pooling layer at the end. Based on this observation, E 1 commented, "The architectures with max-pooling layers at the end enlarge the response areas and tend to introduce information irrelevant to prediction. This may lead to more misclassifications." Therefore, he concluded:</p><p>• Principle 2: max-pooling layers should probably not appear at the end of the architecture.</p><p>Comparing architectures without and with max-pooling layers.</p><p>After analyzing the architecture clusters without and with max-pooling layers separately, E 1 was interested in why the well-performing architectures did not use many max-pooling layers. He randomly selected and trained two architectures a 3 (accuracy: 95.1%) and a 4 (accuracy: 93.9%) with zero and one max-pooling layer, respectively. With a similar analysis as previously described, he found that architectures with max-pooling layers often introduced irrelevant information into the prediction process and thus led to more misclassifications. For example, in Fig. <ref type="figure">8</ref>, a 4 misclassified a ship as an airplane since it mistook the horizontal black bars in the background as the wings of an airplane. For validation, 100 random images were also investigated to examine their activation map differences. The results suggested that both a 3 and a 4 can learn the key part of the object in nearly 90% of the images, but a 4 was more likely to learn some interfering parts (76%) than a 3 (34%). From this analysis, E 1 concluded:</p><p>• Principle 3: the max-pooling layers probably downgrade accuracy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.2">Analyzing NAS-Bench-201</head><p>We collaborated with expert E 2 to demonstrates how to design an architecture with better generalization ability based on the design principles summarized from NAS-Bench-201 <ref type="bibr" target="#b15">[16]</ref>. This space consists of 15, 625 architectures. Each architecture contains six layers chosen from: 1 × 1 convolution, 3 × 3 convolution, 3 × 3 average-pooling, identity, and zeroize. An example architecture is shown in Fig. <ref type="figure" target="#fig_5">10(b)</ref>. Summarizing design principles. E 2 started the analysis from the architecture visualization (Fig. <ref type="figure" target="#fig_4">9</ref>(a)). By examining the summary glyphs, he found that architectures were clustered based on the number of zeroize layers (grey arcs). Cluster A has the largest number of wellperforming architectures, where architectures do not use any zeroize layers. This met his expectation because the architectures with such layers have less trainable parameters and thus smaller model capacity. This leads to performance degradation.</p><p>In cluster A, a region with many darkest green circles (Fig. <ref type="figure" target="#fig_4">9B</ref>)</p><formula xml:id="formula_2">Ship Image Prediction: Ship Airplane Activation map a 3 a 4</formula><p>Fig. <ref type="figure">8</ref>: The activation map differences between architectures with zero (a 3 ) and one (a 4 ) max-pooling layer. a 3 generated a more precise response area on the ship than a 4 . aroused his interest. This indicates that these well-performing architectures have similar structures. Thus, he used the lasso to select these architectures for detailed examination. E 2 noticed that all these architectures had an identity layer connecting the input and the output (dashed ellipses in Fig. <ref type="figure" target="#fig_4">9B'</ref>). He commented that such an identity layer could address the vanishing gradient problem in model training because it provides an alternative path for the gradient flow in back-propagation. This is consistent with the design of ResNet <ref type="bibr" target="#b18">[19]</ref>. Therefore, he suggested: • Principle 4: the identity layer connecting the input and the output is beneficial to the performance.</p><p>Due to the large accuracy variance in cluster A, E 2 zoomed into this cluster for detailed examination. E 2 found that sub-cluster C contained the most well-performing architectures. He selected it and filtered the architectures with the highest accuracy by using the "acc" dimension of the PCP. With a further examination of the PCP (Fig. <ref type="figure" target="#fig_4">9D</ref>), E 2 found that most well-performing architectures did not contain any 3 × 3 averagepooling layer, and a few of them used one such layer. For verification, E 2 also examined the architectures with the top 10 accuracy in the table (Fig. <ref type="figure" target="#fig_4">9C'</ref>). Only two out of them use one average-pooling layer (the rows with orange borders), while the others do not use it. He commented that this followed the results of recent NAS methods <ref type="bibr" target="#b54">[55,</ref><ref type="bibr" target="#b62">63]</ref>, where average-pooling layers seldom appeared in the final searched architectures. Furthermore, we conducted a statistical test to compare the accuracy between architectures with and without average-pooling layers in NAS-Bench-201. The result showed that the accuracy of the architectures with an average-pooling layer was significantly lower than those without average-pooling layers (p &lt; 0.001). This indicates that: • Principle 5: average-pooling layers probably downgrade performance.</p><p>Following a similar analysis (the detailed analysis can be found in supplemental material), E 2 concluded other three design principles: • Principle 6: using multiple 3 × 3 convolution layers in one path improves model performance.</p><p>• Principle 7: using multiple paths containing 3 × 3 convolution layers improves model performance.</p><p>• Principle 8: having two or more paths without a convolution layer downgrades model performance.</p><p>Local analysis of the performance difference. Next, E 2 zoomed back to the overview and briefly examined the well-performing architectures in other clusters. These architectures are scattered in different locations (Fig. <ref type="figure" target="#fig_4">9(a)</ref>). However, some of their adjacent architectures can have much lower accuracy. For example, in cluster E, there is a representative architecture with high accuracy (Fig. <ref type="figure" target="#fig_4">9F</ref>) and a few adjacent ones with low accuracy. Typically, neighboring architectures have similar structures and perform similarly. To figure out the reason for the difference, E 2 analyzed them in context. He selected this well-performing architecture (F 1 ) and two adjacent poor-performing ones (the circles with orange borders, F 2 -F 3 ) for comparison (Fig. <ref type="figure" target="#fig_4">9F</ref>). By examining their structures, he found that F 1 followed Principles 4-8 and had the highest accuracy. F 2 followed Principles 7 and 8, and its accuracy was lower than that of F 1 by 2.13%. F 3 only followed Principle 8, and its accuracy was lower than that of F 1 by 7.65%. The expert appreciated the capability of ArchExplorer to visually convey the performance difference among adjacent architectures. He further commented that the easy finding of such differences and the associated visual explanations help him summarize design principles in a more detailed manner.  design an architecture to evaluate the effectiveness of the summarized design principles. For a fair comparison, he only utilized the layer candidates in NAS-Bench-201. E 2 proposed the two simplest architectures that followed all principles discovered from NAS-Bench-201 (Fig. <ref type="figure" target="#fig_5">10(a)</ref>). Each has an identity layer (Principle 4) and does not contain average-pooling layers (Principle 5). Besides, it has two paths with 3 convolution layers, and at least one of them contains multiple 3 × 3 convolution layers (Principles 6 and 7). The architecture design also followed Principle 8 by containing only one path without a convolution layer. Generally, larger FLOPs lead to better performance. Since the best-performing architecture searched by the recent NAS methods on CIFAR-10 has 153.3M FLOPs <ref type="bibr" target="#b62">[63,</ref><ref type="bibr" target="#b69">70]</ref> (Fig. <ref type="figure" target="#fig_5">10(b</ref>)), he finally selected the one having the largest number of FLOPs (149.3M).</p><p>The generalization ability of the selected principle-based architecture and the best-performing NAS-searched one was evaluated by comparing the performance on a set of image classification datasets. These datasets are from the publicly available Kaggle dataset <ref type="bibr" target="#b26">[27]</ref>: Aircraft, Cars, Covid, DTD, GTSRB, Blood Cells, and Scene. They cover different types of images, including real-world objects, medical images, textures, and scenes. The number of categories in these datasets varies from a few to more than a hundred. Table <ref type="table" target="#tab_1">1</ref> shows the accuracy comparison between the NAS-searched architecture (column "NAS-searched") and the principle-based architecture (column "Principle-based"). We found that the principle-based architecture achieved better or comparable accuracy on all datasets. It had an average accuracy improvement of 1.0%. This demonstrated the effectiveness of the summarized design principles for designing architectures with better generalization ability.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Post-Analysis</head><p>Two experiments were conducted to demonstrate the effectiveness of the design principles in improving the search efficiency of NAS. Experimental settings. We selected a state-of-the-art NAS method, LaNAS <ref type="bibr" target="#b62">[63]</ref>, as our baseline. Then a hybrid method was implemented, which updated LaNAS to reflect Principles 1-8 by discarding the violating architectures in its search process.</p><p>In the experiments, we employed two widely-used architecture spaces, NASNet <ref type="bibr" target="#b62">[63]</ref> and NAS-Bench-301 <ref type="bibr" target="#b55">[56]</ref>. In NASNet, each architecture contains ten layers chosen from four candidates: 3 × 3 max-pooling, 3 × 3 depth-separable convolution, 5 × 5 depth-separable convolution, and identity. In NAS-Bench-301, each architecture contains eight layers chosen from seven candidates, including 3×3 averagepooling, 3 × 3 dilated convolution, 5 × 5 dilated convolution, and the four candidates in NASNet.</p><p>The computation cost of a search process was evaluated by the total Analysis. To identify the reason for the computation cost reduction, we first analyzed the searched architectures found by LaNAS (without integrating any design principle) on NAS-Bench-301 (Fig. <ref type="figure" target="#fig_6">11</ref>(a)). To better understand the search process of LaNAS, we analyzed the searched architectures at different iterations of the search process. We utilized a scented widget to highlight the architectures at different iterations in the architecture visualization. The analysis started from the architectures searched in the first 25% iterations of LaNAS. We found that these architectures randomly came from different clusters with different numbers of pooling layers. We further examined the architectures in the 25%-50%, 50%-75%, and the last 25% iterations. It was found that architectures without a pooling layer appeared more frequently as the search went on. This indicates that LaNAS gradually "learns" a few design principles for searching well-performing architectures, such as the preference of using fewer or even no pooling layers in the search process (Principles 3 and 5). To discover the common properties of the well-performing architectures, we selected them by using the "acc" dimension of the PCP (Fig. <ref type="figure" target="#fig_6">11B</ref>). We found that they had one to three identity layers (Fig. <ref type="figure" target="#fig_6">11A</ref>). By examining their structures, we identified that they had identity layers connecting the input and the output (Fig. <ref type="figure" target="#fig_6">11(c</ref>)), which followed Principle 4. We then counted the occurrence of the architectures with such property at different iterations. These architectures appeared more often in the last 25% of the searched architectures than in the previously ones (50.2% vs. 29.8%), showing that LaNAS also learned such knowledge in the search process. Second, after understanding the working mechanism of the search process of LaNAS, we briefly elaborated on why design principles could reduce the computation cost. By integrating the design principles, LaNAS filters out the architectures that violate any design principles and thus quickly focuses on searching among the well-performing architectures. This reduces the search space (2,000→1,000) and computation cost while also keeping the accuracy of the searched architectures.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">DISCUSSION AND FUTURE WORK</head><p>We conducted a three-hour demo session with the experts. Overall, they appreciated the usefulness and effectiveness of ArchExplorer in summarizing design principles and searching for better-performing architectures. They especially liked the combination of easy-to-use and familiar visualization techniques, such as circle packing and piechart-based summary glyphs. It allows them to find the architectures of interest more quickly and thus focus more on the analysis tasks. Based on a comprehensive analysis, the experts can propose and validate design principles. They also pointed out some limitations that might lead to future research directions.</p><p>Providing more exploration guides. During the collaboration with the experts, we obtained two main needs for acquiring information more easily. First, they required to automatically summarize the characteristics of an architecture cluster and generate a meaningful label (e.g. , a short phrase) for it. For example, in Fig. <ref type="figure" target="#fig_0">1</ref>(a), the desired labels of cluster C can be "using one max-pooling layer and four convolution layers" and "max-pooling layer appearing at the end of the architecture." Such labels can reduce the efforts in identifying the clusters of interest. In addition, this feature will benefit practitioners with average domain knowledge in the model designing process. As commented by experts, the interpretation of current cluster characteristics requires some expertise in the target architecture space. Thus, an interesting avenue is how to leverage the natural language processing techniques, such as GPT-3 <ref type="bibr" target="#b3">[4]</ref>, to generate meaningful labels for architecture clusters and intuitively illustrate them in the architecture visualization. Second, they hoped to visually search the architectures with specific structure components. For example, the experts are interested in how performance changes when replacing an identity layer with a 1 × 1 convolution layer in an architecture of interest. Therefore, another promising future work is to support a structure-based visual query for searching architectures.</p><p>Recommending candidate design principles. The capability of Arch-Explorer in facilitating experts to summarize design principles is demonstrated in the case studies. The experts appreciated this capability because design principles are useful for designing a better-performing architecture. However, the current analysis workflow requires them to explore the architecture space, identify the architectures of interest, and then compare them in context. This takes some time for machine learning experts and even longer time for junior model developers.</p><p>To accelerate the analysis process, the experts required the tool to automatically recommend candidate design principles. Based on the recommendation, they can visually analyze the associated architectures and verify the validity of the candidate design principles. Thus, in the future, we are interested in developing an efficient algorithm for recommending candidate design principles and tightly integrating it with our tool for iteratively verifying these candidates.</p><p>Integrating into the search process of a NAS algorithm. The experts also pointed out that integrating ArchExplorer into the search process of a NAS algorithm would be very useful and effective to reduce the computation cost. This integration opens up the possibility for incrementally integrating the design principles discovered at previous search iterations into the next iteration of the NAS algorithm. To facilitate such an incremental integration, ArchExplorer needs two major augmentations. First, we need to develop an incremental hierarchical clustering algorithm for effectively handling newly searched architectures at each iteration. Second, a set of interactions are required for incrementally and efficiently integrating the summarized design principles into the search process. For example, we can automatically convert the design principles into a set of constraints and then allow users to interactively refine them based on their search purposes. The refined constraints are utilized by the next search iteration for fast convergence.</p><p>Analyzing broader neural architecture spaces. In ArchExplorer, we focus on analyzing the influence of the structure on model performance.</p><p>In general, the performance of a neural network architecture is also influenced by other model-related factors, such as training hyperparameters (learning rates, batch sizes, etc.), training procedure, and data distribution <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b70">71]</ref>. Thus, it would be useful to jointly consider these factors in ArchExplorer. To this end, there are some necessary extensions for ArchExplorer. For example, it is worth exploring how to tightly combine ArchExplorer with existing visual analytics works on analyzing data-distribution-related issues for summarizing the design principles from both structure and data perspectives.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">CONCLUSION</head><p>In this paper, we have developed ArchExplorer, a visual analysis method for understanding a neural architecture space and summarizing design principles. The neural network architectures are represented by directed acyclic graphs, and graph edit distance is employed to model the similarity relationships between them. We formulate the pairwise distance calculation between architectures as an all-pairs shortest path problem and solve it with an accelerated Dijkstra algorithm. Based on the calculated distances, the architectures are then hierarchically clustered. A circle-packing-based architecture visualization has been developed to facilitate the interactive analysis of the architecture space. This visualization well conveys both the global relationships between clusters and the local neighborhoods of the architectures in each cluster.</p><p>The effectiveness of ArchExplorer is demonstrated by two case studies, and the usefulness of the summarized design principles is verified by reducing the computation cost of a state-of-the-art NAS method.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 :</head><label>1</label><figDesc>Fig. 1: ArchExplorer: (a) the architecture visualization to show the architecture clusters; (b) three selected sub-clusters after zooming into cluster A; (c) a detailed comparison of the selected architectures.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 3 :</head><label>3</label><figDesc>Fig. 3: Architecture distance calculation: (a) an example architecture space; (b) building the graph by connecting architectures with only one edit operation difference; (c) calculating all the pairwise distances.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 4 :</head><label>4</label><figDesc>Fig. 4: Decomposing the APSP problem into a set of SSSP problems. The blue dots represent the source architecture, and the blue lines are the visited paths from the source architecture in the Dijkstra algorithm.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 5 :Fig. 6 :</head><label>56</label><figDesc>Fig. 5: Visual design of the architecture space: (a) an architecture cluster; (b) a summary glyph; (c) a structure glyph.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 9 :</head><label>9</label><figDesc>Fig. 9: The analysis workflow of NAS-Bench-201. The dashed ellipses mark the similar parts of the shown architectures.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 10 :</head><label>10</label><figDesc>Designing an architecture with better generalization ability. Based on the above design principles, we collaborated with E 2 to manually NASArchitecture comparison: (a) the principle-based architectures; (b) the NAS-searched architecture with the highest accuracy.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 11 :</head><label>11</label><figDesc>Fig. 11: Analyzing the searched architectures by LaNAS on NAS-Bench-301: (a) overview of the architecture clusters; (b) filtering the well-performing architectures; (c) an example of the well-performing architecture that has identity layers connecting the input and output.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>.022 2396.128s 6.607M A-565150 92.498 2898.259s 15.174M A-718634 93.259 2620.858s 8.576M A-5b08c0 92.882 2351.478s 6.607M A-96372a 92.745 2531.631s 7.024M A-129214 92.702 4230.156s 30.924M</head><label></label><figDesc></figDesc><table><row><cell></cell><cell cols="2">Architecture Distance Calculation</cell><cell cols="2">Visualization</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>Archs.</cell><cell>MP3</cell><cell>C1</cell><cell>C3</cell><cell>skip</cell><cell>acc</cell><cell>time</cell><cell>params</cell></row><row><cell></cell><cell></cell><cell>...</cell><cell>S e le c t</cell><cell cols="5">A-0f42a9 93Arch MP3 C1 C3 skip acc 0 1 0 1 2 3 1 2 1 2 90 91 92 3 4 3 93 94 A (20) ×</cell><cell>time 1,000 1,500 2,000 2,500 3,000 3,500 4,000 4,500</cell><cell>params 0 10 20 30 40</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>A-a4715a</cell><cell></cell><cell></cell><cell></cell><cell>× A-0f42a9</cell><cell>×</cell></row><row><cell>...</cell><cell>...</cell><cell>...</cell><cell></cell><cell>input A-718634</cell><cell cols="4">Visual comparison output maxpool3x3 conv1x1 conv3x3 × A-129214</cell><cell>×</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc>Comparison of the generalization ability between the NASsearched architecture and the principle-based architecture.</figDesc><table><row><cell>Dataset</cell><cell cols="3"># classes NAS-searched Principle-based</cell></row><row><cell>Aircraft</cell><cell>41</cell><cell>85.3%</cell><cell>(+0.0%) 85.3%</cell></row><row><cell>Cars</cell><cell>196</cell><cell>74.2%</cell><cell>(+1.3%) 75.5%</cell></row><row><cell>Covid</cell><cell>4</cell><cell>95.0%</cell><cell>(+0.0%) 95.0%</cell></row><row><cell>DTD</cell><cell>47</cell><cell>56.6%</cell><cell>(+2.3%) 58.9%</cell></row><row><cell>GTSRB</cell><cell>43</cell><cell>97.4%</cell><cell>(+0.1%) 97.5%</cell></row><row><cell>Blood Cells</cell><cell>4</cell><cell>90.6%</cell><cell>(+3.7%) 94.3%</cell></row><row><cell>Scene</cell><cell>6</cell><cell>91.4%</cell><cell>(+0.2%) 91.6%</cell></row><row><cell cols="2">Average</cell><cell>84.4%</cell><cell>(+1.0%) 85.4%</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>Comparison of the search space, computation cost and accuracy on NASNet and NAS-Bench-301. Bench-301, we use the accuracy provided in the dataset. Since we did not need to train the architectures in this space, the GPU hours for training the searched architectures in this search were estimated by multiplying the number of searched architectures and the GPU hours for training one architecture. Here, the GPU hours for training one architecture were estimated by averaging the training time of ten randomly-sampled architectures in this space. Results. Table2compares the search space, computation cost, and accuracy between LaNAS and the hybrid method with design principles on NASNet and NAS-Bench-301. Compared with LaNAS, the hybrid method reduced the search space and computation cost by around 50% while achieving at least the same accuracy on both datasets.</figDesc><table><row><cell>Dataset</cell><cell cols="4">Method # archs. GPU hours Accuracy</cell></row><row><cell>NASNet</cell><cell>LaNAS Hybrid</cell><cell>800 400</cell><cell>1,635 822</cell><cell>97.99% 98.10%</cell></row><row><cell>NAS-301</cell><cell>LaNAS Hybrid</cell><cell>2,000 1,000</cell><cell>3,019 1,510</cell><cell>94.83% 94.83%</cell></row><row><cell cols="5"># archs. refers to the number of searched architectures.</cell></row><row><cell cols="5">GPU hours for searching and training the architectures. It is prohibitive</cell></row><row><cell cols="5">to train each searched architecture in NASNet from scratch to full</cell></row><row><cell cols="5">convergence (about 60 GPU hours for each architecture and nearly</cell></row><row><cell cols="5">50, 000 GPU hours in total for a search process). Following the recent</cell></row><row><cell cols="5">research [49], we trained each architecture for 20 epochs on CIFAR-10.</cell></row><row><cell>In NAS-</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS</head><p>This work was supported by National Key R&amp;D Program of China under Grant 2020YFB2104100, the National Natural Science Foundation of China under grants U21A20469 and 61936002, grants from the Institute Guo Qiang, THUIBCS, and BLBCI, and in part by Tsinghua-Kuaishou Institute of Future Media Data. The authors would like to thank Weikai Yang, Chengjian Chen and Zhen Li for their valuable comments.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A comprehensive review of quadratic assignment problem: Variants, hybrids and applications</title>
		<author>
			<persName><forename type="first">M</forename><surname>Abdel-Basset</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Manogaran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Rashad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">N H</forename><surname>Zaied</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Ambient Intelligence and Humanized Computing</title>
		<imprint>
			<biblScope unit="page" from="1" to="24" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">An exact graph edit distance algorithm for solving pattern recognition problems</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Abu-Aisheh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Raveaux</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-Y</forename><surname>Ramel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Martineau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Pattern Recognition Applications and Methods</title>
				<meeting>the International Conference on Pattern Recognition Applications and Methods</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="271" to="278" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Analysis of K-Means and K-Medoids algorithm for big data</title>
		<author>
			<persName><forename type="first">P</forename><surname>Arora</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Deepali</surname></persName>
		</author>
		<author>
			<persName><surname>Varshney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Procedia Computer Science</title>
		<imprint>
			<biblScope unit="volume">78</biblScope>
			<biblScope unit="page" from="507" to="512" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Language models are few-shot learners</title>
		<author>
			<persName><forename type="first">T</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Mann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Ryder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Subbiah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Kaplan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Dhariwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Neelakantan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Shyam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Sastry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Askell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Advances in Neural Information Processing Systems</title>
				<meeting>the Advances in Neural Information Processing Systems</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="1877" to="1901" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Net2Vis -A visual grammar for automatically generating publication-tailored CNN architecture visualizations</title>
		<author>
			<persName><forename type="first">A</forename><surname>Bäuerle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Van Onzenoodt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Ropinski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="2980" to="2991" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A user-based visual analytics workflow for exploratory model analysis</title>
		<author>
			<persName><forename type="first">D</forename><surname>Cashman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">R</forename><surname>Humayoun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Heimerl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Thompson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Saket</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mosca</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Stasko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Endert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gleicher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics Forum</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="185" to="199" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Ablate, variate, and contemplate: Visual analytics for discovering neural architectures</title>
		<author>
			<persName><forename type="first">D</forename><surname>Cashman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Perer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Strobelt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="863" to="873" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">A simple proof of Thue&apos;s theorem on circle packing</title>
		<author>
			<persName><forename type="first">H.-C</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L.-C</forename><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1009.4322</idno>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">VisEvol: Visual analytics to support hyperparameter search through evolutionary optimization</title>
		<author>
			<persName><forename type="first">A</forename><surname>Chatzimparmpas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Martins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Kucher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kerren</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics Forum</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="201" to="214" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Interactive graph construction for graph-based semi-supervised learning</title>
		<author>
			<persName><forename type="first">C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L.-Z</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y.-F</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="3701" to="3716" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">OoDAnalyzer: Interactive analysis of out-of-distribution samples</title>
		<author>
			<persName><forename type="first">C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="3335" to="3349" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Introduction to algorithms</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">H</forename><surname>Cormen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">E</forename><surname>Leiserson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">L</forename><surname>Rivest</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Stein</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009</date>
			<publisher>MIT press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">QUESTO: Interactive construction of objective functions for classification tasks</title>
		<author>
			<persName><forename type="first">S</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gleicher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Endert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics Forum</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="153" to="165" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Attention Flows: Analyzing and comparing attention mechanisms in language models</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">F</forename><surname>Derose</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Berger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1160" to="1170" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">One-shot neural architecture search via selfevaluated template network</title>
		<author>
			<persName><forename type="first">X</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision</title>
				<meeting>the IEEE/CVF International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="3681" to="3690" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">NAS-Bench-201: Extending the scope of reproducible neural architecture search</title>
		<author>
			<persName><forename type="first">X</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Learning Representations</title>
				<meeting>the International Conference on Learning Representations</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Neural architecture search: A survey</title>
		<author>
			<persName><forename type="first">T</forename><surname>Elsken</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Metzen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Hutter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">55</biblScope>
			<biblScope unit="page" from="1" to="21" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Rich feature hierarchies for accurate object detection and semantic segmentation</title>
		<author>
			<persName><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Donahue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2014 IEEE Conference on Computer Vision and Pattern Recognition</title>
				<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="580" to="587" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
				<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">AutoML: A survey of the state-of-the-art. Knowledge-Based Systems</title>
		<author>
			<persName><forename type="first">X</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Chu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">212</biblScope>
			<biblScope unit="page">106622</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Visual analytics in deep learning: An interrogative survey for the next frontiers</title>
		<author>
			<persName><forename type="first">F</forename><surname>Hohman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kahng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Pienta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">H</forename><surname>Chau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="2674" to="2693" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Densely connected convolutional networks</title>
		<author>
			<persName><forename type="first">G</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Van Der Maaten</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">Q</forename><surname>Weinberger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
				<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="2261" to="2269" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Net: a self-configuring method for deep learning-based biomedical image segmentation</title>
		<author>
			<persName><forename type="first">F</forename><surname>Isensee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">F</forename><surname>Jaeger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Kohl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Petersen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">H</forename><surname>Maier-Hein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature methods</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="203" to="211" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">VisQA: X-raying vision and language reasoning in transformers</title>
		<author>
			<persName><forename type="first">T</forename><surname>Jaunet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Kervadec</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Vuillemot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Antipov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Baccouche</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Wolf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="976" to="986" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Auto-Keras: An efficient neural architecture search system</title>
		<author>
			<persName><forename type="first">H</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Hu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</title>
				<meeting>the ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="1946" to="1956" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Evaluation of parallel coordinates: Overview, categorization and guidelines for future research</title>
		<author>
			<persName><forename type="first">J</forename><surname>Johansson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Forsell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="579" to="588" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title/>
		<author>
			<persName><surname>Kaggle</surname></persName>
		</author>
		<author>
			<persName><surname>Kaggle</surname></persName>
		</author>
		<ptr target="https://www.kaggle.com/datasets" />
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="2022" to="2023" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">ActiVis: Visual exploration of industry-scale deep neural network models</title>
		<author>
			<persName><forename type="first">M</forename><surname>Kahng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">Y</forename><surname>Andrews</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kalro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">H</forename><surname>Chau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="88" to="97" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">An algorithm for drawing general undirected graphs</title>
		<author>
			<persName><forename type="first">T</forename><surname>Kamada</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kawai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Processing Letters</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="7" to="15" />
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Neural architecture search with Bayesian optimisation and optimal transport</title>
		<author>
			<persName><forename type="first">K</forename><surname>Kandasamy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Neiswanger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schneider</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Póczos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">P</forename><surname>Xing</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Advances in Neural Information Processing Systems</title>
				<meeting>the Advances in Neural Information Processing Systems</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="2020" to="2029" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">A survey of the recent architectures of deep convolutional neural networks</title>
		<author>
			<persName><forename type="first">A</forename><surname>Khan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sohail</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Zahoora</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">S</forename><surname>Qureshi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence Review</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="5455" to="5516" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Principles of Gestalt psychology</title>
		<author>
			<persName><forename type="first">K</forename><surname>Koffka</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013">2013</date>
			<publisher>Routledge</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">ImageNet classification with deep convolutional neural networks</title>
		<author>
			<persName><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Advances in Neural Information Processing Systems</title>
				<meeting>the Advances in Neural Information Processing Systems</meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="1097" to="1105" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">A unified understanding of deep nlp models for text classification</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<idno type="DOI">10.1109/TVCG.2022.3184186</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note>to be published</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">DARTS: Differentiable architecture search</title>
		<author>
			<persName><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Learning Representations</title>
				<meeting>the International Conference on Learning Representations</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Analyzing the training processes of deep generative models</title>
		<author>
			<persName><forename type="first">M</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="77" to="87" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Towards better analysis of deep convolutional neural networks</title>
		<author>
			<persName><forename type="first">M</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="91" to="100" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Visual diagnosis of tree boosting methods</title>
		<author>
			<persName><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="163" to="173" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">A visual analytics framework for explaining and diagnosing transfer learning processes</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">R</forename><surname>Nelakurthi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Maciejewski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1385" to="1395" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Clutter-aware label layout</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Pacific Visualization Symposium</title>
				<meeting>the IEEE Pacific Visualization Symposium</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="207" to="214" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Understanding hidden memories of recurrent neural networks</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Ming</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Qu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Visual Analytics Science and Technology</title>
				<meeting>the IEEE Conference on Visual Analytics Science and Technology</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="13" to="24" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Path planning using hardware time delays</title>
		<author>
			<persName><forename type="first">R</forename><surname>Moller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Robotics and Automation</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="588" to="592" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">DeepCompare: Visual and interactive comparison of deep learning model performance</title>
		<author>
			<persName><forename type="first">S</forename><surname>Murugesan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Malik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Koh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">M</forename><surname>Lai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer Graphics and Applications</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="47" to="59" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Optimal transport kernels for sequential and parallel neural architecture search</title>
		<author>
			<persName><forename type="first">V</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Yamada</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Osborne</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Machine Learning</title>
				<meeting>the International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="8084" to="8095" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">A generic graphbased neural architecture encoding scheme for predictor-based NAS</title>
		<author>
			<persName><forename type="first">X</forename><surname>Ning</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision</title>
				<meeting>the European Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="189" to="204" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Pipeline-Profiler: A visual analytics tool for the exploration of AutoML pipelines</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">P</forename><surname>Ono</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Castelo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Lopez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Bertini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Freire</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Silva</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="390" to="400" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">HyperTendril: Visual analytics for user-driven hyperparameter optimization of deep neural networks</title>
		<author>
			<persName><forename type="first">H</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Nam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-H</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Choo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1407" to="1416" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">A simple and fast algorithm for K-medoids clustering</title>
		<author>
			<persName><forename type="first">H.-S</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C.-H</forename><surname>Jun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Expert Systems with Applications</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="3336" to="3341" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Designing network design spaces</title>
		<author>
			<persName><forename type="first">I</forename><surname>Radosavovic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">P</forename><surname>Kosaraju</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Dollár</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
				<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="10425" to="10433" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Visualizing the hidden activity of artificial neural networks</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">E</forename><surname>Rauber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">G</forename><surname>Fadel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">X</forename><surname>Falcao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Telea</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="101" to="110" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Squares: Supporting interactive performance analysis for multiclass classifiers</title>
		<author>
			<persName><forename type="first">D</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Amershi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Suh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Williams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="61" to="70" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Approximate graph edit distance computation by means of bipartite graph matching</title>
		<author>
			<persName><forename type="first">K</forename><surname>Riesen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Bunke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Image and Vision Computing</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="950" to="959" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">VIS4ML: An ontology for visual analytics assisted machine learning</title>
		<author>
			<persName><forename type="first">D</forename><surname>Sacha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kraus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Keim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="385" to="395" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">R</forename><surname>Schwartz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Dodge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Etzioni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">I</forename><surname>Green</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="54" to="63" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Bridging the gap between sample-based and one-shot neural architecture search with BONAS</title>
		<author>
			<persName><forename type="first">H</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Pi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">T</forename><surname>Kwok</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Advances in Neural Information Processing Systems</title>
				<meeting>the Advances in Neural Information Processing Systems</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="1808" to="1819" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<monogr>
		<title level="m" type="main">NAS-Bench-301 and the case for surrogate benchmarks for neural architecture search</title>
		<author>
			<persName><forename type="first">J</forename><surname>Siems</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zimmer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zela</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lukasik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Keuper</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Hutter</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2008.09777</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">LSTMVis: A tool for visual analysis of hidden state dynamics in recurrent neural networks</title>
		<author>
			<persName><forename type="first">H</forename><surname>Strobelt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gehrmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Pfister</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Rush</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="667" to="676" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">EfficientNet: Rethinking model scaling for convolutional neural networks</title>
		<author>
			<persName><forename type="first">M</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Machine Learning</title>
				<meeting>the International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="6105" to="6114" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Dimensionality reduction: A comparative review</title>
		<author>
			<persName><forename type="first">L</forename><surname>Van Der Maaten</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Postma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Van Den Herik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">13</biblScope>
			<biblScope unit="page" from="66" to="71" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Differentiable neural architecture search for spatial and channel dimensions</title>
		<author>
			<persName><forename type="first">A</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
				<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="12965" to="12974" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">On redundancy and diversity in cell-based neural architecture search</title>
		<author>
			<persName><forename type="first">X</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Ru</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">M</forename><surname>Esperanc</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
				<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">AutoDS: Towards human-centered automation of data science</title>
		<author>
			<persName><forename type="first">D</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Andres</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Weisz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Oduor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Dugan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the CHI Conference on Human Factors in Computing Systems</title>
				<meeting>the CHI Conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="1" to="12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Sample-efficient neural architecture search by learning actions for monte carlo tree search</title>
		<author>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Fonseca</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Tian</surname></persName>
		</author>
		<idno type="DOI">10.1109/TPAMI.2021.3071343</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note>to be published</note>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">ATMSeer: Increasing transparency and controllability in automated machine learning</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Ming</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Veeramachaneni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Qu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the CHI Conference on Human Factors in Computing Systems</title>
				<meeting>the CHI Conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="1" to="12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Visual analysis of discrimination in machine learning</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Qu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1470" to="1480" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Visualization of large hierarchical data by circle packing</title>
		<author>
			<persName><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the SIGCHI Conference on Human Factors in Computing Systems</title>
				<meeting>the SIGCHI Conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="517" to="520" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">CNN Explainer: Learning convolutional neural networks with interactive visualization</title>
		<author>
			<persName><forename type="first">Z</forename><forename type="middle">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Turko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Shaikh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Hohman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kahng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">H</forename><surname>Chau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1396" to="1406" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">AutoAIViz: Opening the blackbox of automated artificial intelligence with conditional parallel coordinates</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">K I</forename><surname>Weidele</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Weisz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Oduor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Muller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Andres</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Intelligent User Interfaces</title>
				<meeting>the International Conference on Intelligent User Interfaces</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="308" to="312" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">A study on encodings for neural architecture search</title>
		<author>
			<persName><forename type="first">C</forename><surname>White</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Neiswanger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Nolen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Savani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Advances in Neural Information Processing Systems</title>
				<meeting>the Advances in Neural Information Processing Systems</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="20309" to="20319" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Stronger NAS with weaker predictors</title>
		<author>
			<persName><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Yuan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Advances in Neural Information Processing Systems</title>
				<meeting>the Advances in Neural Information Processing Systems</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="1" to="14" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Diagnosing concept drift with visual analytics</title>
		<author>
			<persName><forename type="first">W</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Maciejewski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Visual Analytics Science and Technology</title>
				<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="12" to="23" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Diagnosing ensemble few-shot classifiers</title>
		<author>
			<persName><forename type="first">W</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Pfister</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="3292" to="3306" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">NAS-Bench-101: Towards reproducible neural architecture search</title>
		<author>
			<persName><forename type="first">C</forename><surname>Ying</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Christiansen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Real</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Hutter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Machine Learning</title>
				<meeting>the International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="7105" to="7114" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">A survey of visual analytics techniques for machine learning</title>
		<author>
			<persName><forename type="first">J</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Visual Media</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="3" to="36" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">Evaluation of sampling methods for scatterplots</title>
		<author>
			<persName><forename type="first">J</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1720" to="1730" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">iForest: Interpreting random forests via visual analytics</title>
		<author>
			<persName><forename type="first">X</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">L</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Cui</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="407" to="416" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">Learning transferable architectures for scalable image recognition</title>
		<author>
			<persName><forename type="first">B</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Vasudevan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
				<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="8697" to="8710" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
