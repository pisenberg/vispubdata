<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">SliceTeller : A Data Slice-Driven Approach for Machine Learning Model Validation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Xiaoyu</forename><surname>Zhang</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Jorge</forename><forename type="middle">Piazentin</forename><surname>Ono</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Huan</forename><surname>Song</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Liang</forename><surname>Gou</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Kwan-Liu</forename><surname>Ma</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Liu</forename><surname>Ren</surname></persName>
						</author>
						<title level="a" type="main">SliceTeller : A Data Slice-Driven Approach for Machine Learning Model Validation</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.2" ident="GROBID" when="2023-03-27T09:18+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Model Validation</term>
					<term>Data Slicing</term>
					<term>Data Validation</term>
					<term>Model Evaluation</term>
					<term>Data-Centric AI</term>
					<term>Human-in-the-loop</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Fig. 1. SliceTeller applied to the comparison of two machine learning models (ResNet50 and GroupDRO) for hair color classification (gray hair, not gray hair), trained on the CelebFaces Attributes Dataset (CelebA). (A) Slice Matrix: The data slices (represented as rows), slice descriptions (encoded as columns), and slice metrics (Support and Accuracy). Slices are sorted by model accuracy. (A -Tooltip) Confusion matrix for Slice 1. (B) Estimated effects of optimizing the model for two data slices (Slices 1 and 2, highlighted in blue). (C) Accuracy comparison between the two models, ResNet50 and GroupDRO. (D) Slice Detail View containing image samples from a data slice. (E) Slice Detail View containing the comparison of two data slices using the MatrixScape visualization. (F) System menu, containing options for model selection, effect estimation of focusing on a slice during model training, and data slice summarization.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>• * These authors contributed equally. ations) engineers for product-quality model development, we have identified that the evaluation of critical ML models is usually conducted beyond the aggregated level (e.g., a single performance metric). Instead, they need to thoroughly evaluate model performance on carefully specified usage scenarios or conditions in order to meet important ML product requirements. Based on this analysis, experts can then take actions to 1) attempt to make the model more robust to various conditions and 2) make customers aware of model limitations in certain conditions, aiding in the development of mitigating measures. During the evaluation of ML models, model developers often have to slice their data based on the specified product usage conditions, to ensure satisfactory performance under such critical conditions. For example, in the autonomous driving setting, experts need to ensure high detection rates for multiple environmental conditions, such as sunny weather and rain, and specific object types, such as cars and pedestrians. Figure <ref type="figure" target="#fig_0">2</ref> shows a common workflow for critical model analysis and iteration.</p><p>Challenges on Model Evaluation and Iteration. While the slicebased analysis is essential for the critical applications, this approach has several limitations. 1) Manually slicing the data is a very timeconsuming task. In our interviews, experts mentioned that this task involved manually creating rules to slice the data, running evaluation scripts on the data subsets, and comparing the results on various data subsets. 2) ML experts cannot explore all possible data subsets to identify relevant failures cases for their application. Data slices can be created by any number of interpretable meta-data (e.g., weather and temperature for autonomous driving), resulting in an exponentially large search space. Therefore, they must rely on domain-specific priors to select what meta-data they will slice the data based on. 3) Once the critical failures are identified, experts have the options to either collect more data to cover the weakness scenarios or retrain their models by prioritizing the critical slices. While the former requires additional investment on data collection, the latter is usually time-consuming, particularly for training neural network architectures. Moreover, it is unclear how the new model will trade-off performance on other slices and whether the result can still meet the product requirements.</p><p>Our Approach. We develop SliceTeller, a novel data slice-driven model validation tool that automates slice finding, enables slice-based model validation and comparison, and allows what-if analysis for slice prioritization. Our tool takes as input the data (non-interpretable features), metadata (interpretable properties that can be used to slice the data), dataset labels and model predictions. A state-of-the-art slicefinding algorithm is adapted to find slices on the data for which a performance metric (for example, accuracy) is significantly different from the overall model metric. Once these slices are found, we use a binary matrix graphical encoding to show the data slices compactly, as well as metrics for these data slices (Figure <ref type="figure" target="#fig_2">1</ref>). We also provide various visualization to help users understand and interpret these data slices. After a data slice of interest is found, users can estimate the performance impact of optimizing the model for this data slice using our effect estimation algorithm, called SliceBoosting. Finally, users can quickly find problematic data slices on their model and derive actionable insights that can be used to improve the results according to their product requirements in a next training iteration.</p><p>Our main contributions include the following:</p><p>1. A novel Visual Analytics (VA) tool, SliceTeller, for the evaluation and comparison of ML models using a data slicing approach. SliceTeller combines data slice finding, together with effective visual representations for data slices and model metrics, to facilitate the iteration and comparison of ML models.</p><p>2. An efficient algorithm, SliceBoosting, for the quick estimation of data slice trade-offs during model training to improve model iteration efficiency. This algorithm estimates the performance effect of focusing on one or more data slices during model training, highlighting potential trade-offs between data slice optimization and overall model performance.</p><p>3. Three use cases, including two real-world use cases of product development, to demonstrate the effectiveness of our approach in assessing, comparing, and iterating over ML model results. We believe our method and design process together with product R&amp;D partner and MLOps Engineers can benefit the practice and research of using VA for model validation at large. In summary, SliceTeller, is a novel VA tool for ML model validation with a data-slice driven approach. This tool is model-agnostic and can be easily plugged in MLOps life-cycles. This work also resonates with recent data-centric AI trends focusing on data instead of models. We hope this work can inspire more research questions innovating VA approaches to address data-driven model validation challenges.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK 2.1 Slice-Oriented Model Validation</head><p>Finding the subgroups of specific quality is one of the classical combinatorial optimization problems, named Constraint Satisfaction Problem (CSP) <ref type="bibr" target="#b50">[51]</ref>. This problem is defined as slice finding in the context of ML model evaluation, the aim of which is to identify the data subgroups over which the ML subgroups underperforms <ref type="bibr" target="#b1">[2]</ref>.</p><p>Most of the existing solutions in commercial tools use greedy heuristics to balance the tradeoff between searching speed and accuracy. For instance, the FreaAI in IBM IGNITE <ref type="bibr" target="#b0">[1]</ref>, Slice Finder in Tensorflow <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b7">8]</ref>, Amazon Sagemaker <ref type="bibr" target="#b31">[32]</ref>, and RobustnessGym <ref type="bibr" target="#b14">[15]</ref> are built upon heuristic techniques such as clustering, self-defined metrics (e.g., highest posterior density), model-based, and rule-based data slicing. Efficient as they are, heuristic solutions could miss critical data slices if they fall into the blind area of the heuristic rules (e.g., the slice size is too small). Thanks to the development of parallel computing devices, researchers could solve this problem by using exhaustive searching with a reasonable time cost. For example, SliceLine includes size and score pruning to boost the performance of exhaustive search, which can be easily deployed onto the parallel devices <ref type="bibr" target="#b46">[47]</ref>. DivExplorer <ref type="bibr" target="#b42">[43]</ref><ref type="bibr" target="#b43">[44]</ref><ref type="bibr" target="#b44">[45]</ref> enumerate the data lattice to look for all candidate itemsets with the highest divergence and support the customization of itemset size. Since such flexibility would allow us to let the users decide the slices they are interested in, we choose DivExplorer as the slice finding tool for our system. The research work in this direction is still in the exploratory stage, and there is an increasing trend of introducing ML for solving the classical combinatorial optimization problems <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b33">34]</ref>.</p><p>However, these approaches mainly focus on search efficiency and scalability, but largely ignore how to understand and interpret the impact of these data slices. Also, it is a non-trivial task to customize and select data slices of interest based on domain-specific requirements. This is where our VA-based approach can help.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Model Robustness over Data Groups</head><p>ML robustness research focuses on achieving consistent model performance under various conditions. Due to data collection, sampling or annotation biases, ML models trained on real-world data tend to identify spurious correlations, connections that appear extensively in the training data, but do not hold in novel scenarios <ref type="bibr" target="#b27">[28,</ref><ref type="bibr" target="#b38">39]</ref>. Under distribution shift, models that rely on these spurious correlations often degrade significantly in performance <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b35">36]</ref>.</p><p>One powerful approach to alleviate this issue is group distributionally robust optimization (DRO) <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b40">41]</ref>. Group DRO utilizes prior Fig. <ref type="figure">3</ref>. Workflow of the model analysis and improvement using SliceTeller . The validation data, together with the model predictions, are used for the automatic slice identification. The produced data slices can be explored using our VA solution (Slice Matrix and Slice Detail View). Users can prioritize groups of data slices and quickly evaluate the effect of this action on the rest of the model slices. Finally, experts can use the insights gained from the system to fine tune the model and continue the analysis with SliceTeller .</p><p>knowledge of spurious correlation to define groups over training data, and optimizes the worst-case loss among the groups, instead of the expected loss of the entire distribution. As a result, the trained model is capable of significantly improving minority group performance while maintaining similar performance over the majority groups. In <ref type="bibr" target="#b47">[48]</ref>, the authors investigate group DRO in the context of over-parameterized deep neural networks (DNNs). They discovered that as opposed to shallow ML models that can directly benefit from group DRO, DNNs require strong regularizations during training to achieve minority group improvements. Recent works along the direction of group DRO research incorporates instance-level weighting to tackle imperfect group partition <ref type="bibr" target="#b56">[57]</ref>, leverages human annotation to discover and optimize over unmeasured variables <ref type="bibr" target="#b49">[50]</ref>, and scales up the optimization method for large-scale problems <ref type="bibr" target="#b28">[29]</ref>.</p><p>In this paper, we utilize distributionally robust deep neural network described in <ref type="bibr" target="#b47">[48]</ref> as the slice optimization model. Our VA framework addresses the following core limitations of group DRO for practical usage: a) Group DRO requires that the group information of training data is known beforehand. Although empirical results have provided evidence of spurious correlations in popular public datasets <ref type="bibr" target="#b27">[28,</ref><ref type="bibr" target="#b40">41]</ref>, such insights are not readily available for most real-world ML problems. b) Group DRO training is time-consuming. It is therefore infeasible to exhaustively apply group DRO on all combinations of data slices in order to determine the ideal slices for optimization. By integrating slice discovery, effect estimation and model optimization under the same VA framework (Figure <ref type="figure">3</ref>), we help users identify problematic slices, understand the optimization trade-off among slices, and eventually optimize the model, thus significantly speeding up model iteration.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Visualization for Slice-Based Model Optimization</head><p>There are various VA techniques supporting the creation and analysis of data slices <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b53">54]</ref>. In the context of model exploration, CoFact <ref type="bibr" target="#b21">[22]</ref> is a VA system that helps users explore counterfactual subsets and thus understand the confounding facts in large and complex datasets. CoFact is close to the first part of our work, but its focus is on spurious feature correlations, not providing any model or data optimization recommendations. FairVIS <ref type="bibr" target="#b2">[3]</ref> and Manifold <ref type="bibr" target="#b55">[56]</ref> also allow data subgroup analysis based on human interaction, but do not provide automated methods for data slicing. Finally, Errudite <ref type="bibr" target="#b51">[52]</ref> provides a domain-specific language for data grouping with unstructured text data analysis, while we mainly focus on structured data.</p><p>Most of these works focus on the data exploration stage and rarely provide optimization solutions to close the entire loop. Therefore, we provide a VA solution for the entire loop of slice-based model optimization that supports slice finding, model optimization, and model comparison with a Matrix visualization inspired by UpSet <ref type="bibr" target="#b29">[30]</ref> and PipelineProfiler <ref type="bibr" target="#b39">[40]</ref>, along with carefully-designed interactions driven by the domain requirements described in Sec. 3.1. To the best of our knowledge, our system is the first of its kind to provide an end-to-end solution for users to identify, understand and optimize model performance on problematic data slices.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">SliceTeller</head><p>In this section, we describe SliceTeller, a system for data slice-driven validation of ML models. We first present a desiderata for our system, distilled from interviews with four industry partners from the product R&amp;D team. Next, we describe the visual components of our system. Finally, we present SliceBoosting, an algorithm that can estimate performance divergences after a slice-based model optimization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Data and Domain Requirements</head><p>SliceTeller was developed based on a collaborative product project with three industry MLOps engineers over the period of six months. We received continuous feedback from our partners, who worked on tabular and image-based classification problems. These experts work on products in critical applications, including autonomous driving and fire detection for building security. Therefore, they often conduct extensive validation of their models before deployment to production.</p><p>In the context of autonomous driving, experts were interested in modeling the ultrasonic sensors to understand the car surroundings. It is a critical modality in the sensor-fusion pipeline to enhance the overall system robustness. The raw ultrasonic sensor data are not directly interpretable by human. However, every sample also contained metadata describing the experiment setup, for example, the object type, distance, sensor location, time of day, etc. Experts had trained a tree boosting model to classify nearby objects' heights (as "high" or "low") using the sensor-derived tabular features. While evaluating their models, they wanted to make sure that certain critical objects had a low error rate. In some cases, they would trade-off between the performance of non-critical objects for the performance of the critical objects. For instance, children, curbstones, and nearby cars should have the highest priority. Therefore, in every evaluation iteration, they had to slice the data, evaluate the model on the data subsets, and retrain the model with different parameters to mitigate critical mistakes. Experts mentioned that these tasks were tedious and time-consuming.</p><p>For the fire detection application, experts trained a deep neural network to detect smoke and fire on video frames. In this setup, every video segment was associated with interpretable metadata that described the video collection process in detail, for example, the recording location, time of day, the smoke density, and whether there were blinking lights in the scene. While the overall performance of this model was high, experts were interested in identifying situations where it failed. Therefore, they spent a large amount of time inspecting the model and using the video metadata to identify these situations. Transparency with customers was a high priority for model release: they wanted to clearly communicate the model capabilities, where it was effective and where it failed. Furthermore, they wanted to understand why the model was failing, and what were the possible confounding features on their dataset.</p><p>While these two applications used different techniques and data types, the experts developing them shared a common goal. Figure <ref type="figure" target="#fig_0">2</ref> shows the model evaluation workflow derived from our interviews. In both cases, experts desired to slice the data into various scenarios, thoroughly evaluate their models, understand the failure cases, and develop strategies to tune the models to improve performance. They noted that this workflow usually took several iterations, requiring significant effort and trial-and-error. Based on these observations, we have compiled the following desiderata for a data slice-driven model validation system: [R1] Data Slice Finding and Overview: Users often spend a significant amount of time slicing the data based on certain heuristics to learn the boundaries of the model. Our system should automatically identify these data slices in the validation dataset and present an overview to the user. [R2] Slice-Based Data Understanding and Valuation: Users should be able to explore the data slices in order to understand them and value how critical they are. The system should allow the user to explore the data, model metrics, and distributions to explain these scenarios.</p><p>[R3] Slice-Based Model Optimization: In critical applications, experts need to trade-off the performance of certain scenarios in order to focus on critical use cases. To do so, they need to train models from scratch, which can be very time-consuming. The system should enable the quick experimentation with the slice-based model optimization, highlighting possible trade-offs in the data.</p><p>[R4] Slice-Based Model Comparison: Users need to train and evaluate multiple models in order to tune parameters and mitigate problems. However, this comparison is usually done at the aggregated level (e.g., a single metric value). The system should allow the comparison of model performances at the slice level, facilitating the identification of trade-offs between data slices.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">System Workflow</head><p>In order to fulfill the requirements identified in the previous section, we developed SliceTeller, a system that tells a story about the evolution of ML models from the perspective of data slices, allowing their evaluation, exploration and comparison. Figure <ref type="figure">3</ref> shows the general workflow for model analysis and improvement with SliceTeller. The input to SliceTeller is the validation dataset consisting of validation data (e.g., raw images or tabular features extracted from the sensor signals), metadata (interpretable features that can be used to slice the data), and ground truth labels (e.g., object classes or obstacle height). Note that we use a validation dataset for model analysis instead of training data since it is unseen by the model. In the case of model overfitting, we observe all slices in the training data having high accuracies. Given the input, the system works as follows:</p><p>1) First, the system uses an automatic slice finding algorithm to identify data slices where the performance measures (e.g., accuracy) are the most different from the overall model performance. We use the DivExplorer algorithm <ref type="bibr" target="#b43">[44]</ref>, a Frequent Pattern Mining-based approach for this task (Section 3.3).</p><p>2) Next, a VA system allows the users to quickly visualize and summarize the produced data slices using the Slice Matrix View (where rows correspond to slices, and columns, to slice descriptions and associated metrics). The user can select slices to view its details using the Slice Distribution View, which can present metadata distributions and correlations to the user. These two views allow the user to identify critical slices in the data, i.e. slices where the model performance has issues (Section 3.4).</p><p>3) When a critical slice is found, the user can test mitigating measures using the 'Slice Prioritization -What-If Analysis' tool. This tool uses our SliceBoosting algorithm to evaluate the effect of optimizing the model for particular data slices. SliceBoosting fits a shallow boosting model on top of the original model to estimate the effect of prioritized optimization (Section 3.5).</p><p>4) Finally, when the user found a group of slices to optimize, they can export the selected slices back to their programming environment, </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Data Slicing</head><p>We begin our analysis by automatically finding problematic data slices using the DivExplorer algorithm <ref type="bibr" target="#b43">[44]</ref> (illustrated in Figure <ref type="figure" target="#fig_1">4</ref>). The algorithm takes the model predictions and the meta-data (interpretable features of the dataset) as input, and executes an exhaustive slice search by frequent pattern mining <ref type="bibr" target="#b16">[17]</ref>. The minimum support (i.e., minimum slice size) is defined as a parameter by the user. Then, a model metric such as accuracy is computed for every data slice found.</p><p>To reduce the searching time for datasets with a larger number of metadata features, we conduct a two-iteration slice finding procedure using DivExplorer. First, we run DivExplorer with a large minimum support to identify the relevant metadata features which are most correlated with poor performance. Then, we run DivExplorer again using the relevant metadata features, this time with a lower minimum support to perform a more fine-grained search. The level of granularity (minimum support) can be fine-tuned by the user in order to find the relevant slices for their model. For example, users can fine-tune the parameter to find slices with sufficiently high support and low performance (such attributes are problem-specific and user-defined).</p><p>The DivExplorer algorithm can find an exponential number of data slices (exponential in the number of unique feature-value pairs). Therefore, we use a summarization approach to reduce the number of slices to be explored by the user [R1]. We allow users to summarize data slices with a redundancy pruning approach <ref type="bibr" target="#b43">[44]</ref> (slider in Figure <ref type="figure" target="#fig_2">1(F)</ref>). If the introduction of an item α (e.g., Weather = Sunny) in a slice S will cause an absolute performance change below a redundancy threshold ε, only the slice without α (denoted S \ {α}) will be presented to the user. This guarantees that the more general slices can be investigated first. More specifically, let p be the function that computes the performance score on a data slice. A data slice S is pruned if: |p(S) − p(S \ {α})| &lt; ε.  <ref type="figure">D-E</ref>). The Slice Matrix shows a summary of all the data slices with a performance metric that diverges from the overall model. The user can drill down on the slices in order to explore one or more data slices simultaneously using the Slice Detail View. The System Menu (F) allows users to switch between data slices from the multiple ML models, summarize model slices and perform What-if analyses to estimate the effect of optimizing the model for a particular data slice. These operations are described later in this section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Visualization Design</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Slice Matrix</head><p>The Slice Matrix (Figure <ref type="figure" target="#fig_2">1(A)</ref>) provides an overview of the problematic data slices to the user [R1]. First, the data slices are identified using DivExplorer <ref type="bibr" target="#b43">[44]</ref>, described in Section 3.3. After the data slices are found, they are graphically represented using Slice Matrix, an adaptation of the UpSet <ref type="bibr" target="#b29">[30]</ref> matrix encoding, where sets are represented as rows, and set members, as columns. In the context of data slices, we Fig. <ref type="figure">5</ref>. Illustration of SliceBoosting algorithm to estimate model optimization effect. Given the selected slice 1, we train a shallow regressor to estimate that, under the ideal scenario where the optimization model correctly fits to slice 1, how will the performance on slice 2 and 3 be affected. We design the prediction target of the regressor as the residuals of the original model predictions to the ground truth validation labels. To focus on the effect estimation of slice 1, we set the residual values only for slice 1, while keeping the residuals of all other slices as 0. The predicted residuals from the regression are in the range of [−1, 1]. We then aggregate the sample-level residual predictions to obtain slice-level estimation results: how will the accuracy on these slices increase or decrease? use a similar encoding where each slice is represented as a row (set), and slice descriptions (items), as columns. Our adaptation also includes data slice metrics on the UpSet visualization encoding.</p><p>Model and data metrics are computed and displayed together with their respective slices ([R2] and [R4]). For model-agnostic metrics, a bar chart is displayed and, for model-specific metrics, a color-coded 1-D scatter plot is shown. In Figure <ref type="figure" target="#fig_2">1</ref>(A), the metrics "Support" and "Accuracy" are displayed. We show a truncated scale for "Support", since the support of the entire dataset (slice "All Data") is always equal to 1. Additional metrics can be defined, including "Precision", "Recall", and "F1 Score". Previous VA systems have enabled users to interactively compare ML models <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b39">40,</ref><ref type="bibr" target="#b52">53,</ref><ref type="bibr" target="#b55">56]</ref>. However, to the best of our knowledge, SliceTeller is the first of its kind to allow a detailed model comparison using automatically computed data slices to guide the analysis process.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Slice Detail View</head><p>During our interviews, experts expressed their interest in understanding the content of the data slices and valuing how much impact they have in their application [R2]. We design two types of slice detail view to cater two major data types in our use cases: a Slice Distribution View ( Figure <ref type="figure">7</ref>(D)) for tabular data, and a MatrixScape View (Figure <ref type="figure" target="#fig_2">1(D-E</ref>) <ref type="bibr" target="#b17">[18]</ref>) for image data.</p><p>Slice Distribution View. In this view, users can select the metadata to understand the distribution shifts across slices. We present the distribution of each metadata feature as a sorted histogram and align those for the same feature of different slices to facilitate a more convenient comparison. For example in Figure <ref type="figure">7</ref>(D), two data slices are selected ("All Data" and "Slice 1") and "Object" metadata distribution is shown.</p><p>MatrixScape View. While looking at distributions was useful, the experts working with image data wanted to be able to explore the images themselves. In particular, they wanted to check whether they could identify potential sources for model mistakes in these samples. To allow this task, we used the MatrixScape visualization <ref type="bibr" target="#b17">[18]</ref>, which can contextualize images with metadata information. In MatrixScape, images can be laid out in a canvas according to different metrics and aggregated at multiple levels of detail. At the coarsest aggregation level, MatrixScape shows a heatmap of a particular data metric (for example, accuracy), grouped by metafeatures chosen by the user (Figure <ref type="figure" target="#fig_2">1(E)</ref>. Upon zooming in, users can see individual data samples as well (Figure <ref type="figure" target="#fig_2">1</ref>(D)).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">SliceBoosting: Estimating the Effect of Data Slice Optimization</head><p>During our interviews with the domain experts, they expressed the need to create multiple models and evaluate trade-offs between them [R3] from the perspective of manually created data slices. In their current approach to train multiple models from scratch for comparison, there are mainly three pain points: 1) Since the model training process is time-consuming, the experimentation cycle is easily interrupted, and the model iteration is slow.</p><p>2) It requires significant efforts from the experts to keeping track of multiple models trained across different data slices. 3) To draw experimentation conclusions and identify the slice trade-offs, they have to switch between development tools multiple times.</p><p>Denote the original input model to SliceTeller as f parameterized by θ . Let the training data be X train ∈ R N train ×D , where N train is the number of samples in training set and D is the feature dimension. Similarly, let the validation data be X val ∈ R N val ×D . We use S val to denote the slices selected by user as in Section 3.4, and S train to denote the training data slices that correspond to the same description as S val (e.g., Weather = Sunny, Ob ject = Wall). We can utilize the optimization approaches (details in Section 3.6) to retrain f on X train to prioritize on S train , in order to obtain the optimized model f . However, due to the scale of X train and the high complexity of f , the optimization is time-consuming. It is therefore infeasible to try out different slice combinations to obtain the optimal f that could satisfy the product requirements.</p><p>To facilitate fast slice-based experimentation, our objective is to estimate the performance difference between f and f without explicitly training for f . We develop a novel SliceBoosting algorithm to perform the estimation. The main idea is that instead of training the full model to evaluate slice trade-offs, we can train a shallow model to approximate the residuals (errors) of the slices, in an approach similar to boosting <ref type="bibr" target="#b22">[23]</ref>. We denote the shallow model as h. Due to the shallowness, the training process is significantly faster than training the full model from scratch.</p><p>We have two assumptions: 1) The validation set X val has a similar distribution to the training data X train while being significantly smaller. This allows us to train the shallow model on the validation set to approximate the full model behavior on the training set. This assumption is valid in most cross-validation experiment settings. 2) The optimization approach (details in Section 3.6) is sufficiently powerful to steer the model to make correct predictions on the selected validation slices. Under these assumptions, we train the shallow model to fit to the selected validation slices S val together with the associated labels. After it is trained, its predictions on other slices will contain the approximation of the full model's behavior with further optimization. Similar approaches have used weak learners to reduce model biases and improve performance, including Multicalibrated Predictor <ref type="bibr" target="#b18">[19]</ref> and MultiAccuracy Boosting <ref type="bibr" target="#b25">[26]</ref>. However, while these approaches train and evaluate multiple boosted models to improve model accuracy, SliceBoosting uses a simplified approach with a single boosted model to estimate the effect of subgroup optimization and allow quick experimentation.</p><p>Since the shallow model is a "weak learner", it is challenging to encode all validation data and labels. Inspired by gradient boosting <ref type="bibr" target="#b22">[23]</ref> and surrogate model explanation approaches <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b9">10]</ref>, we design the shallow model to instead fit to the residuals (errors) of the original model on the selected slices. Since the original model is powerful (e.g., ResNet-50 Deep Neural Networks), its prediction is close to ground truth labels. Therefore, predicting the residual is a significantly easier task for the shallow model. As shown in Figure <ref type="figure">5</ref>, the residual is calculated as the difference between the ground truth validation labels and the predicted labels, in one-hot-encoded format:</p><formula xml:id="formula_0">residual i = y val i − ŷval i (<label>1</label></formula><formula xml:id="formula_1">)</formula><p>where y val i denotes the one-hot-encoded ground truth validation label for sample x val i , and ŷval i denotes the one-hot-encoded predicted label from the original model f . We illustrate the residual for a certain class in Figure <ref type="figure">5</ref>. There are three possible values in the residuals calculated from Eq. (1): 0 denoting the model prediction is correct, 1 denoting the model missed the detection of the class, and -1 denoting the model wrongly predicted the class. Note that since we focus on the selected slices, samples from all other slices have residual of 0.</p><p>We then train the shallow regressor h using XGBoost <ref type="bibr" target="#b4">[5]</ref> to learn the residuals from S val . To achieve fast response for visual interaction, we use only 3 training iterations and maximum tree height 5 in XGBoost (these parameters can be fine-tuned depending on the problem). To emphasize on the small set of misclassified samples, we increase their weights in the loss function. After h is trained, we infer the residual and prediction label for the full optimized model ( ỹval j ) as follows: pred residual j = h(x val j ) ỹval j = pred residual j + ŷval j Here, x val j contains data features of the validation set belonging to Slice j. A good estimation is achieved if ỹval j is close to the true label y j . After obtaining all estimated predictions, we measure the new accuracy in each slice and compare it with the original model accuracy to determine final estimated effect. More specifically, let A be the vector containing the accuracy of the original model on all data slices, and A be the vector containing the accuracy of the boosted model f on all data slices. The estimated effect E is given by E = A − A. As illustrated in Figure <ref type="figure">5</ref>, in the estimation effect, a positive number indicates that the performance on the slice might improve with model optimization. On the other hand, a negative number suggests that the performance on the slice could be reduced.</p><p>In order to evaluate SliceBoosting, we can check whether its estimated effects agree with the real optimized model performance (outlined in Section 3.6) . We measure this Agreement Score using Pearson correlation coefficient <ref type="bibr" target="#b48">[49]</ref> for the first two use cases in Section 4. More specifically, let A be the original model accuracy on all data slices and A be the retrained model accuracy on all data slices. The real performance effect E is given by E = A − A. We compute the Pearson correlation coefficient between the estimated effect E and the real effect E as: Agreement Score = corr(E, E ). We note that in both use cases, the Agreement Score was greater than 0.8, showing high correlation between the estimated slice optimization effects and the real effects. We further validate the SliceBoosting algorithm by evaluating the Agreement Score of ten estimated effects, computed for the top five worst data slices of the two aforementioned use cases (a new estimate and model are computed for each data slice). In Case 1, the estimates for five models optimized on the five worst slices had an Agreement Score of 0.860 ± 0.050. In Case 2, the estimates for five models optimized on the five worst slices had an Agreement Score of 0.776 ± 0.054. A detailed description the SliceBoosting evaluation is available in the supplementary materials.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.6">Model Optimization</head><p>In this section, we utilize state-of-the-art model optimization methods to improve the performance on the selected slices, while minimizing the trade-off for the averaged model performance on the entire dataset [R3]. These methods adapt the loss function based on identified slice prioritization and subsequently perform additional training to steer the model towards the user requirement. Note that our framework is compatible with data-centric model improvement strategies as well (e.g., additional data collection and data augmentation/synthesis) and we leave the discussion to Section 6. Here, we focus on optimizationbased model improvements without any change of the dataset.</p><p>Figure <ref type="figure" target="#fig_3">6</ref> illustrates the model optimization methods in SliceTeller, i.e. importance weighting and group DRO. Note that we merge all unselected slices into a single slice for optimization. In general, importance weighting method changes the loss function by assigning heavier weights to the training samples in the worst-performing slices. On the other hand, group DRO prioritizes the worst-performing slices during the training process. Here we briefly describe the two approaches. Detailed descriptions can be found in <ref type="bibr" target="#b47">[48]</ref>.</p><p>Importance Weighting. Importance weighting modifies the expected loss by emphasizing training samples belonging to the slices S train . Denote the number of samples in S train as n train , the number of samples in the training set as N train , and the total number of slices as M. The weight for slice S is calculated as:</p><formula xml:id="formula_2">w S train = N train M × n train</formula><p>Intuitively, the selected slices with lower performance correspond to the minority groups in training set. We can therefore specify the weights of the slices as inverse proportional to the respective slice size. Then, the modified expected loss can be defined as follows <ref type="bibr" target="#b47">[48]</ref>:</p><formula xml:id="formula_3">E (x train ,y train ,S train )∼P [w S train l(θ ; (x train , y train ))] (<label>2</label></formula><formula xml:id="formula_4">)</formula><p>where P is the distribution of training data X train and l is the loss. Group DRO. Compared to importance weighting that upweights the selected slices by heuristic rule, group DRO adopts a different optimization scheme. Instead of optimizing for the averaged loss over entire training data, it optimizes for the worst-case loss over the groups in the training data. Specifically, the expected loss is defined as <ref type="bibr" target="#b47">[48]</ref>:</p><formula xml:id="formula_5">max S train E (x train ,y train )∼P S train [l(θ ; (x train , y train ))]<label>(3)</label></formula><p>During training, the optimization can be conducted by either recording the historical losses of all groups <ref type="bibr" target="#b40">[41]</ref>, or utilizing gradient ascent <ref type="bibr" target="#b47">[48]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">USE CASES</head><p>In this section, we present three use cases to demonstrate the power of SliceTeller on the analysis, validation and improvement of ML models.</p><p>Case 1 shows how a fictional user would validate an image classification problem for data biases. The next two case studies are taken from our interviews with three MLOps engineers who work on real industry products. Case 2 shows how one engineer working on an ultrasonic object height classification model can use our system to improve their models on critical data slices. Finally, Case 3 shows how two MLOps engineers used our system to explore an image-based fire detection model and identify potential data issues. Table <ref type="table" target="#tab_1">1</ref> shows a summary of the three use cases. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Case 1: Bias Detection for AI Fairness in Image Classification Models</head><p>To showcase how SliceTeller helps ML experts and practitioners detect bias caused by the imbalanced distribution of image dataset, we describe how Hedy, a PhD student interested in computer vision, profiles the performance of ResNet50 on the CelebFaces Attributes Dataset (CelebA) <ref type="bibr" target="#b32">[33]</ref> and identify a gender-related bias inherited in the model. The CelebA dataset contains 202, 599 face images of 10, 177 celebrities, along with 40 binary attribute annotations including gender, skin color, smiling, etc. for each image. It is widely used in the computer vision community for tasks including image classification <ref type="bibr" target="#b23">[24]</ref>. Hedy first divides the data into three splits: training (70%), validation (20%) and testing (10%). She fine-tunes a ResNet50 model on the CelebA dataset to classify gray hair and obtains an overall validation accuracy of 0.98. She wanted to investigate how different models performed over attributes of Male and Gray Hair. The system initially identified 22 slices for Hedy to explore (using Div-Explorer support=0.02). Upon inspecting the model with the matrix view of SliceTeller (Figure <ref type="figure" target="#fig_2">1(A)</ref>), she notices that the model can only achieve a low accuracy of 0.65 on Slice 1, which is defined as females (Male = No) with gray hair (Gray Hair = Yes) (Fig. <ref type="figure" target="#fig_2">1</ref>). She checks the distribution of the dataset over the dimension of Male and Gray Hair, and finds that such a significant performance drop is caused by the highly skewed data distribution in this slice (Figure <ref type="figure" target="#fig_2">1(E) left</ref>). She verifies this observation by browsing the sample images in Slice 1 (Figure <ref type="figure" target="#fig_2">1(D)</ref>). Interestingly, Hedy observes that Slice 2, defined by (Wearing Necktie = No, Double Chin = No, and Gray Hair = Yes), also only achieves an accuracy of 0.65. Although the attribute Wearing Necktie seems related to gender bias as well, it is unclear if this is the true cause of the low performance. Therefore, she decides to take a closer look of these two slices by using the effect estimation functionality in SliceTeller.</p><p>Hedy starts by conducting a what-if analysis with SliceTeller to estimate the effect of optimizing upon Slice 1 and 2 jointly. The estimation result from SliceTeller indicates that the model performance on the worst eight slices will all improve significantly if optimizing Slice 1 and 2 together (Figure <ref type="figure" target="#fig_2">1</ref>(B)). The improvement is higher as compared to optimizing over Slice 1 alone. Hedy checked the support size of Slice 2 (Figure <ref type="figure" target="#fig_2">1(A)</ref>) and its data distribution, then realized that this slice accounts for more minority attributes than females with gray hair. This explains why optimizing Slices 1 and 2 together can improve the performance of the worst eight slices. Such optimization effect appears promising to Hedy, so she retrains a GroupDRO model <ref type="bibr" target="#b47">[48]</ref> that dynamically optimizes upon the two slices. Table <ref type="table" target="#tab_2">2</ref> shows the validation and test accuracy of the two models.</p><p>After the optimization, Hedy adds the performance result of Group-DRO into SliceTeller to compare it with the previous ResNet50 model. She immediately observes that the new model's performance on the gray-haired female images improve significantly (Figure <ref type="figure" target="#fig_2">1(C)</ref>). As predicted in the effect estimation stage, the optimized model's performance on the worst eight slices are improved, with a small trade-off on overall model performance. To confirm that she has alleviated the model bias towards females on classifying gray hair, she places the "All Data" slice of both ResNet50 and GroupDRO side by side in the MatrixScape view and compares them from the 2D dimension Male and gray hair 1 (Figure <ref type="figure" target="#fig_2">1(E)</ref>). The result confirms that the GroupDRO's performance classifying gray-hair females has significantly improved, with slight performance change on the other blocks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Case 2: Ultrasonic Object Height Classification for Autonomous Driving</head><p>We now consider a real-world application: object height detection for autonomous driving. One of our domain experts worked on a model for object height prediction based on vehicle ultrasonic sensors. The sensors produced tabular data has 157, 743 records that consists of 71 numerical features, and the expert's goal was to predict object height as a binary label: 'high' or 'low'. Such predictions would help improve the overall robustness of sensor fusion in the model pipeline, preventing collisions and aiding in the decision-making process of the car. The car's on-board processor has limited compute power and cannot handle very complex models, such as neural networks. Therefore, the expert chose to train an XGBoost <ref type="bibr" target="#b4">[5]</ref> model for this problem, which we will call Model 1. The expert split the data into three splits: training (60%), validation (30%) and testing (10%). They obtained an overall validation accuracy of 0.88, and were interested in evaluating the model using SliceTeller in order to find failure cases. Every sample in the dataset contained associated metadata about the environmental and sensor conditions. The metadata included 'Object Type', 'Distance', 'Sensor Approach', 'Scene Clutter', 'Direction', 'Speed', 'Temperature' and 'Weather'. In this section, we show an example of such analysis. Because this is a private dataset, the results are anonymized.</p><p>SliceTeller identified 145 data slices (using the DivExplorer algorithm with support=0.05). As a first step, the expert used the Slice Summarization tool to reduce the number of data subsets to analyze. They set the Redundancy Threshold to 0.10 and obtained 11 distinct data slices for analysis. Figure <ref type="figure">7(A)</ref> shows the analysis of the data slices from Model 1. The expert noticed that Slices 1 (sunny weather, high clutter and high temperature (in the range <ref type="bibr">(20.6, 29]</ref>)), 2 (high clutter and low speed), 7 (curbstones) and 10 (container sides) performed significantly worse than the overall model.</p><p>Before investing into additional data acquisition for the characterized scenario, the expert wanted to check whether optimizing the model for these slices would be possible. Therefore, they used the SliceBoosting algorithm to estimate the effect of training the model with higher weights on these slices. The result of this run is shown in Figure <ref type="figure">7(B)</ref>. Note that the performance of these slices is expected to improve, as well as the performance of slices 11 and 21.</p><p>They trained a new XGBoost model using the importance weighting method described in Section 3.6, this time adding higher sample weights to the samples belonging to Slices 1, 2, 7 and 10. Model 2 (Figure <ref type="figure">7(C</ref>)) contains the result of this optimized model. The performance of Model 2 is higher on the optimized slices, with an accuracy increase of more than 0.2 for every optimized slice (the Agreement Score of the real model with the estimate model is 0.83412.). This improvement was appreciated by the expert. However, they noticed that there was a trade-off with slices 139, 142 and 143. In particular, the expert noted that slices 139 (Weather=Rain) and 142 (Object=Wall) are critical for the autonomous driving application, and therefore should not have a significant drop in performance.</p><p>To fix this issue, they trained a new model, this time weighting the samples by the previously optimized slices, as well as slices 139 and 142. Figure <ref type="figure">8(A)</ref> shows the results of this optimization. Model 3 has better performance than Model 1 on the data slices where the model performs the worst, and comparable results on the slices Rain and Wall. To conclude the analysis, the expert wanted to visualize the worst data slices from all 3 trained models (Figure <ref type="figure">8(B)</ref>). We see that overall, Model 3 performs better than the other models on the their worst data slices. We highlighted the slices where Model 3 performs worse, noting that this difference was not considered significant by the expert. Table <ref type="table" target="#tab_3">3</ref> shows the performance of the three models on the data slices of interest for validation and test data.  this business application. Therefore, the engineering team wanted to identify and convey the model limitations to their customers. Each video had six interpretable metadata that could be used for exploration with SliceTeller. These metadata were: 'Location' (Outdoor, Indoor), 'Reflections or Shadows' (Yes, No), 'Motion' (Yes, No), 'Approaching Object' (Yes, No), 'Blinking Light' (Yes, No), and 'Smoke Density' (integer between 0 and 4). This metadata was assigned to every video frame, together with a new value: 'Normalized Frame' (real number in the range [0, 1]), describing the frame position in the video. After inserting this data into SliceTeller, the system initially discovered 115 data slices (using the DivExplorer algorithm with support=0.2). They used the slice summarization slider at multiple thresholds in order to inspect the results and select data slices for exploration. Figure <ref type="figure" target="#fig_5">9</ref> shows the most interesting data slices found by them.</p><p>The experts first inspected the worst data slice in the model, which was defined by scenes with 'Blinking Lights' and 'no reflections or shadows' (Figure <ref type="figure" target="#fig_5">9(A)</ref>). Using the confusion matrix, they saw that this data slice contained solely videos without fire, but it had many false alarms (Accuracy of 0.61). According to them, it was known that blinking lights negatively influenced the classifier prediction. However, they did not expect this large effect, with an accuracy decrease of 0.33.</p><p>They also identified data slices with problems in the beginning and ending of the videos. The accuracy of the beginning frames was lower (Figure <ref type="figure" target="#fig_5">9</ref>(B)), with the worst slice having an accuracy of 0.86. The problems in the start of the videos were expected, as cameras were moved around at this time and, as a result, frames would get blurry. The problems at the end of the videos (Figure <ref type="figure" target="#fig_5">9</ref>(C)), however, were surprising. They investigated the video frames using the Slice Distribution View and formulated the hypothesis that at the end of the videos, the smoke was already dissipated and hard to see. This was a useful insight for the experts, who decided to ignore those frames because their goal was to stop fires when they started.</p><p>Another surprising data slice contained samples in the middle of the recording (Figure <ref type="figure" target="#fig_5">9</ref>(D)). This slice contained many false alarms (error rate of 0.14). However, the expert mentioned that "it looks like we should be able to get this case right". Using the Slice Detail View, they attributed these mistakes to mislabeled data. Based on this insight, they decided to double check the sample labels. Furthermore, they were very interested in using SliceTeller to find more cases like this, noting that too many false alarms can annoy customers.</p><p>In order to mitigate the problems found in the data slices, their strategy consisted of increasing the training data size, using data collection and data augmentation. To improve particular data slices, they said they would collect more samples in the same conditions of the slices of interest. They would thoroughly inspect the new samples in order to ensure data quality. Another mitigation strategy mentioned is data augmentation. Currently, the MLOps team is in the process of testing different augmentation strategies, such as including frames with added noise and blur to their training data. They were very interested in comparing multiple model versions using our system. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">EXPERT INTERVIEWS</head><p>SliceTeller was developed with continuous feedback from our product partners (Section 3.1) over the course of six months. In this section, we discuss their analyses, insights and feedback for our system during a final round interview. First, we discuss the feedback from one expert working on the autonomous driving problem, who have used SliceTeller to evaluate and iterate over their object height classification models. Next, we discuss the feedback from two experts working on the imagebased fire detection problem, who derived actionable insights and identify data slices that require more training data using SliceTeller.</p><p>Expert User Demographics. We interviewed three ML experts (MLOps engineers) to evaluate SliceTeller. All experts have more than four years of experience in machine learning and have a graduate degree in STEM. They did not report any visual disabilities and were not color blind. The experts are not authors of this paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Ultrasonic Object Height Classification Experts</head><p>In Section 4.2, we have shown an example of the analysis conducted together with one MLOps engineer from the product R&amp;D team working on the ultrasonic object height classification problem. The expert used our system to evaluate their current model, as well as experiment on new models. The expert was interested in finding potential problems in their models. In particular, they wanted to identify misclassified samples close to the cars, as these mistakes can be critical. In their current workflow, they frequently evaluate their models on hand-curated data slices and fine tune them to achieve near-zero errors within a distance threshold. This workflow relies on many handcrafted scripts that have to be executed sequentially to evaluate and iterate over their models, making the process difficult to use. Therefore, they needed a simpler and more efficient alternative to this workflow.</p><p>During their analyses, they found a set of problematic slices that they wanted to optimize their model for. They did two model iterations, and were able to produce a solution that maintained a good trade-off across the multiple data slices of interest. They mentioned that the automatic data slicing and the slice matrix component were "very useful", because they could reduce the model testing time and effort significantly. However, they noted that they still needed to guarantee a customer-defined quality on the hand-crafted slices. Therefore, they were interested in combining SliceTeller in their current evaluation strategy, which would allow them to identify problems in their models that they did not think to look at before. As a feature request, they would like to propose problem-specific metrics for slice evaluation. We are currently working with the ultrasonic team to learn about their metrics and include them in the future system iteration.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Image-Based Fire Detection Experts</head><p>We interviewed two MLOps engineers working on the image-based fire detection problem. During their analyses, the experts were able to discover potential model issues, as well as formulate strategies to mitigate these issues. They used the Slice Matrix View and the Slice Summarization Slider the most frequently and expressed that these two views could facilitate the model exploration and help reduce the amount of time they needed to spend looking at data slices. They also liked to use the Slice Detail View: after identifying critical data slices, the experts used the Detail View to explore video frames and formulate hypothesis about the root cause.</p><p>Regarding model iteration, these experts did not show too much interest in fine-tuning models. Instead, they wanted to collect quality data to retrain and improve the existing models. They described their own experiments with data augmentation, such as noise and blur, with positive results. They mentioned the model comparison feature would be a powerful tool during model iteration.</p><p>They also had feature requests. They were interested in investigating the explanations for the model predictions. In particular, having importance maps displayed together with the images, so they could see where the model was "looking" when making a prediction. Furthermore, they wanted to be able to manually add data slices to SliceTeller, in order to keep track of critical slices for which 100% accuracy was required. These features will be implemented in the future.</p><p>SliceTeller provided our experts with new insights about their model, as well as validated hypothesis previously held by them. The experts mentioned that the system could be very useful, especially because they wanted to identify "interpretable, quantifiable boundaries for our system". These quality boundaries could be shared with customers, who can make an informed decision about their models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">DISCUSSION</head><p>Other Mitigation Solutions for Model Improvements. As mentioned in Section 3.6, we focused on optimization-based model improvement approaches for SliceTeller without changing the training data. In practice, data-centric model improvement <ref type="bibr" target="#b37">[38]</ref> is a promising direction to tackle real-world challenges. For example, after SliceTeller identifies particular weakness scenarios (e.g., snowy condition for autonomous driving) as indicated by the most critical slices, additional data can be collected corresponding to the scenarios. Recent work in data-centric AI focus on weakly-supervised learning <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b45">46]</ref> and self-supervised learning <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b54">55]</ref> to reduce the annotation cost and facilitate fast model iteration. Another approach is to use image processing and deep learning-based image synthesis techniques to perform data augmentation. For example, adversarial objects can be placed on top of the images in order to improve the robustness of a model <ref type="bibr" target="#b17">[18]</ref>.</p><p>Limitations of SliceBoosting. The SliceBoosting algorithm in Section 3.5 was developed based on the assumption that, with a powerful optimization method, the model is able to make correct predictions on the selected slices in the validation data. The hardness of this task is determined by the generalization gap between training and validation slices. As shown in <ref type="bibr" target="#b47">[48]</ref>, strong regularization strategies in DRO training help to significantly close the gap and we utilized them in the implementation of GroupDRO. Robust optimization <ref type="bibr" target="#b30">[31,</ref><ref type="bibr" target="#b56">57]</ref> and domain generalization <ref type="bibr" target="#b57">[58]</ref> are active research topics in the ML community. Although our empirical results in Section 4 demonstrated strong correlation between SliceBoosting estimation of the model improvement and the real improvement from importance weighting and GroupDRO, we plan to evaluate the effect with additional model optimization techniques as well as more public datasets.</p><p>Application Domains.</p><p>In this paper, we have shown how SliceTeller can be used for the analysis of classification models for image and tabular data. However, our system design is not specific to these domains, and can be applied to other data types, e.g., text data. The Slice Matrix abstracts the data features by using interpretable metadata to describe the data slices. Therefore, it does not need to be adapted to other data types. The Slice Detail View, however, is dependent on the domain, and needs to be adapted to display a summary of the selected slices. For example, in the case of text domains, we foresee the use of text visualizations to convey the data slice's content (e.g., word clouds). Other data types would require custom visualization implementations for the inspection of data samples. An extension of SliceTeller is also possible for regression models: in this case, the slice finding algorithm needs to be adapted to have a measure of how correct a prediction is, and when it should be considered a defect.</p><p>Requirement on Metadata. One limitation of our system is the need for interpretable metadata to slice the models. This metadata usually requires intensive manual annotation, and is therefore expensive to create. Therefore, as future work, we would like to investigate automatic methods to generate such information. For example, for images, one possible research direction is to use self-supervised learning <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b54">55]</ref> to automatically identify interpretable visual concepts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">CONCLUSIONS</head><p>In this paper, we have presented SliceTeller, a novel VA system for data slice-driven validation of ML models. Our tool allows users to quickly identify problematic data slices, investigate the failure cases, understand the potential optimization trade-offs, and eventually iterate on new model solutions.</p><p>We demonstrated the power of SliceTeller with three use cases that show how SliceTeller can be used to analyze, validate, and improve ML models in diverse application areas. SliceTeller was developed and improved in close collaboration with industry ML Ops engineers and domain experts working on product R&amp;D. Based on the positive feedback, we are currently working on incorporating SliceTeller into their ML development workflows to facilitate fast product iteration and model release.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Product MLOps engineer's workflow for model validation and iteration over critical data slices. Experts sliced their data based on product and domain requirements, computed model performances per slice, and explored the data to identify the root causes for potential model mistakes. Based on these observations, they would iterate over the model, by retraining while re-prioritizing certain data slices over others.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Data slicing workflow. It takes as input model predictions combined with interpretable metadata and utilizes frequent itemset mining to automatically identify the most critical slices. It then performs slice merging and redundancy removal to generate concise data slice results. make changes on data, hyperparameter or model, and insert the new model back into SliceTeller to compare models (Section 3.6).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 1</head><label>1</label><figDesc>Figure 1 demonstrates the visualization design of SliceTeller. The main visualization components of SliceTeller are the Slice Matrix (A) and the Slice Detail View (D-E). The Slice Matrix shows a summary of all the data slices with a performance metric that diverges from the overall model. The user can drill down on the slices in order to explore one or more data slices simultaneously using the Slice Detail View. The System Menu (F) allows users to switch between data slices from the multiple ML models, summarize model slices and perform What-if analyses to estimate the effect of optimizing the model for a particular data slice. These operations are described later in this section.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 6 .</head><label>6</label><figDesc>Fig. 6. Illustration of the model optimization methods considered in our work. During re-training, they prioritize slices in the training data according to user's decision.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 7 .Fig. 8 .</head><label>78</label><figDesc>Fig. 7. Analysis of the original model for object height classification (Model 1). (A) The summarized data slices for this model. The highlighted slices were selected by the expert to be improved in further model iterations. (B) SliceBoosting results showing the estimated effect of optimizing the model for the selected slices. (C) The comparison between the original model (Model 1) and the model optimized for the selected slices (Model 2). (D) The Slice Distribution View, containing the distribution of metadata 'Object' for Slices 'All Data' and 'Slice 1'.</figDesc><graphic url="image-43.png" coords="8,64.09,73.00,472.91,117.91" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 9 .</head><label>9</label><figDesc>Fig. 9. Image-Based Fire Detection Use Case: interesting data slices found by the MLOps engineers. (A) Blinking light. (B) Start of video. (C) End of video. (D) Middle of video.</figDesc><graphic url="image-45.png" coords="8,313.92,522.74,230.94,98.12" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>• Xiaoyu Zhang and Kwan-Liu Ma are with UC Davis. Xiaoyu Zhang was an intern at Bosch Research. E-mails: {xybzhang, klma}@ucdavis.edu. • Jorge P. Ono, Huan Song, Liang Gou and Liu Ren are with Robert Bosch Research and Technology Center, USA -Bosch Center for Artificial Intelligence.</figDesc><table /><note>E-mails: {jorge.piazentinono, huan.song, liang.gou, liu.ren}@us.bosch.com. Manuscript received xx xxx. 201x; accepted xx xxx. 201x. Date of Publication xx xxx. 201x; date of current version xx xxx. 201x. For information on obtaining reprints of this article, please send e-mail to: reprints@ieee.org. Digital Object Identifier: xx.xxxx/TVCG.201x.xxxxxxx</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 .</head><label>1</label><figDesc>Use Case Summary</figDesc><table><row><cell></cell><cell>1) Bias Detection</cell><cell>2) Height Classification</cell><cell>3) Fire Detection</cell></row><row><cell>Data Type</cell><cell>Image</cell><cell>Tabular</cell><cell>Image</cell></row><row><cell>Validation Size</cell><cell>40, 520</cell><cell>47, 322</cell><cell>126, 912</cell></row><row><cell>Input Metadata</cell><cell>40 binary</cell><cell>8 numeric / categ.</cell><cell>7 numeric / binary</cell></row><row><cell>Target (Binary)</cell><cell>Yes / No</cell><cell>High / Low</cell><cell>Yes / No</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 .</head><label>2</label><figDesc>Accuracy of Image Classification Models (Val / Test)</figDesc><table><row><cell>Slice</cell><cell>Description</cell><cell>ResNet-50</cell><cell>Group DRO</cell></row><row><cell>0</cell><cell>All Data</cell><cell>0.98 / 0.98</cell><cell>0.95 / 0.95</cell></row><row><cell>1</cell><cell>Gray Hair=Yes, Male=No</cell><cell>0.65 / 0.5</cell><cell>0.91 / 0.81</cell></row><row><cell>2</cell><cell>Gray Hair=Yes, Double Chin=No, Wearing Necktie=No</cell><cell>0.65 / 0.69</cell><cell>0.90 / 0.93</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 .</head><label>3</label><figDesc>Accuracy of Object Height Classification Models (Val / Test)</figDesc><table><row><cell>Slice</cell><cell>Description</cell><cell>Model 1</cell><cell>Model 2</cell><cell>Model 3</cell></row><row><cell>0</cell><cell>All Data</cell><cell>0.88 / 0.74</cell><cell>0.92 / 0.84</cell><cell>0.95 / 0.84</cell></row><row><cell>1</cell><cell>Clutter=High, Weather=Sunny, Temp=(20.6, 29.0]</cell><cell>0.53 / 0.60</cell><cell>0.82 / 0.87</cell><cell>0.96 / 0.85</cell></row><row><cell>2</cell><cell>Clutter=High, Speed=(1.5, 3.4]</cell><cell>0.56 / 0.67</cell><cell>0.82 / 0.86</cell><cell>0.89 / 0.84</cell></row><row><cell>7</cell><cell>Object=Charging Curbstone</cell><cell>0.67 / 0.36</cell><cell>0.94 / 0.85</cell><cell>0.91 / 0.87</cell></row><row><cell>10</cell><cell>Object=Containerside</cell><cell>0.70 / 0.66</cell><cell>0.97 / 0.99</cell><cell>1.00 / 1.00</cell></row><row><cell>139</cell><cell>Weather=Rain</cell><cell>0.98 / 0.83</cell><cell>0.88 / 0.88</cell><cell>0.95 / 0.90</cell></row><row><cell>142</cell><cell>Object=Wall</cell><cell>0.99 / 0.88</cell><cell>0.81 / 0.80</cell><cell>0.93 / 0.83</cell></row><row><cell cols="4">4.3 Case 3: Image-Based Fire Detection</cell><cell></cell></row><row><cell cols="5">Image-based fire detection is an important problem in the industrial</cell></row><row><cell cols="5">setting, having the potential to identify fires in its early stages, prevent-</cell></row><row><cell cols="5">ing accidents and losses. In order to address this problem, our partner</cell></row><row><cell cols="5">MLOps product team trained a Convolutional Neural Network on im-</cell></row><row><cell cols="5">age frames to predict the label 'Fire' / 'No Fire', obtaining a validation</cell></row><row><cell cols="5">accuracy score of 0.94. Transparency with customers is paramount in</cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">FreaAI: Automated extraction of data slices to test machine learning models</title>
		<author>
			<persName><forename type="first">S</forename><surname>Ackerman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Raz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zalmanovici</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Workshop on Engineering Dependable and Secure Machine Learning Systems</title>
				<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="67" to="83" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Bridging the gap between ML solutions and their business requirements using feature interactions</title>
		<author>
			<persName><forename type="first">G</forename><surname>Barash</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Farchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Jayaraman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Raz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Tzoref-Brill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zalmanovici</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 27th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering</title>
				<meeting>the 2019 27th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="1048" to="1058" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">FairVis: Visual analytics for discovering intersectional bias in machine learning</title>
		<author>
			<persName><forename type="first">Á</forename><forename type="middle">A</forename><surname>Cabrera</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Epperson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Hohman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kahng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Morgenstern</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">H</forename><surname>Chau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 2019 IEEE Conference on Visual Analytics Science and Technology (VAST)</title>
				<meeting>2019 IEEE Conference on Visual Analytics Science and Technology (VAST)</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="46" to="56" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Stackgenvis: Alignment of data, algorithms, and models for stacking ensemble learning using performance metrics</title>
		<author>
			<persName><forename type="first">A</forename><surname>Chatzimparmpas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Martins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Kucher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kerren</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1547" to="1557" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Xgboost: A scalable tree boosting system</title>
		<author>
			<persName><forename type="first">T</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Guestrin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd ACM SIGKDD international conference on knowledge discovery and data mining</title>
				<meeting>the 22nd ACM SIGKDD international conference on knowledge discovery and data mining</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="785" to="794" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Slice-based learning: A programming model for residual learning in critical data slices</title>
		<author>
			<persName><forename type="first">V</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Ratner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Weng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Ré</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
				<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">32</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Automated data slicing for model validation: A big data-ai integration approach</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Kraska</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Polyzotis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">H</forename><surname>Tae</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">E</forename><surname>Whang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Knowledge and Data Engineering</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2284" to="2296" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Slice finder: Automated data slicing for model validation</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Kraska</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Polyzotis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">H</forename><surname>Tae</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">E</forename><surname>Whang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2019 IEEE 35th International Conference on Data Engineering (ICDE)</title>
				<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="1550" to="1553" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Strategyatlas: Strategy analysis for machine learning interpretability</title>
		<author>
			<persName><forename type="first">D</forename><surname>Collaris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Van Wijk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Explainexplore: Visual exploration of machine learning explanations</title>
		<author>
			<persName><forename type="first">D</forename><surname>Collaris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Van Wijk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2020 IEEE Pacific Visualization Symposium (PacificVis)</title>
				<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="26" to="35" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Beames: Interactive multimodel steering, selection, and inspection for regression tasks</title>
		<author>
			<persName><forename type="first">S</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Cashman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Endert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE computer graphics and applications</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="20" to="32" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">From visual data exploration to visual data mining: A survey</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">F</forename><surname>De Oliveira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Levkowitz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on visualization and computer graphics</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="378" to="394" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Unsupervised domain adaptation by backpropagation</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Ganin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Lempitsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International conference on machine learning</title>
				<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1180" to="1189" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Boxer: Interactive comparison of classifier results</title>
		<author>
			<persName><forename type="first">M</forename><surname>Gleicher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Barve</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Heimerl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Graphics Forum</title>
				<imprint>
			<publisher>Wiley Online Library</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page" from="181" to="193" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<author>
			<persName><forename type="first">K</forename><surname>Goel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Rajani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Vig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bansal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Ré</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2101.04840</idno>
		<title level="m">Robustness gym: Unifying the nlp evaluation landscape</title>
				<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Bootstrap your own latent-a new approach to self-supervised learning</title>
		<author>
			<persName><forename type="first">J.-B</forename><surname>Grill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Strub</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Altché</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Tallec</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Richemond</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Buchatskaya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Doersch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Avila Pires</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">Gheshlaghi</forename><surname>Azar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
				<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="21271" to="21284" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Frequent pattern mining: current status and future directions</title>
		<author>
			<persName><forename type="first">J</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Xin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Data mining and knowledge discovery</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="55" to="86" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Where can we help? A visual analytics approach to diagnosing and improving semantic segmentation of movable objects</title>
		<author>
			<persName><forename type="first">W</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Shekar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Gou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Ren</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1040" to="1050" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Multicalibration: Calibration for the (computationally-identifiable) masses</title>
		<author>
			<persName><forename type="first">U</forename><surname>Hébert-Johnson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Reingold</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Rothblum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
				<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="1939" to="1948" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Does distributionally robust supervised learning give robust classifiers</title>
		<author>
			<persName><forename type="first">W</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Sato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sugiyama</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
				<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="2029" to="2037" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m">IPAM. Workshop: Deep Learning and Combinatorial Optimization. publisher: IPAM 2021</title>
				<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Improving visualization interpretation using counterfactuals</title>
		<author>
			<persName><forename type="first">S</forename><surname>Kaul</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Borland</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Gotz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="998" to="1008" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Lightgbm: A highly efficient gradient boosting decision tree. Advances in neural information processing systems</title>
		<author>
			<persName><forename type="first">G</forename><surname>Ke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Finley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T.-Y</forename><surname>Liu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">30</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Null-sampling for interpretable and fair representations</title>
		<author>
			<persName><forename type="first">T</forename><surname>Kehrenberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bartlett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Quadrianto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
				<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="565" to="580" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Information visualization and visual data mining</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Keim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="8" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Multiaccuracy: Black-box postprocessing for fairness in classification</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">P</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ghorbani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 AAAI/ACM Conference on AI, Ethics, and Society</title>
				<meeting>the 2019 AAAI/ACM Conference on AI, Ethics, and Society</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="247" to="254" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Xai for operations in the process industry-applications, theses, and research directions</title>
		<author>
			<persName><forename type="first">A</forename><surname>Kotriwala</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Klöpper</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Dix</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Gopalakrishnan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Ziobro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Potschka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI Spring Symposium: Combining Machine Learning with Knowledge Engineering</title>
				<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Unmasking clever hans predictors and assessing what machines really learn</title>
		<author>
			<persName><forename type="first">S</forename><surname>Lapuschkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wäldchen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Binder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Montavon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Samek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K.-R</forename><surname>Müller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature communications</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="8" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Large-scale methods for distributionally robust optimization</title>
		<author>
			<persName><forename type="first">D</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Carmon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Duchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sidford</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
				<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="8847" to="8860" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Upset: visualization of intersecting sets</title>
		<author>
			<persName><forename type="first">A</forename><surname>Lex</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Gehlenborg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Strobelt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Vuillemot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Pfister</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on visualization and computer graphics</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="1983" to="1992" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Learning to generalize: Meta-learning for domain generalization</title>
		<author>
			<persName><forename type="first">D</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y.-Z</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">M</forename><surname>Hospedales</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Thirty-Second AAAI Conference on Artificial Intelligence</title>
				<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Elastic machine learning algorithms in amazon sagemaker</title>
		<author>
			<persName><forename type="first">E</forename><surname>Liberty</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Karnin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Rouesnel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Coskun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Nallapati</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Delgado</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sadoughi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Astashonok</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Das</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 ACM SIGMOD International Conference on Management of Data</title>
				<meeting>the 2020 ACM SIGMOD International Conference on Management of Data</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="731" to="737" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Deep learning face attributes in the wild</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of International Conference on Computer Vision (ICCV)</title>
				<meeting>International Conference on Computer Vision (ICCV)</meeting>
		<imprint>
			<date type="published" when="2015-12">December 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<author>
			<persName><forename type="first">V</forename><surname>Marin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Jialin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Aaron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Brandon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Georg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Bistra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yisong</surname></persName>
		</author>
		<title level="m">Workshop: Learning Meets Combinatorial Algorithms</title>
				<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">A survey on bias and fairness in machine learning</title>
		<author>
			<persName><forename type="first">N</forename><surname>Mehrabi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Morstatter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Saxena</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Lerman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Galstyan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Computing Surveys (CSUR)</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1" to="35" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Accuracy on the line: on the strong correlation between out-of-distribution and in-distribution generalization</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">P</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Taori</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Raghunathan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sagawa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">W</forename><surname>Koh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Shankar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Carmon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Schmidt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
				<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="7721" to="7735" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Self-supervised learning of pretext-invariant representations</title>
		<author>
			<persName><forename type="first">I</forename><surname>Misra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">V D</forename><surname>Maaten</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
				<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="6707" to="6717" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">A data-centric approach for training deep neural networks with less data</title>
		<author>
			<persName><forename type="first">M</forename><surname>Motamedi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Sakharnykh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Kaldewey</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2110.03613</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Understanding the failure modes of out-of-distribution generalization</title>
		<author>
			<persName><forename type="first">V</forename><surname>Nagarajan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Andreassen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Neyshabur</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2010.15775</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Pipelineprofiler: A visual analytics tool for the exploration of automl pipelines</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">P</forename><surname>Ono</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Castelo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Lopez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Bertini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Freire</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Silva</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="390" to="400" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<author>
			<persName><forename type="first">Y</forename><surname>Oren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sagawa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">B</forename><surname>Hashimoto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Liang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1909.02060</idno>
		<title level="m">Distributionally robust language modeling</title>
				<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Doctor xai: an ontologybased approach to black-box sequential data classification explanations</title>
		<author>
			<persName><forename type="first">C</forename><surname>Panigutti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Perotti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Pedreschi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 conference on fairness, accountability, and transparency</title>
				<meeting>the 2020 conference on fairness, accountability, and transparency</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="629" to="639" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Identifying biased subgroups in ranking and classification</title>
		<author>
			<persName><forename type="first">E</forename><surname>Pastor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Alfaro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Baralis</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2108.07450</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Looking for trouble: Analyzing classifier behavior via pattern divergence</title>
		<author>
			<persName><forename type="first">E</forename><surname>Pastor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Alfaro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Baralis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 International Conference on Management of Data</title>
				<meeting>the 2021 International Conference on Management of Data</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="1400" to="1412" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">How divergent is your data?</title>
		<author>
			<persName><forename type="first">E</forename><surname>Pastor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gavgavian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Baralis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>De Alfaro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the VLDB Endowment</title>
				<meeting>the VLDB Endowment</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="2835" to="2838" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Data programming: Creating large training sets, quickly</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Ratner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">M</forename><surname>De Sa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Selsam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Ré</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
				<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="volume">29</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Sliceline: Fast, linear-algebra-based slice finding for ml model debugging</title>
		<author>
			<persName><forename type="first">S</forename><surname>Sagadeeva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Boehm</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 International Conference on Management of Data</title>
				<meeting>the 2021 International Conference on Management of Data</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="2290" to="2299" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Distributionally robust neural networks</title>
		<author>
			<persName><forename type="first">S</forename><surname>Sagawa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">W</forename><surname>Koh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">B</forename><surname>Hashimoto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
				<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<title level="m" type="main">Correlation coefficients: appropriate use and interpretation</title>
		<author>
			<persName><forename type="first">P</forename><surname>Schober</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Boer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">A</forename><surname>Schwarte</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
			<publisher>Anesthesia &amp; Analgesia</publisher>
			<biblScope unit="volume">126</biblScope>
			<biblScope unit="page" from="1763" to="1768" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Robustness to spurious correlations via human annotations</title>
		<author>
			<persName><forename type="first">M</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Hashimoto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
				<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="9109" to="9119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
		<title level="m" type="main">Foundations of constraint satisfaction: the classic text</title>
		<author>
			<persName><forename type="first">E</forename><surname>Tsang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014">2014</date>
			<publisher>BoD-Books on Demand</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Errudite: Scalable, reproducible, and testable error analysis</title>
		<author>
			<persName><forename type="first">T</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">T</forename><surname>Ribeiro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Heer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Weld</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</title>
				<meeting>the 57th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Ensemblelens: Ensemblebased visual exploration of anomaly detection algorithms with multidimensional data</title>
		<author>
			<persName><forename type="first">K</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Mu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Cao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on visualization and computer graphics</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="109" to="119" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Toward a deeper understanding of the role of interaction in information visualization</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Stasko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Jacko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on visualization and computer graphics</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1224" to="1231" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Barlow twins: Selfsupervised learning via redundancy reduction</title>
		<author>
			<persName><forename type="first">J</forename><surname>Zbontar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Jing</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Misra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Deny</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
				<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="12310" to="12320" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Manifold: A model-agnostic framework for interpretation and diagnosis of machine learning models</title>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Molino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">S</forename><surname>Ebert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on visualization and computer graphics</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="364" to="373" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Examining and combating spurious features under distribution shift</title>
		<author>
			<persName><forename type="first">C</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Michel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Neubig</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
				<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="12857" to="12867" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<monogr>
		<title level="m" type="main">Domain generalization: A survey</title>
		<author>
			<persName><forename type="first">K</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Qiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">Change</forename><surname>Loy</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page">2103</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv e-prints</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
