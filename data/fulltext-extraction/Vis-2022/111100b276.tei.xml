<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Extending the Nested Model for User-Centric XAI: A Design Study on GNN-based Drug Repurposing</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Qianwen</forename><surname>Wang</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Kexin</forename><surname>Huang</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Payal</forename><surname>Chandak</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Marinka</forename><surname>Zitnik</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Nils</forename><surname>Gehlenborg</surname></persName>
						</author>
						<author>
							<affiliation>
								<orgName>1</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Extending the Nested Model for User-Centric XAI: A Design Study on GNN-based Drug Repurposing</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.2" ident="GROBID" when="2023-03-27T09:16+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Visual Explanation</term>
					<term>XAI</term>
					<term>Graph Neural Network</term>
					<term>Visualization Design Model</term>
					<term>Drug Repurposing</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>2 2 drug gene/protein cellular_com.. gene/protein disease 2 drug drug disease disease disease 1 drug disease drug disease disease Agalsidase beta chylomicron ret... Alipogene tipar... lysosomal acid l... Wolman disease indication indication indication includes 1 drug disease gene/protein disease disease 1 drug disease gene/protein disease A g a ls id a se b e ta A ve lu m a b Id u rs u lfa se G a ls u lfa se Fig. 1. We design and develop DrugExplorer for domain users to understand and assess graph neural network-based drug repurposing. The design process follows the nested model of visualization design and extends it by adding user-centric XAI design considerations. As in the nested block and guideline model (NBGM) [39], the four nested layers are drawn separately for visual simplicity.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Recent years witnessed a rapid expansion of Artificial Intelligence (AI) techniques in various domains and a growing need for eXplainable Artificial Intelligence (XAI). While a variety of algorithms have been proposed to generate explanations, there is no guarantee that these explanations are always usable in the applied domain, i.e., whether domain users can use AI explanations to complete desired tasks effi- ciently. Even though some studies demonstrate the positive effects of AI explanations <ref type="bibr" target="#b37">[38]</ref>, others report that AI explanations fail to generate actionable insights and even manipulate user trust <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b74">75]</ref>. Recently, AI researchers started to recognize usability as an indispensable requirement for AI explanations <ref type="bibr" target="#b58">[59,</ref><ref type="bibr" target="#b86">87]</ref>. Usable AI explanations not only require accurate, stable, and faithful algorithms, but also need well-designed user interfaces that bridge the capabilities of algorithms to the needs of users in application domains <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b67">68,</ref><ref type="bibr" target="#b68">69]</ref>. Researchers have advocated for usercentered XAI, within which usable explanations are extensively discussed <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b39">40,</ref><ref type="bibr" target="#b67">68,</ref><ref type="bibr" target="#b68">69]</ref>. These studies provide valuable frameworks and guidelines for designing explanation interfaces, either by borrowing lessons from social science and psychology <ref type="bibr" target="#b39">[40,</ref><ref type="bibr" target="#b67">68]</ref> or conducting empirical studies with real users <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b35">36]</ref>. However, these studies mainly discuss the design of general user interfaces without a specific investigation about interactive visualizations, which is a crucial component in explanation interfaces.</p><p>Given the importance of visualization in AI, a growing number of AI visualization tools have been proposed. Most existing AI visu-alization tools are developed for AI developers and AI practitioners rather than domain users who have limited expertise in AI <ref type="bibr" target="#b81">[82]</ref>. Studies that target domain users <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b71">72]</ref> often concentrate on proposing novel visualization designs and coordinated views to make sense of complicated data. A specific explanation is usually selected before the design study based on its popularity in the ML community without considering how the domain characteristics and user needs may influence the selection and visualization of explanations. However, many user studies demonstrated that the visual presentation of explanations could significantly influence humans in using AI, ranging from confidence level to performance accuracy <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b17">18]</ref>. While the visualization field has accumulated extensive experience in developing visualization tools for domain users and summarized many insightful visualization models <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b42">43,</ref><ref type="bibr" target="#b56">57,</ref><ref type="bibr" target="#b64">65]</ref>, the visualization designs are mainly driven by domain problems. It remains unclear how to effectively investigate and fulfill users' needs for usable explanations through the visualization design process.</p><p>This paper presents a design study where we investigated how to select and visualize AI explanations for domain users. We focus on one particular scientific application of AI, i.e., graph neural networks (GNN) in drug repurposing, which enables us to closely work with both domain and AI experts, iterate designs based on user feedback, and conduct evaluations on real datasets and tasks. Our design study follows the nested model and the nested block and guideline model (NBGM) <ref type="bibr" target="#b38">[39,</ref><ref type="bibr" target="#b42">43]</ref> 1 since they provide explicit mechanisms to capture and justify design decision rationales. We incorporate a diverse set of user-centric XAI design considerations into different layers of the design processes, based on our literature review and collaborators' feedback in our iterative design study, as shown in Fig. <ref type="figure">1</ref>. This design process decouples the explanation abstraction from the XAI algorithm, aiming to provide explanation visualizations and interactions that better reflect the domain characterization. Based on the domain characterization (target user, usage context, XAI goal, domain explanation), DrugExplorer provides path-based explanations and presents them both at both instance level and group level for two key XAI operations, why and what else. We also propose a novel visualization design MetaMatrix to help domain users organize and compare explanation paths at different levels of granularity to generate domain-meaningful insights for their XAI goals.</p><p>This paper makes three main contributions:</p><p>• We design and develop an interactive visualization tool, DrugExplorer, to assist domain users in GNN-based drug repurposing. • We present the design process of DrugExplorer, which applies the nested model to the selection and visualization of AI explanations by incorporating a diverse set of user-centric XAI considerations. • We evaluate DrugExplorer and share observations and insights that are generalizable and valuable for the development of future domain-specific XAI visualization tools.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">STUDY CONTEXT: GRAPH NEURAL NETWORKS IN DRUG REPURPOSING</head><p>Drug repurposing is an effective strategy to identify new therapeutic uses of existing drugs. Compared to developing a new drug from scratch, which typically takes 13-15 years and 2-3 billion dollars on average, repurposed drugs can potentially get to market in half the time and at one-quarter of the cost <ref type="bibr" target="#b44">[45]</ref>. However, despite considerable advances, current examples of successful drug repurposing mainly came about through serendipity.</p><p>Recently, GNNs have emerged as a promising approach in computational drug repurposing. However, predicted candidate drugs require rigorous and systematic validation, including in vitro experiments, in vivo experiments, and clinical trials. Given limited resources, a critical task for domain experts is to decide which candidate drugs to investigate further and which ones to leave out. 1 Unless specified otherwise, the nested model refers to both its original version and its extension: the nested block and guideline model (NBGM).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">RELATED WORK</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">User-centric XAI</head><p>User-centric XAI investigates how humans interpret, interact with, and use XAI. Here, we review user-centric XAI studies that inform the design of explanation interfaces for non-AI-expert end users.</p><p>To guide the design of explanation interfaces, some researchers empirically study users' behavior and needs when using XAI. For example, Chen et al. <ref type="bibr" target="#b14">[15]</ref> found that interactive explanations were more effective than static ones at improving user comprehension, but with the cost of longer decision time. Feng and Boyd-Craber <ref type="bibr" target="#b17">[18]</ref> observed that users used different game playing strategies with highlight-, guess-, and evidence-based explanations. On the other hand, by conducting case studies and expert interviews, Zytek et al. <ref type="bibr" target="#b86">[87]</ref> summarized a list of usability challenges of AI in high-stakes decision-making. Liao et al. <ref type="bibr" target="#b35">[36]</ref> present user needs for explainability as a set of prototypical questions.</p><p>Another parallel research aims to summarize guidelines and form frameworks by reviewing literature in related files such XAI, human-AI interaction, psychology, and social science <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b41">42,</ref><ref type="bibr" target="#b57">58,</ref><ref type="bibr" target="#b67">68]</ref>. For example, Chari et al. <ref type="bibr" target="#b11">[12]</ref> proposed Explanation Ontology, which can help designers identify the components that an XAI system should and can provide to its end users. Mohseni et al. <ref type="bibr" target="#b41">[42]</ref> presented a framework that categorizes the design goals of XAI and provides guidelines to evaluate these goals at each stage of the design process. Most relevant to our study is the conceptual framework contributed by <ref type="bibr">Wang et al. [68]</ref>. This framework maps algorithm-generated explanations to human decision-making theories, aiming to mitigate biased decision by helping users select appropriate explanation types and representations for domain-specific XAI applications. Despite the valuable guidelines provided, the proposed framework failed to include how the characteristics of the domain problem can influence the selection of AI explanations. Moreover, the framework only covered simple visualizations (e.g., bar charts, heat maps) and provided limited guidance for the typical multi-step visualization design process.</p><p>Focusing on visualization design for usable explanations, this paper adapts the nested model <ref type="bibr" target="#b38">[39,</ref><ref type="bibr" target="#b42">43]</ref> to design usable visual explanation interfaces. We discuss the threats and validation methods for usable visual explanations at each level of the design framework.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Visualizations for XAI</head><p>Interactive visualizations have been widely used as a medium for explanation <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b81">82]</ref>, since they excel at communication and summarization of complex information.</p><p>Most existing AI visualization tools are developed for AI developers and AI practitioners <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b81">82]</ref>. These tools succeed on a range of tasks, including data augmentation and cleaning <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b77">78]</ref>, model debugging <ref type="bibr" target="#b9">[10]</ref>, and model comparison and selection <ref type="bibr" target="#b70">[71]</ref><ref type="bibr" target="#b71">[72]</ref><ref type="bibr" target="#b72">[73]</ref>. However, domain users have different expertise and analysis goals than AI experts. As a result, these tools can generally not be directly applied for domain users.</p><p>Some recent studies take into account the needs of domain users for the development of XAI visualization tools <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b40">41]</ref>. These studies contribute novel visualization designs and coordinated views to help domain users make sense of complicated data and generate domain-meaningful insights. However, these tools usually employed one particular explanation technique and representation selected based on either popularity or state-of-the-art. As a result, they don't consider the selection of explanations in the design process. However, these tools usually left the selection of XAI outside the design process, choosing an explanation technique and representation based on its popularity in the ML community. Furthermore, existing visualization models <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b42">43,</ref><ref type="bibr" target="#b56">57,</ref><ref type="bibr" target="#b64">65]</ref> propose no explicit design guidelines for AI explanation selection and representation.</p><p>This study incorporates the selection of explanation techniques and representations into the design of an XAI visualization tool. We extend the nested design model, with a particular focus on how the characteristics of the domain problem shape the selection of explanations and the design of visualizations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">AI and Visualization in Drug Repurposing</head><p>Recent advances in AI have presented impressive capabilities to repurpose drugs at unprecedented speed, scale, and accuracy. AI-assisted drug repurposing attracts increasing research interest, especially for treating emerging and challenging diseases, such as COVID-19 <ref type="bibr" target="#b20">[21]</ref>. A widely-used AI model for drug repurposing is GNNs. Many research efforts have been undertaken in GNN-based drug repurposing, including construction of knowledge graphs that comprehensively summarize the existing biomedical knowledge <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b83">84]</ref>, and development of GNN models that can effectively learn from large knowledge graphs <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b59">60]</ref>.</p><p>Even though current GNN-based drug repurposing approaches show promising performance, they usually provide limited explanations, which are important to validate new findings and extend human understanding of how drugs act in different diseases <ref type="bibr" target="#b26">[27]</ref>. This gap partly comes from the complicated nature of drug discovery, as well as the challenges of conducting multidisciplinary research across the fields of visualization, biomedicine, AI, and human-computer interaction. A vast array of XAI techniques have been proposed to generate explanations for GNN predictions <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b54">55,</ref><ref type="bibr" target="#b78">79]</ref>. Meanwhile, many visual analytics tools have been proposed to present complex biological pathways and assist domain users in drug discovery <ref type="bibr" target="#b31">[32,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b46">[47]</ref><ref type="bibr" target="#b47">[48]</ref><ref type="bibr" target="#b48">[49]</ref><ref type="bibr" target="#b53">54]</ref>. However, how to combine these XAI and visualization techniques to facilitate human-AI collaboration in drug repurposing is still an open question.</p><p>This study builds upon prior studies in GNN-based drug repurposing and GNN explainability. While the visualization design is largely inspired by previous studies on visual analytics of graphs and biological pathways, our focus is on defining the designing process for visualizing AI explanations for domain experts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">INCORPORATING XAI DESIGN CONSIDERATIONS INTO THE NESTED MODEL OF VISUALIZATION DESIGN</head><p>This section introduces the motivation and the methodology for incorporating XAI considerations into the visualization design process.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Overview</head><p>Our design study included two stages and was conducted by a multidisciplinary team with diverse backgrounds in visualization, XAI, and biomedicine. In the first stage, we investigated the needs and challenges in explaining AI-based drug repurposing to domain experts with a prototype tool for a specific disease, SARS-CoV-2 (Figure <ref type="figure" target="#fig_0">S3</ref>, Supplementary Material). This prototype was driven by an initial set of requirements and an explanation method (i.e., GNNExplainer <ref type="bibr" target="#b78">[79]</ref>) provided by the XAI researchers, who are also co-authors of this paper. In the second stage, we designed and developed DrugExplorer for general drug repurposing based on the feedback in stage one. The team met on a regular basis to discuss the visualization results of GNN explanations and predictions and iterate the design based on expert feedback. The design study reveals the challenge of directly applying existing design study models. In particular, current visualization models are usually driven by domain problems and provide little guidance about 1) how to investigate experts' needs for AI explanations and 2) how these needs influence visualization design decisions. To incorporate XAI considerations in our visualization design, we choose the nested model among existing visualization models to highlight design decisions rather than the design process (e.g., <ref type="bibr" target="#b56">[57]</ref>) or architecture (e.g., <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b64">65]</ref>). The nested model provides a clear structure to describe and justify design decisions (i.e., design decisions are categorized into four nested layers and connected via design guidelines). Therefore, it serves as a useful backbone structure to incorporate XAI design considerations into our design decisions. To guide the design process with representative XAI considerations, we first extracted all the XAI-related design considerations from nine XAI design frameworks <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b41">42,</ref><ref type="bibr" target="#b67">68]</ref>. We then merged similar design considerations and removed design considerations that are not related to domain users (e.g., design considerations targeted at AI novices). We carefully fit these design considerations into the four layers of the nested model. We tested and modified these considerations throughout how to present the explanation format at selected levels of granularity partially covered in <ref type="bibr" target="#b27">[28]</ref> Interaction how to support required operations at the selected explanation format the design process based on users' feedback about DrugExplorer. Table 1 summarizes how different XAI considerations are incorporated into the design process and extend the nested model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Domain</head><p>In the domain characterization layer, a visualization designer identifies the domain problems and needs related to the design of visual explanations. Unlike the nested model, which includes all necessary elements (e.g., target users, domain questions) in one "situation" block, we follow the practice in current XAI frameworks <ref type="bibr" target="#b33">[34,</ref><ref type="bibr" target="#b41">42]</ref> and use four separate blocks (Target User, XAI Goal, Usage Context, and Domain Explanation) to provide clearer design guidance.</p><p>Target User describes the characteristics of users such as their AI expertise, research field, and their responsibilities in using the AI system. Previous studies <ref type="bibr" target="#b41">[42]</ref> categorize the users into three main groups: data experts, AI novices, and AI experts. The domain users in this paper belong to the data expert group. XAI Goal relates to the motivation of explainability and clarifies which domain-related problems that the target users aim to solve with AI explanations. It is very important to distinguish between the goal for AI and the goal for AI explanations. Usage Context depicts the context of using AI explanations (when and where), revealing characteristics such as outcome criticality, time-sensitivity, and decision complexity.</p><p>An important block that is often overlooked in previous literature is Domain Explanation, which describes how a human expert would reason about a phenomenon in the applied domain. Domain Explanation reflects the user mental model and can help designers present AI explanations in a way that can be efficiently and accurately interpreted by users. Domain Explanation can vary based on target user and usage context. For example, a human expert might use inductive explanation (e.g., explain using similar items) if the time to make decisions is limited and use deductive explanations (e.g., explain through mathematical concepts) for less time-sensitive scenarios <ref type="bibr" target="#b67">[68]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Explanation Abstraction</head><p>This layer clarifies what explanation content and operations should be provided based on the blocks identified in domain characterization. Instead of adding an additional explanation layer to the original 4layer nested model, we specify the data/task abstraction layer as an explanation abstraction layer by considering explanations as a special type of data. This is because most AI explanations are already described in the language of computer science, which is the fundamental purpose of using the abstraction layer in the nested model <ref type="bibr" target="#b42">[43]</ref>. We believe such a specification is more concise and easy to use.</p><p>From the literature, we identify three key blocks in the explanation abstraction layer: Format, Granularity, and Operation. In the original nested model, blocks are either "identified" or "designed". However, explanation abstraction should be "selected" among the possible options restricted by the existing XAI techniques. Therefore, we also enumerate the possible options for each block in the explanation abstraction layer to better guide the design of visual explanations. Meanwhile, by abstracting the three blocks, we can describe explanations in a way that is independent of the XAI algorithm details. Both ante-hoc and post-hoc explanations are supported using these abstractions. For example, rulebased explanations (an explanation format) can be generated by both ante-hoc (e.g., a decision tree) or post-hoc methods (e.g., deep-red <ref type="bibr" target="#b85">[86]</ref>).</p><p>Format: Jin et al. <ref type="bibr" target="#b27">[28]</ref> reviewed 59 XAI techniques and summarized three explanation formats: attribution (e.g., feature importance scores), example (e.g., similar examples, counterfactual examples), and clause (e.g., decision trees, rule lists). This categorization is also used in later XAI frameworks <ref type="bibr" target="#b67">[68]</ref>. However, we found that these formats, even though helpful, are difficult to be applied to summarize GNN explanations, potentially caused by the fact that the three formats are summarized from XAI techniques for Euclidean data (e.g., text, image, table <ref type="table">)</ref>. The boundaries between these three formats can be vague in GNN explanations. Take node prediction in GNN as an example. Given a graph with some unlabeled nodes, a GNN predicts an unlabeled "node m as type A". A common explanation is that "because node m is connected to several type A nodes" <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b78">79]</ref>. This explanation can be treated as an example-based explanation by considering other type A nodes as individual examples. On the other hand, this explanation can also be treated as attribution-based explanation by considering nodes as the attributions of the input graph.</p><p>To solve this problem and guide the visual design for GNN explanations, we conducted a review of GNN explanation techniques based on <ref type="bibr" target="#b79">[80]</ref> and summarized three main formats for GNN explanations, i.e., nodes, paths, and subgraphs. Node-based explanations show important nodes that contribute most to a certain prediction. Such explanations can be extracted from GNN models that employ the attention mechanism <ref type="bibr" target="#b65">[66]</ref> or constructed by post-hoc methods, e.g., Graph Mask <ref type="bibr" target="#b54">[55]</ref>.</p><p>Subgraph-based explanations show a subgraph of the input knowledge graph that is most related to a certain prediction. Such explanations can be extracted from GNNs that learn a local subgraph for making predictions (e.g, SEAL <ref type="bibr" target="#b84">[85]</ref>) or constructed by post-hoc algorithms, e.g., Sub-graphX <ref type="bibr" target="#b80">[81]</ref>. Path-based explanations explain a prediction through relevant paths in the knowledge graph. Such explanations can be extracted from models that consider multi-hop connections (e.g., GTN <ref type="bibr" target="#b82">[83]</ref>) or constructed by post-hoc algorithms (e.g., GNN-LRP <ref type="bibr" target="#b55">[56]</ref>).</p><p>While the explanation format is related to all the domain blocks, it is mostly influenced by the domain explanation. In other words, designers should select explanation formats that are similar to how human users explain a phenomenon to their peers <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b62">63]</ref>. Granularity: granularity specifies whether to present local explanations (i.e., explain individual predictions), group explanations (i.e., explain a group of predictions), global explanations (i.e., explain the whole model), or a combination of the above. Most existing XAI frameworks categorize explanations into local and global and rarely discuss group explanations, which is reported by our collaborators as an important level of granularity. For example, when reasoning about drug indications, domain users usually group drugs that share a similar mechanism of action. A group explanation for these similar drugs can facilitate the understanding and increase the efficiency of the analysis. Operation: Similar to the nested model, we include both low-level operations and high-level operations. A high-level Operation indicates a reasoning process users conduct upon explanations. We bring lessons from previous surveys and expert interviews <ref type="bibr" target="#b35">[36,</ref><ref type="bibr" target="#b41">42]</ref> and summarize five types of high-level operations: why, why not, what if, how to, what else. Other operations, such as understanding algorithms, are excluded since they are not directly related to domain-specific XAI applications, as indicated by the interview results from Sibyl <ref type="bibr" target="#b86">[87]</ref>. Lowlevel operations are similar to the low-level tasks discussed in visual analytics literature <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b75">76]</ref>. To accomplish high-level operations, users need to conduct a set of low-level operations such as filter explanations, compare explanations, and identify abnormal explanations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Visualization</head><p>Designers create visual encoding and interactions in this layer to present explanations to domain users, mainly driven by the three blocks in explanation abstraction. Specifically, the explanation formats should be visualized at the selected levels of granularity and the operations need to be supported through a set of interactive visualizations.</p><p>At the same time, common design practices for AI explanations should also be considered to provide familiar visualizations to users and flatten their learning curve. Some explanations are commonly represented using standard visualizations in the wild, as discussed by Wang et al. <ref type="bibr" target="#b67">[68]</ref> and Jin et al. <ref type="bibr" target="#b27">[28]</ref>. For example, scatter plots have been widely used to display similar and counterfactual examples; the beeswarm plot is typically used to visualize attribution explanations (e.g., SHAP value) for tabular data <ref type="bibr" target="#b27">[28,</ref><ref type="bibr" target="#b67">68]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Algorithm</head><p>The Algorithm level includes the algorithmic implementation of both the interactive visualizations and the XAI techniques. An XAI algorithm should be selected and evaluated by jointly considering the output of the visualization layer, the speed of the explanation query, and the performance of the XAI algorithm (e.g., stability, faithfulness). We do not distinguish ante-hoc and post-hoc explanations here since they are able to support the same explanation abstractions (e.g., they both can generate local explanations). We refer readers to Vilone and Longo's survey <ref type="bibr" target="#b66">[67]</ref> for a comprehensive list of XAI algorithms and Rubin's paper <ref type="bibr" target="#b50">[51]</ref> for the debate about ante-hoc and post-hoc explanations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">DRUGEXPLORER</head><p>This section describes how the XAI considerations introduced in Sect. 4 guide the design of DrugExplorer. Fig. <ref type="figure">2</ref> summarizes the design process and our evaluation strategies. We do not distinguish links within a layer and between layers for simplicity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Target User Usage Context</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>XAI Goal Domain Explanation</head><p>Operations Format Granularity DrugExplorer Fig. <ref type="figure">2</ref>. The design process for DrugExplorer based on the proposed extension of the nested model with user-centric XAI considerations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Domain</head><p>The Target Users of DrugExplorer are domain experts in drug repurposing (e.g., wet lab biologists, physicians, disease experts, pharmacologists). They have limited knowledge about AI algorithms but high expertise in the application domain. As shown in Fig. <ref type="figure" target="#fig_0">3</ref>, the typical Usage Context of DrugExplorer is after a GNN has predicted a list of drug candidates and before downstream-evaluation of these drugs. In a high-stakes task such as drug repurposing, model predictions need to be systematically evaluated by domain experts through resource-intensive laboratory experiments, including in vitro screening <ref type="bibr" target="#b20">[21]</ref>, in vivo testing <ref type="bibr" target="#b15">[16]</ref>, and clinical trials <ref type="bibr" target="#b60">[61]</ref>. Given that only limited resources are available for such studies, domain experts need to choose a small number of highly promising therapeutic opportunities out of a number of predicted drugs. Therefore, the XAI Goal is to assist domain experts in evaluating GNN predicted drugs. Specifically, domain experts will use the explanations to G1) assess whether an individual drug prediction is promising and deserves further investigation; G2) efficiently select several most promising drugs from a potentially long list of predictions. In terms of Domain Explanation, domain experts typically examine drug repurposing predictions by looking at biological processes associated with the predicted drug and reasoning how those processes relate to the disease for which the drug was predicted <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b51">52]</ref>. Take Ibuprofen as an example (Fig. <ref type="figure" target="#fig_1">4(a)</ref>). This drug can treat pain because it inhibits COX, which is required for the synthesis of prostaglandins via the arachidonic acid pathway, and prostaglandins are important mediators of pain.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Abstraction</head><p>Format: Based on the experiments on real datasets and feedback from collaborators, we can rank the three explanation formats based on their similarities to the domain explanation (Fig. <ref type="figure" target="#fig_1">4</ref>). A suitable explanation format for drug repurposing should mimic how a human expert explains a drug indication with biological mechanisms. Therefore, path-based explanations are most suitable because they represent the semantic paths in the knowledge graph. For instance, the biological mechanism of Ibuprofen can be intuitively depicted by a path:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>[Ibuprofen]-[COX]-[arachidonic acid pathway]-[pain]</head><p>. Explanations based on neighbor nodes are least similar to domain explanations as they mainly depict the message passing mechanism at each GNN layer. Even though the subgraph may contain some paths that make sense in the biomedical context, it can be hard for users to effectively locate these paths. Operation: We selected two high-level operations, "why" and "what else", based on the XAI goals in Sect. 5.1. The "why" operation helps users understand the reasons for a certain drug prediction (G1). Since the explanation for one drug can consist of multiple paths, domain users need visualizations and interactions to help them organize these explanations and generate domain insights. Specifically, users may need to G1.1) summarize explanations based on their semantic meanings and G1.2) filter out less meaningful or irrelevant explanations. The "what else" operation allows users to query similar drugs to a predicted drug for a certain disease. Grouping similar predicted drugs can accelerate the analysis of a potentially long list of drugs (G2). To facilitate the "what else" operation, we allow users to G2.1) group similar drugs and summarize them in a domain relevant way and G2.2) compare different drug groups based on their explanations. Other operations, even though promising, are excluded as they are not related to the identified domain problems. For example, the "what if" operation, which investigates how a modification to the input will influence the predictions, can identify new potential therapeutic opportunities by changing the structure of existing compounds. This operation is useful for drug discovery rather than drug repurposing.</p><p>Granularity: We decided granularity mainly based on the XAI goals. To support G1, local explanation is inevitable. For path-based explanations, local explanations can be represented as individual paths that correspond to how this drug perturbs the biological systems to treat a disease. Meanwhile, even though G2 is doable by repeatedly examining local explanations, providing a group explanation for multiple similar predictions can effectively scale up the analysis. Therefore, we provide group explanations using meta-paths, a concept that is widely used in heterogeneous graph learning. A meta-path is a sequence of node/edge types and can summarize paths with similar semantic meanings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>For example, the path [Ibuprofen]-[COX]-[arachidonic acid pathway]-[pain] belongs to the meta-path [drug]-[protein]-[pathway]-[disease]</head><p>, which depicts a potential type of drug action mechanism.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Visualization</head><p>We designed DrugExplorer by jointly considering the three blocks of the abstraction layer. Specially, we visualize path-based explanations at different granularity levels and provide a set of interactive visualizations to support "why" and "what else" operations.</p><p>As shown in Fig. <ref type="figure" target="#fig_2">5</ref>, DrugExplorer consists of three main components: a control panel, a drug embedding view, and an explanation view. In the control panel (a), users can search and select a disease of interest, browse the top-ranked drugs predicted by the back-end GNN model, and filter explanations through their edge importance score (G1.2). The drug embedding view (b) presents the learned embedding of all drugs in the knowledge graph using t-SNE <ref type="bibr" target="#b63">[64]</ref> and highlights the predicted drugs for the selected disease. Users can easily identify similar drugs  in this embedding space (G2.1). The explanation view (c) provides path-based explanations for individual drug predictions.</p><p>The explanation view incorporates a novel MetaMatrix design. This design is inspired by the matrix design in <ref type="bibr" target="#b71">[72]</ref> to enable user examine, summarize, and compare explanations at different granularity. In MetaMatrix, each column is a predicted drug; each row is a meta-path, which can be expanded to rows of the corresponding paths. Meta-path is a concept widely used in heterogeneous graph learning. It uses a sequence of node/sequence types to summarize paths. We use different encodings to distinguish meta paths and paths, i.e., nodes in metapaths are represented as rounded rectangles with borders while nodes in paths are represented as rectangles with solid fills. The number in each cell indicates the number of explanation paths that belong to the corresponding meta-path or path (G1.1).</p><p>MetaMatrix provide diverse user interactions. First, the drugs (i.e., columns) can be sorted based on their prediction scores or grouped based on their proximity in the embedding space (G2.1). Users can efficiently compare different drugs (individual columns) or different groups (grouped columns) of drugs in terms of meta-paths, including the length of meta-paths, node types in meta-paths, and the number of paths belonging to a meta-path (G2.2) of interest. Second, users can hide, un-hide explanation paths (C2) to focus on the explanations of interest (G1.2). For example, as shown in Fig. <ref type="figure" target="#fig_2">5</ref>, users can collapse other meta-paths to highlight the comparison on interesting meta-paths (i.e.,</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>[disease]-[protein]-[drug], [disease]-[protein]-[phenotype]-[protein]-[drug]</head><p>). Users can also hide explanations of a specific meta-path if they think the related mechanism is less convincing. For instance, the meta-path that shows the drug protein and the disease protein are both absent in the same anatomy (i.e.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>, [disease]-[protein]-[anatomy]-[protein]-[drug]</head><p>) is less convincing than the explanation that the drug protein and the disease protein are connected to the same pathway (i.e.,</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>[disease]-[protein]-[pathway]-[protein]-[drug]</head><p>). Third, users can expand meta-paths and compare drugs on a more detailed level based on individual explanation paths. For example, as shown in Fig. <ref type="figure" target="#fig_2">5(C3)</ref>, Clozapine and Clomipramine are predicted for treating the disease unipolar depression partly because they are both connected to HTR2C, a protein that is connected to unipolar depression. Clozapine is at the left side and has a higher rank than Clomipramine, which might be related to the fact that Clozapine is also connected to another protein HTR7. Meanwhile, to help users quickly identify similar explanation paths, we employ the ditto mark (") (C4) to indicate that a node has the same name as the node in the path above (G1.1). Users can also review drug details from the DrugBank database <ref type="bibr" target="#b76">[77]</ref> in a pop-up window (C5).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Algorithm</head><p>Training Datasets. The training data for our study is a heterogeneous knowledge graph consisting of 10 different types of entities (e.g., drug, disease, protein) and 32 semantically distinct types of relationships between the entities (e.g., drug-disease indications, protein-protein interactions, drug-protein interactions). The dataset was assembled from 21 public databases of protein-protein interactions, gene expression data, clinical trials, and drug usage across the entire range of 22K+ human diseases and 7K+ drugs. GNN Model and Explanations. We formulated drug repurposing as a link prediction task. The GNN model tries to predict among three link types r ∈ R (i.e., indication, contra-indication, or off-label use) between a drug and a disease that are not connected in the training data (i.e., their relationship is unknown).</p><p>We used a heterogeneous GNN to generate embeddings for every node in the knowledge graph. Specifically, for a node i at the GNN layer l, its embedding h (l) i is calculated by aggregating the embeddings from the previous layer of its neighbor nodes N i , using relation weight matrices W (l) r and a message calculation function f : h</p><formula xml:id="formula_0">(l) i = h (l−1) i + ∑ r∈R ∑ j∈Ni f (W (l) r , h (l−1) j</formula><p>). Given the embedding of a drug i and a disease j, we predict the probability of edge relation r as p i, j,r = 1/(1 + exp(−sum(h i * w r * h j ))). We show that this model can accurately predict drug-disease relationships: the predicted drugdisease relationships rank 79.5% of hits in the top 5%, and 88.9% of hits in the top 10%.</p><p>To provide high-quality path-based explanations at both group and local level, we experimented with and adapted different ante-hoc and post-hoc explanation methods, including Graph Attention <ref type="bibr" target="#b73">[74]</ref>, GN-NExplainer <ref type="bibr" target="#b78">[79]</ref>, and GraphMask <ref type="bibr" target="#b54">[55]</ref>. We selected GraphMask due to its high fidelity. Finally, we developed a post-hoc graph explainability based on GraphMask that can drop superfluous edges from the knowledge graph and only retain a sparse set of edges that contribute most towards the prediction (Supplementary Sect.S3).  Fig. <ref type="figure">6</ref>. Exploring two groups of drug repurposing predictions (A1, B1) for the treatment of Alzheimer's Disease.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5">Implementation</head><p>The interactive visual explanations are implemented in JavaScript using React.js <ref type="bibr" target="#b25">[26]</ref>, D3.js <ref type="bibr" target="#b6">[7]</ref>, and Ant Design <ref type="bibr" target="#b61">[62]</ref>. The GNN model is implemented in Python using Pytorch <ref type="bibr" target="#b49">[50]</ref>. The graph data is stored in Neo4j database <ref type="bibr" target="#b43">[44]</ref>. The visual explanations communicate with the back-end GNN model through a Python web server built with Flask <ref type="bibr" target="#b19">[20]</ref>. The source code and an interactive demo are available at https://github.com/hms-dbmi/Drug_Explorer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">USAGE SCENARIO</head><p>We demonstrate how DrugExplorer can be used to examine treatments for Alzheimer's Disease (AD). The GNN model was trained on the full knowledge graph and used to make predictions for drugs that were not included in the knowledge graph. We selected AD in the visualization tool and explored predicted drugs and their explanations.</p><p>The tool automatically produced predictions, explanations and updated visualizations for AD (Fig. <ref type="figure">6</ref>). Predicted drugs were scattered in the Embedding view, indicating that the GNN model produced predictions for a diverse set of drugs.</p><p>We first examined the largest cluster of drugs (Fig. <ref type="figure">6(A1)</ref>). This cluster included drugs such as Glyburide, Repaglinide, Tolbutamide, and Metformin, which are commonly used to treat Type 2 diabetes (T2D). Drugs found in the cluster were consistent with the current scientific understanding of the connections between cognitive impairment and T2D <ref type="bibr" target="#b52">[53]</ref>. Previous studies found that the use of antidiabetic treatments among individuals with T2D could mitigate risk for dementia <ref type="bibr" target="#b2">[3]</ref>.</p><p>We then examined explanations for the predicted antidiabetic drugs in the MetaMatrix view. To this end, we first selected Repaglinide in the MetaMatrix view to show detailed explanations. The shortest meta-path is Disease-Gene/Protein-Drug. The explanation path below that meta-path (Fig. <ref type="figure">6</ref>.A2) showed that Repaglinide targets protein PPARG, which, in turn, is associated with AD. Based Disease-Gene /Protein-Drug-Gene/Protein-Disease meta-path (A3), we see that drug Repaglinide was predicted partly because it has the same target protein as Ibuprofen. Ibuprofen targets proteins that are associated with AD and can delay some forms of AD pathology <ref type="bibr" target="#b36">[37]</ref>. Similar instances of meta-paths existed in explanations of other antidiabetic drugs, including Nateglinide and Tolbutamide (A2, A3).</p><p>Another cluster (Fig. <ref type="figure">6</ref>(B1)) in the Embedding view comprised of anticholinergic drugs, including Pergolide and Orphenadrine, which are used to manage Parkinson's disease. Based on the MetaMatrix(C), we found this drug group is different from the previous T2D group in terms of meta-paths. Specifically, the explanations for this group did not have Disease-Gene/Protein-Drug or Disease-Gene /Protein-Drug-Gene/Protein-Disease, which were the main explanations for T2D drug group. We then investigated the explanation paths for more details. We found that the target protein of Pergolide and Orphenadrine interacts with multiple AD-associated proteins through shared cellular phenotypes (B2), an observation consistent with the reported associations between AD and anti-Parkinson's agents <ref type="bibr" target="#b45">[46]</ref>. While some studies <ref type="bibr" target="#b29">[30]</ref> reported the contraindication of these drugs, the contraindication still   about how to read and interact with the three visual explanations. Participants assessed 16 AI predictions under four different conditions (four predictions under each condition). For each prediction, participants decided whether the predicted drug can be used for treating a certain disease and reported their confidence levels using a 5-point Likert scale (1=not confident at all, 5=completely confident). The completion time for assessing each prediction was automatically recorded by our study system. The order of predictions and the order of the four conditions were randomized and counterbalanced across participants. Finally, we asked the participants a set of semi-structured questions around two main topics: 1) which factors influenced their decisions and their confidence level; 2) how they interpreted the AI explanations.</p><p>Results. We set α = 0.05 and tested three hypotheses: H1) Pathbased explanations have higher accuracy than other conditions; H2) Path-based explanations enable more confident user performance than other conditions; H3) Path-based explanations require less time than other explanation types but more time than baseline. Another purpose of assessing the 16 predictions is to force participants to actually make decisions using different explanations, which are important to precisely understand user perception of AI explanations and generate helpful discussions in the following interviews <ref type="bibr" target="#b7">[8]</ref>. We conducted the Repeated Measures ANOVA analysis to compare the average accuracy, self-reported confidence score, and completion time across the four conditions. If there is a significant difference among the four conditions, we ran Tukey's Honest Significant Difference test to confirm whether the differences occurred between each two conditions.</p><p>Results of the user study are summarized in Fig. <ref type="figure" target="#fig_5">8</ref>. Path-based explanations have significantly better performance than baseline and node-based explanations at all three metrics: accuracy, confidence, time. Compared with subgraph-based explanations, even though the path-based explanations' advantages are not significant in terms of accuracy and confidence, they require significantly less time. Surprisingly, the user study results show that providing explanations does not necessarily improve user performance. Node-based explanations and subgraph-based explanations do not have significantly higher accuracy or confidence than baseline. Participants' ratings for the three types of visual explanations were roughly consistent with their similarity to domain explanations, as shown in Fig. <ref type="figure" target="#fig_1">4(b</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">EXPERT INTERVIEW</head><p>Ten out of the twelve participants in the user study agreed to participate in an interview about their experience with DrugExplorer. During the interview, we first demonstrated the functionalities of DrugExplorer using the usage scenario about Alzheimer's Disease Sect. 6. Participants then freely explored the diseases and drugs of interest on a testing set containing 48 diseases (Supplementary Material, Sect. S1). Each participant selected at least one disease of interest, explored the interactive visualizations, and freely commented on the AI predictions, the visual explanations, and their usage experiences of DrugExplorer. The interview took around 25 minutes for each participant.</p><p>Overall, participants expressed great interest in this tool, commented that it "targets an important problem and can be super helpful". Even though we introduced a new visualization design, MetaMatrix, all participants agreed that they had no difficulties in understanding the AI explanations and interacting with the tool. Meanwhile, participants exhibited cautious enthusiasm towards DrugExplorer and emphasized that downstream evaluations, such as clinical trials, were essential to validate the AI-predicted drug repurposing, even if only for regulatory purposes. For example, P8, a physician who specializes in pain management and "prescribed a lot of off-label drugs", expressed strong interest in using this tool since the explanations were consistent with his reasons for some off-label prescriptions. They described his plan for validating the potential drug candidates: i) identify promising drug candidates whose explanations are biomedically meaningful; ii) validate the biomedical mechanisms in the explanation and ensure the drug has no adverse effect; iii) prescribe this drug to some patients who are not responding to first-line treatments (i.e., approved or recommended treatments); iv) conduct clinical trials if the drug seems effective.</p><p>Most participants agreed that DrugExplorer supports the goal of repurposing drugs well. In addition, some participants commented that this tool could potentially be generalized beyond drug repurposing to other related problems. For example, P4 commented that this tool could serve as an educational tool to help medical students better understand existing drugs, diseases, and their relationships to other medical entities. P1 and P2 stated that this tool could be used for polypharmacy (i.e., the simultaneous use of multiple drugs), such as predicting polypharmacy side effects. "Similar to explaining a drug-disease indication, the visualization can show how a drug changes the activities of another drug and illustrates the causes of side effects." (P2).</p><p>Participants also offered helpful suggestions for improving this tool. Five participants mentioned that more biomedical information about the nodes and edges would help them more confidently assess the explanations. "They [the provided explanations] are useful but somehow abstract.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>" (P8) "The [disease] -[protein] -[pathway] -[protein] -</head><p>[disease] can be a piece of strong evidence but I need to know more details about how this protein is involved in this pathway. I can always check literature for such information myself, but it would be great if it is provided here." (P2) P10 suggested the functionality to annotate explanations, save, and share these annotations. These suggestions reflect the participants' wishes to better align the AI explanations with how they typically reason about a drug indication, indicating the importance of choosing proper explanation abstractions based on domain characterizations. Meanwhile, three participants (P2, P5, P9) mentioned that the subtle distinctions between the represented explanations and real-world biomedical mechanisms can sometimes be confusing. For example, in AI explanations, edge thickness represents the importance of this edge to a certain AI prediction. The thickness can be easily confused with the strength of the biological relation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9">OBSERVATIONS, INSIGHTS, AND DISCUSSION 9.1 Observations about domain users</head><p>Human Knowledge vs. AI Explanation. We did not observe blind trust in AI explanations as reported in some previous studies <ref type="bibr" target="#b30">[31,</ref><ref type="bibr" target="#b67">68]</ref>, which might be related to the critical nature of the medical domain. Instead, participants heavily relied on their prior knowledge accumulated through years of experience and medical training when assessing predictions and explanations. All participants stated they first used their own knowledge when checking the predictions. When prior knowledge could help them make a decision, most (9/12) participants stated that they still examined explanations to validate their decisions and evaluate the quality of explanations. When participants were not familiar with the drug or the disease, they examined whether the AI explanation is domain relevant. For example, some (5) participants said that [disease] -[protein] -[drug] was strong evidence, because this path indicated that the disease is directly associated with the drug's target protein.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>On the contrary, [disease] -[protein] -[anatomy] -[protein] -[drug]</head><p>"is more like a correlation rather than a causation" (P2).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Domain explanations can vary slightly across human experts.</head><p>While participants employed similar ways of reasoning about a drug indication (i.e., checking the connections between the drug and the disease), we also observed subtle differences among participants. For example, P5 stated that they "consider[ed] the drug and the disease simultaneously to see how they met in the middle". The path-based explanations in DrugExplorer were confusing at first because P5 felt they need to read from left (drug) to right (disease). But P5 also commented that this problem is "easy to overcome after exploring some predictions".</p><p>Actually making decisions influence human experts' opinions towards explanations. We observed that the attitude of some participants (P2, P4, P5) towards the three explanation types changed before and after assessing the 16 predictions. This indicates the importance of interacting with AI explanations and performing actual tasks in evaluating XAI. For example, P2 commented "the subgraph one is so much better than others" when learning the tutorial. However, in the post-study interview, P2 stated "this [path-based] explanation can provide all the information I needed when checking that [subgraph-based] explanation, and even in a more straightforward way. The subgraph is just more visually appealing to me." In earlier studies, expert interviews that were purely based on imaginary scenarios or non-explainable AI predictions are widely used <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b62">63]</ref>. They provide an efficient approach to understand user needs and preferences, especially considering the numerous time and efforts required to develop XAI systems. However, our observations suggest that, without interacting with AI explanations and completing actual tasks, participants may report inaccurate feedback in some situations.</p><p>Human experts tend to reshape less suitable explanations. All participants stated that examining the connections between the drug and disease is their primary way of assessing an AI prediction. When using node-based explanations, which is inconsistent with their preferred reasoning processes, participants responded differently. Two participants still tried to find connections by identifying same nodes in the neighbors of the drug and the neighbors of the diseases, which are "extremely painful to find useful information" (P3). Other participants, however, treated the node-based explanations as providing context information about the drug and the disease. For example, P8 mentioned that they mainly checked whether the phenotype and pathway nodes in the drug's neighbors were related to the disease based on his prior knowledge. In other words, participants tried to build an implicit connection between the drug and the disease using their prior knowledge. One possibility is that, when the explanation is too far from their mental models, participants tended to reshape the explanation and add extra information to make the explanation similar to their mental models. While this strategy made node-based explanations easier to interpret, participants were less confident about their interpretation, which is reflected in their reported confidence levels (Fig. <ref type="figure" target="#fig_5">8(b)</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9.2">Reflections on XAI visual design</head><p>Contextualized XAI through visualization design. Current XAI algorithms usually construct explanations via a data-centric approach regardless of the context in which the explanation is used. While such a strategy ensures these algorithms are generic and applicable to a variety of problems, it also poses challenges for human experts in interpreting these explanations and obtaining actionable insights. Our study suggests that the one-size-fits-all explanations can fail in realworld applications. When facing explanations that are inconsistent with their commonly-used domain explanations, users tend to reshape these explanations to match their mental models and become less confident about their interpretation. In spite of the importance of context, it can be challenging to integrate context factors into XAI algorithms.</p><p>Our study shows that visualization designs can be considered independently from the algorithmic aspects and serve as an effective method to integrate the context of an explanation. DrugExplorer is designed and developed guided by a list of context factors (i.e., the domain explanations, the usage contexts, the XAI goal, target users) that we identified through literature review and collaborators' feedback. Meanwhile, this list of context factors is not exhaustive and will evolve as future design studies and field studies are conducted. For example, Domain Expla-nation, an important design consideration revealed in our design study, is only briefly discussed in previous studies. We anticipate that this paper will encourage more design studies and field studies to better understand how to contextualize XAI through visualization design.</p><p>Interactive visualization is a fundamental component of AI explanations. This study suggests that, apart from algorithms that extract information for explaining a prediction, visual presentation and user interaction are also critical components of an AI explanation, especially in human-AI collaboration. As we demonstrate, how an AI explanation is visually presented and how users interact with the explanation can directly influence how users interpret and use the explanation.</p><p>More importantly, providing AI explanations with proper interactive visualizations not only helps users interpret the explanations but also encourages feedback from users. For example, our study participants employed the hide interaction to hide meta-paths that are not meaningful in the biomedical context. Such interactions reflect users' domain knowledge and act as important feedback. In future work, we plan to integrate such feedback into the model training, which can improve the performance of the AI and the quality of explanation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9.3">Limitations and future work</head><p>While the evaluation demonstrates the effectiveness of DrugExplorer and the extended nested model, this study has several limitations. First, we conducted the evaluation in the setting of a laboratory study rather than in a real-world deployment. This limitation is shared with many other prototype visualization tools <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b46">47,</ref><ref type="bibr" target="#b69">70]</ref>. More importantly, a real-world deployment of DrugExplorer can be challenging due to the regulatory and ethical issues involved in drug repurposing. At the same time, participants reported positive feedback about DrugExplorer and agreed with its usability. The evaluation generated valuable observations and findings that will benefit future applications of XAI. Second, limited by the training data and the back-end GNN model, the explanation format is relatively simple and may not provide all detailed information a human expert needs to systematically assess a drug repurposing prediction. For example, for edges in the knowledge graph, the back-end GNN model only considers edge types. Therefore, DrugExplorer does not provide edge details such as the protein binding sites targeted in a [drug]-[protein] edge. Even though the GNN model already generates accurate predictions and explanations, providing more biomedical details can better assist human experts. We plan to further improve the knowledge graph and incorporate detailed biomedical information in the visual explanations in future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="10">CONCLUSION</head><p>This paper presents a design study that investigates how to select and visualize AI explanations for domain experts in GNN-based drug repurposing. This design study follows the nested model of visualization design and extends it by incorporating user-centric XAI considerations based on a literature review and feedback from collaborators. An interactive visualization tool, DrugExplorer, is designed, developed, and evaluated. DrugExplorer provides a novel visualization called MetaMatrix that enables efficient organization and comparison of explanation paths at different granularity. This design can be applied to other similar problems, such as explaining GNN-predicted polypharmacy side effects. Our extension to the nested model highlights important takeaways: (1) visualization of explanations should consider both the domain users' mental model and the available explanation formats;</p><p>(2) the needed interactions are related to the XAI goals as well as the supported XAI operations by existing techniques. This extension does not aim to be an exhaustive list, but a cornerstone that will inspire and be further extended through future design studies and field studies.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 3 .</head><label>3</label><figDesc>Fig.3. DrugExplorer provides explanations to help domain experts assess drug repurposing predictions before downstream evaluation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. (a): In the domain layer, we investigate how a domain expert would explain a drug indication. (b): In the explanation abstraction layer, we compare different GNN explanations based on their similarity to the domain explanation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 5 .</head><label>5</label><figDesc>Fig.5. DrugExplorer provides interactive visual explanations for GNN-based drug repurposing. Users can select drugs based on their rankings using the control panel (a) or their similarities using the drug embedding view (b). The explanation view (c) incorporates a novel MetaMatrix design and provides diverse interactions (C1-5) for users to effectively interpret and validate explanations.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 7 .</head><label>7</label><figDesc>Fig. 7. The user study compares path-based explanations against three alternative conditions: node-based explanations (a), subgraph-based explanations (b), and a non-explanation baseline.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 8 .</head><label>8</label><figDesc>Fig. 8. Accuracy (a), confidence levels (b), and time (c) under different conditions. Error bars indicate 95% confidence intervals. A link in (d) indicates a significant difference between two conditions.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 .</head><label>1</label><figDesc>User-centric XAI considerations in the visualization design.</figDesc><table><row><cell>Block</cell><cell>Notes</cell><cell>Ref</cell></row><row><cell></cell><cell>Domain</cell><cell></cell></row><row><cell>Target</cell><cell>users' research field, AI expertise,</cell><cell></cell></row><row><cell>User</cell><cell>and role in using AI systems</cell><cell></cell></row><row><cell>Usage Context XAI</cell><cell>when and where will the AI explana-tions be used (e.g., time sensitivity) domain-related problems that the</cell><cell>[12, 19, 24, 34, 36, 42]</cell></row><row><cell>Goal</cell><cell>users aim to solve using AI expla-</cell><cell></cell></row><row><cell></cell><cell>nations</cell><cell></cell></row><row><cell>Domain</cell><cell>how a human expert would reason</cell><cell>user men-</cell></row><row><cell>Explanation</cell><cell>about a phenomenon in the applied</cell><cell>tal model</cell></row><row><cell></cell><cell>domain</cell><cell>in [17, 24,</cell></row><row><cell></cell><cell></cell><cell>42]</cell></row><row><cell></cell><cell>Abstraction</cell><cell></cell></row><row><cell></cell><cell>attribution: explain using feature</cell><cell>[28, 68]</cell></row><row><cell></cell><cell>attributes (e.g., salience map, feature</cell><cell>mainly for</cell></row><row><cell></cell><cell>importance scores)</cell><cell>Euclidean</cell></row><row><cell></cell><cell>example: explain using similar or</cell><cell>data such as</cell></row><row><cell></cell><cell>contrastive examples</cell><cell>images and</cell></row><row><cell></cell><cell>clause: explain using rules or deci-</cell><cell>tables</cell></row><row><cell>Format</cell><cell>sion trees</cell><cell></cell></row><row><cell></cell><cell>node: important neighbor nodes to</cell><cell>Our survey</cell></row><row><cell></cell><cell>the prediction targets</cell><cell>on GNN ex-</cell></row><row><cell></cell><cell>path: important message passing</cell><cell>planations</cell></row><row><cell></cell><cell>for the prediction targets</cell><cell>based</cell></row><row><cell></cell><cell>subgraph: important subgraphs</cell><cell>on [80]</cell></row><row><cell></cell><cell>around the prediction targets</cell><cell></cell></row><row><cell></cell><cell>local: explain an individual predic-</cell><cell></cell></row><row><cell>Granularity</cell><cell>tion global: explain a prediction process of a model</cell><cell>[34, 36, 42]</cell></row><row><cell></cell><cell>group: explain a group of similar</cell><cell>collaborators'</cell></row><row><cell></cell><cell>predictions</cell><cell>feedback</cell></row><row><cell></cell><cell>why: reason about why a certain pre-</cell><cell></cell></row><row><cell></cell><cell>diction is made</cell><cell></cell></row><row><cell></cell><cell>why not: reason about why a certain</cell><cell></cell></row><row><cell></cell><cell>prediction is not made</cell><cell></cell></row><row><cell></cell><cell>what if: understand how a specific</cell><cell></cell></row><row><cell>Operation</cell><cell>modification will influence the pre-diction</cell><cell>[36, 42, 68]</cell></row><row><cell></cell><cell>how to: investigate the adjustment</cell><cell></cell></row><row><cell></cell><cell>needed to generate a different pre-</cell><cell></cell></row><row><cell></cell><cell>diction</cell><cell></cell></row><row><cell></cell><cell>what else: query similar instances</cell><cell></cell></row><row><cell></cell><cell>that generate similar predictions</cell><cell></cell></row><row><cell></cell><cell>Visualization</cell><cell></cell></row><row><cell>Encoding</cell><cell></cell><cell></cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS</head><p>The authors wish to thank all the participants in the expert interviews and user studies. M.Z. is supported, in part, by NSF  under Nos. IIS-2030459 and IIS-2033384, Air Force Contract No. FA8702-15-D-0001, Harvard Data Science Initiative, Amazon Research Award, Bayer Early Excellence in Science Award, AstraZeneca Research, and Roche Alliance with Distinguished Scientists Award.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>reflected the GNN's ability to identify associations unknown in the training graph. This example also highlighted the utility of visual explanations to involve humans and identify possible inaccurate predictions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">USER STUDY</head><p>Participants. We recruited 12 medical professionals (7 males, 5 females, denoted as P1-12) through personal contacts, Slack channels, and email lists in related institutions. The mean (SD) age of the participants was 34.25 (6.12) years. All participants have worked in medicine-related fields for more than five years, including five clinical researchers (P1-3, P11-12) and five practicing physicians (P4, P7-10), who all have MD degrees, and two medical school students who used to work as pharmacists (P5, P6). The participants were familiar with basic concepts of machine learning but are not experts. No participants knew this project before and none of them are authors of this paper.</p><p>Conditions and Tasks. We tested total four conditions: 1) a nodebased explanation; 2) a path-based explanation; 3) a subgraph-based explanation; and 4) a non-explanation baseline that only reported a confidence score. Since we aim to assess the visual presentations independent of the algorithmic aspect of explanations, we used the same algorithm (i.e., GraphMask <ref type="bibr" target="#b54">[55]</ref>) and generated explanations with different presentations through certain transformations (Supplementary Material, Sect. S1.4). For all three visualizations, the color indicates the node type, and edge line-width indicates the importance. Users can interactively filter explanations based on their importance.</p><p>We collected 16 predicted drug-disease treatment pairs (twelve correct, four wrong) and asked the participants to assess these predictions under four different conditions (four predictions in each condition). Since other alternatives can not effectively group explanations, we only asked users to evaluate individual predictions.</p><p>The tasks and the evaluation procedure were validated and refined through a pilot study with two domain experts and one AI expert. The three pilot study participants were not included in the twelve participants of the study reported here. The two domain experts were not authors but the AI expert is an author of this paper. The full list of the drug-disease pairs and the interface used for the user study are described in the Supplementary Material.</p><p>Procedure. The evaluation took around 40 minutes on average for each participant. Participants were first presented with a brief introduction about the study, an informed consent form, and a 10-min tutorial</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Debugging tests for model explanations</title>
		<author>
			<persName><forename type="first">J</forename><surname>Adebayo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Muelly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Liccardi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
				<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="700" to="712" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Towards a rigorous theoretical analysis and evaluation of gnn explanations</title>
		<author>
			<persName><forename type="first">C</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zitnik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Lakkaraju</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2106.09078</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Antidiabetic drugs for the risk of alzheimer disease in patients with type 2 dm using faers</title>
		<author>
			<persName><forename type="first">H</forename><surname>Akimoto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Negishi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Oshima</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wakiyama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Okita</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Horii</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Inoue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ohshima</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Kobayashi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">American Journal of Alzheimer&apos;s Disease &amp; Other Dementias®</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page">1533317519899546</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Evaluating saliency map explanations for convolutional neural networks: a user study</title>
		<author>
			<persName><forename type="first">A</forename><surname>Alqaraawi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Schuessler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Weiß</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Costanza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Berthouze</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th International Conference on Intelligent User Interfaces</title>
				<meeting>the 25th International Conference on Intelligent User Interfaces</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="275" to="285" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Low-level components of analytic activity in information visualization</title>
		<author>
			<persName><forename type="first">R</forename><surname>Amar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Eagan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Stasko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Symposium on Information Visualization, 2005. INFOVIS 2005</title>
				<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="111" to="117" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Design decision framework for ai explanations</title>
		<author>
			<persName><forename type="first">O</forename><surname>Anuyah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Fine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Metoyer</surname></persName>
		</author>
		<idno type="DOI">10.18420/muc2021-mci-ws02-237</idno>
	</analytic>
	<monogr>
		<title level="m">Mensch und Computer 2021 -Workshopband</title>
				<editor>
			<persName><forename type="first">C</forename><surname>Wienrich</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><surname>Wintersberger</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">B</forename><surname>Weyers</surname></persName>
		</editor>
		<meeting><address><addrLine>Bonn</addrLine></address></meeting>
		<imprint>
			<biblScope unit="page">2021</biblScope>
		</imprint>
		<respStmt>
			<orgName>Gesellschaft für Informatik e.V.</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">D 3 data-driven documents</title>
		<author>
			<persName><forename type="first">M</forename><surname>Bostock</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Ogievetsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Heer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2301" to="2309" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Proxy tasks and subjective measures can be misleading in evaluating explainable ai systems</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Buçinca</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">Z</forename><surname>Gajos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">L</forename><surname>Glassman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th International Conference on Intelligent User Interfaces</title>
				<meeting>the 25th International Conference on Intelligent User Interfaces</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="454" to="464" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">hello ai&quot;: Uncovering the onboarding needs of medical practitioners for humanai collaborative decision-making</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">J</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Winter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Steiner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wilcox</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Terry</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the ACM on Humancomputer Interaction</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="1" to="24" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Analyzing the noise robustness of deep neural networks</title>
		<author>
			<persName><forename type="first">K</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="3289" to="3304" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Readings in information visualization: using vision to think</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">K</forename><surname>Card</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Mackinlay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Shneiderman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Explanation ontology: A model of explanations for user-centered ai</title>
		<author>
			<persName><forename type="first">S</forename><surname>Chari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Seneviratne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Gruen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Foreman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">L</forename><surname>Mcguinness</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Semantic Web Conference</title>
				<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="228" to="243" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">OoDAnalyzer: Interactive analysis of out-of-distribution samples</title>
		<author>
			<persName><forename type="first">C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="3335" to="3349" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Vbridge: Connecting the dots between features and data to explain healthcare models</title>
		<author>
			<persName><forename type="first">F</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zytek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Veeramachaneni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Explaining decision-making algorithms through ui: Strategies to help non-expert stakeholders</title>
		<author>
			<persName><forename type="first">H.-F</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>O'connell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Gray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">M</forename><surname>Harper</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 chi conference on human factors in computing systems</title>
				<meeting>the 2019 chi conference on human factors in computing systems</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="1" to="12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">The susceptibility of trypanosomatid pathogens to PI3/mTOR kinase inhibitors affords a new opportunity for drug repurposing</title>
		<author>
			<persName><forename type="first">R</forename><surname>Diaz-Gonzalez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">M</forename><surname>Kuhlmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Galan-Rodriguez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">M</forename><surname>Da Silva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Saldivia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">E</forename><surname>Karver</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rodriguez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Beverley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Navarro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">P</forename><surname>Pollastri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS Neglected Tropical Diseases</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page">e1297</biblScope>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Bringing transparency design into practice</title>
		<author>
			<persName><forename type="first">M</forename><surname>Eiband</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Schneider</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bilandzic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Fazekas-Con</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Haug</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Hussmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">23rd international conference on intelligent user interfaces</title>
				<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="211" to="223" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">What can AI do for me? evaluating machine learning interpretations in cooperative play</title>
		<author>
			<persName><forename type="first">S</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Boyd-Graber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th International Conference on Intelligent User Interfaces</title>
				<meeting>the 24th International Conference on Intelligent User Interfaces</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="229" to="239" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">What are people doing about xai user experience? a survey on ai explainability research and practice</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Ferreira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Monteiro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Human-Computer Interaction</title>
				<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="56" to="73" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Flask web development: developing web applications with python</title>
		<author>
			<persName><forename type="first">M</forename><surname>Grinberg</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
			<publisher>O&apos;Reilly Media, Inc</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Network medicine framework for identifying drug-repurposing opportunities for covid-19</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Gysi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Í</forename><surname>Valle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zitnik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ameli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Gan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Varol</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">D</forename><surname>Ghiassian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Patten</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Davey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Loscalzo</surname></persName>
		</author>
		<imprint>
			<publisher>Proceedings of the National Academy of Sciences</publisher>
			<biblScope unit="volume">118</biblScope>
			<biblScope unit="page">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Oncothreads: visualization of large-scale longitudinal cancer molecular data</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">A</forename><surname>Harbig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Nusrat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Mazor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Thomson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Bitter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Cerami</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Gehlenborg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">Supplement_1</biblScope>
			<biblScope unit="page" from="59" to="66" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Gamut: A design probe to understand how data scientists understand machine learning models</title>
		<author>
			<persName><forename type="first">F</forename><surname>Hohman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Head</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Caruana</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Deline</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Drucker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems</title>
				<meeting>the 2019 CHI Conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="1" to="13" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Human factors in model interpretability: Industry practices, challenges, and needs</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">R</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hullman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Bertini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the ACM on Human-Computer Interaction</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">CSCW1</biblScope>
			<biblScope unit="page" from="1" to="26" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<author>
			<persName><forename type="first">K</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Roohani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Leskovec</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">W</forename><surname>Coley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zitnik</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2102.09548</idno>
		<title level="m">Therapeutics data commons: machine learning datasets and tasks for therapeutics</title>
				<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">F</forename><surname>Inc</surname></persName>
		</author>
		<ptr target="https://github.com/facebook/react" />
		<imprint/>
	</monogr>
	<note>React.js</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Drug discovery with explainable artificial intelligence</title>
		<author>
			<persName><forename type="first">J</forename><surname>Jiménez-Luna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Grisoni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Schneider</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="573" to="584" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Bridging ai developers and end users: An end-user-centred explainable ai taxonomy and visual vocabularies</title>
		<author>
			<persName><forename type="first">W</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Carpendale</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hamarneh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Gromala</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Visualization</title>
				<meeting>the IEEE Visualization<address><addrLine>Vancouver, BC, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="20" to="25" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Gnnlens: A visual analytics approach for prediction error diagnosis of graph neural networks</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Ming</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Qu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2011.11048</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Association of anticholinergic use with incidence of alzheimer&apos;s disease: population-based cohort study</title>
		<author>
			<persName><forename type="first">K.-I</forename><surname>Joung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">H</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S.-I</forename><surname>Cho</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Scientific reports</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="10" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Interpreting interpretability: Understanding data scientists&apos; use of interpretability tools for machine learning</title>
		<author>
			<persName><forename type="first">H</forename><surname>Kaur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Nori</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Jenkins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Caruana</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wallach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">Wortman</forename><surname>Vaughan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems</title>
				<meeting>the 2020 CHI Conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="1" to="14" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">A visual analytics model applied to lead generation library design in drug discovery</title>
		<author>
			<persName><forename type="first">S</forename><surname>Konecni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Grinstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2009 13th International Conference Information Visualisation</title>
				<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="345" to="352" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Retainvis: Visual analytics with interpretable and interactive recurrent neural networks on electronic medical records</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">C</forename><surname>Kwon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M.-J</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">T</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">B</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kwon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Choo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="299" to="309" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">What do we want from explainable artificial intelligence (xai)?-a stakeholder perspective on xai and a conceptual model guiding interdisciplinary xai research</title>
		<author>
			<persName><forename type="first">M</forename><surname>Langer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Oster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Speith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Hermanns</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Kästner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Schmidt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sesing</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Baum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">296</biblScope>
			<biblScope unit="page">103473</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Entourage: Visualizing relationships between biological pathways using contextual subsets</title>
		<author>
			<persName><forename type="first">A</forename><surname>Lex</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Partl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Kalkofen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Streit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gratzl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Wassermann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Schmalstieg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Pfister</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2536" to="2545" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Questioning the AI: informing design practices for explainable ai user experiences</title>
		<author>
			<persName><forename type="first">Q</forename><forename type="middle">V</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Gruen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Miller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems</title>
				<meeting>the 2020 CHI Conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="1" to="15" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Ibuprofen suppresses plaque pathology and inflammation in a mouse model for alzheimer&apos;s disease</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">P</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Beech</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Teter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Ubeda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">H</forename><surname>Ashe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Frautschy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Neuroscience</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">15</biblScope>
			<biblScope unit="page" from="5709" to="5714" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Explainable machine-learning predictions for the prevention of hypoxaemia during surgery</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Lundberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Nair</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Vavilala</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Horibe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Eisses</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Adams</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">E</forename><surname>Liston</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">K</forename></persName>
		</author>
		<author>
			<persName><forename type="first">.-W</forename><surname>Low</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S.-F</forename><surname>Newman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature biomedical engineering</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="749" to="760" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">The nested blocks and guidelines model</title>
		<author>
			<persName><forename type="first">M</forename><surname>Meyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sedlmair</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">S</forename><surname>Quinan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Munzner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Visualization</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="234" to="249" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Explanation in artificial intelligence: Insights from the social sciences</title>
		<author>
			<persName><forename type="first">T</forename><surname>Miller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">267</biblScope>
			<biblScope unit="page" from="1" to="38" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Rulematrix: Visualizing and understanding classifiers with rules</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Ming</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Bertini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="342" to="352" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">A multidisciplinary survey and framework for design and evaluation of explainable ai systems</title>
		<author>
			<persName><forename type="first">S</forename><surname>Mohseni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Zarei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">D</forename><surname>Ragan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Interactive Intelligent Systems (TiiS)</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">3-4</biblScope>
			<biblScope unit="page" from="1" to="45" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">A nested model for visualization design and validation</title>
		<author>
			<persName><forename type="first">T</forename><surname>Munzner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="921" to="928" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<author>
			<persName><forename type="first">I</forename></persName>
		</author>
		<ptr target="https://neo4j.com" />
		<title level="m">Neo4j graph data platform</title>
				<imprint>
			<date type="published" when="2020-10-01">2020-10-01</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">New tricks for old drugs</title>
		<author>
			<persName><forename type="first">N</forename><surname>Nosengo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">534</biblScope>
			<biblScope unit="issue">7607</biblScope>
			<biblScope unit="page" from="314" to="317" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Anti-parkinsonian agents have anti-amyloidogenic activity for alzheimer&apos;s β -amyloid fibrils in vitro</title>
		<author>
			<persName><forename type="first">K</forename><surname>Ono</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Hasegawa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Naiki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Yamada</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurochemistry International</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="275" to="285" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Pathfinder: Visual analysis of paths in graphs</title>
		<author>
			<persName><forename type="first">C</forename><surname>Partl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gratzl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Streit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Wassermann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Pfister</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Schmalstieg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Lex</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Graphics Forum</title>
				<imprint>
			<publisher>Wiley Online Library</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="71" to="80" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">enroute: Dynamic path extraction from biological pathway maps for exploring heterogeneous experimental datasets</title>
		<author>
			<persName><forename type="first">C</forename><surname>Partl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Lex</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Streit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Kalkofen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Kashofer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Schmalstieg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">19</biblScope>
			<biblScope unit="page" from="1" to="16" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Contour: data-driven exploration of multi-relational datasets for drug discovery</title>
		<author>
			<persName><forename type="first">C</forename><surname>Partl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Lex</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Streit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Strobelt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A.-M</forename><surname>Wassermann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Pfister</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Schmalstieg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="1883" to="1892" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Pytorch: An imperative style, high-performance deep learning library</title>
		<author>
			<persName><forename type="first">A</forename><surname>Paszke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Massa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Lerer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Bradbury</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Chanan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Killeen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Gimelshein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Antiga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Desmaison</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kopf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>De-Vito</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Raison</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Tejani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Chilamkurthy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Steiner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Chintala</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
				<editor>
			<persName><forename type="first">H</forename><surname>Wallach</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Beygelzimer</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">F</forename><surname>Alché-Buc</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">E</forename><surname>Fox</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Garnett</surname></persName>
		</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="8024" to="8035" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Stop explaining black box machine learning models for high stakes decisions and use interpretable models instead</title>
		<author>
			<persName><forename type="first">C</forename><surname>Rudin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="206" to="215" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Identification of disease treatment mechanisms through the multiscale interactome</title>
		<author>
			<persName><forename type="first">C</forename><surname>Ruiz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zitnik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature Communications</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="15" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Effect of the treatment of type 2 diabetes mellitus on the development of cognitive impairment and dementia</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">A</forename><surname>Sastre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">W</forename><surname>Vernooij</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">G</forename></persName>
		</author>
		<author>
			<persName><forename type="first">.-C</forename><surname>Harmand</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Martínez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cochrane Database of Systematic Reviews</title>
		<imprint>
			<biblScope unit="issue">6</biblScope>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Scaffold hunter: a comprehensive visual analytics framework for drug discovery</title>
		<author>
			<persName><forename type="first">T</forename><surname>Schäfer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Kriege</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Humbeck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Koch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Mutzel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Cheminformatics</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="18" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Interpreting graph neural networks for nlp with differentiable edge masking</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Schlichtkrull</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">De</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Titov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
				<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<monogr>
		<title level="m" type="main">Higher-order explanations of graph neural networks via relevant walks</title>
		<author>
			<persName><forename type="first">T</forename><surname>Schnake</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Eberle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lederer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Nakajima</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">T</forename><surname>Schütt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K.-R</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Montavon</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2006.03589</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Design study methodology: Reflections from the trenches and the stacks</title>
		<author>
			<persName><forename type="first">M</forename><surname>Sedlmair</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Meyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Munzner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2431" to="2440" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Explainability for experts: A design framework for making algorithms supporting expert decisions more explainable</title>
		<author>
			<persName><forename type="first">A</forename><surname>Simkute</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Luger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Evans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Jones</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Responsible Technology</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">100017</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Explainability fact sheets: a framework for systematic assessment of explainable approaches</title>
		<author>
			<persName><forename type="first">K</forename><surname>Sokol</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Flach</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency</title>
				<meeting>the 2020 Conference on Fairness, Accountability, and Transparency</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="56" to="67" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">A literature-based knowledge graph embedding method for identifying drug repurposing opportunities in rare diseases</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">N</forename><surname>Sosa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Derry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Brinton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">B</forename><surname>Altman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">PACIFIC SYMPOSIUM ON BIOCOMPUTING 2020</title>
				<imprint>
			<publisher>World Scientific</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="463" to="474" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Effect of remdesivir vs standard care on clinical status at 11 days in patients with moderate COVID-19: a randomized clinical trial</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">D</forename><surname>Spinner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">L</forename><surname>Gottlieb</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">J</forename><surname>Criner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R A</forename><surname>López</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Cattelan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">S</forename><surname>Viladomiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Ogbuagu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Malhotra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">M</forename><surname>Mullane</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Castagna</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of American Medical Association</title>
		<imprint>
			<biblScope unit="volume">324</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1048" to="1057" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">D</forename></persName>
		</author>
		<ptr target="https://github.com/ant-design/ant-design/" />
	</analytic>
	<monogr>
		<title level="j">Team. Ant design</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">What clinicians want: contextualizing explainable machine learning for clinical end use</title>
		<author>
			<persName><forename type="first">S</forename><surname>Tonekaboni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Mccradden</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Goldenberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning for Healthcare Conference</title>
				<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="359" to="380" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Visualizing data using t-sne</title>
		<author>
			<persName><forename type="first">L</forename><surname>Van Der Maaten</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">11</biblScope>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">The value of visualization</title>
		<author>
			<persName><forename type="first">J</forename><surname>Van Wijk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">VIS 05. IEEE Visualization</title>
				<imprint>
			<date type="published" when="2005">2005. 2005</date>
			<biblScope unit="page" from="79" to="86" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Graph attention networks</title>
		<author>
			<persName><forename type="first">P</forename><surname>Veličković</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Cucurull</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Casanova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Romero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Liò</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
				<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<monogr>
		<author>
			<persName><forename type="first">G</forename><surname>Vilone</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Longo</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2006.00093</idno>
		<title level="m">Explainable artificial intelligence: a systematic review</title>
				<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Designing theory-driven user-centric explainable ai</title>
		<author>
			<persName><forename type="first">D</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Abdul</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">Y</forename><surname>Lim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 CHI conference on human factors in computing systems</title>
				<meeting>the 2019 CHI conference on human factors in computing systems</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="1" to="15" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<monogr>
		<title level="m" type="main">Improving the utility and usability of visualization in ai-driven scientific discovery</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Gehlenborg</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Threadstates: State-based visual analysis of disease progression</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Mazor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">A</forename><surname>Harbig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Cerami</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Gehlenborg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE VIS</title>
				<meeting>the IEEE VIS</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Atmseer: Increasing transparency and controllability in automated machine learning</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Ming</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Veeramachaneni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Qu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems</title>
				<meeting>the 2019 CHI Conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="1" to="12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Visual analysis of discrimination in machine learning</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Qu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1470" to="1480" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">Visual genealogy of deep neural networks</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="3340" to="3352" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">Heterogeneous graph attention network</title>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">S</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The World Wide Web Conference</title>
				<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="2022" to="2032" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<monogr>
		<title level="m" type="main">Are Explanations Helpful? A Comparative Study of the Effects of Explanations in AI-Assisted Decision-Making</title>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Yin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021">2021</date>
			<publisher>Association for Computing Machinery</publisher>
			<biblScope unit="page" from="318" to="328" />
			<pubPlace>New York, NY, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">A problem-oriented classification of visualization techniques</title>
		<author>
			<persName><forename type="first">S</forename><surname>Wehrend</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Lewis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the First IEEE Conference on Visualization: Visualization90</title>
				<meeting>the First IEEE Conference on Visualization: Visualization90</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="1990">1990</date>
			<biblScope unit="page" from="139" to="143" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">Drugbank 5.0: a major update to the drugbank database</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">S</forename><surname>Wishart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">D</forename><surname>Feunang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">J</forename><surname>Lo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Marcu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Grant</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Sajed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Sayeeda</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nucleic acids research</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="issue">D1</biblScope>
			<biblScope unit="page" from="D1074" to="D1082" />
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main">Diagnosing concept drift with visual analytics</title>
		<author>
			<persName><forename type="first">W</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Maciejewski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE Conference on Visual Analytics Science and Technology</title>
				<meeting>IEEE Conference on Visual Analytics Science and Technology</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="12" to="23" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<analytic>
		<title level="a" type="main">GNNExplainer: generating explanations for graph neural networks</title>
		<author>
			<persName><forename type="first">R</forename><surname>Ying</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Bourgeois</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>You</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zitnik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
				<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page">9240</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<monogr>
		<author>
			<persName><forename type="first">H</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ji</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2012.15445</idno>
		<title level="m">Explainability in graph neural networks: A taxonomic survey</title>
				<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b80">
	<monogr>
		<title level="m" type="main">On explainability of graph neural networks via subgraph explorations</title>
		<author>
			<persName><forename type="first">H</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ji</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2102.05152</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b81">
	<analytic>
		<title level="a" type="main">A survey of visual analytics techniques for machine learning</title>
		<author>
			<persName><forename type="first">J</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computational Visual Media</title>
				<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="1" to="34" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b82">
	<analytic>
		<title level="a" type="main">Graph transformer networks</title>
		<author>
			<persName><forename type="first">S</forename><surname>Yun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Jeong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">J</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
				<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="11983" to="11993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b83">
	<analytic>
		<title level="a" type="main">Repurpose open data to discover therapeutics for covid-19 using deep learning</title>
		<author>
			<persName><forename type="first">X</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Karypis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Cheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of proteome research</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="4624" to="4636" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b84">
	<analytic>
		<title level="a" type="main">Link prediction based on graph neural networks</title>
		<author>
			<persName><forename type="first">M</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
				<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="5165" to="5175" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b85">
	<analytic>
		<title level="a" type="main">Deepred-rule extraction from deep neural networks</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Zilke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">Loza</forename><surname>Mencía</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Janssen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International conference on discovery science</title>
				<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="457" to="473" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b86">
	<analytic>
		<title level="a" type="main">Sibyl: Understanding and addressing the usability challenges of machine learning in high-stakes decision making</title>
		<author>
			<persName><forename type="first">A</forename><surname>Zytek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Vaithianathan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Veeramachaneni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
