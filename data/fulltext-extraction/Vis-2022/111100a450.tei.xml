<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Effects of View Layout on Situated Analytics for Multiple-View Representations in Immersive Visualization</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Zhen</forename><surname>Wen</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Wei</forename><surname>Zeng</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Luoxuan</forename><surname>Weng</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Yihan</forename><surname>Liu</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Mingliang</forename><surname>Xu</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Wei</forename><surname>Chen</surname></persName>
						</author>
						<title level="a" type="main">Effects of View Layout on Situated Analytics for Multiple-View Representations in Immersive Visualization</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.2" ident="GROBID" when="2023-03-27T09:13+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Situated analytics</term>
					<term>multiple-view representations</term>
					<term>view layout</term>
					<term>immersive visualization</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"> Multiple-view (MV)  <p>representations enabling multi-perspective exploration of large and complex data are often employed on 2D displays. The technique also shows great potential in addressing complex analytic tasks in immersive visualization. However, although useful, the design space of MV representations in immersive visualization lacks in deep exploration. In this paper, we propose a new perspective to this line of research, by examining the effects of view layout for MV representations on situated analytics. Specifically, we disentangle situated analytics in perspectives of situatedness regarding spatial relationship between visual representations and physical referents, and analytics regarding cross-view data analysis including filtering, refocusing, and connecting tasks. Through an in-depth analysis of existing layout paradigms, we summarize design trade-offs for achieving high situatedness and effective analytics simultaneously. We then distill a list of design requirements for a desired layout that balances situatedness and analytics, and develop a prototype system with an automatic layout adaptation method to fulfill the requirements. The method mainly includes a cylindrical paradigm for egocentric reference frame, and a force-directed method for proper view-view, view-user, and view-referent proximities and high view visibility. We conducted a formal user study that compares layouts by our method with linked and embedded layouts. Quantitative results show that participants finished filtering-and connecting-centered tasks significantly faster with our layouts, and user feedback confirms high usability of the prototype system.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>There are many opportunities for data visualization beyond the traditional desktop <ref type="bibr" target="#b43">[44]</ref>. Among the future directions, situated analytics makes use of engaging, embodied analysis tools to support data understanding and decision making <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b19">20]</ref>. Recent advancement of interaction and immersive display technologies for augmented reality (AR) has increased the popularity of situated analytics in a variety of applications, such as sports <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b32">33]</ref>, digital twins <ref type="bibr" target="#b37">[38,</ref><ref type="bibr" target="#b56">57]</ref>, and fieldwork <ref type="bibr" target="#b52">[53]</ref>. Studies show that augmenting the scene with immersive visualization can bring in many benefits, such as situated analytics, embodied data exploration and increased engagement.</p><p>Due to the utilization of three dimensions (3D), immersive visualization by nature faces challenges of 3D visualization such as occlusions and perspective distortions. Multiple-view (MV) paradigm is commonly adopted to manage occlusion in 3D visualization <ref type="bibr" target="#b17">[18]</ref>. MV representations are also frequently employed to visualize large and complex abstract data, due to its advantage in supporting multi-perspective exploration <ref type="bibr" target="#b7">[8]</ref>. Users can see and interact with information in one view, and observe similar features in another <ref type="bibr" target="#b41">[42]</ref>. MV representations have been demonstrated effective for data exploration in immersive visualization <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b42">43]</ref>. Figure <ref type="figure" target="#fig_0">1</ref> presents two usage scenarios in demand of MV representations for abstract data in an AR environment.</p><p>• Scenario 1 − Sport: In a car racing competition, each car produces a real-time recording of speed changes during the competition. Visualizing the records as time-series graphs and positioning them beside  the cars would improve interpretation.</p><p>• Scenario 2 − Board game: In a board game, each character has multi-variate attributes of the character characteristics. Visualizing the attributes as bar charts and positioning them besides the characters would facilitate comparison.</p><p>Nevertheless, there are challenges for using MV representations in immersive visualization. In 3D space, view occlusion happens, and representations positioned in different depth appear in different view sizes. The challenges hinder cross-view data analysis, such as to compare values in different views. Traditional 2D desktop interfaces leverage visual linkage (e.g., <ref type="bibr" target="#b15">[16]</ref>) and coordinated interactions (e.g., <ref type="bibr" target="#b6">[7]</ref>) to mitigate the issues. However, directly adapting these techniques to immersive visualization may bring in other issues. For instance, visual linkage rendered in immersive displays with relatively small field-of-view (FOV) can easily cause visual clutter.</p><p>This work tackles the challenges from another perspective. We focus on view layout that concerns the positioning of MV representations in 3D immersive space. Existing approaches mainly employ embedded or linked layouts for view positioning in immersive visualization. Both layouts have certain advantages and limitations: embedded layout promotes the linkage between views and referents but hinders analytical tasks like comparison, whilst linked layout is preferable for analytics but difficult to relate views and physical referents (Sect. 3.1). To understand the underlying mechanism, we first summarize design considerations for high levels of spatial situatedness and cross-view data analysis (Sect. 3.2). We then perform an in-depth analysis on design trade-offs between situatedness and analytics, using the ethereal planes framework that specifies design space dimensions for the arrangement of 2D interfaces in 3D space <ref type="bibr" target="#b21">[22]</ref>. We distill a list of requirements in aspects of perspective, movability, proximity, and visibility dimen-sions for the desired layout that promotes situatedness and analytics simultaneously (Sect. <ref type="bibr">3.3)</ref>.</p><p>On this basis, we develop a prototype system with an automatic layout adaptation approach to position MV representations in an 3D immersive environment. The method leverages a cylindrical paradigm for egocentric reference frame (Sect. 4.2), and a force-directed method to optimize view-view, view-referent, and view-user proximities and maximize view visibility (Sect. 4.3). To validate the effectiveness of our approach, we conducted a formal user study that compare layout by our method with embedded and linked layouts (Sect. 5). Experimental results show that participants accomplished filteringand connectingcentered tasks significantly faster with our layout, and the advantage is more significant in complex scenes (Sect. 5.6). User feedback also validates the prototype system in terms of usability, utility, workload, confidence, and satisfaction (Sect. 5.7).</p><p>In summary, the main contributions of this work include:</p><p>• We distill a list of design requirements for effective view layout that promotes situatedness and analytics simultaneously.</p><p>• We leverage cylindrical reference frame and propose a forcedirected approach to automatically position MV representations in immersive visualization.</p><p>• We conduct a formal user study that confirms the effectiveness of our proposed method in balancing situatedness and analytics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK 2.1 Multiple-View Representation</head><p>MV representations enable users to explore one dataset from different perspectives <ref type="bibr" target="#b40">[41]</ref>, or different datasets from the same perspective <ref type="bibr" target="#b50">[51]</ref>. Design space for MV representations includes visual encoding, layout, and interaction design. An effective MV representation system has a well-designed layout that involves considerations on view coordination, view type, and viewport <ref type="bibr" target="#b45">[46]</ref>. Empirical studies also revealed common view layout patterns <ref type="bibr" target="#b7">[8]</ref> in MV representations. Visualizations on desktop/tablets can be combined with those on AR headsets in a connected multi-view manner, to help users explore and understand 3D data, e.g., <ref type="bibr" target="#b26">[27,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b51">52]</ref>. Designers need to consider the display ecology that engages the entire workflow of a task to better assist analysts in achieving their desired outcomes <ref type="bibr" target="#b14">[15]</ref>. There are also opportunities and challenges for using MVs in immersive visualization <ref type="bibr" target="#b42">[43]</ref>. FiberClay presents massive airplane trajectories in one primary view, complemented with multiple views on the ground for overview in immersive environments <ref type="bibr" target="#b27">[28]</ref>. The trajectories are rendered three dimensional, to better reveal structural insights. As a close work, Liu et al. <ref type="bibr" target="#b35">[36]</ref> designed a shelf metaphor to flexibly layout multiple abstract data visualizations (e.g., 3D bar charts) in an immersive space. User study found that semi-circular layout that wraps views around the user in half circle is more preferable. Nevertheless, the study neglects situatedness that is an important consideration for situated analytics. We show that the design space for MV representations in AR environments becomes more complicated for situated analytics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Situated Analytics</head><p>Situated analytics refers to the ability of combining visual analytics and AR techniques for in-situ projection of information onto the physical space, to support the purpose of understanding, sensemaking, and decision making <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b19">20]</ref>. A main design consideration is to improve situatedness that measures 'the degree the information and person are connected to the task, location, and/or another person' <ref type="bibr" target="#b49">[50]</ref>, which is a grand challenge for immersive analytics <ref type="bibr" target="#b20">[21]</ref>. Many efforts have been devoted to improving spatial situatedness that links data visualizations with the real-world entities and spaces to which data corresponds <ref type="bibr" target="#b53">[54]</ref>. For example, MARVisT <ref type="bibr" target="#b8">[9]</ref> leverages information from reality to assist non-experts to create expressive AR glyph-based visualizations. Other than space, situatedness can also be improved from perspectives of time, place, activity and community <ref type="bibr" target="#b4">[5]</ref>. Nevertheless, spatial situatedness that concerns proximity between the visualization and objects or features of the environment is still the primary research focus.</p><p>However, existing studies on spatial situatedness are mostly focusing on linking one single representation with the physical world, which may not be enough for complex data and tasks. Many scenarios promote the integration of MV representations for abstract data in the physical world <ref type="bibr" target="#b42">[43]</ref>. Nevertheless, presenting abstract data in immersive environments for effective and efficient data understanding is challenging <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b29">30]</ref>. Specifically, MV representations are often used to support cross-view data analysis like comparison, e.g., to compare speeds of racing cars (Figure <ref type="figure" target="#fig_0">1</ref>(left)) or to compare characteristics of game characters (Figure <ref type="figure" target="#fig_0">1</ref>(right)). Juxtapositioned layout that keeps MV representations close to each other, is often adopted to facilitate comparison <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b36">37]</ref>. However, the layout can be in conflict with spatial situatedness that requires the placement of abstract data representations close to the physical referents.</p><p>Design trade-offs between situatedness and analytics are to be considered. Specifically, we formulate the design requirements for effective layout of MV representations in immersive visualization, and design an automatic layout approach to generate layouts that are more preferable than conventional embedded and linked ones.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Interface Design in 3D Space</head><p>Due to the nature of the third dimension, situated analytics faces common challenges of 3D visualization. Recommendations for 3D visualization design, like the management of occlusion and perspective distortion <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b48">49]</ref>, can facilitate immersive visualization design. This work regards view layout in immersive visualization as a view management problem in 3D space, which is a primary research topic for interface design in mixed reality. In general, 2D view contents shall be arranged in space to fit the environment <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b55">56]</ref>. The HCI community also suggests that the arrangement can be adapted according to the semantic context <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b34">35]</ref> and user behaviors <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b30">31]</ref>. View management for multiple objects in 3D space further needs to consider spatial and visibility relationships <ref type="bibr" target="#b3">[4]</ref>. Layout of MV representations shall accord with these considerations.</p><p>To a certain extent, MVs can be simplified as external labels for physical referents, and a large body of literature has been conducted in the direction <ref type="bibr" target="#b2">[3]</ref>. Specifically in augmented reality, various external labeling techniques have been proposed, such as identifying important regions in image space for label placement <ref type="bibr" target="#b25">[26]</ref>, using 3D geometric constraints to keep layout consistency across different viewports <ref type="bibr" target="#b47">[48]</ref>, and adopting a partially-sorted concentric layout to improve search efficiency <ref type="bibr" target="#b57">[58]</ref>. Nevertheless, MV layout design is more comprehensive than external labeling. In addition to linking views to corresponding physical referents (i.e., situatedness), users also need to conduct cross-view data analysis (i.e., analytics). In-depth analyses reveal that common layout options, including embedded and linked methods, fail to support situatedness and analytics simultaneously.</p><p>To address the challenge, we leverage the ethereal planes framework <ref type="bibr" target="#b21">[22]</ref> and formulate the design considerations as to optimize view-object, view-view, and view-user proximities. We develop an automatic approach with force-directed method to automatically derive the layout that meet the considerations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">DESIGN CONSIDERATION AND TRADE-OFF</head><p>In this section, we first list down common terminologies and introduce layout options (Sect. 3.1). Next, we distill design considerations from aspects of situatedness and analytics (Sect. 3.2), followed by a discussion of design trade-offs in the end (Sect. 3.3).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Terminology and Layout</head><p>As illustrated in Figure <ref type="figure" target="#fig_1">2</ref>, this work considers the following properties:</p><p>• View: Visual structure is the mapping from data to visual representation, and a view is the physical display space where a visual structure is rendered <ref type="bibr" target="#b5">[6]</ref>. In this work, we consider multiple views rendered in an AR environment, where each view has a clear boundary that helps isolate views from each other and from the physical world.</p><p>• Referent: An AR environment comprises of the surrounding entities and physical referents that provide data to be rendered in views. Physical referents are of interest in this work, whilst the surrounding entities provide only the context. Both physical referents and the surrounding entities are fixed and not movable.</p><p>• User: User is an analyst who would like to complete certain tasks (see Sect. 3.2.2) based on MV representations in an AR environment.</p><p>The user can freely navigate in the AR environment, and interact with and manipulate views with basic interactions like highlighting, filtering, and view arrangement.</p><p>Layout design for MV representations concerns the placement of views in the 3D space, to facilitate situated analytics. Chen et al. <ref type="bibr" target="#b9">[10]</ref> summarized three categories of layout design, as follows:</p><p>• Embedded layout. Embedded data representation deeply integrates visual and physical representations of data with the physical spaces, objects, and entities to which the data refers <ref type="bibr" target="#b53">[54]</ref>. Figure <ref type="figure" target="#fig_2">3</ref>(left) shows an exemplar embedded layout, where each view is placed on top of its physical referent. Here, proximity between a view and its physical referent is minimized. As such, embedded layout provides high situatedness−users easily get aware of which physical referent a view refers to. On the other hand, since the view positions are fixed, embedded layout can easily cause problems such as occlusion (like the red view on top of Cat) and different sizes, which are not suitable for cross-view data analysis.</p><p>• Linked layout. Views are separated from physical referents, which can then be organized in parallel or as small multiples as in 2D desktop displays. Figure <ref type="figure" target="#fig_2">3</ref>(right) shows an exemplar linked layout.</p><p>Here, the views are placed side-by-side and assigned the same size. Full visibility for the views is ensured as the views are placed close to the user. However, the user needs to mentally relate a view to its physical referent, which is not straightforward. As in Figure <ref type="figure" target="#fig_2">3</ref>(right), the user may feel puzzled whether the second view links to Cat or Hyena: Cat is the second one from left to right, whilst Hyena is the second one from front to back. Visual linkages connecting a view and its referent can mitigate the issue. However, additional visual elements can easily cause visual clutter when there are many views, which is beyond the consideration of this work. As such, linked layout harms the level of situatedness.</p><p>• Mixed layout. Mixed layout places visual representations and physical referents in a visually continuous manner. With delicate design, mixed layout can achieve proper proximities from a view to its physical referent, to other views, and to the user, to balance situatedness and analytics. Nevertheless, designing proper mixed layout is a nontrivial task, which requires mindful considerations of views and the context in a three dimensional space.</p><p>Embedded and linked layouts are simple to implement and have been commonly adopted in situated analytics, yet both layouts have certain limitations. In comparison, mixed layout is lack of exploration.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Design Considerations</head><p>Based on literature reviews and our own experience, we elicit design considerations from aspects of situatedness and analytics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1">Situatedness</head><p>Situated visualization provides in-situ projection of information on to the physical space <ref type="bibr" target="#b18">[19]</ref>. Bressa et al. <ref type="bibr" target="#b4">[5]</ref> expanded the concept of situatedness and characterized five perspectives: space, time, place, activity, and community. This work focuses on layout design of MV representations, which mainly involves the considerations of space perspective that concerns spatial arrangement and spatial relationship between physical world and visual representation. More specifically, this work lies spatial situatedness on spatial proximity between a visual representation and its physical referent <ref type="bibr" target="#b53">[54]</ref>, rather than people's activity, context of use, or semantic relationship.</p><p>We categorize the level of situatedness as high and low, based on spatial proximity between a view and its physical referent:</p><p>• High situatedness: In this case, a view is placed close to its physical referent, such as to put the view aside the referent or overlay on the referent, as in embedded layout (Figure <ref type="figure" target="#fig_2">3</ref>(left)). Here, proximity between a view and its physical referent is minimized, whilst proximity among the view and the user can be distant. Since physical referents are fixed, high situatedness may also cause problems such as occlusion and perspective distortion.</p><p>• Low situatedness: In this case, a view is not aligned with its physical referent. In an extreme case, the views are separated from the physical referents, but organized in parallel or small multiples, as in linked layout (Figure <ref type="figure" target="#fig_2">3</ref>(right)). Here, proximity between a view and its physical referent is not guaranteed, requiring the user to mentally relate a view to its physical referent.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2">Analytics</head><p>The quality of processing the data and information is regarded as analytic level. The visualization community has identified several highlevel analytics for MV representations. For examples, juxtapositioned views are commonly used for comparison <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b36">37]</ref>. Sun et al. <ref type="bibr" target="#b46">[47]</ref> recently identified three types of users operations for cross-view data analysis, i.e., filtering-, refocusing-, and connecting-centered operations. View layout of MV representations also makes a substantial influence on analytics level in immersive visualization. We summarize design considerations for cross-view data analysis <ref type="bibr" target="#b46">[47]</ref>:</p><p>• Filtering. To select and mark data elements of interest is typically a preceding action to subsequent actions. Since the views can be positioned at any location in the 3D space, selection can be challenging for far-away views. Ray-tracing pointer can be ineffective due to small visual marks in the distance. Alternatively, users can select data elements on a near view, and the corresponding data elements in far-away views will also be filtered.</p><p>• Refocusing. Multiple views enable multi-perspective exploration of a dataset to support complex analytical requirements. Nevertheless, the visualization shall also enable easy focus on some view, allowing users to conduct in-depth examination for the data of a specific physical referent. Two basic requirements here are to enable views of interest presented 1) in full detail and 2) without occlusion.</p><p>• Connecting. To explore and identify connections between data in multiple views is a fundamental requirement. Connecting can be facilitated by consistent visual encodings <ref type="bibr" target="#b38">[39]</ref> or explicit visual linkage <ref type="bibr" target="#b15">[16]</ref>. In this work, we focus on designing proper view layout that requires minimum body and head movements to support effective identification of connections between data in multiple views. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Design Trade-offs</head><p>Situatedness and analytics are two perspectives of consideration when designing MV representations in immersive visualization. Figure <ref type="figure" target="#fig_2">3</ref> illustrates two layouts commonly adopted in existing situated analytics: embedded layout produces high level of spatial situatedness, but low analytics level; in contrast, linked layout is preferable for analytics, but requires substantial efforts for the user to mentally relate views to their physical referents. In the following, we leverage the ethereal planes framework <ref type="bibr" target="#b21">[22]</ref> that specifies the ways of arranging 2D information spaces in 3D environments, to discuss the trade-offs between situatedness and analytics.</p><p>• Perspective: Perspective denotes the conceptual viewpoint of the observer, which can be generally categorized as egocentric and exocentric reference frames <ref type="bibr" target="#b1">[2]</ref>. Egocentric reference frame is set relative to the user reference point, whilst exocentric referent frames are set relative to any object (e.g., the physical referents) reference points. As indicated in Table <ref type="table" target="#tab_1">1</ref>, linked layout is egocentric reference frame, as the layout separates the views from the physical referents. In contrast, embedded layout is exocentric reference frame, as the views are placed close to physical referents.</p><p>This work considers AR scenarios where a single user can freely navigate. Hence, egocentric reference frame that moves along with the user on-the-go is more useful <ref type="bibr" target="#b21">[22]</ref>.</p><p>• Movability: Movability denotes whether the views are movable or fixed with respect to the real-world reference frame. Linked layout allows movable placement of the views in the 3D space. Users can arrange the views in parallel or small multiples close to the user, which is preferable for tasks like filtering and connecting. In contrast, embedded layout arranges the views next to their physical referents that are fixed in the real-world reference frame.</p><p>In this work, views shall be movable such that far-away views can be moved close to the user to facilitate analytics. Nevertheless, the movability shall be constrained to a certain degree, so the spatial situatedness can also be recalled.</p><p>• Proximity: Proximity is a spatial property that indicates how close two entities are. Here we consider spatial proximities between viewuser, view-view, and view-referent. In linked layout, views are moved to near by each other and to the user, hence view-view and view-user proximities are small. Views close to users are more viewable and manipulable during the analytic process, yet the views are moved away from the referents that increase view-referent proximity. In embedded layout, views are placed adjacent to their referents, hence view-referent proximity is small and spatial situatedness level is high. On the other hand, view-view and view-user proximities are dependent on the proximities among the referents and the user, which can be difficult for analytics.</p><p>In summary, a preferred layout shall provide proper view-view proximity to facilitate analytics, proper view-user proximity to promote spatial manipulation <ref type="bibr" target="#b21">[22]</ref>, and proper view-referent proximity to improve spatial situatedness <ref type="bibr" target="#b18">[19]</ref>. Immersive analytics projects in-situ information onto the physical space <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b19">20]</ref>. As such, high visibility of the information space, i.e., views, are necessary for effective analytics.</p><p>From the above analysis, the layout shall meet the following requirements: egocentric reference frame, movable views, proper view-view, view-user, and view-referent proximities, and high visibility.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">LAYOUT ADAPTATION</head><p>In this section, we first present a formal problem definition (Sect. 4.1), followed by a description of cylindrical reference frame that is naturally egocentric (Sect. 4.2). Next, we develop a prototype system using a force-directed method to produce the optimal layout (Sect. 4.3), which is complemented with a series of user interactions to facilitate data exploration and layout configuration (Sect. 4.4).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Problem Formulation</head><p>Many efforts have been devoted to optimizing view layout in 3D visualization for the desktop, to mitigate issues like occlusion and perspective distortion <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b48">49]</ref>. This work further considers the effects of view layout on situatedness (Sect. 3.2.1) and analytics (Sect. 3.2.2). Specifically, this work studies the layout of multiple views, denoted as V := {v i } N i=1 , where N ≥ 2 is the total number of views. Each view V i is represented as a tuple v i := (data vi , struct vi , pos vi , ori vi , size vi ), where data vi denotes the underlying data associated with a physical referent r i , struct vi denotes the visual structure, pos vi denotes the center position of the view in the 3D space, and ori vi and size vi denote the orientation and size of the view respectively. For every physical referent r i , its position pos ri is fixed and the associated data vi is static. The visual structure struct vi is designed to accord with data vi , with a specific visualization type (e.g., bar chart, line chart, etc.) that is not alterable during the exploration process. Users can manipulate visual elements through interactions like selecting and highlighting a bar. The size size vi is set up when the immersive visualization is initialized, and orientation ori vi is automatically adjusted in the way that the view plane is perpendicular to user's line of sight when looking at the view. There is one user (denoted as u) whose position (pos u ) is known.</p><p>As such, this work focuses on the optimization of {pos vi } N i=1 for a set of multiple views {v i } N i=1 in a 3D space, to balance situatedness and analytics in situated analytics. View positions have direct effects on view-view, view-user, and view-referent proximities and visibility, and consequently on situatedness and analytics levels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Cylindrical Reference Frame</head><p>As illustrated in Figure <ref type="figure" target="#fig_3">4</ref>(a), we adopt a cylindrical paradigm that has been widely adopted in immersive visualization, to represent positions in the 3D space. Specifically, we put the user at the center, and model all other positions in the 3D space as positions on cylindrical surfaces around the center. In this way, position of an object is represented as pos := (ψ, θ , z), where ψ denotes the radius of the cylindrical surface to the user, θ denotes the angle of the line connecting the object and the user to the North, and z denotes the vertical position. For simplicity, we keep a 2D plane that is tangent to the cylindrical surface, to render visual structures, rather than bend visual structures to fit the cylindrical layout. This is because a view is relatively small, and it would be rather complicated to adapt internal structures when views are repositioned at different distances to the users.</p><p>The distance between positions of two objects on the cylindrical surfaces is then computed as the polar coordinates distance, denoted as dist(pos i , pos j ). For embedded layout that arranges a view on top of the physical referent, the distance between the view and the referent is only the vertical displacement, which is very small. On the other hand, views will be allocated at a distance if their referents are not nearby, such as view 1 and view 2 in Figure <ref type="figure" target="#fig_3">4</ref>(a), which will require substantial head movement to connect them. We regard views, referents, and the user as mass points, and proximities among them as springs. For each view V i , there are multiple attraction forces applied on it:</p><formula xml:id="formula_0">• View-referent force − → F (v i , r i ) is computed as | − → F (v i , r i )| = K × dist(</formula><p>pos vi , pos ri ) and pointing to the referent pos ri ;</p><p>• View-view force</p><formula xml:id="formula_1">− → F (v i , v j ): For each v j, j =i ∈ V , F(v i , v j ) is computed as | − → F (v i , v j )| = K × dist(pos vi , pos v j</formula><p>) and pointing to view pos v j ;</p><p>• View-user force</p><formula xml:id="formula_2">− → F (v i , u) is computed as | − → F (v i , u)| = K × dist(</formula><p>pos vi , pos u ) and pointing to the user pos u .</p><p>We treat proportional ratios of all forces as the same constant K. With effects of spring forces, the views will reach mechanical equilibrium states that balance the proximities.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Force Directed Method</head><p>On the basis of proximity modeling, we design a twofold process to automatically adapt view layout using a force-directed method. First, we reallocate all views to a common cylindrical surface (Sect. 4.3.1). Second, we adjust view positions leveraging the common cylindrical surface to remove occlusion (Sect. 4.3.2).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.1">Surface reallocation</head><p>In the first step, we choose to place all views on a common cylindrical surface, such that 1) views can be arranged in side-by-side or smallmultiples as in 2D displays, to promote analytics levels in refocusing and connecting; and 2) the problem is simplified to identify a cylindrical surface with suitable distance ψ all to the user. All views have the same radius ψ all . We leave the placement of views on the common cylindrical surface in the next step. Since view-view forces for a pair of views are neutralized, we only need to balance view-referent forces</p><formula xml:id="formula_3">∑ N i=1 − → F (v i , r i ) and view-user forces ∑ N i=1 − → F (v i , u) when determining the common cylindrical position, as ω vr N ∑ i=1 − → F (v i , r i ) + ω vu N ∑ i=1 − → F (v i , u) = 0. (<label>1</label></formula><formula xml:id="formula_4">)</formula><p>where ω vr and ω vu denote the weights for view-referent forces and view-user forces, respectively. A larger weight ω vu for view-user force will attract the cylindrical surface more towards the user, and vice versa.</p><p>Here, the resting lengths of</p><formula xml:id="formula_5">− → F (v i , r i ) and − → F (v i , u</formula><p>) are all set as zero. Since view position on the surface is unknown, the measurement of view-referent proximity dist(pos vi , pos ri ) is simplified to |ψ all − ψ ri |, and that of view-user proximity dist(pos vi , pos u ) is simplified to ψ all . The direction of</p><formula xml:id="formula_6">− → F (v i , u) is centripetal that is represented as positive. The direction of − → F (v i , r i</formula><p>) is dependent on ψ all : if ψ all &lt; ψ ri , the force is centrifugal that is represented as negative, otherwise positive. Hence, Equation 1 is to compute</p><formula xml:id="formula_7">ω vr N ∑ i=1 K(ψ all − ψ ri ) + ω vu N ∑ i=1 Kψ all = 0, N ∑ i=1 ((ω vr + ω vu )ψ all − ω vr ψ ri ) = 0. (<label>2</label></formula><formula xml:id="formula_8">)</formula><p>In a special case when ω vr = ω vu , ψ all = ∑ N i=1 (ψ ri /2N) = ψ ri /2, i.e., the common cylindrical surface will be placed at half of the mean distance of all referent surfaces. This work adopts an adaptable ratio for ω vr : ω vu , which can be adjusted by the user via view arrangement interaction described below. However, if there are a large number of views, a low ratio for ω vr : ω vu leads to views being placed near to the user, which makes sight crowded. Therefore, the recommended ratio is relative to the number of views. In our experiment (Sect. 5), we set the ratio in complex scene much higher than simple scene.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.2">View translation</head><p>Next, we leverage a temporary common cylindrical surface with a constant radius to translate view positions to remove occlusion and balance view-view and view-referent proximities. Here, angle θ and vertical position z of view positions are free to change, whilst radius is fixed. To remove occlusion for views, we introduce occlusion force, denoted as − → F occ , that pushes a view away from occluded referents or other views on its positioned cylindrical surface. Specifically, − → F occ is derived from the view-referent force − → F (v i , r i ) with the resting length set to the sum of view height and referent height, and the view-view force − → F (v i , v j ) with the resting length set to twice the view length. All occlusion forces are calculated on the common cylindrical surface, but applied on views at their located positions. The direction of − → F occ is either up/down if the occlusion happens in vertical dimension, or left/right if the occlusion happens in horizontal dimension. The value of − → F occ is inversely proportional to the proximity between the occluded objects. Note that the force is applied only to views but not referents, i.e., referents can be occluded. As illustrated in Figure <ref type="figure" target="#fig_3">4</ref>(c), the blue view is partially occluded by its referent when the view is translated to the target cylindrical surface. The occlusion force is in up direction, pushing the view upwards. The force becomes weak as the view moves away from its referent and eventually balances with the down-directed view-referent force that attracts the view in down direction. In this way, we identify the vertical position for each view.</p><p>Moreover, view-view and view-referent proximities are balanced using view-view and view-referent forces. Here we first align all views side-by-side with the same vertical position, which is set to the maximum vertical position of all views. Next, we consider viewview and view-referent forces in horizontal directions only, which are proportional to the horizontal view-view and view-referent proximities respectively. Ideally all views will reach the equilibrium states after the above steps. However, views can be occluding each other if there are too many of them. In this case, we arrange views in multiple layers vertically, similar to the shelves metaphor, for layout of the views <ref type="bibr" target="#b35">[36]</ref>.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">User Interaction</head><p>Our prototype system is tested on a HoloLens2 AR glass. Users can freely navigate the AR environment. We also incorporate three types of user interactions in the prototype system: highlighting (Figure <ref type="figure" target="#fig_5">6</ref> Users can select a data item in a view, e.g., by clicking on a bar in a bar chart, and the selected item will be highlighted with a different color. Alternatively, users can also filter data items by specifying a data attribute in a certain range. Both operations are coordinated, i.e., data items of the same attribute or within the same range in the other views will also be highlighted/filtered. With highlighting operation, users can get cross-view insights more easily, e.g., to identify the extreme value of an attribute. The filtering operation helps users search data attributes quickly, e.g., to find the Pokémon with speed attribute over 80.</p><p>View arrangement interaction is designed for fine-tuning view layout generated by the automatic approach. Users are allowed to reposition a specific view or multiple views. To rearrange view position, users need to first select one or multiple views, by finger clicking on nearby views or ray casting on far views. The selected view positions will be updated according to the figure/pointer movement. Here, the views are only allowed to move on their positioned cylindrical surfaces, i.e., only angle θ and vertical position z are changing. Alternatively, users can pull the surface closer or push it farther with two-hand gestural interaction. Moreover, the selected views are seen as views of interests, and we adjust the recommended ratio for ω vr : ω vu of views according to user interests. In general, the view of interests will be attracted closer to the user. To ease the burden of interactions on users, we provide an automatic view alignment function for view arrangement. All selected views will be restricted on a common cylindrical surface and placed side-by-side. However, we are not sure if the automatic alignment have significant effects on the efficiency of layout. We employ it as an optional function in our prototype system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">USER STUDY</head><p>We conducted a user study to evaluate the effectiveness of our proposed layout adaptation framework. In particular, we compare the layout by our approach with alternative layouts in terms of analytics and situatedness levels on different analytic tasks involving MV representations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Experiment Design</head><p>The experiment was set in the background of the popular AR game Pokémon GO. We employed virtual entities to simulate AR environment, which is a common way to create a controlled environment for user studies in AR research <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b39">40]</ref>. From the Pokémon dataset, we selected six Pokémons, and each Pokémon had six quantitative stats in attack, defense, speed, etc. In each experiment trial, we randomly picked several Pokémons and rendered their 3D models on the ground in the AR environment. A stadium was placed at the center of the Pokémon positions as the arena for Pokémon fighting. Participants were asked to compare and identify highest stats among the Pokémons in the training ground. The Pokémon and stadium models were treated as physical referents that provided context information, and the Pokémon stats were represented as views. Specifically, the view related to the stadium presented the overall stats for all the Pokémons on the ground. Each participant played the role of user who was asked to complete tasks comprising of analytics and situatedness components.</p><p>For each study, we designed a within-subjects experiment: 3 layout configurations × 3 scene conditions × 3 tasks. As illustrated in . The cylindrical surface balances the distances of all referents to the user, as highlighted by the red circle on the ground. As such, the layout balances view-user, view-referent, and view-view proximities. We tested the robustness of our proposed method in supporting different levels of scene complexity determined by the number of referents. Since the field of view for AR HMDs is rather limited, we constrain the scene to include maximum six referents. Specifically, view occlusion happens in complex scene, hindering participants from finding answers. We further check if the automatic view alignment can facilitate the completion of tasks in complex scene. As such, we experimented with three scene conditions: S1. Simple scene. There are three pairs of physical referents and views in the scene. The referents are spread in the scene and no view occlusion happens. S2. Complex scene. There are six pairs of physical referents and views in the scene. View occlusion happens, and the participant can interact with the scene:</p><p>S2.1. without view alignment. Participant can only navigate in the scene to find answers, but not rearrange views. S2.2. with view alignment. Participants can manually adjust view positions and also navigate in the scene.</p><p>Our goal is to achieve a layout that balances situatedness and analytics. As such, we set three sets of user tasks: filtering + situatedness, refocusing + situatedness, and connecting + situatedness. Each task comprises an analytics sub-task that requires the participant to examine multiple views, and a situatedness sub-task that requires the participant to relate views to referents. T1. Filtering + Situatedness. The tasks are set as:</p><p>Analytics: Which view has attribute A in the range of x to y? Situatedness: Which Pokémon does the view relate to?</p><p>Participants need to use filtering interaction to identify answer for the analytics sub-task. After that, participants need to relate the view to a Pokémon on the ground for the situatedness sub-task. T2. Refocusing + Situatedness. The tasks are set as:</p><p>Analytics: Which view has the highest value for attribute A? Situatedness: Which Pokémon does the view relate to?</p><p>Highlighting interaction can be utilized to identify answer for the analytics sub-task. Participants only need to highlight attribute A in one view, the attributes in other views will also be highlighted. Similar to T1, participants are then asked to relate the view to a Pokémon on the ground for the situatedness sub-task. T3. Connecting + Situatedness. We found it difficult to separate subtasks for connecting-oriented analytics and situatedness. Therefore, we set an overall task here: Overall: What is the stat for the highest attribute of the Pokémon with the highest overall stats?</p><p>To get the answer, participants need to first check the view related to the stadium and identify Pokémon with the highest overall stats in the scene. Next, they need to find the view related to the most powerful Pokémon, and identify the stat for the highest attribute.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Participants</head><p>We recruited 12 participants (8 males and 4 females; age: 22-25, average: 23.7) for our study. Due to the restriction of COVID-19 pandemic, all participants are students in a university. According to the pre-study survey, three participants are familiar with AR techniques, and one of them is experienced in HoloLens 2. None of them has sight or movement disability. For each task, we adjusted the stat of Pokémon and reminded the participants to finish the tasks based on the views rather than prior knowledge. The study was eligible for exempt research as it involves minimal to no risks to the participants, as reviewed by the institutional review board of the university.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Apparatus</head><p>The study was conducted in an indoor space of approximately 5m × 3m size, where the participants could perform body movements and interactions freely. A video wall was around the experimental space, showing the guidance and questions. All AR content was displayed in front of the video wall. During the study, the participants were equipped with Microsoft HoloLens 2−an AR head-mounted display (HMD) with see-through holographic lenses, which was connected to a high-performance workstation through WiFi during the experiment. The view of the HMD was streamed to the workstation in real-time and recorded for analysis. Besides, each participant wore a microphone to answer questions and the voice was recorded during the experiment.</p><p>In each experiment trial, an experiment regulator was assigned who stood outside of the workspace of the participant and kept watching the AR view of the participant on the screen of the workstation. The regulator would provide in-time guidance to the participant through voice communication. The regulator would stop the experiment if he felt the experiment should not be continued under conditions like the participant feeling dizzy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Procedure</head><p>For each participant, we first introduced the purpose of the experiment and asked the participant to fill in a pre-study survey regarding their background and experience with AR and sign a consent form. Then, the participant was given an instruction to learn the experiment design and how to use HoloLens to accomplish all tasks. Before the formal experiment, the participant was trained to finish training tasks that have the same settings in terms of layout configurations, scene complexity, and set of tasks. Different Pokémons and varying positions, attributes and questions, are used in the training than those in the formal experiment. We let the participant freely explore in the training scene, and moved to the next stage only when the participant felt confident that she/he was familiar with the system and able to accomplish all tasks.</p><p>In the formal experiment, we counterbalanced the order of layout configurations across different participants. All combinations of experiment conditions (3 layout configurations × 3 conditions of scene complexity × 3 tasks) were repeated 2 times so that each participant had to complete 54 experiment trials. The experiment was first conducted in the simple scene (S1), followed by the complex scene without view alignment (S2.1), and finally in the complex scene with view alignment (S2.2). To avoid the effect of user proficiency on completing tasks, we evaluated 3 layout configurations in turn for each task in each scene condition. Before each trial, we gave participants enough time to rest and introduced the next trial to guarantee the analytic efficiency. During the study, participants were encouraged to use think aloud technique when answering questions. After completing the trials before S2.2, participants were asked to give feedbacks about the layouts. Then, after finishing S2.2, we collected feedback about the view alignment function and overall feedback regarding the prototype system. Illustration of the study procedure can be found in Supplementary Figure <ref type="figure" target="#fig_0">1</ref>.</p><p>The whole procedure lasted approximately 1.5 hours, and the participants were compensated with ≈$25 for the time. The first person view videos of all experiment trials were recorded. We evaluated the performance of layouts via the efficiency and accuracy of different conditions of the study from the videos. Efficiency is measured as completion time of a task counted from participants entering the scene to making answers to the questions. Completion times of two sequential questions were separated by the time when the first question was answered. Accuracy is measured as the percentage of correct answers made to the questions. Qualitative user feedbacks including confidence of answering questions, and usefulness and usability of the prototype system, were collected as well.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5">Hypotheses</head><p>The design trade-offs analysis (Sect. 3.3) reveals that embedded and linked layouts fail to facilitate situatedness and analytics simultaneously. Our proposed method is supposed to generate mixed layout that meets the design requirements. As such, we hypothesize that H1. For all scene conditions and tasks, mixed layout (C3) by our method would be more efficient and achieve higher accuracy than embedded layout (C1) and linked layout (C2).</p><p>As shown in Table <ref type="table" target="#tab_1">1</ref>, embedded layout produces high spatial situatedness but low analytics level, whilst linked layout is preferable for analytics but not for situatedness. We also hypothesize that H2. Specifically, mixed layout (C3) would outperform embedded layout (C1) in analytics-centered sub-tasks, and outperform linked layout (C2) in situatedness-centered sub-tasks.</p><p>Furthermore, as studies (e.g., <ref type="bibr" target="#b44">[45,</ref><ref type="bibr" target="#b56">57]</ref>) suggest that egocentric interactions facilitate task completion in 3D space, we hypothesize that H3. For all layout configurations, integrating automatic view alignment would improve efficiency and accuracy than the corresponding layout without view alignment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.6">Results</head><p>We found that all participants finished the questions with high and approximately the same accuracy across all conditions. Hence, we only compared the efficiency of different layout configurations. shows the task completion time for each condition. We used a Friedman test to detect the significant effect of layout configuration on task completion time (at the significance level of α = .05). Furthermore, we ran a post-hoc Wilcoxon signed-rank test to perform pairwise comparison of layout conditions. Significant values are reported for p &lt; .05( * ), p &lt; .01( * * ), p &lt; .001( * * * ). Refer to the supplementary material for details on the experimental data and analysis.</p><note type="other">Figure 7</note><p>Hypothesis 1. H1 is checked using the average overall completion times for both analytics-and situatedness-centered sub-tasks in Filtering + Situatedness (T1) and Refocusing + Situatedness (T2), and the average completion times in Connecting + Situatedness (T3). Significant effects of layout configurations on completion time are observed for T1 ( * ) and T2( * * ) and T3 ( * * * ), respectively. Specifically, i) for T1, C3 is the best and significantly faster than C2 ( * * ); ii) for T2, C2 is the best and significantly faster than C1 ( * * ) and C3 ( * * ); iii) for T3, C3 is the best and significantly faster than C1 ( * * ) and C2 ( * * ). Overall, C3 achieves the best performance on T1 and T3, partially confirming H1.</p><p>Hypothesis 2. H2 is checked using the completion time for each analytics-and situatedness-centered sub-tasks. For analytics-centered sub-tasks in T1, we find no significant effects of layout conditions on time in the simple scene (S1) (χ 2 (2) = .409, p = .815). When the scene complexity becomes high (S2), the significant difference is observed ( * ), but no significant difference is observed from pairwise comparison. For analytics-centered sub-tasks in T2, layout makes significant effects in both S1( * * * ) and S2( * * * ). Especially, C3 is significantly faster than C1 in S1( * ), but is slightly worse than C1 in S2 on average. This is because a participant (P6) accidentally spent much time on T2, which increases the average task completion time for C3. Nevertheless, Wilcoxon signed-rank test demonstrated that the layouts have no significant difference (Z = −1.453, p = .146). For situatednesscentered sub-tasks, layout makes significant effects on time with all combinations of tasks and scene complexity. Concretely, C3 has overall advantages on time consuming over C2. In particular, C3 is significantly faster in S2 ( * * ). In summary, C3 only outperforms C1 in analyticscentered tasks of T2 with simple scene, whilst C3 outperforms C2 in all situatedness-centered sub-tasks, partially confirming H2.</p><p>Hypothesis 3. H3 is checked by Wilcoxon signed-rank test for the task completion time in S2 with alignment vs. without alignment. In the context of analytics-centered sub-tasks, the results show that the view alignment has significant improvement in C3 ( * ) for both T1 and T2. Whereas, it increases the time of C2 for T2. In terms of situatedness-centered sub-tasks, the alignment increases the time for T2 with C1 ( * ) and C2 ( * * ), whilst C3 has not been significantly influenced (Z = −.513, p = .608). On the other tasks, the view alignment makes no significant effects. In a word, the automatic view alignment facilitate the performance of C3 on T1 and T2, partially confirming H3. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.7">User Feedback</head><p>We collected user feedbacks regarding the prototype system with layout by our method from the participants, using 7-point Likert-scale questions in the post-study questionnaires. The feedback covers five perspectives: usability, utility, workload, confidence, and satisfaction. Figure <ref type="figure" target="#fig_9">8</ref> presents the detailed ratings. Overall, the prototype system received all ratings higher than 5 on average, which showed users' satisfaction on our layout method.</p><p>• Usability: The participants responded positively about the usability of mixed layout by our method (μ = 6.08, 95% CI = [5.45, 6.71]).</p><p>The usability is high because mixed layout 'manages to mitigate view occlusion' (P7) compared with embedded layout, and relates views to their referents more intuitively than linked layout that 'confuses me on the mapping rules between views and referents' (P11).</p><p>• Utility: The participants appreciated the usefulness of mixed layout on both spatial situatedness (μ = 6.33, 95% CI = [5.77, 6.90]) and level of analytics with MV representations (μ = 5.33, 95% CI = [4.71, 5.96]). Some participants recommended mixed layout as 'balanced layout' (P3), which benefits both 'context-awareness and multiple-view analysis' (P10). Interestingly, the participants gave a relatively low rating on level of analytics. Here, a main reason is that mixed layout arranges views out of FOV in the complex scene, which is not ideal for analytics.</p><p>• Workload: The participants did not feel much physical load (μ = 5.75, 95% CI = [5.27, 6.23]) as well as mental or perceptual load (μ = 5.92, 95% CI = [5.41, 6.42]) during the tasks in the mixed layout condition. This is remarkably encouraging because most participants (9/12) had no experience in AR HMD. Compared with embedded layout, mixed layout placed views closer to the user, which led to 'a clearer sight on views' (P2) and 'less physical movement' (P8). Compared with linked layout that 'requires turning head frequently to map views to referents' (P3), mixed layout received no complaint on the problem. Nevertheless, some participants were unfamiliar or not satisfactory with the mid-air gesture interaction provided by HoloLens. P4 suggested that 'if the interaction could be more friendly, I would feel easier.'</p><p>• Confidence: All participants had sufficient confidence in answering the questions with mixed layout (μ = 6.25, 95% CI = [5.77, 6.73]). In contrast, several participants pointed out that they were not sure about their answers when using the embedded layout because of 'comparison inconvenience' (P2) and 'visual bias' caused by distance and depth difference between views (P7).</p><p>• Satisfaction: The participants expressed the satisfaction in situated analytics with mixed layout (μ = 5.83, 95% CI = [5. <ref type="bibr">23, 6.43]</ref>). We asked participants about the overall feelings during the analysis process. Some participants praised that the process was 'easy and fun' (P9), while P6 stated that she had 'sufficient engagement' in the experiment. A particular reason here is the adoption of cylindrical reference frame that arranges the user in the center of all views.</p><p>The participants were asked the same questions after S2.2 experiment with automatic view alignment. We measured the mean rating differences before and after the experiment. The results are presented in Figure <ref type="figure" target="#fig_9">8</ref>(right). The participants gave overall positive feedback on the view alignment function (5/7 questions received higher ratings). Specifically, the improvement on analytics level is the highest (μ = 1.08, 95% CI = [0.34, 1.82]). On the contrary, the awareness of spatial situatedness was relatively weakened (μ = −0.67, 95% CI = [−1.08, −0.25]). This confirms again that situatedness and analytics are contradictory considerations when situated analytics involves MV representations, and mixed layout by our approach strikes a good balance between situatedness and analytics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">DISCUSSION, LIMITATION, AND FUTURE WORK</head><p>The study reveals some interesting findings. First, situated analytics is often regarded as a holistic feature and benefit for immersive visualization. However, our study shows that design recommendations for improving situatedness and those for facilitating analytics with MV representations, can be hard to accomplish simultaneously. The finding opens up research opportunities for better understanding the relationship between situatedness and analytics in immersive visualization. Second, we follow design space dimensions as in the Ethereal planes framework <ref type="bibr" target="#b21">[22]</ref> to distill the design requirements, and design the layout adaptation method accordingly. The user study confirms usability and effectiveness of the proposed approach in balancing situatedness and analytics. The result advances our understanding of the design space of immersive visualization. Future studies in this direction may leverage knowledge in interface design and human computer interaction.</p><p>Design Implications. The results (Sect. 5.6) and user feedback (Sect. 5.7) confirm that different layout designs have unique advantages on situatedness-and analytics-centered tasks, respectively. Specifically, movability and view-referent proximity dimensions have significant effects on the efficiency of situatedness-centered tasks, for which both embedded and mixed layouts outperform linked layout. User feedback suggests that view and referent in close proximity promotes the space situatedness, as users can easily connect views to referents. The participants favored fixed views when recalling connections between views and referents, which is consistent with empirical studies <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b31">32]</ref>. Nevertheless, the participants also acknowledged that fixed views decrease their confidence for analytics-centered tasks, especially when the views are placed at different depths.</p><p>In terms of analytics-centered task, view-view and view-user proximities, together with perspective and visibility have more explicit effects than other design dimensions. Close view-view proximity significantly promotes analytics−the participants felt more confident on their answers and less workload is needed. View arrangement that allows users to reduce view-user proximity and examine the views at close facilitates analysis. Egocentric reference frame that arranges views on a common cylindrical surface around users can help reduce head &amp; body movement, which are also beneficial for analytic-centered tasks. Last but not least, exploratory data analysis requires clear sight on visualizations. In case of occlusion, participants had to move around to get a clear sight, causing the burden of body movement and a waste of time.</p><p>Limitations. There are certain limitations in our current work.</p><p>• This work only considers spatial situatedness. Hence we purposely chose an open space for the experiment. As pointed out in <ref type="bibr" target="#b4">[5]</ref>, situatedness can also be enhanced from other perspectives including time, place, activity, and community. The design space becomes more complex and more researches can be conducted when other perspectives are considered. For example, we can include semantic context as in <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b34">35]</ref> to improve place situatedness, and user behaviors as in <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b30">31]</ref> to improve activity situatedness.</p><p>• Due to the limited FOV in HoloLens 2, we only evaluated the effectiveness of the proposed method in positioning six views at maximum, yet view occlusion happened and user preference was reduced. We have provided user interactions including view arrangement to mitigate the issue. More interactions can be incorporated to further improve view readability. For example, we plan to allow users select views of interest, and group them as small multiples. Compositing multiple views into one single view <ref type="bibr" target="#b54">[55]</ref> that reduces the number of views displayed is promising.</p><p>• This work treats each view as a static component with fixed size and visual structure. A more thoughtful solution is to consider responsive design of visual structure and content displayed in a view, which can potentially address the scalability issue caused by limited FOV.</p><p>The visualization community has proposed methods for adapting MV representations on the desktop to mobile phones <ref type="bibr" target="#b0">[1]</ref>. Responsive visualization design for immersive visualization is lack of exploration and worth exploring.</p><p>Future Work. There are several promising directions for future works. First, we plan to integrate more advanced interactions in the prototype system. In the experiment, participants complained that the mid-air gestural interactions provided by HoloLens is difficult to use. We plan to improve interactions from the perspectives of modality and accuracy.</p><p>In terms of modality, the HCI and visualization communities have exploited many other techniques, such as multimodal interactions <ref type="bibr" target="#b26">[27]</ref>, to facilitate data exploration in immersive visualization. In the context of MV representations, well-designed interactions would require low head and body movements for filtering, refocusing, and connecting views. In terms of accuracy, it is possible to improve interaction accuracy based on user intentions predicted by interaction provenance. For example, we would like to exploit deep learning techniques as in <ref type="bibr" target="#b11">[12]</ref> to accurately map from gestural movements to user-intended interactions. Better understanding of user intentions can also improve activity situatedness in situated analytics. Second, we would like to improve the generalizability of our layout adaptation method. We have discussed potential methods such as responsive design, to fit more complex scene with more views. Besides, the proposed method has the potential to be extended to collaborative analytics scenarios that include more than one users. Nevertheless, multiple-user collaboration also needs to consider sharing and privacy issues other than cross-view data analysis. This brings new challenges and opportunities to improve the algorithm. Moreover, our force-directed layout adaptation method is only tested on static scenes. There are also needs for situated analytics with MV representations in dynamic scenes, such as the car racing competition illustrated in Figure <ref type="figure" target="#fig_0">1</ref>. The force-directed method is relatively simple and runs in real-time. However, the method will probably produce inconsistent layouts across different frames, which increases the analysis burden for users. The effects of layout stability on situatedness levels and analytics efficiency in dynamic scenes need to be further studied.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">CONCLUSION</head><p>We have presented an in-depth study on the effects of view layout on situated analytics for MV representations in immersive visualization. The study is based on a new inspection of the contradictory considerations for situatedness and analytics. A close examination of two common layout paradigms, including embedded and linked layouts, reveals the design trade-offs to be made and implies the considerations for a desired layout that balances situatedness and analytics simultaneously. We leverage design space dimensions for 2D interface arrangement in 3D space, and propose an automatic layout adaptation method that fulfills the considerations. The method includes a cylindrical paradigm for egocentric reference frame, and a force-directed method for proper view-view, view-user, and view-referent proximities and high view visibility. Quantitative results and user feedbacks from a formal user study confirm the effectiveness of our proposed method in achieving high level of spatial situatedness and cross-view analysis including filtering, refocusing, and connecting tasks.</p><p>With increasing demand and more mature technologies, situated analytics is becoming an emerging field of research. This work illustrates a promising area for future research on situated analytics. More conceptual and empirical research is needed to achieve a better understanding of design space dimensions for situated analytics. The solution shows that knowledge from multiple research communities can be integrated to improve immersive visualization design.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Integrating multiple-view representations into the physical world can benefit applications like sports (left) and board game (right).</figDesc><graphic url="image-26.png" coords="1,432.63,332.97,110.84,76.33" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig.2. This work considers properties of views, referents, and user to derive the optimal layout that balances situatedness and analytics.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .</head><label>3</label><figDesc>Fig.3. Embedded and linked layouts are commonly adopted in situated analytics. However, both layouts have certain limitations.</figDesc><graphic url="image-52.png" coords="3,319.13,74.06,109.66,71.91" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Illustration of the automatic layout adaptation method: (a) cylindrical layout is adopted as the reference frame to represent positions; (b) surface reallocation is made to balance view-referent and view-user proximities; and (c) view translation is made to remove occlusion and balance view-view and view-referent proximities.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. Illustration of layout configurations used in the experiment: (a) Embedded layout places views directly on top of their referents; (b) Linked layout arranges all views side-by-side on a 2D plane that is close to the user; and (c) Mixed layout by our layout adaptation method arranges all views on a common cylindrical surface projecting the pink circle on the ground.</figDesc><graphic url="image-78.png" coords="6,66.64,211.73,112.94,64.05" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 6 .</head><label>6</label><figDesc>Fig. 6. Two user interactions provided in the prototype system: (a) highlighting, and (b) filtering.</figDesc><graphic url="image-77.png" coords="6,180.55,211.73,112.94,64.05" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head></head><label></label><figDesc>(a)), filtering (Figure 6(b)), and view arrangement. Highlighting and filtering are designed for data exploration by changing visual elements of a view, whereas view arrangement is designed for fine-tuning view layout. All interactions are realized using mid-air gestures provided by HoloLens2.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head></head><label></label><figDesc>Figure 5, we considered 3 layout configurations that produce varied levels of situatedness and analytics: C1. Embedded layout. All views are placed directly on top of their referents (Figure 5(a)). View positions only depend on those of the physical referents. The layout generates close proximity between each pair of view and referent, yet places views far away from each other and may cause occlusion (red view). C2. Linked layout. All views are arranged side-by-side on a 2D plane that is close to the user (Figure 5(b)). The order of views follows a predefined rule, including left-to-right or front-to-back order according to the referent position. The rule was random and would be told to the participants before each trial. The layout generates close promixities among views, yet places views far away from their referents. C3. Mixed layout. All views are arranged on a common cylindrical surface and placed in positions by our layout adaption method (Figure 5(c))</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 7 .</head><label>7</label><figDesc>Fig. 7. Average task completion time (seconds) for each condition. Error bars represent 95% confidence intervals.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig. 8 .</head><label>8</label><figDesc>Fig. 8. User feedbacks on usability, utility, workload, confidence, and satisfaction of mixed layout by our method. Rating changes after providing view alignment is presented on the right.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 .</head><label>1</label><figDesc>Linked and embedded layouts have different values in design space dimensions of the ethereal planes framework<ref type="bibr" target="#b21">[22]</ref>.</figDesc><table><row><cell>Layout</cell><cell cols="2">Dimension</cell><cell>Value</cell><cell>Situated</cell><cell>Analytics</cell></row><row><cell></cell><cell cols="2">Perspective</cell><cell>egocentric</cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="2">Movability</cell><cell>movable</cell><cell></cell><cell></cell></row><row><cell>Linked</cell><cell>Proximity</cell><cell>view-user view-view</cell><cell>near near</cell><cell>Low</cell><cell>High</cell></row><row><cell></cell><cell></cell><cell>view-referent</cell><cell>far</cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="2">Visibility</cell><cell>high</cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="2">Perspective</cell><cell>exocentric</cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="2">Movability</cell><cell>fixed</cell><cell></cell><cell></cell></row><row><cell>Embed</cell><cell>Proximity</cell><cell>view-user view-view</cell><cell>dependent dependent</cell><cell>High</cell><cell>Low</cell></row><row><cell></cell><cell></cell><cell>view-referent</cell><cell>near</cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="2">Visibility</cell><cell>intermediate</cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>•</head><label></label><figDesc>Visibility: Visibility denotes the number of views that clearly shown in the field of view. High visibility is fundamental for analytics, as 'what you see is what you get'. Linked layout organizes views together and close to the view, removing occlusion issue and making high visibility of the views. In contrast, embedded layout may suffer from occlusion issues and the visibility level is low or intermediate, dependent on the user-referent proximities.</figDesc><table /></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS</head><p>This work was supported by the National Natural Science Foundation of China (No. 62132017, No. 62172398).</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Effects of screen-responsive visualization on data comprehension</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">K</forename><surname>Badam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Elmqvist</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Inf. Vis</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="229" to="244" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Situation awareness as a function of frame of reference, computer-graphics eyepoint elevation, and geometric field of view</title>
		<author>
			<persName><forename type="first">W</forename><surname>Barfield</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Rosenberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">A</forename><surname>Furness</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Iii</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Aviat. Psychol</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="233" to="256" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">External labeling techniques: A taxonomy and survey</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Bekos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Niedermann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Nöllenburg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Graph. Forum</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="833" to="860" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">View management for virtual and augmented reality</title>
		<author>
			<persName><forename type="first">B</forename><surname>Bell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Feiner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Höllerer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. UIST</title>
				<meeting>UIST</meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="101" to="110" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">What&apos;s the situation with situated visualization? a survey and perspectives on situatedness</title>
		<author>
			<persName><forename type="first">N</forename><surname>Bressa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Korsgaard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Tabard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Houben</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Vermeulen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Vis. Comput. Graph</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="107" to="117" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Readings in Information visualization: using vision to think</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">K</forename><surname>Card</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Mackinlay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Shneiderman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999">1999</date>
			<publisher>Morgan Kaufmann</publisher>
			<pubPlace>San Francisco</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Nebula: A coordinating grammar of graphics</title>
		<author>
			<persName><forename type="first">R</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Shu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Weng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Vis. Comput. Graph</title>
		<imprint>
			<biblScope unit="page" from="1" to="1" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Composition and configuration patterns in multiple-view visualizations</title>
		<author>
			<persName><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">M</forename><surname>Al-Maneea</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Vis. Comput. Graph</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1514" to="1524" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">MARVisT: Authoring glyph-based visualization in mobile augmented reality</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Vis. Comput. Graph</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="2645" to="2658" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Exploring the design space of immersive urban analytics</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Visual Informatics</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="132" to="142" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Augmenting sports videos with VisCommentator</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Vis. Comput. Graph</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="824" to="834" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">LassoNet: Deep Lasso-Selection of 3D point clouds</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C.-W</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Qu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Vis. Comput. Graph</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="195" to="204" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">SemanticAdapt: Optimization-based adaptation of mixed reality layouts leveraging virtualphysical semantic connections</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Lindlbauer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. UIST</title>
				<meeting>UIST</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="282" to="297" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">TIVEE: Visual exploration and explanation of badminton tactics in immersive visualizations</title>
		<author>
			<persName><forename type="first">X</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Vis. Comput. Graph</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="118" to="128" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Four considerations for supporting visual analysis in display ecologies</title>
		<author>
			<persName><forename type="first">H</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>North</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Jian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE VAST</title>
				<meeting>IEEE VAST</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="33" to="40" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">VisLink: Revealing relationships amongst visualizations</title>
		<author>
			<persName><forename type="first">C</forename><surname>Collins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Carpendale</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Vis. Comput. Graph</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1192" to="1199" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<author>
			<persName><forename type="first">T</forename><surname>Dwyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Cordeil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Czauderna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">D</forename><surname>Haghighi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Ens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Goodwin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Jenny</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Marriott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Wybrow</surname></persName>
		</author>
		<title level="m">The data visualisation and immersive analytics research lab at monash university. Visual Informatics</title>
				<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="41" to="49" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">A taxonomy of 3D occlusion management for visualization</title>
		<author>
			<persName><forename type="first">N</forename><surname>Elmqvist</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Tsigas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Vis. Comput. Graph</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1095" to="1109" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Situated analytics</title>
		<author>
			<persName><forename type="first">N</forename><surname>Elsayed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Marriott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Piantadosi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE BDVA</title>
				<meeting>IEEE BDVA</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Situated analytics: Demonstrating immersive analytical tools with augmented reality</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">A</forename><surname>Elsayed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">H</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Marriott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Piantadosi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">T</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Vis. Lang. Comput</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="13" to="23" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Grand challenges in immersive analytics</title>
		<author>
			<persName><forename type="first">B</forename><surname>Ens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Bach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Cordeil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Engelke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Serrano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Willett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Prouzeau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Anthes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Büschel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Dunne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Dwyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Grubert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Haga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Kirschenbaum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Kobayashi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Olaosebikan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Pointecker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Saffo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Saquib</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Schmalsteig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Szafir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Whitlock</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ACM CHI</title>
				<meeting>ACM CHI</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">459</biblScope>
			<biblScope unit="page" from="1" to="17" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Ethereal planes: a design framework for 2D information space in 3D mixed reality environments</title>
		<author>
			<persName><forename type="first">B</forename><surname>Ens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Hincapié-Ramos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Irani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ACM SUI</title>
				<meeting>ACM SUI</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="2" to="12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">HeatSpace: Automatic placement of displays by empirical analysis of user behavior</title>
		<author>
			<persName><forename type="first">A</forename><surname>Fender</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Lindlbauer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Herholz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Alexa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Müller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. UIST</title>
				<meeting>UIST</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="611" to="621" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Flare: Fast layout for augmented reality applications</title>
		<author>
			<persName><forename type="first">R</forename><surname>Gal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Shapira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Ofek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Kohli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE ISMAR</title>
				<meeting>IEEE ISMAR</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="207" to="212" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Visual comparison for information visualization</title>
		<author>
			<persName><forename type="first">M</forename><surname>Gleicher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Albers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Walker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Jusufi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">D</forename><surname>Hansen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Roberts</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Inf. Vis</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="289" to="309" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Image-driven view management for augmented reality browsers</title>
		<author>
			<persName><forename type="first">R</forename><surname>Grasset</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Langlotz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Kalkofen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Tatzgern</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Schmalstieg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE ISMAR</title>
				<meeting>IEEE ISMAR</meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="177" to="186" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">STREAM: Exploring the combination of spatially-aware tablets with augmented reality head-mounted displays for immersive analytics</title>
		<author>
			<persName><forename type="first">S</forename><surname>Hubenschmid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zagermann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Butscher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Reiterer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ACM CHI</title>
				<meeting>ACM CHI</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="1" to="14" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">FiberClay: Sculpting three dimensional trajectories to reveal structural insights</title>
		<author>
			<persName><forename type="first">C</forename><surname>Hurter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">H</forename><surname>Riche</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Drucker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Cordeil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Alligier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Vuillemot</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Vis. Comput. Graph</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="704" to="714" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Sketching and simulating spatiallyaware interactive spaces in virtual reality</title>
		<author>
			<persName><forename type="first">H.-C</forename><surname>Jetter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Rädle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Feuchtner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Anthes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Friedl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">N</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">VR, everything is possible</title>
				<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="1" to="16" />
		</imprint>
	</monogr>
	<note>Proc. ACM CHI</note>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Immersive analytics with abstract 3D visualizations: A Survey</title>
		<author>
			<persName><forename type="first">M</forename><surname>Kraus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Fuchs</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Sommer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Engelke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Keim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Schreiber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Graph. Forum</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="201" to="229" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Walking with adaptive augmented reality workspaces: design and usage patterns</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">S</forename><surname>Lages</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Bowman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IUI</title>
				<meeting>IUI</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="356" to="366" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Virtual shelves: Interactions with orientation aware devices</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">C Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Dearman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">N</forename><surname>Truong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. UIST</title>
				<meeting>UIST</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="125" to="128" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Towards an understanding of situated ar visualization for basketball freethrow training</title>
		<author>
			<persName><forename type="first">T</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Nobre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Beyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Pfister</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ACM CHI</title>
				<meeting>ACM CHI</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="1" to="13" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Labeling out-of-view objects in immersive analytics to support situated visual searching</title>
		<author>
			<persName><forename type="first">T</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Beyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Pfister</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Vis. Comput. Graph</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Context-aware online adaptation of mixed reality interfaces</title>
		<author>
			<persName><forename type="first">D</forename><surname>Lindlbauer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Feit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Hilliges</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. UIST</title>
				<meeting>UIST</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="147" to="160" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Design and evaluation of interactive small multiples data visualisation in immersive spaces</title>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Prouzeau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Ens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Dwyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE VR</title>
				<meeting>IEEE VR</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="588" to="597" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Comparative layouts revisited: Design space, guidelines, and future directions</title>
		<author>
			<persName><forename type="first">S</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Jo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Seo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Vis. Comput. Graph</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1525" to="1535" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Corsican Twin: Authoring in situ augmented reality visualisations in virtual reality</title>
		<author>
			<persName><forename type="first">A</forename><surname>Prouzeau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Ens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Willett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Dwyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. AVI</title>
				<meeting>AVI</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="1" to="9" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Keeping multiple views consistent: Constraints, validations, and exceptions in visualization authoring</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hullman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Vis. Comput. Graph</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="468" to="477" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Simulation of augmented reality systems in purely virtual environments</title>
		<author>
			<persName><forename type="first">E</forename><surname>Ragan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Wilkes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Bowman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Hollerer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE VR</title>
				<meeting>IEEE VR</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="287" to="288" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">On encouraging multiple views for visualization</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Roberts</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Info. Vis</title>
				<meeting>IEEE Conf. Info. Vis</meeting>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="8" to="14" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">State of the art: Coordinated &amp; multiple views in exploratory visualization</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Roberts</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CMV</title>
				<meeting>CMV</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="61" to="71" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">One view is not enough: Review of and encouragement for multiple and alternative representations in 3D and immersive visualisation</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">W S</forename><surname>Butcher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">D</forename><surname>Ritsos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computers</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">20</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Visualization beyond the desktop-the next big thing</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">D</forename><surname>Ritsos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">K</forename><surname>Badam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Brodbeck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kennedy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Elmqvist</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Comput. Graph. Appl</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="26" to="34" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Fix and float: Object movement by egocentric navigation</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">G</forename><surname>Robertson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">K</forename><surname>Card</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. UIST</title>
				<meeting>UIST</meeting>
		<imprint>
			<date type="published" when="1997">1997</date>
			<biblScope unit="page" from="149" to="150" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Modeling layout design for multiple-view visualization via Bayesian inference</title>
		<author>
			<persName><forename type="first">L</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zeng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Vis</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1237" to="1252" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">SightBi: Exploring crossview data relationships with biclusters</title>
		<author>
			<persName><forename type="first">M</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">R</forename><surname>Shaikh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Alhoori</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Vis. Comput. Graph</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="54" to="64" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Hedgehog labeling: View management techniques for external labels in 3D space</title>
		<author>
			<persName><forename type="first">M</forename><surname>Tatzgern</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Kalkofen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Grasset</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Schmalstieg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE VR</title>
				<meeting>IEEE VR</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="27" to="32" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">An overview of 3D software visualization</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">R</forename><surname>Teyseyre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Campo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Vis. Comput. Graph</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="87" to="105" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">H</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">F</forename><surname>Welch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Dragicevic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Elmqvist</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Irani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Jansen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Schmalstieg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Tabard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">A</forename><surname>Elsayed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">T</forename><surname>Smith</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">11190</biblScope>
			<biblScope unit="page" from="185" to="220" />
		</imprint>
	</monogr>
	<note>Situated analytics. Immersive analytics</note>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
		<title level="m" type="main">Envisioning information</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">R</forename><surname>Tufte</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">H</forename><surname>Goeler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Benson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1990">1990</date>
			<publisher>Graphics press Cheshire</publisher>
			<biblScope unit="volume">2</biblScope>
			<pubPlace>CT</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Towards an understanding of augmented reality extensions for existing 3D data analysis tools</title>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Besanc ¸on</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Rousseau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sereno</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ammi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Isenberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ACM CHI</title>
				<meeting>ACM CHI</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="1" to="13" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Designing for mobile and immersive visual analytics in the field</title>
		<author>
			<persName><forename type="first">M</forename><surname>Whitlock</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Szafir</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Vis. Comput. Graph</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="503" to="513" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Embedded data representations</title>
		<author>
			<persName><forename type="first">W</forename><surname>Willett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Jansen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Dragicevic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Vis. Comput. Graph</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="461" to="470" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">View composition algebra for ad hoc comparison</title>
		<author>
			<persName><forename type="first">E</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Vis. Comput. Graph</title>
		<imprint>
			<biblScope unit="page" from="1" to="1" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Deep recognition of vanishingpoint-constrained building planes in urban street views</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C.-W</forename><surname>Fu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="5912" to="5923" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">UrbanVR: An immersive analytics system for context-aware urban design</title>
		<author>
			<persName><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. &amp; Graph</title>
		<imprint>
			<biblScope unit="volume">99</biblScope>
			<biblScope unit="page" from="128" to="138" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">A partially-sorted concentric layout for efficient label localization in augmented reality</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Popescu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Vis. Comput. Graph</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="4087" to="4096" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
