<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Visual Comparison of Language Model Adaptation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Rita</forename><surname>Sevastjanova</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Eren</forename><surname>Cakmak</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Shauli</forename><surname>Ravfogel</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Ryan</forename><surname>Cotterell</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Mennatallah</forename><surname>El-Assady</surname></persName>
						</author>
						<title level="a" type="main">Visual Comparison of Language Model Adaptation</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.2" ident="GROBID" when="2023-03-27T09:22+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Language Model Adaptation</term>
					<term>Adapter</term>
					<term>Word Embeddings</term>
					<term>Sequence Classification</term>
					<term>Visual Analytics</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Fig. <ref type="figure">1</ref>: We present a workspace that enables the evaluation and comparison of adapters -lightweight alternatives for language model fine-tuning. After data pre-processing (e.g., embedding extraction), users can select pre-trained adapters, create explanations, and explore model differences through three types of visualizations: Concept Embedding Similarity, Concept Embedding Projection, and Concept Prediction Similarity. The explanations are provided for single models as well as model comparisons. For each explanation, we provide further explanation details, such as the word contexts as well as embedding vectors themselves.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Language models (LMs) such as the masked language model BERT <ref type="bibr" target="#b10">[11]</ref> are widely used for diverse natural language processing (NLP) and understanding tasks. Such models are capable of learning manifold language properties in an unsupervised manner <ref type="bibr" target="#b58">[59]</ref>. However, the model parameters typically need to be updated before using them on downstream tasks, such as sentiment classification. Task specific fine-tuning <ref type="bibr" target="#b26">[27,</ref><ref type="bibr" target="#b54">55]</ref> along with domain specific fine-tuning <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b21">22]</ref> are the most common methods for parameter adaptation. Although fine-tuning methods commonly achieve state-of-the-art results on many NLP tasks <ref type="bibr" target="#b54">[55]</ref>, they come along with limitations such as a high training time and storage <ref type="bibr" target="#b31">[32]</ref>. To overcome the shortcomings of the model fine-tuning, Houlsby et al. <ref type="bibr" target="#b25">[26]</ref> have recently introduced adapter modules -a lightweight alternative for LM fine-tuning. Instead of adapting the complete model, adapters learn a small set of task-specific parameters, requiring less training time and storage space. For a more efficient adapter training and composition, Pfeiffer et al. <ref type="bibr" target="#b48">[49]</ref> have proposed a modular adapter framework called AdapterHub. It comes along with adapter-transformers -an extension of HuggingFace's transformers library <ref type="foot" target="#foot_0">1</ref> , integrating adapters into state-of-the-art LMs. In addition to the simple parameter adaptation, the AdapterHub framework allows sharing adapters with the community, supporting open science practices.</p><p>The AdapterHub repository currently contains almost 400 adapters for 72 text analysis tasks and 50 languages. To select the best adapter for a given analysis task, one needs to be able to compare the adapters and their learned language properties. The related work has shown that such model comparison tasks are the focus of both model-and data-driven users working with LMs <ref type="bibr" target="#b4">[5]</ref>. To understand more about the typical analysis setting, data, and performed tasks when evaluating fine-tuned model properties, we conducted literature review and semi-structured interviews with two NLP researchers. The requirement analysis revealed that researchers are interested in analyzing models with respect to different human-interpretable concepts. In particular, they investigate how specific concept representations change during finetuning. The analysis is typically performed on two types of data: <ref type="bibr" target="#b0">(1)</ref> word embedding representations and (2) classifier prediction outcomes. Using word embeddings, they analyze evolving concept intersections as well as newly produced artifacts like strange word associations (e.g., biases). Prediction outcomes are used to analyze task-adapted model behavior changes, e.g., whether specific word associations lead to unexpected prediction outcomes.</p><p>The adapters trained on one particular task typically have different architectures <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b49">50]</ref> and training corpora. These different learning settings usually lead to different model performances; it is difficult, though, to keep track of such performance variations. The continuous development of new adapters thus dictates the need for a solution that assists the analysis and comparison of adapter properties.</p><p>To support the NLP community in an effective adapter evaluation and comparison, we contribute a novel visual analytics workspace. The workspace integrates adapters from the AdapterHub repository and enables their analysis through three types of visual explanation methods: Concept Embedding Similarity, Concept Embedding Projection, and Concept Prediction Similarity (see Fig. <ref type="figure">1</ref>). We support model comparison according to their produced word embeddings and classification predictions, i.e., both intrinsic and extrinsic evaluation methods. The explanations are performed on diverse human-interpretable concepts related to bias mitigation and sentiment analysis tasks (e.g., genderrelated stereotypes, human qualities). The users can upload further concepts to the workspace to cover further analysis directions. The modular composition of visual explanations supports such analysis extensions.</p><p>The comparison of adapter properties requires sufficient comparative visualization designs. As described by Gleicher <ref type="bibr" target="#b18">[19]</ref>, the design of comparative visualizations is not trivial since they typically combine the issues of representing individual objects as well as their relationships. In order to design an appropriate solution, we rely on the comparative visualization guidelines <ref type="bibr" target="#b18">[19]</ref> and consider four task-and data-related aspects: (1) comparative elements, (2) challenges related to representing relationships between the comparative elements, (3) strategies to overcome the challenges, and (4) a sufficient design solution. The design process constituted of several iterations in close collaboration with NLP researchers. In Sect. 5 we present some of the considered design alternatives; others are provided as supplementary material to this paper.</p><p>We show the applicability of the workspace through case studies created collaboratively with NLP researchers. In particular, we compare the properties of six adapters related to debiasing, sentiment classification, and named entity recognition tasks. We present new insights into model properties related to human-interpretable concepts and show that, for instance, context-0 (decontextualized) embeddings of the adapter trained on the language debiasing task contain a bias where words become more similar to femalethan male pronouns; however, the gender information is eliminated from the contextualized word representations.</p><p>To summarize, the contribution of this paper is threefold. (1) We present requirements for a visual analytics system supporting fine-tuned LM comparison. <ref type="bibr" target="#b1">(2)</ref> We introduce a workspace for model comparison and present design considerations for three types of comparative, visual explanation methods. <ref type="bibr" target="#b2">(3)</ref> We present new insights into multiple adapter properties through expert case studies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">BACKGROUND AND RELATED WORK</head><p>In the following, we describe background information related to LM fine-tuning and related work to explanation methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Language Model Fine-Tuning</head><p>In this paper, we analyze transformers, which are multi-layer models that use attention mechanisms <ref type="bibr" target="#b68">[69]</ref>. In these models, each token of the input sequence is mapped to a high-dimensional vector (i.e., contextdependent embedding that encodes specific context properties). These embeddings are updated in each transformer's layer; thus, one can extract and analyze contextualized word embeddings layerwise (e.g., 12 layers for the BERT-base model). It has been shown that these embeddings encode different language properties found in the training data <ref type="bibr" target="#b58">[59]</ref>. LMs, including transformers, are commonly fine-tuned to capture language characteristics for specific domains or tasks. Domainadaptive fine-tuning is an unsupervised fine-tuning approach based on a masked language modeling task on text from a specific domain <ref type="bibr" target="#b21">[22]</ref>. Intermediate-task training is a model's fine-tuning on labeled data prior to task-specific fine-tuning <ref type="bibr" target="#b51">[52]</ref>. Task-specific fine-tuning deals with adapting an LM to a particular output label distribution <ref type="bibr" target="#b26">[27]</ref>. The finetuning of LMs is effective yet time-and resource-consuming. Kirkpatrick et al. <ref type="bibr" target="#b31">[32]</ref> also showed that fine-tuning can lead to catastrophic forgetting of language characteristics acquired during the model's pretraining. To overcome these limitations, Houlsby et al. <ref type="bibr" target="#b25">[26]</ref> introduced adapters. They are a lightweight alternative for model fine-tuning, only optimizing a small set of task-specific parameters learned and stored during the adaptation phase, thus, reducing both training time and storage space. The AdapterHub framework <ref type="bibr" target="#b48">[49]</ref> has brought the advantage of a simple and efficient adapter composition and reuse -one can upload their trained adapters to the AdapterHub or HuggingFace<ref type="foot" target="#foot_1">2</ref> repositories, and they are available in the framework for interested parties, supporting the open science practice. Adapters can be trained on masked language modeling as well as specific downstream tasks (e.g., sentiment classification). The trained adapters can be 'attached' to the pre-trained model, leading to adapted model parameters. The model with an attached task adapter can be used for the target task (e.g., sentiment classification). Adapters have been applied for tasks such as natural language generation <ref type="bibr" target="#b37">[38]</ref>, machine translation <ref type="bibr" target="#b30">[31,</ref><ref type="bibr" target="#b52">53]</ref>, domain adaptation <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b50">51]</ref>, injection of external knowledge <ref type="bibr" target="#b34">[35]</ref>, and language debiasing <ref type="bibr" target="#b33">[34]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Visual Embedding Explanation and Comparison</head><p>With respect to explainability, most relevant work has focused on visualizations that show how transformers work and what they learn. For example, visual analytics systems like NLIZE <ref type="bibr" target="#b39">[40]</ref>, Seq2Seq-Vis <ref type="bibr" target="#b65">[66]</ref>, BertViz <ref type="bibr" target="#b69">[70]</ref>, exBERT <ref type="bibr" target="#b24">[25]</ref>, SANVis <ref type="bibr" target="#b45">[46]</ref>, and Attention Flows <ref type="bibr" target="#b9">[10]</ref> visualize the attention layer, i.e., to highlight tokens to which the model attends to in order to solve a task. Although widely used, attentions and their suitability for explanation purposes are being controversially discussed in related work (see, e.g., <ref type="bibr" target="#b27">[28]</ref>). Other work has focused on visualizing word embeddings to show what LMs learn. The first such tools were designed for static embeddings, such as word2vec <ref type="bibr" target="#b43">[44]</ref> and GloVe <ref type="bibr" target="#b46">[47]</ref>, and facilitated analogies <ref type="bibr" target="#b38">[39]</ref> and tasks related to local word neighborhoods <ref type="bibr" target="#b22">[23]</ref>. Later, Berger <ref type="bibr" target="#b2">[3]</ref> explored correlations between embedding clusters in BERT <ref type="bibr" target="#b10">[11]</ref>. Recent tools focus on LM comparison tasks by visualizing multiple models simultaneously. For instance, Strobelt et al. <ref type="bibr" target="#b66">[67]</ref> present LMDiff -a tool that visually compares LM probability distributions and suggests interesting text instances for the analysis. Heimerl et al. <ref type="bibr" target="#b23">[24]</ref> present embComb, which applies different metrics to measure differences in the local structure around embedding objects (e.g., tokens). Embedding Comparator by Boggust et al. <ref type="bibr" target="#b4">[5]</ref> is a system for embedding comparison through small multiples. It calculates and visualizes similarity scores for the embedded objects based on their local neighborhoods (i.e., shared nearest neighbors). Different from these two approaches, we provide explanations of pre-defined human-interpretable concepts, enabling testing more specific hypotheses related to embedding intersections. Sivaraman et al. <ref type="bibr" target="#b64">[65]</ref> present Emblaze, which uses an animated scatterplot and integrates visual augmentations to summarize changes in the analyzed embedding spaces. In contrast, we compare models by aligning the two spaces using juxtaposition, superposition, and explicit encoding techniques. Our recent work called LMFingerprints <ref type="bibr" target="#b61">[62]</ref> applies scoring techniques to examine properties encoded in embedding vectors and supports model as well as model layer comparison. Embedding comparison tasks are relevant for all types of data that get represented by embedding vectors. For instance, Li et al. <ref type="bibr" target="#b35">[36]</ref> present a visual analytics system for node embedding comparison (i.e., graph data), and Arendt et al. <ref type="bibr" target="#b0">[1]</ref> introduce a visualization technique called Parallel Embeddings for conceptoriented model comparison on image data, to name a few. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">REQUIREMENT ANALYSIS</head><p>Before designing the visual analytics workspace, we conducted a literature review related to LM comparison tasks (e.g., <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b64">65]</ref>). Furthermore, we conducted two semi-structured interviews in an online setting with two NLP researchers (co-authors of this paper) with expertise in language modeling tasks to discuss further common evaluationrelated analysis aspects. Our goal was to gather specific linguistically motivated analysis tasks and research challenges for the evaluation of adapted LMs. In the following, we describe the gathered requirements through Models and Data and Users and Tasks <ref type="bibr" target="#b44">[45]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Models and Data</head><p>The NLP research focuses not only on developing and adapting new models with better performance but also on understanding the linguistic properties the models implicitly capture. Probing classifiers <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b36">37]</ref> and adversarial testing <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b40">41,</ref><ref type="bibr" target="#b57">58]</ref> are the most common methods used in computational linguistics to understand such properties. The current research explores not only what the models learn but also when they fail and which limitations they have, such as different types of biases <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b42">43]</ref>; as well as ways to mitigate those biases <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b55">56,</ref><ref type="bibr" target="#b56">57,</ref><ref type="bibr" target="#b71">72]</ref>. Visualizations are used to analyze the model latent spaces to gain insights into the degree of changes in embedding vectors <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b60">61]</ref>, properties encoded in embedding vectors <ref type="bibr" target="#b61">[62]</ref>, and word neighborhood changes <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b64">65]</ref>. Especially, the comparison of embedding local neighborhoods is one of the critical tasks for many users of LMs <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b64">65]</ref>. For such comparisons, one first needs to select words for the analysis. Boggust et al. <ref type="bibr" target="#b4">[5]</ref> write that this is commonly done either in a data-or model-driven way, for instance, by exploring specific domain-related words or challenging words for the analyzed model. During the interviews, the NLP researchers agreed with this statement and emphasized that evaluation methods related to model limitations often explore specific, pre-defined human-interpretable concepts such as gender-related stereotypes. When analyzing such humaninterpretable concepts, people commonly analyze contextualized word embeddings. For some methods (e.g., Word Embedding Association Tests <ref type="bibr" target="#b6">[7]</ref>), researchers compute word-level vectors without an explicit context <ref type="bibr" target="#b33">[34,</ref><ref type="bibr" target="#b70">71]</ref>. In particular, for BERT, one can append the sequence start and the separator token before and after the word, respectively (e.g., [CLS] word [SEP]) and extract embeddings with context size zero <ref type="bibr" target="#b73">[74]</ref> (also known as decontextualized embeddings <ref type="bibr" target="#b5">[6]</ref>). In the following, we call them context-0 embeddings. Our experts also emphasized the need to 'connect' the embedding space with the model's behavior to inspect whether specific embedding vectors influence the model's predictions on downstream tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Users and Tasks</head><p>With this work, we aim to support developers and researchers who adapt and evaluate LMs to perform their analysis more easily by focusing on the analysis of diverse human-interpretable concepts. To do that, we gathered task-related requirements. NLP researchers' work is related to comparison (i.e., baseline) tasks. In particular, their analysis typically involves (T0) a comparison of multiple LMs with different architectures or fine-tuning settings as well as multiple model layers. Second, they typically analyze specific human-interpretable concepts and try to (T1) partition the representation (e.g., embedding) space according to these concepts. Third, they try to (T2) understand interactions between specific concepts, e.g., to what extent these concepts are represented similarly in the representation (e.g., embedding) space. They aim to (T3) detect 'unexpected' associations, e.g., positive sentiment words that tend to trigger the negative sentiment because, e.g., they are negated. And finally, their goal is to (T4) connect the representation space with the actual behavior of the model, e.g., to understand whether concepts are separated in the representation space yet do not affect the behavior of the model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">VISUAL ANALYTICS WORKSPACE: DATA PROCESSING</head><p>In this section, we present our visual analytics workspace and its three main components: Adapter Composition View (in Fig. <ref type="figure" target="#fig_0">2 A</ref>), Explanation Composition View (in Fig. <ref type="figure" target="#fig_0">2 B</ref>), and Visual Comparison View (in Fig. <ref type="figure" target="#fig_0">2</ref> Workspace) for model and layer comparison. Before introducing the workspace design in Sect. 5, we describe the data processing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Data Modeling</head><p>Motivated by the gathered requirements, we first build the data model. Since human-interpretable concept analysis plays a crucial role in NLP research, we start by modeling such concepts. By default, we work with concepts that are commonly used in research related to bias mitigation <ref type="foot" target="#foot_2">3</ref> and sentiment analysis. The users can upload further concepts as .json files in the interface. One concept is represented by two word lists, each having a specific polarity. For instance, a concept called person names consists of two word lists -male person names and female person names, respectively. We provide the following concepts: male/female person names, male/female pronouns, male/female-related nouns, male/female-related stereotypes, positive/negative human qualities, high/low-GDP countries, and words related to weak/strong, family/career, science/arts, intelligence/appearance.</p><p>We first model each word in a concept through a list of sentences in which the word is used. For this purpose we use the Yelp dataset <ref type="bibr" target="#b72">[73]</ref>; the user can also upload other datasets and use them for explanations. The associated sentences are used for two purposes. First, we use them as an input to the (adapted) LM to extract the word's contextualized word embeddings. The embeddings are extracted layerwise (i.e., layer 1-12 for BERT-base) and get aggregated <ref type="bibr" target="#b5">[6]</ref> for each unique word (e.g., one average embedding from all occurrences of the word Germany per layer). Second, we use these sentences as input for task adapters for prediction making. Furthermore, we extract the word's context-0 embedding by using the model's special tokens and the word itself as the input to the model (i.e., [CLS] word [SEP]). For words that do not occur in the vocabulary, we average their sub-token embeddings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Adapter Composition and Explanation Composition</head><p>We load adapters from AdapterHub repository and list them in the Adapter Composition View. The user can select an adapter for the analysis by clicking on the particular icon. Currently, we have preprocessed the data for six models: the pre-trained BERT (BERT-baseuncased), the debiasing BERT <ref type="bibr" target="#b33">[34]</ref>, and four task adapters for BERT (sentiment classifiers sst-2, rotten-tomates <ref type="bibr" target="#b53">[54]</ref>, and imdb <ref type="bibr" target="#b53">[54]</ref>, and the named entity recognizer conll2003). For a new adapter selection, the data is first pre-processed and stored in the database.</p><p>The user defines which explanation methods to use for their analysis in the Explanation Composition View. The explanations are constructed from available concepts and three visualization types. The visualizations include Concept Embedding Similarity, Concept Embedding Projection, and Concept Prediction Similarity. The Concept Embedding Similarity requires an input of two concepts: one is used as an anchor in the visualization and the other is explained through the cosine similarity to the anchor. The Concept Embedding Projection requires an input of one or two concepts (to analyze a single concept or the relation between two (un)related concepts). The user can choose between multiple projection techniques: Principal Component Analysis (PCA) <ref type="bibr" target="#b29">[30]</ref>, Multidimensional Scaling (MDS) <ref type="bibr" target="#b32">[33]</ref>, t-Distributed Stochastic Neighbor Embedding (t-SNE) <ref type="bibr" target="#b67">[68]</ref>, and Uniform Manifold Approximation and Projection (UMAP) <ref type="bibr" target="#b41">[42]</ref>. The Concept Prediction Similarity can be applied only on adapters with prediction heads (e.g., sentiment classifier). The explanation requires an input of one concept; the class labels are used as anchors in the visualization.</p><p>The pre-computed adapters, as well as created explanations, are displayed on top of the Visual Comparison View, represented through an icon and adapter's or explanation's name. The user first selects an explanation type, then an adapter that they would like to analyze. To guide the users toward interesting adapters for the analysis, we display a glyph underneath the adapter's icon. The glyph shows the overlap between the two concept word lists for the selected explanation. The overlap is determined using a similar algorithm to the class consistency <ref type="bibr" target="#b63">[64]</ref> that is commonly used to select good scatterplot views for high-dimensional data. An example of these glyphs is shown in Fig. <ref type="figure" target="#fig_0">2</ref>. The explanation visualization is displayed in the Visual Comparison View on a zoomable canvas; hence, one can display as many explanations on the canvas as needed. A draggable placeholder icon marks the position where the next selected adapter visualization will be displayed on the screen.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">VISUAL ANALYTICS WORKSPACE: DESIGN RATIONALE</head><p>In the following, we describe the design rationale and the visual encoding for the designed explanation visualizations. Our workspace supports the exploration of a single model and the comparison of two models or two model layers (T0). We apply diverse explanation methods (i.e., the similarity in the high-dimensional space, embedding projection, and explanation details) to detect and avoid potential artifacts generated by a single approach (e.g., projection artifacts). The design of the comparison visualizations was motivated by the design guidelines by Gleicher <ref type="bibr" target="#b18">[19]</ref> that consider the comparative elements, challenges that may occur, strategies to overcome the challenges, and the design solutions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Global Visual Encoding</head><p>In all visualizations, we use the visual mark called point <ref type="bibr" target="#b8">[9]</ref> (i.e., rectangle) to represent words. Hidden word labels are displayed by hovering over a word's rectangle. We use positional encoding <ref type="bibr" target="#b8">[9]</ref> to partition the embedding space (T1), detect concept intersections (T2), and locate 'unexpected' associations (T3). The position is used to show the similarity between words according to underlying features such as different types of word embedding vectors or prediction labels. We group words belonging to the same concept through an additional visual mark, i.e., area/contour. The contours are implemented using the d3-contour library <ref type="foot" target="#foot_3">4</ref> based on a two-dimensional kernel density estimation on the point clouds. The user can specify how many contour lines to display in the visualization by moving a slider. To support memorization and ease the readability, we use a global color encoding <ref type="bibr" target="#b8">[9]</ref> for concepts. In particular, we use two diverging color pairs. One color pair represents the two word lists of a concept. The selection of the color pairs was not trivial since the colors had two objectives: the separability between two concepts and the separability between two word lists of one concept. The final decision was made as follows: we selected two warm colors (i.e., pink and yellow) representing one concept and two cold colors (i.e., green and blue) representing the other, as shown in the side figure. Further color alternatives are included in the supplementary material.</p><p>Visual Encoding for Single Model Visualizations By default, we display as many details as possible in the single visualizations but avoid label overplotting. An algorithm measures whether displaying a label would lead to overlap. The algorithm iterates through words in both word lists of a concept and measures the bounding box of each text element that gets added to the visualization. If the new element creates an overlap, it is hidden in the visualization.</p><p>Visual Encoding for Model Comparison Visualizations For effective model comparison, we use both the juxtaposition design (see <ref type="bibr" target="#b18">[19]</ref>) and either the superposition for visualizations that have a positional anchor or explicit encoding for visualizations that lack the positional anchor (e.g., projection techniques). By default, we show the summary <ref type="bibr" target="#b18">[19]</ref> of the two models to avoid datapoint overplotting. The summaries are created using the contour library; the source model is represented through its contour in the 2D space, and the target model is represented through its filled-out area. We use the scan sequentially <ref type="bibr" target="#b18">[19]</ref> strategy to show exact word positions. The filter icons are explained in Sect. 5.1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Concept Embedding Similarity</head><p>This explanation displays the cosine similarity between two concepts enabling to partition the embedding space (T1), detect concept intersections (T2), as well as locate 'unexpected' associations (T3). In this representation, one concept is used as an anchor for explanation purposes. The other concept can be the same as the anchor (e.g., human qualities used twice in Fig. <ref type="figure">3</ref>) or it may differ from the anchor (e.g., person names as a concept and pronouns as an anchor in Fig. <ref type="figure" target="#fig_4">7</ref>). We measure the average cosine similarity between a word in the concept to words in each pole of the selected anchor. It helps to analyze different biases in the data, for instance, whether, e.g., female pronouns are more similar to specific stereotype words than male pronouns.</p><p>(1) Single Model Explanation -The two anchor word lists represent the two axes in the scatterplot visualization (e.g., negative qualities represent y-axis and positive qualities represent x-axis in Fig. <ref type="figure">3</ref>). The average similarity values between a word in the concept to the anchors are used as coordinates in the 2D visualization. A word's (e.g., cheerful in Fig. <ref type="figure">3</ref>) average similarity to the first anchor word list (e.g., negative qualities) specifies the word's y-position and the average similarity to the second anchor word list (e.g., positive qualities) specifies the word's x-position. To support the readability, we add a diagonal line to the visualization as a point of reference. If a word is more similar to the first word list, then it will be located on the left-hand-side of the diagonal; if a word is more similar to the second word list, then it will be located on the right-hand-side of the diagonal. Words that are equally similar to both word lists are located on the diagonal. By default, we display all Fig. <ref type="figure">3</ref>: We provide two types of model comparison designs for analyzing concept embedding similarity, i.e., juxtapositon where two models are displayed next to each other and superposition, where two models are displayed in one visualization. Here: the contextualized word embeddings extracted from layer 11 for the rotten-tomatoes and sst-2 sentiment classifiers differentiate between positiveand negative human qualities. The rotten-tomatoes model requires context to separate the two polarities since the separation is stronger than for context-0 embeddings (see Fig. <ref type="figure" target="#fig_0">2</ref>). words in the concept word lists as rectangles and show non-overlapping labels. Since most of the word lists consist of ca. 100 words, the visualization has overplotting issues that limit the analysis of concept intersections. To overcome these issues, we add a contour line around each pole. We use the d3-contours library and specify the bandwidth parameter to 5, which leads to larger areas for more dense regions; however, single outlier data points are enclosed in separate, smaller areas, enabling the detection of 'unexpected' associations (T3). The area is colored in the particular concept's color with a decreased opacity.</p><p>(2) Model Comparison Explanation -As mentioned in Sect. 3, the overall goal of NLP researchers is to compare models or layers with respect to concept distributions (T0). The design of comparison visualizations is not trivial, as described by Gleicher <ref type="bibr" target="#b18">[19]</ref>. Thus, in order to consider all relevant aspects, we follow his design guidelines.</p><p>The comparison visualization for Concept Embedding Similarity has to display two models or layers simultaneously, each showing the distribution of concept words with respect to selected anchors. Two types of challenges may arise when designing for this objective: (1) the concepts, as well as models, may overlap, and (2) word similarity changes may produce patterns that are difficult to outline all at once. Before we describe the strategies to overcome these challenges, we name our design considerations. Gleicher <ref type="bibr" target="#b18">[19]</ref> names three design alternatives for comparison visualizations: juxtaposition, superposition, and explicit encoding. In our workspace, each explanation can be explored in a juxtaposition design (shown in Fig. <ref type="figure">3</ref> left) since single model visualizations are always displayed next to each other on the screen. This representation has limitations, though. Since we use all the available 2D space for a single model to reduce word overlaps, the visualizations of the compared models often have different scales. Thus, the detailed model and concept overlap analysis is restricted. Therefore, instead of using juxtaposition, we place two models in the same representation using the superposition design (shown in Fig. <ref type="figure">3</ref>, right). The superposition is a valid alternative since the Concept Embedding Similarity visualization has anchors (which is not the case for projection techniques, as described in the following).</p><p>In the comparison visualization, we display the cosine similarity values between concept words and anchors for two models simultaneously (T0). We follow the comparative visualization guidelines and apply two strategies that enable the analysis of overlapping concepts, models, and word similarity patterns. First, we provide a summary of the two models. We, therefore, display only the contours of their word positions; more details (e.g., word exact positions) are displayed on demand. During the design process, we created several alternative representations to visually separate the two models. Each designed alternative was discussed with a group of visual analytics experts to critically assess the representation's advantages and limitations. In particular, we created representations that showed two types of the density of the visualized words, i.e., discrete as well as continuous. The discrete representation displayed the density regions through triangles arranged on a grid layout, whereby each model was represented with triangles of different sizes and opacity (smaller rectangles with higher opacity for the target model, see design A in the side figure). The continuous representation summarized the models through their contours (see design B in the side figure). After several discussions, the latter was selected as the final design due to its visual smoothness and limited clutter. The final design is as follows: the first (i.e., source) model is displayed only through contour borders. Since the words themselves are not visible, we use multiple contour lines to highlight the density of the word-occurrence regions. The second (i.e., target) model is displayed through a filled-out area of the contour regions with transparency. In addition to the model summarization, we apply the scan sequentially strategy to enable the analysis of word similarity changes. For this purpose, we implemented filter buttons that can be used to highlight words that have common properties with respect to their positional changes (i.e., their position in the source model compared to their position in the target model in the 2D space). In particular, we measure the angle between the word's position in the source and the target model. By hovering over one of the filter buttons , words with similar positional changes are highlighted in the visualization. The buttons themselves are colored according to the anchor to which words in the target model become more similar in comparison to the source model. An example of the word filtering is shown in Fig. <ref type="figure" target="#fig_0">2</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Concept Embedding Projection</head><p>The second explanation method displays the words in a 2D visualization, whereby the 2D positions are obtained using a projection technique such as PCA on the embedding vectors. This explanation visually partitions the representation space (T1) and supports the analysis of concept intersections (T2). Since in the Concept Embedding Similarity explanation we compute the similarity on high-dimensional vectors, this representation shows the similarity from a different modeling perspective.</p><p>(1) Single Model Explanation -The explanation displays words within one or two concepts, depending on whether the user wants to analyze one concept or the overlap of two (un)related concepts. Like in every visualization, we display words as rectangles and, by default, show labels for words that do not overlap. To support the readability of dense regions, we designed and discussed several design alternatives. First, we displayed words using a scatterplot technique, which is common for displaying projection data (design A  in the side figure). Since the goal of the visualization is to clearly show concept intersections (T2), however, words in the projection often overlap, this representation was not feasible. Second, we applied a kernel density estimation algorithm on the projected words to estimate and visualize the densest regions in the 2D space. We first represented the density through triangles displayed in a grid layout, whereas the density value was mapped to the triangles' opacity (design B in the side figure). Similar to the simple scatterplot, it was difficult to detect concept intersections easily. Thus, in the final design, we use multiple contours showing the estimated density of the different regions (Fig. <ref type="figure" target="#fig_2">4</ref>). It allows detecting not only the densest regions but also words with unexpected associations (T3) (i.e., outliers).</p><p>(2) Model Comparison Explanation -Our goal is to display intersections and positional changes of one or two concept word lists. The challenge of this representation is grounded in the artifacts of the applied projection techniques. In particular, since we rely on projection techniques to compute word coordinates, the visualization lacks an interpretable point of reference; projection techniques typically come with artifacts such as rotation or flipping of the representation space, making the comparison of two spaces difficult. Like in all other visualizations, the user can explore model differences in a juxtaposition design since the single model explanations are always placed next to each other on the screen (as shown in Fig. <ref type="figure" target="#fig_2">4b, left</ref>). The juxtaposition has limitations, though. If the compared models produce different embedding spaces (which is the case for most of the model and layer comparisons), they produce 2D spaces that are difficult to align.</p><p>The insufficiency of the superposition design is depicted in the side figure. There, we represent a word's positional changes through lines, whereas a line connects the word's position in the source model with the position in the target model. Due to rotation artifacts, the comparison of word changes is restricted even if the changes are minor. Thus, for projection comparison purposes, we apply the third design alternative, i.e., the explicit encoding design (as shown in Fig. <ref type="figure" target="#fig_2">4b, right</ref>).</p><p>For the explicit encoding, we first define relationships to encode in the visualization <ref type="bibr" target="#b18">[19]</ref>, i.e., we explain the projection changes through word nearest neighbors in the 2D space. In particular, after computing the projection's coordinates, we compute ten nearest neighbors for each word and store them as attributes in the data structure. When the user explores two models according to their embedding projections, we visually explain the neighborhood overlaps. This, according to design guidelines <ref type="bibr" target="#b18">[19]</ref>, is an example of the summarize strategy. Unlike the Concept Embedding Similarity visualization, we display only a single word's instance in the visualization. Its 2D coordinates, by default, are coordinates from the source model. The user can change it by clicking on the model's name in the visualization (shown in Fig. <ref type="figure" target="#fig_2">4b</ref>, right). The neighborhood changes are displayed as follows. For each word, we measure the neighborhood overlap (the number of equal neighbors in the source and target model) and map it to the size of the word's rectangle representation. The higher the overlap, the larger the rectangle and the lower the opacity. Moreover, we add horizontal lines to the rectangle, each showing the nearest neighbors from the particular concept's pole. As shown in the side figure, in the pre-trained BERT the person-name Maverick is more similar to countries (blue and green lines on the left-hand-side) than person names; in the conll2003 named entity recognizer, this word Fig. <ref type="figure">5</ref>: Words with similar neighborhoods can be filtered by selecting particular glyphs. In conll2003 named entity recognizer, country names Jordan and Chad are more similar to person names than countries.</p><p>becomes more similar to person names (yellow and pink lines on the right-hand-side of the rectangle). An example of two models with similar word neighborhoods is shown in Fig. <ref type="figure" target="#fig_2">4a</ref> and with different word neighborhoods -in Fig. <ref type="figure" target="#fig_2">4b</ref>. If the word neighborhoods change, then rectangles are smaller with a higher opacity, as shown in Fig. <ref type="figure" target="#fig_2">4b</ref>. In addition to the summarize strategy, we support the scan sequentially strategy to enable the analysis of word neighborhood changes. The users can filter words based on their neighborhoods by clicking on the glyph representations displayed on top of the visualization. The filtered words are highlighted; the rest are faded out (shown in Fig. <ref type="figure">5</ref>). On mouse over a word, its nearest neighbors in the source model are highlighted; on click, the nearest neighbors in the target model are highlighted, enabling a simple neighborhood comparison.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Concept Prediction Similarity</head><p>The third visualization can be used on adapters that have been trained on two-class classification tasks. It explains the prediction similarity of two models that are trained on the same task, e.g., whether two sentiment classifiers produce similar prediction outcomes, and connects the representation space and the model's behavior (T4). For this task, the user has to select one concept; the model then predicts class labels for the words' assigned sentences.</p><p>(1) Single Model Explanation -To provide an overview of prediction similarity, we aggregate the label information for all sentences in which the word is used in the corpus and use the average prediction to determine the word's x-coordinate in the visualization. In particular, we divide the number of sentences having the first prediction label (e.g., NEGATIVE sentiment) by the total number of sentences for the particular word; the more predictions with the first class label -the closer the point is to the beginning of the x-axis. If the predictions are equal for both class labels, the word is placed in the middle of the x-axis. The ycoordinate is determined by the word's position in the particular word list. The words themselves are displayed as rectangles.</p><p>(2) Model Comparison Explanation -In the comparison visualization, our goal is to show the prediction differences between two models (T0). Since in this visualization we have clear anchors (the prediction labels), we can apply a similar design approach as for the Concept Embedding Similarity plot. In particular, we use both juxtaposition as well as superposition designs. In the superposition design, both models are represented in the same visualization, as shown in Fig. <ref type="figure" target="#fig_3">6</ref>. We stick to the same design as for the Concept Embedding Similarity plot and first summarize the model predictions through contours. The source model is represented through the contour's borders; the target model's contours are filled out with a decreased opacity. The user can click on the filtering icons displayed on top of the visualization; the prediction changes are highlighted accordingly, supporting the scan sequentially strategy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Explanation Details</head><p>When explaining model changes, researchers usually try to find the reasons for particular patterns in the data. Thus, we designed three visualizations to explain patterns in the comparison visualizations.</p><p>Context Concordance View -The patterns in the Concept Embedding Similarity visualization can be influenced by the word contexts (sentences) from which the contextualized word embeddings are extracted. Thus, for this visualization, we added a Context Concordance View that lists all sentences in which a word is used in the corpus (shown in Fig. <ref type="figure">1</ref>, right). The view is displayed when clicking on the particular word in the Concept Embedding Similarity visualization. There, the selected word is highlighted for a better comparison.</p><p>Projection Artifact View -We propose a dense pixel visualization to explore the latent space and reveal semantically similar embeddings. The pixel visualization is inspired by Shin et al. <ref type="bibr" target="#b62">[63]</ref> stripe-based visualization of word embeddings. The primary goal is to create a compact visual summary of the embeddings with all dimensions without using dimensionality reduction methods (e.g., PCA). The pixel visualization displays each embedding as a vertical pixel bar, a grid-shaped column where each colored pixel (rectangle) is an embedding feature value. Herefore, we normalize the embeddings to the unit length and color the pixels according to a diverging color scheme. Then we place the pixel bars next to each other on the x-axis, producing a dense pixel visualization. The y-axis displays the 768 embedding dimensions, and the rows are ordered by the median of the visualized embedding dimensions to highlight block and band patterns <ref type="bibr" target="#b1">[2]</ref>. The x-axis can be reordered by linking and brushing in the single model explanations to interactively create clusters to highlight and display as a block of embeddings. Alternatively, the embeddings can be clustered using HDBSCAN <ref type="bibr" target="#b7">[8]</ref> using cosine similarity to detect clusters of similar embeddings. We can explore clusters in latent space through clustering without relying on dimensionality reduction methods, which typically produce some artifacts. Overall, comparing the colored pixel bars enables us to perceive pairwise similarities between the embeddings and generate new insights into the latent space, such as identifying groups of similar embeddings, meaningful embedding dimensions, or outliers.</p><p>Prediction View -To explore the exact prediction differences in the Concept Prediction Similarity comparison visualization, we display the predicted labels for all sentences assigned to a word in the Prediction View (shown in Fig. <ref type="figure">1</ref>, right). The view is displayed when selecting a word in the Concept Prediction Similarity visualization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">EVALUATION</head><p>We conducted expert case studies <ref type="bibr" target="#b59">[60]</ref> with the experts from the requirement analysis (see Sect. 3) to assess initial feedback on the visualization sufficiency for model comparison tasks. We further gathered positive (informal) feedback from two computational linguistic professors on the designed workspace. We present insights created for three out of six models introduced in Sect. 4.2: the pre-trained BERT, the debiasing adapter for BERT by Lauscher et al. <ref type="bibr" target="#b33">[34]</ref>, and the conll2003 named entity recognizer. We plan to extend the study with more participants to quantitatively evaluate the usability of the interface.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Expert Study Setup</head><p>The following insights were created collaboratively with two experts in natural language processing tasks. The study was conducted online in the form of a video conference. The experts had two main tasks: <ref type="bibr" target="#b0">(1)</ref> to investigate models related to bias and (2) to explore the limitations of a named entity recognition model. The experts further analyzed predictions for sentiment classifiers (T4) as described in Sect. 5.3; however, they are not included in the case study description below due to the paper's space considerations. The study was concluded with a semi-structured interview about the workspace's usability.   <ref type="bibr" target="#b33">[34,</ref><ref type="bibr" target="#b70">71]</ref>. Their produced spaces differ from the contextualized ones, though. Although context-0 embeddings suggest that the debiasing adapter by <ref type="bibr" target="#b33">[34]</ref> inverts the gender bias of the pre-trained BERT, the PCA projection on contextualized embeddings shows that the adapter successfully eliminates the gender information.</p><p>Data -The data for the study included the 10 human-interpretable concepts introduced in Sect. 4.1. The contextualized word embedding representations were extracted from the Yelp dataset <ref type="bibr" target="#b72">[73]</ref>, whereby each word in the concept list was represented by up to 300 contexts. Tasks -For the analysis related to bias detection, the interface provides the debiasing model trained by Lausher et al. <ref type="bibr" target="#b34">[35]</ref>. We use their evaluation results as ground truth to investigate whether the insights can be replicated using our workspace. In particular, the authors show that the model is effective in attenuating gender biases according to most of the applied evaluation methods. However, the results of the Word Embedding Association Test (WEAT) <ref type="bibr" target="#b6">[7]</ref> are less successful. The WEAT test measures the association between two target word sets (e.g., male pronouns) and (e.g., female pronouns) based on their mean cosine similarity to words from two attribute sets (e.g., science terms) and (e.g., art terms) that is measured on context-0 (i.e., static <ref type="bibr" target="#b34">[35]</ref>) word embeddings. Lauscher et al. observe that according to the WEAT test, the pretrained BERT model is insignificantly biased; however, the debiasing adapter does not reduce the bias but instead -inverts it. The participants thus received the task to evaluate the particular adapter regarding two specific analysis tasks: (1) to inspect how the embedding space is partitioned for gender-related concepts (T1) and ( <ref type="formula">2</ref>) to explore genderrelated concept intersections (T2).</p><p>Their second task was to analyze the conll2003 named entity recognizer concerning its learning capabilities of specific named entity categories such as person names and countries. Their particular analysis tasks were to investigate whether the model partitions the embedding space according to the different categories (T1), whether there are intersections between the categories (T2), and whether the model produces 'unexpected' associations (T3) between specific named entities.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Expert Case Studies</head><p>In the following, we describe gained insights for the specified tasks.</p><p>(Task 1) Bias in Language Models -To gain insights into the gender-related concept representation and their intersections, the participants investigated the Concept Embedding Similarity visualization. They selected the pre-trained BERT and debiasing models and analyzed the word similarities between different concepts (e.g., person names as shown in Fig. <ref type="figure" target="#fig_4">7</ref>) to pronouns that were displayed as anchors in the visualization. The visualization revealed that in the upper layers (e.g., layer 11) of the pre-trained BERT, context-0 embeddings for person names are slightly more similar to male pronouns than female pronouns, but the difference is insignificant. However, in debiasing adapter, most of these person names (even male person names) are more similar to female pronouns. Similar patterns could be observed for other concepts (e.g., gender-related stereotypes, countries), which matches the observations by Lauscher et al. <ref type="bibr" target="#b33">[34]</ref>. It is important to notice that this 'bias inversion' is visible only for context-0 embeddings. When exploring the relationships between the same concepts computed on contextualized word embeddings (in Fig. <ref type="figure" target="#fig_4">7</ref>), both Concept Embedding Similarity and Concept Embedding Projection visualizations show that the debiasing adapter was able to eliminate the gender information -the visualizations show no separation between the person-name and pronoun concepts. However, in the pre-trained BERT, female person names are more similar to female pronouns and male person names are more similar to male pronouns. The visualizations reveal that most of the models obtain the gender information from the word's context, and it is not encoded in the word (e.g., person name) itself. The only exception is the sst-2 sentiment classifier; there, even context-0 embeddings get separated by gender (side figure). Different to other adapters, the sst-2 model is trained on phrases extracted from Stanford parse trees rather than full sentences. Thus, words in isolation that are used to extract the context-0 embeddings present an unnatural input to most of the models <ref type="bibr" target="#b5">[6]</ref>; however, the input is less unnatural for the sst-2 model since some of its training instances are one or two words long.</p><p>(Task 2) Named Entity Recognition -To analyze the learning capabilities of the conll2003 named entity recognizer, the participants explored the Concept Embedding Similarity visualization for the concept low/high-GDP countries -two word lists, each grouping countries with a similar GDP rank according to 2020 statistics. As shown in the side figure, the conll2003 model learns that most of the countries are similar without encoding their welfare (see the top-right corner). By exploring the word positions, one can see that the model does not recognize the country Eswatini since its similarity to both low-GDP and high-GDP countries is low (0.31) in comparison to other countries that have a similarity of circa 0.8. Next, the participants analyzed the model's distinction between person names and country names -a typical task for a named entity recognizer. The Concept Embedding Projection visualization of the two concepts is shown in Fig. <ref type="figure" target="#fig_2">4</ref>. In the early layers, both models produce similar word neighborhoods and the person names and country names have a poor separation. In upper layers (e.g., layer 11 in Fig. <ref type="figure" target="#fig_2">4b</ref>), the projection of conll2003 embeddings displays four clusters. One cluster contains country names (Fig. <ref type="figure">8</ref> cluster A) and another -person names (Fig. <ref type="figure">8 cluster B</ref>). The neighborhoods of the two smaller clusters are similar to those in the pre-trained BERT, suggesting that the conll2003 model did not capture any new properties for these particular words. By interactively exploring the word neighborhoods, one can observe that one cluster consists of rare person names (e.g., Nevaeh), whereas the other contains relatively long country names (e.g., Trinidad and Tobago). Since the visualizations show the context-0 embeddings, the person names are not separated by gender. To investigate whether the four clusters are artifacts generated by the PCA projection, the embeddings values were displayed in the Projection Artifact View. Fig. <ref type="figure">8</ref> shows that the values for embedding vectors within one cluster produce similar patterns, suggesting that the four clusters are not the projection's generated artifacts. The separation between long and short country names, as well as common and rare person names, might be a reason of long and rare words not being in the BERT's vocabulary; thus, this might be an artifact of averaging sub-token embedding vectors and must be further investigated.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Preliminary Expert Feedback</head><p>The experts provided positive feedback concerning the workspace's applicability for model evaluation and comparison tasks. They described the interface to be intuitive and easy to use. The experts found it useful having the option to choose between different concepts, and in particular-with respect to bias-different ways to quantify it. This allows them to evaluate the models along 'different axes', and this is in accordance with works that have shown that bias is manifested in multiple ways. The experts also appreciated the ability to analyze both the representations and the predictions that provide two complementary ways to explain a model: the prediction-based view focuses on the more high level 'interface' (i.e., model's predictions) while the representation analysis focuses on its actual working mechanism (i.e., how these predictions are derived). The workspace also demonstrates and makes use of one of the advantages of adapters over other fine-tuning methods -the fact they are easily integrated into one pre-trained model without having to fine-tune a different model per task.</p><p>One important advantage of our workspace was described by the Fig. <ref type="figure">8</ref>: In Projection Artifact View, the user can explore embedding vectors aligned as columns in a pixel visualization. We use a bipolar color scale to show vector values (from min blue to max orange).</p><p>experts as follows. Adapters are usually tested in-domain (e.g., people train for the sentiment task and evaluate on sentiment prediction). The 'side-effects' the training has on other aspects are often unaddressed. Thus, it was appreciated that the workspace puts emphasis on evaluating a given adapter according to metrics that are not necessarily related to the main tasks it was trained on. The interface with its diverse concepts brings another advantage, particularly for the bias evaluation tasks. According to the experts, while certain notions of bias are well studied, the more interesting cases are those which are more subtle and less intuitive or straightforward. The workspace makes it easier to explore the representation space of the models and potentially discover new notions of bias, or more generally, undesired properties of the model in question, as depicted in the Sect. 6.2. The limitations of the workspace are formulated as research opportunities in the following section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">DISCUSSION AND RESEARCH OPPORTUNITIES</head><p>In the previous section, we presented how we can use our workspace to gain insights into model specificities. During the design and evaluation process, we discovered several opportunities for future research.</p><p>Comparison of Numerous Models -Currently, our workspace supports the direct comparison of two models at a time. An interesting research challenge would be to display more than two models in the same comparison visualization. While designing our visualizations, we faced challenges in how to select designs that allow visually separate the two models. By displaying more than two models simultaneously, one would need to come up with new visual design alternatives. Supporting Model Fine-Tuning -Our work is a step toward effectively comparing adapter models. It is still limited to explorative tasks and, at this point, does not actively suggest which actions to undertake to improve the adapter performances. We see, however, this as a very important direction for future work. The system should provide insights into the models' strengths and limitations and, in an ideal case, also provide hints or suggestions on which steps should be overtaken (e.g., adaptation of the training dataset) to improve the models' performances.</p><p>Visual Explanations Combined with Probing Classifiers -During our collaboration, the NLP researchers mentioned several potential extensions concerning the functionality of the workspace. Since they commonly train classifiers to investigate concept intersections, they mentioned this as an extension to the visual explanation methods. The two methods used in parallel could increase their trust in the generated insights. In particular, if the projection and the classifier produce similar results, it is more likely to be true and less likely to be an artifact of the particular method in use. Support for Adapter Training -Currently, our workspace supports the analysis of adapters from the AdapterHub repository. The framework, however, supports different adapter composition techniques, such as adapter stacking <ref type="bibr" target="#b49">[50]</ref> as well as their fusion <ref type="bibr" target="#b47">[48]</ref>. We plan to extend the workspace in a way that researchers could train new adapters in the interface by applying the different adapter composition methods and directly evaluate their created representation spaces, which, hopefully, would lead to better-performing models for downstream tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">CONCLUSION</head><p>We presented a novel visual analytics workspace for the analysis and comparison of LMs that are adapted for different masked language modeling and downstream classification tasks. The design was motivated by requirements gathered during a literature review and collaboration with NLP researchers. We introduced three new comparison visualizations: Concept Embedding Similarity, Concept Embedding Projection, and Concept Prediction Similarity that were designed by applying the comparative visualization guidelines by Gleicher <ref type="bibr" target="#b18">[19]</ref>. We show the applicability of the workspace through expert case studies, confirm findings from the related work, and generate new insights into adapter learning properties. A demo is available as part of the LingVis framework <ref type="bibr" target="#b12">[13]</ref> under: https://adapters.demo.lingvis.io/.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 2 :</head><label>2</label><figDesc>Fig. 2: The workspace contains three views: Adapter Composition View (A), which lists adapters from AdapterHub repository, Explanation Composition View (B) for modular explanation generation, and Visual Comparison View (Workspace) for model comparison. Here: contrary to the rotten-tomatoes model, the context-0 embeddings of the sst-2 sentiment classifier strongly encode the two polarities of human qualities.</figDesc><graphic url="image-4.png" coords="3,64.38,73.65,189.69,191.13" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>(a) In layer 11, the PCA projection generates almost identical 2D spaces for contextualized embeddings extracted from pre-trained BERT and conll2003 named entity recognizer (see the low opacity of word rectangles in the plot on the right hand side). In both models, the person names get separated by gender. (b) In layer 11, the PCA projection of context-0 embeddings from conll2003 named entity recognizer produces four distinct clusters. Two clusters (with low opacity) have similar neighborhoods in both models. These are rare person names (e.g., Nevaeh) and long country names (e.g., Trinidad and Tobago). Person names do not encode gender.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 4 :</head><label>4</label><figDesc>Fig. 4: We provide two different types of model comparison designs for analyzing concept embedding projections, i.e., juxtapositon where two models are displayed next to each other and explicit encoding that summarizes embedding changes through word neighborhood overlaps.</figDesc><graphic url="image-16.png" coords="6,82.95,233.91,373.60,139.70" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 6 :</head><label>6</label><figDesc>Fig. 6: Concept Prediction Similarity shows two sentiment classifiers (see A). Compared to the sst-2 model (contour borders), the rottentomatoes model (filled areas) classifies sentences with occurrences of positive and negative human qualities more often as NEGATIVE (B).</figDesc><graphic url="image-23.png" coords="7,314.44,546.72,99.29,88.27" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 7 :</head><label>7</label><figDesc>Fig.7: Context-0 embeddings are used for evaluation purposes in Word Embedding Association Tests<ref type="bibr" target="#b33">[34,</ref><ref type="bibr" target="#b70">71]</ref>. Their produced spaces differ from the contextualized ones, though. Although context-0 embeddings suggest that the debiasing adapter by<ref type="bibr" target="#b33">[34]</ref> inverts the gender bias of the pre-trained BERT, the PCA projection on contextualized embeddings shows that the adapter successfully eliminates the gender information.</figDesc><graphic url="image-27.png" coords="8,64.03,73.00,284.46,244.32" type="bitmap" /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0">https://github.com/Adapter-Hub/adapter-transformers 1188</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1">https://huggingface.co/</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2">https://github.com/cisnlp/bias-in-nlp</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3">https://github.com/d3/d3-contour</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS</head><p>This paper was funded by the Deutsche Forschungsgemeinschaft (DFG, German Research Foundation) within projects BU 1806/10-2 "Questions Visualized" of the FOR2111, and the ETH AI Center.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Parallel Embeddings: A Visualization Technique for Contrasting Learned Representations</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">L</forename><surname>Arendt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Nur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Fair</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Dou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 25th Int. Conf. on Intelligent User Interfaces</title>
				<meeting>of the 25th Int. Conf. on Intelligent User Interfaces</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="259" to="274" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Matrix reordering methods for table and network visualization</title>
		<author>
			<persName><forename type="first">M</forename><surname>Behrisch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Bach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Henry Riche</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Schreck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-D</forename><surname>Fekete</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Graphics Forum</title>
				<imprint>
			<publisher>Wiley Online Library</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="693" to="716" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Visually Analyzing Contextualized Embeddings</title>
		<author>
			<persName><forename type="first">M</forename><surname>Berger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Visualization Conf. (VIS)</title>
				<meeting><address><addrLine>Los Alamitos, CA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2020-10">oct 2020</date>
			<biblScope unit="page" from="276" to="280" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Language (technology) is power: A critical survey of &quot;bias&quot; in NLP</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">L</forename><surname>Blodgett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Barocas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Daum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Iii</forename></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wallach</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Association for Computational Linguistics</title>
				<meeting>of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Online</publisher>
			<date type="published" when="2020-07">July 2020</date>
			<biblScope unit="page" from="5454" to="5476" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Embedding Comparator: Visualizing Differences in Global Structure and Local Neighborhoods via Small Multiples</title>
		<author>
			<persName><forename type="first">A</forename><surname>Boggust</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Carter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Satyanarayan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">27th Int. Conf. on Intelligent User Interfaces</title>
				<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="746" to="766" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Interpreting Pretrained Contextualized Representations via Reductions to Static Embeddings</title>
		<author>
			<persName><forename type="first">R</forename><surname>Bommasani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Cardie</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.acl-main.431</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</title>
				<meeting>the 58th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2020-07">July 2020</date>
			<biblScope unit="page" from="4758" to="4781" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Semantics derived automatically from language corpora contain human-like biases</title>
		<author>
			<persName><forename type="first">A</forename><surname>Caliskan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Bryson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Narayanan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">356</biblScope>
			<biblScope unit="issue">6334</biblScope>
			<biblScope unit="page" from="183" to="186" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Density-based clustering based on hierarchical density estimates</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Campello</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Moulavi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sander</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Pacific-Asia Conf. on Knowledge Discovery and Data Mining</title>
				<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="160" to="172" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Considering visual variables as a basis for information visualisation</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S T</forename><surname>Carpendale</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PRISM</title>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Attention flows: Analyzing and comparing attention mechanisms in language models</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">F</forename><surname>Derose</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Berger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Visualization and Computer Graphics</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M.-W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
		<author>
			<persName><surname>Bert</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1810.04805</idno>
		<title level="m">Pre-training of deep bidirectional transformers for language understanding</title>
				<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">A Systematic Analysis of Morphological Content in BERT Models for Multiple Languages</title>
		<author>
			<persName><forename type="first">D</forename><surname>Edmiston</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2004.03032</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">lingvis.io -A Linguistic Visual Analytics Framework</title>
		<author>
			<persName><forename type="first">M</forename><surname>El-Assady</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Jentner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Sperrle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Sevastjanova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Hautli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Butt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Keim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Association for Computational Linguistics: System Demonstrations</title>
				<meeting>of the Association for Computational Linguistics: System Demonstrations</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="13" to="18" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Adversarial removal of demographic attributes from text data</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Elazar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Goldberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 2018 Conf. on Empirical Methods in Natural Language Processing</title>
				<meeting>of the 2018 Conf. on Empirical Methods in Natural Language essing</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="11" to="21" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">How Contextual are Contextualized Word Representations? Comparing the Geometry of BERT, ELMo, and GPT-2 Embeddings</title>
		<author>
			<persName><forename type="first">K</forename><surname>Ethayarajh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Conf. on Empirical Methods in Natural Language Proc. and the Int. Joint Conf. on Natural Language Processing (EMNLP-IJCNLP)</title>
				<meeting>of the Conf. on Empirical Methods in Natural Language . and the Int. Joint Conf. on Natural Language essing (EMNLP-IJCNLP)<address><addrLine>China</addrLine></address></meeting>
		<imprint>
			<publisher>ACL, Hong Kong</publisher>
			<date type="published" when="2019-11">Nov. 2019</date>
			<biblScope unit="page" from="55" to="65" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Unsupervised domain adaptation by backpropagation</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Ganin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Lempitsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Int. Conf. on Machine Learning</title>
				<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1180" to="1189" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<author>
			<persName><forename type="first">I</forename><surname>Garrido-Muoz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Montejo-Rez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Martnez-Santiago</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">A</forename><surname>Urea-Lpez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">A survey on bias in deep nlp</title>
				<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page">3184</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Training and domain adaptation for supervised text segmentation</title>
		<author>
			<persName><forename type="first">G</forename><surname>Glava</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ganesh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Somasundaran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 16th Workshop on Innovative Use of NLP for Building Educational Applications</title>
				<meeting>of the 16th Workshop on Innovative Use of NLP for Building Educational Applications</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2021-04">Apr. 2021</date>
			<biblScope unit="page" from="110" to="116" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Considerations for visualizing comparison</title>
		<author>
			<persName><forename type="first">M</forename><surname>Gleicher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="413" to="423" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Breaking NLI Systems with Sentences that Require Simple Lexical Inferences</title>
		<author>
			<persName><forename type="first">M</forename><surname>Glockner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Shwartz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Goldberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 56th Association</title>
				<meeting>of the 56th Association</meeting>
		<imprint>
			<publisher>ACL</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="650" to="655" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Don&apos;t stop pretraining: Adapt language models to domains and tasks</title>
		<author>
			<persName><forename type="first">S</forename><surname>Gururangan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Marasovi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Swayamdipta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Lo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Beltagy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Downey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Association for Computational Linguistics</title>
				<meeting>of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Online</publisher>
			<date type="published" when="2020-07">July 2020</date>
			<biblScope unit="page" from="8342" to="8360" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Unsupervised domain adaptation of contextualized embeddings for sequence labeling</title>
		<author>
			<persName><forename type="first">X</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Eisenstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
				<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Interactive analysis of word vector embeddings</title>
		<author>
			<persName><forename type="first">F</forename><surname>Heimerl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gleicher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Graphics Forum</title>
				<imprint>
			<publisher>Wiley Online Library</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="253" to="265" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">embcomp: Visual interactive comparison of vector embeddings</title>
		<author>
			<persName><forename type="first">F</forename><surname>Heimerl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Kralj</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Moller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gleicher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Visualization and Computer Graphics</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">exBERT: A Visual Analysis Tool to Explore Learned Representations in Transformers Models</title>
		<author>
			<persName><forename type="first">B</forename><surname>Hoover</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Strobelt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gehrmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Association for Computational Linguistics, System Demonstrations. ACL</title>
				<meeting>of the Association for Computational Linguistics, System Demonstrations. ACL</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Parameter-efficient transfer learning for nlp</title>
		<author>
			<persName><forename type="first">N</forename><surname>Houlsby</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Giurgiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Jastrzebski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Morrone</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>De Laroussilhe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gesmundo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Attariyan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gelly</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Int. Conf. on Machine Learning</title>
				<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="2790" to="2799" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Universal language model fine-tuning for text classification</title>
		<author>
			<persName><forename type="first">J</forename><surname>Howard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ruder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Association for Computational Linguistics</title>
		<title level="s">Long Papers</title>
		<meeting>of the Association for Computational Linguistics<address><addrLine>Melbourne, Australia</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018-07">July 2018</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="328" to="339" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Attention is not explanation</title>
		<author>
			<persName><forename type="first">S</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">C</forename><surname>Wallace</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL</title>
				<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">What does BERT learn about the structure of language?</title>
		<author>
			<persName><forename type="first">G</forename><surname>Jawahar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Sagot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Seddah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Association for Computational Linguistics</title>
				<meeting>of the Association for Computational Linguistics<address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019-07">July 2019</date>
			<biblScope unit="page" from="3651" to="3657" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Principal component analysis: a review and recent developments</title>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">T</forename><surname>Jolliffe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Cadima</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Philosophical Trans. of the Royal Society A: Mathematical, Physical and Engineering Sciences</title>
		<imprint>
			<biblScope unit="volume">374</biblScope>
			<biblScope unit="page">20150202</biblScope>
			<date type="published" when="2016">2065. 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Pivot-based transfer learning for neural machine translation between non-English languages</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Petrov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Petrushkov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Khadivi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Ney</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D19-1080</idno>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 2019 Conf. on Empirical Methods in Natural Language Processing and the 9th Int. Joint Conf. on Natural Language Processing (EMNLP-IJCNLP)</title>
				<meeting>of the 2019 Conf. on Empirical Methods in Natural Language essing and the 9th Int. Joint Conf. on Natural Language essing (EMNLP-IJCNLP)<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019-11">Nov. 2019</date>
			<biblScope unit="page" from="866" to="876" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Overcoming catastrophic forgetting in neural networks</title>
		<author>
			<persName><forename type="first">J</forename><surname>Kirkpatrick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Pascanu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Rabinowitz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Veness</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Desjardins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">A</forename><surname>Rusu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Milan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Quan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Ramalho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Grabska-Barwinska</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Hassabis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Clopath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Kumaran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Hadsell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the National Academy of Sciences</title>
				<meeting>of the National Academy of Sciences</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">114</biblScope>
			<biblScope unit="page" from="3521" to="3526" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Multidimensional scaling by optimizing goodness of fit to a nonmetric hypothesis</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">B</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychometrika</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="27" />
			<date type="published" when="1964">1964</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Sustainable modular debiasing of language models</title>
		<author>
			<persName><forename type="first">A</forename><surname>Lauscher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Lueken</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Glava</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: EMNLP 2021</title>
				<meeting><address><addrLine>Punta Cana, Dominican Republic</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2021-11">Nov. 2021</date>
			<biblScope unit="page" from="4782" to="4797" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Common Sense or World Knowledge? Investigating Adapter-Based Knowledge Injection into Pretrained Transformers</title>
		<author>
			<persName><forename type="first">A</forename><surname>Lauscher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Majewska</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">F R</forename><surname>Ribeiro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Gurevych</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Rozanov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Glava</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of Deep Learning Inside Out (DeeLIO): The First Workshop on Knowledge Extraction and Integration for Deep Learning Architectures</title>
				<meeting>of Deep Learning Inside Out (DeeLIO): The First Workshop on Knowledge Extraction and Integration for Deep Learning Architectures</meeting>
		<imprint>
			<publisher>Online</publisher>
			<date type="published" when="2020-11">Nov. 2020</date>
			<biblScope unit="page" from="43" to="49" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Embeddingvis: A visual analytics approach to comparative network embedding inspection</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">S</forename><surname>Njotoprawiro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Haleem</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2018 IEEE Conf. on Visual Analytics Science and Technology (VAST)</title>
				<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="48" to="59" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Open Sesame: Getting inside BERT&apos;s Linguistic Knowledge</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">C</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Frank</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the ACL Workshop BlackboxNLP: Analyzing and Interpreting Neural Networks for NLP</title>
				<meeting>of the ACL Workshop BlackboxNLP: Analyzing and Interpreting Neural Networks for NLP<address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019-08">Aug. 2019</date>
			<biblScope unit="page" from="241" to="253" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Exploring versatile generative language model via parameter-efficient transfer learning</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Madotto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Fung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: EMNLP 2020</title>
				<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2020-11">Nov. 2020</date>
			<biblScope unit="page" from="441" to="459" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Visual exploration of semantic relationships in neural word embeddings</title>
		<author>
			<persName><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P.-T</forename><surname>Bremer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Thiagarajan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Srikumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Livnat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Pascucci</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="553" to="562" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Nlize: A perturbation-driven visual interrogation tool for analyzing and interpreting natural language inference models</title>
		<author>
			<persName><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Srikumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Pascucci</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P.-T</forename><surname>Bremer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="651" to="660" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Targeted Syntactic Evaluation of Language Models</title>
		<author>
			<persName><forename type="first">R</forename><surname>Marvin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Linzen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Conf. on Empirical Methods in Natural Language Processing</title>
				<meeting>of the Conf. on Empirical Methods in Natural Language essing<address><addrLine>Brussels, Belgium</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018-11">Oct.-Nov. 2018</date>
			<biblScope unit="page" from="1192" to="1202" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">UMAP: Uniform Manifold Approximation and Projection</title>
		<author>
			<persName><forename type="first">L</forename><surname>Mcinnes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Healy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Saul</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Grossberger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Open Source Software</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">29</biblScope>
			<biblScope unit="page">861</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">A survey on bias and fairness in machine learning</title>
		<author>
			<persName><forename type="first">N</forename><surname>Mehrabi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Morstatter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Saxena</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Lerman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Galstyan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Computing Surveys (CSUR)</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1" to="35" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<author>
			<persName><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1301.3781</idno>
		<title level="m">Efficient estimation of word representations in vector space</title>
				<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">A matter of time: Applying a data-users-tasks design triangle to visual analytics of time-oriented data</title>
		<author>
			<persName><forename type="first">S</forename><surname>Miksch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Aigner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computers &amp; Graphics</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="page" from="286" to="290" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Sanvis: Visual analytics for understanding self-attention networks</title>
		<author>
			<persName><forename type="first">C</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Na</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Jo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Shin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yoo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">C</forename><surname>Kwon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Noh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Choo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Visualization Conf. (VIS)</title>
				<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="146" to="150" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">GloVe: Global vectors for word representation</title>
		<author>
			<persName><forename type="first">J</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Manning</surname></persName>
		</author>
		<idno type="DOI">10.3115/v1/D14-1162</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
				<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)<address><addrLine>Doha, Qatar</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014-10">Oct. 2014</date>
			<biblScope unit="page" from="1532" to="1543" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title level="m" type="main">AdapterFusion: Non-destructive task composition for transfer learning</title>
		<author>
			<persName><forename type="first">J</forename><surname>Pfeiffer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kamath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rckl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Gurevych</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="487" to="503" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">AdapterHub: A framework for adapting transformers</title>
		<author>
			<persName><forename type="first">J</forename><surname>Pfeiffer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rckl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Poth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kamath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Vuli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ruder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Gurevych</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 2020 Conf. on Empirical Methods in Natural Language Processing</title>
				<meeting>of the 2020 Conf. on Empirical Methods in Natural Language essing</meeting>
		<imprint>
			<publisher>Online</publisher>
			<date type="published" when="2020">2020. 2020</date>
			<biblScope unit="page" from="46" to="54" />
		</imprint>
	</monogr>
	<note>Systems Demonstrations</note>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">MAD-X: An Adapter-Based Framework for Multi-Task Cross-Lingual Transfer</title>
		<author>
			<persName><forename type="first">J</forename><surname>Pfeiffer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Vuli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Gurevych</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ruder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 2020 Conf. on Empirical Methods in Natural Language Processing</title>
				<meeting>of the 2020 Conf. on Empirical Methods in Natural Language essing</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2020-11">Nov. 2020</date>
			<biblScope unit="page" from="7654" to="7673" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">A study of residual adapters for multi-domain neural machine translation</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">Q J M</forename><surname>Crego</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Yvon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Senellart</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Fifth Conf. on Machine Translation</title>
				<meeting>of the Fifth Conf. on Machine Translation</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2020-11">Nov. 2020</date>
			<biblScope unit="page" from="617" to="628" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
		<title level="m" type="main">Sentence Encoders on STILTs: Supplementary Training on Intermediate Labeled-data Tasks</title>
		<author>
			<persName><forename type="first">J</forename><surname>Phang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Fvry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">R</forename><surname>Bowman</surname></persName>
		</author>
		<idno>ArXiv, abs/1811.01088</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Monolingual adapters for zero-shot neural machine translation</title>
		<author>
			<persName><forename type="first">J</forename><surname>Philip</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Berard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Besacier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 2020 Conf. on Empirical Methods in Natural Language Processing (EMNLP)</title>
				<meeting>of the 2020 Conf. on Empirical Methods in Natural Language essing (EMNLP)</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2020-11">Nov. 2020</date>
			<biblScope unit="page" from="4465" to="4470" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">What to pre-train on? Efficient intermediate task selection</title>
		<author>
			<persName><forename type="first">C</forename><surname>Poth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Pfeiffer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>R"uckl'e</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Gurevych</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing</title>
				<meeting>the 2021 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Dominican Republic</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2021-11">Nov. 2021</date>
			<biblScope unit="page" from="10585" to="10605" />
		</imprint>
		<respStmt>
			<orgName>Online and Punta Cana</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Pre-trained models for natural language processing: A survey</title>
		<author>
			<persName><forename type="first">X</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science China Technological Sciences</title>
		<imprint>
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1872" to="1897" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Null it out: Guarding protected attributes by iterative nullspace projection</title>
		<author>
			<persName><forename type="first">S</forename><surname>Ravfogel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Elazar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Gonen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Twiton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Goldberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the</title>
				<meeting>of the</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="7237" to="7256" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Linear adversarial concept erasure</title>
		<author>
			<persName><forename type="first">S</forename><surname>Ravfogel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Twiton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Goldberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">D</forename><surname>Cotterell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 39th Int. Conf. on Machine Learning</title>
				<editor>
			<persName><forename type="first">K</forename><surname>Chaudhuri</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Jegelka</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><surname>Song</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Szepesvari</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><surname>Niu</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Sabato</surname></persName>
		</editor>
		<meeting>of the 39th Int. Conf. on Machine Learning</meeting>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2022-07">Jul 2022</date>
			<biblScope unit="volume">162</biblScope>
			<biblScope unit="page" from="17" to="23" />
		</imprint>
	</monogr>
	<note>Proc. of Machine Learning Research</note>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Probing Natural Language Inference Models through Semantic Fragments</title>
		<author>
			<persName><forename type="first">K</forename><surname>Richardson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">S</forename><surname>Moss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sabharwal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Association for the Advancement of Artificial Intelligence (AAAI)</title>
				<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="8713" to="8721" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">A Primer in BERTology: What We Know About How BERT Works</title>
		<author>
			<persName><forename type="first">A</forename><surname>Rogers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Kovaleva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rumshisky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Trans. of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="842" to="866" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Design Study Methodology: Reflections from the Trenches and the Stacks</title>
		<author>
			<persName><forename type="first">M</forename><surname>Sedlmair</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Meyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Munzner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2431" to="2440" />
			<date type="published" when="2012-12">Dec. 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Explaining Contextualization in Language Models using Visual Analytics</title>
		<author>
			<persName><forename type="first">R</forename><surname>Sevastjanova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A.-L</forename><surname>Kalouli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Beck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Hauptmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>El-Assady</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Association for Computational Linguistics, ACL. ACL</title>
				<meeting>of the Association for Computational Linguistics, ACL. ACL</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">LMFingerprints: Visual Explanations of Language Model Embedding Spaces through Layerwise Contextualization Scores</title>
		<author>
			<persName><forename type="first">R</forename><surname>Sevastjanova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A.-L</forename><surname>Kalouli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Beck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Hauptmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>El-Assady</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics Forum</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="295" to="307" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Interpreting word embeddings with eigenvector analysis</title>
		<author>
			<persName><forename type="first">J</forename><surname>Shin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Madotto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Fung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">32nd Conf. on Neural Information Processing Systems (NIPS 2018), IRASL workshop</title>
				<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Selecting good views of high-dimensional data using class consistency</title>
		<author>
			<persName><forename type="first">M</forename><surname>Sips</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Neubert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">P</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Hanrahan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Graphics Forum</title>
				<imprint>
			<publisher>Wiley Online Library</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="831" to="838" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Emblaze: Illuminating machine learning representations through interactive comparison of embedding spaces</title>
		<author>
			<persName><forename type="first">V</forename><surname>Sivaraman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Perer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">27th Int. Conf. on Intelligent User Interfaces</title>
				<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="418" to="432" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">S eq 2s eq-v is: A visual debugging tool for sequence-to-sequence models</title>
		<author>
			<persName><forename type="first">H</forename><surname>Strobelt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gehrmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Behrisch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Perer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Pfister</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Rush</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="353" to="363" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">LMdiff: A visual diff tool to compare language models</title>
		<author>
			<persName><forename type="first">H</forename><surname>Strobelt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Hoover</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Satyanaryan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gehrmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 2021 Conf. on Empirical Methods in Natural Language Processing: System Demonstrations</title>
				<meeting>of the 2021 Conf. on Empirical Methods in Natural Language essing: System Demonstrations<address><addrLine>Dominican Republic</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2021-11">Nov. 2021</date>
			<biblScope unit="page" from="96" to="105" />
		</imprint>
		<respStmt>
			<orgName>Online and Punta Cana</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Visualizing data using t-SNE</title>
		<author>
			<persName><forename type="first">L</forename><surname>Van Der Maaten</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of machine learning research</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">11</biblScope>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Attention is all you need</title>
		<author>
			<persName><forename type="first">A</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Polosukhin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 31st Int. Conf. on Neural Information Processing Systems, NIPS&apos;17</title>
				<meeting>of the 31st Int. Conf. on Neural Information essing Systems, NIPS&apos;17<address><addrLine>Red Hook, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Curran Associates Inc</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="6000" to="6010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">A Multiscale Visualization of Attention in the Transformer Model</title>
		<author>
			<persName><forename type="first">J</forename><surname>Vig</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Association for Computational Linguistics: System Demonstrations</title>
				<meeting>of the Association for Computational Linguistics: System Demonstrations<address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019-07">July 2019</date>
			<biblScope unit="page" from="37" to="42" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Multi-SimLex: A Large-Scale Evaluation of Multilingual and Crosslingual Lexical Semantic Similarity</title>
		<author>
			<persName><forename type="first">I</forename><surname>Vuli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Baker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">M</forename><surname>Ponti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Petti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Leviant</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Wing</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Majewska</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Bar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Malone</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Poibeau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Reichart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Korhonen</surname></persName>
		</author>
		<idno type="DOI">10.1162/colia00391</idno>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Controllable invariance through adversarial feature learning</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Hovy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Neubig</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
				<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">30</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">Character-level convolutional networks for text classification</title>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
				<editor>
			<persName><forename type="first">C</forename><surname>Cortes</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Lawrence</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><surname>Lee</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Sugiyama</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Garnett</surname></persName>
		</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="volume">28</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">Quantifying the Contextualization of Word Representations with Semantic Class Probing</title>
		<author>
			<persName><forename type="first">M</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Dufter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yaghoobzadeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Schtze</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: EMNLP 2020</title>
				<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2020-11">Nov. 2020</date>
			<biblScope unit="page" from="1219" to="1234" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
