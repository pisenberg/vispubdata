<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A Visual Analytics System for Improving Attention-based Traffic Forecasting Models</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Seungmin</forename><surname>Jin</surname></persName>
							<email>skyjin@unist.ac.kr</email>
						</author>
						<author>
							<persName><forename type="first">Hyunwook</forename><surname>Lee</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Cheonbok</forename><surname>Park</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Hyeshin</forename><surname>Chu</surname></persName>
							<email>hyeshinchu@unist.ac.kr</email>
						</author>
						<author>
							<persName><forename type="first">Yunwon</forename><surname>Tae</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Jaegul</forename><surname>Choo</surname></persName>
							<email>jchoo@kaist.ac.kr</email>
						</author>
						<author>
							<persName><forename type="first">Sungahn</forename><surname>Ko</surname></persName>
							<email>sako@unist.ac.kr</email>
						</author>
						<title level="a" type="main">A Visual Analytics System for Improving Attention-based Traffic Forecasting Models</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.2" ident="GROBID" when="2023-03-27T09:15+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Traffic Visualization</term>
					<term>Deep Learning</term>
					<term>Attention Model</term>
					<term>Speed Prediction</term>
					<term>Explainable Artificial Intelligence</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Fig. 1. Our system for analyzing how an attention-based deep learning model predicts traffic congestion. (a) filter view, (b) table view, (c) ground-truth&amp;prediction result comparison view, (d) a map with attention curves and clusters, and (e) attention heatmap view.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>To mitigate traffic congestion, which is a major issue in modern cities, a lot of effort has been devoted to developing methods for predicting future congestion to support drivers' route decisions <ref type="bibr" target="#b1">[2]</ref>. In particular, as many recent studies show that deep learning (DL) outperforms conventional methods in forecasting traffic congestion <ref type="bibr" target="#b60">[62]</ref> and the estimated time of arrival (ETA) <ref type="bibr" target="#b73">[75]</ref>, there have been numerous practical approaches for developing and deploying new DL models. For example, reporters in broadcasting centers announce which roads will be congested in the next 15, 30, and 60 minutes to help drivers avoid the possibly congested roads or change their driving schedule (i.e., Manuscript received <ref type="bibr" target="#b20">21</ref>   <ref type="bibr" target="#b35">[36]</ref>. Mobility industries, such as navigation service providers, also report that they have achieved greater than 40% accuracy in estimating travel time of drivers with DL <ref type="bibr" target="#b12">[13]</ref>.</p><p>But, many obstacles exist in improving DL models in the traffic domain. First, DL methods are black-box in nature <ref type="bibr" target="#b17">[18]</ref>, which means they do not show what they have learned during training or how they make predictions given input features. Second, traffic domain data is spatio-temporal, which is hard to analyze, as both space and time should be considered simultaneously. For example, when a road is congested because of an accident, there is a high chance that the roads linked to the road with the accident will soon become congested, but it is hard to estimate when the congestion happens and which neighboring roads would be affected <ref type="bibr" target="#b38">[39]</ref>. Third, traffic data is heterogeneous with extreme cases <ref type="bibr" target="#b38">[39,</ref><ref type="bibr" target="#b60">62,</ref><ref type="bibr" target="#b76">78]</ref> and easily affected by uncontrollable external factors (e.g., accidents). Thus the traffic prediction task is especially challenging in that the models need to learn not only spatio-temporal features from the data, but also how to respond to implicit external events on roads. The external factors could even vary by region <ref type="bibr" target="#b35">[36]</ref>, which further complicates to the models. Indeed, spatio-temporal analysis with a large space (e.g., major city's road network) and different time units (e.g., hours, days, months) is a nontrivial task <ref type="bibr" target="#b2">[3]</ref>.</p><p>In this work, we collaborate with domain experts to design a visual analytics (VA) system that supports users in effectively exploring how a DL model predicts future traffic conditions and in finding insights for performance improvements. We first perform task analysis with three domain experts and extract the system requirements needed to support the experts in answering questions that should be answered for their work. Then, we design a VA system, AttnAnalyzer, that provides three automated methods and visual interfaces for exploration. We incorporate the dynamic time warping (DTW) <ref type="bibr" target="#b55">[57]</ref> and Granger causality tests to support users in exploring spatio-temporal dependencies of roads, such as proceeding and lagging speed patterns. We also utilize a spectral clustering algorithm for grouping roads with similar speed patterns for automated methods. There are several visualizations in At-tnAnalyzer, including table, line chart, map and pixel views. The table view presents information of roads, such as speed trends, cluster index, and prediction accuracy. The map view allows spatial dependency analysis, while the line chart view reveals the temporal dependencies of roads. The pixel views have two sub-views to analyze attention information, extracted from an attention-based traffic forecasting model, called ST-GRAT. To validate hypotheses created from the system, we devise an attention enforcement method, which replaces the attention of problematic roads with those from the roads with low MAE error. For demonstration purposes, we use an attention-based traffic forecasting model because they show state-of-the-art performance and because experts have expressed that they extensively use attention-based DL models in navigation service.</p><p>To evaluate the system, we provide three case studies. In the first two case studies, we showcase how domain experts use the system to explore the spatio-temporal dependencies of two different large road networks. In the last case study, we show that the insights derived from the two case studies are meaningful for improving model performance, confirming with attention enforcement. Lastly, we provide domain expert feedback and discuss limitations and future work.</p><p>The main contributions of this work include the following: 1) a VA system design for exploring traffic forecasting model's behaviors from a spatio-temporal perspective, 2) incorporation of automated methods (DTW, Granger causality test, clustering) for visual temporal analysis, 3) development of an attention enforcement method, and 4) quantitative and qualitative evaluations of the system with three case studies, proven model's accuracy improvements with the attention enforcement method, and domain experts' feedback. Although we show how model designers can improve model performance using our tool, the main objective of this work is not to propose a new model, but to demonstrate how to explain deep learning models with attention. To our knowledge, this work the first attempt to exploring and attentionbased traffic forecasting models' prediction process and improving performance in the traffic domain, demonstrating the power of visual analytics approaches <ref type="bibr" target="#b61">[63]</ref>. Traffic data is heterogeneous with extreme cases <ref type="bibr" target="#b38">[39,</ref><ref type="bibr" target="#b60">62,</ref><ref type="bibr" target="#b76">78]</ref> and affected by uncontrollable external factors, such as accidents. Thus the traffic prediction task is especially challenging in that the models in the domain need to learn not only spatio-temporal features from the data, but also how to respond to implicit external events on roads. The external factors could even vary by region <ref type="bibr" target="#b35">[36]</ref>, which further complicates to the models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK 2.1 Spatio-Temporal Models for Traffic Prediction</head><p>As deep learning models are effective in many domains with large data sets, researchers have developed various models for the traffic domain. In particular, many models have been proposed for speed prediction that can be used in the field to relieve traffic congestion issues <ref type="bibr" target="#b35">[36]</ref>. In order to accurately forecast road speeds, most of studies focus on modeling spatial and temporal dependencies that in general affect the dynamics of road speeds <ref type="bibr" target="#b38">[39]</ref>. For example, if there is a vehicle accident on a road, it is highly possible that the other roads; linked to that road will become congested (i.e., spatial dependency). As time passes, the congestion beginning at the road with the accident may propagate to other roads (i.e., temporal dependency). As such, existing models aim to effectively model road network dependencies for speed prediction.</p><p>To effectively capture spatial dependency, graph convolution neural networks (GCNNs) <ref type="bibr" target="#b28">[29]</ref> has been proposed that apply the convolution technique to graphs of roads. As using diffusion on graphs turns out to be effective for modeling spatial dependency <ref type="bibr" target="#b39">[40]</ref> in road networks, many researchers have employed diffusion convolution neural networks (DCNNs) for accurate prediction <ref type="bibr" target="#b39">[40,</ref><ref type="bibr" target="#b48">50,</ref><ref type="bibr" target="#b70">72]</ref>. However, the models based on GCNNs and DCNNs are vulnerable, as they only consider spatial dependency as fixed values, regardless of inputs and traffic condition changes. To alleviate this issue, attention-based models have been employed to better model spatial dependency with considerations of road distances, showing state-of-the-art performance for speed prediction tasks <ref type="bibr" target="#b49">[51,</ref><ref type="bibr" target="#b49">51,</ref><ref type="bibr" target="#b80">82]</ref>.</p><p>Temporal dependency also plays a crucial role in encoding traffic congestion patterns. Examples include congestion propagation on roads over time. To effectively capture the dependency, prior studies have mainly used conventional modeling methods, such as recurrent neural networks (RNNs) <ref type="bibr" target="#b39">[40,</ref><ref type="bibr" target="#b75">77,</ref><ref type="bibr" target="#b80">82]</ref>. However, such RNN-based temporal dependency modeling methods have a limitation in that they cannot effectively capture long-range temporal trends in a given sequence. To alleviate this weakness, recent models have employed other advanced techniques, such as convolution neural networks <ref type="bibr" target="#b70">[72]</ref> or self-attention networks <ref type="bibr" target="#b49">[51]</ref>. In this work, we use ST-GRAT to model both spatial and temporal dependencies due to its enhanced interpretability and better performance over other models for traffic prediction <ref type="bibr" target="#b49">[51]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Visual Analytics for Deep Learning Models</head><p>Although deep learning models are effective, it is difficult to understand how the models work due to their black-box characteristic <ref type="bibr" target="#b47">[48]</ref>. Existing visual analytics approaches and systems for the matter fall into global model analysis and instance-based analysis <ref type="bibr" target="#b22">[23]</ref>. The global model analysis systems focus on how to visualize internal model structures through a graph structure, whose nodes and links are mapped to neural network neurons and weights between two connected neurons, respectively (e.g., CNNVis <ref type="bibr" target="#b41">[42]</ref>). In general, this global model anlaysis category includes visual analytics systems for understanding convolution neural networks (CNNs) applied to computer vision tasks <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b41">42,</ref><ref type="bibr" target="#b52">54,</ref><ref type="bibr" target="#b74">76,</ref><ref type="bibr" target="#b77">79]</ref> and recurrent neural networks (RNNs) for natural language processing tasks <ref type="bibr" target="#b45">[46,</ref><ref type="bibr" target="#b59">61]</ref> For example, Liu et al. <ref type="bibr" target="#b41">[42]</ref> proposed a visual analytics system, called CNNVis to visualize a CNNs via a directed cyclic graph. They additionally use the edge bundling technique to visualize the learned filters and connections between layers. Zeng et al. <ref type="bibr" target="#b79">[81]</ref> study a visual analytics approach to understanding the behaviors of CNNs, solving the modifiable areal unit problem. Shen et al. <ref type="bibr" target="#b57">[59]</ref> suggest a visual analytics system that allows users to visually explore the model behavior from global and individual levels on a multi-dimensional time-series forecast. Compared to the work in the global model analysis category, the main objective of our work is different. For example, while their approach focuses on the analysis of input data with errors, aiming at stabilizing feature embedding and predictions, our work allows for the investigation of spatio-temporal dependencies that a model learns during training. Also, our automated approach is different in that it enables users to directly estimate the reasons for model behaviors using time-series causality analysis.</p><p>Fred et al. <ref type="bibr" target="#b21">[22]</ref> present SUMMIT, which summarizes CNNs at scale by generating an attribute graph from a trained model and finding which filters influence on performance. Inspired by these studies, many VA systems have been proposed to solve similar problems with various models, including generative adversarial networks <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b66">68]</ref>, deep reinforcement learning <ref type="bibr" target="#b65">[67]</ref>, and sequence-to-sequence models with attention <ref type="bibr" target="#b58">[60]</ref> and self-attention networks <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b50">52]</ref>.</p><p>The VA systems for instance-based analysis aim to show how an input instance influences a model and vice versa to help users identify models' robustness and internal mechanisms in given scenarios <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b40">41,</ref><ref type="bibr" target="#b68">70]</ref>. For example, Strobelt et al. <ref type="bibr" target="#b58">[60]</ref> proposed Seq2Seq-VIS to help users manipulate models' internal parameters, and observe how models react to different inputs. SANVis <ref type="bibr" target="#b49">[51]</ref> visualizes self-attention networks with a given sentence, displaying how the model captures the linguistic relationships between the words in the sentence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Visual Analytics for Traffic Congestion</head><p>As traffic congestion is a crucial problem; affecting life quality, many VA systems have been proposed to find the causes and possible solu-tions. Many computational and strategical approaches are employed in designing VA systems for traffic analysis. The systems often integrate new visualizations to better present traffic patterns and anomalies, such as T-Watcher with fingerprint visualization <ref type="bibr" target="#b54">[56]</ref>. Wang et al. <ref type="bibr" target="#b67">[69]</ref> showcases an automated method for detecting traffic congestion, enabling users to explore different traffic congestion propagation graphs of a large city. Zeng et al. <ref type="bibr" target="#b78">[80]</ref> proposed an interchange circus diagram to present interchange patterns at a junction road and help users identify multi-spatial scales and temporal change patterns. Recently, Pi et al. <ref type="bibr" target="#b53">[55]</ref> have built cumulative vehicle count curves (N-curve) and classified patterns of congestion cause by using entropy from information theory to analyze causes of congestion across intersections.</p><p>While much research has been conducted, few studies on visual tools exist for predicting traffic speeds and volumes, which is an important task for experts in the traffic domain, such as reporters at broadcasting centers. Lee et al. <ref type="bibr" target="#b35">[36]</ref> proposed a visualization system to help the experts whose tasks include broadcasting traffic conditions across a city. They use and train Long Short-Term Memory (LSTM) <ref type="bibr" target="#b20">[21]</ref> with three features-road network structure, neighbor roads' speed, and rush-hour-to improve prediction performance. However, as the system does not explain the prediction results, experts may not be confident when they broadcast possible congested roads to citizens based on the prediction results. In this work we design a visual tool that can help users understand the prediction results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">TASK DESCRIPTION AND REQUIREMENTS</head><p>Our system has been designed with input from three domain experts of a corporate, which has 19 million users and processes 100 million map and navigation services per day, as of 2021. We have met with experts over a period of 18 months to extract task requirements and discuss design considerations. The first expert (E1, 20 years of experience) is a director of the map service group, supervising all map-related developments and services. The second expert (E2, 12 years of experience) leads the traffic intelligence team of the group and has developed algorithms for navigation services with the third expert (E3, 6 years of experience). E2 and E3 are the machine learning and software engineers in the traffic domain, and both have software development skills and machine learning knowledge and have applied machine learning algorithms to the domain area (i.e., trainers <ref type="bibr" target="#b59">[61]</ref>).</p><p>According to the experts, the group's main mission is to provide the best optimized navigation services to drivers and pedestrians. To fulfill this mission, they collect traffic speeds and paths from users (e.g., drivers who use their navigation services). They also collaborate with traffic departments of the national government, police agencies, and city halls to collect and utilize additional road events, such as accidents and construction in their services. The collected data is used for pathfinding and travel time estimation algorithms.</p><p>One of the concerns of the group is that although they have done well in the domain, it is possible that their competitors can take a technical advantage with the recent rise of machine learning models, which mean a loss in their market share in the country. To overcome this, they have utilized DL technologies <ref type="bibr" target="#b36">[37,</ref><ref type="bibr" target="#b48">50,</ref><ref type="bibr" target="#b70">72,</ref><ref type="bibr" target="#b75">77,</ref><ref type="bibr" target="#b80">82]</ref>, including LSTM <ref type="bibr" target="#b35">[36]</ref>, attention-based models for predicting future traffic speed <ref type="bibr" target="#b49">[51]</ref> and arrival time <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b15">16]</ref>. But, they often obtain unsatisfactory performance from the models, when they directly apply the models to their data. To find possible reasons for low performance, they conventionally investigate the model behaviors of roads with low accuracy, using the what-if method <ref type="bibr" target="#b16">[17,</ref><ref type="bibr">49,</ref><ref type="bibr" target="#b68">70]</ref>, in which they change the input traffic speed or features of a road in a model and compare forecasting performance. They also compare a road's traffic behavior to that of other roads. They know that a city has multiple regions, and each region shows different traffic and congestion patterns due to the various roles and capacities of the roads across the regions (e.g., residential and university areas, industrial complexes <ref type="bibr" target="#b36">[37]</ref>). In terms of a navigation service point of view, finding out which time and locations where model produces high accuracy is important information for deployment.</p><p>But, after starting their investigation, they soon find that this casebased, individual prediction performance analysis with Python is onerous and ineffective. In particular, the approach takes a great deal of time and effort to answer all of the questions that they create at work for achieving their goal and deployment criteria due to a large number of road links in cities <ref type="bibr" target="#b35">[36]</ref> and complex dependencies among roads <ref type="bibr" target="#b18">[19]</ref>.</p><p>The questions that need to be answered for their tasks are as follows: (Q1) Where and when does a model produce inaccurate predictions?; (Q2) What could be the causes of inaccurate predictions?; (Q3) Which past (combinations of) observations does a model use for speed prediction?; (Q4) Which road does a model refer to for speed prediction?; (Q5) How can the accuracy of a model be improved?; and (Q6) How does a model work across different road topologies? Among the questions, Q1 and Q2 are the main questions, while Q3 and Q4 are auxiliary questions that need to be clarified to better answer Q1 and Q2. Q5 can be considered a question for increasing their competence in the market and Q6 is the last question that should be addressed before in-the-wild deployment.</p><p>From the discussions, we have derived the following requirements for a visual analytics system designed for exploring traffic forecasting model's behavior and performance improvements. First, as it is important to pop out problematic roads with a given model, (R1) a VA system should highlight the roads with low accuracy and provide information on when a model has low accuracy (Q1). As models predict future speed based on spatio-temporal dependencies among roads, (R2) a system should provide a method for effectively exploring encoded dependencies (Q2-Q4) so that users can find evidence on the relationship between high errors and speed patterns <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b38">39]</ref>. Example information for supporting spatio-temporal dependency exploration includes (R2-1) historical traffic patterns of roads, speed distribution of data, standard deviation, daily speed trends (Q3, Q4), and (R2-2) data on model behaviors (Q2-Q5), such as which roads a model refers to for forecasting (i.e., which roads influence the prediction for a target road <ref type="bibr" target="#b18">[19]</ref>), and which input sequences are importantly used for the prediction. In many cases, it is difficult for users to identify which roads affect the prediction performance of a certain road <ref type="bibr" target="#b38">[39]</ref>. While prior work has revealed <ref type="bibr" target="#b18">[19]</ref> that there is a strong dependency among neighboring roads and second and third linked roads by cross validation, methods for investigating whether a target road refers to appropriate neighboring roads or not have been rare. Therefore, a system should also provide information on the similarity of temporal data and causality among roads (Q2-Q4). Lastly, to support users' formulation and validation of hypotheses, (R3) a system should provide a method that shows how much improvement users can expect (Q5, Q6).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">DATA DESCRIPTION AND ATTENTION MECHANISM 4.1 Data Description</head><p>In this work, we use the traffic data of two different road networks-the urban and highway road networks to explore the model's inference process for speed prediction. For the urban road network, we use dedicated short range communication (DSRC) data <ref type="bibr" target="#b27">[28]</ref> generated from Ulsan, South Korea (range: 9/1/2017∼12/28/2017), where more than 1.1 million people live with more than 540,000 registered vehicles as of 2017. A total of 116 DSRC sensors are used for data collection, which are installed every 5.7km and cover a total of 68 main roads. For the highway road network, we use the METR-LA data <ref type="bibr" target="#b23">[24]</ref>, which were collected from 207 loop detectors (range: 3/1/2012∼6/27/2012) on the highways of Los Angeles. Note that the highway network data we use are the standard benchmark data for traffic forecasting tasks <ref type="bibr" target="#b39">[40,</ref><ref type="bibr" target="#b75">77,</ref><ref type="bibr" target="#b80">82]</ref>. After discussing with domain experts and reviewing training results, we replace the missing data and explicit errors with historical data. We also use 5-minute aggregated data to mitigate possible effects of outliers, as performed in many previous studies (e.g., <ref type="bibr" target="#b39">[40]</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Attention Mechanism</head><p>We describe how we utilize ST-GRAT to demonstrate our VA approach. We choose ST-GRAT because 1) it has demonstrated state-of-the-art performance and because 2) we can produce attention matrices on spatio-temporal dependency (e.g., Eq. 1, Fig. <ref type="figure" target="#fig_1">3D</ref>) <ref type="bibr" target="#b49">[51]</ref>. We also consider that the domain experts have expressed that attention models are extensively used at work for not only speed prediction but also other tasks, such as travel time <ref type="bibr" target="#b15">[16]</ref> and taxi demand prediction <ref type="bibr" target="#b72">[74]</ref>.  ST-GRAT (Fig. <ref type="figure" target="#fig_1">3</ref>) is a variation of the transformer <ref type="bibr" target="#b63">[65]</ref> that uses the encoder-decoder architecture with self-attention (i.e., temporal attention). Additionally, ST-GRAT utilizes graph attention as spatial attention before temporal attention with a sentinel vector. The sentinel vector acts as weights for skip connection within the same road. ST-GRAT utilizes 12-length sequential historical speed with encoded features for each road and predicts 12 sequential speed predictions.</p><p>There are three types of layers in the encoder and decoder: embedding, spatial attention, and temporal attention layers (Fig. <ref type="figure" target="#fig_1">3B</ref>). To allow the model to extract the spatio-temporal dependencies, we provide a road network, speed, and observed time as the input features for the embedding layer (Fig. <ref type="figure" target="#fig_1">3B</ref>). The road network graph is directed graph G(V, E, A), where a road is represented as a node (i.e., V ) and the connection between roads is shown as a link (i.e., E). Note that road network G is directed graph, which allow model to distinguish the road directions. Note that we provide the order of a given sequence using the position embedding method <ref type="bibr" target="#b63">[65]</ref>.</p><p>The model captures spatial dependencies among neighbor roads in the spatial attention layer (Fig. <ref type="figure" target="#fig_1">3B</ref>) by using a graph attention network <ref type="bibr" target="#b64">[66,</ref><ref type="bibr" target="#b80">82]</ref>, a well-known graph modeling method. In short, the spatial attention layer integrates information among neighboring roads by directed graph attention. This directed spatial attention improves dependency modeling and helps developers interpret ST-GRAT.</p><p>The temporal attention layer (Fig. <ref type="figure" target="#fig_1">3B</ref>) models the temporal dependency and trends of given sequences. For modeling, temporal attention performs multi-head attention to compute temporal correlations. The attention type is decided by attention axes; spatial attention aggregates features among the spatial axis (i.e., neighboring roads), while temporal attention aggregates input features within the temporal axis (i.e., different time steps of the same roads (Fig. <ref type="figure" target="#fig_1">3C</ref>).</p><p>To sum up, there are two important attention layers-spatial and temporal attention-in ST-GRAT. Vaswani et al. <ref type="bibr" target="#b63">[65]</ref> describe an attention function as mapping a query and a set of key-value pairs to an output, where the query, key, values, and output are all vectors. From this perspective, from each key-value pair, we can derive an attention matrix from each attention layer, called SA and TA, and create a spatio-temporal matrix (ST matrix). Specifically, for each attention head, given X before spatial attention and H after temporal attention, their relationship can be written as follows:</p><formula xml:id="formula_0">H = (TA SA)X,<label>(1)</label></formula><p>where TA SA, named spatio-temporal attention, is the attention that users mainly explore for understanding model behaviors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">VISUAL ANALYTICS ENVIRONMENT</head><p>We describe our visual analytics system, AttnAnalyzer, which we have designed to effectively explore the deep learning model's internal process for traffic forecasting using attentions. Fig. <ref type="figure" target="#fig_0">2</ref> shows the pipeline of the analysis with AttnAnalyzer. We first prepare the data (A) for automated methods (B) and model training (C). After model training, we extract ST attention from the model (C), which is used for visualizations (D). Users explore model behaviors using the automated methods, (E) answering the questions (Q1-Q4) and test and confirm performance improvements (Q5).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Automated Methods</head><p>In this work, we incorporate two automated methods-dynamic time warping (DTW) with spectral clustering <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b55">57,</ref><ref type="bibr" target="#b71">73]</ref> and Granger causality tests <ref type="bibr" target="#b13">[14]</ref>, to allow users to determine which references are appropriate for predictions and whether a model employs proper references for the predictions (R2-3) <ref type="bibr" target="#b37">[38]</ref>.</p><p>We use daily trends of roads as input for DTW computation, which should be explored since they are encoded as temporal dependencies among roads, which a model learns during training <ref type="bibr" target="#b72">[74]</ref>. However, it is difficult to analyze road trends for two reasons. First, there are too many trends (i.e., roads) in a traffic dataset. Second, there are different time gaps between the trends of roads due to different levels of dependencies, which are presented with either lagging or preceding trends <ref type="bibr" target="#b38">[39]</ref>. For example, when congestion occurs on a road, the roads linked to the congested road also become congested, but there are no concrete patterns when the neighboring roads are congested. As such, we incorporate dynamic time warping (DTW) <ref type="bibr" target="#b5">[6]</ref> in this work, which calculates the similarity in two time series over time gaps after finding the best matching alignment that minimizes the distance, as Le Guen and Thome do for their time-series forecasting model design <ref type="bibr" target="#b34">[35]</ref>. For efficiency, we use FastDTW <ref type="bibr" target="#b55">[57]</ref>, whose complexity is O(N).</p><p>Then we perform spectral clustering <ref type="bibr" target="#b46">[47]</ref> with the computed DTW scores to further allow cluster-based analysis, which has shown its effectiveness in analyzing traffic data <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b71">73]</ref>. For example, users can easily confirm whether referred roads of a target road have similar daily trends as the target road using clusters. If the target and referred roads are in the same cluster, it is highly possible that the model learns the dependencies of the target and referred roads during training <ref type="bibr" target="#b38">[39]</ref>. Note that we use the ELBOW method <ref type="bibr" target="#b0">[1]</ref> with visual inspection to choose the number of clusters.</p><p>As Wu et al. <ref type="bibr" target="#b69">[71]</ref> show in their study, catching preceding patterns in time-series enables effective analysis of deep learning models. Therefore, to help users better explore the preceding patterns in the traffic data, and to complement DTW that distorts the time during its computation, we incorporate the Granger causality test <ref type="bibr" target="#b13">[14]</ref> in this work, a well-known temporal dependency investigation method. We first describe the definition of Granger causality based on two principles: <ref type="bibr" target="#b0">(1)</ref> the cause happens prior to its effect and (2) has unique information about the future values of its effect. Given these two principles about causality, Granger causality proposes testing the following hypothesis for the identification of a causal effect.</p><formula xml:id="formula_1">GrangerCausality = P[Y (t + 1) ∈ A|I (t)] = P[Y (t + 1) ∈ |I −X (t)]</formula><p>Here, P is probability, A is an arbitrary non-empty set, and I (t) and I −X (t) denote the information available as of time t in the entire universe, and in the modified universe where X is excluded, respectively. If the above hypothesis is accepted, we say X Granger-causes Y.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Visual Interfaces</head><p>AttnAnalyzer consists of five views: (A) filter, (B) table, (C) line, (D) map, and (E) attention, as shown in Fig. <ref type="figure">1</ref>. The attention view (E) has two sub views-spatio-temporal and head cluster (Fig. <ref type="figure" target="#fig_2">5</ref>) views. In the filter view (A), users can select a dataset, date range, and target prediction time (e.g., 15, 30, 45, and 60 minutes; default: 15 minutes).</p><p>Users can filter out the roads using Mean Absolute Error (A1: : scaled: min-max values) and spatio-temporal attention (A2: scaled: 0-1) values. When roads' MAEs are higher than the threshold value, the center circle of the roads are colored in black (R1). If a road's MAE value is below the value at Q1 (i.e., top 25% in accuracy), the road is included in the low error group. If the MAE of a road is above the value at Q3 (i.e., bottom 25% in accuracy), it belongs to the high error group. When users hover over the filters, a tooltip pops up to show the MAE values at the Q1 and Q3 boundaries (Fig. <ref type="figure">1, A1</ref>). The attention filter is applied to AttnArrows (e.g., Fig. <ref type="figure">4</ref>) on the map, when a road is selected for investigation. There are two legends to represent clusters (Fig. <ref type="figure">1 D1</ref>) and ratio values (D2). We use the color sets from ColorBrewer <ref type="bibr" target="#b19">[20]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.1">Table View</head><p>The sortable view (Fig. <ref type="figure">1 B</ref>) allows users to explore roads' characteristics in a compact form with information on road ID (Road), speed distribution (Speed Dist. (std.)), speed trends (Trend), cluster index (CLS), mean absolute error (MAE), and causality analysis (CA). The view is initially sorted by clusters, but users can sort differently using a small triangle ( ) at column titles. The column title is underscored to represent which column is used for current sorting in the table. For example, the table is currently sorted by the standard deviation (i.e., std) of roads' speed (Fig. <ref type="figure">1</ref>, Speed Dist. (std)). We show the speed distribution of a road (Speed Dist.) in a histogram with the x-axis representing different speed ranges with bins (e.g., 10 miles/bin) and the y-axis meaning the frequency. The bins' height is normalized by the maximum count. At the right side of the distribution, we also place each road's standard deviation value. If a road has a high deviation score, it means the road speed often significantly changes, while the low deviation implies that significant speed changes rarely happen on the road (e.g., highways).</p><p>To allow speed trend analysis, we provide normalized speed trends using spark lines <ref type="bibr" target="#b62">[64]</ref> (Fig. <ref type="figure">1B</ref>, Trend column), with the x-axis representing the time range (0-23) and the y-axis denoting average speeds of roads with the 5-minute interval. As users hover over a trend line, a vertical line and tooltip appear, showing time stamps and speeds. After the trend column, we provide cluster indices that each road belongs to and the MAE values of roads to help users investigate the relationship between speed trends, road clusters, and model accuracy (Q2, Q3). When users click on a trend line, a new window pops up, and shows speeds and MAE values.</p><p>We present Granger causality test results (F values) in the last column (CA) to support users inspecting spatio-temporal dependency in terms of causality. When users click on a road on the table, the F-values between the clicked road and other roads are presented. If the F-value of a pair is higher than of other pairs, we can say that the pair with a higher F-value has a more significant Granger causality relationship than other pairs. For example, we can see from Fig. <ref type="figure">6</ref> B1 that the Road 113 and Road 112 pair has a more significant Granger causality relationship than Road 113 with other roads. Note that if the p-value of a pair is less than 0.05, we do not show the results. We provide</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Target road</head><p>Reference road</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Head</head><p>Self-reference ratio Cluster Fig. <ref type="figure">4</ref>. AttnArrows for presenting which roads a target road refers to for inference. The donut chart surrounding the target road is filled in blue (clockwise) based on the self-reference intensity.</p><p>the test results to help users make and validate hypotheses on model behaviors. For example, users can review F-values to determine if the model sufficiently refers the information of the road with a significant Granger causality relationship for performance analysis (Q2, Q5).</p><p>Users can perform interactions in the table view for coordinating multiple views for detailed investigation. When users hover over a road in the table, corresponding road on the map and the attention matrix are highlighted. When users click a road id, (1) table view highlights (light-blue) the row of the road (e.g., Fig. <ref type="figure" target="#fig_0">1 B2</ref>), (2) map view places the road at the center of the map with highlighting in light blue, and (3) line view shows the collected and predicted speed lines (Fig. <ref type="figure">1 C</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.2">Time-Series Views</head><p>To help users investigate roads' temporal dependencies (R2), comparing road speeds, we provide a line chart view (Fig. <ref type="figure">1C</ref>), where the xaxis and y-axis represent time (5-minute intervals) and road's speed, respectively. Users can add raw and predicted speeds by selecting roads from other views, such as table, map, and attention views, and remove the lines by toggling road labels at the top. There is a blue vertical bar in the view (Fig. <ref type="figure">1 C1</ref>), indicating the current data point in visualizations (e.g., "2017-12-17 13:35:00," Fig. <ref type="figure">1C</ref>, top blue panel). It also shows the absolute error (AE) and STD values in the past one hour of the time specified by the bar (e.g., "AE: 1.24 STD:160.70" Fig. <ref type="figure">1 C1</ref>). Users can move the bar to anywhere to update map and attention views with the data specified by the bar.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.3">Map View</head><p>As models learn dependencies among roads and forecast based on the learned dependencies, it is important to explore what dependencies a model learns with road speed patterns and which roads a model refers to for performance investigation. To help users perform such exploration (R2-1, R2-2), we first present each road as a white dot. Each circle surrounding the dots shows the cluster that the road belongs to. We provide three visualizations in the map view: heatmap, attention arrows (AttnArrows), and cluster visualization. First, to help users overview the relationship between roads' congestion levels and model performance (Q1), we visualize roads' congestion levels using heatmaps (Fig. <ref type="figure">1D</ref>). Here, the redder the heatmaps are, the slower the roads are (heatmap legend: Fig. <ref type="figure" target="#fig_0">1 D2</ref>). We also have considered providing heatmaps with a time filter so that users can explore regions with high model error but decided against this because this approach requires many interactions for filtering and memorizing heatmaps that have changed due to filtering. Using Bezier curves, AttnArrows (Fig. <ref type="figure">4</ref>) link a target road and the roads that the target road attends for prediction. Here, the color represents the amount of attention given to the roads. The darker the head color, the more attention the reference road is given. For example, the head near Fig. <ref type="figure">1</ref>, 73 shows that the attention level is about 40% of the maximum attention value (legend: Fig. <ref type="figure" target="#fig_0">1 D2</ref>). To reduce visual clutter, users can hide unimportant AttnArrows by using attention filters (Fig. <ref type="figure" target="#fig_0">1 A2</ref>), or click AttnArrows to turn off <ref type="bibr" target="#b29">[30]</ref>. By default, the AttnArrows head visualizes the encoder's attention data.</p><p>When users click a road to set a target road for investigating its reference roads, the dot is highlighted steelblue (e.g., Fig. <ref type="figure">1D</ref>, road 81). To represent the selected target road's self-reference intensity (i.e., how much a road attends to its own speed pattern), we present a donut chart around the road, filling the chart according to the self-reference intensity (scale: 0-1, clockwise). For example, the donut chart of road 81 (Fig. <ref type="figure">1D</ref>) has self-reference intensity of 0.29. There are buttons for interactions on the map (Fig. <ref type="figure" target="#fig_1">1 D3</ref>)-CA (Causality Analysis), CLR (Clear map), LBL (Label display), JAM (Traffic Jam Heatmap), zoomin, and zoom-out.</p><p>When users click the CA button, AttnAnalyzer turns on the Causality Analysis mode. Then if users click a road, AttnAnalyzer removes the roads on the map, whose p-value in the test is higher than 0.05 to allow users to analyze with statistically meaningful roads. Users can draw a selection area by creating a polygon on the map where a set of roads can be included for investigation and un-select the selected roads using CLR. The speed heatmap and road labels are turned on and off with JAM and LBL, respectively.</p><p>To help users find which road belongs to which cluster, we initially implemented and compared BubbleSet <ref type="bibr" target="#b10">[11]</ref> and Kelpfusion <ref type="bibr" target="#b44">[45]</ref>, which are effective for set visualization. From our observations, although effective with a small number of clusters, they produced several overlaps among clusters when roads in different clusters are located closely. We have also observed that they may not be helpful, as a large number of overlaps means that there rarely is a dominant clustering pattern among the neighboring roads. Appendix Figure <ref type="figure">11</ref> shows our implementation results with 5 and 8 clusters. After the investigation, we decide to encode the clusters by placing an outer, colored circle on each road <ref type="bibr" target="#b32">[33]</ref>. Figure <ref type="figure">4</ref> shows two example roads, where both the target (left) and reference (right) roads belong to cluster C0 (legend: Fig. <ref type="figure">1 D1</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.4">Attention View</head><p>There are two visualization tabs in the attention views: spatio-temporal (ST) and head-cluster views for R2-2. We use pixel-based visualization <ref type="bibr" target="#b26">[27,</ref><ref type="bibr" target="#b30">31]</ref> to present the model's spatio-temporal attention in a matrix form, because of its scalability on the number of items <ref type="bibr" target="#b26">[27,</ref><ref type="bibr" target="#b30">31]</ref>. In the ST attention matrix view (e.g., Fig. <ref type="figure">1E</ref>), the x-axis indicates different roads, and the y-axis indicates past time steps (5-minute intervals, 12 steps, top: 5 minutes ago, bottom: 60 minutes ago). In the view, users can analyze which roads and time steps the model focuses on with attention intensity, represented by the color (legend: Fig. <ref type="figure" target="#fig_0">1 D2</ref>). For example, when users click road 81 on the map, the spatio-temporal view (Fig. <ref type="figure">1E</ref>) shows that road 81 attends itself (i.e., self-reference) and 73 more than other roads for its prediction.</p><p>There are 8 matrices in the head-cluster view (e.g., Fig. <ref type="figure" target="#fig_2">5</ref> top, first row) to show how much each attention head refers to reference roads for making predictions for target roads in a cluster point of view. In the view, the first four matrices visualize the attention patterns of the four heads with the roads for which the model records high error (top 25%), while the other four matrices display those of the four heads with the roads for which the model shows low error (lower 25%).</p><p>In each matrix, the column represents the clusters of reference roads, while the row means clusters of target roads in ascending order. The color of each cluster cell represents the intensity of the attention that each head assigns, so if a cell color is the darkest red, it means an attention head heavily refers to the roads in the cell (i.e., cluster) for making predictions (legend: Fig. <ref type="figure" target="#fig_0">1 D2</ref>). For example, many target clusters attend cluster 0 and 3 (Fig. <ref type="figure" target="#fig_2">5</ref> top, low error) and record low error. This indicates that the roads in cluster 0 and 3 have strong similarity with the roads in the target clusters in terms of daily speed trend.</p><p>There are global and local scales to normalize the attention values (i.e., intensity) in the matrices differently. All attention values across matrices are divided by the largest attention value to show relative attention intensity in the global normalization (Fig. <ref type="figure" target="#fig_2">5</ref> top, first row), but in the local normalization, each cell is divided by the sum of each row to make row sums of the matrices equal to 1. We show the attention patterns with the two scales to help users analyze the attention patterns by individual heads and across heads (R2-2) and find the reason for the failed inference, using the level of attention intensity information.</p><p>When users hover over a cell on a matrix, a tooltip pops up, showing detailed information, such as head index, relative attention ratio, and the average of their attentions. The interaction also highlights the road in the map and table views associated with the hovered item.</p><p>Inspired by Strobelt et al.'s approach that nullifies attention <ref type="bibr" target="#b58">[60]</ref>, we present an attention enforcement method in the head cluster view that replaces the attention values of the roads with high error with those from the roads with low error. Fig. <ref type="figure" target="#fig_2">5</ref> shows the process. For example, as users select four clusters (blue outline) in the view, AttnAnalyzer searches top-k target roads with high error in each cluster (Fig. <ref type="figure" target="#fig_2">5 [2]</ref>). The enforcement process-1) comparing attention between low (left) and high (right) error cases, 2) selecting k highest error roads in each cluster, 3) replacing the attention of the selected roads with that from low error roads, and 4) testing alternatives.</p><p>Then, the system automatically finds the most appropriate reference roads for each selected road in the chosen clusters, using the DTW distance matrix and Granger causality tests with equal importance (0.5). Lastly, the system extracts the attention values of the reference roads (i.e., alternative inference, Fig. <ref type="figure" target="#fig_2">5 [3]</ref>), applies alternative inference with the replaced attention to the target roads, and expresses new prediction results (Fig. <ref type="figure" target="#fig_2">5 [4]</ref>). Fig. <ref type="figure" target="#fig_2">5</ref> [1] and <ref type="bibr" target="#b2">[3]</ref> show the differences in attention distribution among clusters (i.e., color darkness of the arrows) in the initial and final cases. When users click on the "Test Alternatives" in the view (Fig. <ref type="figure">1 E1</ref>), a new view pops up, showing two line charts to describe the model's original and resulting accuracy (e.g., Fig. <ref type="figure">10</ref>).</p><p>Here, the x-axis corresponds to the degree of error, while the y-axis presents the frequency of the roads with specified error. In sum, if the original performance graph is moved to the left, there is an improvement in model performance. Detailed analysis with the result of using the method is presented in Sec. 6.3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">CASE STUDY</head><p>We present two case studies with two different road networks-the urban and highway road networks-exploring the model's speed prediction process. The case studies are archetypal use-cases that drove the design along with the feedback from our domain experts. The third case study shows how model performance can be improved based on the findings derived from the two case studies. As described in Sec. 4.1, we use DSRC data generated from Ulsan, South Korea as urban road networks and METR-LA data as highway road networks. Note that we define high error (low performance) and low error (high performance) groups of roads. The high error group includes the roads whose MAE is higher than the third MAE quartile (Q3), while the low error group include roads whose MAE is lower than the first MAE quartile (Q1).</p><p>We set DTW's window size as 4 to capture up to 20-minute time lags and use 5 and 6 clusters for Ulsan and LA, respectively, based on the elbow methods <ref type="bibr" target="#b51">[53]</ref>. We performed pre-processing so that both data sets have a 5-minute interval of speeds and timestamps and replace missing values with averages of past data. We used 70% of data for training, 10% of the data for validation, and 20% of the data for testing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Analysis with Urban Roads</head><p>A machine learning model developer, Jane, has recently developed a new deep learning model for traffic forecasting using the attention mechanism and found that the new model shows higher accuracy in experiments, compared to existing models (Appendix, Table <ref type="table">2</ref>); however, she believed the accuracy can be improved more, if she understands how the model works. So, she decided to use AttnAnalyzer to explore how the model predicts road speeds.</p><p>After the traffic data of Ulsan was loaded, AttnAnalyzer showed the roads on the map and the detailed information on the roads in the table (Fig. <ref type="figure">1B</ref>). Jane then turned on the speed heatmap to obtain an overview of typical traffic congestion across the city by clusters and to analyze error patterns by cluster. For example, she found that Cluster 3 usually experienced traffic congestion during the morning and evening rush hours as it includes many roads in the downtown region (Fig. <ref type="figure">6A</ref>, R2), while Cluster 4, which is in a residential region (Fig. <ref type="figure">6A, R1</ref>) is congested in early morning <ref type="bibr" target="#b35">[36]</ref>. Next, as she set the MAE filter's threshold at 4.2, which is about one-fourth of 11 (the largest MAE, Fig. <ref type="figure">1 A1</ref>), AttnAnalyzer highlighted the roads with low accuracy on the map. Interestingly, there seems to be no strong correlation between traffic congestion and model performance. Instead, it was shown that high error roads tend to be located at edges of regions (ER) and intersections of regions (IR), such as commercial and industry complexes, and residential regions <ref type="bibr" target="#b35">[36]</ref> as shown in Fig. <ref type="figure">6A</ref>.</p><p>As the roads with similar characteristics may have similar error levels, she found it is important to explore the roads of high errors (Q1). To identify the characteristics in common, she sorted the table, making hypotheses on a relationship among the deviation, distribution, and accuracy. She quickly noticed many cases seem to imply a relation between speed distribution patterns and the road error, MAE in the table view (Fig. <ref type="figure">1B</ref>). For example, she found that road 81 and road 66 (Fig. <ref type="figure" target="#fig_1">1 B3</ref>) had similar speed distribution, deviation, and error. They both had high deviation (e.g., 11, the speeds were similarly distributed in multiple ranges, and high error was recorded (e.g., MAE: 6). In contrast, road 16 and road 46 (Fig. <ref type="figure">1 B4</ref>) had low standard deviation value (e.g., 3) with a pointy and unbalanced speed distribution and a low error (e.g., MAE: 2).</p><p>Then, she began further investigation on the reason for such a relation, assuming that (Finding 1) the model makes inaccurate predictions (i.e., high error) for roads with high speed fluctuations (i.e., large speed changes). During her investigation, she found many cases that could confirm this assumption. For example, Fig. <ref type="figure">1C</ref> shows two example roads-road 81: high fluctuation and, road 18: low fluctuation. At road 81, the model did not accurately forecast when the speed suddenly dropped or soared (MAE: 6), but it accurately predicted speeds for road 18 (MAE: 2). She thought this finding could also explain why there are many roads with higher error in the intersections of regions (IR) that experience severe speed changes (Q1).</p><p>As she understood which roads tend to have high error and when the high error occurs, she investigated how the model makes prediction with the roads and possible causes of inaccuracy(Q2-Q4). To do so, she first set the attention filter (Fig. <ref type="figure" target="#fig_0">1 A2</ref>) as 0.1 to pass the roads that the model did not give much attention. Then, she clicked road 113, one of the highlighted roads with the highest error on the map (Fig. <ref type="figure">6B</ref>, yellow-fill circle) to add it to the line view and turned on AttnArrows. Once the speed data line was added, she moved the blue bar in the line view to the point that had a low absolute error (Fig. <ref type="figure">7 T1</ref>), updating all other visualization views. Based on the updated map and attention views, (Q4) she found that the model mainly refers to road 113 and road 86 (Fig. <ref type="figure">6 A</ref>). She also noticed several vertical light-pink lines in the attention view, including that of road 113 and 86. The reference to road 113 is a self-reference, implying that it is the model used in the road's past speed data (12 steps, 1 hour) for forecasting (Q3). This selfreference at the low speed deviation is advantageous when the current road speed follows a past speed trend, or periodic pattern, because the speed pattern does not change much from the previous steps <ref type="bibr" target="#b72">[74]</ref>.</p><p>It is interesting that the model referred to road 86 among many other candidates. Initially, she confirmed that road 86's speed trend was a similar to that of road 113 (Fig. <ref type="figure">7 A</ref>). In addition, she found that the model effectively attended road 86's information. For example, there was a time when road 86 had a speed drop (Fig. <ref type="figure">7 P1</ref>), which is different from its average speed trend. When this sudden drop occurred, the model did not refer to road 86 (Fig. <ref type="figure">6 P1</ref>) as it learned the temporal dependency that referring to road 86 in the drop timing is not helpful for accurate predictions for road 113.</p><p>Once she determined how the model makes accurate predictions, she became interested in why the model behaves differently for the road with a high speed fluctuation, making an inaccurate prediction (Q2-Q4). As she moved the blue bar in the line view to the point where road 113 had a sudden speed change and high error (Fig. <ref type="figure">7</ref>, T2), she found that the model began attending other roads (e.g., road 39, 54, 86) and reduced existing self-reference intensity (Fig. <ref type="figure">6</ref> B, attention view). The head-cluster view also showed similar behaviors of the model in terms of cluster point of view. For example, when the model has sufficient self-reference, there are dark red diagonal patterns, similar to Head 2, 3, and 4 in the low error case (Fig. <ref type="figure" target="#fig_2">5</ref> top right). However, when the model lacks self-reference, these patterns vanish from the matrix, as shown in the high error case (Fig. <ref type="figure" target="#fig_2">5</ref>, top left).</p><p>She speculated that this attention behavior is not helpful for an accurate prediction of road 113 for two reasons. First, as the referred roads (e.g., road 39, 54 and 86) are far from the target road (Fig. <ref type="figure">6B</ref>), there is a low probability that the referred roads have similar traffic patterns as that of road 113 and any congestion is propagated among the roads in the near-future (e.g., 15 minutes) with given speed levels <ref type="bibr" target="#b18">[19]</ref>. Second, a distant road can be helpful for prediction if there is any relationship between the traffic patterns of the roads. For example, if the traffic pattern of a referred road precedes that of a target road, referring to distant roads could be advantageous <ref type="bibr" target="#b13">[14]</ref>. But, she could not find crucial evidence of preceding traffic patterns from the line chart view. She also noticed from the cluster visualization and table view they are not even in the same cluster, as shown Fig. <ref type="figure">1B</ref>.</p><p>Rather, during this investigation, she found that road 112 is close  to road 113 and is also in the same cluster as road 113. The speed pattern also seeded to precede that of Road 113, as shown in Fig. <ref type="figure">7</ref> P2. To inspect this further, she ran a Granger causality test <ref type="bibr" target="#b13">[14]</ref> with Road 112 and 113. The test result indicated that road 112's speed trend indeed precedes that of road 113 (F[6,268]=16.2, p=0.001), as shown Fig. <ref type="figure">6</ref> B1 (Table <ref type="table">)</ref>. These observations led her to think that (Finding 2) the model effectively captures similar speed trends, but may not effectively recognize preceding speed patterns (Q2). She also noted that (Finding 3) in the case of high speed fluctuations, the model may attend many other roads and lose the importance of selfreference (Q2, Q4). This behavior is also not appropriate, as existing autoregressive models have already shown that past temporal data acquired by self-reference is more crucial for short-term forecasting (e.g., 15 minutes) <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b43">44]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Analysis with Highway Roads</head><p>To determine whether the model shows the same behaviors with different road networks (Q6), she decided to analyze the model with the speed data on highways in L.A., USA. As her purpose includes confirming the model behaviors on the roads with high and low errors (Q1, Q2), the analysis procedure is similar to that of Ulsan in the previous study.</p><p>After she replaced existing data with L.A. data in the menu (Fig. <ref type="figure">1A</ref>), she set the MAE filter as 3.6-the value at the third quartile and sorted the table view by the speed distribution. Fig. <ref type="figure" target="#fig_5">9</ref> (left) shows an example sorted table by the distribution. She observed that most roads have similar speed trends across the clusters. This could be the characteristic of highway roads since the speed is rather faster than the urban road networks. Speed distributions are skewed right and pointy in the table (Fig. <ref type="figure" target="#fig_5">9A</ref>), indicating typical highways' speed trends. She also obtained an overview of the positive correlation between standard deviation and MAE from the table. For example, roads 140, 61, 38 had a high error having wide range of speed (Fig. <ref type="figure" target="#fig_5">9C</ref>), while roads 40 and 85 with a pointy speed distribution had a low error (Fig. <ref type="figure" target="#fig_5">9B</ref>), which confirms (Finding 1). She also noticed from the map view that high error roads exist at the intersections of regions (IR) and edges of regions (ER) <ref type="bibr" target="#b42">[43]</ref> (Fig. <ref type="figure" target="#fig_4">8A</ref>, roads with black dots inside). This pattern was also found in the previous study.</p><p>As she clicked on road 38 on the map view, one of the black dots (i.e., high error), she moved the blue bar to the point where the model recorded a high error (e.g., AE: 45.63, Fig. <ref type="figure" target="#fig_5">9 T1</ref>). Then, she instantly noticed several light-pink vertical bars in the attention view (Fig. <ref type="figure" target="#fig_4">8B</ref>, attention view) and found that none of the bars had an attention intensity larger than 0.1. She thought that this was the same behavior shown in the previous study and may not be a proper behavior because the roads that encode preceding traffic patterns of other roads (Finding 2) or refer its own past speed pattern (Finding 3) tend to have high accuracy. The head-cluster view also showed similar behaviors from a cluster point of view (Appendix Fig. <ref type="figure" target="#fig_1">13</ref>). The head-cluster view displayed many light pink clusters in the diagonal pattern (i.e., insufficient self-reference), when the model recorded high error. However, with sufficient selfreference, it had high accuracy with dark red diagonal patterns.</p><p>To further inspect the model's attention behavior, she performed a causality analysis (CA) and found that road 206 has a speed pattern that precedes that of road 38 (i.e., dropping and increasing traffic speed earlier than road 38's traffic speed), as shown in Fig. <ref type="figure" target="#fig_5">9</ref> P1. The Granger causality test confirmed that road 206's speed pattern indeed exceeds that of road 38 (F[5, 271]=5.9, p&lt;0.001) as shown in Fig. <ref type="figure" target="#fig_4">8 B1 (Table)</ref>. But the model rarely attended road 206, nor performed self-referencing with attention intensity less than 0.1 (Finding 2). The pie chart of road 38 (yellow) and attention matrix in Fig. <ref type="figure" target="#fig_4">8B</ref> presented this observations. Note that the model had performed self-referencing for road 38's prediction, before the traffic speed fluctuated (Finding 3), as shown in Fig. <ref type="figure" target="#fig_4">8</ref> A, pixel view.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Attention Enforcement Tests</head><p>From the two case studies with AttnAnalyzer, she had three main findings. Finding 1: when a road's speed highly fluctuates, the model's error increases; Finding 2: the model often fails to find appropriate references with preceding speed trends; and Finding 3: the model loses important past self-reference information by dispersing attention to other unimportant roads.</p><p>As a next step, she decided to improve the model performance with the findings, using the attention enforcement method, provided in the attention view (Sec. 5.2.4). First, she selected four clusters in the diagonal pattern at Head 4, as shown in Fig. <ref type="figure" target="#fig_2">5</ref>, green dotted box. As she clicked the "Test Alternatives" button in the view, a new view popped up that presents two line charts for performance comparison (Fig. <ref type="figure">10</ref>). From the chart, she observed a shift in the original model's chart, which indicates improved performance. For example, from the chart of the METR-LA data, she recognized that the number of roads with about 30 absolute error (AE) decreased, while those with about 5 AE increased. Similarly, the number of roads with about 20 AE decreased the same as those with about 5 AE increased with the Ulsan data. She thought this result came from the fact that the attention enforcement method had the model focus on self-reference and roads with preceding speed patterns in the same clusters, confirming and using Finding 2 and 3 together.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">EXPERT FEEDBACK</head><p>To evaluate our VA approach, we conducted a semi-structured interview session (2-hour long) with two domain experts, E3 and E4. E3 and E4 had 6 and 2 years of experience, respectively, as machine learning engineers in the traffic domain, developing deep learning models in the transportation domain. E3 had also participated in meetings to perform task analysis (Sec. 3). Before the session, we performed an online tutorial session on AttnAnalyzer and sent them online access to the system so that they could freely use and test the system. In the interview session, we asked about their challenges at work, showcased the system with the case studies, and had a Q&amp;A session on the system. We then asked about the usefulness and impact of the system on their work.</p><p>First, when we asked them about the challenges in their work, they explained that improving models in the traffic domain is difficult, because the data have complicated spatio-temporal dependencies, and they do not have effective tools for analyzing the dependencies in the layers. Thus, the process is performed in a brute-force manner using scripting languages-"...whenever we evaluate the importance of some features or layers, we have to iteratively retrain our model and check the raw outputs," E4 reported. E4 also commented that the attention view and AttnArrows are helpful for analyzing complex spatio-temporal attention, and they can easily discover important features and layers and debug models' misendeavor in advance, which is critical for shortening their work time due to the reduced number of retraining in the end.</p><p>E3 expressed similar views to E4 regarding the system's usefulness for analyzing attention, as well as exploring and debugging model behaviors. In particular, he mentioned that the system is effective in cases, where DL models do not have specific performance improvement, such as speed predictions for rush hours <ref type="bibr" target="#b35">[36,</ref><ref type="bibr" target="#b36">37]</ref>-"...there are cases where learning models' performance do not outperform existing approaches. ...using the attention enforcement, we can have improved performance, better responding to user requests with higher accuracy."</p><p>He then commented that the system allows great inspiration and has large potential in optimizing computing resources in a novel way. He explained that as deep learning models become heavier with many layers and input features, consuming many computing resources, it becomes a burden to utilize heavy models all the time. In this case, he suggested using the system at work with two types of models-one with high accuracy and resource-demanding and another with reasonable accuracy without resource-demanding. Then, the attention mechanism is used to decide which model to use for prediction with consideration of resource usage (i.e., switching models for prediction by conditions). Then they can explore the behaviors of the attention as described in the case studies and even improve performance by using the attention enforcement method, all of which could contribute to saving computing resources-"...if we can interchange between lightweight and heavy models, [...] , we can save tremendous resources for our navigation and prediction services."</p><p>E3 gave positive feedback on the automated methods. According to E3, DTW and Granger causality methods have already been used and have allowed notable results in their teams dealing with time series data analysis and prediction. E3 said, "...DTW and the enforcement of attention with DTW is a very interesting and novel approach for the traffic forecasting." Lastly E3 spotted that the system can be easily extended for other cities, which is advantageous, as they deal with many large cities for services-"Confirming models with different cities is also important [...] and this system can be frequently used for confirming model performance with many cities' data. "</p><p>Lastly, when asked how to strengthen the system, they answered that temporal analysis on the map could be further strengthened, such as direct time-series pattern visualization on the map with respect to roads, which could help developers better explore the dependencies. They also expressed their interest in using the system with DL models for travel time prediction, as it could reveal new types of insights into how deep learning models deal internally with sub-paths and local roads.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">LIMITATIONS, DISCUSSION, AND FUTURE WORK</head><p>We encode clusters using colors because our algorithm experiment results show that there are less than eight meaningful traffic patterns Fig. <ref type="figure">10</ref>. A result of the attention in our urban and highway traffic data due to the inherent periodicity of the traffic on roads (e.g., existence of rush hour). Note that Kwon et al. <ref type="bibr" target="#b32">[33]</ref> have demonstrated that a greater number of clusters can be identified with colors (e.g., 20 clusters). Although we assign colors to best distinguish the clusters with reduced visual complexity, assigning colors to clusters based on similarity levels could allow for effective cluster analysis. For example, clusters with high similarities could have a similar color <ref type="bibr" target="#b31">[32]</ref>. By modifying Eq. 1, the attention matrix can be calculated from other attention-based spatio-temporal forecasting models. As Table <ref type="table" target="#tab_1">1</ref> with top 10% high error roads shows, the attention enforcement method results in improved accuracy. While a negative relationship is known to exist between traffic volume and speed <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b38">39]</ref>, it has not been investigated in this work; the model behavior with regard to this relationship could be the topic of a future study. The volume data for the LA dataset can be downloaded from the official website <ref type="bibr" target="#b14">[15]</ref> We place road information in the table view, but some information could be shown with visualization on the map for effective visual analysis, though this would also increase visual complexity.</p><p>We perform two experiments and acquire the best performance, when both DTW and Granger causality test are applied. Note that the improvement is meaningful, as most recent traffic forecasting models are recognized with a similar level of performance improvements <ref type="bibr" target="#b36">[37]</ref>. The colored parts of the two inset visualizations in Fig. <ref type="figure">10</ref> mean improved performance gaps and some roads show significant performance improvement (e.g., road 32, 9). We show the usefulness of DTW and Granger causality tests for spatio-temporal attention anlaysis, but incorporating other methods (e.g, Bayesian inferences) also could produce additional insights. We use a fixed range of error using quartiles for the sake of simplicity; hence, the high (Q3) and low (Q1) error bounds are relative and different datasets would have different low and high error bounds with different error distributions. A filtering function for setting the error bound threshold could help users effectively investigate model behaviors with different error ranges. Although the experts in the interview have not reported any concerns regarding the usability of the system, a user study could be performed to investigate usability and complexity issues. For in-depth analysis, a longitudinal study <ref type="bibr" target="#b56">[58]</ref> can be performed with the experts to show how the system can be used at work and to measure the impact of the system.</p><p>As a future work, we plan to research how to make an automated switch based on attention between the light weight and heavy forecasting models for DL resource optimization. It is of interest regarding what VA systems can support the exploration of such models to answer when and how the models are switched during the forecasting process.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9">CONCLUSION</head><p>We design a VA approach to help users explore the process of traffic forecasting and improve model performance. We perform task anlaysis with domain experts, which inform our system design. The system provides users with multiple views, including filter, line, map, and attention views, for effective model exploration in a spatio-temporal perspective. For evaluation, we perform two case studies, showing how users form and validate hypotheses and generate insights into model behaviors. We also show that the insights derived by using our VA approach are critical in improving the accuracy.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. An overview of the system workflow with functional modules and questions. (A) Data pre-processing, (B) automated methods for supporting spatio-temporal analysis, (C) model training and inference, (D) visualization modules, and (E) answering questions using the system.</figDesc><graphic url="image-11.png" coords="4,85.98,192.98,61.96,53.88" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Overall architecture of ST-GRAT (A). Each layer in the encoder is composed of a stack of identical layers (B). G(V , E and A) in (A) indicates a set of nodes, links, and a weighted adjacency matrix, respectively. We create a spatio-temporal attention matrix (D) by calculating point-wise multiplication between spatial and temporal attention weights (C).</figDesc><graphic url="image-14.png" coords="4,85.98,246.62,61.96,53.88" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. (Top) The head-cluster four attention heads, (Bottom)The enforcement process-1) comparing attention between low (left) and high (right) error cases, 2) selecting k highest error roads in each cluster, 3) replacing the attention of the selected roads with that from low error roads, and 4) testing alternatives.</figDesc><graphic url="image-24.png" coords="6,336.29,126.18,61.92,53.44" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 6 .P1Fig. 7 .</head><label>67</label><figDesc>Fig. 6. Two example visualizations during analysis. (A) There are three regions-R1: residential, R2: downtown, and R3: industry complex. R2 has heavy congestion during rush-hours due to in-and-out traffic from R1 and R3. High error roads show inner black dots as a filtering result (Sec. 5.2). (B)Roads with low causality values and attention for Road 113 are filtered out in the causality mode.</figDesc><graphic url="image-35.png" coords="7,80.37,246.24,98.01,64.28" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 8 .</head><label>8</label><figDesc>Fig. 8. An example visualization view with the highway speed data in L.A. (R1: residential, R2: downtown, R3 industrial regions). The two attention views show how the model attends in the low (A) and high error (B) cases.</figDesc><graphic url="image-38.png" coords="8,304.40,73.00,195.44,132.62" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 9 .</head><label>9</label><figDesc>Fig. 9. Summary of tables and Causality Analysis in LA. Overall there is a positive correlation between std. and MAE. Road 206's traffic pattern precedes that of road 38 (line chart, P1).</figDesc><graphic url="image-43.png" coords="8,80.34,229.27,123.89,61.73" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>Mar. 2022; revised 6 June 2022; accepted 8 Aug. 2022. Date of Publication xx xxx. 202x; date of current version xx xxx. 202x. Digital Object Identifier: xx.xxxx/TVCG.201x.xxxxxxx delayed departure time)</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 .</head><label>1</label><figDesc>Improved accuracy using the findings from our visual analytics approach. 10% of roads with the highest error are used.</figDesc><table><row><cell>Dataset</cell><cell>Method</cell><cell cols="4">15 Mins 30 Mins 60 Mins Average</cell></row><row><cell></cell><cell>ST-GRAT</cell><cell>8.70</cell><cell>9.00</cell><cell>9.52</cell><cell>8.98</cell></row><row><cell>Ulsan</cell><cell>Enforced w/ DTW</cell><cell>8.23</cell><cell>8.43</cell><cell>8.81</cell><cell>8.39</cell></row><row><cell></cell><cell>Enforced w/ DTW + Granger</cell><cell>8.24</cell><cell>8.37</cell><cell>8.76</cell><cell>8.37</cell></row><row><cell></cell><cell>ST-GRAT</cell><cell>6.08</cell><cell>7.43</cell><cell>10.61</cell><cell>7.68</cell></row><row><cell>METR-LA</cell><cell>Enforced w/ DTW</cell><cell>6.06</cell><cell>7.38</cell><cell>10.24</cell><cell>7.55</cell></row><row><cell></cell><cell>Enforced w/ DTW + Granger</cell><cell>6.04</cell><cell>7.28</cell><cell>10.08</cell><cell>7.48</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGEMENTS</head><p>This work was supported by the Korean National Research Foundation (NRF) grant (No. 2021R1A2C1004542) and by the Institute of Information &amp; Communications Technology Planning &amp; Evaluation (IITP) grants (No. 2020-0-01336-Artificial Intelligence Graduate School Program, UNIST), funded by the Korea government (MSIT). This work was also partly supported by NAVER Corporation.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">An automated spectral clustering for multiscale data</title>
		<author>
			<persName><forename type="first">M</forename><surname>Afzalan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Jazizadeh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">347</biblScope>
			<biblScope unit="page" from="94" to="108" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A review of traffic congestion prediction using artificial intelligence</title>
		<author>
			<persName><forename type="first">M</forename><surname>Akhtar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Moridpour</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Advanced Transportation</title>
		<imprint>
			<biblScope unit="volume">2021</biblScope>
			<biblScope unit="page" from="1" to="18" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Exploratory spatio-temporal visualization: an analytical review</title>
		<author>
			<persName><forename type="first">N</forename><surname>Andrienko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Andrienko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Gatalsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Visual Languages &amp; Computing</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="503" to="541" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Leveraging spatial abstraction in traffic analysis and forecasting with visual analytics</title>
		<author>
			<persName><forename type="first">N</forename><surname>Andrienko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Andrienko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Rinzivillo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Systems</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="page" from="172" to="194" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Daily traffic flow pattern recognition by spectral clustering</title>
		<author>
			<persName><forename type="first">M</forename><surname>Aven</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017</date>
			<publisher>CMC Senior Theses</publisher>
			<biblScope unit="page">1597</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Using dynamic time warping to find patterns in time series</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Berndt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Clifford</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Knowledge Discovery and Data Mining</title>
				<meeting>the International Conference on Knowledge Discovery and Data Mining</meeting>
		<imprint>
			<date type="published" when="1994">1994</date>
			<biblScope unit="page" from="359" to="370" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Fairvis: Visual analytics for discovering intersectional bias in machine learning</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">A</forename><surname>Cabrera</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Epperson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Hohman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kahng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Morgenstern</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">H</forename><surname>Chau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Visual Analytics Science and Technology</title>
				<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="46" to="56" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Short-time traffic flow prediction with arima-garch model</title>
		<author>
			<persName><forename type="first">C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2011 IEEE Intelligent Vehicles Symposium (IV)</title>
				<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="607" to="612" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">The retrieval of intra-day trend and its influence on traffic prediction</title>
		<author>
			<persName><forename type="first">C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Transportation research part C: emerging technologies</title>
				<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="103" to="118" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Revacnn: Steering convolutional neural network via real-time visual analytics</title>
		<author>
			<persName><forename type="first">S</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Suh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Choo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">C</forename><surname>Kwon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Future of Interactive Learning Machines Workshop(FILM at NerIPS)</title>
				<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Bubble sets: Revealing set relations with isocontours over existing visualizations</title>
		<author>
			<persName><forename type="first">C</forename><surname>Collins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Penn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Carpendale</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1009" to="1016" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Attention flows: Analyzing and comparing attention mechanisms in language models</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">F</forename><surname>Derose</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Berger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1160" to="1170" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Eta prediction with graph neural networks in google maps</title>
		<author>
			<persName><forename type="first">A</forename><surname>Derrow-Pinion</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>She</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Lange</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Hester</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Perez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Nunkesser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Wiltshire</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 30th ACM International Conference on Information &amp; Knowledge Management</title>
				<meeting>the 30th ACM International Conference on Information &amp; Knowledge Management</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="3767" to="3776" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">A new statistic and practical guidelines for nonparametric granger causality testing</title>
		<author>
			<persName><forename type="first">C</forename><surname>Diks</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Panchenko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Economic Dynamics and Control</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">9-10</biblScope>
			<biblScope unit="page" from="1647" to="1669" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Traffic count data: Lac open data</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">C</forename><surname>Division</surname></persName>
		</author>
		<ptr target="https://data.lacounty.gov/transportation/traffic-count-data/uvew-g569" />
		<imprint>
			<date type="published" when="2021-10">Oct 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Constgat: Contextual spatial-temporal graph attention network for travel time estimation at baidu maps</title>
		<author>
			<persName><forename type="first">X</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</title>
				<meeting>the 26th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="2697" to="2705" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Model understanding with the what-if tool dashboard</title>
		<author>
			<persName><surname>Google</surname></persName>
		</author>
		<ptr target="https://www.tensorflow.org/tensorboard/what_if_tool/" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">A survey of methods for explaining black box models</title>
		<author>
			<persName><forename type="first">R</forename><surname>Guidotti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Monreale</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ruggieri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Turini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Giannotti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Pedreschi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Comput. Surv</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1" to="42" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Identifying the most influential roads based on traffic correlation networks</title>
		<author>
			<persName><forename type="first">S</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Tong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Lv</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Havlin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">EPJ Data Science</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="17" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Colorbrewer. org: an online tool for selecting colour schemes for maps</title>
		<author>
			<persName><forename type="first">M</forename><surname>Harrower</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A</forename><surname>Brewer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Cartographic Journal</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="27" to="37" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Long short-term memory</title>
		<author>
			<persName><forename type="first">S</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Comput</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1735" to="1780" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Summit: Scaling deep learning interpretability by visualizing activation and attribution summarizations</title>
		<author>
			<persName><forename type="first">F</forename><surname>Hohman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Robinson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">H</forename><surname>Chau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1096" to="1106" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Visual analytics in deep learning: An interrogative survey for the next frontiers</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">M</forename><surname>Hohman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kahng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Pienta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">H</forename><surname>Chau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="2674" to="2693" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Big data and its technical challenges</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">V</forename><surname>Jagadish</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gehrke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Labrinidis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Papakonstantinou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Patel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Ramakrishnan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Shahabi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Commun. ACM</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="page" from="86" to="94" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Understanding Complex Deep Generative Models using Interactive Visual Experimentation</title>
		<author>
			<persName><forename type="first">M</forename><surname>Kahng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Thorat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">H</forename><surname>Chau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Viégas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Wattenberg</surname></persName>
		</author>
		<author>
			<persName><surname>Gan Lab</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="310" to="320" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Activis: Visual exploration of industry-scale deep neural network models</title>
		<author>
			<persName><forename type="first">M</forename><surname>Kahng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">Y</forename><surname>Andrews</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kalro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Horng Polo</surname></persName>
		</author>
		<author>
			<persName><surname>Chau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="88" to="97" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Designing pixel-oriented visualization techniques: Theory and applications</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Keim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="59" to="78" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Dedicated short-range communications (dsrc) standards in the united states</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">B</forename><surname>Kenney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE</title>
				<meeting>the IEEE</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="volume">99</biblScope>
			<biblScope unit="page" from="1162" to="1182" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Semi-Supervised Classification with Graph Convolutional Networks</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">N</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Learning Representations</title>
				<meeting>the International Conference on Learning Representations</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Analyzing high-dimensional multivariate network links with integrated anomaly detection, highlighting and exploration</title>
		<author>
			<persName><forename type="first">S</forename><surname>Ko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Afzal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Walton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Chae</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Malik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Jang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Ebert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Visual Analytics Science and Technology</title>
				<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="83" to="92" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Marketanalyzer: An interactive visual analytics system for analyzing competitive advantage using point of sale data</title>
		<author>
			<persName><forename type="first">S</forename><surname>Ko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Maciejewski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Jang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">S</forename><surname>Ebert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics Forum</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">3pt3</biblScope>
			<biblScope unit="page" from="1245" to="1254" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Clustered eye movement similarity matrices</title>
		<author>
			<persName><forename type="first">A</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Timmermans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Burch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Mueller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 11th ACM Symposium on Eye Tracking Research &amp; Applications</title>
				<meeting>the 11th ACM Symposium on Eye Tracking Research &amp; Applications</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="1" to="9" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Clustervision: Visual supervision of unsupervised clustering</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">C</forename><surname>Kwon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Eysenbach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Verma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Defilippi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">F</forename><surname>Stewart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Perer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="142" to="151" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Road traffic forecasting: Recent advances and new challenges</title>
		<author>
			<persName><forename type="first">I</forename><surname>Lana</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Del</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">I</forename><surname>Velez</surname></persName>
		</author>
		<author>
			<persName><surname>Vlahogianni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Intelligent Transportation Systems Magazine</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="93" to="109" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Shape and time distortion loss for training deep time series forecasting models</title>
		<author>
			<persName><forename type="first">V</forename><surname>Le Guen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Thome</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
				<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">32</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">A visual analytics system for exploring, monitoring, and forecasting road traffic congestion</title>
		<author>
			<persName><forename type="first">C</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Maciejewski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Ebert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="3133" to="3146" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">An empirical experiment on deep learning models for predicting traffic data</title>
		<author>
			<persName><forename type="first">H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Choo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2021 IEEE 37th International Conference on Data Engineering (ICDE)</title>
				<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="1817" to="1822" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Trend modeling for traffic time series analysis: An integrated study</title>
		<author>
			<persName><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Intelligent Transportation Systems</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="3430" to="3439" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">A brief overview of machine learning methods for short-term traffic forecasting and future directions</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Shahabi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIGSPATIAL Special</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="3" to="9" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Diffusion convolutional recurrent neural network: Data-driven traffic forecasting</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Shahabi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Learning Representations</title>
				<meeting>the International Conference on Learning Representations</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="1" to="16" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Analyzing the noise robustness of deep neural networks</title>
		<author>
			<persName><forename type="first">M</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Visual Analytics Science and Technology</title>
				<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="60" to="71" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Towards better analysis of deep convolutional neural networks</title>
		<author>
			<persName><forename type="first">M</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="91" to="100" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<ptr target="https://planning.lacity.org/" />
		<title level="m">Los Angeles City Planning. Citywide maps</title>
				<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Arima models for bus travel time prediction</title>
		<author>
			<persName><forename type="first">N</forename><surname>Madzlan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Ibrahim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Institution of Engineers Malaysia</title>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Kelpfusion: A hybrid set visualization technique</title>
		<author>
			<persName><forename type="first">W</forename><surname>Meulemans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">H</forename><surname>Riche</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Speckmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Alper</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Dwyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1846" to="1858" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Understanding hidden memories of recurrent neural networks</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Ming</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Qu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Visual Analytics Science and Technology</title>
				<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="13" to="24" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">A family of algorithms using spectral clustering and dbscan</title>
		<author>
			<persName><forename type="first">S</forename><surname>Miyahara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Miyamoto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Granular Computing</title>
				<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="196" to="200" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Opening the black box: Strategies for increased user involvement in existing algorithm implementations</title>
		<author>
			<persName><forename type="first">T</forename><surname>Mühlbacher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Piringer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gratzl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sedlmair</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Streit</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="1643" to="1652" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<title level="m" type="main">Hyperst-net: Hypernetworks for spatio-temporal forecasting</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zheng</surname></persName>
		</author>
		<idno>ArXiv, abs/1809.10889</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">St-grat: A novel spatio-temporal graph attention networks for accurately forecasting dynamically changing road speed</title>
		<author>
			<persName><forename type="first">C</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Bahng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Tae</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Choo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM International Conference on Information &amp; Knowledge Management</title>
				<meeting>the ACM International Conference on Information &amp; Knowledge Management</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="1215" to="1224" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Sanvis: Visual analytics for understanding self-attention networks</title>
		<author>
			<persName><forename type="first">C</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Na</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Jo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Shin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yoo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">C</forename><surname>Kwon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Noh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Choo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Visual Analytics Science and Technology Short</title>
				<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Spectral clustering in the dynamic stochastic block model</title>
		<author>
			<persName><forename type="first">M</forename><surname>Pensky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Electronic Journal of Statistics</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="678" to="709" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Deepeyes: Progressive visual analytics for designing deep neural networks</title>
		<author>
			<persName><forename type="first">N</forename><surname>Pezzotti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Hollt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Van Gemert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Lelieveldt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Eisemann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Vilanova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">98</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Visual cause analytics for traffic congestion</title>
		<author>
			<persName><forename type="first">M</forename><surname>Pi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Yeon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Son</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Jang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="2186" to="2201" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">T-watcher: A new visual analytic system for effective traffic surveillance</title>
		<author>
			<persName><forename type="first">J</forename><surname>Pu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Ni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Mobile Data Management</title>
				<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="127" to="136" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Toward accurate dynamic time warping in linear time and space</title>
		<author>
			<persName><forename type="first">S</forename><surname>Salvador</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Chan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Intelligent Data Analysis</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="561" to="580" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">An insight-based longitudinal study of visual analytics</title>
		<author>
			<persName><forename type="first">P</forename><surname>Saraiya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>North</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Lam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">A</forename><surname>Duca</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1511" to="1522" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Visual interpretation of recurrent neural network on multi-dimensional time-series forecast</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Alexis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Vianova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Qu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2020 IEEE Pacific Visualization Symposium</title>
				<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="61" to="70" />
		</imprint>
	</monogr>
	<note>Paci-ficVis</note>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">SEQ2seq-VIS : A Visual Debugging Tool for Sequence-to-Sequence Models</title>
		<author>
			<persName><forename type="first">H</forename><surname>Strobelt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gehrmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Behrisch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Perer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Pfister</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Rush</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="353" to="363" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Lstmvis: A tool for visual analysis of hidden state dynamics in recurrent neural networks</title>
		<author>
			<persName><forename type="first">H</forename><surname>Strobelt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gehrmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Pfister</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Rush</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="667" to="676" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">A survey on modern deep neural network for traffic prediction: Trends, methods and challenges</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Tedjopurnomo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Bao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Choudhury</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Qin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Knowledge and Data Engineering</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1544" to="1561" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Cook</surname></persName>
		</author>
		<title level="m">Illuminating the Path: The Research and Development Agenda for Visual Analytics. National Visualization and Analytics Ctr</title>
				<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<monogr>
		<title level="m" type="main">Beautiful evidence. Graphis Pr</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">R</forename><surname>Tufte</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Attention is all you need</title>
		<author>
			<persName><forename type="first">A</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ł</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Polosukhin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
				<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="5998" to="6008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Graph attention networks</title>
		<author>
			<persName><forename type="first">P</forename><surname>Veličković</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Cucurull</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Casanova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Romero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Liò</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
				<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Dqnviz: A visual analytics approach to understand deep q-networks</title>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Gou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="288" to="298" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Ganviz: A visual analytics approach to understand the adversarial game</title>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Gou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H.-W</forename><surname>Shen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="1905" to="1917" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Visual traffic jam analysis based on trajectory data</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Van De</surname></persName>
		</author>
		<author>
			<persName><surname>Wetering</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2159" to="2168" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">The what-if tool: Interactive probing of machine learning models</title>
		<author>
			<persName><forename type="first">J</forename><surname>Wexler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Pushkarna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Bolukbasi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Wattenberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Viégas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wilson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="56" to="65" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Connecting the dots: Multivariate time series forecasting with graph neural networks</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</title>
				<meeting>the 26th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="753" to="763" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Graph wavenet for deep spatial-temporal graph modeling</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Joint Conference on Artificial Intelligence</title>
				<meeting>the International Joint Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="1907" to="1913" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">A traffic classification method with spectral clustering in sdn</title>
		<author>
			<persName><forename type="first">P</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>-J. Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>-W. Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M.-X</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2016 17th International Conference on Parallel and Distributed Computing, Applications and Technologies (PDCAT)</title>
				<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="391" to="394" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">Revisiting spatial-temporal similarity: A deep learning framework for traffic prediction</title>
		<author>
			<persName><forename type="first">H</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
				<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="5668" to="5675" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">Deep learning on traffic prediction: Methods, analysis and future directions</title>
		<author>
			<persName><forename type="first">X</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Yin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Intelligent Transportation Systems</title>
		<imprint>
			<biblScope unit="page" from="1" to="17" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">Understanding neural networks through deep visualization</title>
		<author>
			<persName><forename type="first">J</forename><surname>Yosinski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Clune</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Fuchs</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Lipson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Machine Learning</title>
				<meeting>the International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">Spatio-temporal graph convolutional networks: A deep learning framework for traffic forecasting</title>
		<author>
			<persName><forename type="first">B</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Joint Conference on Artificial Intelligence</title>
				<meeting>the International Joint Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="3634" to="3640" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">Hetero-convlstm: A deep learning approach to traffic accident prediction on heterogeneous spatio-temporal data</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</title>
				<meeting>the 24th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="984" to="992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main">Visualizing and understanding convolutional networks</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Zeiler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Fergus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision</title>
				<meeting>the European Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="818" to="833" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<analytic>
		<title level="a" type="main">Visualizing interchange patterns in massive movement data</title>
		<author>
			<persName><forename type="first">W</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C.-W</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Arisona</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Qu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics Forum</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">3-3</biblScope>
			<biblScope unit="page" from="271" to="280" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<analytic>
		<title level="a" type="main">Revisiting the modifiable areal unit problem in deep traffic prediction with visual analytics</title>
		<author>
			<persName><forename type="first">W</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Turkay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="839" to="848" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<analytic>
		<title level="a" type="main">Gaan: Gated attention networks for learning on large and spatiotemporal graphs</title>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>King</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Yeung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Uncertainty in Artificial Intelligence</title>
				<meeting>the Conference on Uncertainty in Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="339" to="349" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
