<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Erato: Cooperative Data Story Editing via Fact Interpolation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Mengdi</forename><surname>Sun</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Ligan</forename><surname>Cai</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Weiwei</forename><surname>Cui</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Yanqiu</forename><surname>Wu</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Yang</forename><surname>Shi</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Nan</forename><surname>Cao</surname></persName>
						</author>
						<title level="a" type="main">Erato: Cooperative Data Story Editing via Fact Interpolation</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.2" ident="GROBID" when="2023-03-27T09:21+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Interpolation</term>
					<term>visual storytelling</term>
					<term>human-machine cooperation</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Fig. <ref type="figure">1</ref>. A data story about natural disasters represented in form of a storyline that was authored by a professional data analyst. The data facts in black (a, c, e, f) were created by the analyst as keyframes of the story, while the facts in red (b, d) were generated based on our interpolation algorithm. The algorithm searches through the fact space to find data facts that best fill the content gap between two keyframes. The story first illustrates an overall situation of global natural disasters (a-c) and gradually focuses on the situation in China (d,e). Finally, it reveals that floods have the most pernicious impact on China (f). The corresponding interpolation process is also shown under the data story. The searching path is marked in red and the nodes with yellow borders are the final selected interpolation results.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>A visual data story is a series of connected data facts shown in form of a narrative visualization, which is usually used to help with information communication <ref type="bibr" target="#b25">[26]</ref>. It has been widely used in many application domains such as business intelligence, data journalism, advertising, and education <ref type="bibr" target="#b39">[40]</ref>. Although important, creating a data story is not an easy task as it acquires multiple skills including data analysis, visualization, graphic design, and storytelling.</p><p>To facilitate the creation of data stories, during the past decades, theories, techniques, and tools have been extensively studied and developed. For example, a series of design spaces have been proposed from two major aspects: the narrative structures <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b59">60]</ref> and the visual representation methods <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b39">40,</ref><ref type="bibr" target="#b43">[44]</ref><ref type="bibr" target="#b44">[45]</ref><ref type="bibr" target="#b45">[46]</ref>, while taking communication goals and tasks into consideration. At the same time, to lower the technical barriers, a number of interactive authoring tools that integrate advanced data analysis and visualization functionalities have been developed <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b52">53,</ref><ref type="bibr" target="#b54">55]</ref>. Although very helpful, using design space or authoring tools to design and create a data story majorly rely on users to make decisions and take actions. The man-made stories are insightful and fluid, but the process is cumbersome, tedious, and inefficient.</p><p>To address this issue, recent studies have been focusing on automatic data story generation based on intelligent algorithms <ref type="bibr">[41-43, 54, 61]</ref>. These techniques, although efficient, suffer from poor quality of the generation results and the lack of humanity, which is usually considered the soul of a story. Therefore, there is a gap between manual story authoring and automatic story generation. A tool that supports human-machine collaborative data story design and editing is desired.</p><p>To fill the gap, we introduce Erato, a human-machine collaborative data story editing system, through which users can design and generate a data story together with a computer. In particular, using the system, a user only needs to concentrate on the key message by inputting a few keyframes (i.e., key data facts). The system will efficiently generate more details of the story by interpolating between any of the two succeeding keyframes. Users can edit both the keyframes and the generated intermediate data facts at any time. When the keyframes are changed, the story content will be updated accordingly. In this way, the system supports the human-machine collaboration to generate data stories efficiently while keeping its humanity via the human-generated keyframes. The major contributions of the paper are as follows:</p><p>• System. We introduce the first intelligent system, to the best of our knowledge, which is designed to support human-machine cooperative data story design and editing <ref type="foot" target="#foot_0">1</ref> . Based on the system, a user can easily generate a data story by only editing a few keyframes and the system will fill the gap by generating a series of data facts to connect the succeeding keyframes. • Data Fact Interpolation Technique. We introduce the first interpolation technique that is able to linearly interpolate between two data facts (usually keyframes in a data story) to generate a series of meaningfully and smoothly connected data facts. • Evaluation. We demonstrate the utility of the proposed system via an interview and case study with three expert users and also show the performance of the fact embedding model via a quantitative evaluation and a controlled user study. A Turing test is also performed to evaluate the overall quality of the story generated based on our technique.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK</head><p>Our work draws inspiration from three areas, including data-driven storytelling, automatic data visualization, and interpolation techniques in data visualization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Data-Driven Storytelling</head><p>Visual data stories refer to a set of story pieces that are visually presented in a meaningful way to deliver an intended message <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b39">40,</ref><ref type="bibr" target="#b48">49]</ref>. Studies showed that incorporating data visualizations in concert with narrative could reveal information effectively <ref type="bibr" target="#b14">[15]</ref> and enhance readers' engagement, memory, comprehension, and communication <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b39">40]</ref>. Therefore, visual data storytelling has gained increasing popularity in many domains and evolved into an important topic in the visualization community <ref type="bibr" target="#b22">[23]</ref>.</p><p>Due to its importance, many theoretical design spaces have been introduced to help clarify the key concepts about visual narratives <ref type="bibr" target="#b30">[31,</ref><ref type="bibr" target="#b39">40,</ref><ref type="bibr" target="#b45">46]</ref> and provide fundamental design principles <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b43">44,</ref><ref type="bibr" target="#b44">45,</ref><ref type="bibr" target="#b59">60]</ref>. Early studies focused on high-level concepts. For example, Segel and Heer <ref type="bibr" target="#b39">[40]</ref> classified narrative visualization into seven genres. McKenna et al. <ref type="bibr" target="#b30">[31]</ref> identified seven key factors for building a fluent visual narrative flow. Stolper et al. <ref type="bibr" target="#b45">[46]</ref> presented four high-level categories of narrative visualization techniques. Recent studies introduce several design spaces that more elaborately provide fundamental design principles from two major aspects: the narrative structures <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b59">60]</ref> and the visual representation methods <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b43">44,</ref><ref type="bibr" target="#b44">45]</ref>, while taking communication goals and design tasks into consideration.</p><p>Based on these theories, techniques and authoring tools have also been proposed to help with the design and creation of visual data stories. For example, chart sequencing techniques <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b40">41]</ref> have been extensively studied for generating a data story by connecting charts to form a meaningful sequence. Some authoring tools <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b37">38]</ref> aim to help users interactively create and place custom annotations to generate a visual narrative, while others are introduced to support data videos <ref type="bibr" target="#b1">[2]</ref>, and time-oriented storytelling <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b13">14]</ref>. Datatoon <ref type="bibr" target="#b18">[19]</ref> is similar to our system in terms of leveraging interpolation techniques. However, we target at a different type of data story in this work, which requires a totally different set of techniques.</p><p>Although very helpful, using the above design space or authoring tools to design and create a data story majorly rely on users to make decisions and take actions. Sometimes, the process is cumbersome, tedious, and inefficient. To address this issue, recent studies have been focusing on automatic data story generation based on intelligent algorithms <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b41">42,</ref><ref type="bibr" target="#b42">43,</ref><ref type="bibr" target="#b60">61]</ref>. For example, Chen et al. <ref type="bibr" target="#b7">[8]</ref> proposed a framework and automatic workflow to bridge the gap between data analysis and communication. AutoClips <ref type="bibr" target="#b41">[42]</ref> optimally organizes data facts in a parallel structure to create data videos. Calliope <ref type="bibr" target="#b42">[43]</ref> automatically generates data stories from a spreadsheet. ChartStory <ref type="bibr" target="#b60">[61]</ref> characterizes charts by their similarity in a fixed layout to form a data story. Although efficient, these tools suffer from their generation quality and lack of user engagement.</p><p>Different from the aforementioned techniques, Erato fills the gap between manually data story authoring and automatic data story generation by striking a balance between machine and human involvements. It ensures the quality of stories, enhances engagement, and improves the efficiency of authoring at the same time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Automatic Data Visualization</head><p>Our work is also related to the broader area of automatic data visualization. As a visual data story is usually composed of individual data visualizations, the automatic extraction and visualization of data insights are essential to the efficiency of the story generation.</p><p>There have been various studies of automatic data visualization over the decades, which can be largely classified into two categories: rule-based techniques and machine learning-based techniques. Rulebased techniques often derive from experimental findings and expert experience. For example, Mackinlay's APT <ref type="bibr" target="#b28">[29]</ref> and Sage <ref type="bibr" target="#b35">[36]</ref> use expressiveness and perceptual effectiveness criteria to enumerate, filter, and score visualizations. Show Me <ref type="bibr" target="#b29">[30]</ref>, Voyager <ref type="bibr" target="#b57">[58,</ref><ref type="bibr" target="#b58">59]</ref> and DIVE <ref type="bibr" target="#b16">[17]</ref> extend the above approach by checking the data types. The machine learning-based approaches train a model to recommend charts or visual encoding methods for input data. For example, Data2Vis <ref type="bibr" target="#b11">[12]</ref> learns an end-to-end generation model to translate data into visualization. DeepEye <ref type="bibr" target="#b27">[28]</ref> and Draco <ref type="bibr" target="#b31">[32]</ref> train a supervised learning-to-rank model to recommend visualizations. VizML <ref type="bibr" target="#b15">[16]</ref> integrates the interpretable measures of feature importance into automatic visualization tools. Text2Vis <ref type="bibr" target="#b8">[9]</ref> employs a natural language processing model to analyze data entities and convert them into proportion charts. Draco <ref type="bibr" target="#b31">[32]</ref> employs answer set programming to automatically find out visual design violations. VizLinter <ref type="bibr" target="#b6">[7]</ref> makes a step further by automatically fixing these violations via linear programming. To ensure efficiency, Erato borrows rule-based methods used in <ref type="bibr" target="#b42">[43]</ref> to automatically visualize story pieces in a number of predefined visualization charts.</p><p>Some other studies capture potentially interesting visualizations based on the statistical properties and insights of the input data, also known as auto-insights. For example, Foresight <ref type="bibr" target="#b9">[10]</ref> helps users rapidly discover visual insights from large high-dimensional datasets. Auto-Vis <ref type="bibr" target="#b55">[56]</ref> recommends interesting relationships between variables in the data. Tang et al. <ref type="bibr" target="#b46">[47]</ref> and Vartak et al. <ref type="bibr" target="#b50">[51]</ref> captured interesting observations derived from aggregation results. DataShot <ref type="bibr" target="#b53">[54]</ref> randomly extracts important insights from the data via statistical methods and displays them in form of a factsheet. Calliope <ref type="bibr" target="#b42">[43]</ref> makes a step further by searching through the data space to extract informative and logically connected data insights to generate a visual data story. Different from these techniques, Erato generates and visualizes informative data insights via interpolating between keyframes in a data story.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Interpolation Techniques</head><p>In the field of data visualization, interpolation techniques have been frequently used in animated transitions to smooth out a visual difference.</p><p>For example, Wittenbrink <ref type="bibr" target="#b56">[57]</ref> proposed a fractal interpolation for two or three dimension visualization. Schlegel et al. <ref type="bibr" target="#b38">[39]</ref> incorporated Gaussian process regression to interpolate uncertain data. Gemini <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b20">21]</ref> recommends animated transitions between charts based on graphical interpolation. In addition, based on specific application scenarios, a variety of interpolation techniques, such as image interpolation <ref type="bibr" target="#b47">[48]</ref>, sequence interpolation <ref type="bibr" target="#b49">[50]</ref>, and surface interpolation <ref type="bibr" target="#b36">[37]</ref>, have been successfully exploited. However, existing techniques interpolate between graphic elements or visual attributes, none of them are able to directly interpolate the data to generate meaningful content used for authoring a data story. In this paper, we introduce a novel interpolation algorithm that is able to interpolate between two data facts to generate the content of story pieces directly.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">SYSTEM OVERVIEW</head><p>This section introduces the design of Erato system. We first provide a formal definition of a data story and the corresponding notations that are used throughout the paper. After that, we summarize the design requirements and introduce the architectural design of the system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Data Story</head><p>In this paper, we borrow and slightly simplify the data story definition introduced in <ref type="bibr" target="#b42">[43]</ref>. In this section, we briefly introduce the key concepts and notations used in this paper as the background but leave the details in <ref type="bibr" target="#b42">[43]</ref> for readers to reference. In particular, we define a data story as a sequence of meaningfully connected data facts that are ordered according to narrative logic. It can be formally represented as { f 1 , f 2 , ⋯, fn}, where f i is a data fact, the elementary building block of the data story. Each fact provides a piece of information extracted from the data, which is formally given by a 5-tuple:</p><formula xml:id="formula_0">f i = {type, subspace, breakdown, measure, f ocus} = {t i , s i , b i , m i , x i }</formula><p>where type (denoted as t i ) indicates the type of information described by the fact. Similar to Calliope, Erato also supports 10 fact types, which are value, difference, proportion, trend, categorization, distribution, rank, association, extreme, and outlier; subspace (denoted as s i ) is given by a set of data filters, i.e., {{F 1 = V 1 }, ⋯, {F k = V k }}, which restrict the data scope of the fact. F i and V i respectively indicate a data field and the selected field value. breakdown (denoted as b i ) is a temporal or categorical data field, which divides a subspace into groups. Each group can be further measured based on a numerical field, indicating by measure (denoted as m i ) via one of the following aggregation methods: count, sum, average, minimum, or maximum. focus (denoted as x i ) indicates a data item or a group that needs to pay attention. For example, regarding to the following fact about the Winter Olympic Games 2022 in Beijing: {"distribution", {{Sex ="Female"}}, {Country}, {sum(Gold Medal)}, {Country="China"}}, it indicates "the distribution (fact type) of the total number of (aggregation method) the gold medals (measure) won by females (subspace) across all the countries (breakdown) and China is the highlight (focus)".</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Design of Erato System</head><p>The design of Erato system was inspired by the users' feedback collected during a series of 5 workshops on data story design, which were organized either by ourselves or by our colleagues in the last year. These workshops involved a total number of 125 participants with various backgrounds, such as university students (major in design, journalism and communication, and computer science), data journalists, citizen journalists, We-Media operators, and data analysts from consultant/IT companies. The goal of the workshops was to teach participants how to author a data story. Each workshop has a focused topic such as "narrative structure", "visualization and infographic design", "data video authoring", "data insight discovery", and "logic transition and animation design". The participants were asked to use design and data analysis tools such as Adobe Illustrator, After Effects, Tableau, and Calliope<ref type="foot" target="#foot_1">2</ref> (a tool developed for automatic data story generation). Through these workshops, we collected a large number of valuable feedback, which eventually inspired us to design and develop the cooperative authoring tool introduced in this paper. The feedback mainly focused on the authoring experience and resulting stories. For example, most of the users felt using these tools to create a data story needed a lot of operations, which was quite inefficient and required much design and data analysis background. They generally liked the idea of automatic data story generation, but they felt the quality of the stories generated by Calliope was not satisfactory. They also believed Calliope limited their control and involvement. We have summarized their comments as the following design requirements: R1 Incorporating Users' Control and Involvement. To ensure the quality of a data story and incorporate users' ideas, the system should directly let the users decide what to tell (i.e., the key message) and how to tell (i.e., the narrative structure) a data story. R2 Improving the Authoring Efficiency. During the data story authoring process, the system should be able to automatically deal with the tedious and cumbersome operations such as exploring the vast data space for potential story pieces or permutably arranging the data facts into a narrative structure. R3 Supporting Smart Interactive Authoring Mechanism. The system should provide a flexible and interactive mechanism that is smart enough to automatically finish some time-consuming tasks to accelerate the authoring process. In this way, users could collaborate with the system toward the same goal of creating a data story.</p><p>To fulfill the requirements, we developed a cooperative data story authoring system, namely Erato, based on a novel fact interpolation technique introduced in this paper. Fig. <ref type="figure" target="#fig_0">2</ref> illustrates the architecture and running pipeline of the system, which consists of three major modules, including the Fact Embedder, the Interpolator, and the Story Editor. Generally, a user starts creating a data story by interactively inputting a number of data facts as key frames and arranging them into a storyline via the Story Editor. In this way, the user decides what to tell (keyframes) and how to tell (narrative structure) the story (R1). After that, the keyframes in the storyline are converted into corresponding vector representations and are projected into a vector space by the Fact Embedder. The Fact Embedder is a pre-trained deep learning model that takes a fact's specification string as the input and converts it into a vector representation to facilitate numerical calculation. Finally, the Interpolator approximately interpolates between the vectors of two specified succeeding key frames to generate viable data facts by searching through the vector space (R2). The results are considered intermediate data facts between these two key frames and presented in the Story Editor. Then the user can further verify, refine, and incorporate them to make a more smooth and more compelling story (R3).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">DATA FACT INTERPOLATION</head><p>In the system, a novel algorithm has been introduced to interpolate between data facts (i.e., key frames) and help users smooth transitions in a story. It first projects data facts to a vector space based on an  embedding model. After that, for a selected pair of succeeding key frames, the algorithm linearly interpolates the corresponding vectors to generate a series of continuously changed latent vectors. Meanwhile, it searches through the fact space to find a series of data facts that best match with the latent vectors as the interpolation results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Fact Embedder</head><p>The fact embedder employs a deep embedding model to covert data facts into vector representations. To support fact interpolation, the embedding should satisfy two criteria: (C1) a vector should capture the data semantics of the corresponding fact; (C2) interpolating between two vectors, (vs, vt ), should generate meaningful results that are not only numerically between (vs, vt ) but also semantically between the corresponding facts.</p><p>With the above requirements in mind, we built a representation learning model (Fig. <ref type="figure" target="#fig_1">3</ref>) for data facts based on BERT <ref type="bibr" target="#b10">[11]</ref>, a pretrained language representation model following the Transformer <ref type="bibr" target="#b51">[52]</ref> architecture. The major advantages of adopting BERT are three folds:</p><p>(1) it adopts a masked mechanism and next sentence prediction to respectively provide a vector representation of both words and sentences that better captures the meaning of an input string; (2) it is trained based on a large text corpus, thus having a good generalization capability; (3) studies showed that BERT could be fine-tuned for a specific task based only on a small set of training samples <ref type="bibr" target="#b32">[33]</ref>.</p><p>Given all the above benefits, we implemented our representation learning model by directly adding two fully connected layers on top of BERT as shown in Fig. <ref type="figure" target="#fig_1">3</ref>. Then, we fine-tuned the model based on a training set collected from a set of manually designed visual narratives, each of which essentially was a sequence of logically connected data facts. Specifically, each training value was a trigram of the facts in the dataset, which captured logical relationships between facts but, at the same time, reduced the unnecessary complexity caused by long stories. We converted each of the data fact in a trigram into a tokenized string to fit the input format of our representation learning model: "[type]fact-type [subspace]field,value [measure]field,agg [breakdown]field [focus]value [meta]extra-info". In addition to the five tuples for a fact (Section 3), we added the meta information to provide extra useful information about the fact. For example, when the fact type is "trend", the extra information will be "increasing" or "decreasing", which indicates the specific type of trend; when the fact type is "extreme", the extra information will be "minimum" or "maximum". The experiment showed that adding this information will increase the accuracy of the embedding results.</p><p>Loss Function To yield a meaningful fact embedding (C1) and interpolation results (C2), the following loss has been designed and used when training the model:</p><formula xml:id="formula_1">L = ∑ (vi−1,vi,vi+1)∈Ds d(v i , m i ) 2 + α ⋅ d(v i , v j ) 2<label>(1)</label></formula><p>where v indicates the vector representation of a data fact; Ds denotes the set of training samples, which are the trigrams of facts, i.e., (v i−1 , v i , v i+1 ); d(⋅) calculates the euclidean distance between two vectors. The first term estimates the differences between the embedded vector v i and the euclidean midpoint</p><formula xml:id="formula_2">m i = (v i−1 + v i+1 )/2.</formula><p>The second term estimates the length of a trigram in Ds. α balances between these two parts. Basically, this loss function tends to reduce the distance between related facts and try to line up the vectors in a trigram.</p><p>Training Corpus To train the model, we selected 100 high-quality data stories that were manually authored by our workshop participants based on different datasets using the Calliope system. All of these stories consist of 5 data facts with diverse fact types. They were designed by following either the time-oriented narrative structure <ref type="bibr" target="#b24">[25]</ref> or the parallel structure <ref type="bibr" target="#b41">[42]</ref>. 300 fact trigrams were extracted from these stories as our training set. Each of them consisted of 3 succeeding data facts in the original story.</p><p>Implementation We implemented the above model in PyTorch. We chose Adam optimizer and updated all the training parameters with a learning rate of 0.01. The model was trained on an Nvidia Tesla-V100 (16GB) graphic card.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Interpolator</head><p>In Erato, the interpolator is designed to interpolate between two data facts ( fs, ft ) to generate new facts in the middle that semantically con- nect fs and ft as the new story content. The interpolation process consists of three major steps. We first convert the facts into their vector representations vs and vt based on the fact embedding technique introduced above. After that, we directly calculate the linear interpolation between vectors as follows:</p><formula xml:id="formula_3">v k = vs + k N + 1 ⋅ (vt − vs) (<label>2</label></formula><formula xml:id="formula_4">)</formula><p>where N is the total number of midpoints to be calculated. It is a user input which controls the length of the resulting story;</p><formula xml:id="formula_5">v k (k ∈ [1, ⋯, N])</formula><p>is the k-th vector interpolation between vector vt and vs. Here, linear interpolation is chosen due to the explainability and intuitiveness of its results that make the evaluation simple. Finally, we search through the fact space to find a data fact whose vector representation is the most similar to v k as the final output of the k-th fact interpolation.</p><p>In our system, we employed the Monte Carlo Tree Search algorithm (MCTS) <ref type="bibr" target="#b4">[5]</ref> to ensure efficient searching through the fact space to find proper interpolation results. In particular, this algorithm dynamically constructs a searching tree T based on a set of predefined actions to explore the vast fact space. As shown in Fig. <ref type="figure" target="#fig_2">4</ref>(a), each node in the tree is a data fact f i and each directed edge indicates an action through which a child node is created.</p><p>These constraints were carefully selected based on the inspection of our embedding space characteristics using numerous experiments. It helps us to eliminate the data facts that might be irrelevant to the story.</p><p>Here, we carefully defined a number of constrained actions for the algorithm to choose under different conditions (Table <ref type="table" target="#tab_1">1</ref>). The constraints were set by inspecting the changes of a fact's vector in the embedding space after performing different actions. These constraints guarantee to generate nodes (i.e., facts) that are meaningful and closely related to their predecessor. Generally, the MCTS iteratively runs the following four steps to search through a vast searching space until the target is reached:</p><p>(1) select the node f i with the largest reward score in T (Fig. <ref type="figure" target="#fig_2">4(a)</ref>);</p><p>(2) expand f i by creating a number of related facts via the set of predefined actions (Fig. <ref type="figure" target="#fig_2">4(b)</ref>); (3) simulate the search based on f i and its descendants to explore a few steps further, so that the different searching directions can be estimated in advance (Fig. <ref type="figure" target="#fig_2">4(c</ref>)); (4) update the reward score on each node in T that is calculated during the simulation (Fig. <ref type="figure" target="#fig_2">4(d)</ref>).</p><p>A reward function is designed to estimate the quality of each searching path in the tree. The reward scores are marked on the tree nodes. They are used to guide the exploration of fact space. To ensure fast and precise searching, we define the reward to align the searching direction with the interpolation direction indicated by → vsvt (Fig. <ref type="figure" target="#fig_3">5</ref>). Formally, the reward is defined as:</p><formula xml:id="formula_6">reward( f i ) = − 1 i i ∑ j=1 |v j − (v * j−1 + vt − vs |vt − vs| ⋅ |v j − v * j−1 |)|<label>(3)</label></formula><p>where f i is a node (i.e., a data fact) in T that is under estimation whose vector representation is v i as shown in Fig. <ref type="figure" target="#fig_3">5</ref>. v j in Eq. 3 is the vector </p><formula xml:id="formula_7">S = { fs, f 1 , ⋯, f N , ft } ← Match(I * , T ); 12 return S;</formula><p>representation of a node (i.e. fact f j ) in the searching path ending at f i . v * j is the expected position of v j on → vsvt in the vector space. It is determined by the step length of the current search, i.e., |v j − v * j−1 |. Ideally, when the searching path is perfectly aligned with → vsvt , v j and v * j will be precisely overlapped. The above reward estimates the averaged vector distance between the actual searching path and the desired interpolation path alone → vsvt . A searching path closer to → vsvt is encouraged. The leading negative sign is added to make the reward optimization a maximization problem.</p><p>The algorithm ends at a point when it tries to expand a node whose vector representation is close enough to the target node's vector vt in the vector space. The nodes in the searching path with the largest reward in T are examined. And the ones that are the closest to the midpoints calculated based on equation 2 are taken as the interpolation results. In this way, all the interpolated facts between fs and ft could be found through the same searching process.</p><p>Algorithm Overview Alg. 1 summarizes the above ideas in pseudo-codes under the MCTS's algorithm framework. In particular, the algorithm takes a pair of endpoint facts ( fs, ft ), the total number of midpoints to be interpolated N, and a spreadsheet D as the inputs. A set of N data facts that meaningfully connects fs and ft are generated as the output. Initially, fs and ft are added into an empty set S (line 1) and are converted into their vector representations vs and vt based on our fact embedding technique (line 2). We use v * to indicate the vector representation of the data fact that is under exploration, which is initially set to vs and set the corresponding data fact fs as the root of the search tree T (line3). After that, we calculate the linear interpolation between vs and vt in the vector space and store all the resulting midpoints in I * (line4). Next, the algorithm searches through the fact space to find a set of best fits to I * via three major steps: TreePolicy(⋅), DefaultPolicy(⋅), and BackPropagation(⋅). In particular, the TreePolicy(⋅) selects a node with the largest reward in T and expends it by creating a set of data facts (denoted as F i ) as its children using the actions summarized in Table <ref type="table">.</ref> 1 (line 6, Fig. <ref type="figure" target="#fig_2">4(a,b</ref>)). The DefaultPolicy(⋅) simulates the search based on f ∈ F i to explore the fact space a few steps further to find the best searching direction f i → f * , where f * ∈ F i has the largest reward Δ * (line 7, Fig. <ref type="figure" target="#fig_2">4(c)</ref>). The reward Δ * of f * is then back-propagated to all the relevant nodes in T and f * is added into T as a child of f i (line 8, Fig. <ref type="figure" target="#fig_2">4(d)</ref>). The above process is iteratively processed until the current best node f * is close enough to the target node ft . Finally, the searching path in T with the largest reward is used to make a match with the midpoints in I * (line 11), and the set of facts that are closest to the midpoints in I * are returned in order as the interpolation results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">STORY EDITOR</head><p>In this section, we introduce the design of the story editor, which aims to provide an intuitive experience for users to explore, refine the interpolated facts, and eventually assemble them into a fluent story. The story editor, as shown in Fig. <ref type="figure" target="#fig_4">6</ref>, consists of four connected views.</p><p>Once a user uploads a spreadsheet into the system, the raw data is displayed in the data story view (Fig. <ref type="figure" target="#fig_4">6-1</ref>). Then, the user can explore the data and select the data fields and elements that he/she is interested in by setting data filters in the configuration panel under the story mode (Fig. <ref type="figure" target="#fig_4">6-2(b)</ref>). Based on the selected data corpus, the underlying system analyzes and recommends a set of important data facts to help users quickly understand the data and inspire them to create meaningful and interesting stories (Fig. <ref type="figure" target="#fig_4">6</ref>-2(c)), which avoids the cold start problem.</p><p>To create a data story, a user first needs to specify a sequence of key facts and arrange them in the storyline view (Fig. <ref type="figure" target="#fig_4">6-4</ref>). In particular, the user can either manually insert an empty fact anywhere in the storyline (e.g., the empty fact shown in Fig. <ref type="figure" target="#fig_4">6-4</ref>) or simply instruct the system to interpolate between any two succeeding facts in the storyline. When a data fact f i is selected from the storyline, the fact configuration panel is displayed (Fig. <ref type="figure" target="#fig_4">6-3</ref>), in which the user can edit the fact's text descriptions (Fig. <ref type="figure" target="#fig_4">6-3(b)</ref>) and its type, measure, breakdown, subspace, and focus fields (Fig. <ref type="figure" target="#fig_4">6-3(c)</ref>). A preview of the fact is shown on top of the panel as a visualization chart (Fig. <ref type="figure" target="#fig_4">6-3(a)</ref>) and the data snippet corresponding to the fact is also shown in a table at the bottom (Fig. <ref type="figure" target="#fig_4">6-3(d)</ref>). The preview and table provide details and guide the user to create a proper data fact for the story. When the selected fact f i has a predecessor f i−1 and a successor f i+1 in the storyline, our system will automatically interpolate between f i−1 and f i+1 . All valid facts on the interpolation path are displayed in a recommendation list (Fig. <ref type="figure" target="#fig_4">6-3(e)</ref>) as they are the candidates that could be potentially used to replace f i , thus providing users with more story ideas.</p><p>Finally, the generated data story is shown in the data story view (Fig. <ref type="figure" target="#fig_4">6-1</ref>) in a form of a storyline (Fig. <ref type="figure">1</ref>), a factsheet (Fig. <ref type="figure" target="#fig_7">9</ref>), or a scroll-up view (Fig. <ref type="figure" target="#fig_8">10</ref>). The user can easily switch between different representation forms via a drop-down menu. The story view is implemented based on the library released by the Calliope project <ref type="bibr" target="#b0">[1]</ref>. In particular, a chart library is used for visualizing individual facts and a data story library is used for showing stories in the aforementioned different forms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">EVALUATION</head><p>We evaluated Erato and the corresponding key techniques via both quantitative experiments and controlled user studies. In particular, we first verified the consistency between the fact's vector representation and human cognition via a user study. Next, we evaluated the interpolation results via a quantitative experiment that measured their overall performance and a Turing test that estimated the quality of the generated content from the human perspective. Finally, three case studies together with domain expert interviews were conducted to verify the overall usability of the system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Evaluation of the Fact Embedding Results</head><p>We conducted a user study to verify the consistency of the fact similarities calculated based on the facts' embedding vectors and the fact similarities perceived by users regarding to the facts' semantics. A consistent result indicated that our embedding technique was able to successfully capture the fact semantics and their relationships.</p><p>Procedure and Tasks. We first prepared 30 manually generated data facts for the study. Each fact, f i , was accompanied by two other randomly generated data facts ( fa, f b ) whose cosine similarities to f i were calculated as the ground truth. We ensured the difference between fa and f b was smaller than 0.25 to check if the participants were sensitive to small differences. As a result, 30 triplets of data facts were prepared. In the study, we showed one triplet at a time to a participant and asked him/her to identify the fact closer to f i based on his/her own judgments. Their answers were recorded and the corresponding accuracy (i.e., the percentage of right answers) was calculated.</p><p>To make sure the participants fully understand the data insight captured by a fact, each fact was shown in a visualization chart with a caption manually written by us in an offline procedure. To ensure a fair and comprehensive comparison, these facts were generated based on 6 datasets covering 6 different topics, including public health, politics, economy, sports, recreation, and industry which had similar schema and data distributions. We also counterbalanced the fact types. During the test, we encouraged the participants to first understand the data insights before providing their answers. 30 participants (7 males and 23 females, mean age 24) were involved in this study. It took an average of 15 minutes for a participant to finish all 30 triplets.</p><p>Results. On average, the accuracy was 89% with a standard deviation of 0.08. This result suggested that in most testing cases, the participants agreed that the computationally more similar facts were also perceivably more similar. It verified that our embedding algorithm was consistent with human cognition.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Evaluation of the Fact Interpolation Results</head><p>We estimated the interpolation technique through a quantitative evaluation to check the precision of the interpolation results. A Turing test was also performed to verify that the results also aligned with a human's perception.</p><p>Quantitative Evaluation We performed 5-fold cross-validation to estimate the performance of the proposed interpolation technique based on the dataset introduced in Section 4.1. In particular, the dataset was first divided into five equal folds, each containing 60 fact trigrams. In the next, we used four folds of data to train the fact embedding model but left the rest one fold for testing the performance of the interpolation technique based on the embedding model. The whole training and testing process was interactively performed five times with a fold of training and testing data shifting at each time.</p><p>The training phase was to fine-tune BERT based on our loss function as described in Section 4.1. During the testing phase, we interpolated between the first fact and the last fact in a trigram in the testing set. The interpolation results, i.e., a sequence of data facts S = { f 1 , ⋯, fn}, were compared to the ground truth (the second fact in the trigram) in terms of cosine similarity via two strategies: (1) comparing with the middle fact f ⌈n/2⌉ ; (2) comparing with the closet fact, i.e., the fact in S that was the most similar to the ground truth. On average, the similarities for strategy (1) and (2) were 0.944 (σ = 0.034) and 0.953 (σ = 0.045), respectively. The cross-validation results were shown in Fig. <ref type="figure" target="#fig_5">7</ref>.</p><p>Turing Test To verify that our algorithm was able to create highquality results from a user's perspective, we also performed a Turing test to let users differentiate the data stories that were fully generated by human designers (denoted as G h ) from those that were partially generated by our interpolation algorithm (denoted as Gm). We established the following hypotheses: H1 There was no significant semantic difference between the humangenerated (G h ) and interpolation-based (Gm) results. H2 Gm's quality was as good as that of G h in terms of the coherence of the corresponding data stories.</p><p>Procedure and Tasks. The Turing test consisted of two stages. In the first stage, we invited 2 senior graduate students to manually create short data stories consisting of 5 data facts using our system with the interpolation feature disabled. Both students were female from a top design college and had rich experience in designing visual data stories. They were provided with 15 datasets covering 5 different topics, including public health, society, economy, sports, and recreation. In total, 15 data stories (G h ) were created based on these datasets with diverse and balanced topics (3 stories for each topic). After that, we replaced the middle three data facts of each data story with another three data facts generated by interpolating between the first and the last data facts based on the proposed technique. As a result, another 15 stories (Gm) were created. Here, we controlled the story length as five to make it not too short so that the interesting content could be captured but also not too long so that the participants could easily read them without spending too much time. We chose to replace three middle facts as we would like to replace the human-generated facts in each data story as many as possible, so that we could clearly check whether the facts generated by our algorithm would affect the coherence of the data story or not.</p><p>In the second stage. we randomly mixed all 30 stories together and put them into an online questionnaire. Another 50 participants (18 males and 32 females, mean age 28.78) were invited to differentiate these data stories. These participants had diverse backgrounds. Some of them were university students majoring in design, architecture, computer science, and mathematics. Some of them were employees in an IT consulting company, faculty members in a university, and data journalists from a news media. In the questionnaire, we showed one story at a time to a participant, who was asked to finish the following two tasks designed regrading to the above hypotheses: T 1 Tell whether the story was fully generated by a human or partially generated by a machine regarding its content. T 2 Rate the quality of the story in terms of its logic coherence using a 5-point Likert scale with 5 indicating the best quality.</p><p>To facilitate understanding, each fact was presented as a visualization accompanied by a manually-written caption. At the end of each test, we encouraged the participants to leave the reasons for their decisions, so that we could find the potential limitations of our technique. On average, each participant spent about 20 minutes completing the test.</p><p>Results. We first reported the accuracy of each group and then discussed the feedback from the participants.</p><p>Accuracy. Fig. <ref type="figure" target="#fig_6">8</ref>(a) showed the results of the first task (T 1), where yaxis indicated the percentage of positive ratings (i.e., identified as fully human generated). Not surprisingly, the performance of G h (M = 0.53, SD = 0.16) was better than that of Gm (M = 0.48, SD = 0.13). However, a paired t-test showed that the difference was not significant (α = 0.05, p = 0.32), thus H1 accepted. Fig. <ref type="figure" target="#fig_6">8(b)</ref> showed the results of the second task (T 2), where y-axis indicated the Likert rating on the data story quality. Again, there was no significant difference (α = 0.05, p = 0.06) between two groups, but G h had a better average rating Human (M = 3.79, SD = 0.39) than that of Gm Erato (M = 3.51, SD = 0.32)(Fig. <ref type="figure" target="#fig_6">8(b)</ref>), thus H2 accepted as well.</p><p>Feedback. During the study, almost all the participants indicated that the data stories were very subjective and they relied primarily on their intuitions to make inferences. They also left their reasons and comments on their choices which were summarized as follows:</p><p>• Logicality, regarding the narrative structures. Three participants pointed out that stories created by people tended to have more complex narrative structures, such as the three-act structures, but "the algorithm tends to generate a parallel structure". At the same time they also mentioned "it is difficult to differentiate stories with a timeoriented structure". We believed this was because it was easier for the algorithm to interpolate on the temporal dimension to generate similar and parallel content. At the same time, we acknowledged that taking narrative structure into consideration was indeed a missing part of the proposed algorithm. • Diversity, regarding the variety of the fact types and the complexity of the data content. Several participants believed stories generated by humans should contain rich fact types which made the whole story vivid. Therefore, they tended to judge stories that contained duplicate content or data facts of the same type as machine-generated. This finding reminded us that even for an interpolation task, the diversity of the content was as important as logical smoothness. • Meaningfulness, regarding the meaning of telling a story. A number of participants mentioned that the story of human creation might connote a certain trend and allow readers to draw some conclusions from it. One participant pointed out that "it will be more likely to be generated by a human if the story is thought-provoking". In addition, some participants believed "[people] not tend to illustrate data facts of common senses". We believed generating insightful stories was a great challenge for a fully automated algorithm, which showed the value of human-machine collaboration.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Interview with Experts</head><p>To further evaluate the usability of Erato, we conducted a semistructured interview with three domain experts (denotes by E1-E3).</p><p>The first expert was a data analyst with 3 years of working experience, whose major job was to analyze customer data. The second expert, a senior designer, had 5 years of experience in creating infographics.</p><p>The third expert was a data journalist who had more than 4 years of working experience and was familiar with data storytelling and data story authoring. Datasets We collected three datasets covering three different topics: natural environment (D1), entertainment (D2), and sports competition (D3). Specifically, D1 contained all the natural disasters worldwide since 2000 (8958 rows, 9 columns). It recorded disaster types, subtypes, year, month, country, region, continent, the number of deaths, and affected people. D2 contained all Disney films produced since 1937 (375 rows, 9 columns), including the movie's title, genre, year of release, country, language, running time, box office, and IMDB ratings. D3 recorded the number of gold, silver, and bronze medals won by a country in each type of sport during the 2022 Winter Olympics (118 rows, 6 columns). These three datasets were used for the case study and had been respectively distributed to the experts.</p><p>Procedure and Tasks Because of the COVID-19 pandemic, all the interviews were conducted online. At the beginning of each interview, we introduced the purpose of our study as well as the data content. We briefly demonstrated Erato system. Each expert then spent 10 minutes familiarizing him/herself with Erato and was asked to use it to create a data story consisting of six data facts with the given dataset based on Erato. All the experts were encouraged to think aloud during the creation process. In order not to interfere with their creative thinking, we did not set any time limit to the process. The experts might work as long as they want. We saved the final stories created by these experts. On average, it took about 30 minutes for an expert to create a story. After creating the stories, interviews were performed separately to collect their comments on three aspects: (1) the coherence of the interpolated facts and the usefulness of the technique; (2) the overall quality of the generated data stories, and (3) the usability of Erato. Each interview lasted for about one hour with the processes recorded for later analysis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Study Results</head><p>We first reviewed the stories generated by our expert users during the case study and then presented their comments on our techniques and systems that were collected during the interview.</p><p>The authored data stories. Three data stories authored by our experts were illustrated in Fig. <ref type="figure">1</ref>, Fig. <ref type="figure" target="#fig_7">9</ref>, and Fig. <ref type="figure" target="#fig_8">10</ref>. In these data stories, the data facts generated by interpolation were marked in red, whereas the keyframes input by users were marked in black.</p><p>Fig. <ref type="figure">1</ref> shows a data story entitled "Nature is Sounding the Alarm" that was created by E1 based on the natural disaster dataset (D1). It consists of four keyframes (Fact a, c, e, f ) and two interpolated data facts (Fact b, d). Specifically, over the past decades, a number of regions suffered from natural disasters (Fact a). Geographic distribution of their occurrences showed how frequently these regions had been affected (Fact b). The top three most influenced areas were Asia, America, and Africa (Fact c). Nearly 40% of disasters occurred in Asia (Fact d), with China having the highest incidence of disasters (Fact b). The three most frequently occurring natural disasters in China were tropical cyclones, river floods, and earthquakes (Fact e), with flooding having the most serious impact (Fact f ), which needed more attention.</p><p>Fig. <ref type="figure" target="#fig_7">9</ref> presents a story about Disney movies (D2) created by E2, which consists of three keyframes (Fact a, c, f ) and three interpolated facts (Fact b, d, e). In particular, during the past 80 years, Walt Disney has released a number of films. Especially after 1995, the number of films released a year increased dramatically but gradually decreased in recent years (Fact a). On average, the annual box office was over 160 million USD (Fact b). The top three films with the best box office were the Lion King, Frozen II, and Frozen (Fact c), and the best one, the Lion King even took about 3% of total box offices in Disney's history (Fact d). Its IMDB rating was 8.5, which was quite a high score (Fact e). The statistics showed that the IMDB rating was positively correlated with the box offices (Fact f ).  e). Specifically, many countries in the world took part in the game and won a medal (Fact a). Among all these countries, Norway won the most medals, making it an outlier (Fact b). The total number of gold medals in Norway was 16 (Fact c). It ranked number one on the Olympic gold medal list (Fact d). In addition, the three strongest sports of the Norwegian team were biathlon, cross-country skiing, and nordic combined. Norway won the most gold medals in biathlon (Fact e), with five more medals than in freestyle skiing (Fact f ) which also revealed Norway's strength in biathlon.</p><p>Interview Feedback. In the follow-up interview, the expert provided a number of valuable comments that were summarized as follows:</p><p>The usefulness of the interpolation. All the experts agreed the proposed interpolation technique was very helpful in terms of supporting both data exploration in context (E1) and data story editing (E2,3). In particular, E1 mentioned "this feature [interpolation] is able to provide meaningful insights in the context ... is better than the quick insight features provided in other BI tools that can only generate random insights". E2 was also impressed by our interpolation algorithm. She felt "it is a smart function that helps complete a smooth data story". She also mentioned "it [the interpolation technique] facilitates the ideation process, ..., especially when I haven't figured out how to tell a story." E3 mentioned "it [the interpolation feature] indeed saved many of my data exploration efforts when creating a story".</p><p>The quality of the interpolation results. All the experts were satisfied with and impressed by the interpolation results. E1 mentioned "the generated logical order is reasonable and makes the data easier to understand". E2 was impressed by the insightful data facts automatically generated by our interpolation algorithm. She said "it is surprising that the system is able to suggest such meaningful content [i.e., data facts] based on my inputs". E3 felt "the resulting data facts are coherent in both logic and content". She said "before using this tool, I didn't realize the intelligent techniques could be so useful ..., it even can create such a good story content [in an automatic process]".</p><p>The authoring tool. All the experts liked the idea of letting users cooperatively design a story with the help of an intelligent system based on the interpolation technique. They believed Erato was an "effective data story authoring tool, especially for users who lack experience" (E2,3). In particular, E2 believed the system's interpolation and recommendation features were nice functions that "provide necessary and helpful inspirations for authoring a data story". She also felt the design of the system was "intuitive" and "easy to get started quickly". E3 said, "I can easily create a data story with the help of the system". She mentioned "it is very important to let users input the keyframes, which gives them a right to control [the content and structure of] the story". At the same time, she also agreed that "interpolation feature will save users' efforts" and "let them focus more on the important part". E1 felt the tool was able to "help people explore the insights in the data and support users to express their ideas".</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">LIMITATIONS AND FUTURE WORK</head><p>While the evaluation results indicate Erato is promising to help users create insightful and fluent data stories, the system still has several limitations that were found during the implementation or mentioned by the participants during interviews. We hope to guide potential future research directions by pointing out these limitations.</p><p>Enriching Visualization. E1,2 would like to have additional formats such as slides and dashboards, to support more application scenarios. E2,3 also felt the provided charts were rather conventional and notably simple. They would like to have more advanced visual representations to make the data stories vivid and engaging.</p><p>Boosting the Creativity. The story editor is not designed to boost users' creativity. For example, users cannot change the size and position of a chart in a factsheet. They also cannot add icons or background images to enhance the narrative of the data story.</p><p>Improving Performance and Quality. The design and implementation of the current system have some performance bottlenecks. It usually takes about 10-40 seconds to run the interpolation algorithm, which, sometimes results in considerable waiting time. The quality of the embedding model could be further improved by training it based on data stories with more sophisticated designs. In addition, although the proposed algorithm is able to generate meaningful data facts, it cannot create soulful stories that are able to affect readers.</p><p>Conducting Thorough Evaluations. In this work, we did not compare the data stories generated based on Erato with those automatically generated ones as we cannot control the story topic even using the stateof-the-art automatic story generation technique. Second, the Turing test also has limitations as the quality of the human-generated stories could be affected by Erato's editing functionality. More in-depth evaluations may help us identify more pain points and future directions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">CONCLUSION</head><p>In this paper, we have presented Erato, the first intelligent system designed for supporting human-machine cooperative data story design. The system employs a fact interpolation algorithm to create intermediate facts that smooth the transition between two succeeding data facts. The proposed technique was evaluated via a series of evaluations including a Turing test, a controlled user study, a performance validation, and interviews with expert users. The evaluation showed the proposed technique is sound and well accepted by our users. Just like the interpolation technique greatly accelerates the creation of animations, we believe the future development of the data content interpolation technique first introduced in this paper will greatly accelerate the traditional data story authoring process and the proposed fact embedding model will be extended and used in many visual content generation tasks.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. The running pipeline of the Erato system.</figDesc><graphic url="image-3.png" coords="3,445.83,72.77,99.33,137.49" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Schematic diagrams of the fact embedding model.</figDesc><graphic url="image-5.png" coords="4,64.07,230.26,230.83,135.72" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. An iteration of the Monte Carlo tree search algorithm consists of four steps, including (a) selection, (b) expansion, (c) simulation, and (d) back-propagation.</figDesc><graphic url="image-6.png" coords="4,313.90,230.56,230.92,89.93" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. The fact interpolation via MCTS in the vector space.</figDesc><graphic url="image-7.png" coords="5,64.25,73.00,230.83,112.83" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 6 .</head><label>6</label><figDesc>Fig.6. The interface consists of four major components: the data story view 1 , two configuration panels for the story mode 2 and the fact mode 3 , respectively, and the storyline view 4 .</figDesc><graphic url="image-10.png" coords="6,442.31,73.00,95.02,207.82" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 7 .</head><label>7</label><figDesc>Fig. 7. The 5-fold cross-validation of the interpolation technique.</figDesc><graphic url="image-12.png" coords="7,79.08,73.00,203.67,129.21" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 8 .</head><label>8</label><figDesc>Fig. 8. Means and standard errors of each item. (a) Percentage of stories perceives as human, (b) ratings on the quality of data stories using a 5-point Likert scale.</figDesc><graphic url="image-13.png" coords="7,330.45,73.00,192.40,122.17" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 9 .</head><label>9</label><figDesc>Fig. 9. A data story about Disney movies represented in form of a factsheet that was authored by an expert user using Erato during our interview. The data facts (a, c, f) were created by the user, based on which the facts (b, d, e) were generated based on the proposed interpolation technique. The story first shows the number of films released each year over the past 80 years (a), followed by the average annual box office (b) and the corresponding ranking of films (c). It gradually focuses on the most popular movie "The Lion King" (d, e), and concludes that the IMDB rating is positively correlated with the box office (f).</figDesc><graphic url="image-14.png" coords="8,314.11,72.92,230.83,324.50" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 10</head><label>10</label><figDesc>illustrates a data story about the Winter Olympic Games 2022 held in Beijing (D3), which was created by E3. The story included three keyframes (Fact a, d, f ) and three interpolated facts (Fact b, c,</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig. 10 .</head><label>10</label><figDesc>Fig. 10. A data story about the Winter Olympic Games 2022 represented in form of an scroll-up view, which is created by a data journalist using Erato during our interview. The data facts (a, d, f) were created by the journalist as the keyframes for the story, based on which (b, c, e) were generated based on our interpolation technique. The story first illustrates an overall geographical distribution of medal-winning countries (a) followed by an elaboration of specific data from Norway, the topranked country in the Winter Olympics (b-e). The story finally makes a comparison between biathlon and freestyle skiing and reveals Norway's strength in biathlon (f).</figDesc><graphic url="image-15.png" coords="9,68.77,73.00,226.34,263.49" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic url="image-1.png" coords="1,87.36,135.93,429.13,230.50" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 .</head><label>1</label><figDesc>Definitions of the 7 constrained actions under different conditions, where NUM indicates the number of values or fields in the attribute. fs, ft represent the selected pair of keyframes. The action can be performed only when the condition is satisfied.</figDesc><table><row><cell>Action Name</cell><cell>Condition</cell><cell>Description</cell><cell>Goal</cell></row></table><note>modifyBreakdown Breakdown( fs)≠ Breakdown( ft ) Change the breakdown from f ield1 to f ield2 To approach Breakdown( ft ). modifyMeasure Measure( fs)≠ Measure( ft ) Change the measure from f ield1 to f ield2 To approach Measure( ft ).</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>Algorithm 1: Interpolation Algorithm based on MCTS Input : fs, ft , N, D Output :S = { fs, f 1 , ⋯, f N , ft } 1 S ← Initialize({ fs, ft }); 2 vs ← embed( fs); vt ← embed( ft ); 3 v * ← vs; T ← { fs}; // Calculate the midpoints in the direction of the storytelling → vsvt . 4 I * ← interpolate(vs, vt , N) ; 5 while |v * − vt | &lt; λ do // The TreePolicy consists of two steps: when the node is not fully expanded, it first selects the best child in T and then expands the corresponding nodes within the executable actions. // The DefaultPolicy is then used until the time limit has been reached. It simulates and calculates the reward to choose the node with the maximum reward.</figDesc><table /><note>6F i ← T REEPOLICY (T ); 7 Δ * , f * ← DEFAULT POLICY (F i ); // Update the reward score on each node in T that is calculated during the simulation. 8 BackPropagation(T , f * , Δ * ); 9 v * ← embed( f * ); 10 end // Choose the best path in T that matches the midpoints as a data story. 11</note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0">https://erato.idvxlab.com/project/</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1">https://datacalliope.com</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS</head><p>Nan Cao is the corresponding author. This work was supported by NSFC 62072338, 62061136003 and NSF Shanghai 20ZR1461500.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<ptr target="https://www.npmjs.com/package/calliope-chart" />
		<title level="m">Calliope visual story chart library</title>
				<imprint>
			<date type="published" when="2022-07-28">July 28, 2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Authoring data-driven videos with dataclips</title>
		<author>
			<persName><forename type="first">F</forename><surname>Amini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">H</forename><surname>Riche</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Monroy-Hernandez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Irani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="501" to="510" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Beyond memorability: Visualization recognition and recall</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Borkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Bylinskii</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">W</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">M</forename><surname>Bainbridge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">S</forename><surname>Yeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Borkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Pfister</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Oliva</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="519" to="528" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Timeline storyteller: The design &amp; deployment of an interactive authoring tool for expressive timeline narratives</title>
		<author>
			<persName><forename type="first">M</forename><surname>Brehmer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">H</forename><surname>Riche</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Tittsworth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Lytvynets</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Edge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>White</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Computation+ Journalism Symposium</title>
				<meeting>the Computation+ Journalism Symposium</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="1" to="5" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">A survey of Monte Carlo tree search methods</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">B</forename><surname>Browne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Powley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Whitehouse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Lucas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">I</forename><surname>Cowling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Rohlfshagen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Tavener</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Perez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Samothrakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Colton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Computational Intelligence and AI in Games</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="43" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Temporal summary images: An approach to narrative visualization via interactive annotation generation and placement</title>
		<author>
			<persName><forename type="first">C</forename><surname>Bryan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K.-L</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Woodring</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="511" to="520" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Vizlinter: A linter and fixer framework for data visualization</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Cao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="206" to="216" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Supporting story synthesis: Bridging the gap between visual analytics and storytelling</title>
		<author>
			<persName><forename type="first">S</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Andrienko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Andrienko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">H</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Turkay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="2499" to="2516" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Text-to-viz: Automatic generation of infographics from proportion-related natural language statements</title>
		<author>
			<persName><forename type="first">W</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-G</forename><surname>Lou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="906" to="916" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">¸</forename><surname>Demiralp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Haas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Parthasarathy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Pedapati</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1707.03877</idno>
		<title level="m">Foresight: Recommending visual insights</title>
				<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M.-W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
		<author>
			<persName><surname>Bert</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1810.04805</idno>
		<title level="m">Pre-training of deep bidirectional transformers for language understanding</title>
				<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Data2vis: Automatic generation of data visualizations using sequence-to-sequence recurrent neural networks</title>
		<author>
			<persName><forename type="first">V</forename><surname>Dibia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Demiralp</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer Graphics and Applications</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="33" to="46" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Narrative visualization: Sharing insights into complex data. Interfaces and Human Computer Interaction (IHCI)</title>
		<author>
			<persName><forename type="first">G</forename><surname>Dove</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Jones</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="21" to="23" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">TimeLineCurator: Interactive authoring of visual timelines from unstructured text</title>
		<author>
			<persName><forename type="first">J</forename><surname>Fulda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Brehmer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Munzner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="300" to="309" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">What storytelling can do for information visualization</title>
		<author>
			<persName><forename type="first">N</forename><surname>Gershon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Page</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="31" to="37" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Vizml: A machine learning approach to visualization recommendation</title>
		<author>
			<persName><forename type="first">K</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Bakker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Kraska</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Hidalgo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the CHI Conference on Human Factors in Computing Systems</title>
				<meeting>the CHI Conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="1" to="12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">DIVE: A mixed-initiative system supporting integrated data exploration workflows</title>
		<author>
			<persName><forename type="first">K</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Orghian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Hidalgo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Workshop on Human-In-the-Loop Data Analytics</title>
				<meeting>the Workshop on Human-In-the-Loop Data Analytics</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="1" to="7" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">A deeper understanding of sequence in narrative visualization</title>
		<author>
			<persName><forename type="first">J</forename><surname>Hullman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Drucker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">H</forename><surname>Riche</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Fisher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Adar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2406" to="2415" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Datatoon: Drawing dynamic network comics with pen+ touch interaction</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">W</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Henry Riche</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Bach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Brehmer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Hinckley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Pahud</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Mcguffin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Pfister</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems</title>
				<meeting>the 2019 CHI Conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="1" to="12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Gemini: A grammar and recommender system for animated transitions in statistical graphics</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Heer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="485" to="494" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Gemini 2: Generating keyframe-oriented animated transitions between statistical graphics</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Heer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Visualization Conference (VIS)</title>
				<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="201" to="205" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Graphscape: A model for automated reasoning about visualization similarity and sequencing</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Wongsuphasawat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hullman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Heer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the CHI Conference on Human Factors in Computing Systems</title>
				<meeting>the CHI Conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="2628" to="2638" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Storytelling: The next step for visualization</title>
		<author>
			<persName><forename type="first">R</forename><surname>Kosara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Mackinlay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="44" to="50" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Kineticharts: Augmenting affective expressiveness of charts in data stories with animation design</title>
		<author>
			<persName><forename type="first">X</forename><surname>Lan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Jiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Cao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="933" to="943" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Understanding narrative linearity for telling expressive time-oriented stories</title>
		<author>
			<persName><forename type="first">X</forename><surname>Lan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Cao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the CHI Conference on Human Factors in Computing Systems</title>
				<meeting>the CHI Conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="1" to="13" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">More than telling a story: Transforming data into visually shared stories</title>
		<author>
			<persName><forename type="first">B</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">H</forename><surname>Riche</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Isenberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Carpendale</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer Graphics and Applications</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="84" to="90" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Data illustrator: Augmenting vector design tools with lazy data binding for expressive visualization authoring</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Thompson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Wilson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Dontcheva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Delorey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Grigg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Kerr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Stasko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the CHI Conference on Human Factors in Computing Systems</title>
				<meeting>the CHI Conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="1" to="13" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Deepeye: Towards automatic data visualization</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Data Engineering (ICDE)</title>
				<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="101" to="112" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Automating the design of graphical presentations of relational information</title>
		<author>
			<persName><forename type="first">J</forename><surname>Mackinlay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Graphics</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="110" to="141" />
			<date type="published" when="1986">1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Show me: Automatic presentation for visual analysis</title>
		<author>
			<persName><forename type="first">J</forename><surname>Mackinlay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Hanrahan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Stolte</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1137" to="1144" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Visual narrative flow: Exploring factors shaping data visualization story reading experiences</title>
		<author>
			<persName><forename type="first">S</forename><surname>Mckenna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Henry Riche</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Boy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Meyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Graphics Forum</title>
				<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="377" to="387" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Formalizing visualization design knowledge as constraints: Actionable and extensible models in draco</title>
		<author>
			<persName><forename type="first">D</forename><surname>Moritz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">L</forename><surname>Nelson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Howe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Heer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="438" to="448" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<author>
			<persName><forename type="first">N</forename><surname>Reimers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Gurevych</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1908.10084</idno>
		<title level="m">Sentence-bert: Sentence embeddings using siamese bert-networks</title>
				<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Chartaccent: Annotation for data-driven storytelling</title>
		<author>
			<persName><forename type="first">D</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Brehmer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Höllerer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">K</forename><surname>Choe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Pacific Visualization Symposium (PacificVis)</title>
				<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="230" to="239" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Data-driven storytelling</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">H</forename><surname>Riche</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Hurter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Diakopoulos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Carpendale</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
			<publisher>CRC Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Interactive graphic design using automatic presentation knowledge</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">F</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kolojejchick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Mattis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Goldstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the SIGCHI conference on Human Factors in Computing Systems</title>
				<meeting>the SIGCHI conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<date type="published" when="1994">1994</date>
			<biblScope unit="page" from="112" to="117" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Visualization of positive and convex data by a rational cubic spline interpolation</title>
		<author>
			<persName><forename type="first">M</forename><surname>Sarfraz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Sciences</title>
		<imprint>
			<biblScope unit="volume">146</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="239" to="254" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Authoring narrative visualizations with ellipsis: Authoring narrative visualizations with ellipsis</title>
		<author>
			<persName><forename type="first">A</forename><surname>Satyanarayan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Heer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics Forum</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="361" to="370" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">On the interpolation of data with normally distributed uncertainty for visualization</title>
		<author>
			<persName><forename type="first">S</forename><surname>Schlegel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Korn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Scheuermann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2305" to="2314" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Narrative visualization: Telling stories with data</title>
		<author>
			<persName><forename type="first">E</forename><surname>Segel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Heer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1139" to="1148" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Task-oriented optimal sequencing of visualization charts</title>
		<author>
			<persName><forename type="first">D</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Cao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Visualization in Data Science (VDS)</title>
				<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="58" to="66" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Autoclips: An automatic approach to video generation from data facts</title>
		<author>
			<persName><forename type="first">D</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Lan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Gotz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Cao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics Forum</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="495" to="505" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Calliope: Automatic visual data story generation from a spreadsheet</title>
		<author>
			<persName><forename type="first">D</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Cao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="453" to="463" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Communicating with motion: A design space for animated visual narratives in data videos</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Lan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Cao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the CHI Conference on Human Factors in Computing Systems</title>
				<meeting>the CHI Conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="1" to="13" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Understanding the design space for animated narratives applied to illustrations</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Cao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the CHI Conference on Human Factors in Computing Systems</title>
				<meeting>the CHI Conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title level="m" type="main">Emerging and recurring data-driven storytelling techniques: Analysis of a curated collection of recent stories</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">D</forename><surname>Stolper</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">H</forename><surname>Riche</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Stasko</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016">2016</date>
			<publisher>Microsoft Research</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Extracting topk insights from multi-dimensional data</title>
		<author>
			<persName><forename type="first">B</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">L</forename><surname>Yiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM International Conference on Management of Data</title>
				<meeting>the ACM International Conference on Management of Data</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1509" to="1524" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title level="m" type="main">Image interpolation and resampling. Handbook of medical imaging, processing and analysis</title>
		<author>
			<persName><forename type="first">P</forename><surname>Thévenaz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Blu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Unser</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="393" to="420" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Storytelling and visualization: An extended survey</title>
		<author>
			<persName><forename type="first">C</forename><surname>Tong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Borgo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Walton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">S</forename><surname>Laramee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Wegba</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Luo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="65" to="106" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Interpolation and visualization for advected scalar fields</title>
		<author>
			<persName><forename type="first">S.-K</forename><surname>Ueng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S.-C</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">VIS 05. IEEE Visualization</title>
				<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="615" to="622" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Seedb: Efficient data-driven visualization recommendations to support visual analytics</title>
		<author>
			<persName><forename type="first">M</forename><surname>Vartak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Rahman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Madden</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Parameswaran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Polyzotis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the VLDB Endowment International Conference on Very Large Data Bases</title>
				<meeting>the VLDB Endowment International Conference on Very Large Data Bases</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="2182" to="2193" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
		<title level="m" type="main">Advances in neural information processing systems</title>
		<author>
			<persName><forename type="first">A</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ł</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Polosukhin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="5998" to="6008" />
		</imprint>
	</monogr>
	<note>Attention is all you need</note>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Narvis: Authoring narrative slideshows for introducing data visualization designs</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Qu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="779" to="788" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Datashot: Automatic generation of fact sheets from tabular data</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="895" to="905" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Infonice: Easy creation of information graphics</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Qu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the CHI Conference on Human Factors in Computing Systems</title>
				<meeting>the CHI Conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="1" to="12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Autovis: Automatic visualization</title>
		<author>
			<persName><forename type="first">G</forename><surname>Wills</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wilkinson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Visualization</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="47" to="69" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Ifs fractal interpolation for 2d and 3d visualization</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">M</forename><surname>Wittenbrink</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Proceedings Visualization&apos;95</title>
				<imprint>
			<date type="published" when="1995">1995</date>
			<biblScope unit="page" from="77" to="84" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Voyager: Exploratory analysis via faceted browsing of visualization recommendations</title>
		<author>
			<persName><forename type="first">K</forename><surname>Wongsuphasawat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Moritz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Anand</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Mackinlay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Howe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Heer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="649" to="658" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Voyager 2: Augmenting visual analysis with partial view specifications</title>
		<author>
			<persName><forename type="first">K</forename><surname>Wongsuphasawat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Moritz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Ouk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Anand</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Mackinlay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Howe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Heer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the CHI Conference on Human Factors in Computing Systems</title>
				<meeting>the CHI Conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="2648" to="2659" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">A design space for applying the freytag&apos;s pyramid structure to data stories</title>
		<author>
			<persName><forename type="first">L</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Lan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Cao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="922" to="932" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Chandrasegaran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Bryan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mishra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K.-L</forename><surname>Ma</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2103.03996</idno>
		<title level="m">Chartstory: Automated partitioning, layout, and captioning of charts into comic-style narratives</title>
				<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
