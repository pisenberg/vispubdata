<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">MetaGlyph: Automatic Generation of Metaphoric Glyph-based Visualization</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Lu</forename><surname>Ying</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Xinhuan</forename><surname>Shu</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Dazhen</forename><surname>Deng</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Yuchen</forename><surname>Yang</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Tan</forename><surname>Tang</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Lingyun</forename><surname>Yu</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Yingcai</forename><surname>Wu</surname></persName>
						</author>
						<title level="a" type="main">MetaGlyph: Automatic Generation of Metaphoric Glyph-based Visualization</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.2" ident="GROBID" when="2023-03-27T09:16+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Glyph-based visualization</term>
					<term>metaphor</term>
					<term>machine learning</term>
					<term>automatic visualization</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Fig. 1. Example MGVs generated by MetaGlyph: (a) several attributes of different pokemons; (b) forest area changes in different countries from 1995 to 2020; (c) display of various CDs; (e) multiple hotels' information arranged by price (x) and rate (y); (f) chocolates in different ratings placed on a map; (g) disparate mushrooms. The legends in (a1)(b1)(f1) are also generated by MetaGlyph. The center boxes with yellow backgrounds illustrate the data mappings for each glyph. Encoding channels are represented in icons and (d) shows the annotation. Dashed arrows are used to associate visual elements with the resulting visualizations.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Glyph-based visualization serves as an effective method for encoding multi-dimensional data <ref type="bibr" target="#b38">[39]</ref>. However, glyph designs can also be complex due to the increasing number of data dimensions, leading to comprehension problems. Accordingly, visual metaphors are actively used to draw data-driven glyphs with representative and familiar appearances related to the data <ref type="bibr" target="#b34">[35]</ref>. We have seen wide adoption of metaphoric glyphs in various domains, such as sports <ref type="bibr" target="#b31">[32,</ref><ref type="bibr" target="#b43">44]</ref>, urban application <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b35">36]</ref>, and blockchain <ref type="bibr" target="#b68">[68]</ref>. Studies have also shown that appropriate metaphors can help people understand glyphs quickly and accurately <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b34">35]</ref>. However, incorporating metaphors in glyph designs is not an easy task. Designers have to balance various factors, such as the expressiveness of the visual representations and the effectiveness of data mappings.</p><p>Many advanced visualization authoring tools have been developed to facilitate the creation of glyph-based visualizations <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b48">48,</ref><ref type="bibr" target="#b62">62,</ref><ref type="bibr" target="#b65">65,</ref><ref type="bibr" target="#b66">66]</ref>. However, it is difficult to balance automation and customization in the creation process. For example, GlyphCreator <ref type="bibr" target="#b65">[65]</ref> and Diatoms <ref type="bibr" target="#b3">[4]</ref> consider basic geometry or limited shapes and do not have explicit support to create metaphoric glyphs with semantic relevance. Other manual authoring tools allow users to craft the graphical elements from scratch through sketching <ref type="bibr" target="#b62">[62]</ref> or interactions <ref type="bibr" target="#b27">[28]</ref>, which are powerful in customization. Such creation is laborious, and the quality of the final glyphs is highly dependent on the user's design experience and expertise. Using online resources may lower the cost of customization and simplify the creative process <ref type="bibr" target="#b66">[66]</ref>. However, users need to manually select and upload the image source online without an image library.</p><p>For better results, we aim to automatically generate metaphoric glyph-based visualization (MGV) using online sources. We attempt to ease the creation of MGV for general users who need to encode multi-variant data. However, two obstacles emerge from the process: • It is unclear how metaphors can be embedded into the glyph-based visualization design. In practice, a great number of visualizations <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b63">63,</ref><ref type="bibr" target="#b64">64,</ref><ref type="bibr" target="#b68">68]</ref> have adopted metaphors to represent data. Existing studies <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b59">59]</ref> have recognized that metaphor is a good design strategy to facilitate glyph understanding. However, a systematic review of these designs to guide the creation of MGV is lacking. Detailed and practical designs for MGV have not been proposed yet. • It is difficult to generate an MGV without the involvement of human intelligence. This generation process involves a series of design decisions, for instance, selecting an appropriate metaphor design and binding data with various elements in the metaphor. It requires comprehensive considerations of the whole process to streamline the production. Although increasing work has been conducted on glyph-based visualization, the automatic method for designing and generating an MGV has received less attention from the community. To address these challenges, we propose an MGV generation framework according to a qualitative analysis established on a collection of MGV examples. We systematically reviewed 50 examples from publications and websites to explore the MGVs' designs. The analysis results provide guidance for understanding a metaphor within a glyph-based visualization for the first challenge. Informed by the results, we design and implement MetaGlyph, a proof-of-concept system that allows users to generate MGVs automatically by importing a spreadsheet. We find appropriate metaphoric images online for the data and assess how well the images match the input data in the following steps: First, the images are decomposed into a list of visual elements. Given the visual elements and different data dimensions, we then formulate the mapping problem as a tree search question and introduce a Monte Carlo tree search (MCTS) algorithm to explore the mapping space. Finally, we utilize criteria to estimate the quality of MGVs and select the best MGV based on the rewards. MetaGlyph also incorporates an interface for users to refine the MGV. The main contribution can be summarized as follows:</p><p>• We conduct a qualitative analysis to understand the design of stateof-the-art MGVs from various stages. • We propose a novel framework by selecting metaphoric images and constructing MGVs. We also introduce a method to estimate the quality of an MGV in the framework. • We develop MetaGlyph, a mixed-initiative system for creating MGVs automatically. We demonstrate the usage of MetaGlyph through a usage scenario and validate its usability through expert interviews.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK</head><p>We summarize prior studies that have covered metaphor-based designs, glyph-based visualizations, and currently available authoring tools.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Metaphor-based designs</head><p>In linguistics, metaphor, analogy, and simile are three basic elements in language <ref type="bibr" target="#b42">[43]</ref>. A metaphor is a word or a phrase that compares one thing to another to make a description more intuitive, like "All the world is a stage" <ref type="bibr" target="#b23">[24]</ref>. Similes create a comparison using "like" or "as" <ref type="bibr" target="#b23">[24]</ref>. A well-known example of a simile is "Life is like a box of chocolates."</p><p>The analogy is a comparison between things that have similar features <ref type="bibr" target="#b23">[24]</ref>. An example of an analogy is "Black is to white as on is to off ". In visualization, researchers do not explicitly differentiate these concepts, and the word "metaphor" is used to depict the case of interpreting complex information via familiar and concrete objects <ref type="bibr" target="#b34">[35]</ref>. By allowing users to maximize their experience and knowledge, metaphors make it easier for users to understand the underlying data.</p><p>Previous studies have suggested that metaphors promote data comprehension <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b51">51]</ref>. A well-known example is Chernoff faces <ref type="bibr" target="#b9">[10]</ref>, which maps one data value to one face character like the eyebrows' angle or the nose's size. Later in two quantitative experiments, Flury et al. <ref type="bibr" target="#b19">[20]</ref> and Jacob <ref type="bibr" target="#b25">[26]</ref> found that face glyphs outperform other visual designs like polygons and digits. Researchers have proved that, compared with glyphs unrelated to data, some metaphor-based glyphs outperform others in accuracy and efficiency through quantitative experiments, such as car glyphs <ref type="bibr" target="#b55">[55]</ref> and clock glyphs <ref type="bibr" target="#b20">[21]</ref>. Chau et al. <ref type="bibr" target="#b5">[6]</ref> found that a combined design that displays glyphs and numbers together performs better in adopting a flower metaphor. Fuchs et al. <ref type="bibr" target="#b22">[23]</ref> recently introduced a leaf glyph based on a natural metaphor and proved its effectiveness in illustrative storytelling. Dasu et al. <ref type="bibr" target="#b13">[14]</ref> proposed an organic metaphor to interpret conditional co-occurrences and verified the effectiveness of complex tasks.</p><p>The concept of metaphor in visualization has a long history. In the 1920s, Otto Neurath and Gert Arntz <ref type="bibr" target="#b41">[42]</ref> invented the 'Vienna Method of Pictorial Statistics', which was renamed 'ISOTYPE (International System Of TYpographic Picture Education)' in the late 1930s. They designed a lot of pictographs using semantically relevant icons.</p><p>Metaphors have been widely used to visualize different data. Metaphors like clock <ref type="bibr" target="#b18">[19]</ref>, wheel <ref type="bibr" target="#b1">[2]</ref>, and radar <ref type="bibr" target="#b61">[61]</ref> are adopted to present radial layouts. Spatial metaphors express the relation "proximity ≈ similarity" <ref type="bibr" target="#b40">[41]</ref>. Ropinski et al. <ref type="bibr" target="#b52">[52]</ref> recommended 3D metaphoric glyphs to visualize spatial multivariate medical data for the attentive phase. Using Fermat's spirals, Lei and Zhang <ref type="bibr" target="#b32">[33]</ref> designed the galaxy visualization to display financial time serials. Matchpad <ref type="bibr" target="#b31">[32]</ref> used metaphoric pictograms, which are easy to learn, remember and guess. Setlur and Mackinlay <ref type="bibr" target="#b54">[54]</ref> generated scatterplots with semantically-relevant icons to replace traditional data points automatically. Users are kept informed by the semantic information during analysis. TenniVis <ref type="bibr" target="#b43">[44]</ref> proposed a novel glyph for individual point outcomes in a tennis match inspired by the needle gauge. SmartAdp <ref type="bibr" target="#b35">[36]</ref> designed a novel dashboard-like glyph to represent a solution for billboard placements. Coelho and Mueller <ref type="bibr" target="#b10">[11]</ref> created Infomages, which utilized thematic images to develop a data chart. A relevant image help users interpret the data. Recently, Compass <ref type="bibr" target="#b16">[17]</ref> introduced a compass glyph to facilitate the in-depth understanding of urban problems.</p><p>Although these works have demonstrated the great advantages of metaphors in the visualization from different perspectives, none of them have proposed an automatic way to generate metaphoric glyphs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Glyph-based visualization and authoring</head><p>Glyph-based visualization has become prevalent in visualization journals <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b57">57]</ref> and celebrated collections (e.g., Dear Data <ref type="bibr" target="#b37">[38]</ref>). It performs well especially for multivariate data <ref type="bibr" target="#b2">[3]</ref>. However, it is not easy to design and generate a glyph-based visualization.</p><p>Thus, many theoretical researchers have focused on how to design glyphs. Ward <ref type="bibr" target="#b58">[58]</ref> discussed the process and issues of glyph generation, including mapping data to graphics attributes and layouts. Borgo et al. <ref type="bibr" target="#b2">[3]</ref> drew the link between basic concepts in semiotics and glyphbased visualization and summarized existing design guidelines and techniques. Recently, Fuchs et al. <ref type="bibr" target="#b21">[22]</ref> provided an overview of glyph types and design characteristics by reviewing experimental studies.</p><p>Furthermore, researchers have proposed many authoring tools to ease the difficulties of creating glyphs. Ribarsky et al. <ref type="bibr" target="#b49">[49]</ref> introduced Glyphmaker, which allows non-expert users to customize data glyphs. Kim et al. <ref type="bibr" target="#b27">[28]</ref> proposed Data-Driven Guides for Information Graphics, a system that can also create glyphs via interaction. Xia et al. <ref type="bibr" target="#b62">[62]</ref> developed DataInk, which aims at author glyphs through freedom sketching. Ren et al. <ref type="bibr" target="#b48">[48]</ref> presented Charticular, an authoring tool focused on layouts between glyphs. Chen et al. <ref type="bibr" target="#b8">[9]</ref> took the first step in creating glyph-based visualization in Augmented Reality environments using mobile devices. Besides creating from scratch, DataQuilt <ref type="bibr" target="#b66">[66]</ref> adopted real images for both inspiration and a resource of visual elements for data binding. On the other hand, while scholars have developed several tools to help users create glyphs, users still need a lot of manual operations in the system. The glyph quality highly depends on the user's design experience and expertise. Therefore, scholars have proposed some automatic systems to simplify the process recently. Ying et al. <ref type="bibr" target="#b65">[65]</ref> aimed at circular glyphs and introduced GlyphCreator based on an example-based method. Brehmer et al. <ref type="bibr" target="#b3">[4]</ref> developed Diatoms, a technique for inspiring glyph design through a sample-based generative process. However, automatic systems only support basic geometry or limited shapes. Unlike regular shapes, metaphors serve as effective methods to help users understand data. Thus, we opt to generate glyphs with metaphors that are not supported by existing systems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">DESIGN OF THE METAGLYPH SYSTEM</head><p>In this section, we introduce the design of the MetaGlyph system. To gain a better understanding of MGV design, we surveyed previous work and conducted a qualitative analysis. Based on the findings, we proposed the design considerations (DCs) for the MetaGlyph system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Data Collection</head><p>To better understand how metaphors are embodied in glyph-based visualization, we examined the practice from both academic literature and online design communities.</p><p>We collected examples from top visualization conferences and journals (IEEE VIS and TVCG) using the keywords "metaphor" and "glyph" and found 221 papers. We manually examined all papers to ensure the existence of MGVs in the paper. Specifically, we checked whether both keywords "metaphor" and "glyph" appeared together to describe a metaphoric glyph. Some papers were excluded. For instance, they might mention "metaphor" and "glyph" in the related work for two different works, respectively. As a result, we collected 20 examples in the literature as the initial corpus.</p><p>To further expand the diversity, we collected more examples from creative websites (e.g.,Behance and Pinterest) with keywords such as "information visualization" "metaphor" and "glyph". We adopted an initial filtering standard of MGV based on our current corpus. Then, we collected the chosen examples as a new part of our corpus. Finally, a total of 50 MGVs were collected as our corpus. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Qualitative Analysis</head><p>To further understand the design of an MGV, we conducted a comprehensive analysis for all examples in our corpus. In general, we analyzed all MGVs in three stages by decomposing them step by step. S1 We find out how metaphors are embodied in an MGV and analyze the pattern of the glyph placement based on the overall design. S2 We drill down into a single glyph and consider its layout. S3 We aim at different visual elements that compose one glyph. Three authors went through our corpus and independently analyzed all examples following the above stages. All disagreements were resolved through iterative discussions. S1: At this stage, we focus on MGVs' general design to understand how designers embody the metaphor and place all glyphs in the MGVs.</p><p>• Metaphor Type. In our corpus, we find that designers use metaphors with respect to data properties and generally divide all examples into two conditions: semantic-related and structure-related. The former indicates the metaphor is related to the topic of data, for example, a coin representing transaction data <ref type="bibr" target="#b68">[68]</ref>, and a dashboard representing speed data <ref type="bibr" target="#b35">[36]</ref>. In this condition, designers commonly use a metaphor within one glyph design. The latter illustrates that the metaphor is related to the data structure. For example, researchers used blooming flowers in a glyph-based visualization to express hierarchical data <ref type="bibr" target="#b18">[19]</ref>. For data about model optimization, researchers may choose the clock metaphor <ref type="bibr" target="#b67">[67]</ref> since it is time-related. In this condition, the metaphors are mainly embodied in the visualization layout. Moreover, some designs are both semantic-related and structure-related. The concrete amounts of different metaphor types in our corpus are shown in Fig. <ref type="figure" target="#fig_0">2(a)</ref>. Finally, the definition of a valid MGV is: using a visual design that suggests a particular association or similarity with data <ref type="bibr" target="#b28">[29]</ref>. • Glyph Placement. In our corpus, we code the glyph placement of MGVs into two groups according to Ward's theory <ref type="bibr" target="#b58">[58]</ref>: data-driven and structure-driven. Data-driven placements correspond to glyphs that are placed based on data values. Some data values are directly used as the x-or y-value. Others need computations (e.g., projection space) to derive the position. Glyphs are usually placed in a Cartesian coordinate system in a data-driven group. The structure-driven group assumes that the data have structural characteristics. It is also a method to present metaphors. Some placements are based on a specific object, such as a tree for hierarchical data <ref type="bibr" target="#b26">[27]</ref> and a map for geospatial data <ref type="bibr" target="#b44">[45]</ref>, or a timeline for time series data <ref type="bibr" target="#b50">[50]</ref>. Designers adopt metaphors in structure-driven placements, such as a map with landscape and a clock for data ordered by temporal data.</p><p>Other metaphors use a typical ordering relationship based on categorical information. Glyphs may be arranged evenly between left and right or located with an organization considering non-overlapping.</p><p>In some cases, designers adopt two placements together for better visualization. Fig. <ref type="figure" target="#fig_0">2</ref>(b) indicates the statistics on the corpus. S2: We then drill down into the design of one glyph. We focus on different glyph layouts in this stage. • Glyph Layout. As glyphs are frequently designed in a radial structure <ref type="bibr" target="#b65">[65]</ref>, we discuss the glyph layout in two groups: radial and non-radial. Fig. <ref type="figure" target="#fig_0">2</ref>(c) displays the used frequency of two groups in our corpus. A radial glyph is a glyph whose elements are organized on a polar coordinate system. Each element shares the same origin. Most elements have a radial shape, like a circle and a sector. Non-radial glyphs can be placed in a Cartesian coordinate system. Notably, some glyphs present a linear structure, that is, elements in such glyphs are arranged vertically or horizontally. Others are arranged relatively freely, such as to compose a specific object like a car <ref type="bibr" target="#b55">[55]</ref>. S3: A glyph is composed of different visual elements encoded by different data dimensions. In the last stage, we focus on the visual elements and discuss some findings of data mapping. • Visual Element. Ying et al. <ref type="bibr" target="#b65">[65]</ref> divided all visual elements in a circular glyph into four categories: chart, shape, icon, and text.</p><p>Given the peculiarity of metaphor, we mainly consider two of these categories: shape-level and chart-level. The shape-level element refers to different shapes, including basic geometry (e.g., circles, polygons) and complex shapes (e.g., leaves). A chart-level element is a variant chart within a glyph, which is also a unit of shape-level elements. We integrate these shape-level elements because the unit (e.g., a pie chart) conveys more information than a single component (e.g., several sectors). In our corpus, designers adopt pie charts, donut charts, star plots, heatmap, and boxplots when designing glyphs. • Element Number. The information conveyed by one glyph is limited.</p><p>A glyph can better represent data in 2 to 4 dimensions <ref type="bibr" target="#b2">[3]</ref>. According to the statistics from our corpus, the frequent amount of encoded elements of a metaphoric glyph is between 2 and 6 (Fig. <ref type="figure" target="#fig_0">2(d)</ref>). • Data Mapping. The mapping relationship of the data and elements is important for presenting the final visualization. For a given data dimension and a given element, the encoding channel is mainly determined by the data type. Fig. <ref type="figure" target="#fig_0">2</ref>(e) presents the frequently used data types and the preferred encoding channel. Moreover, we have two interesting findings in our corpus. First, among all elements in an image, some elements may contain additional semantic information, such as the two circles in the car referring to wheels. Designers prefer to encode such elements with correlated data. In a car, MPG (miles per gallon) is more relevant with the wheel than the car body, and designers prefer to use the wheel size to encode MPG. Second, data with similar attributes can be encoded in the same way. For instance, Chau et al. <ref type="bibr" target="#b5">[6]</ref> used different leaf elements in a metaphoric flower glyph to encode external and internal links of the webpage.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Design Considerations</head><p>We aim to design a system to generate MGVs automatically from a spreadsheet. We summarize three primary DCs to guide the design. DC1 Generate a semantically-resonant MGV. Using metaphors, successful MGVs can promote the interpretation of the input data. Therefore, it is critical to choose an appropriate metaphoric design with respect to the data semantics. We likewise consider the rationality of the mapping between specific data dimensions and individual visual elements. The system should consider both factors and ensure the quality of the final output MGV. DC2 Support automatic and efficient MGV generation. Abundant online image resources provide design inspirations and create an opportunity for the automatic generation of MGV. However, selecting one appropriate metaphor image from abundant online sources is difficult. People must remember complex data features and consider multiple data mappings. Manual data mapping is labor-intensive since users need to calculate different attributes (i.e., size and angle) for encoding. Thus, we plan to automate the process to ease data exploration through quick generation, including image selection and data mapping. On the one hand, due to the large size of online images, it takes a long time to test various combinations of images to generate an appropriate result.</p><p>On the other hand, users feel tired of waiting for a result when all online images are required to be transformed and combined. Thus, we set multiple filter conditions in different steps to balance the quality of MGV and the time spent on the creation. DC3 Integrate a mixed-initiative workflow. Although an automatic system provides convenience, the generated visualization may not satisfy users' expectations. Therefore, users should engage in the creation process <ref type="bibr" target="#b53">[53]</ref>. We consider a mixed-initiative workflow that integrates the machine's and human being's efforts. Our system provides some initial results for users to choose from and change by the given spreadsheet. Then, after modifying visual elements for specific data dimensions from users, MetaGlyph improves the final output and provides alternatives based on the users' preferences. To follow this practice, our system should provide a collaborative design workflow.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">MGV GENERATION MODEL</head><p>This section introduces our two-step model to generate MGVs, including selecting metaphoric images and constructing MGVs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Selecting Metaphoric Images</head><p>To construct valid MGVs for the given input data, we first decide on appropriate metaphors with corresponding images. This subsection elaborates on the process of metaphoric image selection, including segmentation, pruning, and augmentation. After obtaining candidates, we select one image each time for subsequent operations in Sect. 4.2.</p><p>Based on the findings from Sect. 3.2, we summarize two criteria to determine the right image: • C1: It is semantically related to the data. • C2: It is a vector image with a relatively simple structure. First, we can derive C1 directly given the definition of MGV <ref type="bibr" target="#b28">[29]</ref>. For C2, vector images are easy to edit and reuse compared to raster images, which correspond to our needs for data binding. As discussed in Sect. 3.2, it is more appropriate to determine the number of the encoded visual elements within the range from two to five. Given that complex images will lead to high understanding costs, the source images of glyphs should be simple and easy to perceive. According to C1 and C2, we search eligible images on the Internet.</p><p>Given a spreadsheet, we can obtain general information about the dataset. The spreadsheet name is regarded as the topic of the dataset. We choose SVG Repo 1 to search for eligible vector graphics following C1. The format of the vector graphics meets the condition, and their structure is simple for subsequent operations (C2). In addition, we use the Google Image Search Engine as a supplement to ensure the diversity and abundance of candidate images. We use the keyword "icon" and convert the resulting bitmap images into SVG using an opensource package Portace. As a result, we get a first-version candidate metaphoric image list in this step. Next, we filter these candidates through subsequent processing steps, as shown in Fig. <ref type="figure" target="#fig_1">3</ref>.</p><p>Segmentation. We need to segment each image as elements from the previous output list. Given that an SVG file comprises several paths, we convert each path into an individual SVG file to obtain an element list using the SVG format. We derive n files corresponding to the n paths and calculate the center C i (i = 1, 2, ..., n) of each retained element to determine the overall center of glyph C 0 .</p><p>Pruning. Given all visual elements, we prune non-essential elements following C2 and determine the image structure. To map data effectively, we remove tiny overlapped elements temporally, as associating the information with such elements will not improve the understandability. We heuristically found tiny elements were those occupying less than 0.5% of the area of the whole image, which reached a good compromise between the understandability and aesthetics. For instance, elements with center C 3 and C 4 in Fig. <ref type="figure" target="#fig_1">3</ref> are removed in this step. Next, we decide on the image structure based on preserved elements. We follow the same classification as discussed in Glyph Layout (Sect. 3.2) since the image is the vital material to construct a metaphoric glyph. The distinction is used for further data mapping. We use the center position {C 0 ,C 1 ,...,C n } to confirm the structure. As discussed in Sect. 3.2, we check whether the origin of the polar coordinate system exists by analyzing all elements' center. We first derive a possible rough origin position P o based on the center of the glyph. If more than one element's center is close to P o , we define this image as a radial structure and vice versa. For example, in Fig. <ref type="figure" target="#fig_1">3</ref>, since four circular elements and the whole glyph have the same center C 0 , the image is regarded as a radial structure. For non-radial images, we check if the centers of all essential elements C i can be connected in a nearly straight line with slope k.</p><p>Augmentation. In this step, we transform original basic shapes into charts and integrate them into the glyph design. According to our findings in qualitative analysis (Sect. 3.2), we find 5 cases (star plot, donut chart, pie chart, heatmap, and boxplot) in existing research and design. Some charts are directly derived from a circular shape while others (heatmap and boxplot) need extra transformation <ref type="bibr" target="#b35">[36,</ref><ref type="bibr" target="#b36">37]</ref>. Therefore, we add an extra tag for circular elements because they can transform into charts.</p><p>After the above operations, we get an element list. We define the image as follows:</p><formula xml:id="formula_0">Image = {e 1 , e 2 ,...,e n , S} = {{a 1 , p 1 }, {a 2 , p 2 }, ..., {a n , p n }, S}<label>(1)</label></formula><p>where e i refers to different visual elements, a i is a boolean variable indicating whether the element can be augmented, p i describes a path in an SVG file, and S represents the image structure. For a non-radial image, we also record the slope k. For each image in the first-version candidates, we derive an element list for the following step.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Constructing Metaphoric Glyph-based Visualization</head><p>This subsection introduces the method to construct an MGV. We first formulate our problem into a mathematical form and then give a solution overview, mapping data to different visual elements and placement as well as glyph rendering in MetaGlyph.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1">Problem Formulation</head><p>To generate an MGV, we select several data dimensions from the given spreadsheet, pick some visual elements from the element list, map the selected data attributes to the chosen elements and determine the placement. We also determine the visual encoding channel for each pair of one data attribute and an element. The position attribute for glyph placement (discussed in Sect. 3.2) is also based on data. We adopt two variables, α 1 and α 2 , to present both data-driven and structure-driven glyph placements. The two variables are clear for data-driven placement to present numerical data due to a Cartesian coordinate system. We consider several specific objects (map, timeline) and order relationships according to data features for structure-driven placement. One variable α 1 is enough to present this data group. We need one categorical data dimension for the map and order relationship, and one temporal data for the timeline. As the ultimate effect of the MGV is determined by glyphs and placement, we consider them together. Moreover, we take the whole image as an extra visual element e 0 because it often encodes data.</p><p>We formulate the problem as: given data D = {d 1 , d 2 , ..., d n }, we select n mapping pairs P for each data dimension to solve: max</p><formula xml:id="formula_1">D,L R mgv (P D,L )<label>(2)</label></formula><p>where R mgv is the reward function for a solution, P D,L = {p 1 , p 1 ,..., p n } is all mapping pairs, as shown in Fig. <ref type="figure" target="#fig_1">3</ref>(e). Each mapping pair can be represented as:</p><formula xml:id="formula_2">p = d i ↔ e j α k ∅<label>(3)</label></formula><p>where</p><formula xml:id="formula_3">i ∈ [1, n], j ∈ [0, m], k ∈ {1, 2}</formula><p>and ∅ is an empty set. d i ↔ e j means the data dimension is mapped with an element (yellow arrows in Fig. <ref type="figure" target="#fig_1">3(e)</ref>). d i ↔ α k shows the data dimension is mapped with one axis of placement (the black arrow in Fig. <ref type="figure" target="#fig_1">3(e)</ref>). Since we do not present all data dimensions in an MGV, some dimensions are not displayed. d i ↔ ∅ represents this condition (the black dotted arrow in Fig. <ref type="figure" target="#fig_1">3(e)</ref>). Above all, we should guarantee the quality of the final MGV. The number of axes α k is one or two to ensure a successful visualization. For Equation 3, the amount of valid pairs (d i ↔ e j , d i ↔ α k ) is an unknown variable, which means we can choose one pair, two pairs, or even all data for data-mapping. With the above considerations, the mapping space can be large for this question, even for a small dataset. Moreover, intermediate results are not worth referring to until all mapping pairs are determined. We cannot enumerate all solutions first and pick some reasonable ones as the output since a long waiting time for users violates DC2. We address this problem using an efficient method named MCTS <ref type="bibr" target="#b40">[41]</ref>, which is proposed to search for the best next move in a game. This algorithm can efficiently and logically explore a large space via a tree structure.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2">Monte Carlo Tree Search</head><p>We explore the mapping space by constructing a searching tree T . Each tree node is a visual element e i or an axis α k from the elementplacement list. We start from an empty root node, as shown in Fig. <ref type="figure" target="#fig_2">4(b)</ref>. The mapping pairs (Equation <ref type="formula" target="#formula_2">3</ref>) are represented as Node's Height ↔ Node, where the Node's Height corresponds to a data dimension d i , and the Node is one of three options in Equation 3. In MCTS, nodes close to the root are usually explored more fully. Therefore, the order of data dimensions weighs a lot for the resulting mapping method. We adopt an importance score to estimate the importance of all data dimensions and put the higher score dimension at the top of the tree. The search process repeats four stages starting from an empty node: selection, expansion, simulation, and backpropagation. Then, one mapping method is generated by a path from the root to a leaf node. After identifying one data dimension and an element, we choose an encoding channel according to the data type and element feature as discussed in Sect. 4.2.3. We also design a reward function to estimate the quality of all generated MGVs.</p><p>First, we need to order all data dimensions before building a mapping tree. We estimate the importance of one data dimension based on its relevance to the data topic. Semantic text similarity is commonly used in the natural language processing field <ref type="bibr" target="#b24">[25]</ref>, like machine translation and image caption <ref type="bibr" target="#b33">[34]</ref>. Researchers use word embeddings to represent the original text information. Since the description of one data dimension is usually a phrase aside from a word, we choose sentence embeddings. Among existing state-of-the-art models <ref type="bibr" target="#b30">[31,</ref><ref type="bibr" target="#b39">40,</ref><ref type="bibr" target="#b47">47]</ref>, we choose sentence-BERT <ref type="bibr" target="#b47">[47]</ref>, which is suitable for calculating sentence distance and avoids massive computational overhead. We use cosine distance, which is widely used to measure distance in vector space. Consequently, we rank the data dimensions by calculating the distances between the description of data dimensions and the data topic. We group numerical data dimensions with similar meanings as G d , such as math and music scores, and apply the same encoding method to the grouped data dimensions. While the visual elements are being mapped, these groups are treated the same as other data dimensions. They cannot be considered as axes α. We compute the importance of the data dimensions by using the average distance: dist G = dist d , where dist d is the individual importance score of integrated data dimensions. We also prioritize these groups and put them at the top of the tree ordered by their ranking as shown in Fig. <ref type="figure" target="#fig_2">4(a)</ref>.</p><p>Selection. A mapping tree is initialized with an empty root node, as shown in Fig. <ref type="figure" target="#fig_2">4(b</ref>). In the selection stage, we aim to find the most promising element node e i . This step starts from the root node and selects a child node with the maximum upper confidence bound for trees (UCT) <ref type="bibr" target="#b4">[5]</ref> each time. Generally, UCT considers the balance between less-visited and high-valued nodes:</p><formula xml:id="formula_4">UCT = r i n i + c ln N i n i (4)</formula><p>where r i is the reward value, n i is the visited times of e i , N i is the visited times of the parent node, c is a constant. After multiple experiments, we used c = 4 since it performs better. The selection stage ends until the most urgent expandable node is reached. A node is expandable if it has unvisited (i.e., unexpanded) children.</p><p>Expansion. One child node is added to expand the tree in the expansion stage. We add a random visual element or axis node to expand as shown in Fig. <ref type="figure" target="#fig_2">4</ref>(c) and initialize the visited time and reward as zero. Remarkably, we can add an empty node to expand because we do not present all data dimensions. For individual data dimensions, all elements in the list L = {e 0 , e 1 ,...,e m , α 1 , α 2 , ∅} are alternatives. However, for data groups, axes α i are excluded.</p><p>Simulation. A simulation process starts from a new node and uses a rollout policy to produce an outcome, as shown in Fig. <ref type="figure" target="#fig_2">4(d)</ref>. The rollout policy randomly chooses a node to expand recursively (like the step in the Expansion stage) until the node cannot expand, which means all data dimensions have been mapped at that time. To simulate more quickly, we do not pursue a high reward in this stage. Our goal is to simulate more times to get a high reward in a limited time.</p><p>Backpropagation. In this stage, the simulation result is backed up to update the selected nodes (Fig. <ref type="figure" target="#fig_2">4(e)</ref>). New nodes are also added to the tree T with a reward value and one visited time. Other visited nodes need to update a reward value if it is bigger and add one visited time. Then the search process returns to the selection stage or terminates when the time limits are exceeded, or the search tree is exhausted.</p><p>Finally, the path with the highest reward value is identified as the best matching method in this generating iteration.</p><p>Reward Function. We propose a reward function to estimate the quality of the final MGV via three criteria: importance (I), semantic relevance (S), and overlapping (O):</p><formula xml:id="formula_5">R mgv = 1 n O mgv ∑ n d,b∈{e,α} I(d)S(d, b), if N α ∈ {0, 1} 0, otherwise<label>(5)</label></formula><p>where e is one of the selected visual elements, d is one data dimension or one data group, α is one of the axes, and N α is the number of axis nodes. We should check the number of axes (α) in the derived mapping method to guarantee a valid MGV. We removed all empty nodes at that time due to their zero importance.</p><p>• Importance Score estimates the importance of one data dimension or group. Since a cosine distance orders the importance mentioned above, some scores will be negative, which violates the reward calculation of MCTS. We normalize the distance as Importance Score I to ensure the feasibility of our model. • Semantic Score estimates the semantic relevance between a visual element and one data dimension. As discussed in Sect. 3.2, designers prefer to encode visual elements with correlated data. We adopt the Transformer-MM <ref type="bibr" target="#b6">[7]</ref> to bridge a text and image. Chefer et al. <ref type="bibr" target="#b6">[7]</ref> used the attention layers of the model to produce relevancy maps for image and text interactions. We choose the model CLIP <ref type="bibr" target="#b45">[46]</ref> to derive our semantic relevance score due to its abundance. It learns from 400 million text-image pairs already publicly available on the Internet. Specifically, we first convert the origin SVG into a pixel image. Given the pixel image and a textual description of one data dimension (d ∈ D), we derive a heatmap of pixels corresponding to the description and normalize its value. Next, for a visual element e, we calculate the average relevance of the area covered by it as the final S. We adopt different scores based on data type separately for axes. When presenting temporal data or geospatial data, the S is assigned one since such placement is semantically-resonant (DC1). We use the entire image for other data types to derive the relevance score S because the placement is relevant to all elements. • Overlapping Score estimates the overlapping degree of the final MGV. We calculate the overlapping areas in the MGV rendered in Sect. 4.2.3 based on the bounding box of each glyph:</p><formula xml:id="formula_6">O mgv = 1 if P overlap ≤ 30% 0 otherwise<label>(6)</label></formula><p>where P overlap is all elements' average overlapping percentage.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.3">Rendering</head><p>Given a visual element, the glyph placement, and data dimension, we need to make the encoding channel clear for rendering.</p><p>Encoding Channel for Visual Elements. As mentioned above, all data dimensions are divided into d (one data dimension) and g (a data group). Moreover, we divided all visual elements into e a and e !a for different value of the augmentation tag a i retained in Sect. 4.1. e a corresponds to a = 1 and vice versa. We consider three conditions separately for different visual elements and data dimensions: • d ↔ {e a , e !a }. Since the data input is only one dimension, we treated {e a , e !a } the same. Although element e a can be augmented, we preserve its original shape for a better representation. We use a heuristic method based on examples in our corpus (Fig. <ref type="figure" target="#fig_0">2(e)</ref>). We determine the encoding channel by analyzing the shape of elements and the data type. Given a data dimension, we select the most frequent encoding channel based on its type. When two or more data dimensions share the same element, we order them based on the reward function (Equation <ref type="formula" target="#formula_5">5</ref>). Dimensions with a higher reward can occupy a more frequent encoding channel. When using size channel, we need an additional decision based on the image structure (Equation <ref type="formula" target="#formula_0">1</ref>). Height, length, and area are three options for ultimate encoding. • g ↔ e a . For the pair of data groups and elements that can augment, we transform the element into different charts to present all dimensions in the group. We adopt four charts, namely, pie charts, donut charts, star plots, and heatmaps as shown in Fig. <ref type="figure" target="#fig_1">3(d)</ref>. For numerical data, we consider star plots. Specifically, pie charts, donut charts, and heatmaps are alternatives for proportional data. • g ↔ e !a . We use a typical design in our corpus with visual elements that cannot augment. We choose three encoding channels (rotation, color, and size) of one visual element to represent a data group. Rotations and colors are both used to distinguish different data dimensions in the group. The size encodes the numerical data. An example is displayed in Fig. <ref type="figure">1(b</ref>). The leaves are rotated to illustrate the forest area in different years. Color is also utilized to distinguish the value year, as shown in the legend (Fig. <ref type="figure">1</ref>(b1)). The size of the leaves represents the percentage value. Notably, we check if the removed elements e r in Pruning (Fig. <ref type="figure" target="#fig_1">3(c</ref>)) need to be drawn after confirming encoding channels. We call the preserved element that overlaps with the removed one as e p , and the encoding channel for e p as c p . If e p encodes data and c p is size, we scale the e r the same as e p and add it into the glyph. If e p is transformed into a chart or does not encode data, we delete the element. For other conditions, we keep it in its original shape for drawing.</p><p>Glyph Placement. Owing to the limit in the simulation stage of MCTS, we only need to consider the independent data dimensions d and the axes α. For temporal data, we use a timeline to illustrate following DC1. For geo-spatial data, we utilize a map (Fig. <ref type="figure">1(b</ref>) and (f)). For other numerical data, if the number of axes is one, we adopt a horizontal axis to place glyphs. A Cartesian coordinate system is the right choice with two axes, as shown in Fig. <ref type="figure">1</ref>(a) and (e). Concerning categorical data, we place glyphs in a specific order as shown in Fig. <ref type="figure">1(c</ref>) and (g).</p><p>Ultimately, we can obtain one semantically-resonant MGV with the highest reward for each image candidate. We pick the greatest as the output based on all candidates' reward values, and others are ranked as alternatives for users to choose from.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">METAGLYPH</head><p>This section introduces the workflow of MetaGlyph that generates MGVs given a spreadsheet input and the interface design.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Workflow</head><p>We design the workflow of MetaGlyph based on the design considerations proposed in Sect. 3.3. Following DC3, MetaGlyph integrates the automatic model and user interactions into the authoring process. First, users need to import a spreadsheet of data as the input. An initial MGV is generated based on the automatic model. The quality of MGV is ensured by a reward function that considers different dimensions, including data importance and semantic matching (DC2) as discussed in Sect. 4. After that, users can modify the data mappings and the encodings of the initial visualization result. The automatic model will re-calculate and create a new MGV based on users' input. To ensure the efficiency of the computing following DC2, we limit the search number of images at one time. Next, users can smoothly switch between different visualizations and refine the satisfactory one as the final output. Given that both the users and the model contribute to the design of the MGV, MetaGlyph can derive more novel and creative designs compared with a solo-authoring workflow.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">User Interface</head><p>The MetaGlyph (Fig. <ref type="figure" target="#fig_3">5</ref>) consists of four views: Menu view, MGV view, Gallery view, and Edit view. The Menu view shows the creation procedures of our system, that is, first upload, then preprocess, and ultimately edit the visualization. Our system only needs one data input. Users can upload a spreadsheet, and our system will process the data. After the system's calculation, we can derive several MGVs with high rewards within a suitable waiting time (DC2) using the MGV generation model in Sect. 4. Moving to the edit step, the MGV with the highest reward is presented in the MGV view (Fig. <ref type="figure" target="#fig_3">5(b</ref>)), and the other alternatives are shown in the Gallery view (Fig. <ref type="figure" target="#fig_3">5(d)</ref>). Moreover, all segmented visual elements of the image are displayed on the left of the MGV view. Here, Element 0 represents the entire metaphor. Users can select other MGVs in the Gallery view following their preferences. When hovering over the alternatives, we display the original metaphor (Fig. <ref type="figure" target="#fig_3">5(d1)</ref>). The Edit view will show all mappings and allow users to modify them (Fig. <ref type="figure" target="#fig_3">5(c)</ref>). Each small panel illustrates detailed information about one data dimension or one data group, including the title of the data column, data type, element mapped, and corresponding encoding channel. The ordering of different data dimensions depends on the importance score discussed in Sect. 4.2. We use a small icon to illustrate the data type after its title. For data that are not represented in the current MGV, the mapped element is shown as None. Users can alter the data mappings by changing the visual elements in corresponding panels in the Edit view. After clicking the Update button in the MGV view, the generation model will re-calculate to obtain a satisfactory result following DC3. Finally, by clicking the Export button, users can export the MGV shown in the center as an SVG file.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Usage Scenario</head><p>We present one usage scenario in detail in this section. Adam is a junior visualization researcher. His task was to analyze the ingredients and nutrients of different hamburgers in McDonald <ref type="bibr" target="#b0">[1]</ref> for customers to make a better choice. He uploaded the processed tabular data in the MetaGlyph system and clicked the "generate" button. After a few seconds, the system generated a list of MGVs, as shown in Fig. <ref type="figure" target="#fig_3">5</ref>. The MGV in the center represents three data dimensions: burger lettuce, sugars, and bacon (Fig. <ref type="figure" target="#fig_3">5(e)</ref>). After browsing and absorbing the concrete mapping relations displayed in the Edit view (Fig. <ref type="figure" target="#fig_3">5(c</ref>)), Adam quickly understood the encodings of the glyph. Bread is a kind of carbohydrate. Therefore, the size of the upper bread is appropriate to encode the data attribute Sugars. He was also satisfied with the method to show Burger Lettuce and Bacon using green and red lines (Fig. <ref type="figure" target="#fig_3">5(e)</ref>) due to the intuitiveness. He clicked three titles of corresponding data dimensions in the Edit view (Fig. <ref type="figure" target="#fig_3">5</ref>(c1)) to add three limits for the next update. Next, Adam obtained a new result and continued exploration for other alternatives in the Gallery view (Fig. <ref type="figure" target="#fig_3">5(d)</ref>). Reanalyzing the dataset, he considered grouping some data columns, including iron, calcium, vitamin A, and vitamin C, since these are often considered as nutrients. He returned to the Preprocess step (Fig. <ref type="figure" target="#fig_3">5(a)</ref>) and added one data group. This time he found an interesting MGV, which adopted a heatmap-like design on the upper bread to represent the new data group. Adam preserved this design and adjusted other mappings following his preferences. After clicking the legend button (Fig. <ref type="figure" target="#fig_3">5</ref>(b1)), he understood the encodings for the upper bread (Fig. <ref type="figure" target="#fig_4">6(a)</ref>). Using such a design, he could grasp different levels of four components at first sight. Other encodings are displayed in Fig. <ref type="figure" target="#fig_4">6</ref>. The numbers of red lines and green lines illustrate the amount of bacon and lettuce layers, respectively. The length of the bread below represents the Sugars. Satisfied with this result, he exported this MGV.</p><p>Following a similar procedure, we demonstrate the expressiveness of MetaGlyph by creating more MGVs with various datasets ( Fig. <ref type="figure">1</ref>). These examples are hard to create with existing tools. For example, automatic tools (e.g., GlyphCreator <ref type="bibr" target="#b65">[65]</ref>, Diatoms <ref type="bibr" target="#b3">[4]</ref> do not provide explicit support for metaphoric glyph design. Authoring tools (e.g., DDG <ref type="bibr" target="#b27">[28]</ref>, DataQulit <ref type="bibr" target="#b66">[66]</ref>) provide greater flexibility and allow users to achieve similar results. However, the authoring process is tedious and time-consuming (e.g., requiring users to find or draw suitable metaphor images and encode data), and the quality of MGVs is highly dependent on the user. Moreover, they do not support embedding charts in the glyphs (e.g., star plots in Fig. <ref type="figure">1</ref>(a) and pie charts in Fig. <ref type="figure">1(f)</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">EXPERT INTERVIEW</head><p>To evaluate the MetaGlyph system and generated MGVs, we performed a series of interviews with three expert users in different fields. The first expert (E1) is a data journalist who has worked for a digital-news firm for more than three years. The second expert (E2) majored in visual communication and has more than ten years of design experience. The third expert (E3) is a senior researcher who has studied humancomputer interaction and data visualization for more than eight years.</p><p>Procedure. We conducted the interview via an online meeting system. Each interview began with a 10-minute introduction of MGV following a 10-minute demo of our MetaGlyph system. Next, the experts were encouraged to use MetaGlyph online on their own. After thorough trials of our system's features, we asked experts to generate MGVs using the Burger and Pokemon datasets introduced in Sect. 5.3.</p><p>We recorded their creation process in a think-aloud approach. Our interviews were seeded with a set of questions that probed into the effectiveness of MetaGlyph and the quality of the generated MGVs. The one-hour screen capture videos and audios were recorded from these interviews for further analysis.</p><p>Feedback. In general, all experts expressed their compliments of MetaGlyph and agreed on its promising usage. We summarized the interview results from three perspectives:</p><p>Workflow. Three interviewees appreciated the overall design of the workflow. All of them expressed the effectiveness of integrating metaphors into the design. They believed that the automatic system is an efficient way to speed up the generation. During their previous creation, they preferred design software (e.g., Adobe Illustrator) or programming (E1, E3) after confirming the design ideas. E1 said, "Some of my colleagues write codes, but it requires long-time learning." E3 commented, "When using design software, I need to do time-consuming batch work." She also expressed the difficulty of dealing with some visual elements, such as adjustments of arc angles. With MetaGlyph, she thought the creation process would be more straightforward.</p><p>System. All experts were satisfied with the design of MetaGlyph. They appreciated the aesthetics of the interface and expressed the ease of learning cost when using MetaGlyph. E1 noted, "The interaction is intuitive, and I can use it proficiently after a simple demonstration." For the designs of different views, E2 observed the Gallery view and commented, "Due to the difference in users' visual experience, their understanding ability is disparate. It is considerate to provide various alternatives for them." E3 liked the Edit view, "I prefer to try different results on my own. Although the system's results are nice, I can derive a different version by changing some attributes in the edit view."</p><p>Visualization. In terms of the quality of generated MGVs, all interviewees agreed that the outputs were thoughtful due to the semantic relevance and metaphor embodied. E2 underscored the match pattern for data and visual elements in MetaGlyph, which he also focused on during his design. He said, "Important data should be mapped with prominent elements." He also agreed with the limitation of the number of encoded data dimensions, "It is essential to make trade-offs to data, such as preserving three data dimensions. Too much information will lead to comprehension problems." E1 and E3 both commented that MGVs could serve as the basis for creative work in their early design. E3 said, "When designing, the most struggling part is the beginning due to the large design space. The outputs not only give me a direction but also broaden my scope via some unexpected designs." She agreed to use online sources since such images meet most people's cognition. Therefore, the MGVs can be better understood by audiences.</p><p>Suggestions. We also received suggestions from different aspects. As an editor, E1 focused on the stories behind the data and suggested that corresponding conclusions can be generated automatically together with MGVs. E2's advice fell into the improvement of visual comprehension. He was confused about some specific values in the output MGV such as the size of the burger layer represents. E2 suggested adding more annotations and textual descriptions into the MGVs. He noted that color could also be considered in understandability. E3 gave some advice from the perspective of an interaction designer, such as the button position and the highlight effect. She also suggested exporting more files (e.g., legend, files of different elements, mapping space between data and elements) together with the MGV, thereby allowing further refinement using professional design tools. We further revised the system according to her suggestions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">DISCUSSION</head><p>This section reflects the implications and limitations of MetaGlyph.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1">Implications</head><p>In this paper, we contribute an automatic approach to generating glyphbased visualization associated with comprehensive visual metaphors to help people understand data in an intuitive manner <ref type="bibr" target="#b21">[22]</ref>. We propose the semantic-based generation framework by selecting resonant metaphorical images and mapping visual elements with data dimensions considering data importance and semantic relevance. Users can customize the resulting MGVs based on their requirements. We derive a set of implications in the design process of our system.</p><p>Automating glyph designs in association with semantic-resonant metaphors. Metaphors are widely used in visualization, which associates data semantics with figurative motifs. MetaGlyph aims to automatically generate glyphs whose visual elements are associated with semantically related metaphors. To this end, we first search for appropriate metaphors with images considering the overall topic of the input data. Furthermore, we decompose visual elements of the metaphor and match them with data attributes with respect to the underlying semantic relations by adopting a prediction model. For example, the system searches burger images for the dataset of burger ingredients and maps the lettuce and bacon to the green and red elements, respectively (Fig. <ref type="figure" target="#fig_4">6</ref>). In this way, the resulting MGVs are associated with the underlying data semantics cohesively. Balancing design expressiveness and perceptual effectiveness. The increase in data dimensionality leads to a complicated metaphoric glyph design that is difficult to understand <ref type="bibr" target="#b2">[3]</ref>. Our qualitative analysis (Sect. 3.2) and expert interview (Sect. 6) both indicate the constraint of the number of encoded data dimensions. Besides, our expert E2 suggests emphasizing important data with prominent visual elements, "I will not utilize all elements for presenting data. It would be overwhelming." Some visual elements in the metaphor are better used to encode data attributes, while others are more suitable for decoration purposes. Accordingly, the encoded data dimensions and visual elements should be balanced with perceptual constraints. Our current approach has filtered MGVs that utilize overmuch elements in the mapping space (Sect. 4.2.2). Further experiments are encouraged to explore the appropriate amount of conveyed information in an MGV that informs better automatic generation criteria with perceptual effectiveness. Supporting a human-machine teaming approach. We situate MetaGlyph as a human-machine teaming system that integrates the machine with users' feedback. Incorporating metaphors into designs is generally considered a highly creative task, requiring implicit knowledge to determine the right imagery and modify it to fit scenarios. Faced with the large search space of metaphors and data mappings, generating MGVs is time-consuming and laborious. Automating the laborintensive parts with machines is highly required. Moreover, MetaGlyph provides more than tool-level assistance. It explores the search space for users to compare design alternatives. Both novices and experts can benefit from the rapid results of the initial designs. Users are likewise supported to modify the results based on their preferences. With the machine's assistance, users can focus on the data mappings without adjusting the elements' attributes manually. Moreover, MGVs can be updated multiple times according to users' requirements and the machine's re-calculation. By assigning the labor-intensive part to the machine and providing the connectors of subjective decisions to human beings, MetaGlyph provides a successful human-machine teaming example and inspires the design of visualization tools in the future. Providing design inspirations.</p><p>All experts appreciated how MetaGlyph allowed them to discover unexpected designs. Given that the design space of MGVs can be much large considering both metaphor selection and visual mapping, it would be impossible for designers to try all alternatives. In addition, as mentioned by E3, designers are likely to start with familiar designs based on their usual practice. Instead, the machine enumerates all possibilities, which may result serendipitously in promising designs. For example, E3 praised the star plot inside the Pokeball (Fig. <ref type="figure">1(a)</ref>) and the flower-like leaves (Fig. <ref type="figure">1(b)</ref>). "I never thought of using such designs for these datasets. The visualization created by MetaGlyph shows diverse design possibilities," E3 said. Designers can further refine the design using MetaGlyph or export the whole design assets for fine-tuning with professional tools.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2">Failure Cases and Limitations</head><p>Failure Cases. We observed several wrong or bad cases during the development of MetaGlyph. First, one critical source of some failure cases is the diversity of images the system searches from online sources as the metaphors. For example, some images may have elements in multiple layers, such as Fig. <ref type="figure" target="#fig_5">7</ref>(a) shows a car with a background. When scaling the car to encode data, the system cannot guarantee that the car can always be within the background, resulting in an incomprehensible MGV. Second, as we currently adopt some heuristic methods to decide the layout (Sect. 4.2), it cannot always be true. For example, Fig. <ref type="figure" target="#fig_5">7(b</ref>) is wrongly identified as a radial glyph as it has two elements whose centers Limitations. First, the degree of customization for MetaGlyph is limited. Specially, we follow the default style of the metaphoric source image, and use fixed parameters when calculating (e.g., set the boundary 0.5% in Pruning in Sect. 4.1). Future work can allow users to customize their MGVs, including but not limited to styles <ref type="bibr" target="#b7">[8]</ref> and a custom field of parameters. Second, MetaGlyph only supports tabular data with a single sheet, while complicated data structures, such as graph-related data, are not supported. Because graph-related data can be represented as multiple-sheet data (e.g., adjacency matrices), we plan to extend MetaGlyph with more data processing operators to integrate multiple data sheets in the encodings of a single glyph. In this way, we can improve the diversity of the resulting visualization for MetaGlyph. Third, we mainly consider the importance of data dimensions and their semantic relevance with visual elements in data mapping. Other factors (such as SVG elements' sizes and shapes, mapping different elements with different channels, and users' priori knowledge) also play roles in the mapping. Future research can further explore how to consider all these factors to achieve a better MGV design.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">CONCLUSION AND FUTURE WORK</head><p>This paper presents MetaGlyph, an automatic system for generating MGVs. We first conduct qualitative analysis to understand the design patterns of MGVs and then develop an automatic generation framework. We automate the entire process by searching for appropriate metaphors, processing images, and determining multiple data mappings along with visual encodings. Given the ample mapping space between visual elements and data dimensions, we adopt an MCTS algorithm to achieve an efficient and effective search considering data importance, semantic relevance, and glyph separation. By uploading tabular data, our system will generate several MGVs within a few seconds. Moreover, as a human-machine teaming system, MetaGlyph enables users to modify the MGVs following their preferences. We evaluate MetaGlyph through two usage scenarios and a gallery of examples and demonstrate its effectiveness via a series of expert interviews. MetaGlyph shows its potential in various situations, such as education <ref type="bibr" target="#b29">[30]</ref> and journalism. Teachers can use MetaGlyph to create metaphoric designs to help teach data literacy or visual encodings, while journalists can use it to create figurative and expressive visualization easily and quickly.</p><p>Looking into the future, we hope our work can inspire further research from the perspectives of design expressiveness and perceptual effectiveness with regard to different visual representations (e.g., storyline <ref type="bibr" target="#b56">[56]</ref>, data comics, and visual analytics systems <ref type="bibr" target="#b60">[60]</ref>). First, we plan and also encourage researchers to conduct empirical studies to investigate how different users understand metaphoric visualizations. Cognitive experiments can likewise be designed to derive metrics for the effectiveness of metaphor selection, so that more theories about computational metaphors can be constructed. In turn, the theories can be utilized to inspire the development of future visualization tools. Second, research on automatic visualization generation <ref type="bibr" target="#b17">[18]</ref> can benefit from large-scale visualization datasets (e.g., VisImages <ref type="bibr" target="#b14">[15]</ref>). Future work can focus on constructing glyph datasets to facilitate the use of end-to-end deep learning models for an efficient generation.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. The number of MGVs (a) in different metaphor types, (b) in different glyph placements, and (c) in different glyph layouts. The frequency of (d) amounts of different encoded elements and (e) different encoding channels for numerical and categorical data types in our corpus.</figDesc><graphic url="image-2.png" coords="3,314.05,73.00,231.45,137.82" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. The entire process of metaphoric image selection for each (a) input online image, including (b) segmentation: dividing the image into visual elements, (c) pruning: deleting redundant elements and determining the structure, and (d) augmentation: checking if some elements can transform into charts. The output is an element list with an image structure. (e) The mapping space for constructing MGVs.</figDesc><graphic url="image-3.png" coords="5,70.65,72.99,460.00,77.33" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. (a) The data dimensions and groups are ordered by importance independently. An iteration of the Monte Carlo tree search consists of four stages, including (b) selection, (c) expansion, (d) simulation, and (e) backpropagation. The shapes with a yellow frame represent the operation of this stage. Inside the nodes are element thumbnails (e i ) or axes (α i ). Circles with no elements are empty nodes (∅).</figDesc><graphic url="image-4.png" coords="6,64.47,73.00,230.64,84.18" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. The interface of MetaGlyph is consisted of : (a) a Menu view for different steps; (b) an MGV view representing visual elements and corresponding MGV, (c) an Edit view, in which the data mappings can be modified based on user's preferences, and (d) a Gallery view with other MGV options. (e) concrete data mappings for the MGV view in detail.</figDesc><graphic url="image-20.png" coords="7,67.03,191.78,62.60,59.74" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 6 .</head><label>6</label><figDesc>Fig. 6. An example generated with the burger dataset. (a) The legend for the upper bread generated by MetaGlyph. The boxes with yellow backgrounds illustrate the data mappings and encoding channels. Dashed arrows are used to associate visual elements with the MGV.</figDesc><graphic url="image-32.png" coords="8,65.49,153.83,228.35,151.64" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 7 .</head><label>7</label><figDesc>Fig. 7. (a) A car with a driving background. (b) A hotel.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic url="image-1.png" coords="1,85.69,188.31,429.31,344.07" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>• L.Ying, D. Deng, Y. Yang, Y. Wu are with the State Key Lab of CAD&amp;CG, Zhejiang University, Hangzhou, China. Y. Wu is also with the Alibaba-Zhejiang University Joint Research Institute of Frontier Technologies. E-mail: {yingluu, dengdazhen, yyc yang, ycwu}@zju.edu.cn.</figDesc><table><row><cell>• X. Shu is with Department of Computer Science and Engineering, The Hong</cell></row><row><cell>Kong University of Science and Technology, Hong Kong, China. E-mail:</cell></row><row><cell>xinhuan.shu@connect.ust.hk.</cell></row><row><cell>• T. Tang is with School of Art and Archaeology, Zhejiang University,</cell></row><row><cell>Hangzhou, China. E-mail: tangtan@zju.edu.cn.</cell></row><row><cell>• L. Yu is with Department of Computing, Xi'an Jiaotong-Liverpool</cell></row><row><cell>University, Suzhou, China. Email: Lingyun.Yu@xjtlu.edu.cn.</cell></row><row><cell>• Yingcai Wu is the corresponding author.</cell></row></table><note>Manuscript received xx xxx. 201x; accepted xx xxx. 201x. Date of Publication xx xxx. 201x; date of current version xx xxx. 201x. For information on obtaining reprints of this article, please send e-mail to: reprints@ieee.org. Digital Object Identifier: xx.xxxx/TVCG.201x.xxxxxxx</note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS</head><p>The work was supported by NSFC (62072400) and the Collaborative Innovation Center of Artificial Intelligence by MOE and Zhejiang Provincial Government (ZJU).</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Menu -Comparative Nutrition Values</title>
		<author>
			<persName><surname>Mcdonald's</surname></persName>
		</author>
		<ptr target="https://www.kaggle.com/code/kathakaliseth/mcdonald-s-menu-comparative-nutrition-values" />
		<imprint>
			<biblScope unit="page" from="2022" to="2023" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Reinventing the Contingency Wheel: Scalable Visual Analytics of Large Categorical Data</title>
		<author>
			<persName><forename type="first">B</forename><surname>Alsallakh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Aigner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Miksch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">E</forename><surname>Groller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2849" to="2858" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Glyph-based Visualization: Foundations, Design Guidelines, Techniques and Applications</title>
		<author>
			<persName><forename type="first">R</forename><surname>Borgo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kehrer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">H S</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Maguire</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Laramee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Hauser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ward</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eurographics</title>
				<meeting>the Eurographics</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="39" to="63" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Generative design inspiration for glyphs with diatoms</title>
		<author>
			<persName><forename type="first">M</forename><surname>Brehmer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Kosara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Hull</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="389" to="399" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">A Survey of Monte Carlo Tree Search Methods</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">B</forename><surname>Browne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Powley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Whitehouse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Lucas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">I</forename><surname>Cowling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Rohlfshagen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Tavener</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Perez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Samothrakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Colton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Computational Intelligence and AI in Games</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="43" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Visualizing web search results using glyphs: Design and evaluation of a flower metaphor</title>
		<author>
			<persName><forename type="first">M</forename><surname>Chau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Management Information Systems</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="27" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<author>
			<persName><forename type="first">H</forename><surname>Chefer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wolf</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2103.15679</idno>
		<title level="m">Generic Attention-model Explainability for Interpreting Bi-Modal and Encoder-Decoder Transformers</title>
				<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">A review of image and video colorization: From analogies to deep learning</title>
		<author>
			<persName><forename type="first">S.-Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-Q</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y.-Y</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">L</forename><surname>Rosin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y.-K</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Gao</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2022">2022</date>
			<publisher>Visual Informatics</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">MARVisT: Authoring Glyph-Based Visualization in Mobile Augmented Reality</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="2645" to="2658" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">The Use of Faces to Represent Points in k-Dimensional Space Graphically</title>
		<author>
			<persName><forename type="first">H</forename><surname>Chernoff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Statistical Association</title>
		<imprint>
			<biblScope unit="volume">68</biblScope>
			<biblScope unit="issue">342</biblScope>
			<biblScope unit="page" from="361" to="368" />
			<date type="published" when="1973">1973</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Infomages: Embedding Data into Thematic Images</title>
		<author>
			<persName><forename type="first">D</forename><surname>Coelho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Mueller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics Forum</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="593" to="606" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">VineMap: A metaphor visualization method for public opinion hierarchy from text data</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Visualization</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">The Many-Faced Plot: Strategy for Automatic Glyph Generation</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Cunha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Polisciuc</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Martins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Machado</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference Information Visualisation</title>
				<meeting>the International Conference Information Visualisation</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="71" to="77" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">An Organic Visual Metaphor for Public Understanding of Conditional Co-occurrences</title>
		<author>
			<persName><forename type="first">K</forename><surname>Dasu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Fujiwara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K.-L</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Scientific Visualization Conference</title>
				<meeting>the IEEE Scientific Visualization Conference</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="1" to="5" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">VisImages: A Large-scale, High-quality Image Corpus in Visualization Publications</title>
		<author>
			<persName><forename type="first">D</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Shu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">You are experienced: Interactive tour planning with crowdsourcing tour data from web</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Weng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Visualization</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page">2023</biblScope>
		</imprint>
	</monogr>
	<note>to appear</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Compass: Towards Better Causal Analysis of Urban Time Series</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Weng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Bao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1051" to="1061" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Dashbot: Insight-driven dashboard generation based on deep reinforcement learning</title>
		<author>
			<persName><forename type="first">Dazhen</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aoyu</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Huamin</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yingcai</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint/>
	</monogr>
	<note>To Appear</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Visual Analytics for Topic Model Optimization based on User-Steerable Speculative Execution</title>
		<author>
			<persName><forename type="first">M</forename><surname>El-Assady</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Sperrle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Deussen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Keim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Collins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="374" to="384" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Graphical representation of multivariate data by means of asymmetrical faces</title>
		<author>
			<persName><forename type="first">B</forename><surname>Flury</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Riedwyl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Statistical Association</title>
		<imprint>
			<biblScope unit="volume">76</biblScope>
			<biblScope unit="issue">376</biblScope>
			<biblScope unit="page" from="757" to="765" />
			<date type="published" when="1981">1981</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Evaluation of alternative glyph designs for time series data in a small multiple setting</title>
		<author>
			<persName><forename type="first">J</forename><surname>Fuchs</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Mansmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Bertini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Isenberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Human Factors in Computing Systems</title>
				<meeting>the Conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="3237" to="3246" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">A Systematic Review of Experimental Studies on Data Glyphs</title>
		<author>
			<persName><forename type="first">J</forename><surname>Fuchs</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Isenberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bezerianos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Keim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1863" to="1879" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Leaf Glyphs: Story Telling and Data Analysis Using Environmental Data Glyph Metaphors</title>
		<author>
			<persName><forename type="first">J</forename><surname>Fuchs</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Jäckle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Weiler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Schreck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision</title>
				<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="volume">598</biblScope>
			<biblScope unit="page" from="123" to="143" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">An evaluation of the use of analogy, simile, and metaphor in science texts</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">W</forename><surname>Gilbert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Research in Science Teaching</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="315" to="327" />
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">An introductory survey on attention mechanisms in nlp problems</title>
		<author>
			<persName><forename type="first">D</forename><surname>Hu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of SAI Intelligent Systems Conference</title>
				<meeting>SAI Intelligent Systems Conference</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="432" to="448" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Facial representation of multivariate data</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Jacob</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Graphical representation of multivariate data</title>
				<imprint>
			<date type="published" when="1978">1978</date>
			<biblScope unit="page" from="143" to="168" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">MotionFlow: Visual Abstraction and Aggregation of Sequential Patterns in Human Motion Tracking Data</title>
		<author>
			<persName><forename type="first">S</forename><surname>Jang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Elmqvist</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Ramani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="21" to="30" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Data-Driven Guides: Supporting Expressive Design for Information Graphics</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">W</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Schweickart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Dontcheva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Popovic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Pfister</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="491" to="500" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Understanding visual metaphor: Developmental and individual differences. Monographs of the Society for Research in Child Development</title>
		<author>
			<persName><forename type="first">N</forename><surname>Kogan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Connor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Fava</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1980">1980</date>
			<biblScope unit="page" from="1" to="78" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">A survey of visual analytics techniques for online education</title>
		<author>
			<persName><forename type="first">X</forename><surname>Kui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2022">2022</date>
			<publisher>Visual Informatics</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Distributed representations of sentences and documents</title>
		<author>
			<persName><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Machine Learning</title>
				<meeting>the International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="1188" to="1196" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">MatchPad: Interactive Glyph-Based Visualization for Real-Time Sports Performance Analysis</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">A</forename><surname>Legg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">H S</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">L</forename><surname>Parry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">W</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">W</forename><surname>Griffiths</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics Forum</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">3pt4</biblScope>
			<biblScope unit="page" from="1255" to="1264" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Visual signatures for financial time series</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">T</forename><surname>Lei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Visual Information Communication -International Symposium</title>
				<meeting>the Visual Information Communication -International Symposium</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="1" to="10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Image Captioning with multi-level similarity-guided semantic matching</title>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Visual Informatics</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Metaphoric transfer effect in information visualization using glyphs</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Symposium on Visual Information Communication and Interaction</title>
				<meeting>the International Symposium on Visual Information Communication and Interaction</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="121" to="130" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">SmartAdP: Visual Analytics of Large-scale Taxi Trajectories for Selecting Billboard Locations</title>
		<author>
			<persName><forename type="first">D</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Weng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Bao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="10" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">An Uncertainty-Aware Approach for Exploratory Microblog Retrieval</title>
		<author>
			<persName><forename type="first">M</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Pan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="250" to="259" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Dear data</title>
		<author>
			<persName><forename type="first">G</forename><surname>Lupi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Posavec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Chronicle books</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">ARGUS: Interactive Visual Analysis of Disruptions in Smartphone-detected Bio-Behavioral Rhythms</title>
		<author>
			<persName><forename type="first">H</forename><surname>Mansoor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Gerych</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Alajaji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Buquicchio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Chandrasekaran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Agu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Rundensteiner</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021">2021</date>
			<publisher>Visual Informatics</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Efficient estimation of word representations in vector space</title>
		<author>
			<persName><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of International Conference on Learning Representations</title>
				<meeting>International Conference on Learning Representations</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Testing the First Law of Cognitive Geography on Point-Display Spatializations</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">R</forename><surname>Montello</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">I</forename><surname>Fabrikant</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ruocco</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">S</forename><surname>Middleton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Spatial Information Theory. Foundations of Geographic Information Science</title>
				<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="volume">2825</biblScope>
			<biblScope unit="page" from="316" to="331" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">From vienna method to isotype</title>
		<author>
			<persName><forename type="first">O</forename><surname>Neurath</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Empiricism and Sociology</title>
				<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1973">1973</date>
			<biblScope unit="page" from="214" to="248" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">G. lakoff, m. johnson, metaphors we live by. Artificial Intelligence</title>
		<author>
			<persName><forename type="first">P</forename><surname>Norvig</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1985">1985</date>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="357" to="361" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">TenniVis: Visualization for Tennis Match Analysis</title>
		<author>
			<persName><forename type="first">T</forename><surname>Polk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2339" to="2348" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">CleanAirNowKC: Building Community Power by Improving Data Accessibility</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Proma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sumpter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Lugo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Friedman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">T</forename><surname>Huq</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Rosen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE Workshop on Visualization for Social Good</title>
				<meeting>IEEE Workshop on Visualization for Social Good</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="1" to="5" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title level="m" type="main">Learning transferable visual models from natural language supervision</title>
		<author>
			<persName><forename type="first">A</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">W</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Hallacy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ramesh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Goh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Sastry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Askell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Mishkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Krueger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title level="m">Proceedings of the International Conference on Machine Learning</title>
				<meeting>the International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="8748" to="8763" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Sentence-bert: Sentence embeddings using siamese bert-networks</title>
		<author>
			<persName><forename type="first">N</forename><surname>Reimers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Gurevych</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing</title>
				<meeting>the Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="3980" to="3990" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Charticulator: Interactive Construction of Bespoke Chart Layouts</title>
		<author>
			<persName><forename type="first">D</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Brehmer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="789" to="799" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Glyphmaker: Creating Customized Visualizations fo Complex Data</title>
		<author>
			<persName><forename type="first">W</forename><surname>Ribarsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">Z</forename><surname>Ayers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Eble</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mukherjea</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="57" to="64" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">TimeBench: A Data Model and Software Library for Visual Analytics of Time-Oriented Data</title>
		<author>
			<persName><forename type="first">A</forename><surname>Rind</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Lammarsch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Aigner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Alsallakh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Miksch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2247" to="2256" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
		<title level="m" type="main">On the role of metaphor in information visualization</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Risch</surname></persName>
		</author>
		<idno type="arXiv">arXiv:0809.0884</idno>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Survey of glyph-based visualization techniques for spatial multivariate medical data</title>
		<author>
			<persName><forename type="first">T</forename><surname>Ropinski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Oeltze</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Preim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computers &amp; Graphics</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="392" to="401" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Examining interaction techniques in data visualization authoring tools from the perspective of goals and human cognition: A survey</title>
		<author>
			<persName><forename type="first">S</forename><surname>Rubab</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Visualization</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Automatic generation of semantic icon encodings for visualizations</title>
		<author>
			<persName><forename type="first">V</forename><surname>Setlur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Mackinlay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the SIGCHI Conference on Human Factors in Computing Systems</title>
				<meeting>the SIGCHI Conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="541" to="550" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">The effect of data-relatedness in interactive glyphs</title>
		<author>
			<persName><forename type="first">H</forename><surname>Surtola</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Information Visualisation</title>
				<meeting>the International Conference on Information Visualisation</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="869" to="876" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<monogr>
		<author>
			<persName><forename type="first">T</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Knittel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Koch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Ertl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2009.00249</idno>
		<title level="m">PlotThread: Creating Expressive Storyline Visualizations using Reinforcement Learning</title>
				<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">AFExplorer: Visual analysis and interactive selection of audio features</title>
		<author>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Visual Informatics</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">2022</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Multivariate Data Glyphs: Principles and Practice</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">O</forename><surname>Ward</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Handbook of Data Visualization</title>
				<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="179" to="198" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Towards a Systematic Combination of Dimension Reduction and Clustering in Visual Analytics</title>
		<author>
			<persName><forename type="first">J</forename><surname>Wenskovitch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Crandell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Ramakrishnan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>House</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Leman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>North</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="131" to="141" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Qu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2201.09772</idno>
		<title level="m">Defence of Visual Analytics Systems: Replies to Critics</title>
				<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">A Visual Analytics Approach for Equipment Condition Monitoring in Smart Factories of Process Industry</title>
		<author>
			<persName><forename type="first">W</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Cao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Pacific Visualization Symposium</title>
				<meeting>the IEEE Pacific Visualization Symposium</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="140" to="149" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">DataInk: Direct and Creative Data-Oriented Drawing</title>
		<author>
			<persName><forename type="first">H</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">H</forename><surname>Riche</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Chevalier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">R D</forename><surname>Araújo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Wigdor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM Conference on Human Factors in Computing Systems</title>
				<meeting>the ACM Conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page">223</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">PassVizor: Toward Better Understanding of the Dynamics of Soccer Passes</title>
		<author>
			<persName><forename type="first">X</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1322" to="1331" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<monogr>
		<author>
			<persName><forename type="first">K</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Qiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Qu</surname></persName>
		</author>
		<title level="m">CloudDet: Interactive Visual Analysis of Anomalous Performances in Cloud Computing Systems. IEEE Transactions on Visualization and Computer Graphics</title>
				<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="1" to="1" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">GlyphCreator: Towards example-based automatic generation of circular glyphs</title>
		<author>
			<persName><forename type="first">L</forename><surname>Ying</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="400" to="410" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">DataQuilt: Extracting visual elements from images to craft pictorial visualizations</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Sultanum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bezerianos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Chevalier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM Conference on Human Factors in Computing Systems</title>
				<meeting>the ACM Conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="1" to="13" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y.-R</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Collins</surname></persName>
		</author>
		<author>
			<persName><surname>Fluxflow</surname></persName>
		</author>
		<title level="m">Visual Analysis of Anomalous Information Spreading on Social Media. IEEE Transactions on Visualization and Computer Graphics</title>
				<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="1773" to="1782" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">SilkViser: A Visual Explorer of Blockchain-based Cryptocurrency Transaction Data</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Shi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE Conference on Visual Analytics Science and Technology</title>
				<meeting>IEEE Conference on Visual Analytics Science and Technology</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="95" to="106" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
