<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Exploring Interactions with Printed Data Visualizations in Augmented Reality</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Wai</forename><surname>Tong</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Zhutian</forename><surname>Chen</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Meng</forename><surname>Xia</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Yu-Ho</forename><surname>Leo</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Linping</forename><surname>Lo</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Benjamin</forename><surname>Yuan</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Huamin</forename><surname>Bach</surname></persName>
						</author>
						<author>
							<persName><surname>Qu</surname></persName>
						</author>
						<title level="a" type="main">Exploring Interactions with Printed Data Visualizations in Augmented Reality</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.2" ident="GROBID" when="2023-03-27T09:18+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Interaction design</term>
					<term>augmented reality</term>
					<term>paper interaction</term>
					<term>tangible user interface</term>
					<term>printed data visualization</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Fig. 1. We investigate the possibility of interacting with printed visualizations in Augmented Reality. Suppose a student receives (a) a leaflet about university ranking and wants to analyze three universities' ranking history of interest. Examples of interactions with (b) digital content overlaid: (c) tilt the paper to rescale the y-axis, (d) move (translate) to zoom (e) unfold to show two charts side by side and link them, (f) point to select elements and highlight them in the other chart.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Interaction with visualizations is necessary for exploration, personalization, and wider engagement with data visualizations. Nevertheless, the specific means and their effectiveness for visualizations still cause considerable controversies and open research questions <ref type="bibr" target="#b29">[30,</ref><ref type="bibr" target="#b40">41]</ref>. For example, visualizations may support direct manipulation <ref type="bibr" target="#b63">[64]</ref> through pan&amp;zoom, interactive lenses <ref type="bibr" target="#b77">[78]</ref>, or brushing&amp;linking. However, these interactions are limited by the current interaction modalities (e.g., mouse, keyboard, touchscreen) and by the visibility and understandability of their interaction affordances <ref type="bibr" target="#b12">[13]</ref>. Unnatural interaction, unnoticed affordances, repetitive interactions, ambiguous interaction goals <ref type="bibr" target="#b1">[2]</ref>, or missing general interaction literacy <ref type="bibr" target="#b2">[3]</ref> pose serious obstacles to people engaging with data through visualizations.</p><p>To improve affordances and provide for effective interaction, different interaction modalities have been explored <ref type="bibr" target="#b52">[53]</ref>. For example, natural language interaction uses voice as a medium for interaction to support querying and creation of visualizations <ref type="bibr" target="#b28">[29]</ref>; data physicalizations provide affordances through three-dimensionality, situatedness, tangibility <ref type="bibr" target="#b45">[46]</ref>, and even dynamicity <ref type="bibr" target="#b74">[75]</ref>. Recently, virtual and augmented reality further provide the potential for display and direct interaction <ref type="bibr" target="#b27">[28,</ref><ref type="bibr" target="#b33">34]</ref> as well as offer combinations and hybridizations with tangible means for visualization and interaction <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b25">26]</ref>.</p><p>Complementing this line of research, we explore paper sheets as tangible means to interact with visualizations printed onto these paper sheets under augmented reality. We are interested in how far papers can provide affordances and means for direct manipulation with visualizations, and how to inform building systems that use these interactions. This research is motivated by paper being a cheap means to distribute and access information through, e.g., infographics <ref type="bibr" target="#b20">[21]</ref>, newspapers, posters, books, data comics <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b83">84]</ref>, or zines <ref type="bibr" target="#b56">[57]</ref>. Augmented reality (AR)-supported through camera-bearing mobile devices or Headmounted displays (HMD)-can update such static visualizations <ref type="bibr" target="#b20">[21]</ref> and bring interactivity to them by overlaying digital layers. While previous work has demonstrated interaction techniques to interact with data visualization in AR <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b25">26]</ref>, paper upon which the visualization is printed provides its very own affordances for interaction. These techniques are only marginally explored yet <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b46">47,</ref><ref type="bibr" target="#b67">68]</ref>. For example, paper can serve as a touch surface, which can be moved and rotated in space, bent, folded, moved, tilted, or stacked onto other paper sheets and even torn apart and crumpled. We argue that these interactions might occur naturally and require less training and practice to perform than customized physical tangible devices, such as <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b42">43,</ref><ref type="bibr" target="#b65">66,</ref><ref type="bibr" target="#b69">70]</ref>, due to familiarity, yet provide an effective means to interact with the data. Moreover, paper sheets provide tangible surfaces which ease arm fatigue compared to mid-air gestures <ref type="bibr" target="#b25">[26]</ref>. With paper interactions, people could easily interact with printed visualization distributed in exhibitions and presentations. Besides, interacting with printed visualizations could be helpful in visualization education <ref type="bibr" target="#b6">[7]</ref> and brainstorming <ref type="bibr" target="#b72">[73,</ref><ref type="bibr" target="#b73">74]</ref>. Moreover, paper interactions could possibly facilitate casual collaborative visual analytics <ref type="bibr" target="#b34">[35]</ref> due to its low technical barrier and enhance existing authoring tools <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b64">65]</ref> to support interactive visualizations in AR using paper interactions.</p><p>In this work, we present a design space of possible interactions with paper sheets and visualizations enhanced through AR. This design space helps us analyze interactions, inform future interfaces, and point to open research questions. For the purpose of this paper, we define an interaction as the mapping of an action onto a command, which we denote as a function action⇒command. Using terminology from the instrumental interaction framework <ref type="bibr" target="#b8">[9]</ref>, an action is any manipulation applied to an instrument (e.g., a point, rub, or fold to a paper sheet) while a command is an interaction task applied to a domain object (e.g., pan, zoom, and filter a data visualization). For example, we can map the action fold to the command filter. Consequently, we denote this interaction as fold⇒filter (speak: "fold-to-filter" or "filter-by-fold") The parameters that the fold action provides, e.g., the degree of folding, can be used to parameterize the filter command, e.g., define a threshold for filtering a set of elements from the visualization. Figure <ref type="figure">1</ref> shows an example of how a student performs a set of interactions onto a leaflet provided on an university open day.</p><p>We collected 146 ideas, 10 commands, and 18 actions from both an extensive literature survey and an ideation workshop with 20 participants (graduate students and researchers in visualization and HCI) (Section 3). Then, we extracted 81 interactions from these ideas and constructed a three-dimensional design space to classify interactions and guide the design of future interactions. The dimensions include 1) the commands supported by an interaction (e.g., zoom, pan, filter, etc.), 2) the specific parameters provided by an interaction (boolean, position/area, direction+value, and free expression), and 3) the number of paper sheets involved in an interaction (1 or many). Each interaction, being a combination of an action and a command, can be classified along these three dimensions.</p><p>Selecting 11 interactions by focusing on those commands used for view manipulation as described by Heer and Shneiderman <ref type="bibr" target="#b37">[38]</ref>, we then built an experimental prototype using HoloLens 2 and ran a user study (Section 5) with 12 participants. We were interested in participants' subjective considerations (preference, comfort, intuitiveness, and engagement) as well as interactions' practical viability by observing possible combinations and confounds when using multiple interactions in the same system. Our selected interactions involve eight actions and four commands (i.e., select an interval, zoom, pan, and link&amp;select).</p><p>Participants were highly positive towards paper interactions and engaged with the techniques, seamlessly using paper actions to ex-plore static visualizations. We summarize our main findings into six design implications that can inform future designs for interacting with visualizations on paper in AR (Section 6). For example, designers can consider alternative interactions (e.g., tilt⇒pan) when one interaction (e.g., point⇒pan) faces technical barriers or is not optimal for different data exploration purposes (e.g., casual exploration). All materials from the user studies and ideation workshops, and a demo video of the experiment prototype can be found at https://paperinteraction.github.io.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK</head><p>Interaction Techniques for AR Visualization. Existing interaction techniques for data visualizations under AR can be roughly classified into five categories based on their modalities: mid-air, tangible, touch, gaze and speech, and spatial based interfaces. Given that mid-air hand gestures are natural and intuitive for general users, several works have adopted mid-air hand gestures to help users navigate maps <ref type="bibr" target="#b61">[62]</ref> and static visualizations projected on projector screens <ref type="bibr" target="#b47">[48]</ref>. However, midair hand gestures can cause arm fatigue <ref type="bibr" target="#b38">[39]</ref> and thus are not suitable for long-term usage. To ease the arm fatigue issue <ref type="bibr" target="#b25">[26]</ref>, researchers have built AR tangible interfaces <ref type="bibr" target="#b11">[12]</ref>. For example, tangible objects, such as paper cards <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b46">47,</ref><ref type="bibr" target="#b67">68]</ref>, paper spheres <ref type="bibr" target="#b32">[33]</ref>, embodied axes <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b65">66]</ref>, and custom widgets <ref type="bibr" target="#b34">[35,</ref><ref type="bibr" target="#b42">43,</ref><ref type="bibr" target="#b69">70]</ref> have been utilized as controllers for users to interact with AR visualizations. As an alternative to the tangible interface, the touch interface on physical objects could be used to manipulate digital information precisely <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b31">32]</ref>. For example, the touch interface on the tabletop has been utilized for 3D parallel coordinate plot specification and manipulation <ref type="bibr" target="#b18">[19]</ref> and 3D selection <ref type="bibr" target="#b9">[10]</ref> in AR. Xiao et al. <ref type="bibr" target="#b80">[81]</ref> further proposed turning every flat surface into a touch screen for head-mounted mixed reality systems. Furthermore, researchers started to utilize gaze and speech interfaces for data visualization interaction <ref type="bibr" target="#b41">[42,</ref><ref type="bibr" target="#b47">48,</ref><ref type="bibr" target="#b55">56]</ref> because AR HMDs natively support these interactions (e.g., Microsoft HoloLens 2 and Magic Leap 1). Lastly, spatial user interfaces are also increasingly used for data navigation and placement. For example, researchers extended mobile devices as spatial devices to facilitate 3D data navigation <ref type="bibr" target="#b17">[18]</ref> and visualization placement in the 3D environment <ref type="bibr" target="#b41">[42]</ref>.</p><p>Nevertheless, paper, leveraging the benefit of touch ability, unique tangibility, and spatial interface, is only marginally explored <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b46">47,</ref><ref type="bibr" target="#b67">68]</ref> for data interaction, especially when visualizations can be easily printed on paper. As such, we aim to explore how to utilize the "already there" paper to manipulate data visualizations printed on paper directly.</p><p>Paper Interactions in HCI and Visualization. Previous work in the Human-Computer Interaction (HCI) literature investigated the use of paper and its metaphors to achieve better interaction design for tangible interfaces <ref type="bibr" target="#b36">[37,</ref><ref type="bibr" target="#b39">40]</ref>, desktops <ref type="bibr" target="#b0">[1]</ref>, and touchscreens <ref type="bibr" target="#b35">[36,</ref><ref type="bibr" target="#b48">49,</ref><ref type="bibr" target="#b71">72,</ref><ref type="bibr" target="#b75">76]</ref>. For example, Holman et al. <ref type="bibr" target="#b39">[40]</ref> proposed eight paper gestures for interacting with the digital information projected on paper. They are hold, collocate, collate, flip, rub, staple, point, and two-handed pointing. Utilizing paper interaction has been found to make interaction design more playful and enjoyable, and further help users leverage real-world knowledge in performing the proposed interactions <ref type="bibr" target="#b0">[1]</ref>.</p><p>At the same time, researchers in the visualization community have also used natural interactions with the paper to create more effective ways to interact with visualizations. For example, papers can be utilized as an extra layer on top of a tabletop to interactively display more information <ref type="bibr" target="#b46">[47,</ref><ref type="bibr" target="#b67">68]</ref>, while Bach et al. <ref type="bibr" target="#b5">[6]</ref> used paper cardboard to interact with three-dimensional holograms. Spindler et al. <ref type="bibr" target="#b67">[68]</ref> further summarized a set of interaction vocabularies for tangible views, such as translation and rotation. Besides using the paper as a planar, paper could also be used as a prop to interact with 3D visualization of thin fiber structures <ref type="bibr" target="#b43">[44]</ref> and a printed wheel chart to interact with volume visualization <ref type="bibr" target="#b70">[71]</ref>. Moreover, these paper interactions and their metaphors (e.g., piling and folding) are heavily used in the traditional desktop and mobile environment for data visualization tasks, such as comparison <ref type="bibr" target="#b76">[77]</ref>, navigation <ref type="bibr" target="#b30">[31]</ref>, organization <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b53">54]</ref>, coordination <ref type="bibr" target="#b50">[51]</ref>, and set operations <ref type="bibr" target="#b59">[60]</ref>. Different from utilizing paper interactions as metaphors in the desktop environment, we explore the possibility of using paper as a touch, tangible, and spatial interface for people to interact with digital data intuitively and engagingly in the physical world through AR. We construct a design space to provide designers with a structured way to design systems using paper interactions as well as designing further paper interactions. Visualization Task Taxonomies. Many works have summarized data exploration tasks as high-level tasks <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b49">50,</ref><ref type="bibr" target="#b54">55]</ref> and low-level tasks <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b37">38,</ref><ref type="bibr" target="#b82">83]</ref>. High-level tasks, such as identify, compare, or summarize, describe why users interact with a visualization <ref type="bibr" target="#b14">[15]</ref>. Since low-level tasks are building blocks for high-level tasks <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b37">38,</ref><ref type="bibr" target="#b82">83]</ref>, we focus on how paper interactions support low-level tasks. Yi et al. <ref type="bibr" target="#b82">[83]</ref> proposed a set of seven low-level tasks, for instance, select, filter, and connect. Later, Heer and Shneiderman <ref type="bibr" target="#b37">[38]</ref> further suggested twelve low-level tasks for data &amp; view specification (i.e., visualize, filter, sort, and derive), view manipulation (i.e., select, navigate, coordinate, and organize), and analysis process (record, annotate, share, and guide). Besides, Brehmer and Munzner <ref type="bibr" target="#b14">[15]</ref> added change to the low-level tasks.</p><p>However, these tasks are mainly explored and summarized in the desktop environment and thus actions beyond the use of the mouse and keyboard are seldom discussed <ref type="bibr" target="#b29">[30,</ref><ref type="bibr" target="#b45">46,</ref><ref type="bibr" target="#b51">52]</ref>. Our work utilizes the existing low-level tasks as an initial set of commands to explore how actions on paper sheets can be used to execute these commands.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">SOLICITING INTERACTIONS</head><p>To understand the potential of using paper as an interaction medium for data exploration, we conducted an ideation study. Based on the existing literature survey as mentioned in Section 2, we start exploring possible interactions with paper actions: hold, collocate, collate, flip, rub, staple, point, and two-handed pointing <ref type="bibr" target="#b39">[40]</ref>, and data visualization commands: visualize, filter, sort, derive, select, navigate, coordinate, organize, and change <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b37">38]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Ideation Workshop</head><p>Participants: We invited 20 researchers (one Associate Professor, two Postdoctoral fellows, and 17 Ph.D. students, aged between 22 and 30; 15 males and 5 females) 14 participants came from the same research lab as the first author, four participants joined from other research labs in the same university, and two from other universities. We selected participants with VIS or HCI backgrounds to provide more detailed ideas and start brainstorming in a shorter time due to familiarity with visualization and interaction design <ref type="bibr" target="#b15">[16]</ref>. Setup and Materials: To encourage participants to brainstorm more creative ideas (other than familiar point-related gestures), we divided participants into groups of four and across five sessions, inspired by the partners technique <ref type="bibr" target="#b57">[58]</ref>. We constructed five basic charts (bar chart, pie chart, line chart, scatter chart, and choropleth map) with a Covid-19 dataset (ending on January 17 th of 2021) from data repository 1 (containing two-dimensional data, temporal data, and spatial data) to cover the common visualizations and data types encountered in daily life. Since paper action techniques can involve multiple papers/visualizations with the same chart type (e.g., stacking one bar chart on another bar chart), we provided participants two sets of five charts with the confirmed and recovery datasets of Covid-19 cases. Moreover, since the size of the visualization may affect the paper action, we printed two versions of each chart: A4 width and half-A4 width. In total, each participant received 1 https://github.com/CSSEGISandData/COVID-19/ 20 (5 × 2 × 2) charts. Due to the Covid-19 pandemic, all sessions were hosted on Zoom. Participants were asked to print out these materials before the sessions. Each participant received $10 for compensation.</p><p>Procedure: Each session lasted about 90 minutes, consisting of three parts: introduction (15 mins), individual brainstorming (20 mins), and group discussion (55 mins). In the introduction, we first briefly introduced the project background and the workshop's goal. To encourage participants to produce diversified ideas on interactions, we provided two demonstrations created by the authors (flipping a sheet of paper to trigger filtering, and collating two papers to combine two bar charts into one grouped bar chart), inspired by the priming technique <ref type="bibr" target="#b57">[58]</ref>. Then, we gave participants a task and asked them to spend 20 minutes brainstorming the commands they would like to perform on the printed visualizations and how they would achieve these commands by interacting with the paper. The task description was Given static Covid-19 figures from a report, what do you want to know more about from the visualizations printed on paper and how will you interact with them?. To accelerate and encourage participants to brainstorm novel ideas, we provided the initial set of commands and paper actions (we excluded point-related gestures like pointing and two-handed pointing for more diverse ideas) as prompts, adapted from <ref type="bibr" target="#b15">[16]</ref>. We also encouraged participants to generate ideas beyond the actions mentioned in the list. Participants were then asked to write down their thoughts without considering any technological restrictions and send them to the host. The host then organized all ideas in a Google Doc for later group discussion. After the individual brainstorming step, each participant shared and demonstrated their ideas to the group. The group then discussed the ideas and brainstormed more ideas (i.e., build upon each other's ideas) and usage scenarios based on these individual ideas in the Google Doc for 55 minutes. As we were interested in collecting a wide variety of ideas for our design space, we did not seek a consensus for a single "ideal" mapping between action and command at the end of each session. All sessions were recorded.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Data Analysis Procedure</head><p>In total, we have gathered 146 ideas from both individual brainstorming and group discussions in all sessions. To extract interactions from these ideas, we performed the following analysis procedures (illustrated in Fig. <ref type="figure" target="#fig_0">2</ref>). First, the lead author extracted statements involving tasks and paper actions from the ideas and broke down statements into multiple single action and task mappings if necessary. Next, two authors independently coded the type of commands and actions for the mappings in the first two sessions according to the initial set of data visualization commands <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b37">38]</ref> and paper actions <ref type="bibr" target="#b39">[40,</ref><ref type="bibr" target="#b67">68]</ref>. For the commands and paper actions that did not fit into the existing taxonomy, the same two authors independently open-coded them and discussed their definitions. For example, participants offered the ideas of folding and tearing the paper, which were not in the initial set of paper actions. The same two authors iteratively discussed and refined the coding scheme until reaching a Cohen's κ <ref type="bibr" target="#b23">[24]</ref> above 0.7 for all classes of actions and commands. The lead author then coded the rest of the sessions. For each command category, the lead author further grouped commands with similar meanings (e.g., "select a country (from a map)" and "select a timestamp (from a line chart)" are grouped to "select single mark"). Finally, we had summarized 81 unique interactions. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">DESIGN SPACE</head><p>By analyzing the interactions resulting from the ideation workshop, we constructed a design space to facilitate the organization and creation of paper actions for data exploration in the future. The design space contains three dimensions: Commands, Degree of Information, and Number of Paper Sheets Involved.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Dimension I: Commands</head><p>Dimension I, Commands, describes the low-level tasks <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b37">38,</ref><ref type="bibr" target="#b68">69]</ref> on data visualizations. We listed out all 10 commands found in the workshop as follows. First, participants wanted to filter and select data points in the visualizations. To access more details, participants intended to navigate (e.g., zoom, pan, and show tooltip) into different charts and derive statistical calculations, like mean, min, and max. They might also change the chart type for different insights or update the dataset for the latest information. For visual comparison, participants wished to sort the data to rearrange the visual marks and organize the visualizations in juxtaposition or superimposition. Furthermore, participants wanted to coordinate different charts to expand their exploration. For example, one participant wanted "the information related to this country to be highlighted in another paper (visualization) when one of them is selected." Lastly, participants proposed to reset the charts or undo some comments (by traversing recorded states) to prepare another round of data exploration.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Dimension II: Degree of Information</head><p>Dimension II, Degree of Information (DoI), is inspired by the notion of degree of freedom in HCI. This dimension describes the number of parameters an action can provide as well as the possible information. Only paper actions that provide a matching DoI can support a given target data visualization command. For example, we can point at the visualization to select a data point because the point action provides the positional information for the system to select the data point in the specified location. However, we cannot shake the paper to select a data point because shaking cannot provide the positional information. Shaking the paper can only trigger a predefined selection. We analyzed the DoI of each action found in the workshop and identified four kinds of DoI, namely, boolean, position/area, direction+value, and free expression. We then used these four kinds of DoI to organize the 18 actions found in the workshop (paper actions with an asterisk indicate actions not presented in previous works <ref type="bibr" target="#b39">[40,</ref><ref type="bibr" target="#b67">68]</ref>):</p><p>Boolean actions provide a yes/no state.</p><p>Shake: Move the paper up and down or from side to side forcefully, jerkily, and rapidly. Shake provides a boolean informationwhether the paper is being shook or not. For simplicity, this will involve some sort of threshold.</p><p>Hold: Pick up a piece of paper to the mid-air. Hold provides a boolean information-whether the paper is being held or lies flat on a surface.</p><p>Pin*: Anchor the visualization to its current position with the pin hand gesture, similar to fixing a paper on a board using a push pin. Pin provides a boolean information-the paper is being pinned, or not.</p><p>Staple: Place the papers face to face to mimic the metallic staple effect. Staple provides a boolean information-whether papers are being stapled together or not.</p><p>Position/Area actions provide the x, y, z value and possibly an area.</p><p>Cover*: Put a hand on the paper to block part of the view. Cover provides the position and the area covered by the hand. Toolbox: Utilize other papers with different shapes, colors, and text annotations as interactive widgets (e.g., buttons, menus, and sliders) for user input. Depending on the design of the paper widget, a toolbox can provide any expression to manipulate the visualization.</p><p>Sketch: Use a pen or digital pen to write or draw on the paper. Depending on the predefined commands, free-form sketching or writing can provide any expression to interact with the visualization.</p><p>Note that this analysis is capturing only those mappings discussed in the workshop. For example, there could potentially be a multitude of ways to shake a paper, e.g., shake vertically, shake horizontally, shake multiple times. Our design space aims at a first overview of possible and feasible interactions and thus these variations are not considered.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Dimension III: Number of Paper Sheets Involved</head><p>Dimension III, Number of Paper Sheets Involved, describes the number of papers involved in the paper action. Paper actions involving one paper target at single view manipulation, while paper actions involving multiple papers supports multiview manipulation and analysis. Single paper. There are 15 actions (as shown in Fig. <ref type="figure" target="#fig_1">3</ref>) found to involve one piece of paper in the workshop. For example, participants pointed at one paper and folded one paper. Multiple papers. Three actions (i.e., collate, collocate, and staple) were found to involve two or more pieces of paper. These actions allow users to organize multiple sheets of paper into different layouts or use visualization as an object to interact with other visualizations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Supporting Commands through Paper Actions</head><p>Based on the design space, we describe the collected interactions from the workshop as shown in Fig. <ref type="figure" target="#fig_1">3</ref>. The figure shows interactions involving one paper sheet (left) and multiple paper sheets (right). In each sub-table, we have DoI (with the corresponding paper actions) listed horizontally and data visualization commands listed vertically. Each item in a cell represents one or more interactions grouped by the commands. For example, indicates two interactions: point⇒filter-single-mark, and rub⇒filter-single-mark. Other combinations (e.g., translate⇒select-single-mark) that had no practical solutions proposed in the workshop, we have left blank. Below, we explain the details of the design space organized by DoI. Boolean interactions (14/81) are mainly used as a trigger to activate or deactivate commands. For example, it could be used as shake⇒triggerfilter (</p><p>) or shake⇒reset (Fig. <ref type="figure" target="#fig_3">4(a)</ref>). Moreover, we can trigger commands (e.g., derive) with multiview by stapling paper sheets. The number of Boolean interactions is low, probably because the expressiveness (ability to convey users' intentions to the of these interactions is low. Position/Area interactions (33/81) allow users to directly communicate with specific visualization components of the visualization since it provides position data for the system to locate visual elements, i.e., x and y location. In addition to triggering the filter command in the Boolean interaction, users can now specify the visual mark to be filtered out by pointing or rubbing (</p><p>). Figure <ref type="figure" target="#fig_3">4</ref>(b) illustrates that users filter a bar on a printed visualization using the rubbing gesture. Moreover, by involving multiple papers, multiple visualizations can be coordinated using their spatial relationship for more complex multivariate data exploration. There are 12/33 interactions involving multiple papers to perform navigation, coordination, and organization. For example, as shown in Fig. <ref type="figure" target="#fig_3">4(c)</ref>, users can overlay one paper over the other one to pick a specific timestamp from the bottom visualization and update both visualizations (</p><p>). Direction+Value interactions (25/81) provide more information than the position. They allow users to perform commands that require directional information such as sorting in ascending or descending order by rotating, tilting, flipping, or dragging ( ) as shown in Fig. <ref type="figure" target="#fig_3">4(d)</ref>. Moreover, direction+value interactions can also be transformed into area information. For example, users can fold the paper in x or y direction to select or filter an area of visual marks covered by the folded part of the paper. Some of the interactions, such as tilt⇒pan and translate⇒zoom, have previously been proposed for mobile devices <ref type="bibr" target="#b66">[67]</ref> or tabletop paper lens <ref type="bibr" target="#b67">[68]</ref>. Free expression interactions (8/81) can deal with more complex command that are derived and encoded by utilizing extra objects, i.e., pen or customized toolbox. With their expressive power, these interactions can support advanced filtering, querying, or calculation, such as directly picking the elements with the minimum value using a circle shaped representing a min command ( , Fig. <ref type="figure" target="#fig_3">4(e)</ref>). Overall, our design space provides designers with a structured way to design paper interactions on printed visualizations. It provides an overview over the feasibility of the interactions. For example, we cannot have shake⇒select-single-mark as the shake action only provides a Boolean input to the selection command. Designers can look up Position/Area interactions to choose an action for the selection command.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">USER STUDY</head><p>Our design space helps designers to design feasible paper interactions for data visualization. Apart from the design insights, we want to further investigate paper interactions' functionality in real practice.</p><p>Table <ref type="table">1</ref>. Interactions implemented in this study with their names and a brief description.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Commands Actions Description</head><p>Select  Thus, we conducted a controlled user study with a proof-of-concept prototype to investigate user preferences (G-Preferences) and practical viability (G-Viability) of the interactions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Prototype</head><p>We simplify our study by focusing on those commands used for view manipulation as described by Heer and Shneiderman <ref type="bibr" target="#b37">[38]</ref>. We implemented the 11 interactions listed in Table <ref type="table">1</ref>. An example of using fold⇒zoom can be found in Fig. <ref type="figure" target="#fig_7">7</ref>. We built the experimental prototype using a client-server model with a WebSocket for the network communication as shown in Fig. <ref type="figure" target="#fig_5">5</ref>.</p><p>• The client app runs on the Hololens 2 to detect users' hand gestures and papers' status. The newer HoloLens 2 provides a diagonal 52 • field of view and two-handed fully articulated hand tracking. Handpose data was collected through Microsoft's Mixed Reality Toolkit on HoloLens 2. For pose tracking of printed visualizations, we used Vuforia image tracking. Rich feature patterns were added on all sides of the paper for more accurate tracking. Depending on the relative position and direction of fingers and paper sheets, different paper actions and gestures are recognized as action events (Table <ref type="table">1</ref>). For example, when two sheets were placed close together, a collocate action event was created (Fig. <ref type="figure">1(e)</ref>). After observing the events, the client app sends these events to the server. • The server receives the paper action events with their parameters (e.g., positions in the case of a Position/Area action) and updates the visualization through a corresponding command. We maintain a Vega <ref type="bibr" target="#b62">[63]</ref> specification for each visualization on the server. The updated visualization is returned to the client. • The configuration website with dropdown menus allows the conductor to change the selected interactions based on the task and participants' needs (Fig. <ref type="figure" target="#fig_6">6</ref>(c)). The configuration is updated to the server and the effect is immediately reflected in the client app.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Setup and Participants</head><p>We recruited 12 university students (P1-P12; aged between 22 and 30; 6 males and 6 females). None of them had participated in the ideation workshop. The distribution of their visual analysis experience was "none" (3), "novice" (5), "knowledgeable" (4), and "expert" (0). The distribution of their AR experience was "none" (2), "novice" (9), "knowledgeable" (1), and "expert" (0). The distribution of their daily paper usage was "0 day per week" (1), "1-2 days per week" (2), "3-6 days per week" (1), and "every day" <ref type="bibr" target="#b7">(8)</ref>. Overall, participants are mainly novices in both visual analysis and AR, and daily paper users. All sessions were recorded using a mobile phone, as shown in Fig. <ref type="figure" target="#fig_6">6(b)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Procedure</head><p>The study consisted of an introduction, two tasks, and a semi-structured interview. Each participant received $13-$17 as compensation according to a 90-120 minute study time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Introduction (∼10 mins).</head><p>We first introduced the study background and procedure, and then asked participants to sign the consent form.</p><p>After that, participants were asked to put on the AR HMD and adjust the device until they felt comfortable and could see the AR content attached to the printed visualization clearly.</p><p>Task 1: Unit Evaluation (∼60 mins). To assess G-Preferences for each interaction, we asked participants to perform all 11 interactions on a set of printed visualizations showing the latest Covid-19 dataset (e.g., a scatter plot with total confirmed cases against total recovered cases, Fig. <ref type="figure" target="#fig_7">7</ref>) , the source of which was the same as the workshop. We counterbalanced the sequence of data visualization commands and also Fig. <ref type="figure">8</ref>. This figure shows participants' ratings on "intuitiveness", "comfort", "engagement", and "overall preference" for each interactions in task 1.</p><p>the sequence of actions per command using the balanced Latin Square method <ref type="bibr" target="#b13">[14]</ref>. For each command, we first introduced the task to the participants and then the participants started to try each interaction with the procedure below:</p><p>1. The study conductor demonstrated the interaction to the participant. 2. The participant performed the interaction five or more times successfully. 3. The participant rated the interaction on metrics widely adopted in previous research on interactions in AR, i.e., intuitiveness, comfort, engagement, and overall preference <ref type="bibr" target="#b60">[61]</ref>, by filling in a questionnaire. (To get ratings independently and not implementation specific, participants were told that it was not necessary to compare it with other presented interactions, and it was assumed that the HoloLens 2 worked without technical issues <ref type="bibr" target="#b36">[37]</ref>.) 4. A series of follow-up questions were asked to obtain further comments and in-depth rationales for the ratings. After Task 1, participants were asked if they had any discomfort. A five-minute break was given based on the participants' needs.</p><p>Task 2: Free-Form Exploration (∼15 mins). For G-Viability (whether people can use and how they use interactions), we asked participants to use the above-mentioned interactions to answer a question and explore the data freely within the given 15 minutes time frame. We introduced a set of five visualizations (two visualizations are shown in Fig. <ref type="figure">1</ref>) on a different dataset from Task 1 (i.e., worldwide university rankings in 2016) to reduce the effect of memorizing the dataset from Task 1. To initialize a set of interactions for participants to perform the Task 2 as the initial setting for free exploration, we picked those interactions with the highest preference for each command from Task 1. For interactions with the same preference rating, we let the participants choose the interaction. In addition, participants were encouraged to tell us when they want to change and explore different interaction mappings, e.g., changing pinch⇒zoom to translate⇒zoom), and then we change the setting for them. To kick-start exploration, we asked participants to answer the following question: "Given the line chart, what is the trend of MIT's total score from 2011 to 2016?". Participants were required to zoom (select, and pan if necessary) since the line chart was complex and cluttered at times, as shown Fig. <ref type="figure">1(b</ref>). After answering this question, participants could use the remaining time to explore on the five visualizations freely. During free exploration, participants were asked to think aloud about what they were doing and how they planned to perform an interaction. Post-Study Interview (∼15 mins). We conducted a semi-structured interview with nine questions in three topics: preference, usefulness, and possible new interaction, at the end of the study.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Results</head><p>We report on participants' quantitative ratings and verbal feedback for the interactions from both tasks as well as the semi-structured interview in the user study. Overally, with respect to G-Preferences, we found that participants rated the proposed interactions intuitive and engaging to use. With respect to G-Viability, they enjoyed interacting with the printed visualizations using paper actions with different affordances.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Preference and feedback for interactions</head><p>Figure <ref type="figure">8</ref> shows the ratings of 12 participants on intuitiveness, comfort, engagement, and overall preference across all interactions for each data visualization command. Overall, participants were positive for most of the interactions from each dimension. Below we present the users' preferences and feedback grouped by the interaction commands. The number inside the brackets indicates the median of the ratings. Select-an-interval. In this task, participants were asked to select a range of bars in a given bar chart. Participants preferred the point&amp;drag action the most (4.5). They explained that point&amp;drag was very intuitive (5) as it was "similar to their current practise [, i.e.,] clicking on desktops" and "touching on tablets". Participants also preferred cover (4), reporting this action to be natural and easy to perform (intuitiveness: (4)). P1 and P9 found themselves engaged and immersed in the data when performing cover. P1 said "it [cover] is fun because I feel involved in the virtual world." P9 commented that "it [cover] is just like communicating with data using body language."</p><p>Participants rated fold rather neutral (3) because of less comfort (2.5). Reasons reported included that folding damages the paper (P4, P5, P8) and requires extra effort (P2, P3, P4, P12). P4 further commented that both hands would be required to perform the action: "it is troublesome for me to use both hands to interact with the paper." Participants added that they were "sometimes lazy".</p><p>Zoom. Participants were asked to zoom in and out the given scatterplot to get an overview or obtain detailed information about the data. The two most preferred actions were pinch (4) and translate (4). One reason was that both actions are intuitive (pinch: <ref type="bibr" target="#b4">(5)</ref>, and translate: (5)). Participants reported again that these actions were natural and similar to daily practice. "I think everyone [who uses smartphones or tablets] is used to pinch," P8 said. For translating papers, P1 said "I do this in the real world when I want to see something larger on paper." P7 found that fold⇒zoom had a unique advantage in terms of preciseness and preferred using it because it allowed for "controlling the exact amount of zoom in." Pan. Participants were asked to pan a given scatterplot in different directions. Overall, point&amp;drag was again strongly preferred (4.5) because of participants' familiarity with actions on touchscreen (intuitiveness: ( <ref type="formula">5</ref>)). It is exciting that both tilt (4.5) and flip (4) were also highly ranked. P1 emphasized that "flip [to pan] is surprisingly easy to understand. It's like there is a bigger visualization behind." Tilt was ranked intuitive (4.5) and engaging <ref type="bibr" target="#b4">(5)</ref>, reporting this action to be natural and playful to perform the pan command, as well as "similar to a waterfall" (P2, P8), "playing games" (P2, P3), and "driving" (P1). Link&amp;Select. Participants were asked to first select countries from a bar chart by selecting a continent in a pie chart (Fig. <ref type="figure" target="#fig_3">4</ref>(f)) and then select a time in a timeline to show different data in the pie chart about that specified time (Fig. <ref type="figure" target="#fig_3">4(c)</ref>). Collocate&amp;point was strongly preferred (4.5) due to its naturalness and strong familiarity of selection by "touching" <ref type="bibr" target="#b4">(5)</ref>. Collate was less preferred (3.5) because of occlusion (P1-5, P7, P8, and P11). However, half of the participants (P1-3, P5, P8, and P12) appreciated collate for revealing temporal changes. They described collate as novel and engaging and that they could easily focus the changes at the top visualization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Practical Viability and Observation</head><p>All participants could complete the question and explore the data in Task 2. During exploration, there are four participants (P3, P5, P6 and P12) changed the interactions. Two participants (P5 and P12) had switched from pinch⇒zoom to fold⇒zoom when answering the question. While they first used pinch⇒zoom and further point&amp;drag⇒pan to the cluttered lines, it required several trials of zoom and pan to observe the trend, which was tedious. Thus, they tried using fold⇒zoom because they noticed that folding the paper might possibly zoom in to that specific area easier. Moreover, P6 and P3 found alternatives to point actions. P6 has switched collocate&amp;point⇒link&amp;select to collate⇒link&amp;select for more accurate selection and P3 had changed point&amp;drag⇒pan to tilt⇒pan for the free exploration in the remaining time. P3 commented that "it <ref type="bibr">[tilt]</ref> is much easier to perform than dragging when the hand tracking is not working well."</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Users' attitudes and reactions</head><p>All participants enjoyed interacting with the printed visualizations using paper actions and looked forward to the complete prototype system. As key strengths for data exploration participants reported that paper interactions "increase the capability of static visualizations" (5/12 participants) and were generally "convenient" (4/12 participants). For example, P3 commented that "direct interacting with papers is more convenient than using PC for data exploration." Yet, the key weaknesses were reported to be "the durability of the paper" (4/12 participants) and "ergonomic issues brought by the HMD" (4/12 participants). Overall, all participants stated that they would use these interactions for data analysis in other contexts. Five participants would have liked to perform multiview analyses on experiment reports and academic papers. Seven participants envisioned that paper interactions could be used in presentations to interact with data directly on the printed reports. Moreover, four participants can see paper interactions being used in education due to the interactions engagingness. For instance, P10 stated "It would be great if students could interact with the map directly to learn about geography." Furthermore, due to the ubiquity of paper and the ease of deploying interactions, three participants imagined using it inside shopping malls and exhibitions to interact with the materials (e.g., leaflets) received. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">DESIGN IMPLICATIONS</head><p>Based on the results and observations in the study, we derived six design implications (i.e., I1-I6) for future designs and studies. I1. Provide Redundant Actions to Point. Due to the limited accuracy of fingertip detection using only computer vision algorithms, we suggest designers provide redundant actions, such as cover, tilt, and translate, to point for selecting an interval, panning, and zooming, respectively. Although point-related paper actions are the most preferred paper actions for all commands presented in the study, it is still challenging to provide a good and precise pointing experience similar to touchscreen due to the limitations of fingertip tracking with occluded and fast-moving fingers <ref type="bibr" target="#b7">[8]</ref> and depth estimation with deformable papers. In addition, imprecise pointing required participants to increase their fingers' movement when they conducted data exploration using pointing gestures. Moreover, the study from Spindler et al. <ref type="bibr" target="#b66">[67]</ref> showed that the task completion time of spatial input (i.e., 3D translation) for 2D document navigation on mobile phones was faster than conventional point-based input. As a result, we suggest that designers use cover, translate, and tilt to complement pointing in range selection, zoom, and pan, respectively, with more accurate detection and similar high scores for intuitiveness, comfort, and engagement. I2. Make Use of Different Actions for Command Shortcuts. Paper actions can be utilized as shortcuts to save users' efforts. Paper sheets can provide additional actions (e.g., flip and fold) compared to the mouse, touchscreen, and keyboard (i.e., click, touch, and keypress). We can utilize some of the proposed interactions (i.e., fold⇒zoom, flip⇒pan, and collate⇒link&amp;select) that provide unique advantages as shortcuts. For flip⇒pan, participants agreed on its intuitiveness and showed its strength in panning a long distance, which can relieve users from pointing and dragging multiple times and tilting for a long time. Furthermore, fold⇒zoom is beneficial when dealing with skewed data distribution (i.e., dense points in the corner in the visualization). Lastly, users are engaged to use collate⇒link&amp;select to quickly link two visualizations and make a selection simultaneously to focus on the temporal changes of the visualization on the top without context switching compared with collocate&amp;point⇒link&amp;select. I3. Support both Selection and Inverse Selection for Cover. Our study suggests supporting cover⇒select-an-interval for both selection and inverse selection. Cover an area can be treated as selecting wanted data or excluding unwanted data, as shown in Fig. <ref type="figure" target="#fig_8">9</ref>. In the user study, while it is easy to use the cover gesture to hide a small set of outliers and focus on the main area of the data, it becomes difficult to cover a large portion of the visualization to select a small amount of uncovered data. This trade-off has also been stated in <ref type="bibr" target="#b74">[75]</ref>. As a result, designers can provide both selection and inverse selection by using different gestures, such as palm up and palm down. I4. Utilize the Semantic Meaning of Paper Actions. Designers should consider the semantic meaning of the paper action to increase the intuitiveness when designing new interaction. Although paper actions within the same DoI could be used for a command, they provide different semantic meanings related to day-to-day usages of papers. For example, participants in the workshop preferred rubbing as a filtering action (as a rubber) or a revealing action (as a cleaner). Rotation-based actions, i.e., tilt and rotate, correlate physics-based metaphor, such as gravity. Moreover, moving a paper sheet back and forth has implicitly provided a zooming metaphor. As such, translate⇒zoom and tilt⇒pan provide strong semantic meaning and support a strong mental model <ref type="bibr" target="#b44">[45,</ref><ref type="bibr" target="#b58">59]</ref>, thus getting high ratings in intuitiveness.</p><p>I5. Intuitiveness of Actions vs. Readability of Text. Designers need to consider the trade-off between the intuitiveness of the paper action and the readability of the digital visualization. Users need to read both the text and the visual marks on the visualization for value retrieval and pattern recognition. Therefore, ensuring text readability is essential for designing interactions. In the study, some interactions are intuitive and engaging. However, they may not be optimal for readability. For example, tilt⇒pan causes the text to be hard to read because the text is tilted. Thus, designers might consider ensuring readability when using actions that involve movements on paper, such as tilting and translating. One possible solution is to fix some visualization components in place, such as the title, axis, and legend, while translating and tilting. While the text is fixed at a certain distance for reading, the visual pattern could follow the movement for intuitiveness and engagement. This implication could value beyond the domain of visualization to general physical documents. I6. Effects of Paper's Physical Properties on Actions. Visualizations can be printed on, e.g., books, A4-sized leaflets, and small paper cards. During the investigation of paper actions for data exploration, we found that the physical properties (e.g., size, weight, thickness, and physical constraints) could affect the usage of interactions. First, people prefer large-sized papers to perform actions with large movements or high precision. Participants in the ideation workshop preferred to interact with visualizations on a larger paper size because they can perform actions requiring large movements easier, such as folding. On the other hand, it becomes hard to select a large area with cover⇒select-aninterval if the size of the paper is too large. Second, the weight of the paper used should be light, so that none of the participants reported that interacting with the paper for about an hour was tiring. Furthermore, participants can easily pick up the paper sheet for a better angle to view the visualization. Third, the thickness affects the use of paper action. In the user study, we used standard office paper, which is thin. While participants can easily fold the papers, it is hard to perform point-related gestures, as the thin paper cannot support the force given by the participants' fingers. Media like paper cards may provide an ideal experience for these actions. Fourth, designers should consider the paper format. Paper actions (i.e., fold, collocate, collate, flip, and staple) are constrained if papers are bounded together. For example, participants can only fold one side of the paper and cannot perform multi-paper actions if papers are bounded as books and magazines. These findings might still be valid outside the field of visualization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">DISCUSSION</head><p>Paper Interaction Design Space. Our design space captures actions and their mappings to commands. It shows the mappings we have investigated in this study while leaving the possibility and feasibility of other mappings to future work. The design space and our findings can help choosing mappings for real-life systems. It shows that for some combinations of actions and commands, multiple options exist. Specifically, our design space and study help making more informed decisions for creating systems based on paper interactions. For example, participants in our study preferred point-based gestures or spatial paper actions (e.g., tilting, translating) over folding. Designers should also consider redundant actions for the same command, especially when a command requires different levels of granularity. For example, tilt could be used for fine-grained panning, while flip could be used to quickly pan over large distances. Possible usage scenarios. Our study demonstrates that interacting with printed visualizations is fun and practically viable. We envision five application opportunities for applying paper interactions with data analysis: (1) education: we can add interactivity to paper sheets that could benefit classroom teaching that are still common to use paper and data visualization, such as teaching data visualization <ref type="bibr" target="#b6">[7]</ref>, geography (e.g., printed maps), chemistry (e.g., printed experiment results), and math (printed or hand drawn plots); (2) brainstorming sessions: UX designers may consider making use of different types of papers for different tasks. In addition to qualitative data analysis with printed reports, sticky note is a common tool for supporting brainstorming <ref type="bibr" target="#b73">[74]</ref>. Sup-porting interactions directly on papers can reduce the context switching between the desktop visual analytics tools and sticky notes <ref type="bibr" target="#b72">[73]</ref>; (3) exhibitions/presentations: audiences could directly interact with paper handouts (e.g., worksheets, leaflets, and pamphlets; as shown in Fig. <ref type="figure">1</ref>) provided without switching back and forth between mobile phones and handouts to seek more information during visiting an exhibition and attending a presentation. (4) collaboration: with intuitive paper actions, people could quickly explore the data printed on the paper sheets, which can support short analytical sprints. It helps enhancing collaboration between diverse domains <ref type="bibr" target="#b34">[35]</ref>. (5) AR-based authoring tools for interactive visualization: current AR-based authoring tools <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b64">65]</ref> only support minimal or even no interaction configuration, which hinders users to interact with the created visualization. Our paper interaction design space could help developers and researchers to further extend their tools to support feasible paper interactions for interactive AR visualizations. Study Limitations. Despite our best effort, this study has some limitations to be aware of. First, our investigation was mainly based on the workshop's outcomes and unable to investigate all possible designs conclusively and exhaustively. Second, AR technology is still premature. For example, the inaccurate detection of fingers and paper hindered the user experience; blurry text, due to the fixed focal length of HoloLens 2, caused eye fatigue and strain (reported by half of the participants). Furthermore, as an exploratory study, we have implemented a subset of 11 interactions with two paper-specific actions (i.e., cover and fold) to complete simple tasks. The sample of the user study is also small and did not consider the analytic benefits of interactions. However, our design space with 81 interactions, our grouping of paper actions and commands, as well as our study results provide a good framework for a more systematic exploration of paper interactions in the future. Future Work. More studies could be done to expand the design space for the analysis process &amp; provenance <ref type="bibr" target="#b37">[38]</ref>. The prototype could also be extended to conduct more studies for assessing other aspects (e.g., task accuracy and completion time for analytic benefits and memory test for intuition), as well as complex tasks for authoring visualizations and immersive collaborative analysis <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b34">35]</ref>. It could further include more paper-specific actions to support more commands, such as dogearing⇒pin-view. Furthermore, artificial intelligence could be introduced to facilitate better interaction support in AR <ref type="bibr" target="#b78">[79,</ref><ref type="bibr" target="#b79">80]</ref>, and better paper detection and finger detection with depth cameras and extra sensors. Last but not least, it is interesting to explore the possibility of using paper action as metaphors for intuitive gesture design in the air (without actually interacting with physical papers) to interact with data visualizations in virtual reality (VR) <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b81">82]</ref>. Although the haptic feedback might be lost, there are more design choices when deploying paper interactions without the physical paper. For instance, undoing a tearing action on a virtual paper sheet is possible in VR.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">CONCLUSION</head><p>This paper explores the use of paper sheets as a new means for interaction with data visualization. We first conducted an ideation workshop with 20 VIS and HCI researchers to solicit 81 interactions. Furthermore, we construct a three-dimensional design space (i.e., Commands, Degree of Information and Number of Paper Sheets Involved) to describe and create possible interactions and verify the feasibility of interactions. Lastly, we built a proof-of-concept prototype and conducted a user study with 12 participants to provide initial insights by evaluating 11 interactions. Our findings show that all participants considered these interactions intuitive and engaging. Based on the findings, we developed six design implications. We found strong affordances for some interactions, physical limitations and properties of paper as a medium, cases requiring redundancy and shortcuts, and other implications for design. We hope that our work can inspire future work on developing interactions for data exploration more intuitively and engagingly.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. This figure illustrates the analysis procedure of the ideas collected from the workshop.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Interactions are summarized using the proposed design space. Sub-tables show interactions involving a single paper (left) and multiple papers (right): paper actions grouped by information provided (horizontally) and data visualization commands (vertically). In each cell, we presented the interactions found in the workshop. Interactions highlighted using red dashed rectangles are what we have implemented for the user study.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Point:</head><label></label><figDesc>Use a finger to point on the paper. Point provides the x, y coordinate of the intended position of the visualization. Rub: Point on the paper and move the finger back and forth on the paper quickly and repeatedly. Similar to point, rub provides the x, y coordinate of the intended position of the visualization. Collate: Stack multiple papers together. Collate provides the relative position of the upper visualization to the bottom visualization. Collocate: Organize multiple pieces of paper side-by-side. Collocate provides the relative positions of other papers. Direction+value actions provide a direction and a value. Flip: Turn the paper's front side back or the back side front. Flipping along different edges of the paper provides the direction information and the current state of the paper-facing up or down. Tilt: Slant the view plane to a different angle than its normal viewing position. Tilting vertically and horizontally provides different direction information, and the tilt angle provides the value. Rotate: Reorient the paper to a different angle. Similar to tilt, rotate provides the direction of rotation and the rotation degree. Fold (bend)*: Fold or bend a piece of paper over to cover other parts of itself. Fold/bend provides the folding/bending direction and the portion of the cover. Translate: Move the paper up and down, left and right, also close or far from the eyes. Translate provides the direction and magnitude of the movement. Split (Tear/Cut)*: Tear or cut the paper into two parts, splitting up the content. Tear/Cut provides the tearing/cutting direction and the size of the resulting parts. Point&amp;drag: Point and drag one or multiple fingers on the paper, such as drag and pinch gestures. Point and drag utilizes time to create the direction and moving distance. Free expression paper actions can provide an expression beyond numerical values.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Illustrations of interaction examples. (a) -(e) cover examples in each DoI category. (a) shows a boolean interaction, (b) and (c) show a position interaction and a multiview position interaction, (d) shows a direction+value interaction , and (e) shows a free expression interaction. (f) shows a combination of two interactions to link and select.</figDesc><graphic url="image-128.png" coords="5,325.33,72.99,207.87,85.73" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>-an-interval Point&amp;Drag Swipe the finger on the paper sheet =⇒ select the data points in the range of the axis brushed Cover Cover part of the visualization with flat hand =⇒ select the data points NOT in the range of the axis covered Fold Fold the paper to cover a large (or small) portion of the axis =⇒ select the data points NOT in the range of the axis covered Zoom Pinch Two-finger pinch outward (or inward) on the visualization =⇒ zoom-in (or zoom-out) of the visualization Translate Move the paper closer to (or farther from) the camera =⇒ zoom-in (or zoom-out) of the visualization Fold Fold the paper to cover a large (or small) portion of the axis =⇒ zoom-in (or zoom-out) to the portion of visualization NOT covered Pan Point&amp;Drag Finger scroll left (right, up, or down) on the visualization =⇒ pan the visualization rightward (leftward, downward, or upward) Tilt Slant the paper to the left (right, up, or down) relative to the ground =⇒ pan the visualization rightward (leftward, downward, or upward) Flip Flip the paper from left to right (right to left, up to down, or down to up) =⇒ pan the visualization leftward (rightward, upward, or downward) Link&amp;Select Collate Put one visualization on top of another and center it to specific position relative to the bottom one =⇒ connect the two visualizations, select the data point from the bottom one, and update both visualizations Collocate&amp;Point Put two visualizations side by side and point at the visualization =⇒ connect the two visualizations, select the data point, and update both visualizations</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. This figure shows the framework of the prototype and relationship between client, server, and configuration website.</figDesc><graphic url="image-138.png" coords="6,342.84,300.62,173.56,116.69" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 6 .</head><label>6</label><figDesc>Fig. 6. This figure shows the experiment setting: (a) the participant were wearing the HoloLens 2 to view the digital visualization in AR; (b) both of the participant's hands were recorded by both a smartphone on a phone stand; (c) a laptop was used by one of the authors to change the settings of the current activated interactions.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 7 .</head><label>7</label><figDesc>Fig. 7. This figure demonstrates an example of fold⇒zoom: (a) the initial scatter plot and its changes after (b) vertically and (c) horizontally folding the paper. The right hand joints are visualized using the white spheres.</figDesc><graphic url="image-140.png" coords="7,157.69,73.00,62.80,89.49" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 9 .</head><label>9</label><figDesc>Fig. 9. When a user (a) covers five bars in a bar chart, (b) the covered bars or (c) the uncovered bars can be selected.</figDesc></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS</head><p>This work is partially supported by Hong Kong RGC GRF Grant (No. 16210321).</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Keepin&apos;it real: Pushing the Desktop Metaphor with Physics, Piles and the Pen</title>
		<author>
			<persName><forename type="first">A</forename><surname>Agarawala</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Balakrishnan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Human Factors in Computing Systems</title>
				<meeting>the Conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="1283" to="1292" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Low-level components of analytic activity in information visualization</title>
		<author>
			<persName><forename type="first">R</forename><surname>Amar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Eagan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Stasko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Symposium on Information Visualization, 2005. INFOVIS 2005</title>
				<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="111" to="117" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Ceci n&apos;est pas la data: Towards a notion of interaction literacy for data visualization</title>
		<author>
			<persName><forename type="first">B</forename><surname>Bach</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Small MultiPiles: Piling Time to Explore Temporal Patterns in Dynamic Networks</title>
		<author>
			<persName><forename type="first">B</forename><surname>Bach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Henry-Riche</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Dwyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Madhyastha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-D</forename><surname>Fekete</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Grabowski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Graphics Forum</title>
				<imprint>
			<publisher>Wiley Online Library</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="31" to="40" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">The Emerging Genre of Data Comics</title>
		<author>
			<persName><forename type="first">B</forename><surname>Bach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">H</forename><surname>Riche</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Carpendale</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Pfister</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer Graphics and Applications</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<author>
			<persName><forename type="first">B</forename><surname>Bach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Sicat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Beyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Cordeil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Pfister</surname></persName>
		</author>
		<title level="m">The Hologram in My Hand: How Effective is Interactive Exploration of 3D Visualizations in Immersive Tangible Augmented Reality? IEEE Transactions on Visualization and Computer Graphics</title>
				<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="457" to="467" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Touching information with diy paper charts &amp; ar markers</title>
		<author>
			<persName><forename type="first">S</forename><surname>Bae</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Gyory</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Uhr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Szafir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">Y</forename></persName>
		</author>
		<author>
			<persName><forename type="first">-L</forename><surname>Do</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Interaction Design and Children</title>
				<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="433" to="438" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Analysis of the hands in egocentric vision: A survey</title>
		<author>
			<persName><forename type="first">A</forename><surname>Bandini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zariffa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE transactions on pattern analysis and machine intelligence</title>
				<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Instrumental interaction: An interaction model for designing post-wimp user interfaces</title>
		<author>
			<persName><forename type="first">M</forename><surname>Beaudouin-Lafon</surname></persName>
		</author>
		<idno type="DOI">10.1145/332040.332473</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, CHI &apos;00</title>
				<meeting>the SIGCHI Conference on Human Factors in Computing Systems, CHI &apos;00<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="446" to="453" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Balloon selection: A multi-finger technique for accurate low-fatigue 3d selection</title>
		<author>
			<persName><forename type="first">H</forename><surname>Benko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Feiner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2007 IEEE Symposium on 3D User Interfaces. IEEE</title>
				<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Collaborative immersive analytics</title>
		<author>
			<persName><forename type="first">M</forename><surname>Billinghurst</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Cordeil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bezerianos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Margolis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Immersive Analytics</title>
				<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="221" to="257" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Tangible augmented reality</title>
		<author>
			<persName><forename type="first">M</forename><surname>Billinghurst</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Kato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Poupyrev</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Siggraph Asia</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1" to="10" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Suggested interactivity: Seeking perceived affordances for information visualization</title>
		<author>
			<persName><forename type="first">J</forename><surname>Boy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Eveillard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Detienne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-D</forename><surname>Fekete</surname></persName>
		</author>
		<idno type="DOI">10.1109/TVCG.2015.2467201</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="639" to="648" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Complete counterbalancing of immediate sequential effects in a latin square design</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">V</forename><surname>Bradley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Statistical Association</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="issue">282</biblScope>
			<biblScope unit="page" from="525" to="528" />
			<date type="published" when="1958">1958</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">A Multi-level Typology of Abstract Visualization Tasks</title>
		<author>
			<persName><forename type="first">M</forename><surname>Brehmer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Munzner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2376" to="2385" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Sketching and ideation activities for situated visualization design</title>
		<author>
			<persName><forename type="first">N</forename><surname>Bressa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Wannamaker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Korsgaard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Willett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Vermeulen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 on Designing Interactive Systems Conference</title>
				<meeting>the 2019 on Designing Interactive Systems Conference</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="173" to="185" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Interaction for immersive analytics</title>
		<author>
			<persName><forename type="first">W</forename><surname>Büschel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Dachselt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Drucker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Dwyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Görg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Isenberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kerren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>North</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Stuerzlinger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Immersive analytics</title>
				<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="95" to="138" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Investigating smartphone-based pan and zoom in 3d data spaces in augmented reality</title>
		<author>
			<persName><forename type="first">W</forename><surname>Büschel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mitschick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Meyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Dachselt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 21st International Conference on Human-Computer Interaction with Mobile Devices and Services</title>
				<meeting>the 21st International Conference on Human-Computer Interaction with Mobile Devices and Services</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="1" to="13" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Clusters, trends, and outliers: How immersive technologies can facilitate the collaborative analysis of multidimensional data</title>
		<author>
			<persName><forename type="first">S</forename><surname>Butscher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Hubenschmid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Fuchs</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Reiterer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems</title>
				<meeting>the 2018 CHI Conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="1" to="12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Marvist: Authoring glyph-based visualization in mobile augmented reality</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<idno type="DOI">10.1109/TVCG.2019.2892415</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="2645" to="2658" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Augmenting static visualizations with paparvis designer</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Tong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Bach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Qu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems</title>
				<meeting>the 2020 CHI Conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="1" to="12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Augmenting sports videos with viscommentator</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<idno type="DOI">10.1109/TVCG.2021.3114806</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Vis. Comput. Graph</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="824" to="834" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">TIVEE: visual exploration and explanation of badminton tactics in immersive visualizations</title>
		<author>
			<persName><forename type="first">X</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<idno type="DOI">10.1109/TVCG.2021.3114861</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Vis. Comput. Graph</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="118" to="128" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">A coefficient of agreement for nominal scales</title>
		<author>
			<persName><forename type="first">J</forename><surname>Cohen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Educational and psychological measurement</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="37" to="46" />
			<date type="published" when="1960">1960</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Embodied axes: Tangible, actuated interaction for 3d augmented reality data spaces</title>
		<author>
			<persName><forename type="first">M</forename><surname>Cordeil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Bach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Cunningham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Montoya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">T</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">H</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Dwyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems</title>
				<meeting>the 2020 CHI Conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="1" to="12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Design space for spatio-data coordination: Tangible interaction devices for immersive information visualisation</title>
		<author>
			<persName><forename type="first">M</forename><surname>Cordeil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Bach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Wilson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Dwyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2017 IEEE Pacific Visualization Symposium (PacificVis)</title>
				<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="46" to="50" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Iatk: An immersive analytics toolkit</title>
		<author>
			<persName><forename type="first">M</forename><surname>Cordeil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Cunningham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Bach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Hurter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">H</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Marriott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Dwyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2019 IEEE Conference on Virtual Reality and 3D User Interfaces (VR)</title>
				<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="200" to="209" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Imaxes: Immersive axes as embodied affordances for interactive multivariate data visualisation</title>
		<author>
			<persName><forename type="first">M</forename><surname>Cordeil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Cunningham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Dwyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">H</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Marriott</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 30th Annual ACM Symposium on User Interface Software and Technology</title>
				<meeting>the 30th Annual ACM Symposium on User Interface Software and Technology</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="71" to="83" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">A multi-modal natural language interface to an information visualization environment</title>
		<author>
			<persName><forename type="first">K</forename><surname>Cox</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">E</forename><surname>Grinter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">L</forename><surname>Hibino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">J</forename><surname>Jagadeesan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Mantilla</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Speech Technology</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="297" to="314" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">What is interaction for data visualization?</title>
		<author>
			<persName><forename type="first">E</forename><surname>Dimara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Perin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on visualization and computer graphics</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="119" to="129" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Melange: space folding for multi-focus interaction</title>
		<author>
			<persName><forename type="first">N</forename><surname>Elmqvist</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Henry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Riche</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-D</forename><surname>Fekete</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the SIGCHI Conference on Human Factors in Computing Systems</title>
				<meeting>the SIGCHI Conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="1333" to="1342" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Blended ui controls for situated analytics</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">A</forename><surname>Elsayed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">T</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Marriott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">H</forename><surname>Thomas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2016 Big Data Visual Analytics (BDVA)</title>
				<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">A tangible spherical proxy for object manipulation in augmented reality</title>
		<author>
			<persName><forename type="first">D</forename><surname>Englmeier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Dörner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Butz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Höllerer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Virtual Reality and 3D User Interfaces</title>
				<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="221" to="229" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Grand challenges in immersive analytics</title>
		<author>
			<persName><forename type="first">B</forename><surname>Ens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Bach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Cordeil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Engelke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Serrano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Willett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Prouzeau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Anthes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Büschel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Dunne</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Uplift: A tangible and immersive tabletop system for casual collaborative visual analytics</title>
		<author>
			<persName><forename type="first">B</forename><surname>Ens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Goodwin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Prouzeau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Anderson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gratzl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Lucarelli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Moyle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Smiley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Dwyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Displaystacks: interaction techniques for stacks of flexible thin-film displays</title>
		<author>
			<persName><forename type="first">A</forename><surname>Girouard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Tarun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Vertegaal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2012 CHI Conference on Human Factors in Computing Systems</title>
				<meeting>the 2012 CHI Conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="2431" to="2440" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Replicate and reuse: Tangible interaction design for digitally-augmented physical media objects</title>
		<author>
			<persName><forename type="first">A</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">R</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Patel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Vogel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems</title>
				<meeting>the 2020 CHI Conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="1" to="12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Interactive Dynamics for Visual Analysis</title>
		<author>
			<persName><forename type="first">J</forename><surname>Heer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Shneiderman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Queue</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="30" to="55" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Consumed endurance: a metric to quantify arm fatigue of mid-air interactions</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Hincapié-Ramos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Moghadasian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Irani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 CHI Conference on Human Factors in Computing Systems</title>
				<meeting>the 2014 CHI Conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="1063" to="1072" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Paper windows: interaction techniques for digital paper</title>
		<author>
			<persName><forename type="first">D</forename><surname>Holman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Vertegaal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Altosaar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Troje</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Johns</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2005 CHI Conference on Human Factors in Computing Systems</title>
				<meeting>the 2005 CHI Conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="591" to="599" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">What do we mean by &quot;interaction&quot;? an analysis of 35 years of chi</title>
		<author>
			<persName><forename type="first">K</forename><surname>Hornbaek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mottelson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Knibbe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Vogel</surname></persName>
		</author>
		<idno type="DOI">10.1145/3325285</idno>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Computer-Human Interaction</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page">2019</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Stream: Exploring the combination of spatially-aware tablets with augmented reality head-mounted displays for immersive analytics</title>
		<author>
			<persName><forename type="first">S</forename><surname>Hubenschmid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zagermann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Butscher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Reiterer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems</title>
				<meeting>the 2021 CHI Conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="1" to="14" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Slicing techniques for handheld augmented reality</title>
		<author>
			<persName><forename type="first">P</forename><surname>Issartel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Guéniat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ammi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2014 IEEE Symposium on 3D User Interfaces (3DUI)</title>
				<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="39" to="42" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">A lightweight tangible 3d interface for interactive visualization of thin fiber structures</title>
		<author>
			<persName><forename type="first">B</forename><surname>Jackson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">Y</forename><surname>Lau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Schroeder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">C</forename><surname>Toussaint</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">F</forename><surname>Keefe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on visualization and computer graphics</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2802" to="2809" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Reality-based interaction: a framework for post-wimp interfaces</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Jacob</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Girouard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">M</forename><surname>Hirshfield</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Horn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Shaer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">T</forename><surname>Solovey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zigelbaum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2008 CHI Conference on Human Factors in Computing Systems</title>
				<meeting>the 2008 CHI Conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="201" to="210" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">An interaction model for visualizations beyond the desktop</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Jansen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Dragicevic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2396" to="2405" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Embodied lenses for collaborative visual queries on tabletop displays</title>
		<author>
			<persName><forename type="first">K</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Elmqvist</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Visualization</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="319" to="338" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title level="m" type="main">Visar: Bringing interactivity to static data visualizations through augmented reality</title>
		<author>
			<persName><forename type="first">T</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Saket</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Endert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Macintyre</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1708.01377</idno>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Paperphone: understanding the use of bend gestures in mobile devices with flexible electronic paper displays</title>
		<author>
			<persName><forename type="first">B</forename><surname>Lahey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Girouard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Burleson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Vertegaal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the SIGCHI Conference on Human Factors in Computing Systems</title>
				<meeting>the SIGCHI Conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="1303" to="1312" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Bridging from Goals to Tasks with Design Study Analysis Reports</title>
		<author>
			<persName><forename type="first">H</forename><surname>Lam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Tory</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Munzner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="435" to="445" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Vistiles: Coordinating and combining co-located mobile devices for visual data exploration</title>
		<author>
			<persName><forename type="first">R</forename><surname>Langner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Horak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Dachselt</surname></persName>
		</author>
		<idno type="DOI">10.1109/TVCG.2017.2744019</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="626" to="636" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Beyond mouse and keyboard: Expanding design considerations for information visualization interactions</title>
		<author>
			<persName><forename type="first">B</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Isenberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">H</forename><surname>Riche</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Carpendale</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2689" to="2698" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Multimodal interaction for data visualization</title>
		<author>
			<persName><forename type="first">B</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Srinivasan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Stasko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Tory</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Setlur</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 International Conference on Advanced Visual Interfaces</title>
				<meeting>the 2018 International Conference on Advanced Visual Interfaces</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="1" to="3" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">A generic framework and library for exploration of small multiples through interactive piling</title>
		<author>
			<persName><forename type="first">F</forename><surname>Lekschas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Gehlenborg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Bach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Pfister</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Mental Models, Visual Reasoning and Interaction in Information Visualization: A Top-down Perspective</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Stasko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="999" to="1008" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Improving information sharing and collaborative analysis for remote geospatial visualization using mixed reality</title>
		<author>
			<persName><forename type="first">T</forename><surname>Mahmood</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Fulmer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Mungoli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2019 IEEE International Symposium on Mixed and Augmented Reality (ISMAR)</title>
				<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="236" to="247" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<monogr>
		<title level="m" type="main">On the potential of zines as a medium for visualization</title>
		<author>
			<persName><forename type="first">A</forename><surname>Mcnutt</surname></persName>
		</author>
		<imprint>
			<biblScope unit="volume">08</biblScope>
			<biblScope unit="page">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<monogr>
		<title level="m" type="main">Reducing legacy bias in gesture elicitation studies. interactions</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Morris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Danielescu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Drucker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Fisher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Schraefel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">O</forename><surname>Wobbrock</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="40" to="45" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Kinetica: Naturalistic multi-touch data visualization</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Rzeszotarski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kittur</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the SIGCHI Conference on Human Factors in Computing Systems</title>
				<meeting>the SIGCHI Conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="897" to="906" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Onset: A visualization technique for large-scale binary set data</title>
		<author>
			<persName><forename type="first">R</forename><surname>Sadana</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Major</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Dove</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Stasko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="1993" to="2002" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Popular performance metrics for evaluation of interaction in virtual and augmented reality</title>
		<author>
			<persName><forename type="first">A</forename><surname>Samini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">L</forename><surname>Palmerius</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2017 International Conference on Cyberworlds (CW)</title>
				<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="206" to="209" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Augmented reality map navigation with freehand gestures</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">A</forename><surname>Satriadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Ens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Cordeil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Jenny</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Czauderna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Willett</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Virtual Reality and 3D User Interfaces</title>
				<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="593" to="603" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Reactive Vega: A Streaming Dataflow Architecture for Declarative Interactive Visualization</title>
		<author>
			<persName><forename type="first">A</forename><surname>Satyanarayan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Russell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hoffswell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Heer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="659" to="668" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Direct manipulation: A step beyond programming languages</title>
		<author>
			<persName><forename type="first">B</forename><surname>Shneiderman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Joint Conference on Easier and More Productive Use of Computer Systems.(Part-II): Human Interface and the User Interface</title>
				<meeting>the Joint Conference on Easier and More Productive Use of Computer Systems.(Part-II): Human Interface and the User Interface</meeting>
		<imprint>
			<date type="published" when="1981">1981</date>
			<biblScope unit="volume">1981</biblScope>
			<biblScope unit="page">143</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Dxr: A toolkit for building immersive data visualizations</title>
		<author>
			<persName><forename type="first">R</forename><surname>Sicat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Cordeil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W.-K</forename><surname>Jeong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Bach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Pfister</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="715" to="725" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">The made-axis: A modular actuated device to embody the axis of a data dimension</title>
		<author>
			<persName><forename type="first">J</forename><surname>Smiley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Tandon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Cordeil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Besanc ¸on</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Knibbe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Jenny</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Dwyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the ACM on Human-Computer Interaction</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">ISS</biblScope>
			<biblScope unit="page" from="1" to="23" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Pinch-dragflick vs. spatial input: rethinking zoom &amp; pan on mobile displays</title>
		<author>
			<persName><forename type="first">M</forename><surname>Spindler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Schuessler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Martsch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Dachselt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the SIGCHI Conference on Human Factors in Computing Systems</title>
				<meeting>the SIGCHI Conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="1113" to="1122" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Tangible views for information visualization</title>
		<author>
			<persName><forename type="first">M</forename><surname>Spindler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Tominski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Schumann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Dachselt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM International Conference on Interactive Tabletops and Surfaces</title>
				<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="157" to="166" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Inchorus: Designing consistent multimodal interactions for data visualization on tablet devices</title>
		<author>
			<persName><forename type="first">A</forename><surname>Srinivasan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Henry Riche</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Drucker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Hinckley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems</title>
				<meeting>the 2020 CHI Conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="1" to="13" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Geogate: Correlating geo-temporal datasets using an augmented reality space-time cube and tangible interactions</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">Y</forename><surname>Ssin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Walsh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">T</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Cunningham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">H</forename><surname>Thomas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2019 IEEE Conference on Virtual Reality and 3D User Interfaces (VR)</title>
				<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="210" to="219" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Printable interactive volume visualization</title>
		<author>
			<persName><forename type="first">S</forename><surname>Stoppel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bruckner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on visualization and computer graphics</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="861" to="870" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Reflex: A flexible smartphone with active haptic feedback for bend input</title>
		<author>
			<persName><forename type="first">P</forename><surname>Strohmeier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Burstyn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">P</forename><surname>Carrascal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Levesque</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Vertegaal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the TEI&apos;16: Tenth International Conference on Tangible, Embedded, and Embodied Interaction</title>
				<meeting>the TEI&apos;16: Tenth International Conference on Tangible, Embedded, and Embodied Interaction</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="185" to="192" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">Composites: A tangible interaction paradigm for visual data analysis in design practice</title>
		<author>
			<persName><forename type="first">H</forename><surname>Subramonyam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Adar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Drucker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2022 International Conference on Advanced Visual Interfaces</title>
				<meeting>the 2022 International Conference on Advanced Visual Interfaces</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="1" to="9" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">Affinity lens: data-assisted affinity diagramming with augmented reality</title>
		<author>
			<persName><forename type="first">H</forename><surname>Subramonyam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Drucker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Adar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 CHI conference on human factors in computing systems</title>
				<meeting>the 2019 CHI conference on human factors in computing systems</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="1" to="13" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">Exploring interactions with physically dynamic bar charts</title>
		<author>
			<persName><forename type="first">F</forename><surname>Taher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hardy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Karnik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Weichel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Jansen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Hornbaek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Alexander</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 33rd annual acm conference on human factors in computing systems</title>
				<meeting>the 33rd annual acm conference on human factors in computing systems</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="3237" to="3246" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">Affordances for manipulation of physical versus digital media on interactive surfaces</title>
		<author>
			<persName><forename type="first">L</forename><surname>Terrenghi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Kirk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sellen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Izadi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the SIGCHI conference on Human factors in computing systems</title>
				<meeting>the SIGCHI conference on Human factors in computing systems</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="1157" to="1166" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">Interaction support for visual comparison inspired by natural behavior</title>
		<author>
			<persName><forename type="first">C</forename><surname>Tominski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Forsell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Johansson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Transactions on Visualization and Computer Graphics</title>
				<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="2719" to="2728" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main">A survey on interactive lenses in visualization</title>
		<author>
			<persName><forename type="first">C</forename><surname>Tominski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gladisch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Kister</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Dachselt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Schumann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EuroVis</title>
				<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<analytic>
		<title level="a" type="main">Computableviz: Mathematical operators as a formalism for visualisation processing and analysis</title>
		<author>
			<persName><forename type="first">A</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Tong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Moritz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Qu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CHI Conference on Human Factors in Computing Systems</title>
				<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="1" to="15" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<analytic>
		<title level="a" type="main">Ai4vis: Survey on artificial intelligence approaches for data visualization</title>
		<author>
			<persName><forename type="first">A</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Shu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Moritz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Qu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<analytic>
		<title level="a" type="main">MRTouch: Adding Touch Input to Head-mounted Mixed Reality</title>
		<author>
			<persName><forename type="first">R</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schwarz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Throm</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">D</forename><surname>Wilson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Benko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1653" to="1660" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b81">
	<analytic>
		<title level="a" type="main">Shuttlespace: Exploring and analyzing movement trajectory in immersive visualization</title>
		<author>
			<persName><forename type="first">S</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<idno type="DOI">10.1109/TVCG.2020.3030392</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Vis. Comput. Graph</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="860" to="869" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b82">
	<analytic>
		<title level="a" type="main">Toward a deeper understanding of the role of interaction in information visualization</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Stasko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Jacko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1224" to="1231" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b83">
	<monogr>
		<title level="m" type="main">Data comics: Sequential art for data-driven storytelling</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Marr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Elmqvist</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note type="report_type">tech. report</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
