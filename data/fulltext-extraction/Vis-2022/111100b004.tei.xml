<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Geo-Storylines: Integrating Maps into Storyline Visualizations</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Golina</forename><surname>Hulstein</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Vanessa</forename><surname>Pe Ña-Araya</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Anastasia</forename><surname>Bezerianos</surname></persName>
						</author>
						<title level="a" type="main">Geo-Storylines: Integrating Maps into Storyline Visualizations</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.2" ident="GROBID" when="2023-03-27T09:13+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Storyline visualization</term>
					<term>geo-temporal data</term>
					<term>maps</term>
					<term>hypergraphs</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Storyline visualizations are a powerful way to compactly visualize how the relationships between people evolve over time. Real-world relationships often also involve space, for example the cities that two political rivals visited together or alone over the years. By default, Storyline visualizations only show implicitly geospatial co-occurrence between people (drawn as lines), by bringing their lines together. Even the few designs that do explicitly show geographic locations only do so in abstract ways (e.g., annotations) and do not communicate geospatial information, such as the direction or extent of their political campains. We introduce Geo-Storylines, a collection of visualisation designs that integrate geospatial context into Storyline visualizations, using different strategies for compositing time and space. Our contribution is twofold. First, we present the results of a sketching workshop with 11 participants, that we used to derive a design space for integrating maps into Storylines. Second, by analyzing the strengths and weaknesses of the potential designs of the design space in terms of legibility and ability to scale to multiple relationships, we extract the three most promising: Time Glyphs, Coordinated Views, and Map Glyphs. We compare these three techniques first in a controlled study with 18 participants, under five different geospatial tasks and two maps of different complexity. We additionally collected informal feedback about their usefulness from domain experts in data journalism. Our results indicate that, as expected, detailed performance depends on the task. Nevertheless, Coordinated Views remain a highly effective and preferred technique across the board.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>In 2009 the XKCD comic introduced narrative charts, a visualization to summarize movie plots <ref type="bibr" target="#b32">[35]</ref>. In these charts, each character in the movie is represented by a line along an implicit horizontal timeline. Characters' lines curve towards each other when they meet, stay close as long as they are together, and move apart again when they split up.</p><p>This co-occurrence between movie characters can be more broadly defined as a relationship among entities of any type that occurs on a specific point in time. Their succinct layout makes narrative charts, later known as Storylines, a powerful tool applicable to a variety of domains. For example, they have been used to visualize how developers interact on a code repository <ref type="bibr" target="#b33">[36]</ref>, to illustrate spatio-temporal patterns of fixations in eye tracking <ref type="bibr" target="#b6">[9]</ref>, and to visualize the evolution of communities in dynamic social networks <ref type="bibr" target="#b41">[44]</ref>. More recently, HyperStorylines has generalized Storylines to represent complex relationships between any type of entity in a hypergraph <ref type="bibr" target="#b38">[41]</ref>.</p><p>• Golina Hulstein is with Université Paris-Saclay. E-mail: golina@hulstein.com • Vanessa Peña-Araya is with Université Paris-Saclay, CNRS, Inria. E-mail: vanessa.pena-araya@inria.fr Relationships among people in real world contexts commonly include geographical locations (e.g., countries or cities) or other contextual places (e.g., a cafe or a theater). Let us consider the example of our journalist experts analysing the election campaign of two political rivals in France, Juliet and Antoine, shown in Fig. <ref type="figure" target="#fig_0">1</ref>. We can define each political debate between them as a relationship, linking the two candidates, a city and a date. A more complex relationship can consider other events organised by their parties occurring simultaneously in different cities. Here, a single relationship can link the names of the organizers, several locations and a date. Journalists may investigate the structure and impact of these campaigns, trying to understand the cities the politicians visited together, if the supporting events happened between contiguous cities or were more wide-spread, and whether the campaign events were organized simultaneously or moved sequentially from city to city following a geographical pattern. Answering these questions requires a visualization of geospatial, temporal, and relationship data. For example, in Fig. <ref type="figure" target="#fig_0">1</ref> we observe that the relationships that link Juliet and Antoine start in the north of the country in 2001 and move slowly to the south over the years. Some Storyline variations use abstract strategies, such as line position or annotations, to visualize where relationships occur (e.g., <ref type="bibr" target="#b4">[7,</ref><ref type="bibr" target="#b28">31,</ref><ref type="bibr" target="#b47">50]</ref>). However, they lack geospatial detail and therefore cannot answer all of the questions mentioned above. In addition, they do not consider complex spatial links where more than one location is linked to a single relationship. We address this gap by introducing and studying geo-storylines, visualizations that integrate the full geospatial context of relationships into storyline visualizations. Our work makes the following two contributions:</p><p>1. The Geo-Storylines design space, derived from sketching workshops and a literature review of tangentially related visualizations. 2. The evaluation of the three most promising designs from the design space. First, in a controlled user-study that focuses on five spatiotemporal tasks: identify locations, identify dates, distance, direction and adjacency. And second, through expert feedback. The three designs differ in their focus on space vs. time: Map Glyphs split spatial information over multiple maps within the storyline; Coordinated Views link the temporal information in the storyline with a separate map on user interactions; and Time Glyphs split time by representing it in a separate storyline for each geospatial location.</p><p>Our results found Coordinated Views more efficient and preferred overall. However, both Map Glyphs and Time Glyphs had higher accuracy than Coordinated Views when identifying locations. Our code, supp.material and link to a live demo are available at https://gitlab. inria.fr/ilda/geo-storylines, and experimental analysis and scripts can be found at https://osf.io/5wnyg.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK</head><p>In this section we first summarize literature on the visualization of relationships over space and time in generally. We then cover existing work on Storyline visualization, and relevant design spaces.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Visualizing Relationships over Space and Time</head><p>There is an extensive amount of research on spatio-temporal visualizations. For instance, there are general approaches to represent change over space and time, like small multiples <ref type="bibr" target="#b17">[20,</ref><ref type="bibr" target="#b27">30,</ref><ref type="bibr" target="#b53">56]</ref>, animation <ref type="bibr" target="#b29">[32]</ref> or 3D views <ref type="bibr" target="#b24">[27,</ref><ref type="bibr" target="#b49">52]</ref>. Other approaches focus on specific types of data, like flow of movement <ref type="bibr" target="#b42">[45,</ref><ref type="bibr" target="#b53">56]</ref>, trajectories <ref type="bibr" target="#b5">[8,</ref><ref type="bibr" target="#b50">53,</ref><ref type="bibr" target="#b54">57]</ref> and other spatio-temporal patterns <ref type="bibr" target="#b31">[34]</ref>. Nevertheless, this work does not include information about the evolving spatio-temporal relationships among entities, such as when the entities come together or diverge in their trajectories. When we do not consider time, there is also considerable work expressing the relationships of only two entities, expressed as nodes, in the form for geospatial networks. This work is summarized in the survey by Schöttler et al. <ref type="bibr" target="#b44">[47]</ref>.</p><p>There is little work that considers multiple entities (e.g., people), whose relationships evolve in space and time. Examples of such data can include genealogies, academic co-authorship networks, or political rivalries, and can be modeled as dynamic hypergraphs. Hypergraphs are the generalization of graphs, where links can include any number of nodes instead of only two <ref type="bibr" target="#b8">[11]</ref>, and nodes can be of any type (e.g., people, locations). The visualization of dynamic hypergraphs, that represent the evolution of relationships over time, is an active research field <ref type="bibr" target="#b19">[22]</ref>. The three more recent visualizations are PAOHViz <ref type="bibr" target="#b52">[55]</ref>, Hyper-Matrix <ref type="bibr" target="#b18">[21]</ref> and HyperStorylines <ref type="bibr" target="#b38">[41]</ref>. The first two adopt a matrix approach and represent entities as rows and relationships in columns. HyperStorylines, on the other hand, generalizes Storyline visualizations to show relationships between multiple types of entities. HyperStorylines and PAOHViz both encode location entities, but these are treated as any other named entity without explicit geographical context to allow for geospatial analysis (e.g., the distance or spread between the locations where two relationships occur).</p><p>In summary, there are no existing visualizations that describe the geospatial context of entities' relationship dynamics. Furthermore, most of geospatial network visualizations do not focus on links of more than two elements. In this paper we set out to create visualizations that can combine entities' dynamic relationships with the geospatial context they occur in. We chose to do this by integrating geospatial information into Storylines as their layout prioritizes grouping of related entities and allows for a more compact and easy-to-analyze visualization than PAO-HVis <ref type="bibr" target="#b38">[41]</ref>. It is this relative simplicity of Storylines that makes them a promising candidate for integrating additional geospatial information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Storyline visualizations</head><p>Inspired by the XKCD's Narrative Charts, Ogawa and Ma introduced Storyline visualizations, including a layout algorithm, that was used to display interactions between software developers <ref type="bibr" target="#b33">[36]</ref>. Later research has mostly focused on their automatic generation <ref type="bibr" target="#b4">[7,</ref><ref type="bibr" target="#b21">24,</ref><ref type="bibr" target="#b28">31,</ref><ref type="bibr" target="#b30">33,</ref><ref type="bibr" target="#b45">48,</ref><ref type="bibr" target="#b46">49]</ref> and on applying them to different domains. For example, Storylines have been used to visualize dynamic social networks <ref type="bibr" target="#b41">[44,</ref><ref type="bibr" target="#b56">59]</ref>, collaboration in groups <ref type="bibr" target="#b30">[33,</ref><ref type="bibr" target="#b33">36]</ref>, genealogical data <ref type="bibr" target="#b25">[28]</ref>, temperature changes over time <ref type="bibr" target="#b55">[58]</ref>, and even to analyze eye tracking data <ref type="bibr" target="#b6">[9]</ref>. A more recent line of research considers how additional information can be integrated into Storyline visualizations including mixing automatic and human input <ref type="bibr" target="#b47">[50,</ref><ref type="bibr" target="#b48">51]</ref>, non-linear narratives <ref type="bibr" target="#b34">[37,</ref><ref type="bibr" target="#b35">38]</ref> and multiple relationships at once by branching their lines <ref type="bibr" target="#b14">[17]</ref>.</p><p>Only a handful of papers consider space in Storylines. The original Narrative Charts <ref type="bibr" target="#b32">[35]</ref> use labeled background contours to encode space, which was later extended with layered contours that can show location hierarchy in a form similar to a river plot <ref type="bibr" target="#b28">[31,</ref><ref type="bibr" target="#b45">48,</ref><ref type="bibr" target="#b46">49]</ref>. Other visualizations use arc segments drawn between entities <ref type="bibr" target="#b40">[43]</ref>, or the y-axis position of entities to encode space <ref type="bibr" target="#b4">[7]</ref>. Finally, some hand-drawn Storyline examples use line rendering properties to show transitions between worlds <ref type="bibr" target="#b47">[50,</ref><ref type="bibr" target="#b48">51]</ref>.</p><p>The aforementioned representations of space show the geospatial context to a limited extent. Layered background contours in the form of river plots provide information about the hierarchical relationships between locations, but do not show information related to distance or direction. Designs that reduce 2D space to the y-axis can show distance but distort the horizontal space making horizontal direction or adjacency hard to determine. One exception is the work of Yagi et al. <ref type="bibr" target="#b55">[58]</ref> that shows temperature variation in Japan. Their visualization combines a map of Japan with a Storyline representation of temperature, and relates the two through color. While this design does describe the full geospatial context, its reliance on color strongly limits the number of locations it can encode.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Existing Design Spaces relevant to Storylines</head><p>Some existing design spaces are relevant to Storylines, although they do not necessarily consider geographical context. For example, Tang et al. <ref type="bibr" target="#b48">[51]</ref> created a design space for their narrative elements. Their design space is structured into five dimensions describing ways to encode actors, relationships, and plots as well as variations of timeline structure and decorative elements. However, their design space does not cover geospatial representations in Storylines.</p><p>Brehmer et al. created a design space for storytelling with timelines <ref type="bibr" target="#b10">[13]</ref> which is structured into three dimensions: how a timeline is represented (linear, radial, a grid, etc.), the scale used in the timeline, and its layout. It does not, however, address Storylines specifically.</p><p>Bach et al.'s recent review of geospatial network visualizations provides a comprehensive overview of how networks can be combined with geospatial visualizations <ref type="bibr" target="#b43">[46]</ref>. Their design space describes the representations of space and networks, but also considers how the two are combined. Although this design space does cover geospatial representations, it is missing the time dimension. On the other hand, the more general framework defined by Bach et al. <ref type="bibr" target="#b5">[8]</ref> gives a descriptive model for temporal data. However, it does not consider explicit relationships among entities, nor geo-spatial data. Finally, the framework by Windhager et al. <ref type="bibr" target="#b54">[57]</ref> visualizes biographical data over space and time using multiple 3D views. It describes people's trajectories, but does not explicitly represent relationships between them.</p><p>While none of these design spaces describe how geospatial context can be integrated into Storylines, they provide inspiration for the dimensions proposed in our own design space and are discussed there.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">GENERATIVE WORKSHOPS</head><p>The challenge of analysing the spatio-temporal properties of evolving relationships is important in several domains, including data journalism. The example provided in the introduction comes from a long collaboration with data journalists <ref type="bibr" target="#b38">[41]</ref> (see Sect. 7), where we identified the need to add topological / geographical information in Storylines. We thus set out to explore the different forms that Geo-Storyline visualizations could take. As existing approaches include limited spatial information in Storylines, we decided to generate a breadth of alternative visualizations to better understand their properties and limitations. Following an approach similar to Tang et al. <ref type="bibr" target="#b48">[51]</ref>, we conducted design workshops where participants generated hand-drawn visualizations, which we then used to create a design space. We describe our workshop considerations, procedure and the analysis of the created designs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Spatial relationship patterns and tasks</head><p>We asked participants to generate designs that combine three dimensions: people, and how their relationships evolve over space, and over time. As we are interested in adding geo-spatial context, we identified early on five patterns that describe how people's locations relate to one another: for example when two politicians visit cities which direction do they follow, or what distance do their respective campaigns cover. These patterns are: distance, direction, extent, adjacency, and hierarchy (discussed next). In the workshop, we used these patterns to inspire participants to include different aspects of space in their sketches (Sect. 3.3). We then used them as a basis for the tasks in our comparison study (Sect. 5). We next explain why we chose these patterns and how we turned them into questions and tasks.</p><p>To obtain the geospatial patterns of how locations relate to each other, we looked at the taxonomy of movement by Dodge et al. <ref type="bibr" target="#b15">[18]</ref>, that organizes the possible parameters that define a movement pattern. We focused on their primary derivative parameters that define basic movement. Additionally, we do not include parameters in the temporal dimension (duration) as we focus on the spatial context of relationships. This led us to the spatial patterns: distance, direction, and spatial extent. When used as prompts, participants in the workshop would be asked to design a visualization that could answer questions such as what distance did these two people travel together?, which direction did they take?, and how much of the country did they cover?</p><p>We consider two additional spatial relationships that stem from the structure of maps: adjacency and hierarchy. Similarly to work on visualizing spatial propagation <ref type="bibr" target="#b36">[39]</ref>, we consider two locations as adjacent when the trajectory between them is contiguous and is not separated by other locations (no hops). Geo-spatial hierarchy describes the common spatial organization of map locations into levels such as cities, countries, and continents. Prompt questions for these relationships would be were there any jumps in the trajectory followed by these two people? or how did people move between countries and continents?</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Participants and data</head><p>We conducted three 2h workshops with 11 participants from our institution (7 women, 4 men, 1 did not specify). Workshops were divided in two 1h sessions and were conducted online. In an effort to generate usable and varied designs, all participants were practitioners or researchers in HCI and visualization.</p><p>Participants could choose to prepare their own dataset or use one of two prefabricated datasets: (i) the movements of a subset of Lord of the Rings (LotR) characters, and (ii) a music tour of Imagine Dragons between 09-2017 and 08-2018 with its opening acts. For both datasets we provided a map. Five participants chose to use the LotR dataset and two chose the Imagine Dragons one. The remaining four participants chose to collect a personal dataset about their trips with family or friends, and were instructed to collect data about when and where the relationships between people occurred. To keep the datasets manageable in size for creating hand-drawn sketches, we limited them to 3-5 people and approximately 15 relationships.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Procedure</head><p>The workshop was structured into two sessions of one hour each. In the first session, we introduced the theme and showed participants a set of basic visualizations of time, space, and relationships as inspiration (slides provided in supp.material). We note that storylines were only one among several inspiration visualizations. Participants were then given 25 minutes to sketch a first, unguided, visualization of their data. They were asked to upload their sketches to a Miro board 1 and then present them to the group. At the end they were asked what remaining questions they had about their data.</p><p>Before the second session, we prepared two sets of 2-3 questions for each participant to choose from. Allowing participants to choose from 1 www.miro.com a set of constraints has been used in previous visualization workshops to foster creativity in a reasonable time span <ref type="bibr" target="#b23">[26]</ref>. The first set came from the questions participants reported having about their data at the end of session 1. The second set asked participants to focus on answering a question related to one of the identified geospatial patterns (see Sect. 3.1), guiding participants to explore different aspects of space in their sketches such as distance, direction, spatial extent, and hierarchy. The second session started with a short intro, after which participants completed two rounds of sketching of 20 minutes each. In each round they chose one of the questions we prepared. We also gave participants a set of inspiration cards (supp. material) to remind them of different ways to visualize space, time and people.</p><p>As our goal was to generate a wide variation of visualizations, all three authors participated in the sketching during the workshops. We used the Imagine Dragons dataset as well as our own custom datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Analysis of Generated Sketches</head><p>The workshop produced 67 sketches (supp.material), among which 39 were created by participants and the rest by the authors. However, not all sketches visualize multiple people and their relationships over space and time. For example, 5 participant sketches visualized the movements of only one person, failing to describe relationships. And notably, 11 sketches (7 from participants) are missing the time dimension. Based on our observations, this happened when participants made the strategic decision to start their visualization with only two aspects of the data (e.g., people and space). In some cases, they were able to integrate the third aspect (e.g., time) later on, but sometimes they failed to do so indicating that combining all three aspects is challenging. Indeed, at the end of the workshop several participants expressed how difficult it was to combine all three dimensions.</p><p>It is interesting to note that while participants were provided with several geo-temporal inspiration visualisations (not only storylines) they often naturally converged to sketches that have storyline visualization characteristics (21 out of 39 generated by participants). Examples of sketches can be seen on the left and right side of Fig. <ref type="figure" target="#fig_1">2</ref>.</p><p>We performed a bottom-up card sorting of the workshop sketches in several iterations, grouping them by visual encoding, and by what aspects of the data they highlight. We examined the resulting clusters in terms on whether they can represent the relationships of multiple people and their spatial evolution. We eliminated clusters that rely on abstract representations of space, as they are either unable to show spatial relationships between locations, or only show a single spatial relationship (such as distance or hierarchy only). This resulted in five clusters whose characteristics we analysed to create a design space (Sect. 4), made up of 41 sketches (25 from participants). Details of our iterative analysis, resulting clusters and all sketches are in supp.material.</p><p>We note that the workshop sketches did not always include Storylines: for example some included other timeline representations, like Fig. <ref type="figure" target="#fig_1">2H</ref> that associates a separate custom timeline representation to each location. We thus created representative designs for each cluster that illustrate the sketch concepts, but are adapted for storylines. For example in Fig. <ref type="figure" target="#fig_1">2H</ref> we replaced the custom timeline with a Storyline. These representative designs are seen at the center of Fig. <ref type="figure" target="#fig_1">2</ref>. As the Small Multiples cluster presents two promising design variations, one with a map per relationship, and one with a map per time-step, we included two representative designs, seen in Fig. <ref type="figure" target="#fig_1">2A,E</ref> respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">THE DESIGN SPACE</head><p>Here we introduce the Geo-Storylines design space, that considers how to best incorporate geographical context into storylines. We first describe its three dimensions that explain how space and time can be combined, how the design space categorizes the designs extracted from the workshop, and how it was used to generate two additional designs. The design space, along with representative designs and inspiration sketches, can be seen in Fig. <ref type="figure" target="#fig_1">2</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Design Dimensions</head><p>We observed that the six representative designs extracted from the sketching workshop (Fig. <ref type="figure" target="#fig_1">2</ref>) may split either the space or time rep- resentations in the layout, depending on their emphasis (keeping the dimension of emphasis unified). This difference between split and unified layout representations of time and space defines the first two dimensions of our design space. However, there are cases where these two dimensions were insufficient to differentiate all the potential designs. For example, Fig. <ref type="figure" target="#fig_1">2A</ref> and Fig. <ref type="figure" target="#fig_1">2C</ref> both maintain time unified and space split, yet they clearly differ in how they combine these two dimensions. This difference motivated the third dimension: the overall composition of the visualization, which can be merged or separated.</p><p>We note that the design space resulting from these dimensions had two cells with no representative design, so we generated two additional designs to fill the gaps, seen in Fig. <ref type="figure" target="#fig_1">2G</ref> and Fig. <ref type="figure" target="#fig_1">2F</ref>. We next discuss the characteristics, advantages and disadvantages of these dimensions.</p><p>Time Layout. The layout of time can be either unified (a single timeline) or split (one timeline per location). Our time layout dimension resembles the one proposed in the design space for timelines by Brehmer et al. <ref type="bibr" target="#b10">[13]</ref>. They distinguish between unified, faceted and segmented layout. The latter two, where time is split by a categorical value (faceted) or temporal divisions (segmented), correspond to our split time layout. When considering the Space-Time Cubed framework for temporal data by Bach et al. <ref type="bibr" target="#b5">[8]</ref>, we can classify Storylines as a space flattening operation and our design space as chained operations. However, this framework does not address space explicitly, and thus does not acknowledge the way space is embedded (e.g., in Fig. <ref type="figure" target="#fig_1">2A</ref>).</p><p>For unified time, Fig. <ref type="figure" target="#fig_1">2</ref> shows three designs that use a single linear timeline, with a map positioned either: inside it (Fig. <ref type="figure" target="#fig_1">2A</ref>), on top (Fig. <ref type="figure" target="#fig_1">2C</ref>), or next to it (Fig. <ref type="figure" target="#fig_1">2D</ref>). In the case of (Fig. <ref type="figure" target="#fig_1">2D</ref>), links between the map and the timeline appear interactively by scrolling horizontally. In a fourth design (Fig. <ref type="figure" target="#fig_1">2B</ref>) time is encoded on trajectories: people are differentiated through line symbols (dashes, dots, etc.) and time by a common time-color gradient (higher saturation indicates recency).</p><p>For split time, Fig. <ref type="figure" target="#fig_1">2</ref> shows how we can split time: by periods (small map multiples in Fig. <ref type="figure" target="#fig_1">2E and G</ref>), by locations with one timeline per location (Fig. <ref type="figure" target="#fig_1">2H</ref>), or by people and individual trajectories (Fig. <ref type="figure" target="#fig_1">2F</ref>). Space Layout. Similar to time, the layout of space can be either unified (one map) or split (small multiples). The spatial layout dimension resembles Peña-Araya et al.'s categorization of spatio-temporal visualizations <ref type="bibr" target="#b37">[40]</ref>. In their categorization, visualizations are classified based on whether they juxtapose time (e.g., animation) or locations (e.g., small multiples). While their categorization strongly overlaps with the space layout dimension in our design space, it does not cover all cases in the Geo-Storylines design space. Notably, one of our Geo-Storylines designs juxtaposes space based on relationships rather than based on time (Fig. <ref type="figure" target="#fig_1">2A</ref>).</p><p>For split space we have designs that use one map per relationship (Fig. <ref type="figure" target="#fig_1">2A</ref>) or per periods of time (Fig. <ref type="figure" target="#fig_1">2C, E and G</ref>). For unified space, we see one map with merged or split timelines inside it (Fig. <ref type="figure" target="#fig_1">2B,F</ref>), or next to the map (Fig. <ref type="figure" target="#fig_1">2D,H</ref>).</p><p>Composition. The third and final dimension describes how the representations of time and space are combined into one visualization. Time and space representations can be either placed side by sidekeeping them separated -or they can be merged. The composition dimension also exists in Schöttler et al.'s survey of geospatial networks <ref type="bibr" target="#b43">[46]</ref>. They define four categories of compositions ranging from loosely to strongly integrated: juxtaposed, superimposed, nested, and integrated. Superimposing, nesting and integrating all describe different ways to merge the representations of time and space, and are all three present in the Geo-Storyline designs. In one design, small maps are nested into the storylines for each relationship (Fig. <ref type="figure" target="#fig_1">2A</ref>). In other designs, time is integrated into trajectories (Fig. <ref type="figure" target="#fig_1">2B,F</ref>). Finally, one design superimposes timelines over maps (Fig. <ref type="figure" target="#fig_1">2E</ref>). As we have only one or two examples using superimposed, nested, or integrated composition each, we combine these categories into merged compositions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Design Assessment</head><p>We assessed the capabilities of each visualization in an effort to identify the most promising designs. Our goal was to identify designs that represent all individual relationships without overlapping and without requiring arbitrary aggregations, i.e. designs that show all available relationship information. In particular, avoiding aggregation ensures that different relationships occurring at the same time and place are distinguishable.</p><p>The designs Fig. <ref type="figure" target="#fig_1">2B</ref> and F are incapable of differentiating multiple relationships occurring at the same time and location(s). These designs, as well as Fig. <ref type="figure" target="#fig_1">2E</ref> also suffer from occlusion. All three place relationships as glyphs over a map, so the available space to position a set of relationships is constrained by the boundaries of the location they are associated with. Small locations or those with large number of relationships will inevitable suffer from occlusion.</p><p>Design Fig. <ref type="figure" target="#fig_1">2C</ref> aggregates several relationships over time, shown together on one of the mini-maps on top of the timeline. This aggregation makes it difficult to differentiate relationships happening in the same location at different times. Extending the design to one map per relationship would eliminate the problem. However, it would require users to split their attention between navigating the storyline and identifying the corresponding mini-map on top. This makes it a less legible version of (A) where the mini-maps follow the people's lines.</p><p>Design Fig. <ref type="figure" target="#fig_1">2G</ref> also requires aggregation of time. And as it combines multiple time glyphs with map glyphs, it subdivides time and space to such an extent that it becomes a less illegible variation of Fig. <ref type="figure" target="#fig_1">2H</ref>.</p><p>Three promising designs remain: the small multiple maps per relationships that we will call from now on Map Glyphs (Fig. <ref type="figure" target="#fig_1">2A</ref>); the design where each location has its own storyline, called from now on Time Glyphs (Fig. <ref type="figure" target="#fig_1">2H</ref>), and the Coordinated Views (Fig. <ref type="figure" target="#fig_1">2D</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">USER STUDY</head><p>In this section we describe our evaluation of the three selected Geo-Storylines designs. The study aims to evaluate two aspects of the designs: 1) How effectively they visualize the geospatial relationships described in Sect. 3.1; and 2) how their performance scales with the number of locations they visualize. Figure <ref type="figure" target="#fig_0">1</ref> shows an example of the implementation of the three selected designs. This dataset is inspired by a real example from data journalism. It contains ten relationships between seven people, at six different points in time, meeting at four locations on a map. In each visualization, two people are selected.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Implementation of the designs</head><p>For our study, we implemented the three Geo-Storylines designs as an online interactive system. We took care to make interactions and the visual representation of relationships and entities (time, location, people) as similar as possible across the three visualizations.</p><p>Visual Properties: Designs vary in how to represent the links between time and geography. However, all timelines follow a basic Storyline visualization where each line represents a person that evolves over time in the horizontal axis. Lines, representing people, come together inside relationship boxes each time there is an event that involves all these people. Relationship boxes are rounded rectangles, with a hinge (dot) at the point where peoples' lines go through them. In the case of Map Glyphs, the relationship box is replaced by a mini-map. All locations of the map are colored with gray at the beginning. We limited the use of color as much as possible to push the basic visual encoding of each design. Each visualization fits in 2564×1310 pixels.</p><p>Interactions: Our design space does not consider interactions (except scrolling for Coordinated Views). When rendering real world datasets (see Sect. 5.5) it became clear that realistic timelines, where the names of the entities are big enough to be readable, extend beyond the available screen real-estate. So basic scrolling was added to all visualizations.</p><p>In addition, we observed in a pilot that visually tracing the path of specific entities while scrolling was tedious, as entity lines often cross and curve. We thus added basic selection functionality, that also exists in many other Storylines systems (e.g., <ref type="bibr" target="#b2">[5,</ref><ref type="bibr" target="#b33">36,</ref><ref type="bibr" target="#b38">41]</ref>) The three designs allow users to select one or more people, locations or dates. Selected entities are highlighted in blue, and so are the borders of the relationship boxes they are involved in. When more than one entity is selected, it is the relationship boxes that include all these entities that get highlighted in blue (intersection). Once a selection is activated, the remaining entities are faded out: if they are connected with some (but not all) of the selected entities they become gray, and if they are not connected to any selection they fade out to a light gray. This distinction allows users to differentiate between related, but unselected entities (gray) that may provide contextual information, and ones they do not relate to user's selection at all (light gray). We did not add advanced interaction, such as filtering or zooming, as we wanted to study the core design trade-offs of the techniques, distilled in our hypothesis in Sect. 5.3 (e.g., Time Glyphs require vertical space for all timelines, Map Glyphs result in small resolution mini-maps). We next note differences across the designs (also seen in Fig. <ref type="figure" target="#fig_0">1</ref>).</p><p>Coordinated Views (Fig. <ref type="figure" target="#fig_0">1A</ref>): Coordinated Views contain a map on the left, and on the right a single Storyline visualization. To see which locations are associated with a relationship, users scroll until the relationship's box is close to the left border of the timeline (dashed vertical line). Map locations that are associated with the upcoming relationship in the scrolled storyline, are visually linked with the relationship box and colored orange (to differentiate them from blue selections).</p><p>Map Glyphs (Fig. <ref type="figure" target="#fig_0">1B</ref>): In this case, the base Storyline visualization stays the same except that each relationship box is replaced by an embedded mini map. All locations that are part of the relationship are colored with orange. Users can select any location inside the mini maps and the selection will be reflected in all the mini maps of the timeline.</p><p>Time Glyphs (Fig. <ref type="figure" target="#fig_0">1C</ref>): A map is positioned at the left. On the right, there is a scrollable vertical list of multiple Storylines glyphs, one per location. Storyline glyphs are linked to their associated location in the map with a gray link. Users can scroll vertically to see the different storylines. Each time a location is selected on the map, an animation puts the corresponding storyline in the center of the view.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Tasks</head><p>Similarly to HyperStorylines <ref type="bibr" target="#b38">[41]</ref>, we considered the Andrienko &amp; Andrienko task taxonomy for spatial and temporal data <ref type="bibr" target="#b3">[6]</ref>. Our goal was to include tasks from both reading levels of this taxonomy: elementary (about individual elements of the dataset) and synoptic (that require looking at the entire dataset or a subset of it). We started with the spatial relationships used in the workshop (distance, direction, adjacency, coverage, hierarchy -Sect. 3.1), which can be categorized as synoptic. To include elementary tasks, we added two baseline tasks, inspired by the basic tasks used to evaluate PAOHViz <ref type="bibr" target="#b52">[55]</ref> and HyperStorylines <ref type="bibr" target="#b38">[41]</ref>: "find all relationships between person A and person B". In our case, this requires users to find either all the locations or all the dates involved in the relationships between a set of people.</p><p>Finally, after an initial pilot we realized that the strategies to perform the tasks coverage and hierarchy were very similar to the baseline task of identifying all locations involved in a set of relationships. Therefore, we only kept the simpler task of identifying locations (next described as Baseline Locations) to reduce the duration of the study. We thus tested the following tasks:</p><p>-[T1] Baseline Locations: "In how many different locations did person A and B meet?" (numeric answer). This task is an elementary look-up as it requires participants to find a set of individual targets (locations) given a set of references (people).</p><p>-[T2] Baseline Time : "On how many different dates did person A and B met in location L?" (numeric answer). Similar to the previous one, this is also a elementary look-up task.</p><p>-[T3] Distance : "In which location did person A and B meet that is closest to location L?" (answer is a location's name). This is a elementary comparison task as it requires participants to compare the distance of a set of individual locations in relation to an specified one.</p><p>-[T4] Direction: "Which direction did person A and B follow when they met?" The answer to this task can be: north-south, southnorth, west-east, east-west, or no pattern. This is a synoptic relationseeking task that requires participants to see the overall trajectory two people followed.</p><p>-[T5] Adjacency: "Did person A and B move only between adjacent locations?" Binary answer between "Yes, they move only between adjacent locations" and "No, there one or more jumps in their path". This is a synoptic relation-seeking task, as it requires participants to observe the overall pattern and check for neighboring locations linked to the two central people across time steps.</p><p>We explain why we focus on relationships between two people in the dataset creation method (Sect. 5.5).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Hypotheses</head><p>We describe next our formulated hypotheses for our user study and the reasoning behind them:</p><p>[H1] Movement patterns -CoordV &gt; MapG &gt; TimeG Previous research shows that animations are better suited to identifying sudden changes in movements <ref type="bibr" target="#b11">[14,</ref><ref type="bibr" target="#b20">23,</ref><ref type="bibr" target="#b36">39]</ref>, followed by smallmultiples. Therefore, for the tasks that track movement (Direction and Adjacency) Coordinated Views should perform best, as it is essentially a user-controlled animation. Map Glyphs will follow as they behave similarly to small multiples. Finally, as Time Glyphs split time by location we expect participants will have trouble following the movement of people across several split timelines.</p><p>[H2] Identifying locations -CoordV &amp; TimeG &gt; MapG Designs with a single unified representation of space are better suited for tasks that require identifying all the locations linked to a group of people. We thus expect Coordinated Views and Time Glyphs to perform better in Distance and Baseline Locations. For Map Glyphs, the selection interaction may mitigate some of the challenges when searching all the locations across multiple mini-maps, but the small size of the map glyphs themselves may also impact performance.</p><p>[H3] Identifying dates -TimeG &gt; CoordV &amp; MapG As Time Glyphs group together all the relationships of one location, we expect it will perform better than the other two when identifying the dates when two people were linked with a location (Baseline Time).</p><p>[H4] Map Scalability -CoordV &gt; MapG &gt; TimeG We expect that all of the designs will suffer as we increase the number of locations shown in the maps. But Time Glyphs' performance will likely deteriorate the most, as more locations means participants will have to visually aggregate information across more separate timelines. We also expect that Map Glyphs will suffer more than Coordinated Views due to the small size of the mini-maps. Increasing the number of locations on such small maps risks making them illegible.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Experiment Design and Procedure</head><p>We used a within-participant study design, where participants are exposed to all three visualizations. For each technique, they performed 10 training trials (2 repetitions per task), and 5 measured tasks × 4 repetitions = 20 main trials. In total, the experiment consists of 18 participants × 3 visualizations × 20 main trials = 1080 main trials.</p><p>We counterbalanced technique and dataset presentation order using a Latin square. Additionally, we rotated the maps used in the trials by 0, 90 and 180 degrees across trials, to avoid participants learning the location patterns on the maps. Finally, the task presentation order, was randomly assigned for each participant.</p><p>The study was divided into three 30 min sessions, one per visualization. At the start of the first session, participants signed a consent form and completed a demographics questionnaire. The rest of the sessions have the same structure: (i) explanation, (ii) training and (iii) main trials. In the explanation phase, an experimenter described the visualization, and guided participants in exploring the available interactions. The training phase consists of ten trials, two per task. Participants are asked to think aloud while completing the trials in order for the experimenter to provide clarifications when needed. If participants failed to complete a training trial, or ignored tools available to them (e.g., selection interactions) the experimenter would provide help. Participants only continued with the main trials if they completed all the training ones.</p><p>In the main trials, participants carried out four repetitions for each of the five tasks, using different datasets than those in training. In this phase, participants solved the tasks without instruction and did not follow a think aloud protocol. They were asked to perform the tasks as accurately and quickly as possible. After each trial, participants were asked to rate how easy it was to solve the task and how confident they were about their answer. At the end of each session, participants were asked to explain their strategies. And at the end of all three sessions, they were asked to rank the three visualizations as a whole.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5">Datasets</head><p>To avoid learning effects between visualizations and tasks, we created a separate dataset for each trial: 10 for training (the same for all visualizations); and 60 for the main trials (20 main trials × 3 variations, assigned to visualizations using a Latin Square). To ensure realistic temporal relationship patterns, our datasets are extracted from real world data provided by the news agency OuestFrance <ref type="bibr" target="#b1">[4]</ref>. When entities of different types (people, locations) appear together in an article, this co-occurrence represents a relationship <ref type="bibr" target="#b38">[41]</ref>.</p><p>To make the study tractable our trials focused on data for two central people, adding another eight secondary people that were connected to them as distractors (i.e. a total of 10 people per dataset). This matches the use-case from data journalism described in the introduction, where we can assume one has filtered their dataset to focus and follow two rival politicians. This total number of people allowed us to compare the basic properties of the designs, without considering the impact of searching or filtering functionality. Similar to previous studies <ref type="bibr" target="#b9">[12,</ref><ref type="bibr" target="#b36">39]</ref>, we consider 35 time steps with one or more relationships per date. On average, an extracted dataset has 36 relationships (SD = 1), 10 of these are between the two central people (i.e., 28% of the dataset on average).</p><p>We manually generated two spatial patterns for each of the five tasks. Each of these patterns were later projected into two maps of different size (one with 23 locations and the other with 59). This prevented participants from learning the answer for each task, and allowed us to test the geographic scalability of the designs. We replaced the original locations that dealt with regions in France with locations in maps unlikely to be known by participants, as did Beecham et al. <ref type="bibr" target="#b7">[10]</ref>.</p><p>Details of the dataset construction are available in supp. material. They include the scripts to generate the datasets, the maps, the spatial patterns and solutions, as well as steps taken to ensure trials were visually different but of equivalent difficulty across visualizations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.6">Participants &amp; Apparatus</head><p>We recruited 18 participants, from 24 to 45 years old (mean = 28, SD = 4.8). None of them had participated in our design workshops. Five identified themselves as women and 13 as men. Seven of them had a background in HCI, six in visualisation, and five in other areas that included geology, data science or quantum computing. We aimed for a mix of participant backgrounds in order to elicit different types of feedback: participants with an HCI background can identify general usability issues, participants with a Vis background can provide a general critique of visual analytics systems, and participants with broader backgrounds represented a more general user population. 17 participants had normal, or corrected-to-normal vision. One reported color vision deficiency with the red component of colors, however, our color selection was such that they could conduct the study normally. Participants did not receive any monetary compensation.</p><p>We conducted the experiment on a Macbook Pro with a 27" Apple Thunderbolt Display (2560x1440 pixels). The system and visualizations were implemented in the Django framework [3] and Javascript respectively. The visualizations additionally use D3.js [2], and a publicly available Storyline layout algorithm <ref type="bibr" target="#b0">[1]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.7">Measures</head><p>We collect four primary measures per trial: -Completion time: time in milliseconds from the moment a participant is presented with a task to when they select an answer.</p><p>-Error rate: percentage of incorrect answers per task.</p><p>-Self-reported confidence: a 5-point Likert scale (Highly not confident, Not confident, Neutral, Confident, and Highly confident).</p><p>-Self-reported easiness to do the task: as a 5-point Likert scale (Very hard, Hard, Neutral, Easy, Very easy).</p><p>Additionally, we collected participants' strategies per task, their overall feedback and preference of the three designs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">RESULTS OF COMPARATIVE STUDY</head><p>We report and interpret our results of Completion Time and Error Rate using interval estimation <ref type="bibr" target="#b13">[16,</ref><ref type="bibr" target="#b16">19]</ref>. Sample means of 95% confidence intervals (CIs) are constructed using BCa bootstrapping (10,000 bootstrap iterations). No p-values are reported, but they can be obtained from CI results <ref type="bibr" target="#b26">[29]</ref>. When interpreting results, a CI that does not overlap with 0 provides evidence of a difference, corresponding to statistically significant results in traditional p-value tests. Nonetheless, CIs allow for more subtle interpretations: the farther from 0 and the tighter the CI is, the stronger the evidence. For self-reported confidence and easiness to complete the tasks, we only report means. All analyses were planned before collecting the data, and the study was preregistered <ref type="bibr" target="#b12">[15]</ref> with the Open Science Framework<ref type="foot" target="#foot_0">2</ref> . We removed one trial from our analysis due to a technical problem. Analysis scripts, collected data (quantitative and qualitative), and detailed CIs can be found in supp.material.    0 and the tighter the CI, the stronger the evidence). Inconclusive evidence (barely touching 0) is not reported in text, but marked with as it may represent trends. The 3rd column shows the percentage of trials that participants reported being Very easy ( ) to complete, to very hard ( ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Overall performance for tasks collectively</head><p>For all tasks collectively, mean times are lower for Coordinated Views (23.2s), than for Time Glyphs (33.55s) and Map Glyphs (35.55s).</p><p>There is evidence of Coordinated Views being faster than both Map Glyphs (by 12.35s on avg. CI[8.77:17.75]) and Time Glyphs (by 10.34s on avg. CI[7.92:12.66]). Although mean Error Rate is also lower for Coordinated Views (1.39%), followed by Map Glyphs (1.67%) and Time Glyphs (3.33%), there is no evidence of difference between the techniques. Self-reported confidence is high for the three techniques in more than 90% of the trials. Self-reported easiness to complete the task is high for 90% of the trials when using Coordinated Views, and 76% of the trials for Time Glyphs and Map Glyphs. The overall ranking was consistent with performance results: 15/18 participants ranked Coordinated Views as being best overall, followed by 5/18 raking Map Glyphs (participants were allowed to rank more than one technique as best).</p><p>No participant ranked Time Glyphs as best. The results dis-aggregated by task (next) give more insights of these differences. From now on we do not report self-reported confidence as it is high for more than 80% of all trials, for all tasks and visualizations (see supp.material).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Results per working hypothesis</head><p>We analyze results for each task individually and group them by our initial hypotheses, displayed in gray next to them. Fig. <ref type="figure" target="#fig_5">3</ref> shows an overview of our results per task and technique. We do no report inconclusive evidence in the text (CIs that barely cross 0), but we highlight them in our image as it could indicate interesting trends for future study.</p><p>[H1] Movement patterns -CoordV &gt; MapG &gt; TimeG For both tasks that analyzed movement, Direction and Adjacency, there is evidence that Coordinated Views are faster than both Map Glyphs and Time Glyphs. Additionally, there is evidence that Map Glyphs are faster than Time Glyphs in the Direction task (consistent with our hypothesis). There is no evidence of difference for Error Rate for these two tasks. Self-reported easiness to complete the task using Time Glyphs was lower than with the other two designs, while easiness was consistently higher with Coordinated Views.</p><p>There is support for H1 as Coordinated Views are faster than the other two designs without being more prone to errors, and Map Glyphs are faster than Time Glyphs in one task. Participants mentioned that Map Glyphs required a lot of scrolling to explore the whole timeline, explaining why they were slower than Coordinated Views. Additionally, the gaps between the mini maps on the storyline required participants to rely on their memory of already visited mini maps in order to follow a movement pattern (10/18 participants commented on this issue). Time Glyphs required participants to select and unselect dates in chronological order to see the evolution of the dynamic pattern across all storylines. This involved a lot of selection actions and participants had to rely on their memory, as they would continuously switch focus between the map and dates (11/18 participants commented about this).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>[H2] Identifying locations -CoordV &amp; TimeG &gt; MapG</head><p>There is evidence that Coordinated Views are faster than Map Glyphs and Time Glyphs for tasks that require users to observe geographical entities (Baseline Locations and Distance). There is also evidence that Map Glyphs are faster than Time Glyphs in the Baseline Locations task. For Error Rate, Time Glyphs are less prone to errors than Coordinated Views for the Baseline Locations task, and Map Glyphs are less prone to errors than Time Glyphs in the Distance task.</p><p>We have partial support for H2. Coordinated Views are the fastest, but Time Glyphs are more accurate in Baseline Locations. What is surprising is that Map Glyphs were not the worst: they were either faster or less error prone than Time Glyphs in these tasks, and were even more accurate than Coordinated Views in Baseline Locations. We were surprised that participants were 100% accurate only with Map Glyphs. In our hypothesis we assumed that a single big map (Coordinated Views and Time Glyphs) would help participants to identify and compare locations more easily than several small ones (Map Glyphs).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>[H3] Identifying dates -TimeG &gt; CoordV &amp; MapG</head><p>There is strong evidence that Map Glyphs are slower than both Coordinated Views and Time Glyphs for the task of Baseline Time. There is also evidence that Time Glyphs are slower than Coordinated Views. Regarding Error Rate, there is evidence that Coordinated Views were less prone to errors than Map Glyphs. Self-reported easiness to complete the task for Map Glyphs was high for a lower number of trials than the other two (only 57%).</p><p>There is no support for H3 as Coordinated Views performed best in this task. Our hypothesis was based on the fact that Time Glyphs group all relationships for a location in one timeline. Therefore, the best strategy was to first select the location of interest and then the two people. However, only 2 participants used the optimized strategy consistently during the trials, 5 only used it during some of the trials and 8 used it only during training. We believe this result is due the fact that our tasks were designed to mainly focus on the behavior of two people, and not on particular locations. Thus our participants adopted a global strategy that was ineffective for this task.</p><p>[H4] Map Scalability -CoordV &gt; MapG &gt; TimeG When looking at how map size affected each technique, we found no evidence of a differences for Map Glyphs. For Time Glyphs there seems to be a time/accuracy trade-off: tasks on smaller maps led to more errors but were faster. Most surprising, in Coordinated Views performance using small maps was worst both for time and errors. We thus did not find support for H4, as it seems that smaller maps either were not easier or were in fact worst. For detailed CIs see supp.material.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">FEEDBACK FROM DOMAIN EXPERTS</head><p>We complemented the results of our user study with feedback from domain experts that analyse geo-temporal relationships. We conducted two workshops in the context of a long term collaboration with Ouest France <ref type="bibr" target="#b1">[4]</ref>, the most read francophone newspaper in the world (see work on HyperStorylines <ref type="bibr" target="#b38">[41]</ref>). In a first informal workshop (7 investigative journalism practitioners) that lasted 1h, experts expressed their interest in combining storylines with maps in order to analyse the movement and relationships of politicians. They even suggested the generalization of the concept by linking storylines with other 2D visualizations (for example a thematic map instead of a geographical one).</p><p>We then conducted a structured 1.5h workshop with three investigative journalism practitioners (more than 10 years of experience each). We asked our domain experts to explore their own data using the three final Geo-Storylines designs. The dataset they provided contained a set of news articles about a famous local politician who, over time, changed the region they represented in local elections. It contained 32 articles with 102 people entities over the span of 4 years. The map showed 1272 locations (communes). The dataset is not publicly available due to a confidentiality agreement.</p><p>We provided brief descriptions of each visualization and then let them explore their dataset. To help guide the exploration, we asked them (in each vis) if they can describe the overall movement of the protagonist politician. One participant (P1) interacted with the system and the other two (P2,3) suggested actions and provided comments.</p><p>In Coordinated Views, P1 was able to quickly identify the overall trajectory of the politician. P1 and P2 explained it was very helpful to have a mix of a storyline and a map, as it helped them to explore the dataset starting either with people or locations of interest. Even though they were able to find the overall movement pattern, they requested more explicit ways to see the patterns. For example, P1 suggested adding arrows on the map to show explicit movement, and a "play" button to provide automatic scrolling of the timeline. P3 requested the addition of a mechanism to extract several important stories, e.g., extract the relationships between the top 1-2 most connected politicians.</p><p>Although Time Glyphs performed worse than Coordinated Views in our study, experts appreciated its ability to show stories per commune / location. P1 commented (and the others agreed): "It's hard to see the <ref type="bibr">[person's]</ref> story, but we can see clearly the articles for each location which is very important when analysing local news." Both P1 and P2 requested to completely filter out (remove) the storylines of uninteresting locations. Finally, all experts mentioned how Time Glyphs and Coordinated Views are complementary, and both are useful depending on the focus of the exploration (politicians vs. local councils/politics).</p><p>Participants found Map Glyphs somewhat overwhelming. Given the large number of communes (more than 1200 locations), each location ended up being very small in the map glyphs, thus it was hard to see which communes were involved in several relationships. Our participants requested some form of geographic aggregation. P1 commented: "It would be interesting to choose the zoom level [geographical granularity] of the visualization". After exploring some more, P1 and P2 mentioned that one article per relationship was too much information, as each relationship introduced a new map glyph in the visualization. They suggested to filter or aggregate relationships by time.</p><p>Participants were overall very enthusiastic about the exploration potential of the visualizations, and at the end of the session they requested an open link to the software to continue exploring their data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">DISCUSSION, LIMITATIONS &amp; FUTURE WORK</head><p>We discuss next the results of our study and feedback from experts on the three most promising geo-storyline designs. Then we take a step back to consider the limitations of our study and design space.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.1">Study Results and Expert Feedback</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.1.1">Identifying entities and overall navigation</head><p>Coordinated Views performed well when considering all study tasks combined, likely because it presents a more compact timeline than the other two designs. Issues mentioned by our study participants and journalism experts can start explaining these results.</p><p>Map Glyphs do not offer an overview of the data as the storyline expands to accommodate the map glyphs, so participants had to scroll a lot to do the tasks. Five study participants commented on this lack of overview for Map Glyphs (versus only two for Time Glyphs and none for Coordinated Views). Some mentioned specifically too much scrolling being an issue: eight for Map Glyphs, versus two for Coordinated Views and one for Time Glyphs. Our domain experts also commented on the clutter of the Map Glyphs design that makes it hard to follow the entity relationships. We can think of several ways to improve Map Glyphs in this regard. First, we can allow users to customize the size of the mini-maps, adjusting the importance the geographical context has in the view. However, it is possible that users would like to focus on a particular set of relationships so the importance of the mini-maps might not be the same across the timeline. Therefore, an alternative could be to make the relationships (and thus mini-maps) collapsible by default and only open on demand, in a way similar to nested entities in HyperStorylines <ref type="bibr" target="#b38">[41]</ref>. Or, as some domain experts suggested, to aggregate relationships over time (over a week or a month) thus reducing the number of required mini-maps.</p><p>In our study, finding a particular person with Time Glyphs takes longer as people's names are scattered over the different timeline glyphs. Indeed, six participants had at least one comment about this drawback (versus two participants for Map Glyphs and only one for Coordinated Views). We believe it is hard to improve this design without applying general strategies like adding a list of entities or a search option. Nevertheless, we did note this design was less error-prone than Coordinated Views when it came to identifying and counting locations themselves. Contrary to the study results, our domain experts really appreciated that when using Time Glyphs they could focus on the story of specific locations (focusing on local news and politics). They explained that Time Glyphs and Coordinated Views are complementary designs.</p><p>We were surprised to see that Map Glyphs, which have small map representations, reported no errors in the tasks related to identifying locations in our study (Baseline Locations and Distance), and weree more accurate than the other two designs (including Coordinated Views). It is possible that seeing fewer details of the maps allowed participants to be less distracted by their geographic details. However map size was an issue for our experts with this design: as their dataset contained a very large number of locations (more than a thousand) the mini maps were too cluttered and locations too small to interact with.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.1.2">Understanding Movement Patterns</head><p>Coordinated Views performed well in the two tasks related to movement patterns (Direction and Adjacency). As the horizontal scrolling simulates an animation of the geographical pattern, our results are aligned with our hypotheses and previous work that have shown that sudden changes are better detected with animation <ref type="bibr" target="#b11">[14,</ref><ref type="bibr" target="#b20">23,</ref><ref type="bibr" target="#b36">39]</ref>. Our domain experts confirmed this, requesting automatic scrolling (play an animation) on demand of the entire timeline. Both study participants and our experts found navigation with Map Glyphs to be hard and tedious as the resulting timeline is bigger than the other two designs. In addition, the mini-maps are dispersed across the timeline, and the gaps between them makes their sequential comparison (to follow a pattern) harder. The collapsable or aggregated mini-maps mentioned earlier can improve this issue by bringing them closer for comparison. However, we hypothesize that it will remain less efficient than Coordinated Views.</p><p>Time Glyphs required participants to shift their focus across regions of the visualization to follow the entities of interest. The best strategy was to select the dates in chronological order to highlight the locations associated to each time step, switching focus between the dates and the map. This process can be improved by implementing an animation option in the interface that automatically highlights progressively the dates and associated locations for the selected people. We hypothesize this would make Time Glyphs comparable to Coordinated Views for observing movement patterns, but this remains future work. We note nonetheless, that experts felt Time Glyphs excelled in cases where the focus is on local news (small number of locations). It is likely that our study tasks did not reflect well this real-world need.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.1.3">Number of locations and map complexity</head><p>We expected that the number of locations would impact performance, in particular for Map Glyphs that use small maps to begin with. Surprisingly we only saw clear evidence of a difference between the two types of maps in Coordinated Views, where trials using the smaller map with fewer locations was in fact more prone to errors. While further experimentation is needed, we feel this may be due to the nature of the chosen maps: our small map may have been more visually complex, as it includes locations of very different sizes (including some very small ones) and water features that participants could have confused with locations. Further studies are needed where more diverse metrics of geographical complexity are used to measure this effect, e.g., geometric irregularity <ref type="bibr" target="#b7">[10,</ref><ref type="bibr" target="#b22">25]</ref>. Feedback from our domain experts provided more insights on scalability, as they used the visualizations with maps of more than a 1000 locations. Our experts did not raise any issues with Coordinated Views. For Time Glyphs they communicated the need to filter out unused location storylines to reduce clutter. More importantly, they found location scalability to be an issue for Map Glyphs, as locations become too small to interact with. They suggested aggregating geographical locations, allowing semantic zooming to see content at different granularity (e.g., region vs. country), thus reducing the number of locations on mini-maps, making them more readable.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.2">Study: Discussion &amp; Limitations</head><p>For our evaluation, we chose three representative designs that could easily accommodate several people, locations and temporal relationships, without the need to aggregate any of these entities. Even though our datasets had 35 timesteps (comparable to previous work <ref type="bibr" target="#b9">[12,</ref><ref type="bibr" target="#b36">39]</ref>), the number of people in our tasks <ref type="bibr" target="#b7">(10)</ref> was smaller than that of previous work focusing on entity relationships (HyperStorylines <ref type="bibr" target="#b38">[41]</ref>: around 529 entities, or PAOHVis <ref type="bibr" target="#b52">[55]</ref>: 57-371 people). This was a deliberate decision, as it allowed us to compare the benefits and drawbacks of the basic designs, without adding search and filtering interactions (which were necessary in previous work with more entities <ref type="bibr" target="#b38">[41,</ref><ref type="bibr" target="#b52">55]</ref>).</p><p>Nevertheless, in real analysis situations our designs would have to handle larger numbers of people or locations, as our expert feedback demonstrated. We could envision only transitioning to the geo-spatial views after the data has been filtered, as it was suggested by our domain experts (e.g., focusing on the most connected politicians). But more interesting yet would be to consider aggregation, to provide meaningful overviews: our experts suggested aggregating relationships over time to handle the number of relationships, and geographical aggregation of cities/regions/countries to handle large number of locations. It is interesting to note that our experts raised these scalabilty issues mainly for Map Glyphs. Further research is required to determine the best aggregation methods of entities evolving over time <ref type="bibr" target="#b39">[42]</ref>, how to allow viewers to determine the required level of detail on the fly, and how our design space can accommodate such aggregations.</p><p>Our study tasks focus on people whose relationships follow five specific spatial patterns. We removed the patterns Hierarchy and Coverage as the strategies adopted in our pilots were similar to our task Baseline Locations. However, if we consider explicit aggregations to deal with scale, it is likely that the strategies for some of these tasks may diverge (e.g., Hierarchy). While our chosen tasks cover a wide range of patterns from the related work, it is possible that they may have biased against some of our techniques. For example, Time Glyphs could have been more efficient for questions that focus on the co-occurrence of locations. This is supported by feedback from our experts that found Time Glyphs very useful for focusing on news articles (relationships) from specific regions. More generally, it remains future work to investigate whether our results hold for patterns about other types of entities (not just people), as well as more complex movement patterns (more central people, more relationships, etc.), especially since these would require filtering and aggregation options as discussed above.</p><p>Finally, 2/3 of the participants of our user study had an HCI or visualization background. These participants could be considered as experts in the use of interactive systems, and thus find the tools easier to use than the general public. So we complemented our results with feedback from domain experts in data journalism. Further work can explore the use of these designs in other domains or general public use.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.3">Design space: Discussion &amp; Limitations</head><p>When organizing the workshop we provided participants with inspiration visualizations that were not necessarily storyline or timeline centered. Nevertheless, a large number of participant sketches naturally converged to such representations, confirming the ability of storylines to convey temporal relationships. We did categorize all sketches from the workshop, but for our design space we kept ones that could accommodate multiple people and their relationships (often as timelines), but also provide geo-spatial context in the form of a map, rather than an abstract representation of space (like a chart indicating distance).</p><p>In our designs, maps are divided in regions. As discussed, this fixed level of granularity may not always be appropriate, as geo-spatial navigation could adapt the content depending on zoom level (semantic zooming). Future work should extend the design space to accommodate transitions between different levels of geo-spatial granularity. For example, in Time Glyphs, the storylines for countries can be split into storylines for cities as a response to zooming-in. Or in Map Glyphs and Coordinated Views, regions can be semantically merged or split to the level of cities, regions or countries as the user zooms out or in.</p><p>Our design space did not consider interactions and we implemented basic interaction support (scroll, selection). Nevertheless, the changes in granularity discussed above require interaction mechanisms, like semantic zooming, interactively choosing appropriate levels of aggregation per entity, and animated transitions. This, combined with user requests for filtering and switching views, points to the need for future design spaces and user studies that consider advanced interaction and animated transitions. This may require revisiting some of the discarded designs of the design space that rely on aggregation.</p><p>Our aim was to provide geo-spatial context into storylines, which naturally limits our designs to representations of "space" that are geographical maps. But our design space can be extended to combine storylines with other 2D visualizations that represent space or different dimensions. Consider for example scatterplots or treemaps. As long as the definition of a region is possible (a treemap cell, a scatterplot selection or cluster), then our designs can combine these 2D visualizations with storylines. For example, we can envision customizable timelines that are created after a manual selection over a scatterplot similarly to Attribute Signatures <ref type="bibr" target="#b51">[54]</ref>, resembling our Time Glyphs design but focusing on the selected area. Or instead of a geographical map, Coordinated Views and Map Glyphs may show a treemap, highlighting the relevant cells. Nevertheless, if the number of 2D regions is large, or the regions themselves are small, some designs from our design space will suffer: for example it will be challenging to create one storyline per point in a scatterplot (Time Glyphs), or highlight individual scatterplot points in a small 2D glyph embedded in a large storyline (Map Glyphs).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9">CONCLUSIONS</head><p>We presented Geo-Storylines, a set of designs to integrate maps into Storyline visualizations. We report on a sketching workshop used to derive a design space for their creation, the arguments to select the three more promising designs, and the results of a user study and expert feedback that compares them. Our study shows that, overall, Coordinated Views were more efficient and preferred than the other two designs. Surprisingly, although Map Glyphs reported no errors in the user study, they were hard to use with a real-world dataset. Finally, even though Time Glyphs did not outperform other techniques in our user study when focusing on a particular location, they were highly appreciated by our expert users. Our work illustrates how Storyline visualizations can be effectively extended to incorporate 2D information, including maps, improving their already considerable expressive power.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 :</head><label>1</label><figDesc>Fig. 1: Three Geo-Storyline designs showing the geo-temporal evolution of the relationships between people. The two selected people in blue moved together from north to south. (A) Coordinated Views include a map on the left and a unique Storyline timeline on the right. While scrolling, links appear between the relationship nearest to the map and the associated locations. (B) In Map Glyphs each relationship is represented by a map with the associated locations drawn in orange. (C) Time Glyphs are composed by a map on the left and a scrollable list of Storyline glyphs on the right. Each Storyline glyph contains all the relationships associated with one location. Gray lines between a location on the map and a storyline glyph indicate the correspondence between the two.</figDesc><graphic url="image-1.png" coords="1,225.38,135.93,147.16,80.86" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 :</head><label>2</label><figDesc>Fig. 2: Design space. The central part of the image provides an overview of the design space, with the six representative designs selected from the analysis of our sketching workshop (A-E,H). The two representative designs indicated with a gray border (F,G) were added later to fill gaps in the design space. Surrounding the design space are sketches from each of the clusters identified in the workshop, that inspired the different representative designs. The cluster names are indicated above the sketches, and the number of sketches in them below in gray.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 3 :</head><label>3</label><figDesc>Fig. 3: Completion Time (sec), Error Rate (in %) and mean self-reported easiness per visualization per task. In each row (task) for the first two measures, mean values per visualization are seen on the left and means of pairwise differences on the right. Error bars represent 95% Bootstrap confidence intervals. Gray rectangles indicate the direction of our hypotheses. Evidence of differences is marked with a * (the further away from</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>• Anastasia Bezerianos is with Université Paris-Saclay, CNRS, Inria. E-mail:</figDesc><table /><note>anastasia.bezerianos@universite-paris-saclay.fr Manuscript received xx xxx. 201x; accepted xx xxx. 201x. Date of Publication xx xxx. 201x; date of current version xx xxx. 201x. For information on obtaining reprints of this article, please send e-mail to: reprints@ieee.org. Digital Object Identifier: xx.xxxx/TVCG.201x.xxxxxxx</note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_0">https://osf.io/5wnyg</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<idno>31.03.2021</idno>
		<ptr target="https://github.com/abcnews/d3-layout-narrative" />
		<title level="m">D3 layout narrative</title>
				<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Ouest</forename><surname>France</surname></persName>
		</author>
		<idno>31.03.2021</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<ptr target="https://www.abc.net.au/news/2015-12-16/star-wars-every-scene/7013826.Lastac-cessed:01.07.2022" />
		<title level="m">Star wars: every scene from i-vi charted</title>
				<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Exploratory analysis of spatial and temporal data: a systematic approach</title>
		<author>
			<persName><forename type="first">N</forename><surname>Andrienko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Andrienko</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006">2006</date>
			<publisher>Springer Science &amp; Business Media</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">The &quot;y&quot; of it matters, even for storyline visualization</title>
		<author>
			<persName><forename type="first">D</forename><surname>Arendt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Pirrung</surname></persName>
		</author>
		<idno type="DOI">10.1109/VAST.2017.8585487</idno>
	</analytic>
	<monogr>
		<title level="m">2017 IEEE Conference on Visual Analytics Science and Technology (VAST)</title>
				<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="81" to="91" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A descriptive framework for temporal data visualizations based on generalized space-time cubes</title>
		<author>
			<persName><forename type="first">B</forename><surname>Bach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Dragicevic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Archambault</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Hurter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Carpendale</surname></persName>
		</author>
		<idno type="DOI">10.1111/cgf.12804</idno>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics Forum</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="36" to="61" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Storyline visualizations of eye tracking of movie viewing</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">T</forename><surname>Balint</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Arendt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">M</forename><surname>Blaha</surname></persName>
		</author>
		<idno type="DOI">10.1109/ETVIS.2016.7851163</idno>
	</analytic>
	<monogr>
		<title level="m">2016 IEEE Second Workshop on Eye Tracking and Visualization (ETVIS)</title>
				<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="35" to="39" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Map LineUps: Effects of spatial structure on graphical inference</title>
		<author>
			<persName><forename type="first">R</forename><surname>Beecham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Dykes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Meulemans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Slingsby</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Turkay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wood</surname></persName>
		</author>
		<idno type="DOI">10.1109/TVCG.2016.2598862</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="391" to="400" />
			<date type="published" when="2017-01">Jan. 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<author>
			<persName><forename type="first">C</forename><surname>Berge</surname></persName>
		</author>
		<title level="m">Hypergraphs: combinatorics of finite sets</title>
				<imprint>
			<publisher>Elsevier</publisher>
			<date type="published" when="1984">1984</date>
			<biblScope unit="volume">45</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">A qualitative study on the exploration of temporal changes in flow maps with animation and smallmultiples</title>
		<author>
			<persName><forename type="first">I</forename><surname>Boyandin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Bertini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Lalanne</surname></persName>
		</author>
		<idno type="DOI">10.1111/j.1467-8659.2012.03093.x</idno>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics Forum</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">3pt2</biblScope>
			<biblScope unit="page" from="1005" to="1014" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Timelines revisited: A design space and considerations for expressive storytelling</title>
		<author>
			<persName><forename type="first">M</forename><surname>Brehmer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Bach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">H</forename><surname>Riche</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Munzner</surname></persName>
		</author>
		<idno type="DOI">10.1109/TVCG.2016.2614803</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="2151" to="2164" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">A comparative evaluation of animation and small multiples for trend visualization on mobile phones</title>
		<author>
			<persName><forename type="first">M</forename><surname>Brehmer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Isenberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">K</forename><surname>Choe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="364" to="374" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Hark no more: On the preregistration of chi experiments</title>
		<author>
			<persName><forename type="first">A</forename><surname>Cockburn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Gutwin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Dix</surname></persName>
		</author>
		<idno type="DOI">10.1145/3173574.3173715</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems, CHI &apos;18</title>
				<meeting>the 2018 CHI Conference on Human Factors in Computing Systems, CHI &apos;18</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">141</biblScope>
			<biblScope unit="page" from="1" to="141" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">The new statistics: Why and how</title>
		<author>
			<persName><forename type="first">G</forename><surname>Cumming</surname></persName>
		</author>
		<idno type="DOI">10.1177/0956797613504966</idno>
	</analytic>
	<monogr>
		<title level="j">Psychological Science</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="7" to="29" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Storyline visualizations with ubiquitous actors</title>
		<author>
			<persName><forename type="first">E</forename><surname>Di Giacomo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Didimo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Liotta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Montecchiani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Tappini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Graph Drawing and Network Visualization</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<imprint>
			<publisher>Springer International Publishing</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="324" to="332" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Towards a taxonomy of movement patterns</title>
		<author>
			<persName><forename type="first">S</forename><surname>Dodge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Weibel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A.-K</forename><surname>Lautenschütz</surname></persName>
		</author>
		<idno type="DOI">10.1057/PALGRAVE.IVS.9500182</idno>
	</analytic>
	<monogr>
		<title level="j">Information Visualization</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">3-4</biblScope>
			<biblScope unit="page" from="240" to="252" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Fair statistical communication in HCI</title>
		<author>
			<persName><forename type="first">P</forename><surname>Dragicevic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Modern Statistical Methods for HCI</title>
				<editor>
			<persName><forename type="first">J</forename><surname>Robertson</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Kaptein</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham, Switzerland</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="291" to="330" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Diffusion of lexical change in social media</title>
		<author>
			<persName><forename type="first">J</forename><surname>Eisenstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">T</forename><surname>O'connor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">P</forename><surname>Xing</surname></persName>
		</author>
		<idno type="DOI">10.1371/journal.pone.0113114</idno>
	</analytic>
	<monogr>
		<title level="j">In PloS one</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">T</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Arya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Streeb</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Seebacher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Keim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Worring</surname></persName>
		</author>
		<idno type="DOI">10.1109/TVCG.2020.3030408</idno>
		<title level="m">Visual analytics for temporal hypergraph model exploration. IEEE Transactions on Visualization and Computer Graphics</title>
				<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="550" to="560" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Towards a survey on static and dynamic hypergraph visualizations</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">T</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Frings</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Keim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Seebacher</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">A comparison of animated maps with static small-multiple maps for visually identifying space-time clusters</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">L</forename><surname>Griffin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Maceachren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Hardisty</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Steiner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Li</surname></persName>
		</author>
		<idno type="DOI">10.1111/j.1467-8306.2006.00514.x</idno>
	</analytic>
	<monogr>
		<title level="j">Annals of the Association of American Geographers</title>
		<imprint>
			<biblScope unit="volume">96</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="740" to="753" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Crossing minimization in storyline visualization</title>
		<author>
			<persName><forename type="first">M</forename><surname>Gronemann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Jünger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Liers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Mambelli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Graph Drawing and Network Visualization</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<imprint>
			<publisher>Springer International Publishing</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="367" to="381" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Strategies for detecting difference in map line-up tasks</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Haider</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Pohl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Beecham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Dykes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Human-Computer Interaction -INTERACT 2021</title>
				<editor>
			<persName><forename type="first">C</forename><surname>Ardito</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Lanzilotti</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Malizia</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Petrie</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Piccinno</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><surname>Desolda</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">K</forename><surname>Inkpen</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer International Publishing</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="558" to="578" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Let&apos;s get physical: Promoting data physicalization in workshop formats</title>
		<author>
			<persName><forename type="first">S</forename><surname>Huron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Gourlet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Hinrichs</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Hogan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Jansen</surname></persName>
		</author>
		<idno type="DOI">10.1145/3064663.3064798</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 Conference on Designing Interactive Systems, DIS &apos;17</title>
				<meeting>the 2017 Conference on Designing Interactive Systems, DIS &apos;17<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1409" to="1422" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Visual exploration of changes in passenger flows and tweets on mega-city metro network</title>
		<author>
			<persName><forename type="first">M</forename><surname>Itoh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Yokoyama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Toyoda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Tomita</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kawamura</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kitsuregawa</surname></persName>
		</author>
		<idno type="DOI">10.1109/TBDATA.2016.2546301</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Big Data</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="85" to="99" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Tracing genealogical data with timenets</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">W</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">K</forename><surname>Card</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Heer</surname></persName>
		</author>
		<idno type="DOI">10.1145/1842993.1843035</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Advanced Visual Interfaces, AVI &apos;10</title>
				<meeting>the International Conference on Advanced Visual Interfaces, AVI &apos;10<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="241" to="248" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Points of significance: Error bars</title>
		<author>
			<persName><forename type="first">M</forename><surname>Krzywinski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Altman</surname></persName>
		</author>
		<idno type="DOI">10.1038/nmeth.2659</idno>
	</analytic>
	<monogr>
		<title level="j">Nature Methods</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page">2013</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">A generic framework and library for exploration of small multiples through interactive piling</title>
		<author>
			<persName><forename type="first">F</forename><surname>Lekschas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Gehlenborg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Bach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Pfister</surname></persName>
		</author>
		<idno type="DOI">10.1109/TVCG.2020.3028948</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="358" to="368" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Storyflow: Tracking the evolution of stories</title>
		<author>
			<persName><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<idno type="DOI">10.1109/TVCG.2013.196</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2436" to="2445" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Animation plans for before-andafter satellite images</title>
		<author>
			<persName><forename type="first">M.-J</forename><surname>Lobo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Appert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Pietriga</surname></persName>
		</author>
		<idno type="DOI">10.1109/TVCG.2018.2796557</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics (TVCG)</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1347" to="1360" />
			<date type="published" when="2019-02">Feb 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">An effective demonstration for group collaboration based on storyline visualization technology</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>-Y. Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S.-B</forename><surname>Cao</surname></persName>
		</author>
		<idno type="DOI">10.1109/CSCWD.2014.6846815</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 IEEE 18th International Conference on Computer Supported Cooperative Work in Design (CSCWD)</title>
				<meeting>the 2014 IEEE 18th International Conference on Computer Supported Cooperative Work in Design (CSCWD)</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="47" to="52" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">A pandemic influenza modeling and visualization tool</title>
		<author>
			<persName><forename type="first">R</forename><surname>Maciejewski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Livengood</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Rudolph</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">F</forename><surname>Collins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">S</forename><surname>Ebert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">T</forename><surname>Brigantic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">D</forename><surname>Corley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">A</forename><surname>Muller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">W</forename><surname>Sanders</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.jvlc.2011.04.002</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of Visual Languages &amp; Computing</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="268" to="278" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Movie narrative charts</title>
		<author>
			<persName><forename type="first">R</forename><surname>Munroe</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009-06-28">2009. 28.06.2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Software evolution storylines</title>
		<author>
			<persName><forename type="first">M</forename><surname>Ogawa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K.-L</forename><surname>Ma</surname></persName>
		</author>
		<idno type="DOI">10.1145/1879211.1879219</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 5th International Symposium on Software Visualization, SOFTVIS &apos;10</title>
				<meeting>the 5th International Symposium on Software Visualization, SOFTVIS &apos;10<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="35" to="42" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Yarn: Generating storyline visualizations using htn planning</title>
		<author>
			<persName><forename type="first">K</forename><surname>Padia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">H</forename><surname>Bandara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">G</forename><surname>Healey</surname></persName>
		</author>
		<idno type="DOI">10.20380/GI2018.05</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 44th Graphics Interface Conference, GI &apos;18</title>
				<meeting>the 44th Graphics Interface Conference, GI &apos;18<address><addrLine>Waterloo, CAN</addrLine></address></meeting>
		<imprint>
			<publisher>Canadian Human-Computer Communications Society</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="26" to="33" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">A system for generating storyline visualizations using hierarchical task network planning</title>
		<author>
			<persName><forename type="first">K</forename><surname>Padia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">H</forename><surname>Bandara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">G</forename><surname>Healey</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.cag.2018.11.004</idno>
	</analytic>
	<monogr>
		<title level="j">Computers &amp; Graphics</title>
		<imprint>
			<biblScope unit="volume">78</biblScope>
			<biblScope unit="page" from="64" to="75" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">A comparison of geographical propagation visualizations</title>
		<author>
			<persName><forename type="first">V</forename><surname>Pe Ña Araya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bezerianos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Pietriga</surname></persName>
		</author>
		<idno type="DOI">10.1145/3313831.3376350</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems, CHI &apos;20</title>
				<meeting>the 2020 CHI Conference on Human Factors in Computing Systems, CHI &apos;20<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<biblScope unit="page">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">A Comparison of Visualizations for Identifying Correlation over Space and Time</title>
		<author>
			<persName><forename type="first">V</forename><surname>Pe Ña-Araya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Pietriga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bezerianos</surname></persName>
		</author>
		<idno type="DOI">10.1109/TVCG.2019.2934807</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<date type="published" when="2019-10">Oct. 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Hyperstorylines: Interactively untangling dynamic hypergraphs</title>
		<author>
			<persName><forename type="first">V</forename><surname>Pe Ña-Araya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Pietriga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Amsaleg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bezerianos</surname></persName>
		</author>
		<idno type="DOI">10.1177/14738716211045007</idno>
	</analytic>
	<monogr>
		<title level="m">formation Visualization</title>
				<imprint>
			<biblScope unit="volume">0</biblScope>
			<biblScope unit="page">0</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Integrating prior knowledge in mixed-initiative social network clustering</title>
		<author>
			<persName><forename type="first">A</forename><surname>Pister</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Buono</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-D</forename><surname>Fekete</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Plaisant</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Valdivia</surname></persName>
		</author>
		<idno type="DOI">10.1109/TVCG.2020.3030347</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1775" to="1785" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">Storytelling by the storycake visualization. The Visual Computer</title>
		<author>
			<persName><forename type="first">L</forename><surname>Qiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Bingjie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Haibo</surname></persName>
		</author>
		<idno type="DOI">10.1007/s00371-017-1409-2</idno>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="1241" to="1252" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Visualizing the evolution of community structures in dynamic social networks</title>
		<author>
			<persName><forename type="first">K</forename><surname>Reda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Tantipathananandh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Leigh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Berger-Wolf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics Forum</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1061" to="1070" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Influence of color and size of particles on their perceived speed in node-link diagrams</title>
		<author>
			<persName><forename type="first">H</forename><surname>Romat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Lebout</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Pietriga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Appert</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-29384-037</idno>
	</analytic>
	<monogr>
		<title level="m">Human-Computer Interaction -INTERACT 2019</title>
				<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer International Publishing</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="619" to="637" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Visualizing and interacting with geospatial networks: A survey and design space</title>
		<author>
			<persName><forename type="first">S</forename><surname>Schöttler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Pfister</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Bach</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Graphics Forum</title>
				<imprint>
			<publisher>Wiley Online Library</publisher>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Visualizing and interacting with geospatial networks: A survey and design space</title>
		<author>
			<persName><forename type="first">S</forename><surname>Schöttler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Pfister</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Bach</surname></persName>
		</author>
		<idno type="DOI">10.1111/cgf.14198</idno>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics Forum</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="5" to="33" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">An efficient framework for generating storyline visualizations from streaming data</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Tanahashi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C.-H</forename><surname>Hsueh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K.-L</forename><surname>Ma</surname></persName>
		</author>
		<idno type="DOI">10.1109/TVCG.2015.2392771</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="730" to="742" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Design considerations for optimizing storyline visualizations</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Tanahashi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K.-L</forename><surname>Ma</surname></persName>
		</author>
		<idno type="DOI">10.1109/TVCG.2012.212</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2679" to="2688" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Plotthread: Creating expressive storyline visualizations using reinforcement learning</title>
		<author>
			<persName><forename type="first">T</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Knittel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Koch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Ertl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<idno type="DOI">10.1109/TVCG.2020.3030467</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="294" to="303" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">istoryline: Effective convergence to hand-drawn storylines</title>
		<author>
			<persName><forename type="first">T</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Rubab</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<idno type="DOI">10.1109/TVCG.2018.2864899</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="769" to="778" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">A 3d visualization of multiple time series on maps</title>
		<author>
			<persName><forename type="first">S</forename><surname>Thakur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Hanson</surname></persName>
		</author>
		<idno type="DOI">10.1109/IV.2010.54</idno>
	</analytic>
	<monogr>
		<title level="m">2010 14th International Conference Information Visualisation</title>
				<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="336" to="343" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Extraction and visualization of poincare map topology for spacecraft trajectory design</title>
		<author>
			<persName><forename type="first">X</forename><surname>Tricoche</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Schlei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">C</forename><surname>Howell</surname></persName>
		</author>
		<idno type="DOI">10.1109/TVCG.2020.3030402</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="765" to="774" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Attribute signatures: Dynamic visual summaries for analyzing multivariate geographical data</title>
		<author>
			<persName><forename type="first">C</forename><surname>Turkay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Slingsby</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Hauser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wood</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Dykes</surname></persName>
		</author>
		<idno type="DOI">10.1109/TVCG.2014.2346265</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2033" to="2042" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Analyzing dynamic hypergraphs with parallel aggregated ordered hypergraph visualization</title>
		<author>
			<persName><forename type="first">P</forename><surname>Valdivia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Buono</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Plaisant</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Dufournaud</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-D</forename><surname>Fekete</surname></persName>
		</author>
		<idno type="DOI">10.1109/TVCG.2019.2933196</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="13" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Mobilitygraphs: Visual analysis of mass mobility dynamics via spatio-temporal graphs and clustering</title>
		<author>
			<persName><forename type="first">T</forename><surname>Landesberger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Brodkorb</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Roskosch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Andrienko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Andrienko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kerren</surname></persName>
		</author>
		<idno type="DOI">10.1109/TVCG.2015.2468111</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="11" to="20" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">A synoptic visualization framework for the multi-perspective study of biography and prosopography data</title>
		<author>
			<persName><forename type="first">F</forename><surname>Windhager</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Federico</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Salisu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Schlögl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Mayr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2nd IEEE VIS Workshop on Visualization for the Digital Humanities (VIS4DH&apos;17)</title>
				<meeting>the 2nd IEEE VIS Workshop on Visualization for the Digital Humanities (VIS4DH&apos;17)<address><addrLine>Phoenix, AZ, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">2017</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">A layout technique for storyline-based visualization of consecutive numerical time-varying data</title>
		<author>
			<persName><forename type="first">S</forename><surname>Yagi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Itoh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Takatsuka</surname></persName>
		</author>
		<idno type="DOI">10.1145/2801040.2801067</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 8th International Symposium on Visual Information Communication and Interaction, VINCI &apos;15</title>
				<meeting>the 8th International Symposium on Visual Information Communication and Interaction, VINCI &apos;15<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="156" to="157" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<monogr>
		<title level="m" type="main">Egocentric Analysis of Dynamic Networks with EgoLines</title>
		<author>
			<persName><forename type="first">J</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Glueck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Chevalier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Khan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016">2016</date>
			<publisher>Association for Computing Machinery</publisher>
			<biblScope unit="page" from="5003" to="5014" />
			<pubPlace>New York, NY, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
