<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Quick Clusters: A GPU-Parallel Partitioning for Efficient Path Tracing of Unstructured Volumetric Grids</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Nate</forename><surname>Morrical</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">SCI Institute</orgName>
								<orgName type="institution" key="instit2">University of Utah</orgName>
								<orgName type="institution" key="instit3">NVIDIA § Bilkent University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Alper</forename><surname>Sahistan</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">SCI Institute</orgName>
								<orgName type="institution" key="instit2">University of Utah</orgName>
								<orgName type="institution" key="instit3">NVIDIA § Bilkent University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">U</forename><surname>Gur Güdükbay</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">SCI Institute</orgName>
								<orgName type="institution" key="instit2">University of Utah</orgName>
								<orgName type="institution" key="instit3">NVIDIA § Bilkent University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Ingo</forename><surname>Wald</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">SCI Institute</orgName>
								<orgName type="institution" key="instit2">University of Utah</orgName>
								<orgName type="institution" key="instit3">NVIDIA § Bilkent University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Valerio</forename><surname>Pascucci</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">SCI Institute</orgName>
								<orgName type="institution" key="instit2">University of Utah</orgName>
								<orgName type="institution" key="instit3">NVIDIA § Bilkent University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Quick Clusters: A GPU-Parallel Partitioning for Efficient Path Tracing of Unstructured Volumetric Grids</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.2" ident="GROBID" when="2023-03-27T09:10+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Ray Tracing</term>
					<term>Path Tracing</term>
					<term>Volume Rendering</term>
					<term>Scientific Visualization</term>
					<term>Delta Tracking</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Fig. <ref type="figure">1</ref>: Using our method, we can render volumetric shadows on large unstructured datasets while maintaining interactive frame rates. As shown in the image above (top left is one sample per pixel (spp), bottom right is rendered to 4K spp), we can achieve up to 12 frames per second (fps) at 1 spp, at 22.2M rays per second (rps) on the 788M element Mars Lander dataset on a single workstation GPU-nearly 5 × faster than the state-of-the-art that required eight GPUs in a supercomputer [49]-and at significantly higher image quality and lower technical complexity than prior works.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Unstructured meshes are an enticing format for large-scale volumetric simulations, as elements can be adaptively distributed such that important regions receive more elements-increasing local accuracy and precision-while less important regions receive fewer elementssaving valuable memory resources. Take, for example, the NASA Landing Gear (shown in Figure <ref type="figure" target="#fig_0">2</ref>), where the largest element is 4096× larger than the finest element. An equal precision regular grid transformation would consume nearly 4 petabytes of data, while the native unstructured mesh format requires only 11.6 gigabytes.</p><p>The power of these meshes comes from their flexibility, as elements can twist and bend to represent complex shapes and domains. Frameworks supporting these unstructured grids naturally extend to support adaptive mesh refinement data, as hexahedra can be used to represent voxels in same-level bricks. Then, a combination of hexahedra, wedges, pyramids, and tetrahedra can be used to interpolate between neighboring bricks of different resolutions <ref type="bibr" target="#b45">[46,</ref><ref type="bibr" target="#b50">51]</ref>. However, this flexibility comes at a cost, as few assumptions can be made about the structure of the underlying elements. Challenges emerge at the level of a single primitive. Although, in their entirety, finite element meshes can adapt in resolution to improve overall memory consumption, a single finite element consumes a considerable amount of memory. Elements must store vertices and vertex indices explicitly, unlike regular grids where the geometry of a voxel is almost entirely implicit. As a result, meshes often need to be compressed to fit within system resources; however, this compression can easily take several hours and must support on-the-fly, localized decompression during rendering <ref type="bibr" target="#b48">[49]</ref>.</p><p>Then, rendering these volumetric meshes requires quickly identifying which element contains a given query point and interpolating that element's corresponding per-vertex values. These queries require constructing auxiliary data structures (trees or mesh connectivity) over the elements to facilitate fast element point location <ref type="bibr" target="#b38">[39,</ref><ref type="bibr" target="#b41">42]</ref>. However, many of these structures are surprisingly challenging to implement, and take a significant amount of time and memory to compute <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b48">49]</ref>.</p><p>Once these structures are built, they can be used to optimize direct volume rendering for point location queries that are executed along with a set of view-aligned rays. However, determining the number of samples required to compute clean-looking images is another challenge. For regular grids, volumes can be accurately rendered by relating the step size between each query to the voxel width, thus sampling approximately every voxel along the ray. However, with unstructured meshes, the widths of fine elements are much smaller than the widths of the coarse elements (see Fig. <ref type="figure" target="#fig_0">2</ref>). Unfortunately, relating the step size to the finest element width results in a prohibitively expensive number of samples per ray in coarser regions, while larger step sizes undersample the volume.</p><p>Thus, before these datasets can be queried, they often must undergo an expensive compression process accompanied by constructing several auxiliary data structures that can take several hours to complete. Then during rendering, the irregularity of these large unstructured meshes causes modern methods to oversample coarse regions while undersampling fine details within the data. These obstacles, and many more, hinder the adoption of direct volume rendering as a method for visualizing unstructured volumetric grids.</p><p>Fortunately, many of these obstacles can be overcome by challenging common assumptions made by prior works. One common assumption is that preprocessing trees are required to cluster nearby elements. These preprocessing trees are then discarded in favor of hardwareaccelerated trees built over these clusters during runtime. However, there are much simpler and much faster means of clustering elements that do not require an expensive preprocessing step. Then, many prior methods assume alpha-composited ray marching is the only method for rendering volumetric data; and yet, alternative Monte Carlo volume rendering methods exist and have several unexplored yet appealing properties for unstructured grid visualization. These Monte Carlo methods amortize sampling expense over time, trading noise in intermediate images for significantly faster frame rates and improved final image quality. Finally, by targetting just the primary sources of memory consumption of these datasets, both the mesh and corresponding structures can be compressed in parallel immediately before runtime to enable visualization on a broader set of systems and architectures. By optimizing the implementation complexity and runtime performance of mesh compression and visualization, we believe that more applications will be able to benefit from the power and flexibility of these adaptive finite element formats.</p><p>To this end, we present a novel approach to unstructured mesh visualization that leverages the optimal clustering properties of Hilbert space-filling curves <ref type="bibr" target="#b27">[28]</ref> in combination with high-performance GPU ray tracing APIs to enable accessible, high quality, high performance, low memory consumption rendering, all with little to no preprocessing. We sort all unstructured elements along this Hilbert curve in parallel to establish a structure for otherwise unstructured data. Then, we repeatedly leverage this resulting spatial locality to quickly generate collections of clusters that can be used to address the variety of challenges posed by unstructured grid rendering, including memory consumption of vertex indices, hardware BVH memory consumption, and rendering performance. We then show how these clusters can be combined with a Monte Carlo alternative to ray marching, called Delta Tracking, to amortize rendering expense over time-at the trade-off of noise at intermediate frames-to improve visualization interactivity by adaptively sampling cluster-localized density estimates.</p><p>More specifically, we present the following contributions:</p><p>• a method that leverages Hilbert curves and a parallel GPU sort to cluster unstructured elements quickly, • a strategy that leverages these clusters to significantly reduce the memory footprint of hardware-compatible structures for accelerated unstructured point queries, • a parallel mesh re-indexing scheme that uses coarse clusters to reduce the memory required by 2×, and • two methods that transform object-oriented clusters into spatial partitions for use in adaptive sampling.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORKS</head><p>Recent works have made significant progress in unstructured volume rendering. Here, we cover these prior works and how they address memory consumption, runtime performance, preprocessing times, and ease of implementation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">High-Performance Element Traversal</head><p>Early methods <ref type="bibr" target="#b40">[41]</ref> rasterized tetrahedral mesh volumes by sorting elements from front to back. This sorting step scales poorly to large datasets, resulting in slow interactivity during camera manipulation. So instead of sorting elements by visibility order, modern methods use auxiliary data structures like bounding volume hierarchies (BVHs) or element connectivity data to traverse from front to back.</p><p>Recent methods for unstructured mesh visualization use hardware ray-tracing cores, otherwise known as RT cores. Unlike singleinstruction, multiple-data cores of a GPU, modern ray-tracing cores follow a multiple-instruction, multiple-data execution model that is better suited for divergent tree traversal <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b34">35]</ref>. Unfortunately, these cores appear as a "black box" to end-users, as exact tree and traversal implementations vary from one vendor to the next and from hardware generation to generation. Almost all aspects of these treesincluding tree width, construction, node bounds, and quantizationare made private. This makes utilizing these trees for tasks other than ray-triangle intersection testing a challenge, as tree traversal cannot be customized, nor can internal tree nodes be accessed. However, by leveraging these frameworks, users do not need to write any code to construct trees or for ray-tree traversal, dramatically reducing implementation complexity.</p><p>Recent methods <ref type="bibr" target="#b31">[32,</ref><ref type="bibr" target="#b44">45]</ref> use GPU ray tracing frameworks to improve tree construction and query performance of unstructured meshes by transforming the task of finite element point containment into a raytracing problem that can be hardware accelerated. Although query performance is fast, these works require auxiliary triangles from element faces to leverage ray-triangle hardware intersectors, where each triangle identifies two neighboring elements. Computing these triangles requires a lengthy sequential triangle insertion step into an unordered map, and once found, a hardware tree must be built over them. These data structures consume a prohibitive amount of time and memory to compute and store and therefore do not scale to large meshes. Alternatively, rays can march from element to element using connectivity data <ref type="bibr" target="#b33">[34]</ref>. The recent work by Sahistan et al. <ref type="bibr" target="#b39">[40]</ref> improves the performance and complexity of tetrahedral mesh marching by using GPU ray tracing frameworks and cores to identify where rays enter and exit the volume. Then, they apply an exclusive-or compacting scheme by Aman et al. <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b2">3]</ref> to reduce memory bandwidth and significantly improve performance when marching from one tetrahedron to the next. Unfortunately, computing the required connectivity data is often an arduous preprocess, and storing it quickly becomes prohibitively expensive, especially as datasets grow larger <ref type="bibr" target="#b18">[19]</ref>. The approach by Aman et al. also requires tetahedralizing pyramids, wedges, and hexahedra, which increases the number of elements, and, therefore, memory consumption up to 6× <ref type="bibr" target="#b31">[32,</ref><ref type="bibr" target="#b33">34]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Space Skipping and Adaptive Sampling</head><p>As these data sets grow large and irregular (cf. Figure <ref type="figure" target="#fig_0">2</ref>), it becomes a challenge to adequately sample small features within a large domain. If done naively, too small of a step size between queries results in oversampling coarse elements, which is detrimental to rendering performance. Increasing the step size improves performance but results in undersampling small features of interest. Therefore, sampling rates need to adapt to the underlying data. However, to our knowledge, very few works address this issue for unstructured meshes, and none do so in a way that is free from visual artifacts.</p><p>For adaptive sampling, prior works have proposed to adapt the step size along the ray depending on local statistics or the resolution of the data <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b49">50]</ref>. Recent methods <ref type="bibr" target="#b30">[31,</ref><ref type="bibr" target="#b49">50]</ref> trace rays through non-overlapping clusters of unstructured elements, skipping empty space and adapting the sampling rate by the variance of the scalar field within each cluster. Due to the "black box" nature of hardware-accelerated trees and the requirement that clusters do not overlap, these methods require an expensive top-down KD tree build over the unstructured elements. This KD tree construction can take several hours, as each tree level requires sorting elements to compute split planes. This method also relies on opacity correction to account for the now spatially varying sampling rates, as proposed by Engel et al. <ref type="bibr" target="#b9">[10]</ref>; however, this opacity correction is more beneficial in the context of sheer warp algorithms <ref type="bibr" target="#b23">[24]</ref>-where the apparent thickness of a slice of voxels depends on the viewing angle-and does not correct for undersampling errors in high-density regions. As a result, artifacts can be seen during adaptive sampling, as demonstrated in Figure <ref type="figure" target="#fig_1">3</ref>.</p><p>In the context of regular grids and cinematic rendering, some applications <ref type="bibr" target="#b22">[23]</ref> drop alpha-composited ray marching in favor of stochastic null collision methods like Delta Tracking, as tracking methods have a lower algorithmic complexity with respect to scatter interactions than alpha-composited ray marching. This is because composited marching methods require secondary rays be traced for each sample taken along a primary ray, which results in an exponential number of rays as scatter interactions increase. To address this, shadow maps can be used to cache visibility from light sources to maintain camera interactivity with alpha-composited ray marching <ref type="bibr" target="#b4">[5]</ref>; though, these maps must be recomputed on transfer function and lighting changes, and consume additional memory. For our application, these data structures would require separate techniques to be developed to support unstructured grids. Alternatively, if low frequency shadows are acceptable, fewer samples can be taken along shadow rays. On the other hand, tracking methods require only a linearly increasing number of rays per scatter interaction, as these methods only consider the particle at the sampled distance, and therefore do not require any precomputation to maintain interactivity.</p><p>Additionally, these tracking methods allow for artifact-free adaptive sampling <ref type="bibr" target="#b42">[43,</ref><ref type="bibr" target="#b43">44,</ref><ref type="bibr" target="#b52">53]</ref> through localized maximum density estimates along the ray. Kalos et al. <ref type="bibr" target="#b43">[44]</ref> propose traversing through an easyto-compute grid of macrocells to identify more tightly bounding local maximum density. They use a 3D digital differential analyzer (DDA) algorithm to traverse through these cells, reading local density estimates from the macrocells to adapt the underlying sampling rate. In the context of scientific visualization, the work by Günther et al. <ref type="bibr" target="#b15">[16]</ref> employs a macrocell-based Delta Tracking approach to render finitetime Lyapunov exponent fields adaptively. Recent prior works <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b26">27]</ref> also propose moving to Delta Tracking methods to achieve adaptive, high-quality visualization of medical volumes.</p><p>To our knowledge, no prior works have explored the use of adaptive Delta Tracking for unstructured mesh visualization. However, as shown in Figure <ref type="figure" target="#fig_1">3</ref>, this Monte Carlo approach has clear benefits for performance and image quality. We refer to our supplemental for more information on how alpha-composited ray marching and Monte Carlo Delta Tracking compare.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Compression</head><p>As these meshes grow large, storing these datasets within GPU memory is challenging. Prior works optimize the memory footprint of the mesh as well as corresponding acceleration structures to reduce memory consumption. Naive approaches construct bounding volume hierarchies down to the individual element with a branching factor of two, resulting in a significant number of internal nodes that consume a large amount of memory. To remedy this, prior works <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b47">48]</ref> use wider branching factors to reduce the number of internal nodes significantly and, therefore, overall memory consumption. Benthin et al. <ref type="bibr" target="#b5">[6]</ref> additionally show that internal nodes of wide BVHs can be quantized relative to their parent bounds, further reducing the bytes used per node. Unfortunately, these trees are incompatible with raytracing cores and are slow to traverse in software; however, the works by Wald and Morrical <ref type="bibr" target="#b31">[32,</ref><ref type="bibr" target="#b44">45]</ref> compare the memory consumption of a four-wide quantized BVH against a hardware-accelerated BVH used by NVIDIA's Turing architecture and demonstrate a similar footprint.</p><p>Ströter et al. <ref type="bibr" target="#b41">[42]</ref> propose to sort tetrahedra in parallel on a Morton space-filling curve, then construct a memory-efficient OLBVH similar to the LBVH by Lauterbach et al. <ref type="bibr" target="#b24">[25]</ref>. Their approach requires precomputing neighboring element connectivity data, which can be done for tetrahedral meshes using the GPU-optimized structure by Mueller-Roemer et al. <ref type="bibr" target="#b32">[33]</ref>. Although their method does consume less memory than hardware-accelerated trees, this compression comes at a performance cost, as their method is several magnitudes slower than that by Wald <ref type="bibr" target="#b44">[45]</ref>, even on GPUs using a software fallback to ray-tracing cores. This method also requires users to construct and traverse these trees themselves.</p><p>Wald et al. <ref type="bibr" target="#b48">[49]</ref> recently proposed a memory-efficient encoding that compromises rendering performance to reduce memory consumption significantly. Their work constructs a wide BVH with quantized nodes and then reduces the number of bits per element index by dividing the mesh into submeshes referencing no more than 2 16 vertices. Then, a per-leaf element reordering is used to reduce the memory footprint of child pointers within the tree. Though their method saves an impressive amount of memory, constructing these wide compressed trees is complex and requires several hours of preprocessing. Traversal is also nontrivial, as nodes must be decompressed on the fly, and it requires eight nodes on a supercomputer to achieve a semi-interactive 2.5 fps on the Small NASA Mars Lander dataset. Then, like the work by Morrical et al. <ref type="bibr" target="#b30">[31]</ref>, Wald et al. discard the top levels of their data structure, substituting with a second top-level tree that is compatible with ray-tracing cores.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">METHOD</head><p>We present a high-quality direct volume rendering method for large unstructured grids with a low implementation complexity that still scales to very large data. The proposed method focuses on GPU architectures with ray-tracing cores; however, in theory, the techniques we offer should also work with CPU ray tracing frameworks and GPUs with software fallbacks to ray tracing hardware.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Baseline Unstructured Mesh Renderer</head><p>We begin by implementing a simple baseline method <ref type="bibr" target="#b31">[32]</ref> with an off-the-shelf GPU ray tracing framework compatible with ray-tracing cores. By building off these frameworks, we significantly reduce the implementation complexity and improve the performance of our method, especially for BVH construction and traversal. Naturally, these frameworks will impose several constraints that will direct the design choices with our method, as we cannot change internal aspects of these frameworks like BVH construction or ray traversal.</p><p>First, we load our unstructured mesh into memory. Vertices of the mesh are stored in a list of float3 representing x, y, and z coordinates, respectively. For simplicity, we assume that each mesh vertex is associated with a single corresponding scalar value. Then, we load all tetrahedra indices into a list of 32-bit ints, such that each tetrahedron corresponds to four unique, contiguous indices. Pyramid indices are stored in a separate list, as are wedges and hexahedra, each using five, six, and eight indices per element, respectively. Thus, our unstructured mesh consists of one list of vertices, one list of scalar values, and four lists of indices-one for each element type. With this format, we can efficiently load elements from disk by storing and loading these lists as large contiguous binary arrays that we copy all at once into memory. Once loaded, we copy these lists to the GPU for on-the-fly pre-processing.</p><p>Modern GPU ray tracing frameworks focus on ray-triangle intersection testing; however, our primitives are not triangles. Prior works <ref type="bibr" target="#b31">[32,</ref><ref type="bibr" target="#b44">45]</ref> tessellate element faces, using ray-triangle intersectors to significantly improve query performance; however, triangulating element faces consumes a prohibitive amount of memory. Therefore, we instead use a more memory-efficient custom primitive type, where raytracing cores traverse through a tree of bounding boxes but return to software when query points intersect the leaves. Note that hardwareaccelerated rays can be made to act like point queries by setting the ray origin to the query point, then choosing an arbitrary direction and setting the T_MIN and T_MAX values to 0. So long as T_MIN equals 0, all primitive bounding boxes intersecting the ray origin will be returned to the user.</p><p>To use a custom primitive, these ray tracing APIs require us to supply primitive bounding boxes and a handwritten intersection test. So for every element in parallel, we compute a bounding box over that element's vertices, storing bounding boxes for tetrahedra, wedges, pyramids, and hexahedra in separate lists. We also compute a global bounding box in parallel over all mesh vertices by using atomic minimum and maximum functions over the vertex coordinates. Next, we create a custom geometry structure for each element type, allowing us to write four different intersection tests in our ray tracing framework. The appropriate intersection test will be called when a ray hits a bounding box belonging to a particular element type. We then construct a tree over these lists of bounding boxes using the ray-tracing API's high-performance tree construction method.</p><p>Next, we write a custom intersection program for each element type. When a ray hits a bounding box containing an element, we read all element indices and vertices into local registers. Then, we test to see if the ray origin is contained within our element. If so, we interpolate the corresponding per-vertex values, returning the result in a register associated with the ray-typically called a ray payload register. This intersection test and interpolation can be done using Newton's method, and we provide relevant code for them in our supplemental.</p><p>Finally, we need a colormap to convert scalar data values sampled from the volume into colors and corresponding alpha-transparency values to render this data volumetrically. Typically this colormap is editable at runtime to enable interactive exploration of the data, where each edit uploads the updated colormap to the GPU. To create our final image, we write a ray generation program where we trace view-aligned rays out from the camera origin and compute an intersection distance to the front and the back of the global volume bounds. We then march along these rays, sampling the volume at a user-specified sampling rate, using the colormap to transform the sampled scalar value into color and corresponding alpha value, which we can composite from front to back and store in our image framebuffer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Tree Compression through Hilbert Clusters</head><p>This baseline method by Morrical <ref type="bibr" target="#b31">[32]</ref> is a good starting point, as we can render unstructured volumes without lengthy preprocessing steps. Right now, we only require constructing a hardware-accelerated tree, which we can do in real-time using our GPU ray tracing framework. However, some fundamental issues with the current approach prevent us from rendering large unstructured grids. One limitation is that our trees currently consume too much memory.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1">Hilbert Leaf Clusters</head><p>Currently, we construct our trees down to the individual element. This results in a costly number of internal nodes near the leaves of the treeas trees grow exponentially with depth-and as a consequence, our BVH consumes more memory than the unstructured mesh does. To solve this, we could follow the method by Wald et al. <ref type="bibr" target="#b49">[50]</ref>, and build a second, highly compressed BVH on the CPU in a top-down process. Then, we could follow the nested-hierarchies approach proposed by Gralka et al. <ref type="bibr" target="#b13">[14]</ref> and construct a hardware-compatible tree over highly compressed treelets to still leverage the performance of ray-tracing cores. However, as shown by prior works, constructing compressed trees top-down on the CPU requires several hours of preprocessing time and introduces technical complexity to the method.</p><p>Interestingly, the work by Gralka et al. demonstrates that compressed treelets provide performance benefits over simpler flat lists of primitives only when a treelet stores more than 128 primitives. For smaller clusters of primitives, they suggest forgoing treelets in favor of simpler flat lists of elements contiguous in memory. With these small flat primitive clusters, memory is reduced by eliminating bounding boxes and child/node pointers in the tree. Additionally, as shown by an earlier work by Wald. <ref type="bibr" target="#b44">[45]</ref>, the hardware-accelerated BVHs we currently build have a similar memory footprint to compressed quantized BVHs like those by Benthin et al. <ref type="bibr" target="#b5">[6]</ref>. Therefore, we can achieve nearly all the memory optimizations proposed by Wald's compressed data structure <ref type="bibr" target="#b49">[50]</ref> by aggregating primitives into small flat lists less than 128 primitives in length, then constructing a hardware-accelerated BVH over these clusters. Furthermore, as shown by Gralka et al., for flat lists containing 16 primitives or fewer, traversal performance should still greatly benefit from hardware acceleration. From here on, we refer to these clusters as Leaf Clusters.</p><p>Unfortunately, in the current state of our data, the underlying elements of our mesh are ordered unpredictably. If we were to group sets of N elements into one primitive bound, neighboring elements in memory may lie on opposite sides of the spatial domain. Although we would significantly reduce our acceleration structure's memory footprint, our primitive bounding boxes could contain a significant amount of empty space and would very likely overlap. As a result, our rendering performance would quickly degrade to non-interactive frame rates due to poor culling performance. Indeed, through our experimentation, we found that simply aggregating two neighboring elements together in their original memory order resulted in a complete lock-up of the system on the data sets we use for evaluation.</p><p>Fortunately, this element ordering in memory can be easily changed without affecting the spatial data representation, and we can do so without requiring secondary trees like those used by prior works. So as a first step, we sort our elements along a space-filling curve exhibiting nice clustering properties, using an off-the-shelf GPU radix sort. For simplicity, we recommend the radix sort routine made available in NVIDIA's CUB library, though the fast four-way radix sort by Ha et al. <ref type="bibr" target="#b16">[17]</ref> would also work well. The space-filling curve we use is vital to generating high-quality clusters without significant overlap. At first, we explored Morton order curves, which can be computed by first quantizing element centroids to a fixed grid spanning the bounding volume of the entire dataset, then interlacing the bits of the individual quantized dimensions of the element centroids. For the purposes of our application, we used 48-bit codes, with 16 bits allocated per dimension. These codes might not be unique per-polyhedra, as the quantization process might assign two or more polyhedra to the same cell. However, only a few polyhedra will receive identical codes, and when they do, we assume they will be sufficiently nearby in space for reasonable clustering.</p><p>Sorted elements can then be clustered by dropping N least significant bits in these codes and then clustering neighboring elements with identical sub-codes. To establish intuition on this process, these Morton codes can be thought of as a round-robin middle-split KD tree, and by dropping N least significant bits and clustering elements with identical subcodes, this process can be interpreted as extracting the internal nodes from this implicit KD tree. This process is very similar to the first step employed by parallel tree construction routines like the LBVH proposed by Lauterbach et al. <ref type="bibr" target="#b24">[25]</ref>, with the only difference being that we compute just the bounds of the leaves of LBVH, rather than the full tree.</p><p>Unfortunately, we ran into several undesirable issues with Morton codes. First, the number of least significant bits to drop is a userdefined parameter, and it is difficult to determine what this number should be. Drop too many bits, and all elements get clustered together; drop too few, and we end up with many leaf clusters containing only a single element. This is problematic because we want to keep the number of primitives per leaf less than 128 to still benefit from hardware acceleration from ray-tracing cores, but we also need more than one element per cluster; otherwise, we do not realize any memory savings. Alternatively, we could choose to cluster primitives into equal length subsets, thus guaranteeing each leaf cluster contains exactly N primitives. However, Morton codes exhibit undesirable large jumps at higher levels of the implicit KD tree, which result in suboptimal bounds when clustering equal length subsets together.</p><p>So instead, we sort elements by their centroid on a Hilbert spacefilling curve. Just like a Morton curve, we can quantize element centroids to a fixed resolution grid before sorting key-value pairs with a parallel GPU radix routine. However, as Moon et al. <ref type="bibr" target="#b27">[28]</ref> demonstrated, Hilbert curves provide more optimal clustering properties and do not exhibit the large undesirable jumps that Morton curves do. Although Hilbert codes are slightly more challenging to compute than Morton codes, they are still nearly instant to compute relative to treelets. Still, for reference, we include a non-recursive Cartesian-to-Hilbert implementation in our supplemental material, as described by Butz <ref type="bibr" target="#b7">[8]</ref>, then simplified by Moore <ref type="bibr" target="#b28">[29]</ref>. A visual comparison between clusters generated from BVH nodes, KD tree nodes, Macrocells, Morton curves, and Hilbert curves can be seen in Figure <ref type="figure" target="#fig_2">4</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2">Hilbert Instance Clusters</head><p>By sorting our elements along a Hilbert curve and clustering neighboring elements together, we can significantly reduce the final memory consumption of our BVH. However, as found by prior works <ref type="bibr" target="#b44">[45]</ref>, current GPU ray tracing frameworks exhibit a different peak memory consumption versus final memory consumption when constructing trees. If too many primitives are stored within a single acceleration structure, the scratch memory required to build this tree on the GPU can quickly become prohibitively expensive. Though future GPU tree construction implementations may reduce this peak memory consumption, a workaround to this problem is to divide elements of the unstructured mesh into different bottom-level acceleration structures, then build each of these smaller trees in series, and then instantiate these trees in a final top-level acceleration structure.</p><p>To do this, prior works <ref type="bibr" target="#b31">[32,</ref><ref type="bibr" target="#b44">45]</ref> propose to divide unstructured elements in memory order into groups of one million elements each; however, as discussed before, clusters of neighboring elements with an unpredictable ordering in space relative to memory will likely generate bounds containing many empty spaces overlapping other clusters. This would then degrade instance culling performance during traversal. Therefore, we propose slightly modifying this pre-splitting strategy, where we reuse our previously Hilbert-curve-reordered elements to generate higher-quality clusters of one million elements each. From now on, we refer to this second type of cluster as an Instance Cluster. Like these prior works, this pre-splitting strategy reduces peak memory consumption to acceptable levels. However, with our approach, these bottom-level acceleration structures will have less overlap when instantiated in the top-level acceleration structure than the overlap of prior works. This should improve the performance of our point location queries to be similar to if we were using one unified tree, though we primarily do this pre-splitting out of necessity. An illustration of this instance clustering process-as well as the prior leaf clustering process-is shown in Figure <ref type="figure" target="#fig_3">5</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Mesh Compression through Re-Indexing</head><p>At this point, we have a relatively memory-efficient and accessible method for querying our unstructured elements. Still, prior works <ref type="bibr" target="#b49">[50]</ref> go on to compress the unstructured mesh itself. Element indices consume a significant amount of memory and make up the majority of the footprint of our unstructured mesh. Currently, we use 32-bit integers to represent our indices, which can address up to 2 32 vertices. If we in-spect the contents of these indices, we will find a considerable amount of redundancy in the most significant bits. This is because more significant bits naturally change less frequently than less significant bits when storing ascending addresses. Fortunately, we can leverage this redundancy to cut our effective mesh memory footprint in half.</p><p>To implement index compression, we can split the mesh into meshlets such that each meshlet references fewer than 2 16 vertices. Then, we can replace the global list of vertices with smaller, per-meshlet vertex lists. As a consequence of splitting our mesh into meshlets, vertices from the global vertex list will be duplicated when referenced by more than one meshlet. Ideally, these meshlets would have a small outer surface area relative to their volume to minimize vertex replication throughout this process.</p><p>Wald et al. <ref type="bibr" target="#b49">[50]</ref> address this issue by constructing a tree over the unstructured elements from the top down. During construction, tree nodes are split by a surface area heuristic until they reference fewer than 2 16 vertices; however, when meshes contain billions of elements, reordering primitives at each node split slow and expensive. So instead, we propose to transform the instance clusters previously generated in Section 3.2.2 to reduce peak memory consumption during hardware BVH construction to also serve as our meshlets for index compression. Previously, these instance clusters contained one million elements each. We reduce the size of these instance clusters to approximately 30, 000 − 60, 000 elements, reducing the number of vertices referenced per instance cluster. Then, we make instance clusters referencing more than 2 16 vertices use 32-bit indices, while instance clusters with fewer than 2 16 vertices use 16-bit indices.</p><p>Given an instance cluster of elements, we need a way to efficiently compute that cluster's vertex list and the new indices that reference this list. We follow a prior mesh re-indexing method <ref type="bibr" target="#b46">[47]</ref> that re-indexes meshes in parallel on the GPU. We propose slightly modifying this parallel re-indexing method to improve re-indexing performance. More specifically, we remove the requirement that duplicate vertices be eliminated. Removing duplicate vertices requires sorting all vertices in the global list for each instance cluster. Since we have potentially thousands of instance clusters, these sorts quickly become prohibitively expensive to do during application startup.</p><p>Instead, we assume the unstructured mesh does not contain duplicate vertices, and if it does, we preserve those duplicates to avoid sorting. We substitute this sort with a parallel flagged device selection operation to collect all vertices marked as used into a new subset. This selection process can be implemented in parallel on the GPU through an inclusive prefix sum (minus one) over an array of "isUsed" flags for each vertex; however, we recommend using the flagged device selection operation provided by NVIDIA's CUB library for simplicity and improved performance.</p><p>An illustration of this re-indexing process is shown in Figure <ref type="figure" target="#fig_4">6</ref>. This data transformation is much faster than prior works but can take several minutes depending on the number of instance clusters that need reindexing; so for large datasets, we recommend minimizing the number of instance clusters required for index compression.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Adaptive Sampling through Delta Tracking</head><p>Now that our data fits within system resources, we will re-evaluate our rendering approach. Adequately sampling these datasets with a naive ray marcher requires an unacceptably high number of samples to sufficiently sample the small cells of interest. To address this issue, prior works <ref type="bibr" target="#b42">[43,</ref><ref type="bibr" target="#b43">44,</ref><ref type="bibr" target="#b52">53]</ref> adapt the sampling rate to the underlying data by first gathering maximum density estimates along the ray, which are stored in clusters of elements. Unfortunately, unstructured elements make these algorithms difficult to implement, as these methods require that adaptive sampling clusters do not overlap. Therefore, we propose two ways to efficiently transform our Hilbert clusters into non-overlapping spatial partitionings for use with these adaptive sampling methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.1">Hilbert Adaptive Sampling Clusters</head><p>We introduce a third cluster type, Adaptive Sampling Clusters, where we again use our Hilbert-ordered elements to quickly generate a set of clusters with an equal number of primitives each. Additionally, for each cluster, we now store the minimum and maximum scalar data value within that cluster. Once these clusters are identified, we build a hardware-accelerated BVH over the cluster bounds to facilitate traversal.</p><p>Once we have a set of boxes with local estimates for minimum and maximum data values, before rendering, we need to transform these minima and maxima into a set of maximum density estimates considering the currently applied transfer function. Our approach is similar to prior works <ref type="bibr" target="#b30">[31]</ref>, but we focus on computing only maximum density rather than data variance. For every cluster, we use the per-cluster minimum and maximum data values to iterate over the range of the transfer function density values that affect the contents of the current cluster. We compute the maximum extinction value during this iteration and store this as our current maximum density estimate. (See Figure <ref type="figure">7</ref> for an illustration of this process.) We then calculate the maximum density for each cluster in parallel on the GPU whenever the transfer function is edited.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.2">Option I: Cluster Rasterization into Ray-Centric Bins</head><p>To adaptively sample our large unstructured data sets, we need an efficient way to transform our overlapping clusters into non-overlapping maximum extinction segments along our ray (see also the pseudocode in our supplemental material). We begin by intersecting our ray with the bounding box of the entire volume, calculating the enter and exit distances along the ray. Next, we divide the interval defined between this enter and exit distance into a constant number of disjoint, equidistant segments. Then, we allocate a bin to store the maximum extinction value along each segment, initializing each bin to a value of 0 (i.e., fully transparent).</p><p>Once the segment bins are allocated and initialized, we trace a second ray through the previously obtained adaptive sampling clusters. For each cluster we intersect, we "rasterize" the maximum extinction associated with the intersected cluster into the bins of the overlapping ray segments. This rasterization process occurs as clusters are "splat" into 1D segments along the 3D ray, which is slightly different from classical rasterization where triangles are "splat" onto pixels on a 2D screen. This process effectively transforms our object-space partitioning into spatial partitioning, though our maximum extinction estimation becomes more approximate at the compromise. See Figure <ref type="figure" target="#fig_5">8</ref> for an illustration of this process.</p><p>In practice, we allocate these bins using ray payload registers to avoid unnecessary VRAM traffic during traversal and cluster rasterization. At the time of writing, current GPU architectures are limited to at most 32 ray payload registers. To further improve precision, we break up this long ray into M shorter ray segments, with N bins per ray where N &lt;= 32, and where M is a user-chosen parameter depending on the dataset being rendered and the precision required. Two rays give an effective resolution of 64 bins along our ray, four rays give 128 bins, and so on. (See also Subfigure 8b.) Then, we bounce back and forth between binning clusters and the Delta Tracking process. If our ray collides with a particle inside the volume, we can terminate traversal early without necessarily tracing all of our adaptive sampling rays.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.3">Option II: Cluster Rasterization into a Macrocell Grid</head><p>We also explore a second method that transforms our object-oriented clusters into a spatial partitioning via a macrocell grid (see also the pseudocode in our supplemental material). At the cost of some memory, we can achieve approximately the same resolution as our ray binning method by allocating an auxiliary regular grid whose side length is numBins/ √ 3. We make each voxel within this grid contain a minimum and maximum scalar value, which we initialize to FLOAT_MAX and FLOAT_MIN, respectively.</p><p>Then, for each adaptive sampling cluster in parallel, we use GPU atomics to rasterize each cluster's minimum and maximum scalar values into all cells of our regular grid that the cluster intersects. This region of interest can be found by rounding up and down each cluster's upper and lower bounds to the nearest regular grid cells. Once this is done, as we edit our transfer function, we compute the maximum density values for all of the regular grid bins in parallel using the same approach described in Section 3.4.1. One exception is that we assign a maximum density of 0 (i.e., fully transparent) to all regular grid bins whose scalar value ranges are uninitialized, i.e., FLOAT_MAX and FLOAT_MIN, meaning no cluster touches that bin.</p><p>Finally, during rendering, we can traverse through these nonoverlapping grid cells using a 3D Digital Differential Analyzer (DDA) algorithm <ref type="bibr" target="#b3">[4]</ref>. This algorithm draws a line through the cells of the grid in order along that line. In our case, that line is our volume sampling ray. For each cell returned by DDA, we read the majorant density at that cell and determine where the ray enters and exits that cell to compute our non-overlapping segment for adaptive sampling. (See also Subfigure 8c.) By using DDA to traverse through these cells rather than the GPU's ray-tracing cores, we reserve the use of these cores for polyhedra point location queries.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.4">Adaptive Delta Tracking of Unstructured Data</head><p>Now that we have a disjoint set of bins containing maximum extinction estimates, we can use a piecewise constant adaptive delta tracking approach to reduce the number of samples taken from the volume to improve rendering performance. Instead of immediately marching through the volume, we first iterate over the ray segments made by the previous step. We compute a localized enter and exit distance for each bin allocated along the ray for just the current segment. If the maximum extinction value for the segment is 0, the current segment represents empty space and can be skipped altogether. Otherwise, we use the maximum extinction value associated with the current segment to sample free flight distances. Now that we are using accurate maximum extinction estimates, the probability of a null collision is significantly reduced, increasing the sampled step size and reducing the number of rejected samples taken from the volume. If the sampled distance from delta tracking passes the end of the segment, we iterate to the next segment allocated along the ray, resetting the sampled distance to account for the change in the maximum extinction estimate.</p><p>We can then use this additional performance to improve the quality of the visualization. After tracing a ray through the unstructured data, adaptive delta tracking will return a single representative free flight distance. For pure emission and absorption rendering modes, we return the color of the volume at that distance. To simulate shadows, we trace a shadow ray originating at this final free flight distance and in the direction of the directional light source. This shadow ray operates similarly to the adaptively sampled primary ray. First, an adaptive sampling ray is traced towards the light to collect maximum extinction estimates into a set of bins allocated along the ray. Then, an adaptive delta tracking routine is employed to determine if the light is visible or occluded depending on if the ray makes it through the entirety of the volume without an absorption event occurring. We then use the results of this shadow ray to shade our primary ray's volumetric sample.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">EXPERIMENTAL RESULTS</head><p>To evaluate our method, we use OptiX 7 <ref type="bibr" target="#b35">[36]</ref> to access hardwareaccelerated ray tracing functionality in NVIDIA GPUs. All measurements were taken using an NVIDIA RTX8000 GPU and an Intel i9 12900K processor. All images were rendered at a resolution of 1024 × 1024 up to 4000 samples per pixel, with one sample per frame.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Datasets</head><p>With this hardware, we performed a series of tests on a collection of unstructured data sets of varying sizes (cf. Figure <ref type="figure" target="#fig_6">9</ref>):</p><p>1) The TACC Japan Earthquake simulates the effects of the 2011 earthquake and subsequent tsunami that hit Japan. Scientists resolved the movement of the seismic waves using an adaptive grid; however, our copy of this data set consists of non-adaptive, roughly equallysized hexahedra.</p><p>2) The Deep Ocean Impact is derived from AMR <ref type="bibr" target="#b36">[37]</ref> and comes from an xRage <ref type="bibr" target="#b12">[13]</ref> simulation of an asteroid impacting the ocean.</p><p>3) The NASA Landing Gear is derived from AMR and visualizes the vorticity of air around the landing gear, simulated with NASA's LAVA code <ref type="bibr" target="#b21">[22]</ref>. Coarse cells are 2 12 × larger than the finest cells.</p><p>4) The NASA Mars Lander visualizes a retropropulsion study to decelerate the Mars lander entering the martian atmosphere <ref type="bibr" target="#b19">[20]</ref>. This data was simulated using NASA's FUN3D code <ref type="bibr" target="#b6">[7]</ref> and consists of nearly a billion mixed finite elements that vary significantly in volume.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>5) Cell</head><p>Variance Datasets are synthetic datasets of 3 million cells each, used to evaluate how sensitive our method is to varying cell sizes. Table <ref type="table">1</ref>: Memory usage of our test models. Each data type is given before and after instance cluster mesh compression. All datasets are clustered into instance clusters containing 30k-60k primitives in order to keep the referenced vertices within each cluster less than 2 16 for mesh index compression. We also store 16 elements per leaf cluster to reduce tree memory consumption per instance cluster. We generate a Delaunay tetrahedralization over random points generated through a Poisson sphere sampling method, resulting in evenlysized tetrahedra. These vertices are then displaced randomly, up to the Poisson sphere radius, to introduce variance in the derived tetrahedra sizes (see the supplemental for an illustration).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Evaluation</head><p>With these datasets, we measure our method's preprocessing time, compression effectiveness, and rendering performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1">Clustering and Compression</head><p>Table <ref type="table">1</ref> shows the effectiveness of our Hilbert clusters and mesh reindexing in reducing memory consumption. As shown, we achieve compression factors between 0.32 and 0.70. We also outperform the compression method by Wald et al. <ref type="bibr" target="#b48">[49]</ref> for all but the Mars Lander dataset (ours at 9.71 GB, theirs at 9.3 GB).</p><p>Table <ref type="table" target="#tab_2">2</ref> shows the evaluation of our Hilbert clusters' performance versus memory consumption. We incrementally cluster more and more elements together, building trees over these different cluster sizes and measuring the impacts on memory consumption of the BVH as well as rendering performance. For the majority of our datasets, clustering neighboring elements results in significant tree memory reductions while still maintaining interactive performance. We did notice a drop in performance on Landing Gear as more and more elements were clustered together at the leaves, which we hypothesized might be a sensitivity to highly varying cell sizes. Indeed, strong variance in cell size degrades performance somewhat, as shown by our synthetic Cell Variance benchmarks, but only by about 6.8%. Therefore, we suspect that the majorant estimate for Landing Gear is poor, resulting in many null collisions, which grow linearly in expense with leaf cluster size.</p><p>Table <ref type="table" target="#tab_3">3</ref> compares time to cluster elements of the Mars Lander Dataset by splitting the mesh into equal-sized clusters using different approaches, including a KD tree, a BVH, and our Hilbert clustering. Top-down KD tree construction on the CPU quickly becomes impractical to compute as cluster sizes decrease, requiring a prohibitive amount of memory. Bottom-up LBVH construction on the CPU does much better but still is relatively impractical for generating small clusters of elements immediately before rendering. Hilbert clusters can be formed with a single sort, independent of cluster count; hence, they can be computed at runtime. Table <ref type="table" target="#tab_4">4</ref> presents statistics related to compressing mesh indices using our parallel mesh re-indexing method for various data sets. We measure how long our parallel mesh re-indexing strategy takes to complete and compare this to how long it takes to load the dataset from the disk and how much memory we save. As shown in the table, prior works needed several hours to re-index on the CPU, while our largest data sets only take a couple of minutes. Though the Landing Gear data set is smaller than the Mars Lander data set, the hexahedra representing the Landing Gear exhibit less vertex reuse than Small Lander, thus requiring more clusters with fewer elements to guarantee each cluster references fewer than 2 16 vertices.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2">Visual Results</head><p>As shown in Table <ref type="table" target="#tab_5">5</ref>, all datasets improve significantly in performance when adaptive sampling is enabled versus disabled by up to 100× in the case of the Landing Gear dataset. Compared to a traditional alphacomposited ray marcher, our results are significantly more noisy per frame (see the supplemental for what this noise looks like), but as shown in Figure <ref type="figure" target="#fig_6">9</ref>, our adaptive sampled images converge to an unbiased result-unlike adaptive ray marching, as shown in Figure <ref type="figure" target="#fig_1">3</ref>-due to the physically-based model that Monte Carlo Delta Tracking follows. Delta tracking also easily extends to volumetric shadows, unlike alpha-composited raymarching, which requires a shadow ray for every sample taken from the volume.</p><p>Our results show noticeable performance improvements when transforming our overlapping Hilbert clusters on the fly into nonoverlapping bins, despite the overhead of on-the-fly rasterization. However, our results show that DDA traversal over our macrocells performs better than our ray-binning method by 1.4× to 3×. With our ray binning method, we also have resource contention over ray-tracing cores, which is not an issue with the DDA traversal approach.</p><p>One exception we found was that, for the Landing Gear dataset, even a 512 3 grid of macrocells was insufficient to approximate maximum density estimates accurately. Compared to even the Mars Lander dataset, the actual Landing Gear model is incredibly small relative to the simulation domain. As a result, our on-the-fly ray binning method can achieve a higher effective adaptive sampling resolution at a fraction of the memory due to the adaptivity of the Hilbert clusters. In this case, on-the-fly ray binning outperforms DDA traversal, but only for highly optically dense colormaps where insufficient adaptive sampling becomes too costly and achieving sufficient resolution with macrocells requires too much memory.</p><p>Ultimately, we believe these results suggest that, for our current datasets, it is best to rasterize adaptive sampling clusters into an intentionally small set of macrocells. This may seem counterintuitive, as the unstructured meshes themselves are non-uniform, so in theory, a more adaptive cluster structure would do better at adaptive sampling; however, fewer adaptive sampling segments promote larger Delta Tracking skips forward. As more adaptive sampling segments along the ray are formed, traversing through too many segments introduces overhead that starts to dominate rendering time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">LIMITATIONS AND FUTURE WORK</head><p>Ultimately we are very excited with these results, as we show that low memory, high-performance unstructured volume rendering is possible using only relatively simple data transformations. Still, our method has some limitations that are worth discussing.</p><p>One limitation of our approach is that our preprocessing steps to reduce memory consumption can consume a large amount of memory, as we require the entire data set to fit within GPU memory to be compressed. Therefore, it might still make sense to compress datasets on a workstation GPU with more VRAM, then save these results to disk for post-hoc visualization on a more consumer-friendly card. Alternatively, all these compression processes could be done in parallel on the CPU, which would likely still be much faster than the preprocessing required by prior work. As for future work, we believe there is still room to further reduce memory consumption without introducing significant preprocessing time, perhaps by compressing neighboring tetrahedra pairs. In terms of rendering, as we discussed before, our ray binning method is limited in the number of clusters that rays can traverse through, and it suffers from resource contention with the ray-tracing cores also used for point location. On the other hand, our clustergenerated macrocells quickly consume too much memory, as a doubling in spatial resolution results in a cubic number of allocated macrocells. To address this, we believe it would be worth exploring alternative data transformations that transform clusters into a hierarchy of macrocells, perhaps using the number of clusters that fall within a coarse macrocell to guide subdividing that macrocell into finer macrocells. Then, a hierarchical DDA process could be used instead of a traditional DDA. Orthogonally, we might also be able to improve rendering performance by attempting to execute multiple subsequent point containment queries within one RT core trace call by leveraging the multiple clustered elements contained within a single leaf.</p><p>Our work focuses on single scattering effects in terms of rendering quality, as single scattering along a common light direction is relatively efficient while still conveying depth information. Our approach should naturally extend to support multiple scattering effects, but how our raybinning strategy performs, in this case, warrants further evaluation.</p><p>As our method uses a Monte Carlo approach, individual frames produce noise that must be converged over time. To reduce noise, we could benefit from a blue noise error distribution, as shown by Wolfe et al. <ref type="bibr" target="#b51">[52]</ref>. We would also likely benefit from a neural network denoiser similar to that proposed by Hofmann et al. <ref type="bibr" target="#b17">[18]</ref>. Caching light visibility in finite elements could also be an interesting avenue to explore, similar to how prior regular grid shadow maps work. Finally, we believe it would be interesting to explore how our approach might be used in a distributed setting, e.g., for use in in-situ rendering.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">CONCLUSION</head><p>This work presented a set of simple, efficient, yet highly effective data transformations to reduce the memory footprint of large unstructured grids for rendering. To reduce implementation complexity, we substitute complex bounding volume hierarchy construction for a simple sort along a Hilbert space-filling curve. Then, we use clusters generated from this curve to compress the size of point location trees and mesh indices, all in under a couple of minutes.</p><p>We then presented two different methods that transform these clusters into a structure suitable for adaptive sampling during volumetric path tracing: one that rasterizes clusters on the fly into nonoverlapping bins along a ray, and another that rasterizes clusters into macrocells which can be traversed during runtime using DDA. These approaches dramatically improve rendering performance, opening the door to higher quality volumetric renderings, including volumetric shadows. Using a Monte Carlo path tracing approach over alphacompositing, we can amortize sampling expenses over time to improve interactivity and final image quality.</p><p>Ultimately, we hope for the high-performance data transformations in this work to improve the accessibility of these powerful unstructured grid formats, which we believe could enable new possibilities for large data exploration and high-quality visualization.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 2 :</head><label>2</label><figDesc>Fig. 2: Illustration of the spatial domains common to large unstructured data, here shown for the NAsA Landing Gear AMR dataset. Elements throughout the simulation adapt in resolution to reduce memory consumption. From left to right, we progressively zoom in.</figDesc><graphic url="image-2.png" coords="2,65.25,72.77,76.55,76.55" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 3 :</head><label>3</label><figDesc>Fig.3: a) clusters of elements from the TACC Japan Earthquake dataset, used for adaptive sampling. b) artifacts caused by adaptive ray marching methods<ref type="bibr" target="#b30">[31,</ref><ref type="bibr" target="#b49">50]</ref> due to undersampling. c) unbiased adaptive sampling using our delta tracking approach. d) and e) demonstrate the benefits of shadows on the perception of depth, which we additionally support thanks to Delta Tracking. (Intermediate images converged to 4000 SPP.)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 4 :</head><label>4</label><figDesc>Fig. 4: A visual comparison between clustering methods on the Mars lander for 100K clusters.</figDesc><graphic url="image-15.png" coords="5,314.11,72.95,115.69,115.70" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 5 :</head><label>5</label><figDesc>Fig. 5: An illustration of elements are along the Hilbert space-filling curve (a and b). Once sorted, neighboring elements be clustered into small leaf clusters (in c, represented with sold lines) to reduce final tree memory consumption, and into larger instance clusters (in d, shown with dashed lines) to reduce peak tree memory consumption, as well as for mesh index compression.</figDesc><graphic url="image-17.png" coords="5,314.11,203.67,115.62,115.48" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 6 :</head><label>6</label><figDesc>Fig.6: An illustration of our parallel mesh reindexing to reduce bits per element index. In a), subsets of the mesh are clustered along a Hilbert curve. b) The indices of these elements reference a global vertex array and consume 32-bits per index. c) For each cluster, we mark used vertices in parallel, compacting away any unused vertices. We also create a permutation table for each cluster, mapping old vertex addresses to new ones. d) This results in smaller mesh clusters, whose bits-per-index can be reduced due to the smaller per-cluster vertex lists.</figDesc><graphic url="image-23.png" coords="6,333.73,296.34,57.86,75.56" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 8 :</head><label>8</label><figDesc>Fig.8: In a) clusters (top middle) are generated from mesh elements (top), then maximum densities of intersected clusters are rasterized (bottom middle) into bins along the ray (bottom). In b), for highly nonuniform datasets (top), we break up our ray (bottom three rows) to increase bin counts and reduce majorant error (in red). Alternatively, in c) clusters (top middle) are generated from mesh elements (top) like before, but now we rasterize them into a grid of macrocells, which we can traverse using 3D-DDA (bottom middle), producing non-even, but also non-overlapping adaptive sampling intervals along our ray (bottom).</figDesc><graphic url="image-25.png" coords="7,64.26,72.79,80.29,80.09" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 9 :</head><label>9</label><figDesc>Fig. 9: Data sets used for testing. Impact and Landing Gear are adaptive mesh refinement simulations, while Earthquake and Mars Lander are fully unstructured finite element meshes. All images are rendered at 1024x1024, at 1 spp per frame (top right of each image), with one primary ray and one shadow ray per pixel, and are converged over time to 4000 SPP (bottom left of each image).</figDesc><graphic url="image-28.png" coords="8,79.62,72.88,109.23,108.18" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic url="image-1.png" coords="1,85.82,167.22,429.67,185.37" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>Manuscript received xx xxx. 201x; accepted xx xxx. 201x. Date of Publication xx xxx. 201x; date of current version xx xxx. 201x. For information on obtaining reprints of this article, please send e-mail to: reprints@ieee.org. Digital Object Identifier: xx.xxxx/TVCG.201x.xxxxxxx</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>A performance versus memory consumption evaluation of our Hilbert clusters for different cluster sizes for two NASA datasets. Baseline signifies the case where elements are not sorted along the curve.</figDesc><table><row><cell>Model</cell><cell></cell><cell>baseline</cell><cell>1</cell><cell>4</cell><cell>8</cell><cell>16</cell><cell>32</cell></row><row><cell>Lander</cell><cell>Accel GB</cell><cell>16.9</cell><cell>16.6</cell><cell>4.5</cell><cell>2.3</cell><cell>1.2</cell><cell>0.6</cell></row><row><cell></cell><cell cols="7">FPS/RPS 11.5 / 24.1 13.8 / 28.9 11.7 / 24.5 10.0 / 20.9 8.2 / 17.2 5.8 / 12.1</cell></row><row><cell>Gear</cell><cell>GB</cell><cell>6.20</cell><cell>6.53</cell><cell>1.51</cell><cell>0.86</cell><cell>0.45</cell><cell>0.23</cell></row><row><cell></cell><cell cols="7">FPS/RPS 10.1 / 21.2 15.1 / 31.7 4.8 / 10.1 2.8 / 5.9 1.7 / 3.6 0.78 / 1.6</cell></row><row><cell>0% Cell</cell><cell>Accel GB</cell><cell>0.60</cell><cell>0.56</cell><cell>0.15</cell><cell>0.08</cell><cell>0.04</cell><cell>0.02</cell></row><row><cell cols="8">Variance FPS/RPS 48.3/101.3 51.4/107.8 46.7/97.9 38.0/79.7 29.8/62.5 20.9/43.8</cell></row><row><cell cols="2">50% Cell Accel GB</cell><cell>0.61</cell><cell>0.58</cell><cell>0.16</cell><cell>0.08</cell><cell>0.04</cell><cell>0.02</cell></row><row><cell cols="8">Variance FPS/RPS 46.7/97.9 50.2/105.3 45.3/95.0 37.1/77.8 28.9/60.6 20.1/42.2</cell></row><row><cell cols="2">100% Cell Accel GB</cell><cell>0.62</cell><cell>0.59</cell><cell>0.16</cell><cell>0.08</cell><cell>0.04</cell><cell>0.02</cell></row><row><cell cols="8">Variance FPS/RPS 45.0/94.4 48.5/101.7 43.6/91.4 35.9/75.3 27.8/58.3 19.3/40.5</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 :</head><label>3</label><figDesc>A comparison of time to cluster elements of the Mars Lander Dataset using different approaches (KD tree and LBVH implementations are taken from PBRT v3<ref type="bibr" target="#b37">[38]</ref>).</figDesc><table><row><cell>Clustering Method</cell><cell>KD Tree</cell><cell>LBVH</cell><cell>Hilbert Clusters</cell></row><row><cell>100K Elems / Cluster</cell><cell>30+ hrs</cell><cell>16.3 mins</cell><cell>2.5 secs</cell></row><row><cell>16 Elems / Cluster</cell><cell>NA</cell><cell>23.5 mins</cell><cell>2.5 secs</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 4 :</head><label>4</label><figDesc>Time required to compress mesh indices using our parallel mesh reindexing method for various data sets.</figDesc><table><row><cell>Mesh Compression</cell><cell>Earth</cell><cell>Impact</cell><cell>Gear</cell><cell>Lander</cell></row><row><cell>Number of Clusters</cell><cell>3K</cell><cell>8K</cell><cell>16K</cell><cell>6K</cell></row><row><cell>Seconds to Load</cell><cell>2.72</cell><cell>6.31</cell><cell>14.6</cell><cell>10.9</cell></row><row><cell>Seconds to Compress</cell><cell>9.76</cell><cell>71.5</cell><cell>216</cell><cell>57.6</cell></row><row><cell>Memory Saved (in GB)</cell><cell>0.73</cell><cell>2.80</cell><cell>3.79</cell><cell>5.94</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 5 :</head><label>5</label><figDesc>Comparing rendering performance for alpha-composited ray marching, non-adaptive delta tracking, and our adaptive approach using ray bins and DDA. Adaptive methods use 50M Hilbert clusters. Measurements are in frames per second / million rays per second. Note, our ray marcher does not include volumetric shadows, as shadows cause the marcher to not return in a reasonable time.</figDesc><table><row><cell>Model</cell><cell>Marching  *</cell><cell>Tracking</cell><cell>Ray Bins</cell><cell>DDA</cell><cell>DDA</cell></row><row><cell></cell><cell></cell><cell></cell><cell>2K bins</cell><cell>100 3</cell><cell>512 3</cell></row><row><cell>Earth</cell><cell>3.89  *  / 4.1</cell><cell>3.87 / 8.1</cell><cell>7.53 / 15.8</cell><cell>22.4 / 47.0</cell><cell>13.9 / 29.2</cell></row><row><cell>Impact</cell><cell>1.13  *  / 1.2</cell><cell>5.05 / 10.6</cell><cell>7.62 / 16.0</cell><cell>11.8 / 24.7</cell><cell>6.87 / 14.4</cell></row><row><cell>Gear</cell><cell>0.75  *  / 0.8</cell><cell>0.10 / 0.2</cell><cell>7.26 / 16.0</cell><cell>4.85 / 10.2</cell><cell>9.72 / 20.4</cell></row><row><cell>Lander</cell><cell>0.58  *  / 0.6</cell><cell>2.25 / 7.7</cell><cell>11.8 / 24.7</cell><cell>16.3 / 34.2</cell><cell>14.1 / 30.0</cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Advanced Micro Devices, Inc. RDNA 2 Instruction Set Architecture: Reference-Guide</title>
		<ptr target="https://developer.amd.com/wp-content/resources/RDNA2_Shader_ISA_November2020.pdf" />
		<imprint>
			<date type="published" when="2020-03">2020. March 2022</date>
			<publisher>Advanced Micro Devices, Inc</publisher>
		</imprint>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Compact tetrahedralizationbased acceleration structures for ray tracing</title>
		<author>
			<persName><forename type="first">A</forename><surname>Aman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Demirci</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Güdükbay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Visualization</title>
		<imprint/>
	</monogr>
	<note>In press</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Multi-level tetrahedralization-based accelerator for ray-tracing animated scenes</title>
		<author>
			<persName><forename type="first">A</forename><surname>Aman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Demirci</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Güdükbay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Wald</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Animation and Virtual Worlds</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note>3-4):e2024, 11 pages</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">A fast voxel traversal algorithm for ray tracing</title>
		<author>
			<persName><forename type="first">J</forename><surname>Amanatides</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Woo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Eurographics, EG &apos;87</title>
				<meeting>Eurographics, EG &apos;87</meeting>
		<imprint>
			<date type="published" when="1987">1987</date>
			<biblScope unit="page" from="3" to="10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Low-pass filtered volumetric shadows</title>
		<author>
			<persName><forename type="first">M</forename><surname>Ament</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Sadlo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Dachsbacher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Weiskopf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2437" to="2446" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Compressed-leaf bounding volume hierarchies</title>
		<author>
			<persName><forename type="first">C</forename><surname>Benthin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Wald</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Woop</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">T</forename><surname>Áfra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on High-Performance Graphics</title>
				<meeting>the Conference on High-Performance Graphics</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note>Article no. 6, 4 pages</note>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">FUN3D Manual: 13.6. National Aeronautics and Space Administration</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">T</forename><surname>Biedron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>-R. Carlson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Derlaga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">A</forename><surname>Gnoffo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>Hammond</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">T</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Kleb</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">M</forename><surname>Lee-Rausch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">J</forename><surname>Nielsen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Park</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
			<publisher>Langley Research Center</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Alternative algorithm for Hilbert&apos;s space-filling curve</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">R</forename><surname>Butz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Computers</title>
		<imprint>
			<biblScope unit="volume">100</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="424" to="426" />
			<date type="published" when="1971">1971</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Shallow bounding volume hierarchies for fast SIMD ray tracing of incoherent rays</title>
		<author>
			<persName><forename type="first">H</forename><surname>Dammertz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hanika</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Keller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics Forum</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1225" to="1233" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Real-time volume graphics</title>
		<author>
			<persName><forename type="first">K</forename><surname>Engel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hadwiger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Kniss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">E</forename><surname>Lefohn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">R</forename><surname>Salama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Weiskopf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In ACM SIGGRAPH Course Notes, #</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<date type="published" when="2004">2004</date>
			<publisher>ACM</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Multi bounding volume hierarchies</title>
		<author>
			<persName><forename type="first">M</forename><surname>Ernst</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Greiner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Symposium on Interactive Ray Tracing, RT 08</title>
				<meeting>the IEEE Symposium on Interactive Ray Tracing, RT 08</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="35" to="40" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">An analysis of region clustered BVH volume rendering on</title>
		<author>
			<persName><forename type="first">D</forename><surname>Ganter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Manzke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">GPU. Computer Graphics Forum</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="13" to="21" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">The RAGE radiation-hydrodynamic code</title>
		<author>
			<persName><forename type="first">M</forename><surname>Gittings</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Weaver</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Clover</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Betlach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Byrne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Coker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Dendy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Hueckstaedt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>New</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">R</forename><surname>Oakes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Science &amp; Discovery</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">63</biblScope>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Spatial partitioning strategies for memory-efficient ray tracing of particles</title>
		<author>
			<persName><forename type="first">P</forename><surname>Gralka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Wald</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Geringer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Reina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Ertl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE 10th Symposium on Large Data Analysis and Visualization</title>
				<meeting>the IEEE 10th Symposium on Large Data Analysis and Visualization</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="42" to="52" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">A quick guide to Intel&apos;s ray-tracing hardware</title>
		<author>
			<persName><forename type="first">H</forename><surname>Gruen</surname></persName>
		</author>
		<ptr target="https://www.intel.com/content/www/us/en/events/developer/gdc-march-2022.html" />
	</analytic>
	<monogr>
		<title level="m">Game Developers Conference</title>
				<imprint>
			<date type="published" when="2022-03-27">2022. 27 March 2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">MCFTLE: Monte Carlo rendering of finite-time Lyapunov exponent fields</title>
		<author>
			<persName><forename type="first">T</forename><surname>Günther</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kuhn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Theisel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics Forum</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="381" to="390" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Fast four-way parallel radix sorting on GPUs</title>
		<author>
			<persName><forename type="first">L</forename><surname>Ha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Krüger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">T</forename><surname>Silva</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics Forum</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="2368" to="2378" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Neural denoising for path tracing of medical volumetric data</title>
		<author>
			<persName><forename type="first">N</forename><surname>Hofmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Martschinke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Engel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Stamminger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of SIGGRAPH &apos;20)</title>
				<meeting>SIGGRAPH &apos;20)</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">18</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Solving PDEs in space-time: 4D tree-based adaptivity, mesh-free and matrix-free approaches</title>
		<author>
			<persName><forename type="first">M</forename><surname>Ishii</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Fernando</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Saurabh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Khara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Ganapathysubramanian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Sundar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis</title>
				<meeting>the International Conference for High Performance Computing, Networking, Storage and Analysis</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note>SC 19, Article no. 61, 22 pages</note>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Summit supercomputer simulates how humans will &apos;brake&apos; during Mars landing</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">E</forename><surname>Jones</surname></persName>
		</author>
		<ptr target="https://www.ornl.gov/news/summit-simulates-how-humans-will-brake-during-mars-landing" />
		<imprint>
			<date type="published" when="2019-10-27">October 2019. 27 March 2021</date>
		</imprint>
		<respStmt>
			<orgName>Oak Ridge National Laboratory</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">GPU-assisted raycasting for cosmological adaptive mesh refinement simulations</title>
		<author>
			<persName><forename type="first">R</forename><surname>Kähler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wise</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Abel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H.-C</forename><surname>Hege</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Volume Graphics</title>
				<meeting>Volume Graphics</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="103" to="110" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">The LAVA computational fluid dynamics solver</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">C</forename><surname>Kiris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">F</forename><surname>Barad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Housman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Sozer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Brehm</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Moini-Yekta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">American Institute of Aeronautics and Astronautics (AIAA) SciTech Forum, 52nd Aerospace Sciences Meeting</title>
				<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="1" to="43" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Exposure render: An interactive photo-realistic volume rendering framework</title>
		<author>
			<persName><forename type="first">T</forename><surname>Kroes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">H</forename><surname>Post</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">P</forename><surname>Botha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PloS One</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">7</biblScope>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
	<note>e38586, 10 pages</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Fast volume rendering using a shear-warp factorization of the viewing transformation</title>
		<author>
			<persName><forename type="first">P</forename><surname>Lacroute</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Levoy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 21st Annual Conference on Computer Graphics and Interactive Techniques, SIGGRAPH &apos;94</title>
				<meeting>the 21st Annual Conference on Computer Graphics and Interactive Techniques, SIGGRAPH &apos;94</meeting>
		<imprint>
			<date type="published" when="1994">1994</date>
			<biblScope unit="page" from="451" to="458" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">C</forename><surname>Lauterbach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Garland</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sengupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Luebke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Manocha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Fast BVH construction on GPUs. Computer Graphics Forum</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="375" to="384" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Adaptive sampling in single pass, GPU-based raycasting of multiresolution volumes</title>
		<author>
			<persName><forename type="first">P</forename><surname>Ljung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Volume Graphics</title>
				<meeting>Volume Graphics</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="39" to="46" />
		</imprint>
	</monogr>
	<note>The Eurographics Association</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Adaptive temporal sampling for volumetric path tracing of medical data</title>
		<author>
			<persName><forename type="first">J</forename><surname>Martschinke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Hartnagel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Keinert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Engel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Stamminger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics Forum</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="67" to="76" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Analysis of the clustering properties of the Hilbert space-filling curve</title>
		<author>
			<persName><forename type="first">B</forename><surname>Moon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">V</forename><surname>Jagadish</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Faloutsos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Saltz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Knowledge and Data Engineering</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="124" to="141" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Fast Hilbert curve generation, sorting, and range queries</title>
		<author>
			<persName><forename type="first">D</forename><surname>Moore</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">Computational and Applied Mathematics</title>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
		<respStmt>
			<orgName>Rice University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Visualization of AMR data with multi-level dual-mesh interpolation</title>
		<author>
			<persName><forename type="first">P</forename><surname>Moran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Ellsworth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="1862" to="1871" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Efficient space skipping and adaptive sampling of unstructured volumes using hardware accelerated ray tracing</title>
		<author>
			<persName><forename type="first">N</forename><surname>Morrical</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Usher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Wald</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Pascucci</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE Visualization, VIS &apos;19</title>
				<meeting>IEEE Visualization, VIS &apos;19</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="256" to="260" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Accelerating unstructured mesh point location with RT cores</title>
		<author>
			<persName><forename type="first">N</forename><surname>Morrical</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Wald</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Usher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Pascucci</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Transactions on Visualization and Computer Graphics</title>
				<imprint/>
	</monogr>
	<note>In press</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Gpu-based polynomial finite element matrix assembly for simplex meshes</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Mueller-Roemer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Stork</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics Forum</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="443" to="454" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Interactive volume visualization of general polyhedral grids</title>
		<author>
			<persName><forename type="first">P</forename><surname>Muigg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hadwiger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Doleisch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Groller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2115" to="2124" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">NVIDIA Ampere GA102 GPU Architecture: Second-Generation RTX</title>
		<author>
			<persName><surname>Nvidia Corp</surname></persName>
		</author>
		<ptr target="https://images.nvidia.com/aem-dam/en-zz/Solutions/geforce/ampere/pdf/NVIDIA-ampere-GA102-GPU-Architecture-Whitepaper-V1.pdf" />
		<imprint>
			<date type="published" when="2021-03-27">2021. 27 March 2021</date>
		</imprint>
		<respStmt>
			<orgName>NVIDIA</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Optix: a general purpose ray tracing engine</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">G</forename><surname>Parker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Bigler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Dietrich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Friedrich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hoberock</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Luebke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Mcallister</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mcguire</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Morley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Robison</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Graphics</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1" to="13" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Visualization and analysis of threats from asteroid ocean impacts</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Patchett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">J</forename><surname>Samsel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">C</forename><surname>Tsai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">R</forename><surname>Gisler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">H</forename><surname>Rogers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">D</forename><surname>Abram</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">L</forename><surname>Turton</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
		<respStmt>
			<orgName>Los Alamos National Laboratory</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">Physically Based Rendering: From Theory To Implementation</title>
		<author>
			<persName><forename type="first">M</forename><surname>Pharr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Jakob</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Humphreys</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016">2016</date>
			<publisher>Morgan Kaufmann Publishers Inc</publisher>
			<pubPlace>San Francisco, CA, USA</pubPlace>
		</imprint>
	</monogr>
	<note>3rd ed.</note>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">SIMD parallel ray tracing of homogeneous polyhedral grids</title>
		<author>
			<persName><forename type="first">B</forename><surname>Rathke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Wald</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Chiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Brownlee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eurographics Symposium on Parallel Graphics and Visualization</title>
				<meeting>the Eurographics Symposium on Parallel Graphics and Visualization</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="33" to="41" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Ray-traced shell traversal of tetrahedral meshes for direct volume visualization</title>
		<author>
			<persName><forename type="first">A</forename><surname>Sahistan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Demirci</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Morrical</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Zellmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Aman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Wald</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Güdükbay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE Visualization Conference</title>
				<meeting>IEEE Visualization Conference</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="91" to="95" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">A polygonal approximation to direct scalar volume rendering</title>
		<author>
			<persName><forename type="first">P</forename><surname>Shirley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Tuchman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of SIG-GRAPH &apos;90)</title>
				<meeting>SIG-GRAPH &apos;90)</meeting>
		<imprint>
			<date type="published" when="1990">1990</date>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page">6370</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">OLBVH: Octree Linear Bounding Volume Hierarchy for Volumetric Meshes</title>
		<author>
			<persName><forename type="first">D</forename><surname>Ströter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Mueller-Roemer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Stork</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Fellner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Visual Computer</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">10-12</biblScope>
			<biblScope unit="page" from="2327" to="2340" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Free path sampling in high resolution inhomogeneous participating media. Computer Graphics Forum</title>
		<author>
			<persName><forename type="first">L</forename><surname>Szirmay-Kalos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Tóth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Magdics</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="85" to="97" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Efficient free path sampling in inhomogeneous media</title>
		<author>
			<persName><forename type="first">L</forename><surname>Szirmay-Kalos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Tóth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Magdics</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Csébfalvi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Eurographics (Posters)</title>
				<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Computing minima and maxima of subarrays</title>
		<author>
			<persName><forename type="first">I</forename><surname>Wald</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Ray Tracing Gems: High-Quality and Real-Time Rendering with DXR and Other APIs</title>
				<editor>
			<persName><forename type="first">E</forename><surname>Haines</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">T</forename><surname>Akenine-Möller</surname></persName>
		</editor>
		<meeting><address><addrLine>Berkeley, CA</addrLine></address></meeting>
		<imprint>
			<publisher>Apress</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="61" to="70" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title level="m" type="main">A simple, general, and GPU friendly method for computing dual mesh and iso-surfaces of adaptive mesh refinement</title>
		<author>
			<persName><forename type="first">I</forename><surname>Wald</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2004.08475</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">AMR) data. arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title level="m" type="main">GPGPU-parallel re-indexing of triangle meshes with duplicatevertex and unused-vertex removal</title>
		<author>
			<persName><forename type="first">I</forename><surname>Wald</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2109.09812</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Getting rid of packets-efficient SIMD single-ray traversal using multi-branching BVHs</title>
		<author>
			<persName><forename type="first">I</forename><surname>Wald</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Benthin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Boulos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Symposium on Interactive Ray Tracing</title>
				<meeting>the IEEE Symposium on Interactive Ray Tracing</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="49" to="57" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">A memory efficient encoding for ray tracing large unstructured data</title>
		<author>
			<persName><forename type="first">I</forename><surname>Wald</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Morrical</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Zellmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="583" to="592" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<author>
			<persName><forename type="first">I</forename><surname>Wald</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Zellmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Usher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Morrical</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Lang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Pascucci</surname></persName>
		</author>
		<title level="m">Ray tracing structured AMR data using ExaBricks. IEEE Transactions on Visualization and Computer Graphics</title>
				<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="625" to="634" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Efficient parallel extraction of crack-free isosurfaces from adaptive mesh refinement (AMR) data</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">H</forename><surname>Weber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Childs</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Meredith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Symposium on Large Data Analysis and Visualization</title>
		<title level="s">LDAV</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="31" to="38" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><surname>Wolfe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Morrical</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Akenine-Möller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Ramamoorthi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2112.09629</idno>
		<title level="m">Scalar spatiotemporal blue noise masks</title>
				<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Unbiased, adaptive stochastic sampling for rendering inhomogeneous participating media</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Yue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Iwasaki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B.-Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Dobashi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Nishita</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Graphics</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page">177</biblScope>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
	<note>8 pages</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
