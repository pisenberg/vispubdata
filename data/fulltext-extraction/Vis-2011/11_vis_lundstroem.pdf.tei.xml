<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/pisenberg/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.4.1" ident="GROBID" when="2016-09-09T14:59+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Multi-Touch Table System for Medical Visualization: Application to Orthopedic Surgery Planning</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName>
								<forename type="first">Claes</forename>
								<surname>Lundströmlundstr¨lundström</surname>
							</persName>
						</author>
						<author>
							<persName>
								<forename type="first">Ieee</forename>
								<surname>Member</surname>
							</persName>
						</author>
						<author>
							<persName>
								<forename type="first">Thomas</forename>
								<surname>Rydell</surname>
							</persName>
						</author>
						<author>
							<persName>
								<forename type="first">Camilla</forename>
								<surname>Forsell</surname>
							</persName>
						</author>
						<author>
							<persName>
								<forename type="first">Ieee</forename>
								<surname>Member</surname>
							</persName>
						</author>
						<author>
							<persName>
								<forename type="first">Anders</forename>
								<surname>Persson</surname>
							</persName>
						</author>
						<author>
							<persName>
								<forename type="first">Anders</forename>
								<surname>Ynnerman</surname>
							</persName>
						</author>
						<author>
							<persName>
								<forename type="first">Ieee</forename>
								<surname>Member</surname>
							</persName>
						</author>
						<title level="a" type="main">Multi-Touch Table System for Medical Visualization: Application to Orthopedic Surgery Planning</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Index Terms—Medical visualization</term>
					<term>multi-touch</term>
					<term>tabletop display</term>
					<term>treatment planning</term>
				</keywords>
			</textClass>
			<abstract>
				<p>Fig. 1. The medical visualization table during user study sessions with orthopedic surgeons. Abstract—Medical imaging plays a central role in a vast range of healthcare practices. The usefulness of 3D visualizations has been demonstrated for many types of treatment planning. Nevertheless, full access to 3D renderings outside of the radiology department is still scarce even for many image-centric specialties. Our work stems from the hypothesis that this under-utilization is partly due to existing visualization systems not taking the prerequisites of this application domain fully into account. We have developed a medical visualization table intended to better fit the clinical reality. The overall design goals were twofold: similarity to a real physical situation and a very low learning threshold. This paper describes the development of the visualization table with focus on key design decisions. The developed features include two novel interaction components for touch tables. A user study including five orthopedic surgeons demonstrates that the system is appropriate and useful for this application domain.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p> Medical imaging is one of the cornerstones of healthcare and opportunities for improved diagnostics steadily arise thanks to technology advances . For the benefit of the patient, the acquired image data sets become larger and more complex <ref type="bibr" coords="1,146.69,482.00,9.52,8.02" target="#b1">[2]</ref> . The image-related clinical workflow includes several parts: diagnostics (including data acquisition and the radiologist's image review), treatment planning (such as preoperative surgery planning), and actual treatment (such as surgery). The main focus in our work is treatment planning where interaction with volumetric imaging data has been shown to be very beneficial in clinical practice. Several previous research efforts demonstrate the usefulness of 3D visualizations in terms of increased efficiency and @BULLET Claes Lundström is with the Center for Medical Image Science and Visualization, Linköping University, Sweden, and Sectra Imtec AB, Sweden, e-mail: clalu@cmiv.liu.se. @BULLET Thomas Rydell is with Interactive Institute, Norrköping, Sweden, e-mail: thomas.rydell@tii.se. @BULLET Camilla Forsell is with C-research, Linköping University, Sweden, e-mail: camilla.forsell@liu.se. @BULLET Anders Persson is with the Center for Medical Image Science and Visualization, Linköping University, Sweden, e-mail: anders.persson@cmiv.liu.se. @BULLET Anders Ynnerman is with C-research, Linköping University, Sweden, e-mail: lowered risk of complications, for example for lung <ref type="bibr" coords="1,483.44,451.85,13.74,8.02" target="#b15">[16]</ref>, gastric <ref type="bibr" coords="1,529.55,451.85,14.94,8.02" target="#b22">[23] </ref>and adrenal <ref type="bibr" coords="1,337.09,461.81,14.94,8.02" target="#b34">[35] </ref>surgery. Nevertheless, usage of interactive 3D outside of the radiology department is still very scarce in many institutions despite an excellent standard of care from other aspects. This situation of underdeveloped usage of mature visualization technology despite high potential benefits is the foundation for the work presented in this paper. Our assumption was that the limited deployment was due to not taking the prerequisites of the clinical environments fully into account. We hypothesized that central requirements for visualization systems for general healthcare were: a) similarity to a real physical situation and b) an extremely low threshold for usage learning. A touch-controlled table-top display was identified as a suitable platform for achieving these design goals. This paper describes the developed system, the Medical Visualization Table (MVT), from the first ideas via a prototype demonstrator to a complete mature system. The work includes an analysis of the application domain and a description of how the design requirements evolved according to user feedback. Finally, we investigated the benefits of the MVT for pre-operative surgery planning by performing a user study. Here, five orthopedic surgeons studied two authentic cases of pelvic fractures. The key research contributions are: @BULLET Introduction of two interaction concepts for table-top displays: movable alternator pucks and natural size zoom. @BULLET Enhancement of an existing prototype by introducing 6 DOF interaction and arbitrarily oriented clip planes. </p><p> @BULLET Qualitative investigation of the usefulness of the system for preoperative planning with five orthopedic surgeons. </p><p>As this application paper touches on several highly active fields of research, the review of previous efforts in this section will not attempt to cover everything but has a rather strict focus on touch interaction for volumetric visualization. Regarding other options for interactive visualization of volumetric data we refer to the following surveys: 3D user interfaces <ref type="bibr" coords="2,75.63,117.01,9.52,8.02" target="#b3">[4]</ref>, 3D interaction input devices <ref type="bibr" coords="2,191.42,117.01,9.71,8.02" target="#b2">[3,</ref><ref type="bibr" coords="2,202.85,117.01,10.64,8.02" target="#b9"> 10]</ref>, and augmented reality displays for medical use <ref type="bibr" coords="2,136.80,126.98,13.74,8.02" target="#b35">[36]</ref>. Touch interfaces are often considered as intuitive and easy to use. The commercial success of touch-controlled smart phones in itself demonstrates the validity of this standpoint. Several researchers have investigated the advantages of large touch screens. Kin et al. <ref type="bibr" coords="2,257.93,167.17,14.94,8.02" target="#b19">[20] </ref>found that touch is more efficient than the mouse for selection tasks, and that multi-touch brings additional efficiency. Novice users performing sorting tasks were studied by North et al. <ref type="bibr" coords="2,206.98,197.06,14.94,8.02" target="#b29">[30] </ref> and touch interaction was here significantly faster than mouse usage. Yu et al. <ref type="bibr" coords="2,257.93,207.02,14.94,8.02" target="#b41">[42] </ref>showed that their touch interface was preferred for exploratory tasks. Better task performance with touch could not be shown, but this was believed to stem from hardware limitations. There are also potential benefits of large touch displays for collaborative scenarios. The effectiveness of joint decision-making can be improved thanks to equal access to the interaction, as found by Rogers et al. <ref type="bibr" coords="2,43.99,277.10,13.74,8.02" target="#b31">[32]</ref> . Moreover, the interaction gestures were shown to effectively let collaborators convey their reasoning, without the need to always verbalize it. Hornecker et al. <ref type="bibr" coords="2,149.97,297.03,14.94,8.02" target="#b14">[15] </ref>further studied the awareness aspect. Touch input was found to be superior in supporting helping behaviors and hand-overs. An interesting finding was also that more interference situations occurred for touch interaction. The suggested remedy was not to remove these conflicts, but to provide effective tools to deal with them, for instance making it easy to follow actions by others and allowing swift switching of responsibilities. Isenberg et al. <ref type="bibr" coords="2,257.93,356.81,14.94,8.02" target="#b16">[17] </ref>showed that the tabletop display is well suited for collaborative work on document-centered visual analytics tasks. Touch-controlled visualization tables have been applied to many domains, for example scientific visualization <ref type="bibr" coords="2,183.11,397.00,14.19,8.02" target="#b17">[18,</ref><ref type="bibr" coords="2,199.10,397.00,10.64,8.02" target="#b41"> 42]</ref>, surveillance <ref type="bibr" coords="2,260.17,397.00,9.52,8.02" target="#b8">[9]</ref>, and architecture <ref type="bibr" coords="2,82.00,406.96,13.74,8.02" target="#b18">[19]</ref> . Touch screens are increasingly used in the medical context <ref type="bibr" coords="2,65.90,416.93,14.94,8.02" target="#b38">[39] </ref>and many applications for image review are available in touch-controlled versions. Although less common, there are also examples of table applications or other large-size screens for healthcare professional use. Stereotactic workbenches have been suggested for medical tasks such as surgical training and planning <ref type="bibr" coords="2,210.31,456.78,9.71,8.02" target="#b7">[8,</ref><ref type="bibr" coords="2,222.16,456.78,11.21,8.02" target="#b20"> 21,</ref><ref type="bibr" coords="2,235.51,456.78,10.64,8.02" target="#b23"> 24]</ref>. Other examples include a case study on brain fiber exploration <ref type="bibr" coords="2,234.64,466.74,14.94,8.02" target="#b41">[42] </ref>and a touch-enabled version of a traditional image display system with some 3D visualization support <ref type="bibr" coords="2,114.35,486.67,9.52,8.02" target="#b0">[1]</ref>. Although not a table or touch solution, the medical 3D visualization system developed by Gallo et al. <ref type="bibr" coords="2,257.93,496.63,14.94,8.02" target="#b10">[11] </ref> share some design objectives with our work. The system includes support for stereoscopic displays and mouse or Wiimote input. The design of touch gestures has been addressed in many previous research efforts, in particular the challenge of mapping 2D touch interaction to more degrees of freedom (DOF). A basic form of gesture design is to control panning by mapping it directly to movement of a single touch point. Approaches to additionally control 2D orientation without a second touch point has been proposed <ref type="bibr" coords="2,202.65,576.67,14.19,8.02" target="#b21">[22,</ref><ref type="bibr" coords="2,219.81,576.67,10.64,8.02" target="#b24"> 25]</ref>. With two touch points further opportunities arise and the rotate-scale-translate (RST) gesture design, described by Hancock et al. <ref type="bibr" coords="2,209.96,596.60,13.74,8.02" target="#b13">[14]</ref>, has become widely popular. A key characteristic, known as " sticky fingers " , is that interacting fingers always remain with the original virtual contact point in the data set. Working with 3D data using touch gestures poses further challenges . At least 6 DOF need to be handled: rotation around x-y-z axes, panning along x-y axes and zooming. Some approaches have employed simplifying restrictions such as shallow depth <ref type="bibr" coords="2,224.87,666.68,14.94,8.02" target="#b11">[12] </ref> or no ro- tation <ref type="bibr" coords="2,45.31,676.65,13.74,8.02" target="#b26">[27]</ref>. Hancock et al. <ref type="bibr" coords="2,119.90,676.65,14.94,8.02" target="#b12">[13] </ref>extended the sticky fingers concept to 3D manipulation, using a third touch point to achieve rotation about x and y axes. A variant separating translation and rotation interaction was presented by Martinet et al. <ref type="bibr" coords="2,144.61,706.53,13.74,8.02" target="#b27">[28]</ref>. Reisman et al. <ref type="bibr" coords="2,223.29,706.53,14.94,8.02" target="#b30">[31] </ref></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Initial assessment</head><p> @BULLET Assess treatment options </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Pre-operative planning</head><p>@BULLET Prepare for surgery  approach to make more operations available without introducing complex gestures is to employ mode-alternating zones, as presented by Yu et al. <ref type="bibr" coords="2,305.94,313.63,13.74,8.02" target="#b41">[42]</ref>. In this work interaction is with the 3D space itself rather than with objects, which is not the case in our system. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Surgery</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">APPLICATION DOMAIN</head><p> Two application domains for the MVT are in focus in this paper: treatment planning/execution and autopsies. The current usage of 3D visualizations in these domains is outlined in this section. In this context " 3D " refers to 3D renderings on a 2D screen, i.e., stereoscopic displays are not targeted. The description is based on an informal but extensive investigation that consisted of interviews, both over the phone and in person, with more than 50 physicians representing a vast range of specialties . The working environment of these physicians was hospitals with fully digital image handling since many years. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Treatment planning and execution</head><p>Medical imaging is a crucial component of the healthcare workflow for a vast range of diseases, and for most physicians ordering radiology examinations is an everyday task. The process connected to an imaging study is shown in <ref type="figure" coords="2,382.00,496.87,26.66,8.02">figure 2</ref>. The term referring physician will here be used to denote the physician in charge of the patient's treatment , as a distinction from the radiologist doing image reviews. There is a large variation in how extensively the referring physician interacts with the images themselves. For certain physician specialties such as surgeons the images are crucial, whereas the radiologist's textual report is sufficient in other cases. Moreover, among the imagecentric referring physicians there is large variation in the level of 3D visualization usage. One group in our interviews that represents a high expressed need for 3D but low level of actual 3D usage was orthopedic surgeons. An overview of the activities where there is potential use of 3D visualization for an orthopedic surgeon is given in <ref type="figure" coords="2,438.91,616.72,27.01,8.02">figure 3</ref>. The first of these activities is an initial assessment of injuries and treatment options at an image-centered session with a radiologist and several orthopedic surgeons. The images are presented by a radiologist via a projector. Today 2D slices are very dominant, but for certain complex fractures the radiologist can prepare 3D snapshots, i.e., static 3D projections. The snapshots can cover a series of angles, but free rotation or other manipulation is not available to the orthopedic surgeons in our inves- tigation. A second image-centered session that is today dominated by 2D slice images is the pre-operative planning, where tasks such as planning drill angles and selecting appropriate materials (screws, plates, etc.) can be very challenging. The orthopedic surgeon performs the planning individually but can consult colleagues at times. There is some intra-operative use (during the operation) of imaging but of limited value as the surgeon does not wish to interact with mouse and keyboard themselves. Imaging for post-operative follow-up is commonly done despite image artifacts from the metal materials used. Again, the 3D snapshots prepared by the radiologist is used in pre-and postoperative activities for the complex cases. Other groups of referring physicians, such as colorectal surgeons, had similar needs but with more emphasis on multi-disciplinary team (MDT) collaborations. The initial illness assessment lead by the radiologist often include several surgeons, an oncologist, a pathologist and if necessary an urologist and a gynecologist. The usage of 3D visualizations was less than for the orthopedic surgeons. Orthopedic and colorectal surgeons anticipated that full access to 3D visualizations would be useful to understand complex anatomy better and potentially lead to shorter operation times and fewer complications . The foreseen benefits pertained to both sessions with the radiologist , other MDT meetings, pre-operative planning, intra-operative guidance, and post-operative follow-up. The need in intra-operative use is underlined by the fact that since the incision should be minimized , the overview of the anatomy is highly limited during surgery. There are, however, referring physicians already putting 3D visualizations to extensive use, in our investigation primarily represented by cardiovascular surgeons. Pre-operative planning using 3D is considered essential for the quality of surgery. Features studied in 3D include diameters, lengths, angles, and spatial relations of anatomic structures. The development needs for 3D visualization voiced by these surgeons revolve around usability aspects. It should be noted that in all the scenarios above 3D visualization would be used in multiple relatively short sessions rather than prolonged use throughout a day. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Autopsy</head><p> Autopsies have traditionally been a cornerstone for improving quality of health care. Medical conclusions such as cause of death constitute an important feed-back for treatment revision. While the rate of medical autopsies is in decline for various reasons, their medical value has repeatedly been demonstrated <ref type="bibr" coords="3,179.95,424.69,9.71,8.02" target="#b4">[5,</ref><ref type="bibr" coords="3,192.60,424.69,10.64,8.02" target="#b32"> 33]</ref> . Post-mortem imaging (PMI) is an active research area in this domain. There is evidence supporting PMI as a valuable adjunct to physical autopsies <ref type="bibr" coords="3,242.42,444.61,10.45,8.02" target="#b4">[5] </ref> and ongoing research investigates if and when it also can be a replacement <ref type="bibr" coords="3,31.50,464.54,13.74,8.02" target="#b37">[38]</ref> . The non-invasive character of PMI may lead to increasing autopsy use, since physical autopsies are often declined. Forensics is another discipline highly dependent on autopsy results. Forensic PMI is not yet a wide-spread routine, but where such operations are being put to practice significant benefits have been shown <ref type="bibr" coords="3,218.23,504.39,14.19,8.02" target="#b25">[26,</ref><ref type="bibr" coords="3,234.66,504.39,10.64,8.02" target="#b39"> 40]</ref>. Adding PMI to the traditional autopsy workflow means that it is extended with an imaging scan of the cadaver before the regular physical autopsy. Potential activities related to the 3D visualizations correspond to the three first parts in <ref type="figure" coords="3,140.31,544.44,26.29,8.02">figure 3</ref>: initial assessment, pre-autopsy planning and intra-autopsy guidance. The first activity is viewed as the most important and is also the most frequent of the three in current practice. In this image-centered collaborative discussion between radiologist and pathologist, 3D visualizations are considered essential to many of the investigations. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">VIRTUAL AUTOPSY TABLE DEMONSTRATOR</head><p>The visualization table development was conducted in several phases. The first system developed was the Virtual Autopsy Table (VAT) demonstrator specifically targeting PMI, see figure 4. While multitouch technology and surface computing had been identified as promising for medical imaging applications in general, the VAT project aimed to go further in demonstrating concrete advantages for a specific application, namely the PMI process. The VAT system is not the focus of this paper, but since feedback on the VAT constituted important input to the development of the Medical Visualization Table , the design will be briefly described here. Apart from PMI needs, VAT design considerations were also influenced by the fact that public exhibitions was a primary target for the demonstrator. Many Graphical User Interface (GUI) elements traditionally used in WIMP (Window, Icon, Menu, Pointer) environments such as labels, text, and buttons were intentionally left out in the VAT design to avoid having elements distracting the user from the image. Furthermore, collaborative use was facilitated by designing the few GUI elements to be understood from any direction. For simplicity reasons, a limited set of manipulation options for the touch interaction was defined, providing 4 DOF. Single point gestures control rotation of the volume along the x-axis and panning in the x-y plane, interactions that are in line with a " patient on a table " metaphor. Zoom is controlled by two-point pinching . Clip planes parallel to sagittal (side view) and coronal (front view) planes of the body are controlled by small GUI widgets and there are browsable icons for Transfer Function (TF) preset selection docked to one side. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">MEDICAL VISUALIZATION TABLE SYSTEM</head><p>The VAT demonstrator described above was well received both by medical professionals, forensic pathologists and the general public. With this encouragement regarding the overall concept, a deeper investigation on useful applications in healthcare was carried out. This application domain analysis lead to the conclusion that a 3D visualization table would benefit efficiency and quality of care also in treatment planning scenarios, as described in section 3.1. Therefore, a new development project was launched, targeting a system that would realize the identified potential in clinical production use. This system, the Medical Visualization <ref type="figure" coords="3,390.66,489.92,27.36,8.02">Table (</ref>MVT), is described in depth in the remainder of this section. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Design requirements</head><p>The MVT design was developed iteratively based on feedback from a vast range of potential users as well as technology and domain experts. This process, described below, finally resulted in the following set of design requirements, which we first state and then explain in detail: R1: The learning threshold for basic interaction should be close to none. R2: Advanced interaction should be available without disturbing the ease-of-use of the basic interaction. R3: The system should be alluring such that novice users are inspired to start interacting. R4: The users should experience similarity with real-world situations in patient care. R5: The interaction should be highly responsive and robust. R6: The interaction should be equally intuitive for all positions around the table. R7: Swift but distinct changes of which person who is currently interacting should be supported. R8: The system should work in versatile environments without recurring maintenance efforts. </p><p> At the onset of the VAT development the main requirements identified was perceived simplicity (R1) and responsive interaction (R5). Feedback on the VAT was then iteratively collected from numerous usage sessions during approximately a year, the latter part overlapping with the start of the MVT development. The VAT was during most of this time located at a research center within a university hospital, but was also showcased at four different medical conferences. Feedback was continuously collected from a large number of radiology technologists , radiologists and other physicians trying out the system. At several occasions informal workshops were performed, containing organized interviews and careful observation. The conclusions at this stage was that simplicity (R1), " wow " factor (R3) and realism (R4) needed to be top priorities on the requirement list for the MVT. The main reason for the requirement of an alluring system (R3) is that physicians reported that the perceived effort of adopting yet another system can often be overwhelming. A system that invokes use not only for rational but also emotional reasons has a better chance of realizing its potential. Along similar lines, simplicity (R1) and realism (R4) are important since the obstacles for both initial and sustained usage could be prohibitive. The many multi-user sessions demonstrated that statically placed elements such as the TF selection items caused uneven engagement around the table (R6). Occasional stability issues with different parts of the system provided a first insight into the importance of low-effort maintenance (R8). The applicability of a visualization table for non-autopsy purposes such as treatment planning and teaching was commonly emphasized. A workshop towards the end of the VAT evaluation period focused on explicitly identifying the shortcomings of the VAT in clinical practice . It was then concluded that the feature set of the VAT was not sufficient. While the touch control as such received very positive feedback , the 4 DOF interaction was considered too restrained. The clip planes were found to be easy to use, but the restriction to major axes was judged inappropriate for actual medical use. Furthermore, the potential conflict of introducing complex features versus retaining low learning threshold lead to the separation of basic and advanced interaction requirements (R1 &amp; R2). Three forensic institutes were visited to gather in-depth information about MVT design requirements within forensic work. In these discussions the importance of real-world similarity was underlined (R4). Moreover, practical requirements on collaboration (R6) and maintenance (R8) were again brought forward. From the very early stage of MVT development repeated discussions with potential users and independent peers (medical IT professionals) were performed that included hands-on testing of the latest version of the evolving MVT. The importance of responsiveness and robustness (R5) was commonly emphasized and the collaborative need for effective hand-overs (R7) was identified. The refined collaboration-centric requirements (R6, R7) were motivated by a perceived risk that, despite the intentions, the MVT would often not be able to engage all persons around the table in interaction. Next we will describe how these design requirements were realized in our system. First there is a description of the overall design and in the following subsections the rendering engine and key interaction components are presented in more detail. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Overall design</head><p>A number of design decisions concerned the hardware of the table. A major requirement here was the element of realism (R4). The conclusion was to keep the demonstrator's targeted experience of " a patient on a table " which lead to the choice of a large screen, 46 inches at 1920x1080p resolution, primarily intended for horizontal display. However, it was also concluded that the possibility for vertical display would allow the table to be more versatile in terms of usage scenarios since it would be visible from a larger distance and be less spaceconsuming (R8). Therefore, a tiltable stand was selected, allowing horizontal, vertical and slanted orientations as shown in <ref type="figure" coords="4,224.10,706.11,26.52,8.02" target="#fig_1">figure 5</ref>. Several technologies for touch interaction were assessed. The demonstrator experience was that a multi-touch technology was preferable. Moreover, the environment in health care can be ing and the interaction must be robust with regards to various lighting conditions (R5, R8). For camera-based systems that detect gestures optically through the screen the lighting robustness is a problem and they are also prone to needing recurring calibration efforts. The selected technology was instead based on infrared sensors placed on top of a regular screen, which proved to have sufficient responsiveness (R5). Currently this solution does not allow sterile touch interaction, which needs to be solved if the MVT is to be used by the surgeon in the operating room. Further hardware considerations was to create an appealing and solid appearance (R3). The intuitiveness of the system (R1) was in part addressed by the touch technology and also by the design decision to let the medical image heavily dominate the screen area, as for the demonstrator. There are no menus or toolbars visible and very few other GUI elements. This clean design is also intended to attract interest and desire to start using the system (R3). Perspective projection with a fixed angle is used. On demand, the user can launch a set of browsable Multiplanar Reconstruction (MPR) views showing the three main orientations. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Volume rendering engine</head><p> The volume rendering software in the table consists of GPU-based raycasting using Direct3D version 10 and high-end off-the-shelf graphic boards. Data is processed in texture blocks, sized 512 3 at maximum. Textures overlap by one voxel to enable hardware-accelerated trilinear interpolation. Acceleration based on empty-space skipping is employed , based on block geometries according to <ref type="bibr" coords="4,458.34,593.68,13.74,8.02" target="#b33">[34]</ref>. In the default configuration, the rendering engine maintains a fixed high frame rate (25 fps) and reduces the rendering quality if necessary. Quality reduction is achieved by increasing the sample step size along the ray, whereas the ray density is always one ray per screen pixel. At full quality, the rate is 2.5 samples per voxel and a typical interaction quality corresponds to 1.33 samples per voxel. A representative scenario is shown in <ref type="figure" coords="4,365.37,663.76,27.96,8.02" target="#fig_2">figure 6</ref>: a data set of 512x512x1895 voxels, rendered in a 1920x1080 viewport with 1.33 samples per voxel on an nVidia GeForce GTX580. Using the typical transfer function shown, the system achieves a frame rate of 23 fps. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Touch gesture design</head><p> The experience from the VAT demonstrator was that 4 DOF interaction was overly limiting. Therefore, the touch gestures designed for a b c d the MVT enable 6 DOF, x-y pan, x-y-z rotation and zoom, through a combination of one-and two-finger interactions in the 2 DOF touch input to the screen. Illustrations of the gestures are shown in <ref type="figure" coords="5,249.96,372.45,26.52,8.02" target="#fig_3">figure 7</ref>. Rotation around x-and y-axes is connected to a single-touch movement and is relative to a global reference point. The reference point is by default set to the middle of the volume. The user can also explicitly define the global reference point through a double touch, which selects the closest visible point of the volume corresponding to the screen position . A fixed mapping of input movement to amount of rotation is used, typically set at 0.2 degrees per screen pixel. The other DOF are rotate-scale-translate (RST) interactions achieved by two-touch pinching, which for 2D is well known in many touch applications. Rotation around the z-axis is connected to the angular movement of the directed line between the two touch points. The rotation axis is at the midpoint between the touch points, referred to as the " touch midpoint " . Panning in the x-y-plane is determined by the xy movement of the touch midpoint. Because of the perspective model it is necessary to identify a depth for which the panning movement is equal to the input movement. This is defined as the closest visible point at the z-axis of the touch midpoint. Finally, the distance between the touch points determines the zoom factor, changing the distance corresponds to changing the zoom with the same factor. The three two-point gestures are available simultaneously which is intended to give a sense of direct and complete control (R1) and a typical twopoint gesture would invoke all three interactions to some extent. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5">Movable alternator pucks</head><p>As previously described, the toolset of the VAT was not considered sufficient by potential users. A broad feature set is, however, an interaction challenge since the number of intuitive touch gestures is limited. A solution that has been proven effective in the past is to let a limited set of base features be directly available to the user whereas the remaining features are available after additional activation, still through straightforward touch gestures (R2). Applying a function then turns into a compound task: enter mode, execute function, exit mode. Bux- ton <ref type="bibr" coords="5,45.61,706.53,10.45,8.02" target="#b5">[6] </ref>argues that touch activation is an intuitive approach to realize temporary states for compound tasks. Yu et al. <ref type="bibr" coords="5,205.29,716.50,14.94,8.02" target="#b41">[42] </ref>employed frame areas for activation. One drawback with such an approach is that the area for unobscured view of the rendered image is decreased. <ref type="figure" coords="5,294.12,180.71,18.89,7.37">Fig. 8</ref> . Using the moveable alternator pucks. Activate the puck by holding it with one hand and perform the desired action with the other. more, with several frame areas representing different feature sets it is difficult to provide equal access to the tools at every position around the table. To address the challenge of supporting a large feature set we developed an approach employing movable alternator objects, referred to as " pucks " due to their round shape and behavior. The alternator pucks activate specific feature sets. In our current implementation there are three pucks corresponding to TF adjustment, TF preset selection, and clip plane interaction. The user touches and holds the puck with one hand and performs the desired interaction with the other hand (<ref type="figure" coords="5,524.00,472.98,20.49,8.02;5,294.12,482.94,3.24,8.02">figure  8</ref> ). As soon as the puck is released the base features are again avail- able. The mobility of the pucks enables equal access for all table users, and this is further emphasized by the round shape (R6). Rotationally invariant puck design (R6) is available for TF selection and clip plane thickness, as shown in <ref type="figure" coords="5,378.69,533.20,27.08,8.02" target="#fig_5">figure 9</ref>. Thumbnails representing TF presets are optionally presented in a radial layout. Browsing and focusing on thumbnails is done through a single-finger touch. The clip plane thickness is set by the diameter of a circle around the clip puck. An additional advantage of the movable puck approach in the collaborative context is that all users know which person in the group is currently in control (R7), which is another improvement of the MVT over the VAT. The result is that for the base features, such as rotation, everybody can interact and when more advanced features, such as clip planes, are being used a single person interacts and it is clear who it is. Passing on the control to another user is done by sliding the puck across, like a relay race baton. As suggested by Hornecker et al. <ref type="bibr" coords="5,527.31,643.22,13.74,8.02" target="#b14">[15]</ref>, the intent is to provide an effective way of handling interference between collaborators. For increased realism, the pucks are subjected to a virtual friction as they slide and puck collisions are handled according to the laws of physics. Furthermore, when the table is in vertical mode a gravity force can be applied pulling the pucks downwards. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VISUALIZATION AREA </head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.6">Natural size zoom</head><p>Similarity to corresponding clinical situations with a real patient is one of the identified key design factors for the visualization table (R4). Displaying the patient data in natural size is an important part of the experience of realism. Perspective projection is used for the volume rendering of the MVT in order to achieve best possible depth cues. Using perspective projection means, however, that the concept of natural size is undefined since the size depiction depends on the depth position . Our solution to this problem was to provide a straightforward way for the user to define which part of the data that the natural size calibration should be performed on. </p><p> To apply natural size magnification the user selects a rectangular region of interest (ROI), see <ref type="figure" coords="6,119.76,488.65,30.93,8.02" target="#fig_6">figure 10</ref>. The touch gesture used consists of four fingers representing the corners of a rectangle. The gesture acts both as an activation of the natural size command and as the definition of the ROI. In case the four positions significantly deviate from a rectangular shape, the natural size command is not activated, which allows for other four-point gestures to be available simultaneously. As an indication that the natural size gesture has been recognized, the system displays a corresponding rectangle frame on the display. The system then analyzes the content of selected ROI along the full depth in the virtual projection model. A depth map of visible (having non-transparent TF mapping) points is collected. From this depth map a reference point is derived. Finally, the plane that is parallel to the screen plane and includes the reference point is the one to be shown in natural size on the screen. The calibration requires that the physical sizes of voxels and display are known. The magnification consists of both a zoom and a pan operation, through which we ensure that the screen position of the reference point remains fixed to allow undisturbed focus of attention for the user. </p><p>There are many possible solutions for deriving the reference point from the depth map. We opted for the straightforward approach to use the point closest to the screen plane, see figure 11. The derivation of the depth map can be done in different ways, in our current implementation 100 rays are cast evenly spread in the ROI. The implementation could easily be made more precise but we anticipate that it would make little difference for the user experience. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">USER STUDY DESIGN</head><p>A user study was performed in order to assess the MVT system in a major intended application area, namely treatment planning by orthopedic surgeons. The study was set up to mimic a realistic clinical scenario and included physicians reviewing two actual patient cases using the table. The objective was to overall evaluate the potential clinical usefulness of the MVT but also to receive feedback on the fulfillment of the design requirements described in section 5.1, primarily R1-R5. In order to receive as broad feedback as possible, each surgeon took part independently. The drawback of this decision was that the assessment of collaborative aspects such as R6-R7 could not be based on hands-on usage. The user study also aimed to gather opinions regarding future development. We opted for a predominantly qualitative user study, complemented by a minor quantitative questionnaire, since we judged that broad and deep insights were only attainable through observation in combination with an open and flexible interview format . It has previously been shown that a qualitative approach is the most feasible approach in this type of studies <ref type="bibr" coords="6,448.98,226.11,9.71,8.02" target="#b6">[7,</ref><ref type="bibr" coords="6,460.93,226.11,10.64,8.02" target="#b40"> 41]</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Participants</head><p> Five persons participated in the study, all employed as orthopedic surgeons at a university hospital. Their level of expertise ranged from residents that graduated three years ago (two, both female, both 29 years of age) to attending specialists (three, all male, ages 50, 51 and 54) with more than 20 years of experience. All of the participants were potential users of the table in their current work and they were familiar with it as a concept. However, none had seen or tried the table prior to the study. They received no compensation for taking part in the evaluation. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Task and procedure</head><p>Each participant took part in the study on an individual basis, one at a time. First demographic background information was obtained regarding their age, gender, experience and expertise. Participants then reviewed a written instruction material before the actual session at the table began. Participants were explicitly encouraged not to feel any pressure to give positive assessments, although they were aware of that one of the experimenters was involved in the development of the table. The session at the table consisted of two parts. First, there was a demonstration. This prepared tutorial provided an overview of the table and a step-by-step walk-through of its interface components and their basic functionality. This demonstration never exceeded five minutes . Second, participants were given two authentic cases of pelvic fractures, with which they interacted independently. The starting point of the cases was a 3D front view of the pelvis. This view could then be subject to interaction and alteration according to each participant's choice. The overall tasks were to diagnose the fracture and plan the treatment. The treatment planning included a decision on whether to perform surgery or not, and if so, also to describe appropriate procedures and material needed for the surgery. The reason for having specific tasks was to provide a goal for using the table rather than telling the participants to explore it freely. The two specific tasks were chosen since they represent the pre-operative planning actions that the orthopedic surgeons perform when faced with a fracture. While carrying out the tasks the surgeons were instructed to " think aloud " , meaning that they should describe what they did, why they did it, and also what they would like to do. Our main interest was to gain as much information as possible about how the table supported the surgeon when working on these tasks. Therefore participants were encouraged to ask questions and request help. Assistance was given primarily when the surgeons expressed intended actions beyond the basic interaction, by introducing additional features available in the table. To a small extent, reminders about the basic functionality and other information to resolve confusion was given. We let each participant work on two different cases, the second one was presented when the participant had agreed on being finished with the first. The motivation for this was to encourage as much interaction as possible within a reasonable time-frame. Consequently, order of presentation of the two cases was not a factor that could affect the outcome of this study negatively. One experimenter engaged in the demonstration of the table and in assisting the participant when needed. A second experimenter took notes and also documented the session by voice recording. A prepared interview guide was used. It included a set of predefined questions that covered various aspects of the design goals (section 5.1) and also a number of potential questions used to prompt the participant to " think aloud " when needed. Both experimenters engaged in the conversation and made sure that all questions in the interview guide were covered by the end of the session. Some questions were discussed while participants worked on the cases and some were reviewed afterwards. After using the table participants completed a subjective satisfaction questionnaire. The responses were given on a 5-point rating scale: Strongly unfavorable (1), Unfavorable (2), Unsure (3), Please note that while the list above well represents the statements rated by the participants, the wording has been translated and slightly changed to clarify reporting of the results. A full session lasted for approximately 50 minutes including all parts. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">RESULTS</head><p>The user study proved effective for the objective of collecting distinct and broad feedback from the orthopedic surgeons about how the visualization table would fit in their application domain. They did not consider the " think aloud " approach to be distracting from the evaluation tasks. The overall assessment from the surgeons is that the table would be useful in their clinical work. This is illustrated by the numerical ratings in the post-session questionnaire, see figure 12. Responses for the eleven statements has a group mean value 1 of 3.8 (two statements), 4 (two statements) and above 4 (seven statements) respectively, all corresponding to a clearly favorable rating. Statistical significance was, however, not achieved but this is to be expected for this small study. There is only one example of a negative rating, one surgeon expressed moderate disagreement with the table's potential to improve efficiency during surgery (specialist, age 50). There were three statements concerning general impressions of usefulness, Overall impression, Willingness to use, and Recommend to others, and in all three cases the study shows a strongly favorable mean rating of 4.4. Both the younger and less experienced participants and the older specialists contributed to all levels of the rating scale (3-5). Hence, for this participant pool, age and level of experience did not seem to affect the attitude towards the technique. The issues behind the rather general statements in the questionnaire were discussed in greater detail during the sessions at the table and these findings provide a more nuanced and informative view of opinions . Below, these findings are summarized under the following four subheadings: Ease of use and learnability, Clinical usefulness, Workflow , and Desired features. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1">Ease of use and learnability</head><p>Low learning threshold and high usability were central objectives in the design of the system, reflected by design requirements R1-R5. Regarding the overall impression of the table all participants expressed positive statements. The interface was considered intuitive and convenient , and it was easy to learn how to use the basic functionality . The comments about learning threshold expressed an anticipation that novice users would quickly learn the basic functionality, although some of the more advanced functionality (activated via the pucks) would require some practice. All appreciated the clean interface with only a few visible GUI elements and emphasized the benefit and importance of the screen being focused towards visualizing the 3D image. Regarding the interaction, the touch gestures were described as intuitive and straightforward to use, also for one of the participants who pointed out that he had never used a touch-controlled interface before (specialist, age 54). The surgeons were asked if they perceived the interaction as robust and responsive. They all concurred, through statements that the result of actions on the screen was what they expected and that they felt in control. Nobody mentioned that the level of precision provided by the touch technology and the RST interaction was insufficient or problematic. Even though the participants did not bring it up, the experimenters noted a few occasions of unintentional gestures due to holding the knuckles of inactive fingers too close to the surface. The typical effect was that panning occurred instead of an intended x-y-rotation, which the users dealt with by lifting the hand and reapplying the rotation gesture. For the additional MPR slice views it was commented that touch gestures were more efficient for transversal browsing than using a mouse. The pucks were, in general, described as a convenient approach for reaching additional features. The interaction that caused some confusion was the advanced parts of the clip plane functionality, namely to control and understand slab clipping. The surgeons adopted the natural size zoom as an integral part of the toolset and no usability obstacles could be noted. It was pointed out that displaying the data in real size could be very useful for treatment planning when deciding on what material to use (e.g., size of plates). Nevertheless, for a majority of the session time a higher zoom level than the natural size was used, for instance for various close-up views. An indication of overall ease of use was that, when asked about how they experienced their session, everyone stated that the very brief introductory demonstration covered their needs to start using the table. The positive impression of the interaction was reflected by spontaneous comments such as: " It is so much better to have both your eyes and your fingers in the image " (resident, age 29) " It is very fun to interact with the table and that is an aspect that should not be neglected " (specialist, age 50) </p><p>The first comment describes an experience that the MVT is less of an obstacle for the image review reasoning process, as compared to the mouse and keyboard practice this surgeon was used to. The second comment illustrates the enjoyment that all participants expressed when using the touch screen, but also underlines that the allure of the system (R3) can be important for its clinical adoption. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2">Clinical usefulness</head><p>The view that the table is a relevant and useful tool for clinical practice was expressed by all orthopedic surgeons. The usefulness was primarily pertinent for complex cases. A complicated fracture, for instance, was described to be effectively studied using the table. The surgeons appreciated reviewing the bone fragments and their relation to other parts. The think-aloud clinical comments revolved around how to remove or put fragments together, what materials to use, where and in which angle to drill, etc. One surgeon (resident, age 29) commented that using the touch interface is a type of motor learning exercise, beneficial as a preparation for the surgical task. Whereas most comments made were in favor of the system, as also illustrated by the quantitative results, one of the surgeons (specialist, age 50) was more reserved when assessing the usefulness. All participants except him said spontaneously that they immediately saw significant value in MVT usage. Although he acknowledged the added benefits, he stated to manage very well with the imaging available today , and assessed that the benefits would not be any significant improvement for him personally. He also stated, however, that the reason for the already satisfactory situation was because the radiologists were highly supportive in providing suitable static 3D renderings as requested. The surgeons' assessments of the table was made in the context of the current practice of being provided 3D snapshots in a series of angles around a certain axis. All agreed on that the free 6 DOF interaction of the table provided substantial additional value. One reason is that for any clinical question that arises, the best possible view to assist the investigation is always available. During the session it was also evident that the surgeons intuitively rotated slightly back and forth around the selected viewpoint, presumably to get a clearer mental 3D model. Compared to not having 3D snapshots (viewing only 2D slices), the surgeons described even larger benefits with the table, in terms of effectively and efficiently comprehending complex anatomy. Nevertheless, all surgeons agreed that the 3D rendering alone is by no means sufficient for their needs, the combination with 2D slices is essential . Thus, the possibility to bring up browsable MPR views was highly appreciated. The need for MPR views was mainly due to the fact that internal structures of the bone are often very difficult to depict in 3D, and, to a lesser degree, that the surgeons were accustomed to primarily work in 2D. Two types of usefulness were discussed, time savings and quality of work improvements. The main advantage the surgeons expressed was increased confidence during the surgical procedure. A logical consequence of such statements would be that the result would be shorter operation times, fewer complications and/or better outcomes. However , some surgeons were hesitant to drawing far-reaching conclusions to that end. Others (resident, age 29, and specialist, age 51) were more conclusive and both used the following statement to emphasize the benefit of efficiency as well as quality: " If you are well prepared when you go into surgery you decrease the 'open wound' time " </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.3">Workflow</head><p>In this section we present results regarding visualization table aspects with respect to the treatment planning workflow stages: initial assessment , pre-operative planning, intra-operative guidance, and postoperative follow-up. The main result is that the surgeons believed that the table would be a valuable tool during all stages of work. The major advantage of the table and the volumetric visualization was seen for pre-operative planning, both to make the treatment decision and then plan the operation in more detail. This was particularly stressed by the two less experienced surgeons. They appreciated the table as an aid in creating an accurate mental 3D model, which is essential to create before going into surgery, especially for complex anatomy. Several surgeons brought up the possibility to use the table in the operating room to refresh the mental 3D model and produce visualizations tailored for specific decision points that arise during the operation . Regarding intra-operative use the surgeons pointed out the importance and challenge of supporting sterile touch interaction, which is not yet supported by the MVT. The usefulness for post-operative follow-up was also anticipated to be significant, since judging the outcome of treatment often includes complex three-dimensional assessments . Finally, one participant (resident, age 29) spontaneously commented that the MVT would be very suitable for training purposes. The orthopedic surgeons disagreed somewhat on whether collaboration would be more effective using the table. The ones in favor agreed that the size of the screen was important to support collaboration . It was seen as valuable that everyone can easily interact with and manipulate the view regardless of position. The alternator pucks were acknowledged to fulfill this requirement. The surgeons' current image review practice was described as limited with respect to collaboration since one person is in charge of the mouse and others have to ask for interaction and potentially switch position to use the mouse. The surgeons saw the benefits of the table format and the puck mobility in this respect. However, one participant (specialist, age 50) pointed out the fact that for many cases everyone wants to see the same view of an image. The users must then stand at one side of the table, which means that there is only room for 2-3 persons. Regarding the possible orientations of the table the surgeons' preference was dependent on usage scenario and ergonomics. When used pre-and post-operatively the horizontal orientation was considered better especially when several persons use it together. When used at surgery a vertical orientation was requested. The surgeons would not like to leave the patient to lean over another table, therefore the visualization should be visible at a distance. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.4">Desired features</head><p>The user study resulted in several suggestions of desired additional features in a medical visualization table intended for orthopedic surgeons . The table system version in the user study lacked standard tools such as segmentation and length/angle measurements, and this was requested . The main use of segmentation would be to remove parts of the skeleton for a clearer view, in a better way than a clip plane can do. One example is to remove the femur (thigh bone) to reveal the acetabulum (hip joint surface). A better visualization of muscles and tendons was requested, as this information is important for some treatment decisions. Since the data acquisition method does not separate different types of soft tissue well, it is difficult to tackle this problem in the visualization step. There were also more visionary suggestions to create a full virtual operation using the table. This would require virtual representations of all materials used and the possibility to move bone fragments as done during surgery. Given the plethora of materials and implants, trying out the best choice in advance would save surgery time and improve clinical outcomes. Additional benefits of such simulation systems would be for effective training. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">DISCUSSION</head><p> In this section we discuss the lessons learned with regards to the application design, summarize the realized benefits for the application domain and, finally, suggest some future work. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.1">Design lessons learned</head><p>A number of design lessons relevant for the targeted domain have been learned during the course of our work. The design requirements from section 5.1 are one part, and the positive results from the user evaluation demonstrate that at least R1-R5 are relevant. On a more detailed application level, additional lessons pertaining to table-top visualization systems in clinical scenarios have been learned: L1: A large multi-touch display can be suitable as a visualization solution for real clinical scenarios. L2: A clean interface dominated by the rendering inspires to interac- tion. L3: The similarity to real-world situations provided by 3D imaging in a table format is important. L4: 6 DOF interaction with the 3D rendering is necessary. L5: Clipping along main axes is not sufficient, free orientation is needed. L6: 3D renderings alone are not sufficient, the combination with slice-based views is preferred. L7: Movable alternator pucks are practicable for enabling large feature sets with few touch gestures. L8: The ROI approach for natural size zoom in perspective projection is feasible and useful. </p><p>As lessons L1–L4 are the result of consistent feedback from many sources, it is reasonable to assume that they are generally applicable for the medical domain as long as imaging is a central clinical component . Lessons L7 and L8 relate to very general concepts and are thus also likely to have a wide applicability. Lessons L5 and L6, on the other hand, stem solely from the orthopedic surgeons' feedback and are probably more pertinent for medical professionals with advanced image review needs. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.2">Domain insights enabled</head><p>The evaluation showed that in a pre-operative setting the MVT enables the orthopedic surgeons to reach insights important for their clinical task. Furthermore, the table provides advantages compared with current imaging tools. The orthopedic surgeons claimed to get a better understanding of complex anatomy, to get better support for planning the surgery procedure, and to get a better foundation for follow-up assessments. The ability to freely investigate a fracture in 3D views allows a detailed perception of fragments and their surrounding that is hard to achieve using 2D slice images or static 3D imaging only. The table supports effective insight creation for surgery planning in terms of trying out hypothesis and revealing unexpected findings. The table assists in creating the accurate mental 3D model of the patient's anatomy that is necessary to comprehend before going into surgery. This is vital for planning on how to place the incisions, how to reconstruct the fracture by fitting the bone fragments together, what material to use and how it should be placed and fastened. The natural size capability of the MVT contributes to these insights. A relevant question is if the visualization table is pivotal for providing 3D capabilities to the domain, or if regular 3D applications could bring the same improvement. The study supports the conclusion that the table does make a significant difference, since the surgeons were favorable to the similarity to the real-world situation of having a patient in front of them. Another indication to the same end is that despite the maturity of 3D applications, wide-spread usage in this domain has not been achieved. </p><p> The orthopedic surgeons in this study expressed that the radiologists they worked with were very supportive about providing images and reconstructions specifically for treatment planning and follow-up. Furthermore, their experience was that this was not the case in other institutions which means that for instance series of 3D snapshots could be rare elsewhere. While not studied in this work, it seems likely that the clinical usefulness of the visualization table would be even greater in scenarios where orthopedic surgeons have more limited support for advanced visualization from the radiologists. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.3">Future work</head><p> While aiming to mimic a clinical pre-operative situation, the evaluation was not performed in a true clinical workflow where MVT usage was followed by an actual operation. Thus, further studies under such conditions are needed to verify the clinical value of the MVT predicted by the orthopedic surgeons in our study. Such future work is also pertinent for use during surgery and for post-operative follow-up, which in this paper was studied only in the form of the surgeons' anticipations . An important part of future evaluations is to include quantitative assessments of the effectiveness and efficiency (accuracy of treatment planning, time saving, treatment outcome quality, etc) of the MVT to further establish its value in this application domain. Finally, the collaborative aspect needs to be investigated further, in order to verify the predictions from the surgeons based on individual use. Both surgeonsurgeon and surgeon-radiologist collaborations are of interest. As the needs and prerequisites in post-operative use of the MVT are very similar to pre-operative use, it is likely that the clinical benefits are also similar. A prioritized development for the MVT is to support sterile interaction for intra-operative use. Motion sensors could be a solution, but performance in terms of robustness, responsiveness, and accuracy needs to be evaluated. Potentially, the GUI and gesture set need to be adapted. Medical education is another application domain where the visualization table could offer benefits, and in particular anatomy and pathology studies. In recent years the dominant role of cadaver use has been questioned in favor of medical imaging material <ref type="bibr" coords="9,472.79,402.57,14.94,8.02" target="#b28">[29] </ref> and 3D visualizations of actual clinical cases has been successfully used <ref type="bibr" coords="9,504.16,412.53,13.74,8.02" target="#b36">[37]</ref> . Compared to visualization of 3D models, the ability to use clinical patients makes it possible for the students to review a broad range of normal variants, rather than just a single example. In many respects the visualization sessions in anatomy education is similar to the clinical situations described in section 3.1. Future work includes specifically tailoring our system for teaching purposes. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="3,294.12,190.81,250.38,7.37;3,294.12,200.28,250.38,7.37;3,294.12,209.74,64.84,7.37"><head>Fig. 4. </head><figDesc>Fig. 4. The Virtual Autopsy Table demonstrator, that provided important user experience feedback considered in the development of the Medical visualization table. </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="4,285.12,148.29,250.38,7.37;4,285.12,157.76,176.23,7.37"><head>Fig. 5. </head><figDesc>Fig. 5. A tiltable design was selected for the Medical Visualization Table, in order to enable use in many different scenarios. </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="4,285.12,300.04,250.38,7.37;4,285.12,309.50,187.43,7.37"><head>Fig. 6. </head><figDesc>Fig. 6. An example rendering created by our DVR module. At 1.33 samples per voxel, a frame rate of 23 fps is achieved. </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="5,31.50,301.25,250.38,7.37;5,31.50,310.72,250.38,7.37;5,31.50,320.18,218.61,7.37"><head>Fig. 7. </head><figDesc>Fig. 7. Touch gesture design. a) Rotation around x-and y axis with single finger. b) Rotation around z-axis with two fingers. c) Panning in x-y-plane with two fingers. d) Zooming with a two-finger pinch. </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5" coords="5,294.12,331.93,250.38,7.37;5,294.12,341.39,250.38,7.37;5,294.12,350.86,196.00,7.37"><head>Fig. 9. </head><figDesc> Fig. 9. Rotation-invariant puck design, enabling usage from any direction . Left: Radial design of TF preset catalog. Right: Radial design of clip plane thickness, a circle around the alternator puck. </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6" coords="6,22.50,192.35,250.38,7.37;6,22.50,201.81,250.38,7.37;6,22.50,211.28,128.40,7.37"><head>Fig. 10. </head><figDesc>Fig. 10. Natural size zoom. A four-finger gesture outlining a rectangle both activates the natural size zoom calibration and selects the region of interest to base the calibration on. </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7" coords="6,22.50,345.37,250.38,7.37;6,22.50,354.84,248.58,7.37"><head>Fig. 11. </head><figDesc>Fig. 11. Derivation of reference point for the natural zoom calibration. In our implementation the closest visible point is used, as illustrated here. </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8" coords="7,230.32,193.08,51.56,8.02;7,31.50,203.05,250.37,8.02;7,31.50,213.01,23.91,8.02;7,39.72,233.27,217.42,8.12;7,39.72,245.98,242.15,8.12;7,51.43,256.05,124.92,8.02;7,39.72,268.66,242.16,8.12;7,51.43,278.73,114.18,8.02;7,39.72,291.33,242.15,8.12;7,51.43,301.40,138.30,8.02;7,39.72,314.00,242.15,8.12;7,51.43,324.07,86.07,8.02;7,39.72,336.67,229.61,8.12;7,39.72,349.38,180.82,8.12;7,39.72,362.09,242.16,8.12;7,51.43,372.17,209.35,8.02;7,39.72,384.77,242.15,8.12;7,51.43,394.84,152.77,8.02;7,35.24,407.44,246.64,8.12;7,51.43,417.51,230.44,8.02;7,51.43,427.47,29.14,8.02;7,35.24,440.08,246.64,8.12;7,51.43,450.15,170.23,8.02"><head></head><figDesc>Favorable (4), and Strongly favorable (5). The questionnaire covered the following issues: 1. Overall impression: The overall impression of the table. 2. Willingness to use: Whether the orthopedic surgeon would like to use the table in their daily work. 3. Efficiency for planning: Whether using the table would save time for pre-operative planning. 4. Efficiency for surgery: Whether using the table pre-operatively would save time during actual surgery. 5. Quality of work: Whether using the table would improve the quality of clinical work. 6. Learnability: Ease of learning table usage for a novice user. 7. Interaction: Ease of interacting with the table. 8. Benefits over static imaging: Whether interactive 3D imaging is superior to the series of static 3D snap-shots used today. 9. Collaboration: Whether access to the table at work would facilitate collaboration between several people. 10. Similarity to real situation: Whether the similarity to a real situation (patient lying on a table) facilitates insights and decision making. 11. Recommend to others: Whether the orthopedic surgeon would recommend colleagues to use the table at work. </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9" coords="7,294.12,226.87,250.38,7.37;7,294.12,236.34,250.38,7.37;7,294.12,245.80,250.38,7.37;7,294.12,255.27,250.38,7.37;7,294.12,264.73,250.38,7.37;7,294.12,274.20,75.36,7.37"><head>Fig. 12. </head><figDesc> Fig. 12. The quantitative results of the user study questionnaire. Subjective satisfaction regarding use of the table was measured for 11 questions , see section 6. The 5-point rating scale ranges from Strongly unfavorable (1) through Unsure (3) to Strongly favorable (5). Vertical red bars denote the mean value and horizontal blue lines denote the full span of given ratings. </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false" coords="2,22.50,51.14,513.00,693.29"><figDesc coords="2,241.36,706.53,31.51,8.02;2,22.50,716.50,250.37,8.02;2,22.50,726.46,250.37,8.02;2,22.50,736.42,250.37,8.02">achieved a 3D extension to RST also using virtual contact points. An error minimization solver in screen space finds the RST operation that best corresponds to the new screen position of the touch points. Another</figDesc><table coords="2,285.12,51.14,250.38,123.13">Imaging exam-
ination order 

Image-guided 
treatment planning 

Diagnostic 
image review 

Imaging data 
acquisition 

Referring 
physician 

Radiologist 

Image-guided 
treatment 

Follow-up 

1 

2 
3 

4 

Fig. 2. Overview of physician roles and activities related to the medical 
imaging workflow. Numbers refer to activities relevant for this paper, see 
figure 3. 

</table></figure>

			<note place="foot" n="1"> It can be discussed whether averaging in an ordinal scale is appropriate, our conclusion is that in this case it is the best way to convey the results, in combination with the min-max measures in figure 12.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGEMENTS </head><p>The authors wish to thank the orthopedic surgeons participating in the user study as well as the group of designers and developers that has worked on the implementation of the VAT prototype and the MVT: David Karlsson, Per Elmhester, Magnus Ranlöf, Aron Ernvik, Joackim Pennerup, Igor Milososki, Erik Edespong, Hong Lo, and Willem Frishert . Martin Nyström is acknowledged for contributions to the domain analysis. Finally, the authors thank the anonymous reviewers for their valuable improvement suggestions for the paper. </p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct coords="9,312.38,603.11,232.12,8.61;9,312.38,614.06,120.17,7.13"  xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Digital Lightbox</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2011-03" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,312.38,623.52,232.12,7.13;9,312.38,632.99,232.12,7.13;9,312.38,642.45,232.12,7.13;9,312.38,651.92,200.70,7.13"  xml:id="b1">
	<analytic>
		<title level="a" type="main">Optimizing Analysis, Visualization , and Navigation of Large Image Data Sets: One 5000-Section CT Scan Can Ruin Your Whole Day</title>
		<author>
			<persName>
				<forename type="first">K</forename>
				<surname>Andriole</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Wolfe</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Khorasani</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Treves</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Getty</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">F</forename>
				<surname>Jacobson</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Steigner</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Pan</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Sitek</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Seltzer</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Radiology</title>
		<imprint>
			<biblScope unit="volume">259</biblScope>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,312.38,661.38,232.12,7.13;9,312.38,670.85,232.12,7.13;9,312.38,680.31,186.83,7.13"  xml:id="b2">
	<analytic>
		<title level="a" type="main">Usability comparison of mouse-based interaction techniques for predictable 3d rotation</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Bade</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">F</forename>
				<surname>Ritter</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">B</forename>
				<surname>Preim</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Smart Graphics</title>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,312.38,689.77,232.12,7.13;9,312.38,699.24,232.12,7.13;9,312.38,708.70,232.12,7.13;9,312.38,718.17,33.87,7.13"  xml:id="b3">
	<analytic>
		<title level="a" type="main">3D user interfaces: New directions and perspectives</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Bowman</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Coquillart</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">B</forename>
				<surname>Froehlich</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Hirose</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">Y</forename>
				<surname>Kitamura</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">K</forename>
				<surname>Kiyokawa</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">W</forename>
				<surname>Stuerzlinger</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics and Applications</title>
		<imprint>
			<publisher>IEEE</publisher>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="2820" to="2856" />
			<date type="published" when="2008" />
			<publisher>IEEE</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,312.38,727.63,232.12,7.13;9,312.38,737.10,222.92,7.13"  xml:id="b4">
	<analytic>
		<title level="a" type="main">Clinical, educational, and epidemiological value of autopsy</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">L</forename>
				<surname>Burton</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Underwood</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">LANCET</title>
		<imprint>
			<biblScope unit="volume">369</biblScope>
			<biblScope unit="issue">9571</biblScope>
			<biblScope unit="page" from="1471" to="1480" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,40.76,54.06,232.12,7.13;10,40.76,63.52,232.12,7.13;10,40.76,72.99,49.81,7.13"  xml:id="b5">
	<analytic>
		<title level="a" type="main">Chunking and phrasing and the design of human-computer dialogues</title>
		<author>
			<persName>
				<forename type="first">W</forename>
				<surname>Buxton</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IFIP World Computer Congress</title>
		<meeting>the IFIP World Computer Congress</meeting>
		<imprint>
			<date type="published" when="1986" />
			<biblScope unit="page" from="475" to="480" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,40.76,82.45,232.12,7.13;10,40.76,91.92,232.12,7.13;10,40.76,101.38,232.13,7.13;10,40.76,110.85,112.75,7.13"  xml:id="b6">
	<analytic>
		<title level="a" type="main">Evaluating information visualizations</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Carpendale</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Information Visualization</title>
		<editor>A. Kerren, J. Stasko, J.-D. Fekete, and C. North</editor>
		<meeting><address><addrLine>Berlin / Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2008" />
			<biblScope unit="page" from="19" to="45" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,40.76,120.31,232.12,7.13;10,40.76,129.78,232.12,7.13;10,40.76,139.24,232.12,7.13;10,40.76,148.70,232.12,7.13;10,40.76,158.17,17.93,7.13"  xml:id="b7">
	<analytic>
		<title level="a" type="main">Slice WIM: a multi-surface, multi-touch interface for overview+ detail exploration of volume datasets in virtual reality</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Coffey</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">N</forename>
				<surname>Malbraaten</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Le</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">I</forename>
				<surname>Borazjani</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">F</forename>
				<surname>Sotiropoulos</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Keefe</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Symposium on Interactive 3D Graphics and Games</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="191" to="198" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,40.76,167.63,232.12,7.13;10,40.76,177.10,232.12,7.13;10,40.76,186.56,232.12,7.13"  xml:id="b8">
	<analytic>
		<title level="a" type="main">The DabR -a multitouch system for intuitive 3D scene navigation The True Vision - Capture, Transmission and Display of 3D Video</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Edelmann</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Schilling</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Fleck</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">3DTV Conference</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="1" to="4" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,40.76,196.03,232.12,7.13;10,40.76,205.49,229.44,7.13"  xml:id="b9">
	<analytic>
		<title level="a" type="main">On 3D input devices</title>
		<author>
			<persName>
				<forename type="first">B</forename>
				<surname>Fröhlich</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Hochstrate</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Kulik</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Huckauf</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer Graphics and Applications</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="15" to="19" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,40.76,214.96,232.12,7.13;10,40.76,224.42,232.12,7.13;10,40.76,233.88,120.87,7.13"  xml:id="b10">
	<analytic>
		<title level="a" type="main">A user interface for VR-ready 3D medical imaging by off-the-shelf input devices</title>
		<author>
			<persName>
				<forename type="first">L</forename>
				<surname>Gallo</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Minutolo</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">G</forename>
				<forename type="middle">D</forename>
				<surname>Pietro</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computers in Biology and Medicine</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="350" to="358" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,40.76,243.35,232.12,7.13;10,40.76,252.81,232.12,7.13;10,40.76,262.36,232.12,6.86;10,40.76,271.74,136.58,7.13"  xml:id="b11">
	<analytic>
		<title level="a" type="main">Shallow-depth 3d interaction: design and evaluation of one-, two-and three-touch techniques</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Hancock</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Carpendale</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Cockburn</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the SIGCHI conference on Human factors in computing systems, CHI &apos;07</title>
		<meeting>the SIGCHI conference on Human factors in computing systems, CHI &apos;07</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="1147" to="1156" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,40.76,281.21,232.12,7.13;10,40.76,290.67,232.12,7.13;10,40.76,300.14,232.12,7.13;10,40.76,309.60,69.95,7.13"  xml:id="b12">
	<analytic>
		<title level="a" type="main">Sticky tools: full 6DOF force-based interaction for multi-touch tables</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Hancock</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Cate</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Carpendale</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM International Conference on Interactive Tabletops and Surfaces, ITS &apos;09</title>
		<meeting>the ACM International Conference on Interactive Tabletops and Surfaces, ITS &apos;09</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="133" to="140" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,40.76,319.07,232.12,7.13;10,40.76,328.53,232.12,7.13;10,40.76,338.07,232.12,6.86;10,40.76,347.46,17.93,7.13"  xml:id="b13">
	<analytic>
		<title level="a" type="main">Rotation and translation mechanisms for tabletop interaction</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Hancock</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">F</forename>
				<surname>Vernier</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Wigdor</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Carpendale</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Shen</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">First IEEE International Workshop on Horizontal Interactive Human-Computer Systems</title>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,40.76,356.92,232.12,7.13;10,40.76,366.39,232.12,7.13;10,40.76,375.93,232.12,6.86;10,40.76,385.32,69.95,7.13"  xml:id="b14">
	<analytic>
		<title level="a" type="main">Collaboration and interference: awareness with mice or touch input</title>
		<author>
			<persName>
				<forename type="first">E</forename>
				<surname>Hornecker</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Marshall</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">N</forename>
				<forename type="middle">S</forename>
				<surname>Dalton</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">Y</forename>
				<surname>Rogers</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2008 ACM conference on Computer supported cooperative work</title>
		<meeting>the 2008 ACM conference on Computer supported cooperative work</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="167" to="176" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,40.76,394.78,232.12,7.13;10,40.76,404.25,232.12,7.13;10,40.76,413.71,232.11,7.13;10,40.76,423.17,17.93,7.13"  xml:id="b15">
	<analytic>
		<title level="a" type="main">The feasibility of three-dimensional displays of the thorax for preoperative planning in the surgical treatment of lung cancer</title>
		<author>
			<persName>
				<forename type="first">Y</forename>
				<surname>Hu</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">R</forename>
				<forename type="middle">A</forename>
				<surname>Malthaner</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">European Journal of Cardio-Thoracic Surgery</title>
		<imprint>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="31506" to="511" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,40.76,432.64,232.12,7.13;10,40.76,442.10,232.12,7.13;10,40.76,451.57,232.12,7.13;10,40.76,461.03,137.16,7.13"  xml:id="b16">
	<analytic>
		<title level="a" type="main">An exploratory study of co-located collaborative visual analytics around a tabletop display</title>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Isenberg</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Fisher</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Morris</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">K</forename>
				<surname>Inkpen</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Czerwinski</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Symposium on Visual Analytics Science and Technology (VAST)</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="179" to="186" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,40.76,470.50,232.12,7.13;10,40.76,479.96,232.12,7.13;10,40.76,489.43,69.29,7.13"  xml:id="b17">
	<analytic>
		<title level="a" type="main">Interactive exploratory visualization of 2d vector fields</title>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Isenberg</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">M</forename>
				<forename type="middle">H</forename>
				<surname>Everts</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Grubert</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Carpendale</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics Forum</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="983" to="990" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,40.76,498.89,232.12,7.13;10,40.76,508.36,232.12,7.13;10,40.76,517.82,232.12,7.13;10,40.76,527.28,17.93,7.13"  xml:id="b18">
	<analytic>
		<title level="a" type="main">Adapting X3D for multi-touch environments</title>
		<author>
			<persName>
				<forename type="first">Y</forename>
				<surname>Jung</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Keil</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Behr</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Webel</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Zöllner</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Engelke</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">H</forename>
				<surname>Wuest</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Becker</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th international symposium on 3D web technology</title>
		<meeting>the 13th international symposium on 3D web technology</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="27" to="30" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,40.76,536.75,232.12,7.13;10,40.76,546.21,232.12,7.13;10,40.76,555.68,201.85,7.13"  xml:id="b19">
	<analytic>
		<title level="a" type="main">Determining the benefits of directtouch , bimanual, and multifinger input on a multitouch workstation</title>
		<author>
			<persName>
				<forename type="first">K</forename>
				<surname>Kin</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Agrawala</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Derose</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Graphics Interface</title>
		<meeting>Graphics Interface</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="119" to="124" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,40.76,565.14,232.12,7.13;10,40.76,574.61,186.51,7.13"  xml:id="b20">
	<analytic>
		<title level="a" type="main">The Responsive Workbench</title>
		<author>
			<persName>
				<forename type="first">W</forename>
				<surname>Krueger</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">B</forename>
				<surname>Froehlich</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer Graphics and Applications</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="12" to="15" />
			<date type="published" when="1994-03" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,40.76,584.07,232.12,7.13;10,40.76,593.54,232.12,7.13;10,40.76,603.00,221.96,7.13"  xml:id="b21">
	<analytic>
		<title level="a" type="main">Fluid integration of rotation and translation</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Kruger</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Carpendale</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">S</forename>
				<forename type="middle">D</forename>
				<surname>Scott</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Tang</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the SIGCHI conference on Human factors in computing systems, CHI &apos;05</title>
		<meeting>the SIGCHI conference on Human factors in computing systems, CHI &apos;05</meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="601" to="610" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,40.76,612.47,232.12,7.13;10,40.76,621.93,232.12,7.13;10,40.76,631.39,232.12,7.13;10,40.76,640.86,232.12,7.13;10,40.76,650.32,178.10,7.13"  xml:id="b22">
	<analytic>
		<title level="a" type="main">Preoperative simulation of vascular anatomy by three-dimensional computed tomography imaging in laparoscopic gastric cancer surgery</title>
		<author>
			<persName>
				<forename type="first">S.-W</forename>
				<surname>Lee</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">H</forename>
				<surname>Shinohara</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Matsuki</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Okuda</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">E</forename>
				<surname>Nomura</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">H</forename>
				<surname>Mabuchi</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">K</forename>
				<surname>Nishiguchi</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">K</forename>
				<surname>Takaori</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">I</forename>
				<surname>Narabayashi</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">N</forename>
				<surname>Tanigawa</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American College of Surgeons</title>
		<imprint>
			<biblScope unit="volume">197</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="927" to="936" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,40.76,659.79,232.12,7.13;10,40.76,669.25,232.12,7.13;10,40.76,678.80,232.12,6.86;10,40.76,688.18,69.95,7.13"  xml:id="b23">
	<analytic>
		<title level="a" type="main">Interaction with medical volume data on a projection workbench</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Lin</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Loftin</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">I</forename>
				<surname>Kakadiaris</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Chen</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Su</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Proceedings of 10th International Conference on Artificial Reality and Telexistence</title>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="page" from="148" to="152" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,40.76,697.65,232.12,7.13;10,40.76,707.11,232.12,7.13;10,40.76,716.57,169.22,7.13"  xml:id="b24">
	<analytic>
		<title level="a" type="main">TNT: improved rotation and translation on digital tables</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Liu</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Pinelle</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Sallam</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Subramanian</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Gutwin</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Graphics Interface 2006, GI &apos;06</title>
		<meeting>Graphics Interface 2006, GI &apos;06</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="25" to="32" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,40.76,726.04,232.12,7.13;10,40.76,735.50,232.12,7.13;10,303.38,54.14,232.12,6.86;10,303.38,63.52,225.10,7.13"  xml:id="b25">
	<analytic>
		<title level="a" type="main">Full body virtual autopsies using a state-of-the-art volume rendering pipeline</title>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Ljung</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Winskog</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Perssson</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Lundström</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Ynnerman</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer GraphicsProceedings Visualization/Information Visualization</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="869" to="876" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,303.38,72.99,232.12,7.13;10,303.38,82.45,232.12,7.13;10,303.38,91.92,230.12,7.13"  xml:id="b26">
	<analytic>
		<title level="a" type="main">3D positioning techniques for multi-touch displays</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Martinet</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">G</forename>
				<surname>Casiez</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">L</forename>
				<surname>Grisoni</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 16th ACM Symposium on Virtual Reality Software and Technology, VRST &apos;09</title>
		<meeting>the 16th ACM Symposium on Virtual Reality Software and Technology, VRST &apos;09</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="227" to="228" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,303.38,101.38,232.12,7.13;10,303.38,110.85,232.12,7.13;10,303.38,120.39,232.12,6.86;10,303.38,129.78,106.93,7.13"  xml:id="b27">
	<analytic>
		<title level="a" type="main">The effect of DOF separation in 3D manipulation tasks with multi-touch displays</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Martinet</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">G</forename>
				<surname>Casiez</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">L</forename>
				<surname>Grisoni</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 17th ACM Symposium on Virtual Reality Software and Technology, VRST &apos;10</title>
		<meeting>the 17th ACM Symposium on Virtual Reality Software and Technology, VRST &apos;10</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="111" to="118" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,303.38,139.24,232.12,7.13;10,303.38,148.70,192.96,7.13"  xml:id="b28">
	<analytic>
		<title level="a" type="main">Teaching anatomy without cadavers</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">C</forename>
				<surname>Mclachlan</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Bligh</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Bradley</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Searle</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Medical Education</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="418" to="424" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,303.38,158.17,232.12,7.13;10,303.38,167.63,232.12,7.13;10,303.38,177.10,232.12,7.13;10,303.38,186.56,186.54,7.13"  xml:id="b29">
	<analytic>
		<title level="a" type="main">Understanding multi-touch manipulation for surface computing</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>North</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Dwyer</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">B</forename>
				<surname>Lee</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Fisher</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Isenberg</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">G</forename>
				<surname>Robertson</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">K</forename>
				<surname>Inkpen</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Human-Computer Interaction INTERACT 2009</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="236" to="249" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,303.38,196.03,232.12,7.13;10,303.38,205.49,232.12,7.13;10,303.38,214.96,232.11,7.13;10,303.38,224.42,61.98,7.13"  xml:id="b30">
	<analytic>
		<title level="a" type="main">A screen-space formulation for 2D and 3D direct manipulation</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">L</forename>
				<surname>Reisman</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">P</forename>
				<forename type="middle">L</forename>
				<surname>Davidson</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">Y</forename>
				<surname>Han</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd annual ACM symposium on User interface software and technology, UIST &apos;09</title>
		<meeting>the 22nd annual ACM symposium on User interface software and technology, UIST &apos;09</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="69" to="78" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,303.38,233.88,232.12,7.13;10,303.38,243.35,232.12,7.13;10,303.38,252.81,232.12,7.13;10,303.38,262.28,141.90,7.13"  xml:id="b31">
	<analytic>
		<title level="a" type="main">Finger talk: collaborative decision-making using talk and fingertip interaction around a tabletop display</title>
		<author>
			<persName>
				<forename type="first">Y</forename>
				<surname>Rogers</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">W</forename>
				<surname>Hazlewood</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">E</forename>
				<surname>Blevis</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">Y.-K</forename>
				<surname>Lim</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CHI &apos;04 extended abstracts on Human factors in computing systems</title>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="1271" to="1274" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,303.38,271.74,232.12,7.13;10,303.38,281.21,232.12,7.13;10,303.38,290.67,207.30,7.13"  xml:id="b32">
	<analytic>
		<title level="a" type="main">Discrepancies between clinical and autopsy diagnosis and the value of post mortem histology; a meta-analysis and review</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Roulson</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">E</forename>
				<forename type="middle">W</forename>
				<surname>Benbow</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">P</forename>
				<forename type="middle">S</forename>
				<surname>Hasleton</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Histopathology</title>
		<imprint>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="47551" to="559" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,303.38,300.14,232.12,7.13;10,303.38,309.60,139.35,7.13"  xml:id="b33">
	<analytic>
		<title level="a" type="main">Advanced GPU raycasting</title>
		<author>
			<persName>
				<forename type="first">H</forename>
				<surname>Scharsach</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Central European Seminar on Computer Graphics</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="69" to="76" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,303.38,319.07,232.12,7.13;10,303.38,328.53,232.12,7.13;10,303.38,337.99,118.59,7.13"  xml:id="b34">
	<analytic>
		<title level="a" type="main">Preoperative virtual simulation of adrenal tumors</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Shiozawa</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">N</forename>
				<surname>Sata</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">K</forename>
				<surname>Endo</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Koizumi</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">Y</forename>
				<surname>Yasuda</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">H</forename>
				<surname>Nagai</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">H</forename>
				<surname>Takakusaki</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Abdominal Imaging</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="113" to="120" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,303.38,347.46,232.12,7.13;10,303.38,356.92,232.12,7.13;10,303.38,366.39,67.30,7.13"  xml:id="b35">
	<analytic>
		<title level="a" type="main">Advanced medical displays: A literature review of augmented reality</title>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Sielhorst</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Feuerstein</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">N</forename>
				<surname>Navab</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Display Technology</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="451" to="467" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,303.38,375.85,232.12,7.13;10,303.38,385.32,232.12,7.13;10,303.38,394.78,69.29,7.13"  xml:id="b36">
	<analytic>
		<title level="a" type="main">Advanced 3D visualization in student-centred medical education</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Silén</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Wirell</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Kvist</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">E</forename>
				<surname>Nylander</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">O</forename>
				<surname>Smedby</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Medical Teacher</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="115" to="124" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,303.38,404.25,232.12,7.13;10,303.38,413.71,232.12,7.13;10,303.38,423.17,221.42,7.13"  xml:id="b37">
	<analytic>
		<title level="a" type="main">Post-mortem MR and CT imaging in fetuses, newborns and children: an evidenced based approach</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Thayyil</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">N</forename>
				<forename type="middle">J</forename>
				<surname>Robertson</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">N</forename>
				<forename type="middle">J</forename>
				<surname>Sebire</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">A</forename>
				<forename type="middle">M</forename>
				<surname>Taylor</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Diagnostic Histopathology</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="565" to="572" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,303.38,432.64,232.12,7.13;10,303.38,442.10,232.12,7.13;10,303.38,451.57,224.55,7.13"  xml:id="b38">
	<analytic>
		<title level="a" type="main">A lung segmentectomy performed with 3D reconstruction images available on the operating table with an iPad</title>
		<author>
			<persName>
				<forename type="first">F</forename>
				<surname>Volonte</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Robert</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">O</forename>
				<surname>Ratib</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">F</forename>
				<surname>Triponez</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Interactive CardioVascular and Thoracic Surgery</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,303.38,461.03,232.12,7.13;10,303.38,470.50,232.12,7.13;10,303.38,479.96,232.12,7.13;10,303.38,489.43,232.12,7.13;10,303.38,498.89,35.86,7.13"  xml:id="b39">
	<analytic>
		<title level="a" type="main">Post-mortem forensic neuroimaging: Correlation of MSCT and MRI findings with autopsy results</title>
		<author>
			<persName>
				<forename type="first">K</forename>
				<surname>Yen</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">K.-O</forename>
				<surname>Lövblad</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">E</forename>
				<surname>Scheurer</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Ozdoba</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">M</forename>
				<forename type="middle">J</forename>
				<surname>Thali</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">E</forename>
				<surname>Aghayev</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Jackowski</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Anon</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">N</forename>
				<surname>Frickey</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">K</forename>
				<surname>Zwygart</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Weis</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Dirnhofer</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Forensic Science International</title>
		<imprint>
			<biblScope unit="volume">173</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="21" to="35" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,303.38,508.36,232.11,7.13;10,303.38,517.82,82.23,7.13"  xml:id="b40">
	<monogr>
		<title level="m" type="main">Case Study Research: Design and Methods</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<forename type="middle">K</forename>
				<surname>Yin</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
			<publisher>Sage Publications Inc</publisher>
		</imprint>
	</monogr>
	<note>Fourth. edition</note>
</biblStruct>

<biblStruct coords="10,303.38,527.28,232.12,7.13;10,303.38,536.75,232.12,7.13;10,303.38,546.21,232.12,7.13;10,303.38,555.68,77.26,7.13"  xml:id="b41">
	<analytic>
		<title level="a" type="main">FI3D: Direct-touch interaction for the exploration of 3D scientific visualization spaces</title>
		<author>
			<persName>
				<forename type="first">L</forename>
				<surname>Yu</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Svetachov</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Isenberg</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">M</forename>
				<forename type="middle">H</forename>
				<surname>Everts</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Isenberg</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1613" to="1622" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
