<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/pisenberg/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.4.1" ident="GROBID" when="2016-09-09T14:59+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Hierarchical Event Selection for Video Storyboards with a Case Study on Snooker Video Visualization</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName>
								<forename type="first">Matthew</forename>
								<forename type="middle">L</forename>
								<surname>Parry</surname>
							</persName>
						</author>
						<author>
							<persName>
								<forename type="first">Philip</forename>
								<forename type="middle">A</forename>
								<surname>Legg</surname>
							</persName>
						</author>
						<author>
							<persName>
								<forename type="first">David</forename>
								<forename type="middle">H S</forename>
								<surname>Chung</surname>
							</persName>
						</author>
						<author>
							<persName>
								<forename type="first">Iwan</forename>
								<forename type="middle">W</forename>
								<surname>Griffiths</surname>
							</persName>
						</author>
						<author>
							<persName>
								<forename type="first">Min</forename>
								<surname>Chen</surname>
							</persName>
						</author>
						<title level="a" type="main">Hierarchical Event Selection for Video Storyboards with a Case Study on Snooker Video Visualization</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Index Terms—Multimedia visualization</term>
					<term>Time series data</term>
					<term>Illustrative visualization</term>
				</keywords>
			</textClass>
			<abstract>
				<p>Fig. 1. Left: Keyframes from a 3 minute snooker video segment consisting of 6 shots taken from a complete match of 67 shots. Right: Visualization created from the video data. The visualization displays each shot from the video, whilst introducing event importance shown by ball trajectory emphasis, and event ordering shown by numbered ball icons. Table annotations represent ball pots, player scores, points remaining and the position in the full video where this sequence of events occurs. Abstract—Video storyboard, which is a form of video visualization, summarizes the major events in a video using illustrative visu-alization. There are three main technical challenges in creating a video storyboard, (a) event classification, (b) event selection and (c) event illustration. Among these challenges, (a) is highly application-dependent and requires a significant amount of application-specific semantics to be encoded in a system or manually specified by users. This paper focuses on challenges (b) and (c). In particular, we present a framework for hierarchical event representation, and an importance-based selection algorithm for supporting the creation of a video storyboard from a video. We consider the storyboard to be an event summarization for the whole video, whilst each individual illustration on the board is also an event summarization but for a smaller time window. We utilized a 3D visualization template for depicting and annotating events in illustrations. To demonstrate the concepts and algorithms developed, we use Snooker video visualization as a case study, because it has a concrete and agreeable set of semantic definitions for events and can make use of existing techniques of event detection and 3D reconstruction in a reliable manner. Nevertheless, most of our concepts and algorithms developed for challenges (b) and (c) can be applied to other application areas.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p> Video visualization is concerned with the creation of a new visual representation from an input video to reveal important features and events in the video <ref type="bibr" coords="1,80.53,572.91,9.52,8.07" target="#b1">[2]</ref> . A video storyboard, which is a form of video visualization , typically summarizes a video using a small sequence of keyframes and composite images that are often enhanced by additional  illustrative annotations. Unlike those storyboards used in movie making as a pre-visualization of the planned actions, here we focus on video storyboards as a post-visualization of the events in a video. It helps users primarily as a visual medium to aid discussions and comparison , facilitating memory externalization while removing the burden of viewing videos repeatedly. </p><p>Video storyboards have been proposed in the literature (e.g., <ref type="bibr" coords="1,530.04,616.83,9.41,8.07" target="#b8">[9]</ref>). However, the technical advances have been largely limited to annotating motions, such as an actor moving from one place to another <ref type="bibr" coords="1,533.03,636.75,9.52,8.07" target="#b8">[9]</ref>. The difficulties reside in the pipeline for creating a storyboard from a video, which typically consists of (a) event detection and classification , (b) event prioritization and selection, and (c) event depiction and annotation. One of the major obstacles is the need for encoding some application-specific semantics at some stages of the pipeline, fogging generic approaches with application-specific algorithms. Among the three stages, (a) depends heavily on application-specific semantics and algorithmic encoding (e.g., object and event classification is usually difficult to port from one application to another). Techniques for (c) may require some application-specific specification such as visual de-signs and mappings, but are generally more portable as they rarely involve machine learning. Techniques for (b) are potentially more generic and can have many applications. It is necessary to note that although the creation of video storyboard requires the input and encoding of application-specific semantics, this does not undermine its potential as a vital tool for video visualization because many applications , such as sports, have the needs and resources to build such an application-specific pipeline. In this work, we focus on (b), examining a generic scheme for representing events hierarchically and a recursive algorithm for selecting events for creating storyboards (Section 3). To demonstrate the usability of this scheme, we present a case study of snooker video visualization , where the hierarchical selection approach is particularized (Section 4). The reason to choose this case study is that the definition and importance of events in snooker games are reasonably welldefined and agreeable by most experts and audience. As the filming takes place indoor under a controlled environment, this makes object and event detection and classification more reliable (Section 5), allowing us to focus on (b) without being distracted by application-specific difficulties. We utilized a form of 3D perspective view of a snooker table as the basic template for our visualization, because this is consistent with what users would commonly see on the television. We show that the hierarchical event prioritization and selection can be integrated directly with algorithms for visual mappings (Section 6). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORKS</head><p> Whilst the topic of event visualization is still relatively new, event detection has been studied for many years in the computer vision community . It is widely adopted in surveillance work, as shown in the survey by Hu et al. <ref type="bibr" coords="2,102.03,346.98,13.74,8.07" target="#b11">[12]</ref>. In particular, it is often used for traffic monitoring <ref type="bibr" coords="2,66.54,356.94,14.94,8.07" target="#b16">[17] </ref>or for human behaviour analysis <ref type="bibr" coords="2,204.54,356.94,13.74,8.07" target="#b28">[29]</ref> . Another popular application of event detection has been sports broadcasting. Li and Sezan <ref type="bibr" coords="2,65.16,376.86,14.94,8.07" target="#b15">[16] </ref>propose to use a Hidden Markov Model to classify events in sports videos (e.g., for American football, baseball and sumo wrestling) into four basic states: start-of-play, in-play, end-of-play and non-play. Sadlier and O'Connor <ref type="bibr" coords="2,145.80,406.75,14.94,8.07" target="#b20">[21] </ref> use both audio and visual features to detect events in sports video by using a Support Vector Machine . Pan et al. <ref type="bibr" coords="2,83.14,426.68,14.94,8.07" target="#b17">[18] </ref> perform event detection based on detecting slowmotion replays that are likely to correspond to major event highlights in broadcast footage. Video visualization compliments automated video analysis, especially in situations where accurate detection and classification cannot be achieved. <ref type="bibr" coords="2,91.35,476.92,58.99,8.07">Borgo et al. [2] </ref>conduct a comprehensive survey on this topic. Daniel and Chen <ref type="bibr" coords="2,144.62,486.88,10.45,8.07" target="#b3">[4] </ref> use video visualization to summarize CCTV footage. <ref type="bibr" coords="2,110.81,496.85,53.08,8.07">Chen et al. [3] </ref> propose to improve visualization using both volume (change) and flow (motion) signatures. Their study show that ordinary people can learn to recognise events based on event signatures in static visualization rather than having to view the entire video content. Romero et al. <ref type="bibr" coords="2,165.47,536.70,14.94,8.07" target="#b19">[20] </ref>use video visualization to add human behavioral analysis. Yeo and Yeung <ref type="bibr" coords="2,196.07,546.66,14.94,8.07" target="#b26">[27] </ref> implement a system that uses keyframes to summarize video. Since using keyframes is common practice, this is not a new idea, but a new implementation . Takahashi et al. <ref type="bibr" coords="2,103.28,576.55,14.94,8.07">[24] </ref>propose to summarize video footage using a 'video poster' created from the keyframes and meta-data of sports video. Dony et al. <ref type="bibr" coords="2,94.44,596.47,10.45,8.07" target="#b5">[6] </ref>and Goldman et al. <ref type="bibr" coords="2,180.85,596.47,10.45,8.07" target="#b8">[9] </ref>propose to summarize videos using storyboards, which accompany keyframes with annotations (such as motion arrows). Assa et al. <ref type="bibr" coords="2,183.76,616.40,10.45,8.07" target="#b0">[1] </ref>extract a selection of poses from a short sports video and compose them into a single illus- tration. In the context of event-based visualization, Kapler and Wright developed a prototype system 'GeoTime' that displays military events in a combined temporal and geo-spatial visualization <ref type="bibr" coords="2,219.77,666.64,13.74,8.07" target="#b12">[13]</ref>. They use the 2D x-y space for the geographic space, and the third dimension (z) to represent time in the future and past. <ref type="bibr" coords="2,189.19,686.57,53.70,8.07">Gatalsky et al. </ref>use the similar concept of the 'space-time cube' to visualize spatio-temporal information relating to earthquake events <ref type="bibr" coords="2,173.58,706.49,9.52,8.07" target="#b7">[8]</ref>. Wang et al. <ref type="bibr" coords="2,232.10,706.49,14.94,8.07" target="#b24">[25] </ref>use 3D environment models to contextualize spatially-related videos. Yu et al. <ref type="bibr" coords="2,35.21,726.42,14.94,8.07" target="#b27">[28] </ref>propose to organize identified events into an event graph to aid the creation of animation of different event sequences. </p><p>Finally, for snooker videos, Höferlin et al. <ref type="bibr" coords="2,453.08,53.34,14.94,8.07" target="#b10">[11] </ref>present a study on using video visualization in snooker coaching and skill training. Rea et al. <ref type="bibr" coords="2,298.32,73.27,14.94,8.07" target="#b18">[19] </ref> perform video analysis for classifying snooker events, in particular: shot-to-nothing, break building, conservative play and snooker escapes. Denman et al. <ref type="bibr" coords="2,377.42,93.19,10.45,8.07" target="#b4">[5] </ref> make use of table geometry in processing snooker broadcast videos, and propose to detect the disappearance of objects using histogram analysis at pocket regions. Guo and Namee <ref type="bibr" coords="2,314.07,123.08,14.94,8.07" target="#b9">[10] </ref>perform 3D reconstruction using a smallscale toy snooker table with a camera placed directly above. Shen and Wu <ref type="bibr" coords="2,488.17,133.04,14.94,8.07" target="#b21">[22] </ref>carry out 3D reconstruction from a camera placed above the centre of the table. They acknowledge the difficulty to capture the entire table because of the altitude of the camera. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">FACETS OF EVENTS</head><p>An event can be described as a significant occurrence or happening, which typically has some application-specific meaning in the context where it occurs. A conceptual framework of events may feature several major facets of events. These may include: @BULLET Hierarchy — Events may have a hierarchical relationship, that is, an event may be defined as an abstraction or a composition of a series of more elemental events. @BULLET Importance — Events may have different levels of importance. Such a quantity can be defined by a group of experts for a specific application. @BULLET State — Events may act as a transition, or one of the causes of a transition, from one state to another <ref type="bibr" coords="2,436.78,309.97,13.74,8.07" target="#b22">[23]</ref>. It may appear that the specification of events and their abovementioned facets could be rather arbitrary and might be judged by different individuals in different circumstances. However, in many applications , such as sports games and road traffic, there exists a common understanding. It is such a common understanding that makes event detection and classification possible. On the other hand, the personal and circumstantial variance makes event summarization a challenging task. In comparison with a textual summarization, event visualization has the potential to convey a summary of major events, and their temporal and spatial context in a more effective and efficient manner, while supporting industrials' reasoning and judgment. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Event Hierarchy</head><p>Let e q w denote an event at a time window w in a semantic context q. Without losing generality, we treat a specific point of time t and an ordinal number i as two special cases of w. In the following discussions, we also assume that semantic contexts are organized into a hierarchy. Thus, e h t implies that it is a level h event occurring at time t. When discussing events at a particular hierarchical level, we may use a specific letter (e.g., a, b) to denote all events at that level. For example, consider all image frames in a snooker video: </p><formula>E 1 = F = ⟨ f 1 , f 2 , . . . , f t , . . .⟩. </formula><p>F can be considered as the most elementary level of events. All ball motions and contacts with cues, cushions and pockets form a sequence of events at a higher level, </p><formula>E 2 = C = ⟨c 1 , c 2 , . . . , c i , . . .⟩. </formula><p>All shots, from the first contact between the cue and ball to the time when all balls become stationary, fall into the 3rd level, </p><formula>E 3 = W = ⟨w 1 , w 2 , . . . , w j , . . .⟩. </formula><p>A collection of consecutive shots that are related forms an event at the 4th level, and all such events belong to the sequence of </p><formula>E 4 = P = ⟨p 1 , p 2 , . . . , p k , . . .⟩. </formula><p>All game frames becomes a sequence at the 5th level, </p><formula>E 5 = R = ⟨r 1 , r 2 , . . . , r l , . . .⟩. </formula><p>This framework can be extended to include even higher levels such as games, tournaments or seasons. We use symbol ≺ to denote the hierarchical order, e.g., </p><formula>F ≺ C ≺ W ≺ P ≺ R ≺ . . . . </formula><p>Conceptually, events at each level are interleaved with a sequence of states at the same level. Each state is unique, and can be determined based on a set of attributes. In practice, it is usually more meaningful and efficient to represent states explicitly only at higher levels. We use s q w to denote a state at a time window w in a semantic context q. Similar to event definitions, we can have special cases for a specific point in time, order and hierarchy. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Event Classification</head><p>Classification is a process to assign a semantic meaning to an event or state. This is highly application-dependent. For example, in soccer video annotation, it is common for a video analyst to observe an event in a video, create an event mark, and select a type from a list of predefined keywords. For snooker videos, it is more feasible to determine a low level event by an automatic classification algorithm. When considering an event as a record in the computer, we can call an event classification function Ψ(e) to determine the type of the event. For example, events in sequence C may be classified as (i) no collision, (ii) ball-to-ball, (iii) cue-to-ball, (iv) ball-to-cushion, (v) ball-near-pocket, and (vi) ball-in-pocket. Events in sequence W may be classified as (i) break building, (ii) conservative play, (iii) snooker escape and (iv) shot to nothing. Similarly, states are classified by a function Φ(s), such that Ψ and Φ are level dependent. In general, a higher level event is an abstraction or composition of some lower level events. For instance, a motion event m is determined by examining several consecutive image frames . . . , f t−2 , f t−1 , f t . A more complex classification scheme may involve processing both events and states at lower levels. In our work, we restrict the classification process only to the level immediately below the current level. Note that this is only a convenient implementation, not a limitation , since one can always 'copy' an event from a lower level to a higher level. Hence, given three event sequences at different levels, X ≺ Y ≺ Z, if the definition of an event z ∈ Z depends on some events in X and some in Y , we can always add new events in Y to mirror those relevant events in X. We thereby have the following classification dependency: </p><formula>Ψ : (E h ) d × (S h ) d → E h+1 Φ : (E h ) d × (S h ) d → S h+1 </formula><p>where d is the small constant representing the number of events and states in a sequence of transitions that a classification scheme will consider . As almost all events and states are type-defined by Ψ or Φ (except the image frames in F), event detection and classification conform to the general problem of pattern recognition in text strings <ref type="bibr" coords="3,244.76,538.92,13.74,8.07" target="#b13">[14]</ref>. For instance, given a sequence of event-state transition, </p><formula>A = ⟨e 1 , s 1 , e 2 , s 2 , . . . , e d , s d ⟩</formula><p>, we can compute a corresponding string of types as: </p><formula>T A = ⟨Ψ(e 1 ), Φ(s 1 ), Ψ(e 2 ), . . . , Ψ(e d ), Φ(s d )⟩ </formula><p>We then search for a particular type-signature sequence in T A . </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Event Importance and Selection</head><p>Given an event record e, we can also determine the importance of the event by using an importance function Γ(e). Unlike event and state classification functions, Γ(e) operates on the events and states at the same level. A simple importance function can simply be a mapping from event type to a scalar value representing the importance. A slightly sophisticated function may take the preceding state and succeeding state into account. A more complex function may be a function of a sequence of event-state transitions in a manner similar to the processing of T A in Section 3.2. In any form of event summarization, including video storyboarding, we need to select a set of events to be communicated to the users. The three points), brown (worth four points), blue (worth five points), pink (worth six points) and black (worth seven points). The aim of the game is to score as many points as possible by striking the cue ball with the cue in order to pot the red and coloured balls in sequential order. <ref type="figure" coords="4,24.00,230.36,21.77,8.07" target="#fig_0">Fig. 3</ref> gives the event hierarchy that was adopted for snooker storyboarding . The hierarchy shows three event levels, where </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Snooker Event Hierarchy</head><formula>E 2 ≺ E 3 ≺ E 4 . </formula><p>Given each ball on the table we define the detectable low-level events into the following classes Ψ(c) = {moving, collision, pot}, c ∈ E 2 . It is assumed that at the start and end of each shot that each ball will take the event ψ stopped . Let us now consider the series of lowlevel events E 2 that would make a typical shot in snooker. The player strikes the cueball (triggering the cueball event moving) and collides with another object ball (triggering the cueball event collision). If this results in the object ball event pot being triggered then the player takes another shot, otherwise the opponent takes their turn. Each shot is clearly bounded between the sequence of events that results in each ball object being stationary on the table. Hence we can begin to formulate higher level events E 3 by collecting the events and states occurring between this interval. As discussed in Section 3, higher-level events are made up of lower level events, subject to satisfying the condition of states. By searching for a particular signature contained in E 3 , we assign each shot to one of the follow types: break building, conservative play, snooker escape, shot-to-nothing and foul. In order to define the states between events, we consider a set of attributes α, each of which can take a particular value. Then any state can be defined as s = {α 1 , α 2 , . . . , α k }. For snooker we use the following attributes: player1 score, player2 score, current break, points remaining on table, cueball safe, valid shot played. Likewise , these attributes may have additional parameters associated with them (e.g., cueball safe depends on cueball position and distance to closest red). At any time window w, the set of attributes can be assessed to determine the current state. Due to the nature of snooker, it is reasonable to consider these attributes for states at level S 3 which coincides with each independent shot in the match. After each shot at event level E 3 , each attribute is updated to determine the new state before the next shot is played. Let us consider the events at level E 3 . Break building is defined where α valid shot played is true, and the event ψ pot occurs. Similarly, a shot where α valid shot played is true but the event ψ pot does not occur can be considered to be conservative play, subject to α cueball sa f e being true. A shot-to-nothing can be defined where ψ pot occurs with attribute α cueball sa f e being true. We deduce a snooker-escape by looking for the occurrence of a collision with the cushion before making contact with the ball, subject to α cueball sa f e being true. Finally, a foul occurs when α valid shot played returns false. For our highest event level E 4 , we begin to cluster together relevant shots based on the context of a regular game of snooker. A collection of break building shots can be grouped to give a break phase where a player has potted multiple balls. Likewise, a collection of shots classified as conservative play could be grouped to be a safety exchange. In some cases, it may also be important to know the shot that came before or after an event (e.g., poor cueball positioning that allowed a break to be scored, or a missed pot that ended a break). Hence we type define ψ break phase as a sequence of consecutive break building shots along with the shots that precede directly before and after. We use the term 'tactical play' to categorize shots that involve escaping from a snooker. Again, we consider the preceding shot in order to establish the action that took place that results in the snooker. <ref type="figure" coords="4,286.62,295.64,22.15,8.07" target="#fig_1">Fig. 4</ref>shows a bar chart that represents the event importance for a snooker match, illustrating the importance of events at levels E 3 and E 4 . The 4 peaks in E 4 corresponds to the 3 largest breaks in the game and the phase when the frame ball was potted. Within each region, we can see local peaks that show the more important individual shots (e.g., potting the black ball) that are derived from the general form: </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Snooker Event Importance</head><formula>Γ(ψ type ) = b + ν(α) (1) </formula><p>where b is a constant that gives the baseline importance value for each event type ψ type and ν(α) denotes the variable importance computed based on the current attributes in the state. Given the higher level events and the state attributes, we define our following importance functions based on our general definition: </p><formula>Γ(ψ conservative play ) = 1 + (1 − |α cueball p osition |) </formula><formula>(2) Γ(ψ break building ) = β c + β c × ln(α current b reak ) (3) Γ(ψ snooker escape ) = 2 + 1 e 1/η (4) Γ(ψ shot to nothing ) = 4 + |α cueball p osition | (5) </formula><p>where η ∈ N is the number of cue ball collisions before contact with object ball and β c corresponds to the score of potted ball colour (where c = 1 . . . 7). From Eq. 2, the importance value for a typical conservative shot is bounded between the interval <ref type="bibr" coords="4,397.08,586.69,9.71,8.07" target="#b0">[1,</ref><ref type="bibr" coords="4,409.86,586.69,7.47,8.07" target="#b1"> 2] </ref>where Γ(ψ conservative play ) −→ 2 as α cueball p osition −→ 0. A good conservative shot generally involves leaving the cue ball near the baulk end of the table which in our case is when the cue ball x-position is at its maximum. As a general frame of snooker can contain a large number of good conservative shots, we indicate the bad conservative shots (i.e., when ξ tends to zero) with higher importance as they occur less frequently. Similarly, this is also applied in computing the importance for 'shot-to-nothing' in Eq. 5. However, in this case we accentuate that the pot is more difficult when the cue ball is closer to the top cushion (when α cueball p osition −→ 1). Break building is derived using a two-stage iteration. We use the value of the potted ball as the base score followed by an additional factor of β c × α current b reak . The higher the break that a player makes, the more important that particular break becomes. We use a natural logarithmic function to model the behaviour of a break being gradually less important once a player has completed a break to secure a win. <ref type="figure" coords="5,31.74,191.92,20.12,7.55">Fig. 5</ref>. Applying Gaussian moderation as a weighting parameter for event importance. The adjusted importance parameters are shown in green. This introduces a temporal focus surrounding the key local event that occurs within the grouping given by the global importance. </p><p>The most important shot in a frame is considered to be 'frame ball'. This is where the difference between the player scores is greater than the number of points remaining on the </p><formula>(7) </formula><p>A frame ball is more significant if the remaining score on the table is small (this will occur if the game happens to be close) or if the score difference between both players is small. <ref type="figure" coords="5,41.70,406.20,22.42,8.07">Fig. 5</ref>shows Gaussian moderation being applied to the original event importance (<ref type="figure" coords="5,101.28,416.16,20.85,8.07" target="#fig_1">Fig. 4</ref> ) as discussed in Section 3. For a particular higher-level event, the Gaussian curve is centred on the greatest low-level event within this set. The Gaussian curve is used to apply a weighting to the importance in order to provide a temporal focus surrounding the key event. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">SYSTEM OVERVIEW</head><p> The system can be described as a three-stage process, (a) event detection and classification, (b) event prioritization and selection, and (c) event depiction and annotation. In (a), the input video is processed to detect the snooker table and ball objects, and based on the tracking data, detects the occurrence of low-level events. From this, the system is able to produce the hierarchical event classification. Given the event hierarchy, (b) computes the importance of each event that occurs . From this, the system selects the shots of greatest importance. Finally, (c) generates the visualization by using the event importance and selection data in conjunction with the tracking data. We capture video footage from the snooker table using a single camera that is mounted above the table. The process of detecting, classifying and tracking each ball object within the captured scene (<ref type="figure" coords="5,258.89,616.83,19.48,8.07" target="#fig_2">Fig. 6</ref>) is given in <ref type="bibr" coords="5,71.96,626.79,13.74,8.07" target="#b14">[15]</ref>. For each shot in the match, and each frame of video in the shot, we obtain the following data for each ball: ID, colour, position , speed, direction. This provides enough data to generate a 3D reconstruction of the captured scene. Extending on our previous work, each ball will also have three event tags that correspond to the three low-level events: moving, collision and pot. A ball is detected as moving if the speed is greater than a fixed parameter, based on the position between subsequent frames in the video. A collision is detected where a ball starts moving, subject to another ball moving close to this. Finally , a pot is detected where a ball disappears from the table, subject to being close to a pocket region. These make up the low-level events that are used for further processing by the event selection tool. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">VISUALIZATION DESIGN</head><p>A storyboard consists of a series of illustrations. Each illustration represents a major event selected by the event selection algorithm described in Section 3. Unlike the conventional storyboard used in computer animation, each of our illustrations is not just a keyframe, but a visualization of several sub-events related to the major event associated with this illustration. As described in Section 3, the selection of these sub-events is based on Gaussian-moderated importance values . In this section we shall discuss the visualization design used to generate the illustrations, and how these form the video storyboard. It is important that our visualization design follows best practice guidelines. There are existing guidelines for how to use different visual cues such as colour, thickness/size, opacity, lines, texture and symbols when producing visualizations <ref type="bibr" coords="5,437.23,336.70,13.74,8.07" target="#b25">[26]</ref>. The visualization should clearly represent the action from the video data, whilst maintaining temporal information. It should address the concept of event hierarchy, and emphasize the key events at each level of the hierarchy by importance . The visualization should be intuitive for the user and provide faster interpretation of events than watching the video in real-time. As a basis for the visualization we use a 3-dimensional model of a snooker table to give clear contextual representation of the data. Obviously other event-based systems would utilize a different environment, based on the application area. The system will incorporate the tracking data for each ball object as performed in Section 5. However, due to the wealth of information that is present in the snooker video content , the challenge in this system is quickly apparent. At most, there will be 22 ball objects on the table during a match. For each shot, the cueball will move around the table which will collide with a number of other balls, causing these to move also. A typical match may have 50-60 shots played. To represent this information on a single image will result in an exceptionally confusion representation due to overcluttering . Therefore we use a video storyboard to represent the video using a user-defined number of static visualizations. We use event prioritization and selection (from Section 4) to determine the key event sequences from the video data for the storyboard. <ref type="figure" coords="5,304.32,557.05,26.68,8.07" target="#tab_1">Table 1</ref>gives an overview of some of the different visual cues that could be utilised in our visualization design. It is important that for each visual cue we consider how this may be constrained by the application context, and how this could be used to introduce additional information to the scene. In snooker, the obvious constraint is colour since this is already used extensively to represent different balls on the table. Since colour is so commonly adopted as a visual cue in visualization this poses an additional challenge to our work. Other cues that are restricted by the data space are the size of the ball objects and the line length of the trajectory paths. Just as with the data space, there are constraints introduced in the rendering space for representing information on the 3-dimensional snooker table. Colour, ball size and trajectory line length remain constrained due to the data space being rendered. The main constraint introduced in the rendering is lighting, since this is required to give a realistic representation of the scene. Therefore, ball and table textures, along with shadow effects, are also constrained by the rendering process. Finally, since this is a 3- dimensional model that can be viewed from any arbitrary viewpoint, the perspective viewpoint of the visualization will affect the size of <ref type="figure" coords="6,23.00,222.56,24.52,7.55" target="#tab_1">Table 1</ref>. Table to show the different possible visual cues that could be used within the visualization scheme. For each of the visual cues given we assess the constraints that are imposed by the data space (i.e. visual cues that are already used in snooker), and the constraints that are imposed in creating a realistic rendering of the scene. We then give design options based on each of the visual cues that could be used to introduce additional information to the visualization. </p><p>both ball objects and line trajectories. <ref type="figure" coords="6,32.96,290.18,27.14,8.07" target="#tab_1">Table 1</ref>also gives possible suggestions as to how visual cues can be used to incorporate event ordering into the visualization. This is important to provide temporal relevance to the information presented in the visualization. In particular, this would indicate the ordering for a sequence of shots on the snooker table. It is clear that some visual cues will not offer significant benefit to illustrate such information, for instance, luminance. Whilst other cues could technically be employed, such as size, they are perhaps not particularly intuitive to a user whilst maintaining a clear visualization style. Finally, suggestions are given in the table for key event representation. This should introduce the notion of event importance as discussed in Section 3.3. The visualization should clearly indicate that particular shots are more significant than others. Again, some of the visual cues presented may be unsuitable for our task (e.g., colour) or may not provide intuitive representation of the key events (e.g., annotation outside the frame). <ref type="figure" coords="6,23.00,466.46,21.31,8.07" target="#fig_4">Fig. 7</ref> shows the development of the visual language used for our visualization scheme, based on the initial design ideas. To illustrate this, we use an example visualization from the video storyboard, generated from real match data. The visualization represents a 'break phase' event from level E 4 , that consists of 6 'break building' shots from level E 3 , each of which consist of events (e.g., motion) from level E 2 . As we have previously discussed, we know that ball colours, ball size and ball motion trajectories are three key elements confined by the data space and so are preserved. <ref type="figure" coords="6,124.06,546.16,20.13,8.07" target="#fig_4">Fig. 7</ref>(a) gives the initial visualization for the video storyboard. In this we show each of the ball objects on the table, along with the associated ball motion as depicted by coloured lines on the table. This is done for each of the six shots. This initial design suffers from a number of flaws: it does not indicate the key event, time information is not explicit for neither a shot or the entire sequence, and the sense of action and movement that a video offers is lost from the static representation. We address these concerns in the following revisions of the design. Firstly we replace the line trajectories with ball objects (<ref type="figure" coords="6,237.03,636.75,19.53,8.07" target="#fig_4">Fig. 7</ref>(b)). Using ball objects to show the trajectory path provides a more intuitive cue due to a greater sense of ball motion. We then replace any static balls that are not directly involved in play with only the ball shadow (<ref type="figure" coords="6,56.02,676.60,19.44,8.07" target="#fig_4">Fig. 7</ref> (c)). This choice was made to draw the viewer's attention away from ball objects of low interest, whilst not removing the information entirely. Only balls that move, or balls that contribute to the state of play (i.e. in the case of a snookered position), remain in full view. To enhance the sense of action in the visualization, we use semi-transparent trajectories (<ref type="figure" coords="6,131.21,726.42,29.78,8.07" target="#fig_4">Fig. 7(d)</ref>). The trajectory begins with a low alpha value that increases as the ball travels. This gives directional information, and helps emphasize the starting position for each shot. Event importance is introduced into the visual design at the shot level E 3 . To do this we use both opacity and trajectory width (<ref type="figure" coords="6,289.06,309.53,20.40,8.07" target="#fig_4">Fig. 7</ref>(e)). Before, opacity was applied only to the ball trajectory, within the range <ref type="bibr" coords="6,345.34,319.40,28.03,8.17">[0.05, 1]</ref>. Here, the maximum opacity value is defined by the event importance, and applied to both the trajectory path and the ball object, by the formula: </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Visual Language</head><formula>v e m , m = α max − α k 2 (8) </formula><p>where α max is the maximum local importance for the series of shots, α is the local importance for that particular shot and k is a user-defined constant that influences the steepness of the function. For computing the maximum opacity, v = 1 since this is the upper bound that the parameter can take. The formula is also used to calculate the trajectory width, where the upper bound for width is v = 50. From <ref type="figure" coords="6,501.93,433.81,20.72,8.07" target="#fig_4">Fig. 7</ref>(e), the shot that results in the black ball being potted in the bottom right pocket has the greatest alpha value associated with it, and also is the thickest trajectory, making this the most important shot in the series. We present two approaches for incorporating temporal information in the visual design. The first shows coloured rings on the table at the cueball start position for each shot (7(f)). The number of rings indicate the shot number, and the colour of each ring indicates the target ball colour for that shot. The second approach places icons on the cueball at each start position (7(g)), where the icon number refers to the shot number and the icon colour refers to the target ball colour. Whilst both approaches seem reasonable, the number-based icons are more explicit and so we choose this for our final design (<ref type="figure" coords="6,444.16,553.72,20.03,8.07" target="#fig_5">Fig. 8</ref>(a) gives a close-up view of the icons used). By using icons we can also link this with the additional table annotations for ball potting information (discussed in Section 6.2). <ref type="figure" coords="6,337.16,583.61,20.98,8.07" target="#fig_4">Fig. 7</ref>(h) presents the final visual design, whereby the key event from the series is given an emphasized shadow to make this stand out clearer from the other shots on the table. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Table Annotations</head><p>We have presented the visual language that will be used to construct the illustrations for the video storyboard. In addition to this, we also use annotation to display key information about the series of events. <ref type="figure" coords="6,295.58,666.64,21.14,8.07" target="#fig_5">Fig. 8</ref>gives examples of the annotations used in the snooker video storyboard. <ref type="figure" coords="6,331.88,676.61,31.84,8.07" target="#fig_5">Fig. 8(a)</ref> shows the icons used on the cueball. As previously discussed, the number indicates which shot this is in the keyframe and the colour indicates the object ball that the cueball collides with first. <ref type="figure" coords="6,341.25,706.49,19.87,8.07" target="#fig_5">Fig. 8</ref>(b) uses the same iconic notation to show the ball pots at each pocket within the displayed sequence. <ref type="figure" coords="6,467.94,716.46,30.73,8.07" target="#fig_5">Fig. 8(c)</ref>shows the 'dashboard' that represents the key information about the match for the displayed sequence. The red and blue bars correspond to player shows the original representation with all ball objects shown and trajectory data shown by lines. 7(b) replaces the trajectory lines for each ball with ball objects. 7(c) replaces stationary balls with shadow objects. 7(d) introduces a semi-transparent trajectory to represent direction of ball motion. 7(e) incorporates shot importance, based on opacity (applied to both the ball object and the trajectory) and the trajectory width. 7(f) shows event ordering using ring notation, where the number of rings indicates shot number and the outer ring shows object ball colour. 7(g) shows event ordering using numbered icons, where the number indicates shot number and the icon colour shows object ball colour. 7(h) highlights the key event in the sequence (shot 4) using emphasized shadow. one and two respectively, whilst the width of each bar represents the score. The solid region shows the scores prior to the displayed sequence , whilst the lighter reqion shows the scores as a result of the sequence. An important factor in snooker is the remaining points on the table, since if this is less than the difference between the player scores then the highest scoring player has won. A green bar is displayed on the lowest scoring player to show this value as a result of the visualized sequence. <ref type="figure" coords="7,381.17,493.77,19.81,8.07" target="#fig_5">Fig. 8</ref>(d) shows where the remaining points is less than the player score difference, indicating the state 'frame ball'. Finally, the dashboard also shows timing information from the video data. The clock on the right represents the full length of the video, starting from the up-most position and moving around clockwise. The orange segment indicates the time period for the visualized sequence being shown. The gray segments indicate the other sequences used within the current video storyboard. </p><formula>(a) (b) (c) (d) </formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Video Storyboarding</head><p>We now generate the video storyboard for a typical game of snooker, based on the keyframe visualizations. Our example match was played in 66 shots, with each shot being recorded in 30 second segments (total length 33 minutes). From our initial case study, <ref type="figure" coords="7,485.28,623.82,21.76,8.07" target="#fig_1">Fig. 4</ref>gives the computed event importance for this match. <ref type="figure" coords="7,302.32,643.74,21.26,8.07">Fig. 9</ref>presents 4 different video storyboards that are generated for the snooker match, using (a) 3, (b) 4, (c) 5 or (d) 6 illustrations. The video storyboard is depicted from left-to-right in sequential order, and maintains the event hierarchy presented in Section 4. Each illustration represents an event at level E 4 . Each shot depicted on the table represents an event at level E 3 . Each shot is made up of detected motion that represent events at level E 2 . We have discussed how importance is depicted for events at level E 3 , however by using video storyboarding we also introduce this for higher levels. The importance of E 4 events is shown by the relative size of each illustration. Frame ball has the 1753 PARRY ET AL: HIERARCHICAL EVENT SELECTION FOR VIDEO STORYBOARDS WITH A CASE STUDY ON SNOOKER (a) Using 3 illustrations: the greatest level of detail, including all shot trajectories, shot number identifiers and corresponding pot identifiers. </p><p>(b) Using 4 illustrations: level of detail is reduced to remove outside annotation from the visualizations, however main table is preserved. </p><p>(c) Using 5 illustrations: level of detail is reduced so that less significant shots are no longer shown. </p><p>(d) Using 6 illustrations: more global events can be shown but at much lower level of detail. This results in only a single shot trajectory per visualization. <ref type="figure" coords="8,23.00,693.05,19.80,7.55">Fig. 9</ref>. Video storyboard based on hierarchical event visualization. 4 examples are shown using (a) 3, (b) 4, (c) 5, or (d) 6 illustrations (this parameter can be defined by the user). Each keyframe shows an event at level E 4 and shows importance based on relative illustration size. Each keyframe consists of a number of shots from event level E 3 . The importance of events at level E 3 is depicted through the visual design (using shot opacity and size), with the key event being depicted using emphasized shadow. Event ordering is shown using illustration ordering, trajectory paths, cueball icons, and the dashboard annotation. The number of illustrations used also impacts on the detail shown in each keyframe. greatest importance and so the illustration appears largest in the storyboard (illustrations 2, 3, 4 and 5 for (a)-(d) respectively). We also show how the number of illustrations can be used to impact the event importance. When 3 illustrations are used, the full visualization is shown with all shots portrayed on each illustration. As the number of illustrations increases, it may be that the level of detail required by the user becomes less. In this example, we choose to show only the key event from level E 3 when 6 illustrations are used. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">EVALUATION</head><p> To evaluate the work in this paper, we organized two consultation sessions . In the first consultation session, we invited 10 participants (7 males and 3 females) with varied familiarity with the game of snooker. The feedback from this consultation session indicates clearly that the storyboard is a much more time-efficient method of understanding the most important events in the video. The full video requires 33 minutes to watch, whereas the participants required (on average) 2 minutes 44 seconds to view the storyboard. Additionally, several participants commented that viewing the video became tedious because of the large number of events that were of little interest, and 'non-action' moments. The feedback also indicates that the storyboard has the clear advantage over basic keyframes in helping viewers identify events. This is because each illustration in a storyboard captures several shots and depicts a series of motions and actions, while each keyframe shows a static temporal instant, from which it is difficult to infer the actual event. However, keyframes are more intuitive to depict the order of events as long as there are a sufficient number of them. Following the initial consultation, we decided to conduct an indepth study on the event selection algorithm by holding a second consultation session. This time, we invited 5 participants all with a good understanding of the game of snooker, but without any knowledge about our event selection algorithm. The goal of this consultation is to establish how close our event selection algorithm would match the expectation of the participants. After a brief introduction, the 5 participants watched the 33 minute video of the snooker match. As instructed , when watching the video, the participants paid their attention to important events of the video. They were allowed to make notes during this time. Immediately after watching the video, we asked the participants 'what would you consider to be the most significant moments in the video?' Participants were given a set of 66 keyframes, one per shot, with textual annotation describing the shots. As shown in <ref type="figure" coords="9,92.39,463.35,24.44,8.07" target="#fig_7">Fig. 10</ref> (a), the 5 participants selected a diverse collection of shots that are considered to be important. The participants often named a group of shots as important, and it was unavoidable to have some numbering errors(±1). Taking these facts into account, the algorithmically determined top level event importance (i.e., the pink regions) correlates well with that suggested by the participants, except for the region of shots 47-49. In fact, shot 48 is a critical point of the match (frame ball). As the video does not show the current scores, most participants did not identify such a key event. On the other hand, our event selection process is capable of computing the numerical scores, thus taking such considerations into account. We then provided the participants with the summary information of their assessment of the importance, highlighting the fact that the region of shots 27-42 were considered to be important by most. Some participants identified this range as two individual events that occur between 27-31 and 33-38, whilst others listed a number of shots that occur within the range 27-42 with (±1) shot-shifting. We then asked the participants to write 5 sentences to describe that particular period of the video. We collected these writings and associated each sentence with the relevant shot numbers. The results are shown in <ref type="figure" coords="9,237.54,652.66,23.66,8.07" target="#fig_7">Fig. 10</ref>(b). The objective is to examine the usefulness of the Gaussianmoderation in selecting events for each illustration in the storyboard. Again we take into account the facts of naming groups of shots and the (±1) shot-shifting errors. Let us focus on shots 28, 30, 34, 36 and 41. The ordinal ranking of the five events are high <ref type="bibr" coords="9,204.22,703.73,65.73,8.17">[30/36, 28/34, 41] </ref>low . The Gaussian moderated-ranking is high <ref type="bibr" coords="9,173.66,715.02,13.94,7.96">[36,</ref><ref type="bibr" coords="9,188.59,715.12,11.46,8.07"> 34,</ref><ref type="bibr" coords="9,201.04,715.12,11.45,8.07"> 41,</ref><ref type="bibr" coords="9,213.48,715.12,11.46,8.07"> 30,</ref><ref type="bibr" coords="9,225.93,715.12,11.46,8.07" target="#b27"> 28] </ref> low . The participants' collective ranking is high <ref type="bibr" coords="9,156.30,726.32,64.73,8.17">[36, 34/41, 30, 28] </ref> low , which is reasonably close to the Gaussian-moderated ranking. The second consultation session has offered a more informative evaluation about our event selection algorithms. It has shown that our top-level importance classification is consistent with the collective views of potential users, and the Gaussian moderation is highly useful in selecting events for each illustration. The two consultation sessions have also revealed that the assessment of importance varies noticeably between users. Storyboarding can potentially be used by coaches to help players make more objective and consistent assessment. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">CONCLUSION</head><p> In this work, we have studied the use of video storyboarding to visualize events in video footage. We have presented a hierarchical framework for event organization, where higher level events are defined upon more detectable low-level events. A video storyboard, which is also organized in a hierarchical manner, consists of a set of illustrations . While each illustration corresponds to a major high-level event, it also depicts a number of events at a lower level. In the context of a sport application, we have developed a software pipeline from object detection to event classification, and from 3D reconstruction to visualization design. The most important contribution of this work is a novel method for hierarchical event selection. This method can easily be deployed in many other applications of event visualization. We have conducted two consultation sessions to evaluate our approach. The results have confirmed the usefulness of video storyboarding in general and the merits of our event selection algorithm in particular. Through an application in snooker, we have demonstrated that a storyboard can provide an effective video visualization tool that facilitates memory externalization and reduces the needs for watching videos repeatedly. Such a tool can be used to analyse events in a game or a training session. A local snooker club has expressed that using such a video storyboard for training summarization would be greatly beneficial to players and coaches. The time required to interpret the visualization is significantly less than viewing the video footage. This approach may also be applicable to other sporting scenarios, along with other application areas, which remains the topic of future work. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS </head><p> Many thanks to Terry Griffiths Matchroom for the use of their facilities and to the Welsh Assembly Government for funding this research. Thanks also goes to Adrian Morris for managing the industrial collaboration , and to Dave Marshall (Cardiff) and Richard Jiang (Swansea) for their involvement in the early developments prior to this work. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="4,24.00,119.90,250.38,7.55;4,24.00,128.20,250.37,8.72;4,24.00,137.67,226.89,8.71"><head>Fig. 3. </head><figDesc>Fig. 3. Snooker event hierarchy. This shows low-level events that occur within a particular shot (E 2 ), higher-level events that define a single shot (E 3 ) and higher-level events that group a collection of shots (E 4 ). </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="4,286.62,191.92,250.39,7.55;4,286.62,200.22,250.39,8.71;4,286.62,209.68,250.38,8.71;4,286.62,219.15,216.81,8.71"><head>Fig. 4. </head><figDesc>Fig. 4. A bar chart of event importance (X-axis givens shot number compared against Y-axis for importance). Events at level E 3 are shown in blue and events at level E 4 are shown in red. Four significantly large peaks occur for E 4 that represent the key events for that level. </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="5,294.36,178.30,213.87,7.55"><head>Fig. 6. </head><figDesc>Fig. 6. Conversion from video view to 3D reconstructed view. </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="7,70.96,169.72,53.98,7.17;7,171.84,169.72,103.28,7.17;7,295.98,169.72,240.18,7.17;7,37.10,302.76,121.70,7.17;7,193.62,302.76,59.71,7.17;7,303.53,302.76,90.94,7.17;7,423.39,302.76,102.27,7.17"><head></head><figDesc>using ball objects (c) Static balls shown by shadow (d) Semi-transparent motion trajectory (e) Importance by shot opacity &amp; size (f) Circle ordering (g) Numbered icon ordering (h) Key event shadow emphasis </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4" coords="7,29.74,335.90,513.00,7.55;7,29.74,345.36,513.00,7.55;7,29.74,354.83,513.01,7.55;7,29.74,364.29,513.00,7.55;7,29.74,373.75,513.00,7.55;7,29.74,383.22,513.00,7.55;7,29.74,392.68,489.29,7.55"><head>Fig. 7. </head><figDesc>Fig. 7. Development of the visualization language used for snooker video storyboarding. Shot 4 is the most important shot in this sequence, where the black is potted in the bottom-right pocket and the cueball travels up the table. 7(a) shows the original representation with all ball objects shown and trajectory data shown by lines. 7(b) replaces the trajectory lines for each ball with ball objects. 7(c) replaces stationary balls with shadow objects. 7(d) introduces a semi-transparent trajectory to represent direction of ball motion. 7(e) incorporates shot importance, based on opacity (applied to both the ball object and the trajectory) and the trajectory width. 7(f) shows event ordering using ring notation, where the number of rings indicates shot number and the outer ring shows object ball colour. 7(g) shows event ordering using numbered icons, where the number indicates shot number and the icon colour shows object ball colour. 7(h) highlights the key event in the sequence (shot 4) using emphasized shadow. </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5" coords="7,29.74,654.65,250.39,7.55;7,29.74,664.11,250.38,7.55;7,29.74,673.58,250.38,7.55;7,29.74,683.04,250.38,7.55;7,29.74,692.51,250.38,7.55;7,29.74,701.97,128.48,7.55"><head>Fig. 8. </head><figDesc>Fig. 8. Snooker visualization annotations. 8(a) shows the numbered icons used for each shot on the table. 8(b) shows the ball pot icons at the side of each pocket which correspond to the shot icons. 8(c) and 8(d) show the 'dashboard' that represents scoring and video timing information. 8(c) shows the state of play early in a match whilst 8(d) indicates a key moment, 'frame ball'. </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7" coords="9,295.36,249.10,250.38,7.55;9,295.36,258.57,250.38,7.55;9,295.36,266.87,249.88,8.71;9,295.36,277.49,250.38,7.55;9,295.36,286.96,250.38,7.55;9,295.36,296.42,250.38,7.55;9,295.36,305.89,221.72,7.55"><head>Fig. 10. </head><figDesc>Fig. 10. Comparing the importance determined by our event selection algorithm to that of the five participants in a consultation session. (a) Each participant corresponds to a line below the bar chart of E 4 and E 3 importance, and the shot considered to be important by the participant is marked with a red circle. (b) Each participant corresponds to a line below the Gaussian-moderated importance chart. The shot considered to be important by the participant is marked with a green circle. </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false" coords="5,31.74,268.47,250.38,94.38"><figDesc coords="5,170.65,268.47,111.46,8.07;5,31.74,278.43,62.50,8.07;5,67.40,298.35,13.45,8.07;5,33.27,308.05,5.66,11.82;5,39.46,313.65,75.02,6.19;5,117.42,302.02,6.97,11.66;5,126.83,297.68,153.77,9.37;5,150.48,308.17,8.14,11.66;5,159.14,313.65,39.35,6.19;5,200.23,308.05,13.87,11.82;5,214.62,313.65,39.34,6.19;5,254.46,308.17,2.49,11.66;5,271.67,320.82,10.45,8.07;5,31.74,332.06,163.59,8.07;5,56.13,351.14,8.14,11.66;5,64.79,356.62,39.35,6.19;5,105.87,351.02,13.88,11.82;5,120.27,356.62,39.34,6.19;5,160.10,351.02,19.10,11.82;5,179.72,353.44,78.02,9.37">table. The importance of frame ball is defined as: 147 α points remaining on table × max(α player1 score , 1) max(α player2 score , 1) |α player1 score − α player2 score | (6) Note that frame ball is only considered when: |α player1 score − α player2 score | &gt; α points remaining on table .</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false" coords="5,30.75,26.18,518.00,7.54"><figDesc coords="5,532.75,26.46,16.00,7.26;5,30.75,26.18,441.78,7.50;6,40.33,51.13,40.22,7.02;6,129.28,51.13,112.09,7.02;6,307.07,51.13,181.50,7.02;6,105.63,60.55,210.67,7.08;6,403.12,60.55,32.02,7.08;6,40.33,70.46,38.53,7.02">1751 PARRY ET AL: HIERARCHICAL EVENT SELECTION FOR VIDEO STORYBOARDS WITH A CASE STUDY ON SNOOKER Visual Cues Constraints due to current use in Design options of additional event annotation to show Existing Data Space Existing Rendering Space Event Order Key Event Luminance</figDesc><table coords="6,40.33,70.41,478.34,139.67">n/a 
n/a 
Diffuse or specular highlight 
Trajectory of key event only 
Colour 
Ball colours 
Constrained by data 
Varying trajectory colours 
Varying trajectory colours 
Opacity 
n/a 
n/a 
Use to show ball motion 
Use for relative shot comparison 
Size 
Ball size 
Constrained by data 
Increment size based on order 
Larger ball object for key event 
Shadow 
n/a 
Shadow of ball objects 
Increase darkness based on order 
Shadow only for key events 
Line 
-length 
Ball trajectory 
Constrained by data 
Constrained by data space 
Constrained by data space 
-thickness 
n/a 
Based on 3-D perspective 
Increase line thickness 
Key events shown thicker 
Texture 
-ball 
n/a 
Ball luminance 
Constrained by rendering space 
Constrained by rendering space 
-trajectory 
n/a 
n/a 
Texture a proportion based on order 
Use ball motion for key events 
-table 
n/a 
n/a 
Rings around cueball to show order 
Text or symbol to shown key events 
Annotation 
-inside frame 
n/a 
n/a 
Text-based label (may clutter) 
Text-based label (may clutter) 
-outside frame 
n/a 
n/a 
Show potted balls by pocket 
Speech bubble pointing to key event 

</table></figure>

			<note place="foot">Fig. 2. Example to show event importance and selection. Events to be selected for video storyboard at level k and k − 1 are shown by the blue &apos;tick&apos; icon. This illustrates how the Gaussian function introduces a temporal measure into the moderated importance criteria. importance of a higher level event will have significant influence on the selection of lower level events. In many ways, this is similar to storytelling. The selection of a lower level event (e.g., pick up a knife) for the story would depend heavily on the importance of the related event at a higher level (e.g., fighting or cooking). Once importance for each event is computed, we can start to select events for event summarization. In this work, a summarization is also organized hierarchically. Again, similar to storytelling, a story consists of a number of sub-stories. Each sub-story consists of a number of subsub-stories . There is an overall control about the coverage in breadth (i.e., how many sub-stories are allowed) and depth (i.e., how many levels of details). Our event selection algorithm assumes the input of the following initial conditions from the user: the particular levels of events to be included in the summary, the maximum number of events at the highest level to be included in the summary, the time period covered, and a few other parameters to be given later in the relevant context. Let H 1 ≺ H 2 ≺ . . . ≺ H k be the k levels of events to be visualized. N k be the maximum number of events to be depicted at level H k . The selection algorithm first selects N k events at level H k with the highest importance values, resulting in a sequence: A = ⟨a 1 , a 2 , . . . , a n ⟩ where each event a i has an importance value α i . For each event a i ∈ A at level k, we identify a sequence of relevant events at level k − 1. The relevance is defined by a time period, [t − δ 1 ,t + δ 2 ] where t is the point in time of a i , and δ 1 , δ 2 ≥ 0. Often, we set δ 2 = 0 as the depiction of an event usually involves showing more information about the sub-events leading the event. Let B i = ⟨b i,1 , b i,2 , . . . , b i,m ⟩ be a sequence of such sub-events at level k − 1. Each b i, j is defined with its importance β j and time u j . The importance value β j is moderated by a Gaussian function G(x) where x = |u j − t|. The parameter σ of G(x) is pre-defined, and we set σ = 2 as a default in our system. This Gaussian function gradually reduces the importance of events in B i if they are further away from t, which is the temporal focus of a i . Let β ′ 1 , β ′ 2 , . . . , β ′ m be the resultant importance values after Gaussian moderation. Let N k−1 be a local maximum number of events at level k − 1 to be visualized for each event a i at level k. We select N k−1 events from B i based on with the highest importance values in ⟨β ′ 1 , β ′ 2 , . . . , β ′ m ⟩. Fig. 2 illustrates this moderation process, which can continue recursively. 4 CASE STUDY: SNOOKER VIDEO VISUALIZATION We now present the proposed framework in application to sports video event visualization. We choose snooker as an example since it consists of well-defined events that can be clearly represented. Snooker is played on a large green baize-covered table (of size 12 × 6 ft) with pockets in each of the four corners and in the middle of each of the long side cushions [7]. It is played using a cue and a set of snooker balls, consisting of one white cue ball, 15 red balls (worth one point each), and a series of coloured balls: yellow (worth two points), green (worth</note>

			<note place="foot">PARRY ET AL: HIERARCHICAL EVENT SELECTION FOR VIDEO STORYBOARDS WITH A CASE STUDY ON SNOOKER</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="10,40.26,74.54,232.12,7.17;10,40.26,84.01,213.83,7.17"  xml:id="b0">
	<analytic>
		<title level="a" type="main">Action synopsis: pose selection and illustration</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Assa</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">Y</forename>
				<surname>Caspi</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Cohen-Or</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Graphics</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="667" to="676" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,40.26,93.47,232.12,7.17;10,40.26,102.94,232.12,7.17;10,40.26,112.40,232.11,7.17;10,40.26,121.87,143.01,7.17"  xml:id="b1">
	<analytic>
		<title level="a" type="main">A survey on videobased graphics and video visualization</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Borgo</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Chen</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">B</forename>
				<surname>Daubney</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">E</forename>
				<surname>Grundy</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">H</forename>
				<surname>Jänicke</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">G</forename>
				<surname>Heidemann</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">B</forename>
				<surname>Höferlin</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Höferlin</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Weiskopf</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">X</forename>
				<surname>Xie</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Eurographics (State of the Art Reports)</title>
		<meeting><address><addrLine>Llandudno, UK</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="1" to="23" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,40.26,131.33,232.12,7.17;10,40.26,140.80,232.12,7.17;10,40.26,150.26,212.05,7.17"  xml:id="b2">
	<analytic>
		<title level="a" type="main">Visual signatures in video visualization</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Chen</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">R</forename>
				<forename type="middle">P</forename>
				<surname>Botchen</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">R</forename>
				<forename type="middle">R</forename>
				<surname>Hashim</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Weiskopf</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Ertl</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">I</forename>
				<forename type="middle">M</forename>
				<surname>Thornton</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1093" to="1100" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,40.26,159.72,232.12,7.17;10,40.26,169.19,181.84,7.17"  xml:id="b3">
	<analytic>
		<title level="a" type="main">Video visualization</title>
		<author>
			<persName>
				<forename type="first">G</forename>
				<forename type="middle">W</forename>
				<surname>Daniel</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Chen</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Visualization</title>
		<meeting>. IEEE Visualization<address><addrLine>Seattle, WA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003-10" />
			<biblScope unit="page" from="409" to="416" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,40.26,178.65,232.12,7.17;10,40.26,188.12,232.12,7.17;10,40.26,197.58,17.93,7.17"  xml:id="b4">
	<analytic>
		<title level="a" type="main">Content based analysis for video from snooker broadcasts</title>
		<author>
			<persName>
				<forename type="first">H</forename>
				<surname>Denman</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">N</forename>
				<surname>Rea</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Kokaram</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Image and Video Retrieval</title>
		<imprint>
			<biblScope unit="volume">2383</biblScope>
			<biblScope unit="page" from="198" to="205" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,40.26,207.05,232.12,7.17;10,40.26,216.51,232.12,7.17;10,40.26,225.98,87.44,7.17"  xml:id="b5">
	<analytic>
		<title level="a" type="main">Techniques for automated reverse storyboarding</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<forename type="middle">D</forename>
				<surname>Dony</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">W</forename>
				<surname>Mateer</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">A</forename>
				<surname>Robinson</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEE Journal of Vision Image and Signal Processing</title>
		<imprint>
			<biblScope unit="volume">152</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="425" to="436" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,40.26,235.44,232.13,7.17;10,40.26,244.91,170.92,7.17"  xml:id="b6">
	<monogr>
		<title level="m" type="main">Snooker and Billiards: Techniques, Tactics and Training (Crowood Sports Guides)</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Everton</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="1991" />
			<publisher>The Crowood Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,40.26,254.37,232.13,7.17;10,40.26,263.83,232.12,7.17;10,40.26,273.30,129.81,7.17"  xml:id="b7">
	<analytic>
		<title level="a" type="main">Interative analysis of event data using space-time cube</title>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Gatalsky</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">N</forename>
				<surname>Andrienko</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">G</forename>
				<surname>Andrienko</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">8th International Conference on Information Visualisation</title>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="145" to="152" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,40.26,282.76,232.12,7.17;10,40.26,292.23,232.12,7.17;10,40.26,301.69,102.82,7.17"  xml:id="b8">
	<analytic>
		<title level="a" type="main">Schematic storyboarding for video visualization and editing</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<forename type="middle">B</forename>
				<surname>Goldman</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">B</forename>
				<surname>Curless</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Salesin</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">S</forename>
				<forename type="middle">M</forename>
				<surname>Seitz</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Graphics</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="862" to="871" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,40.26,311.16,232.12,7.17;10,40.26,320.62,232.12,7.17;10,40.26,330.09,232.12,7.08;10,40.26,339.55,131.18,7.17"  xml:id="b9">
	<analytic>
		<title level="a" type="main">Using computer vision to create a 3d representation of a snooker table for televised competition broadcasting</title>
		<author>
			<persName>
				<forename type="first">H</forename>
				<surname>Guo</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">B</forename>
				<forename type="middle">M</forename>
				<surname>Namee</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 18th Irish Conference on Artifical Intelligence and Cognitive Science</title>
		<meeting>the 18th Irish Conference on Artifical Intelligence and Cognitive Science</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="220" to="229" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,40.26,349.02,232.12,7.17;10,40.26,358.48,232.12,7.17;10,40.26,367.94,133.64,7.17"  xml:id="b10">
	<analytic>
		<title level="a" type="main">Video visualization for snooker skill training</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Höferlin</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">E</forename>
				<surname>Grundy</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Borgo</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Weiskopf</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Chen</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">I</forename>
				<forename type="middle">W</forename>
				<surname>Griffiths</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">W</forename>
				<surname>Griffiths</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics Forum</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1053" to="1062" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,40.26,377.41,232.13,7.17;10,40.26,386.87,232.11,7.17;10,40.26,396.34,221.75,7.17"  xml:id="b11">
	<monogr>
		<title level="m" type="main">A survey on visual surveillance of object motion and behaviors. IEEE transactions on systems, man and cybernetics -Part C: Applications and reviews</title>
		<author>
			<persName>
				<forename type="first">W</forename>
				<surname>Hu</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Tan</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">L</forename>
				<surname>Wang</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Maybank</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="334" to="352" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,40.26,405.80,232.12,7.17;10,40.26,415.27,232.13,7.08;10,40.26,424.73,61.97,7.17"  xml:id="b12">
	<analytic>
		<title level="a" type="main">Geotime information visualization</title>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Kapler</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">W</forename>
				<surname>Wright</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">INFOVIS &apos;04 Proceedings of the IEEE symposium on Information Visualization</title>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="25" to="32" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,40.26,434.20,232.12,7.17;10,40.26,443.66,161.40,7.17"  xml:id="b13">
	<analytic>
		<title level="a" type="main">Fast pattern matching in strings</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<forename type="middle">E</forename>
				<surname>Knuth</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">H</forename>
				<surname>Morris</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">V</forename>
				<forename type="middle">R</forename>
				<surname>Pratt</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM Journal on Computing</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="323" to="350" />
			<date type="published" when="1977" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,40.26,453.12,232.12,7.17;10,40.26,462.59,232.12,7.17;10,40.26,472.05,232.12,7.17;10,40.26,481.52,232.12,7.08;10,40.26,490.98,76.37,7.17"  xml:id="b14">
	<analytic>
		<title level="a" type="main">Intelligent filtering by semantic importance for single-view 3D reconstruction from snooker video</title>
		<author>
			<persName>
				<forename type="first">P</forename>
				<forename type="middle">A</forename>
				<surname>Legg</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">M</forename>
				<forename type="middle">L</forename>
				<surname>Parry</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">D</forename>
				<forename type="middle">H S</forename>
				<surname>Chung</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">R</forename>
				<forename type="middle">M</forename>
				<surname>Jiang</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Morris</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">I</forename>
				<forename type="middle">W</forename>
				<surname>Griffiths</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Marshall</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Chen</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">18th International Conference on Image Processing (ICIP)</title>
		<meeting><address><addrLine>Brussel, Belgium</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
	<note>To. appear in</note>
</biblStruct>

<biblStruct coords="10,40.26,500.45,232.12,7.17;10,40.26,509.91,232.12,7.17;10,40.26,519.38,159.31,7.17"  xml:id="b15">
	<analytic>
		<title level="a" type="main">Event detection and summarization in sports video</title>
		<author>
			<persName>
				<forename type="first">B</forename>
				<surname>Li</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">M</forename>
				<forename type="middle">I</forename>
				<surname>Sezan</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Content-Based Access of Image and Video Libraries</title>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="page" from="132" to="138" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,40.26,528.84,232.12,7.17;10,40.26,538.31,232.13,7.17;10,40.26,547.77,183.53,7.17"  xml:id="b16">
	<analytic>
		<title level="a" type="main">Event detection and analysis from video streams</title>
		<author>
			<persName>
				<forename type="first">G</forename>
				<surname>Medioni</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">I</forename>
				<surname>Cohen</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">F</forename>
				<surname>Bremond</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Hongeng</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Nevatia</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="873" to="889" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,40.26,557.23,232.12,7.17;10,40.26,566.70,232.13,7.17;10,40.26,576.16,232.11,7.08;10,40.26,585.63,199.44,7.17"  xml:id="b17">
	<analytic>
		<title level="a" type="main">Detection of slow-motion replay segments in sports video for highlights generation</title>
		<author>
			<persName>
				<forename type="first">H</forename>
				<surname>Pan</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Van Beek</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">M</forename>
				<forename type="middle">I</forename>
				<surname>Sezan</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Acoustics, Speech, and Signal Processing Proceedings. (ICASSP &apos;01). 2001 IEEE International Conference on</title>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="page" from="1649" to="1652" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,40.26,595.09,232.12,7.17;10,40.26,604.56,232.11,7.17;10,40.26,614.02,232.12,7.17;10,40.26,623.49,17.93,7.17"  xml:id="b18">
	<analytic>
		<title level="a" type="main">Modelling high level structure in sports with motion driven HMMS</title>
		<author>
			<persName>
				<forename type="first">N</forename>
				<surname>Rea</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Dahyot</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Kokaram</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Acoustics, Speech and Signal Processing</title>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="621" to="624" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,40.26,632.95,232.13,7.17;10,40.26,642.41,232.13,7.17;10,40.26,651.88,188.51,7.17"  xml:id="b19">
	<analytic>
		<title level="a" type="main">Viz-a-vis: Towards visualizing video through computer vision</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Romero</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Summet</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Stasko</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">G</forename>
				<surname>Abowd</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1261" to="1268" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,40.26,661.34,232.12,7.17;10,40.26,670.81,232.12,7.17;10,40.26,680.27,232.11,7.17;10,40.26,689.74,17.93,7.17"  xml:id="b20">
	<analytic>
		<title level="a" type="main">Event detection in field sports video using audio-visual features and a support vector machine. Circuits and Systems for Video Technology</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<forename type="middle">A</forename>
				<surname>Sadlier</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">N</forename>
				<forename type="middle">E</forename>
				<surname>Connor</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1225" to="1233" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,40.26,699.20,232.12,7.17;10,40.26,708.67,232.11,7.17;10,40.26,718.13,117.56,7.17"  xml:id="b21">
	<analytic>
		<title level="a" type="main">A method of billiard objects detection based on snooker game video</title>
		<author>
			<persName>
				<forename type="first">W</forename>
				<surname>Shen</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">L</forename>
				<surname>Wu</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Future Computer and Communication (ICFCC)</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,40.26,727.60,232.12,7.17;10,40.26,737.06,69.28,7.17"  xml:id="b22">
	<analytic>
		<title level="a" type="main">Activities: States or events?</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<forename type="middle">S</forename>
				<surname>Smith</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Linguistics and Philosophy</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="479" to="508" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,284.62,54.02,250.39,7.17;10,302.88,63.49,232.12,7.17;10,302.88,72.95,112.23,7.17"  xml:id="b23">
	<analytic>
		<title level="a" type="main">Video summarization for large sports video archives</title>
		<author>
			<persName>
				<forename type="first">]</forename>
				<forename type="middle">Y</forename>
				<surname>Takahashi</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">N</forename>
				<surname>Nitta</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">N</forename>
				<surname>Babaguchi</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Multimedia and Expo</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="1170" to="1173" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,302.88,82.42,232.12,7.17;10,302.88,91.88,232.12,7.17;10,302.88,101.35,232.11,7.17;10,302.88,110.81,129.61,7.17"  xml:id="b24">
	<analytic>
		<title level="a" type="main">Contextualized videos: Combining videos with environment models to support situational understanding</title>
		<author>
			<persName>
				<forename type="first">Y</forename>
				<surname>Wang</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">D</forename>
				<forename type="middle">M</forename>
				<surname>Krum</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">E</forename>
				<forename type="middle">M</forename>
				<surname>Coelho</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">D</forename>
				<forename type="middle">A</forename>
				<surname>Bowman</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1568" to="1575" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,302.88,120.27,232.12,7.17;10,302.88,129.74,55.55,7.17"  xml:id="b25">
	<monogr>
		<title level="m" type="main">Information Visualization: Perception for Design</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Ware</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2000" />
			<publisher>Morgan Kaufmann</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,302.88,139.20,232.12,7.17;10,302.88,148.67,123.29,7.17"  xml:id="b26">
	<analytic>
		<title level="a" type="main">Retrieving and visualizing video</title>
		<author>
			<persName>
				<forename type="first">B.-L</forename>
				<surname>Yeo</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Yeung</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="43" to="52" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,302.88,158.13,232.12,7.17;10,302.88,167.60,232.11,7.17;10,302.88,177.06,17.93,7.17"  xml:id="b27">
	<analytic>
		<title level="a" type="main">Automatic animation for timevarying data visualization</title>
		<author>
			<persName>
				<forename type="first">L</forename>
				<surname>Yu</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Lu</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">W</forename>
				<surname>Ribarsky</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">W</forename>
				<surname>Chen</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics Forum</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="2271" to="2280" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,302.88,186.53,232.12,7.17;10,302.88,195.99,232.12,7.08;10,302.88,205.45,232.12,7.17;10,302.88,214.92,33.86,7.17"  xml:id="b28">
	<analytic>
		<title level="a" type="main">Event-based analysis of video</title>
		<author>
			<persName>
				<forename type="first">L</forename>
				<surname>Zelnik-Manor</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Irani</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition Proceedings of the 2001 IEEE Computer Society Conference on</title>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="page" from="123" to="130" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
