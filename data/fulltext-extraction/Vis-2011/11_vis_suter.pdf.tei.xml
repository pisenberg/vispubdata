<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/pisenberg/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.4.1" ident="GROBID" when="2016-09-09T15:00+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Interactive Multiscale Tensor Reconstruction for Multiresolution Volume Visualization</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName>
								<forename type="first">Susanne</forename>
								<forename type="middle">K</forename>
								<surname>Suter</surname>
								<roleName>Student Member, Ieee</roleName>
							</persName>
						</author>
						<author>
							<persName>
								<forename type="first">Joséjos´josé</forename>
								<forename type="middle">A Iglesias</forename>
								<surname>Guití</surname>
							</persName>
						</author>
						<author>
							<persName>
								<forename type="first">Fabio</forename>
								<surname>Marton</surname>
							</persName>
						</author>
						<author>
							<persName>
								<forename type="first">Marco</forename>
								<surname>Agus</surname>
							</persName>
						</author>
						<author>
							<persName>
								<forename type="first">Andreas</forename>
								<surname>Elsener</surname>
								<roleName>Member, Ieee</roleName>
							</persName>
						</author>
						<author>
							<persName>
								<forename type="first">Christoph</forename>
								<forename type="middle">P E</forename>
								<surname>Zollikofer</surname>
							</persName>
						</author>
						<author>
							<persName>
								<forename type="first">M</forename>
								<surname>Gopi</surname>
							</persName>
						</author>
						<author>
							<persName>
								<forename type="first">Enrico</forename>
								<surname>Gobbetti</surname>
							</persName>
						</author>
						<author>
							<persName>
								<forename type="first">Renato</forename>
								<surname>Pajarola</surname>
								<roleName>Member, Ieee</roleName>
							</persName>
						</author>
						<title level="a" type="main">Interactive Multiscale Tensor Reconstruction for Multiresolution Volume Visualization</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Index Terms—GPU/CUDA</term>
					<term>multiscale</term>
					<term>tensor reconstruction</term>
					<term>interactive volume visualization</term>
					<term>multiresolution rendering</term>
				</keywords>
			</textClass>
			<abstract>
				<p>—Large scale and structurally complex volume datasets from high-resolution 3D imaging devices or computational simulations pose a number of technical challenges for interactive visual analysis. In this paper, we present the first integration of a multiscale volume representation based on tensor approximation within a GPU-accelerated out-of-core multiresolution rendering framework. Specific contributions include (a) a hierarchical brick-tensor decomposition approach for pre-processing large volume data, (b) a GPU accelerated tensor reconstruction implementation exploiting CUDA capabilities, and (c) an effective tensor-specific quantization strategy for reducing data transfer bandwidth and out-of-core memory footprint. Our multiscale representation allows for the extraction, analysis and display of structural features at variable spatial scales, while adaptive level-of-detail rendering methods make it possible to interactively explore large datasets within a constrained memory footprint. The quality and performance of our prototype system is evaluated on large structurally complex datasets, including gigabyte-sized micro-tomographic volumes.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p> The continuing advances in 3D imaging technologies, such as the improvements of phase contrast synchrotron and micro-computed X-ray tomography, as well as the ever higher resolution of numerical simulations brought up by high performance computing, are leading to the generation of large scale and structurally complex volume datasets. These large 3D data volumes not only represent an immense amount of information, but also exhibit an increasing level of detail of internal structure in space (and possibly time), resulting in a high degree of complexity at different scales. The visualization challenge is to create new methods that allow analysts to visually examine and understand these datasets of overwhelming size and complexity. Direct volume rendering (DVR) is the technique of choice for interactive data visualization and exploration, since it supports the representation of the full dataset in a single image using a variety of semitransparent mappings. In the last few years, improvements in programmability and performance of GPUs have made GPU solutions the main option for real-time rendering on desktop platforms <ref type="bibr" coords="1,244.17,468.92,9.52,11.66" target="#b8">[9]</ref> . However , the sheer size of nowadays large datasets requires the integration of adaptive data reduction methods based on levels of detail (LOD), together with out-of-core memory management techniques, since full datasets typically do not fit in the available GPU memory (nor main memory), and, even if they could, traversing all data voxels for computing volume integrals remains too costly for real-time rendering. The key point is to define a suitable multiresolution model, an approximation hierarchy over the volume that can be traversed at run-time to adaptively select a LOD, which satisfies a certain visual quality or rendering performance threshold for every displayed frame. In recent years, much effort has been put into the development of mathematical representations that can approximate complex data. A @BULLET S.K. Suter, A. Elsener, C.P.E. Zollikofer, and R. Pajarola are with University of Zurich, Switzerland, E-mail: susuter@ifi.uzh.ch, elsener@ifi.uzh.ch, zolli@aim.uzh.ch, and pajarola@acm.org. @BULLET J.A. Iglesias Guitián, F. Marton, M. Agus and E. Gobbetti are with CRS4, Italy, E-mail: jalley@crs4.it, marton@crs4.it, magus@crs4.it, and gobbetti@crs4.it. @BULLET M. Gopi is with University of California, Irvine, USA, E-mail:  widespread approach is to find a limited set of numerical bases together with a corresponding set of coefficients whose weighted linear combination is a close approximation of the original data. Decomposition of large datasets into bases has two main objectives: (1) save memory and bandwidth to accelerate rendering tasks, and (2) extract and represent relevant features, where relevance is defined by the scientific questions asked during the dataset visualization. The potential of these methods for simultaneous bandwidth reduction and feature extraction is largely unexplored. Accordingly, the goal is to search for feature-specific bases that reflect statistical (spatial) properties of the features to be extracted rather than to use a-priori bases. Tensor approximation (TA) frameworks, as summarized in <ref type="bibr" coords="1,527.32,418.88,13.74,11.66" target="#b14">[15]</ref>, are an extension of standard matrix data approximation tools, such as SVD, to higher-orders and provide such bases for a compact linear data representation (see Appendix A). There are two parts to tensor approximation: (1) tensor decomposition, usually an offline process, to compute the bases and coefficients, and (2) tensor reconstruction from the previously computed bases, which should be a fast online process in an interactive visualization application. Suter et al. <ref type="bibr" coords="1,479.36,488.62,14.94,11.66" target="#b22">[23] </ref>have recently presented preliminary results on small datasets, which indicate that TA promises to be a viable alternative to more traditional approaches like, e.g., wavelets, for creating compact feature-preserving volume representations . The efficiency of TA for interactive DVR, associated to real-time tensor reconstruction, is currently mostly unexplored, as is the applicability of such methods to large datasets. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Contributions: </head><p>In this paper, we advance the state-of-the-art by introducing the first GPU accelerated integration of multiscale volume tensor reconstruction within a real-time single-pass multiresolution volume ray-casting framework. Our specific contributions are: @BULLET we introduce and analyze an end-to-end system based on a bricked tensor decomposition, which is capable of preprocessing and rendering in real-time multi-gigabyte datasets using a limited memory footprint; @BULLET we introduce and describe a CUDA TA reconstruction process with a computational complexity growing only linearly with the reduced tensor rank and with an implementation exploiting the parallelism and memory hierarchy of GPGPU platforms; @BULLET we introduce and evaluate a tensor specific quantization scheme, which reduces the out-of-core memory footprint as well as disk to CPU to GPU data transfer bandwidth; @BULLET we provide an experimental analysis of the impact of the above contributions on massive volume datasets (17GB). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK</head><p>LOD based rendering using hierarchical volume representations as well as multiresolution out-of-core models are standard techniques to achieve interactive visualization performance for large scale volume data <ref type="bibr" coords="2,40.71,94.65,9.52,11.66" target="#b8">[9]</ref>. Most modern techniques perform full ray traversal on the GPU. In this context, large volume data is handled by compressing it using adaptive texturing schemes to fit entire datasets into GPU mem- ory <ref type="bibr" coords="2,36.24,124.54,13.74,11.66" target="#b24">[25]</ref>, or by using flat <ref type="bibr" coords="2,109.76,124.54,14.94,11.66" target="#b16">[17] </ref>or hierarchical <ref type="bibr" coords="2,179.85,124.54,14.19,11.66" target="#b11">[12,</ref><ref type="bibr" coords="2,195.83,124.54,6.72,11.66" target="#b4"> 5,</ref><ref type="bibr" coords="2,204.34,124.54,11.95,11.66" target="#b13"> 14] </ref>multiresolution structures in conjunction with adaptive loaders to deal with datasets of potentially unlimited size. In this context, our contribution is the first integration of a GPU accelerated tensor reconstruction of multiscale volume data into a real-time and out-of-core LOD based volume renderer (i.e., MOVR <ref type="bibr" coords="2,90.28,174.35,14.19,11.66" target="#b11">[12,</ref><ref type="bibr" coords="2,106.71,174.35,10.31,11.66" target="#b13"> 14]</ref>). Data reduction, in this context, is of great importance to save storage space at all stages of the processing and rendering pipelines, as well as to reduce time and cost of transmission between the layers of the memory hierarchy. Since lossless schemes typically provide limited gains <ref type="bibr" coords="2,91.30,224.51,13.74,11.66" target="#b10">[11]</ref>, many of the efforts are concentrated around lossy approximation methods, combining various forms of data transformation and quantization. Fout and Ma <ref type="bibr" coords="2,179.06,244.43,14.94,11.66" target="#b10">[11] </ref> emphasize that compression and decompression processes have to be highly asymmetric: with todays GPU rendering capabilities, we can afford a slow (offline) compression, while, in contrast, decompression needs to be fast and spatially independent to enable real-time rendering. This fact rules out techniques for achieving higher compression ratios (e.g., complex variable-length entropy coders), but having detrimental effects on GPU decompression speeds. Compact mathematical representations of volume datasets can be based on predefined or data-specific bases decompositions. Methods using predefined basis are often computationally cheaper, while methods using data-specific bases require more precomputing time (to compute the bases), but are potentially able to remove more redundancy from a dataset. Today, predefined methods like Fourier trans- form <ref type="bibr" coords="2,42.73,384.26,9.52,11.66" target="#b3">[4]</ref>, wavelet transform (e.g., <ref type="bibr" coords="2,149.66,384.26,14.19,11.66" target="#b20">[21,</ref><ref type="bibr" coords="2,167.15,384.26,11.21,11.66" target="#b12"> 13,</ref><ref type="bibr" coords="2,181.65,384.26,10.31,11.66" target="#b10"> 11]</ref>), and discrete cosine transform <ref type="bibr" coords="2,61.39,394.22,13.74,11.66" target="#b27">[28]</ref> , as well as data-specific bases like vector quantiza- tion <ref type="bibr" coords="2,39.62,404.18,14.19,11.66" target="#b21">[22,</ref><ref type="bibr" coords="2,56.98,404.18,11.21,11.66" target="#b10"> 11,</ref><ref type="bibr" coords="2,71.35,404.18,11.95,11.66" target="#b19"> 20] </ref> are well-known approaches for volume data representations . In particular, wavelet transform and vector quantization, often combined together, are standard tools for compression domain volume rendering. Wavelets are especially convenient for compressed LOD DVR since they define a multiresolution hierarchy of coefficients , where each coefficient improves the approximation – higherlevel coefficients are more important and small coefficients may be thresholded. Similary, there exist hierarchical vector quantizers <ref type="bibr" coords="2,255.70,473.92,13.74,11.66" target="#b21">[22]</ref>, where the focus lies on finding an optimal decoding scheme for a realtime and simultaneous GPU reconstruction. Using predefined or data-specific bases should be seen as two alternatives with both assets and drawbacks. Wavelets correspond to spatial averaging and the wavelet coefficients are derived from the convolution of applying one-dimensional filters along the spatial axes. That makes it difficult to compactly represent unaligned three-dimensional features <ref type="bibr" coords="2,53.28,553.97,13.74,11.66" target="#b22">[23]</ref> . There has been much work on developing more powerful oriented wavelet bases for multi-dimensional spaces <ref type="bibr" coords="2,226.72,563.93,9.71,11.66" target="#b6">[7,</ref><ref type="bibr" coords="2,239.06,563.93,6.47,11.66" target="#b7"> 8]</ref> . However , such bases are still data-independent prescribed filters, and the gained compression efficiency over axis-aligned bases is limited <ref type="bibr" coords="2,254.92,583.85,13.74,11.66" target="#b26">[27]</ref>. We would like to have a fresh look at the problem by learning preferential bases directly from the data, thus removing a bias in the approximation process. This, so far, has been done in DVR using learned codebooks combined with vector quantization <ref type="bibr" coords="2,191.31,624.05,14.19,11.66" target="#b21">[22,</ref><ref type="bibr" coords="2,208.02,624.05,11.21,11.66" target="#b10"> 11,</ref><ref type="bibr" coords="2,221.73,624.05,10.65,11.66" target="#b19"> 20]</ref> , which require , however, large dictionaries if low distortion is desired. While computational aspects and rendering performance of base decomposition methods have been studied extensively, these methods are only beginning to be used for feature extraction. Our choice of approach was, however, to find bases, which simultaneously reduce datasets and represent features. The most common tools for data approximation with computed bases are the singular value decomposition (SVD) and the principal component analysis (PCA). Both approaches work on 2D matrix data and exploit the fact that the dataset can be represented with a few highly significant coefficients and corresponding reconstruction vectors (based on the matrix rank reduction concept). The extension of rank-reduced data approximation to higher-order is not unique and can be grouped into two main so called tensor approximation (TA) approaches: the Tucker model and the Candecomp/Parafac (CP) model, which were recently reviewed in <ref type="bibr" coords="2,403.93,90.79,13.74,11.66" target="#b14">[15]</ref>. Recently, tensor approximation has been demonstrated to be a valid alternative 3D spatial volume compression method <ref type="bibr" coords="2,472.28,111.05,14.19,11.66" target="#b23">[24,</ref><ref type="bibr" coords="2,489.20,111.05,11.21,11.66" target="#b26"> 27,</ref><ref type="bibr" coords="2,503.13,111.05,10.65,11.66" target="#b22"> 23]</ref>. Our work builds on the approaches of Wu et al. <ref type="bibr" coords="2,443.57,121.01,14.94,11.66" target="#b26">[27] </ref>and Suter et al. <ref type="bibr" coords="2,518.32,121.01,13.74,11.66" target="#b22">[23]</ref>, where tensor approximation is used as an approach to reduce and visualize volume data with a mathematical representation. Specifically, we use a Tucker model for which a short summary is given in Appendix A. Properties of the Tucker model and common notations, which we follow in this work, are elaborated in <ref type="bibr" coords="2,420.91,170.83,13.74,11.66" target="#b14">[15]</ref>. It should be noted that the TA approach has the advantage that the ranks of the factor matrices (and in turn the size of the core tensor) can be conveniently reduced without destroying cache coherence and without data repacking. Our idea was to extend and improve the offline TA method used in <ref type="bibr" coords="2,296.62,220.97,14.94,11.66" target="#b22">[23] </ref>to a real-time interactive system and verify it with large datasets. We extended the previous work <ref type="bibr" coords="2,436.98,230.93,14.94,11.66" target="#b22">[23] </ref> with a bricked TA implementation , we evaluated and defined a Tucker-specific quantization scheme and we provided a real-time tensor decomposition reconstruction on the GPU. As in other works, out-of-core <ref type="bibr" coords="2,466.65,260.82,14.94,11.66" target="#b25">[26] </ref> and hierarchi- cal <ref type="bibr" coords="2,297.82,270.78,14.94,11.66" target="#b26">[27] </ref>data management techniques were applied to our approach. A complete hierarchical multiscale TA system has been proposed in <ref type="bibr" coords="2,295.08,291.04,13.74,11.66" target="#b26">[27]</ref> . Their data hierarchy consists of tensor decomposed subvolumes with each level having a progressively decreasing rank-reduction level. All subvolumes or (volume) bricks – as they are called – on one hierarchy level, representing the residual to the parent level, are treated as a tensor ensemble. As a result, each hierarchy level consists of one single rank-reduced core tensor and multiple factor matrices. However , for interactive reconstruction and visualization many temporary results must be cached in the hierarchy at run-time. Instead, we build a multiresolution TA octree where each lower resolution brick is an autonomous tensor decomposition that can independently be reconstructed and rendered on demand, attaining interactive speed. The reconstruction process from our chosen tensor decomposition is, in principle, straightforward, and can be optimized by a careful reordering of operations (Appendix A.2). Nevertheless, reconstruction time can be critical for real-time visualization and therefore needs to be given attention in our system. For the first time, we address GPGPUbased tensor reconstruction and therefore the reconstruction concepts should fit parallel computing concepts. E.g., while thresholding of tensor coefficients <ref type="bibr" coords="2,341.03,470.70,14.94,11.66" target="#b26">[27] </ref>may reduce the amount of data, the reconstruction process can be more tedious for parallel computing since complex decoding algorithms have to be used. Moreover, the reconstruction is affected by the format and representation of the coefficients. For compact data representation, the encoding of numerical values is fundamental and hence an appropriate quantization must be devised. We refrain from variable-length coding at this point to avoid the corresponding costly decompression. Fixed linear quantization for the factor matrices (8-bit) and core tensor (8-20-bit) has been proposed in <ref type="bibr" coords="2,295.63,560.69,13.74,11.66" target="#b26">[27]</ref> . We investigate more tensor-specific linear as well as nonlinear quantizations, suitable for fast reconstruction implementation on the GPU. In particular, the distribution of the core tensor coefficients can benefit from logarithmic quantization, and we analyze the error rate of different quantization strategies. There exist only a few commonly available TA implementations: e.g, there is a comprehensive MatLab toolbox <ref type="bibr" coords="2,452.99,620.80,10.45,11.66" target="#b1">[2] </ref>, and for C++ there is a tensor framework for 3D datasets available with the VMMLib <ref type="bibr" coords="2,522.80,630.76,9.52,11.66" target="#b0">[1]</ref>, which was extended for this project and used for the preprocessing part on the CPU. However, no hardware accelerated implementations have been proposed so far. In this paper, we present the first CUDA <ref type="bibr" coords="2,521.30,660.65,14.19,11.66" target="#b17">[18,</ref><ref type="bibr" coords="2,285.12,670.61,11.95,11.66" target="#b18"> 19] </ref>based GPU accelerated implementation of a reduced complexity Tucker volume tensor reconstruction algorithm. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">BRICKED MULTIRESOLUTION TA</head><p>Large volumes cannot be processed/rendered as a monolithic block, since not only their size exceeds available working memory, but spatial adaptation is paramount for implementing fast renderers. Therefore, a data management system that divides the data into blocks is an important basis both to process and to visualize large datasets. Our method is based on the offline decomposition of the original volumetric dataset into small cubical bricks (subvolumes), i.e., third-order tensors, which are approximated, quantized and organized into an octree structure maintained out-of-core. The octree contains data bricks at different resolutions, where each resolution of the volume is represented as a collection of bricks in the subsequent octree hierarchy level. Each brick has a fixed width B with an overlap of two voxels at each brick boundary for efficiently supporting runtime operations requiring access to neighboring voxels (trilinear interpolation and gradient computation ). The width of the brick is flexible, but in this paper is set to B = (28 + 2 + 2) = 32, i.e., one brick is 32 3 , which has proved small enough to guarantee LOD adaptivity, while coarse enough to permit an effective brick encoding by the analysis of the local structure. Each octree brick A ∈ R 3 is tensor approximated using rankreduced Tucker decomposition. A Tucker decomposition (see Appendix A) is defined as </p><formula>A = B × 1 U (1) × 2 U (2) × 3 U (3) </formula><p>, where B is the so called core tensor and U (n) are the factor matrices. A rankreduced TA along every mode of the dataset is written with the notation: rank-(R 1 , R 2 , R 3 ) TA. As illustrated in <ref type="figure" coords="3,198.16,254.65,20.28,11.66" target="#fig_0">Fig. 1</ref>, we compute for each brick of size B 3 a rank-(R, R, R) TA, with R ∈ <ref type="bibr" coords="3,208.84,264.62,31.22,11.66">[1..B−1]</ref>. Typically, we use a rank reduction, where R = B/2, i.e., R = 16 for B = 32, following the rank reduction scheme used in other tensor approximation works <ref type="bibr" coords="3,56.55,294.51,14.19,11.66" target="#b26">[27,</ref><ref type="bibr" coords="3,73.97,294.51,10.65,11.66" target="#b22"> 23]</ref> . The resulting rank-reduced decomposition is quantized to further reduce memory usage (see Sec. 4) and stored in a out-of-core brick database. With each brick, we store a 64-bit binary histogram, which is used for transfer-function-based culling.  The whole preprocessing is performed in a low-memory setting using a bottom-up process on a brick-by-brick basis, which is repeated until we reach the octree root. Leafs are constructed by sampling the original dataset, while non-leaf bricks are constructed from their previously constructed eight children, which are dequantized, reconstructed , and spatially averaged. At run-time, an adaptive loader updates a view-and transfer function-dependent working set of bricks. The working set is incrementally maintained on the CPU and GPU memory by asynchronously fetching data from the out-of-core brick multiresolution TA structure. Following the MOVR approach <ref type="bibr" coords="3,145.72,623.94,14.18,11.66" target="#b11">[12,</ref><ref type="bibr" coords="3,161.77,623.94,10.65,11.66" target="#b13"> 14]</ref>, the working set is maintained by an adaptive refinement method guided by the visibility information fed back from the renderer. The adaptive loader maintains on GPU a cache of recently used volume bricks, stored in a 3D texture. At each frame, the loader constructs a spatial index for the current working set in the form of an octree with neighbor pointers. For rendering and visibility computation, the octree is traversed using a CUDA stack-less octree ray-caster, which employs preintegrated scalar transfer functions to associate optical properties to scalar values, and supports a variety of shading modes <ref type="bibr" coords="3,176.04,714.06,13.74,11.66" target="#b13">[14]</ref>. The ray-caster works on reconstructed bricks, and reconstruction steps occur only upon GPU cache misses. The quantized tensor decomposition is dequantized and reconstructed on demand by the adaptive loader during the visualization on the GPU (see Sec. 5). In order to permit structural exploration of the datasets, the reconstruction can consider only the K most significant ranks of the tensor decomposition, where K ∈ [1..R] is chosen by the user. The reconstruction rank K can be changed during the visualization process with a rank slider. Lower-rank reductions give a faster outline of the visualized dataset and can highlight structures at specific scales <ref type="bibr" coords="3,513.01,120.68,13.74,11.66" target="#b22">[23]</ref>, see also Sec.6. Higher K values add more details onto the dataset. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>... ... ... </head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">ENCODING OF COEFFICIENTS</head><p>As mentioned previously, the tensor and factor matrix coefficients take up unnecessary space if maintained as floating point values, see also storage cost analysis in Sec. 6.2. For compact representation of the tensor decomposition and to reduce the disk to host to device bandwidth during rendering, we apply a simple fixed bit length encoding based on tensor-specific quantization. In particular, the factor matrices and the core tensor of the Tucker model have a different distribution of coefficients and thus the quantization approach was selected accordingly, as described below. A fixed bit length approach has been selected in order to simplify parallel decoding on the GPU. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Factor Matrices and Core Tensor Coefficients</head><p>The coefficients of the basis factor matrices U (1...3) are normalized and distributed between <ref type="bibr" coords="3,384.97,291.61,23.55,11.66">[−1, 1]</ref>, due to the orthonormality of factor matrices in the Tucker model. Therefore, a uniform linear 8-or 16-bit quantization as in Eq. 1 can effectively be applied. We use a single min/max-pair to indicate the quantization range for all three factor matrices to minimize the number of coefficients that need to be loaded by the CUDA kernels. </p><formula>˜ x U = (2 Q U − 1) · x − x min x max − x min (1) </formula><p>As per definition of the Tucker model, the core tensor B captures the contribution of the linear bases combinations, i.e., the energy of the data, in its coefficients. The distribution of the signed coefficients is such that the first entry of the core tensor has an especially high absolute value close to the volume's norm, capturing most of the data energy, while many other entries concentrate around zero. The probability distribution of the other values between the two extrema is decreasing with their absolute magnitude in a logarithmic fashion. Hence we apply a logarithmic quantization scheme as in Eq. 2 for the core tensor coefficients, using a separate sign-bit. </p><formula>| ˜ x B | = (2 Q B − 1) · log 2 (1 + |x|) log 2 (1 + |x max |) (2) </formula><p> Special treatment is given to the one first high energy value mentioned before. It is known that this value, the hot-corner coefficient, is always at position B(0, 0, 0). Since it is one value and in order to give more space to the quantization range to the other coefficients, we optionally do not quantize this value and store it separately. Various quantization levels for the other coefficients, Q U and Q B , could be used and analyzed. In practice, we have chosen a bytealigned quantization of Q U,B = 8-or 16-bit as a compromise between the most effective quantization and efficient bit-processing. The effects of quantization as well as other tensor-specific optimizations are reported in Sec. 6.2 where we analyze the quantization error. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Storage Requirements</head><p>The basic storage needed for a volume dataset A of size of </p><formula>I 1 × I 2 × I 3 , is I 1 · I 2 · I 3 · Q</formula><p>, where Q is the number of bits (bytes) per scalar value. A rank-(R 1 , R 2 , R 3 ) tensor approximation, however, only </p><formula>quires R 1 · R 2 · R 3 · Q B + (I 1 · R 1 + I 2 · R 2 + I 3 · R 3 ) · Q U , </formula><p>in addition to three floating point numbers for the quantization ranges of the factor matrices (min/max values) and core tensor (max quantization value), and one floating point value for the hot-corner value. This first coefficient of the core tensor is (optionally) encoded separately from the remaining ones, leading to a reduced quantization range for Eq. 2. </p><p>The ratio of the achieved data reduction depends on the input size and rank reduction of the TA. In Sec. 6.2, we analyze the amount of storage needed for rank-reduced and quantized TA of complete data volumes as well as bricked multiresolution volumes. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">GPU TENSOR RECONSTRUCTION</head><p>For volume ray-casting one can consider either a per-voxel (e.g., for random access during traversal) or per-brick reconstruction approach. Using a per-brick solution permits us to optimize reconstruction by refactoring computations in order to reduce computational costs and to take advantage of the complex memory hierarchy of nowadays GPGPU platform. As outlined in the previous section, we perform a brick-wise reconstruction of the tensor from its decomposition according to the multiresolution octree hierarchy. If not already cached by the rendering system, a requested tensor brick is loaded and transferred to the GPU where the tensor reconstruction is performed. In the following we analyze the basic tensor reconstruction strategy and its implementation on the GPU using the CUDA framework. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">CUDA Terminology</head><p> A CUDA kernel is a SIMD parallel program that is executed by an array of threads (work-items), 1 all running the same code. The threads are organized in a grid of thread blocks, and each kernel is called with a given grid size (NDRange) and a given blocks size (work groups). Each thread owns some registers (private memory) and each thread block has access to a limited amount of shared memory (local memory ), which constitute the fastest data access paths. Additionally all threads can concurrently access global memory, constant memory and texture memory (global memory), where the memory latency increases from constant and texture memory (read only and cached), to local and global memory (read/write). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Reconstruction Strategy</head><p>First, we describe a simple but not optimized implementation to set out a starting approach for the reconstruction problem. Later, we introduce an optimized reconstruction based on the Tucker formulation implemented as so called tensor times matrix (TTM) multiplications. In both cases, the reconstruction on the GPU is parallelized such that the voxels of each brick are reconstructed in parallel, i.e., one thread of the GPU kernel computes one voxel. According to Eq. A.5 the simple reconstruction solution can be implemented with a single CUDA kernel that sums over all core tensor coefficients, each multiplied with the corresponding entries from the factor matrices. Despite the simplicity of this implementation drawbacks arise as a consequence. First, Eq. A.5 includes a triple-for-loop, which makes the computational cost per reconstructed voxel and thread of cubic order R 3 , where R is the number of reduced ranks. Second, to reconstruct a single voxel the complete core tensor B needs to be available in each thread, which is not memory efficient. The computational complexity can significantly be reduced by sequentially applying the core tensor and factor matrix multiplications using n-mode products as in Eq. A.6 and storing intermediate reconstruction results. This reconstruction corresponds to the initial formulation in Eq. A.3 and has been implemented as so called tensor times matrix (TTM) multiplications. With this three step TTM volume reconstruction, the computational complexity per reconstructed voxel grows only linearly with R. Hence, we have to call three different GPU TTM kernels successively and store the intermediate results in between kernel calls. The CUDA implementation of this approach is described in more detail below. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">CUDA TTM Reconstruction</head><p> The tensor reconstruction in CUDA is implemented using three successively applied TTM kernels. Each kernel corresponds to the application of one n-mode product (as in Eq. A.6), hence TTM1, TTM2, and TTM3. After applying TTM1 and then TTM2, we need each time 1 Analogous OpenCL terms are mentioned in parenthesis. to temporarily store a third-order tensor of size B × R 2 and B 2 × R, respectively . Eventually after applying TTM3 the final B 3 sized volume brick is reconstructed. The implementation of TTMn: Y = X × n U (n) is based on a matrix-matrix multiplication as illustrated in <ref type="figure" coords="4,457.87,91.85,26.14,11.66" target="#fig_0">Fig. 14</ref> . More precisely , the factor matrix U (n) is multiplied with each slice (matrix) of the third-order tensor X , sliced according to the mode n (e.g., lateral, frontal, or horizontal slices). Hence the full reconstruction </p><formula>A = B × 1 U (1) × 2 U (2) × 3 U (3</formula><p> ) corresponds to successive matrixmatrix multiplications, which can be optimized by following CUDA implementation best practices <ref type="bibr" coords="4,394.45,154.83,13.74,11.66" target="#b17">[18]</ref>. The pseudo code implementation of the three CUDA kernels is given in the Algs. 1–3. We use a thread block per decoded brick, where each thread is responsible for computing one element of the tensor-matrix multiplication. The grid-size for parallel execution is determined by the number of bricks that need to be decoded in the current frame (e.g., 8 bricks for the minimal octree refinement step). For TTM1, we compute one slice of the intermediate tensor B on one thread block. For one TTM1-block, we load the factor matrix U (1) and one slice of B (slice is given by blockId). For reasons of memory optimizations, we compute for TTM2 and TTM3 only half slice of B and half slice of A , respectively, on one thread block. For one TTM2/TTM3-block, we load half of the factor matrix and one slice of the intermediate data structures B and B . The memory usage and performance optimizations of the CUDA TTM reconstruction are explained next. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 1 CUDA kernel for TTM1 </head><p>1: load U (1) and tensor core B slices to GPU 2: CUDA kernel: 3: extract min/max values for dequantization 4: linearly dequantize one element of U (1) 5: log dequantize one element of B 6: each thread writes one element of U (1) to shared memory 7: each thread writes one element of the B slice to shared memory 8: synchthreads() 9: for each r1 in R1 do 10: voxel += U (1) (i1, r1) · B(r1, r2, r3) 11: end for 12: store voxel to the intermediate B (i1, r2, r3) </p><p>Algorithm 2 CUDA kernel for TTM2 1: load U (2) and half tensor B slices to GPU 2: CUDA kernel: 3: extract min/max values for dequantization 4: linearly dequantize one element of U (2) 5: each thread writes one element of U (2) to shared memory 6: each thread writes one element of the B slice to shared memory 7: synchthreads() 8: for each r2 in R2 do 9: voxel += U (2) (i2, r2) · B (i1, r2, r3) 10: end for 11: store voxel to the intermediate B (i1, i2, r3) </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Performance Optimizations</head><p>In order to optimize the parallel execution on the GPU, we should exploit data parallelism, optimize memory usage, take into account the bandwidths to the various parts of the memory hierarchy, and optimize instruction usage, thus increasing throughput. In our approach, host-to-device data transfers are reduced by using page-locked buffers. That is, before launching the kernel TTM1, we transfer the factor matrices and the core tensor of one brick all at once and in a quantized form to the global GPU memory. Our GPU TTM reconstruction code (TTM kernels) uses intermediate data structures (B and B ), which allows us to make use of the on-chip memory. The temporary data structures of the third-order tensors are stored in the global memory, and slices of these third-order tensors are loaded to the shared memory when requested. Threads within the same thread block cooperate to load into shared memory the necessary elements of </p><formula>U (1) , U (2) ,U (3) , B</formula><p> , B and B , by loading one single element per tensor per thread. A syncthreads() barrier at the end of the loading phase ensures that all the elements are up-to-date before performing calculations . In order to avoid bank conflicts in shared memory accesses, we dequantize the factor matrices and core tensor to 32-bit floating point words before we upload the data to shared memory. Thus, all accesses are aligned on 32-bit words. For TTM2 and TTM3, we split the matrix-matrix multiplication of one slice into two blocks. In that way, we optimize the shared memory usage and load only half of a factor matrix together with the full core tensor (we thus compute only upper or lower half of a matrix with the other matrix). With this scenario, we need for TTM1 (B·R·4+R·R·4) bytes and for TTM2/TTM3 (B/2 · R · 4 + B · R · 4) bytes of shared memory per block, which works with 32-cubed bricks for CUDA 1.x and 2.x. We have a maximum of 16 KB (CUDA 1.x) or 48 KB (CUDA 2.x) of shared memory available per multiprocessor, whereas one multiprocessor can have at maximum 8 blocks. Depending on how much shared memory is used, fewer or more blocks are loaded per multiprocessor . To summarize, in our implementation, increasing the use of shared memory has higher priority than maximizing the number of blocks run per processor (for CUDA 1.x). In addition, TTM3 separately handles the contribution of the hotcorner coefficient, adding its contribution to the overall reconstruction directly from the unquantized value of B(0, 0, 0). In order to simplify decoding and avoid special case handling in the inner loop, we encode a zero quantized coefficient at the corresponding core tensor position. The final reconstruction A , is stored into an intermediate decoding buffer in device linear memory. We perform for each decoded brick a device-to-device copy in order to place the decoded brick in the correct place in the GPU cache, which is maintained as a texture bound to a CUDA array in order to maximize texture memory cache coherence. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">EXPERIMENTAL RESULTS</head><p> We have implemented a library supporting the multiscale volume tensor reconstruction and its integration with a GPU-accelerated outof-core multiresolution volume rendering framework using C++ and CUDA 3.2. All performance tests have been carried out on an Intel Core 2 E8500 3.2GHz Linux PC with 4GB RAM, and GeForce GTX 480 graphics with 1.5GB of memory. The multiresolution volume octree is stored in an out-of-core structure, based on the Berkeley DB, with each 32 3 brick being stored as a quantized rank-(16, 16, 16) tensor decomposition. We discuss the performance results obtained based on the large scale micro-CT veiled chameleon and great ape molar (tooth) datasets. The chameleon (1024 2 × 1080, 16-bit) is a micro-CT scan of the upper body, where each slice is 0.105mm thick with an inter-slice spacing of 0.105mm and a field of reconstruction of 94.5mm. The tooth (2048 3 , 16-bit) is a 7mm 3 block cut out of dental enamel, scanned by phase-contrast synchrotron tomography at high resolution to reveal growth patterns of the dental enamel. Additionally, we use three smaller datasets (256 2 × 128) for the quantization error analysis. Preprocessing consisted in the construction and storage of the multiresolution volume octree, including the computation of the tensor decomposition for all bricks and the quantization of the coefficients. The preprocessing time for the 2GB chameleon dataset was 25min15sec and produced a 231M file. In the case of the 17GB tooth dataset the preprocessing time was 8h45min and the resulting file was of 5.5GB. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Interactive Performance</head><p>We evaluated the rendering and tensor reconstruction performance on the two large volumes (Figs. 2 and 3). The qualitative performance and interactivity of our adaptive GPU ray-caster is demonstrated in an accompanying video, recorded using a window size of 1024 × 768 pixels using a 1 voxel/pixel LOD rendering accuracy threshold. Our interactive inspection sequences include overall views and extreme close-ups, which stress our adaptive loader by incrementally requesting and reconstructing a large number of bricks. Figs. 4 and 5 demonstrate the achieved performance. As we can see, in any case an interactive rendering performance can be maintained, with frame-rates higher than 12Hz even for the most demanding situations , and on average between 50Hz and 100Hz. In particular, the timing reveals that our tensor reconstruction constitutes only a negligible overhead with respect to the overall rendering cost. Rendering time is in fact dominated by the ray-casting and data transfer times. The most costly part of the (fast) tensor reconstruction process is the final copy of the decoded bricks to texture cache. The number of rendered bricks per frame varies depending on the zoom factor, and is always maintained below 7000 by our adaptive renderer. Brick dequantization and reconstruction occurs only upon cache misses, which attributes to the low tensor reconstruction cost. But even under the most stressful situations where the number of rendered bricks changes rapidly, the dynamic update process is largely dominated by the brick data uploading time from CPU to GPU and not by the tensor reconstruction. Given the high tensor reconstruction performance, we see as an interesting avenue for future work the possibility to further reduce device memory occupation by removing the uncompressed brick cache and decoding bricks on-demand at each frame. This would allow to display even larger amounts of volume data in each rendered image. </p><formula>!" #!" $!" %!" &amp;!" '!" (!" #" $'#" '!#" )'#" #!!#" #$'#" #'!#" #)'#" $!!#" $$'#" $'!#" $)'#" %!!#" %$'#" *+," ,+-./0"1*+,</formula><formula>!" #!!!" $!!!" %!!!" &amp;!!!" '!!!" (!!!" #" $'#" '!#" )'#" #!!#" #$'#" #'!#" #)'#" $!!#" $$'#" $'!#" $)'#" %!!#" %$'#" *+,-*+*"./0,12" /+3*+/+*"</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Data Reduction</head><p>The quantization of the tensor coefficients helps to keep the critical CPU-to-GPU data transfer and disk storage low. In this section, we analyze the error due to quantization and how the storage size is thus affected. We considered quantization approaches that use the same bit-length (from 8-bit to 16-bit) for all values within a coefficient type, the factor matrices U (n) and the core tensor B. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.1">Storage Cost</head><p>The storage cost for different quantization approaches is indicated in <ref type="figure" coords="6,22.50,629.69,19.91,11.66">Fig. 6</ref>, where U and B indicate factor matrices or core tensor settings, respectively, and klin/log indicates linear or logarithmic quantization to Q U,B = k bits according to Eqs. 1 and 2. The left-most value A:16 represents the size of a 2048 3 16-bit input volume dataset A , and U:32 B:32 a 32-bit floating point representation of the reference rank-(1024, 1024, 1024) reduced tensor approximation of A . The data reduction follows the storage requirements outlined in Sec. 4.2. We can see in <ref type="figure" coords="6,88.32,704.09,22.00,11.66">Fig. 6</ref>that the proposed quantization (U:8 B:8 to U:16 B:16) has a additional storage reduction effect, compared to the floating point tensor (U:32 B:32) and original volume (A:16) data representation. Furthermore, for the quantized 32 3 -bricked  olution octree hierarchy the storage consumption is minimally different from the non-bricked quantized format. Only the non-quantized bricked floating-point representation has an adverse space cost behavior due to its many coefficients that have to be stored. The approximation quality of the different quantization levels is analyzed below. From the storage cost results we can conclude that it is preferable to spend 16-bits on the factor matrix entries rather than on the core tensor , as the factor matrices U (n) , being quadratic, affect the total storage marginally compared to the core tensor B, being cubic (see Sec. 4.2). </p><formula>!" #!" $!" %!" &amp;!" '!" (!" )!" *!" +!" #!!" #" '!#" #!!#" #'!#" $!!#" $'!#" %!!#" %'!#" &amp;!!#" ,-." </formula><formula>!" #!!!" $!!!" %!!!" &amp;!!!" '!!!" (!!!" )!!!" #" '!#" #!!#" #'!#" $!!#" $'!#" %!!#" %'!#" &amp;!!#" *+,-*+*"</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.2">Quantization Error</head><p> To evaluate the approximation quality of a rank-reduced and quantized tensor decomposition we use the signal-to-noise ratio (SNR) to express the error in relation to the data's signal strength. We define the signal strength of a volume A as the averaged Frobenius </p><formula>norm A ¯ F = 1 N ∑ a 2 i 1 ,i 2 ,i 3 </formula><p>, and the approximation and quantization noise of the reconstructed volume A as the root-mean-squared error </p><formula>(RMSE) ε A = 1 N ∑(ai 1 ,i 2 ,i 3 − ˜ a i 1 ,i 2 ,i 3 ) 2 . </formula><p>Hence the SNR is defined </p><formula>as σ A = 20 · log 10 A ¯ F ε A . </formula><p>As base reference to evaluate quantization effects, we compare to the error which was introduced by a reduced </p><formula> (R 1 , R 2 , R 3 ) tensor approximation A of the original volume A ∈ R I 1 ×I 2 ×I 3 , where R k = I k 2 (following </formula><p>the rank scheme used in <ref type="bibr" coords="6,443.07,629.44,14.19,11.66" target="#b26">[27,</ref><ref type="bibr" coords="6,459.51,629.44,10.31,11.66" target="#b22"> 23]</ref>). Due to limits in processing time, the costly approximation error analysis was not performed on the full size 2048 3 tooth volume, but on a representative 256 2 × 128 subvolume, and put in comparison to the approximation quality achieved for the well known bonsai tree and engine datasets of the same resolution. The triple-bars in Tucker TA-specific Quantization: We analyzed the quantization approaches outlined in Sec. 4.1, applying linear and logarithmic tization to both the factor matrices and core tensor as well. The effects on approximation error were analyzed for entire as well as bricked volume Tucker decompositions. <ref type="figure" coords="7,151.70,445.40,21.48,11.66" target="#fig_8">Fig. 7</ref> shows the analysis of the approximation quality in terms of the SNR σ A for different linear and logarithmic quantizations. Except for the 8-bit linear core quantization (B:8lin), it is clear from <ref type="figure" coords="7,31.50,486.90,21.42,11.66" target="#fig_8">Fig. 7</ref>that for the factor matrices a significant improvement in SNR, and hence lower approximation error, can be achieved when using 16- bit (U:16) instead of 8-bit (U:8) quantization. Though the bonsai tree dataset does not benefit as strongly from this as the other volumes. With respect to the core tensor quantization, it can be seen that the logarithmic is superior to the linear quantization, reaching comparable SNR values using much fewer bits, i.e. B:8log achieving almost the same quality as B:16lin for the same factor matrices quantization. It can be seen that increasing the quantization resolution from 8 to 12-bit only minimally improves the SNR, with the latter (B:12log) basically matching the more costly linear quantization. We evaluated the separate floating point representation of the hotcorner core tensor coefficient (B:8log+ in <ref type="figure" coords="7,190.59,607.43,20.87,11.66" target="#fig_8">Fig. 7</ref>), which otherwise potentially wastes quantization resolution better spent on the remaining core tensor coefficients. The SNR can so be increased slightly at the expense of only 4 extra bytes. Taking the results from the storage cost study into account, the optimally compact quantization can be achieved using 16-bit linear factor matrix and 8-bit logarithmic core tensor quantization with separate hot-corner (U:16 B:8log+). Bricked TA Quantization: In a bricked multiresolution octree setting the quantization quality differs only so slightly as shown in <ref type="figure" coords="7,31.50,714.06,20.84,11.66" target="#fig_8">Fig. 7</ref>(U:.. B:..-bricked), sometimes even being better. This could be explained by the fact that the bricked representation uses more coefficients in total over all bricks for the same volume dataset, consuming a little bit more space (<ref type="figure" coords="7,381.29,50.94,20.08,11.66">Fig. 6</ref>). The preferable optimal quantization setting is thus the same as above also for the bricked TA. Additionally, for the structural tooth dataset we performed a quantization error analysis on a larger 1024 3 -cubed volume. The reference SNR of 37.16 for U:32 B:32 compares well with the SNR of 37.09 for U:16 B:8log-bricked, which matches well with the SNR study for the smaller tooth subvolume in <ref type="figure" coords="7,405.85,110.72,19.55,11.66" target="#fig_8">Fig. 7</ref>. The SNR over individual bricks varies from 35.11 to 40.94 with an average of 37.16. Note that the U:16 B:8log-bricked representation differs from the original 16-bit input volume only by a very low (normalized) RMSE of 0.007. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Visual Results</head><p> In order to give insight into the capability of multiscale tensor approximation for DVR, we show visual results from the veiled chameleon and the great ape molar. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Approximative Visualization: </head><p>The veiled chameleon dataset as shown in <ref type="figure" coords="7,328.87,214.27,20.97,11.66" target="#fig_9">Fig. 8</ref> is visualized with the out-of-core multiresolution volume renderer based on tensor reconstructed bricks. It can be seen that even with a lower rank tensor approximation, i.e., by using less storage and bandwidth, the essential parts as well as details of a certain feature size can be visualized. Small scale features are effectively removed from the visible bone structures, in a different way than by reducing the rendering LOD which typically results in a more blurred volume close up. <ref type="figure" coords="7,328.26,284.00,20.53,11.66">Fig. 9</ref>shows the effects of rank reduction on gradient quality. As we can see, block boundaries become apparent only at low ranks. Such artifacts are inherent to all brick-based lossy compression methods , and can be alleviated, at the cost of higher rendering time, by interblock interpolation through sampling neighboring bricks <ref type="bibr" coords="7,519.91,323.85,14.19,11.66" target="#b15">[16,</ref><ref type="bibr" coords="7,537.03,323.85,7.47,11.66" target="#b2"> 3] </ref>or by using deferred filtering approaches <ref type="bibr" coords="7,443.93,333.82,14.19,11.66" target="#b9">[10,</ref><ref type="bibr" coords="7,460.69,333.82,10.65,11.66" target="#b10"> 11]</ref>. This is orthogonal to the presented research. <ref type="bibr" coords="7,400.42,498.63,10.30,7.37" target="#b15">16,</ref><ref type="bibr" coords="7,411.61,496.73,10.18,10.36" target="#b15"> 16,</ref><ref type="bibr" coords="7,422.67,496.73,7.08,10.36" target="#b15"> 16</ref>) and a rank-(8, 8, 8) TA. <ref type="figure" coords="7,294.12,614.52,18.94,7.37">Fig. 9</ref> . Comparison of various rank-(R, R, R) TAs using the gradient vector of the skin isosurface mapped to RGB color. Structural Features: As an application, we look at dental internal structures of a great ape molar. The relevant growth structures are found in the tooth enamel, which has a microstructure that is roughly comparable to densely packed fibers (so called prims). During dental enamel formation, each enamel prism elongates in centrifugal direction through the daily apposition of a small segment of enamel. In other words, the prisms grow along all three spatial dimensions and are in particular not axis-aligned, but of curved shape. Examples of such enamel growth patterns can be found in Suter et al. <ref type="bibr" coords="7,493.17,714.06,14.94,11.66" target="#b22">[23] </ref>and in the accompanying video. Those prisms represent important growth structures , but are difficult to visualize since the scanned high-resolution dataset includes spatial information of growth patterns that are of multiple scales (daily appositions form prisms). In our experiments, we observed the effect of different rank-reduced and tensor-approximated dental growth structures in the great ape molar . We noticed that by using lower-rank TA, dental structures like growth prisms become highlighted as illustrated in an example closeup in <ref type="figure" coords="8,44.99,110.80,24.95,11.66" target="#fig_0">Fig. 10</ref>. In <ref type="figure" coords="8,90.28,110.80,26.44,11.66" target="#fig_0">Fig. 11</ref>a horizontal cut orthogonal to the growth prisms (yellow dots) is shown. The image of the base reference at a rank-(16, 16, 16) TA shows the prisms irregular spatial distribution, which makes the identification of individual prisms more difficult. The lower-scale rank-(8, 8, 8) reconstruction clears out the fuzziness and reveals the layered periodic and parallel arrangement of the prisms. From these experiments, we conclude that the effect of rank-reduced TA supports counting or analyzing layer formations. <ref type="figure" coords="8,38.59,540.35,7.39,7.37" target="#fig_0">11</ref>. Dental growth structures (prisms), highlighted with a reduced rank-(8, 8, 8) reconstruction. Taken from a horizontal cut through an area below the enamel surface (see <ref type="figure" coords="8,132.89,559.28,18.60,7.37" target="#fig_1">Fig. 2</ref>). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Even </head><p> if more experimentation is required on a large variety of realworld datasets, our initial results seem to indicate that TA is able to preserve important features using coarse ranks. We see tensorreconstructed volumes as an alternative to potentially help researchers to visualize and explore particular features at different scales by playing with tensor approximations of different ranks. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">CONCLUSION</head><p> We have presented the first integration of a multiscale volume representation based on tensor approximation within a GPU-accelerated out-of-core multiresolution rendering framework. Our multiscale representation allows for the extraction, analysis and display of structural features at variable spatial scales, while adaptive level-of-detail rendering methods make it possible to interactively explore large datasets within a constrained memory footprint, allowing analysts to visually examine and understand datasets of overwhelming size and complexity . We have shown that tensor approximation offers good compression , and, by reducing the reconstruction rank, permits the highlighting of structural features. Thus, TA is a powerful approach to represent microstructural volume datasets at high data reduction ratios, and simultaneously highlighting relevant features at different spatial scales but high display resolution. Our system allows this exploration to occur for massive volumes and in real time. Our future work will concentrate on further improving the performance and capabilities of our system by removing the need for an uncompressed brick cache, further reducing GPU memory needs. Moreover , we plan to improve our representation by using a per-brick adaption of the approximation rank, non-uniform quantization of coefficients , as well as thresholding of insignificant core tensor coefficients (sparse tensors) to further reduce memory needs. However, we would need to evaluate such a scenario with respect to the decoding and reconstruction times on the GPU. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>APPENDIX A TENSOR APPROXIMATION (TA) </head><p>In tensor approximation (TA) approaches, an multi-dimensional input dataset in array form, i.e., a tensor, is factorized into a sum of rank-one tensors or into a product of a core tensor and matrices, i.e., one for each dimension. This factorization process is generally known as tensor decomposition, while the reverse process of the decomposition is the tensor reconstruction. In the following sections, we give an overview of these two processes. In order to obtain a data reduction, which is an approximation of the input data, an additional process has to be introduced: the tensor rank-reduction. The concepts presented in the following subsections hold for general higher-order tensors. However, we restrict ourselves to third-order tensor as this is more intuitive and this represents the datasets used in Direct Volume Rendering (DVR). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.1 Tensor Decomposition </head><p>Let A be a third-order tensor in R I 1 ×I 2 ×I 3 with elements a i i i 2 i 3 . The Tucker model is a common approach for tensor decompositions. There the third-order tensor is approximated by a product of a core tensor B and three factor matrices U (n) </p><formula>A = B × 1 U (1) × 2 U (2) × 3 U (3) , (A.3) </formula><p>where the products × n denote the n-mode product between the tensor and the matrices (see <ref type="bibr" coords="8,363.91,438.78,14.94,11.66" target="#b14">[15] </ref>and <ref type="figure" coords="8,396.83,438.78,21.30,11.66" target="#fig_0">Fig.12</ref>). The Tucker decomposition of a tensor, which is a higher-order form of a matrix SVD or a PCA (extension of matrix rank concept), can be obtained from an higher-order SVD (HOSVD) algorithm (computed by a matrix SVD along every data mode). Other successful factorization methods are TUCKALS3 (an ALS approach for Tucker decompositions in three dimensions) and its generalized version, the higher-order orthogonal iteration (HOOI) (details see <ref type="bibr" coords="8,327.45,508.52,13.44,11.66" target="#b14">[15]</ref>). After a HOSVD the core tensor B has the same size as the original input dataset A and all the factor matrices are quadratic. However, we are more interested in light-weight, approximative Tucker decompositions , where B is element of R </p><formula>U (3) U (1) U (2) I 1 I 2 I 1 I 2 I 3 I 3 R 1 R 2 R 3 R 1 R 2 R 3 B ï¿¿ A </formula><formula>R 1 ×R 2 ×R 3 with R 1 &lt; I 1 , R 2 &lt; I 2 and R 3 &lt; I 3 . </formula><p> Using the HOOI algorithm one can directly obtain a reducedrank Tucker decomposition, whereas the rank reduction. Alternatively one can truncate the result obtained from HOSVD which is according to Bader and Kolda <ref type="bibr" coords="8,360.16,673.85,14.94,11.66" target="#b14">[15] </ref>not optimal in terms of difference between approximated and original data. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2 Tensor Reconstruction </head><p>The tensor reconstruction of a reduced-rank Tucker decomposition can be achieved in different ways. One alternative, is a progressive reconstruction: Each entry in the core tensor B is considered as weight for the outer product between the corresponding column vectors in the factor matrices </p><formula>A = ∑ r 1 ∑ r 2 ∑ r 3 b r 1 r 2 r 3 · u (1) </formula><formula>r 1 · u (2) </formula><formula>r 2 · u (3) r 3 . (A.4) </formula><p> The sum of all theses weighted " subtensors " forms the approxima- tion A of the original data A (see <ref type="figure" coords="9,157.57,117.32,23.54,11.66" target="#fig_0">Fig. 13</ref>). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>+ ... = ... + </head><formula>I 3 I 2 I 1 b r 1 r 2 r 3 u (1) r1 u (2) r2 u </formula><p>(3) r3 ï¿¿ A  Another approach, is to reconstruct each element of the approximated dataset individually, which we call voxel-wise reconstruction approach. Each element a i1i2i3 is reconstructed as shown in Eq. A.5, i.e., sum up all core coefficients multiplied with the corresponding coefficients in the factor matrices (weighted product). </p><formula>a i 1 i 2 i 3 = ∑ r 1 ∑ r 2 ∑ r 3 b r 1 r 2 r 3 · u (1) i 1 r 1 · u (2) i 2 r 2 · u (3) i 3 r 3 (A.5) </formula><p>A third reconstruction approach is to build the n-mode products along every mode <ref type="bibr" coords="9,100.12,328.42,14.94,11.66" target="#b14">[15] </ref> (notation: B × n U (n) ), which leads to a tensor times matrix (TTM) multiplication for each mode, i.e., dimension. This is analogous to the Tucker model given by Eq. A.3. The n-mode product between a tensor and a matrix is equivalent to a matrix product as it can be seen from Eq. A.6. In <ref type="figure" coords="9,172.93,368.27,25.88,11.66" target="#fig_0">Fig. 14</ref>we visualize the TTM approach using n-mode products. </p><formula>Y = X × n U ⇔ Y (n) = UX (n) , (A.6) </formula><p>where X (n) represents the mode-n unfolded tensor, i.e., a matrix. </p><formula>I 1 U (1) R 1 R 3 R 2 × 1 B B ï¿¿ R 3 I 1 R 1 (a) TTM 1 I2 R2 U (2) I1 R2 R3×2 B ï¿¿ B ï¿¿ï¿¿ I2 I1 (b) TTM 2 I 3 R 3 U (3) I 2 R 3 I 1 × 3 B ï¿¿ï¿¿ ï¿¿ A I 2 I 3 </formula><p>(c) TTM 3  Given the fixed cost of generating an I 1 × I 2 × I 3 grid, the computational overhead factor varies from cubic rank complexity R 1 · R 2 · R 3 in the case of the progressive reconstruction (Eq. A.4) to a linear rank complexity R 1 for the TTM or the n-mode product reconstruction (Eq. A.5). (For R = 16, the improvement to R 3 = 4 096 is 256-fold</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>.) </head><p>ACKNOWLEDGMENTS This work was supported in part by a grant from the Forschungskredit of the University of Zurich, Switzerland, and by internal research funds at CRS4, Italy. The authors wish to thank Paul Tafforeau for the help of acquiring the tooth dataset, which was scanned at the SLS in Switzerland (experiment number: 20080205). </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="3,31.50,496.17,249.88,11.36;3,31.50,508.53,43.56,7.37"><head>Fig. 1. </head><figDesc>Fig. 1. Multiresolution octree tensor decomposition hierarchy with B 3 sized bricks. </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="5,294.12,414.21,250.38,11.36;5,294.12,426.57,141.80,7.37"><head>Fig. 2. </head><figDesc>Fig. 2. Great ape molar (tooth), 7mm 3 sampled at 2048 3 , scanned with phase-contrast synchrotron tomography. </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="5,294.12,641.72,155.69,7.37"><head>Fig. 3. </head><figDesc>Fig. 3. Full reconstruction of the chameleon. </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4" coords="6,22.50,359.58,175.51,7.37"><head>Fig. 4. </head><figDesc>Fig. 4. Performance measured on the chameleon. </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6" coords="6,285.12,359.60,217.51,7.37"><head>Fig. 5. </head><figDesc>Fig. 5. Performance measured on the great ape molar (tooth). </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7" coords="6,423.45,679.25,112.05,11.66;6,285.12,689.22,250.38,11.66;6,285.12,699.18,250.38,11.66;6,285.12,709.14,189.35,11.66"><head></head><figDesc> Fig. 7 are organized in the indicated dataset order and bright-dark-medium-luminance color coded. The reference floating-point tensor decomposition (U:32 B:32) is shown to isolate and evaluate the quantization effect. </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8" coords="7,31.50,372.06,250.38,7.37;7,31.50,381.53,250.38,7.37;7,31.50,390.99,250.38,7.37;7,31.50,400.46,250.38,7.37;7,31.50,409.92,152.28,7.37"><head>Fig. 7. </head><figDesc>Fig. 7. Quantization error as SNR for various quantization approaches. The triple-bars are organized in the indicated dataset order and brightdark-medium-luminance color coded. U stands for the factor matrices, B for the core tensor. The number after B and U gives the number of bits used for the respective coefficient type. </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9" coords="7,294.12,496.73,218.73,10.36"><head>Fig. 8. </head><figDesc>Fig. 8. Comparison of a rank-(16, 16, 16) and a rank-(8, 8, 8) TA. </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10" coords="8,22.50,331.23,250.38,7.37;8,22.50,338.80,250.38,10.36;8,22.50,350.16,135.19,7.37"><head>Fig. 10. </head><figDesc>Fig. 10. Dental growth structures (prisms), highlighted with a reduced rank-(4, 4, 4) reconstruction. Taken from a frontal projection to an area below the enamel surface (see Fig. 2). </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11" coords="8,22.50,540.35,250.38,7.37;8,22.50,547.92,250.38,10.36;8,22.50,559.28,135.19,7.37"><head>Fig. </head><figDesc>Fig. 11. Dental growth structures (prisms), highlighted with a reduced rank-(8, 8, 8) reconstruction. Taken from a horizontal cut through an area below the enamel surface (see Fig. 2). </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12" coords="8,285.12,590.95,106.77,7.37"><head>Fig. 12. </head><figDesc>Fig. 12. Tensor decomposition </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13" coords="9,31.50,218.35,191.37,7.37"><head>Fig. 13. </head><figDesc>Fig. 13. Tensor reconstruction from Eq. A.4 visualized. </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14" coords="9,31.50,537.70,250.38,7.37;9,31.50,547.16,199.09,7.37"><head>Fig. 14. </head><figDesc>Fig. 14. TTM: tensor times matrix along the 3 modes (n-mode products). Backward cyclic reconstruction after Lathauwer et al. [6]. </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false" coords="4,285.12,610.31,223.38,129.00"><figDesc coords="4,285.12,610.31,136.76,11.66;4,288.48,623.84,148.30,11.36;4,288.48,634.31,56.49,10.36;4,288.48,643.77,144.45,10.36;4,288.48,652.23,135.79,11.36;4,288.48,661.70,192.94,11.36;4,288.48,672.16,220.01,10.36;4,288.48,681.63,62.85,10.36;4,288.48,691.09,75.29,10.36;4,288.48,699.56,136.76,11.36;4,285.12,710.02,38.54,10.36;4,285.12,719.49,172.09,10.36;4,285.12,728.95,161.89,10.36">Algorithm 3 CUDA kernel for TTM3 1: load U (3) and half tensor B slices to GPU 2: CUDA kernel: 3: extract min/max values for dequantization 4: linearly dequantize one element of U (3) 5: each thread writes one element of U (3) to shared memory 6: each thread writes one element of the B slice to shared memory 7: synchthreads() 8: for each r3 in R3 do 9: voxel += U (3) (i3, r3) · B (i1, i2, r3) 10: end for 11: add contribution of hot-corner core value to voxel 12: store voxel in decoding buffer for A (i1, i2, i3)</figDesc><table></table></figure>
		</body>
		<back>
			<div type="annex">
			</div>
			<div type="references">

				<listBibl>

<biblStruct coords="9,49.76,706.54,203.86,10.36"  xml:id="b0">
	<monogr>
		<title level="m" type="main">vmmlib: A vector and matrix math library</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="9,49.76,716.00,232.12,10.36;9,49.76,725.46,232.12,10.36;9,49.76,734.93,88.92,10.36"  xml:id="b1">
	<analytic>
		<title level="a" type="main">Algorithm 862: Matlab tensor classes for fast algorithm prototyping</title>
		<author>
			<persName>
				<forename type="first">B</forename>
				<forename type="middle">W</forename>
				<surname>Bader</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">T</forename>
				<forename type="middle">G</forename>
				<surname>Kolda</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Mathematical Software</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="635" to="653" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,312.38,51.89,232.12,10.36;9,312.38,61.36,232.12,10.36;9,312.38,70.82,144.24,10.36"  xml:id="b2">
	<analytic>
		<title level="a" type="main">Smooth mixed-resolution GPU volume rendering</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Beyer</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Hadwiger</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Möller</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">L</forename>
				<surname>Fritz</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE/EG Symposium on Volume and Point-Based Graphics</title>
		<meeting>. IEEE/EG Symposium on Volume and Point-Based Graphics</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="163" to="170" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,312.38,80.28,232.12,10.36;9,312.38,89.75,232.12,10.36;9,312.38,99.21,166.93,10.36"  xml:id="b3">
	<analytic>
		<title level="a" type="main">Integrated volume compression and visualization</title>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Yang</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">H</forename>
				<surname>He</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">A</forename>
				<forename type="middle">E</forename>
				<surname>Pfister</surname>
			</persName>
		</author>
		<author>
			<persName>
				<surname>Kaufman</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Visualization</title>
		<meeting>. IEEE Visualization</meeting>
		<imprint>
			<publisher>Computer Society Press</publisher>
			<date type="published" when="1997" />
			<biblScope unit="page" from="329" to="336" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,312.38,108.68,232.12,10.36;9,312.38,118.14,232.12,10.36;9,312.38,127.61,232.12,10.36;9,312.38,137.07,48.93,10.36"  xml:id="b4">
	<analytic>
		<title level="a" type="main">GigaVoxels: Rayguided streaming for efficient and detailed voxel rendering</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Crassin</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">F</forename>
				<surname>Neyret</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Lefebvre</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">E</forename>
				<surname>Eisemann</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Symposium on Interactive 3D Graphics and Games</title>
		<meeting>. Symposium on Interactive 3D Graphics and Games</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="15" to="22" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,312.38,146.54,232.12,10.36;9,312.38,156.00,232.12,10.36;9,312.38,165.47,77.26,10.36"  xml:id="b5">
	<analytic>
		<title level="a" type="main">A multilinear singular value decomposition</title>
		<author>
			<persName>
				<forename type="first">L</forename>
				<surname>De Lathauwer</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">B</forename>
				<surname>De Moor</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Vandewalle</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM Journal of Matrix Analysis and Applications</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1253" to="1278" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,312.38,174.93,232.12,10.36;9,312.38,184.39,211.47,10.36"  xml:id="b6">
	<analytic>
		<title level="a" type="main">Pyramidal directional filter banks and curvelets</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Do</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Vetterli</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Image Processing</title>
		<meeting>. IEEE Image essing</meeting>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="page" from="158" to="161" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,312.38,193.86,232.12,10.36;9,312.38,203.32,232.12,10.36;9,312.38,212.79,81.25,10.36"  xml:id="b7">
	<analytic>
		<title level="a" type="main">The contourlet transform: an efficient directional multiresolution image representation</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Do</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Vetterli</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Im. Proc</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2091" to="2106" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,312.38,222.25,232.12,10.36;9,312.38,231.72,149.52,10.36"  xml:id="b8">
	<monogr>
		<title level="m" type="main">Real-Time Volume Graphics</title>
		<author>
			<persName>
				<forename type="first">K</forename>
				<surname>Engel</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Hadwiger</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">M</forename>
				<surname>Kniss</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Rezk-Salama</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Weiskopf</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2006" />
			<publisher>AK Peters</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,312.38,241.18,232.12,10.36;9,312.38,250.65,232.12,10.36;9,312.38,260.11,75.05,10.36"  xml:id="b9">
	<analytic>
		<title level="a" type="main">High quality rendering of compressed volume data formats</title>
		<author>
			<persName>
				<forename type="first">N</forename>
				<surname>Fout</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">H</forename>
				<surname>Akiba</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">K.-L</forename>
				<surname>Ma</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Lefohn</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Kniss</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings Eurographics</title>
		<meeting>Eurographics</meeting>
		<imprint>
			<date type="published" when="2005-06" />
			<biblScope unit="page" from="77" to="84" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,312.38,269.57,232.12,10.36;9,312.38,279.04,232.12,10.36;9,312.38,288.50,90.10,10.36"  xml:id="b10">
	<analytic>
		<title level="a" type="main">Transform coding for hardware-accelerated volume rendering</title>
		<author>
			<persName>
				<forename type="first">N</forename>
				<surname>Fout</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">K.-L</forename>
				<surname>Ma</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transaction on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1600" to="1607" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,312.38,297.97,232.12,10.36;9,312.38,307.43,232.12,10.36;9,312.38,316.90,211.26,10.36"  xml:id="b11">
	<monogr>
		<title level="m" type="main">Guitì an. A single-pass GPU ray casting framework for interactive out-of-core rendering of massive volumetric datasets. The Visual Computer</title>
		<author>
			<persName>
				<forename type="first">E</forename>
				<surname>Gobbetti</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">F</forename>
				<surname>Marton</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">A</forename>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2008-07" />
			<biblScope unit="page" from="7" to="9797" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,312.38,326.36,232.12,10.36;9,312.38,335.83,230.07,10.36"  xml:id="b12">
	<analytic>
		<title level="a" type="main">Interactive rendering of large volume data sets</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Guthe</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Wand</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Gonser</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">W</forename>
				<surname>Strasser</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Visualization</title>
		<meeting>. IEEE Visualization</meeting>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="53" to="60" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,312.38,345.29,232.12,10.36;9,312.38,354.76,232.12,10.36;9,312.38,364.22,156.82,10.36"  xml:id="b13">
	<monogr>
		<title level="m" type="main">View-dependent exploration of massive volumetric models on large scale light field displays. The Visual Computer</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">A</forename>
				<surname>Iglesias Guitián</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">E</forename>
				<surname>Gobbetti</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">F</forename>
				<surname>Marton</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="6" to="81037" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,312.38,373.68,232.12,10.36;9,312.38,383.15,127.94,10.36"  xml:id="b14">
	<analytic>
		<title level="a" type="main">Tensor decompositions and applications</title>
		<author>
			<persName>
				<forename type="first">T</forename>
				<forename type="middle">G</forename>
				<surname>Kolda</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">B</forename>
				<forename type="middle">W</forename>
				<surname>Bader</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Siam Review</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="455" to="500" />
			<date type="published" when="2009-09" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,312.38,392.61,232.12,10.36;9,312.38,402.08,232.12,10.36;9,312.38,411.54,186.05,10.36"  xml:id="b15">
	<analytic>
		<title level="a" type="main">Multiresolution interblock interpolation in direct volume rendering</title>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Ljung</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Lundstrom</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Ynnerman</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Eurographics/IEEE TCVG Symposium on Visualization</title>
		<meeting>. Eurographics/IEEE TCVG Symposium on Visualization</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="259" to="266" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,312.38,421.01,232.12,10.36;9,312.38,430.47,232.12,10.36;9,312.38,439.94,232.12,10.36;9,312.38,449.40,47.37,10.36"  xml:id="b16">
	<analytic>
		<title level="a" type="main">Full body virtual autopsies using a state-of-the-art volume rendering pipeline</title>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Ljung</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Winskog</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Persson</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Lundstrom</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Ynnerman</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="869" to="876" />
			<date type="published" when="2006-10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,312.38,458.87,228.59,10.36"  xml:id="b17">
	<monogr>
		<title level="m" type="main">CUDA C best practices guide, version 3.2 edition</title>
		<author>
			<persName>
				<forename type="first">Nvidia</forename>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2010-08" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,312.38,468.33,227.82,10.36"  xml:id="b18">
	<monogr>
		<title level="m" type="main">CUDA C programming guide, version 3.2 edition</title>
		<author>
			<persName>
				<forename type="first">Nvidia</forename>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2010-11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,312.38,477.79,232.12,10.36;9,312.38,487.26,101.30,10.36"  xml:id="b19">
	<analytic>
		<title level="a" type="main">Giga-voxel rendering from compressed data on a display wall</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Parys</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">G</forename>
				<surname>Knittel</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WSCG</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,312.38,496.72,232.12,10.36;9,312.38,506.19,232.12,10.36"  xml:id="b20">
	<analytic>
		<title level="a" type="main">Wavelet based 3D compression with fast random access for very large volume data</title>
		<author>
			<persName>
				<forename type="first">F</forename>
				<surname>Rodler</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Pacific Graphics</title>
		<meeting>. Pacific Graphics</meeting>
		<imprint>
			<date type="published" when="1999" />
			<biblScope unit="page" from="108" to="117" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,312.38,515.65,232.12,10.36;9,312.38,525.12,162.43,10.36"  xml:id="b21">
	<analytic>
		<title level="a" type="main">Compression domain volume rendering</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Schneider</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Westermann</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Visualization</title>
		<meeting>. IEEE Visualization</meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="293" to="300" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,312.38,534.58,232.12,10.36;9,312.38,544.05,232.12,10.36;9,312.38,553.51,161.91,10.36"  xml:id="b22">
	<analytic>
		<title level="a" type="main">Application of tensor approximation to multiscale volume feature representations</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<forename type="middle">K</forename>
				<surname>Suter</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">C</forename>
				<forename type="middle">P</forename>
				<surname>Zollikofer</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Pajarola</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Vision, Modeling and Visualization</title>
		<meeting>. Vision, Modeling and Visualization</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="203" to="210" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,312.38,562.97,232.12,10.36;9,312.38,572.44,232.12,10.36;9,312.38,581.90,174.42,10.36"  xml:id="b23">
	<analytic>
		<title level="a" type="main">All-frequency precomputed radiance transfer using spherical radial basis functions and clustered tensor approximation</title>
		<author>
			<persName>
				<forename type="first">Y.-T</forename>
				<surname>Tsai</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">Z.-C</forename>
				<surname>Shih</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Graphics</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="967" to="976" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,312.38,591.37,232.12,10.36;9,312.38,600.83,232.12,10.36;9,312.38,610.30,166.86,10.36"  xml:id="b24">
	<analytic>
		<title level="a" type="main">Employing complex GPU data structures for the interactive visualization of adaptive mesh refinement data</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">E</forename>
				<surname>Vollrath</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Schafhitzel</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Ertl</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Volume Graphics</title>
		<meeting>. Volume Graphics</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="55" to="58" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,312.38,619.76,232.12,10.36;9,312.38,629.23,232.12,10.36;9,312.38,638.69,128.50,10.36"  xml:id="b25">
	<analytic>
		<title level="a" type="main">Out-of-core tensor approximation of multi-dimensional matrices of visual data</title>
		<author>
			<persName>
				<forename type="first">H</forename>
				<surname>Wang</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">Q</forename>
				<surname>Wu</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">L</forename>
				<surname>Shi</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">Y</forename>
				<surname>Yu</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">N</forename>
				<surname>Ahuja</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Graphics</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="527" to="535" />
			<date type="published" when="2005-08" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,312.38,648.16,232.12,10.36;9,312.38,657.62,232.12,10.36;9,312.38,667.08,218.03,10.36"  xml:id="b26">
	<analytic>
		<title level="a" type="main">Hierarchical tensor approximation of multidimensional visual data</title>
		<author>
			<persName>
				<forename type="first">Q</forename>
				<surname>Wu</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Xia</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Chen</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">H.-Y</forename>
				<forename type="middle">S</forename>
				<surname>Lin</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">H</forename>
				<surname>Wang</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">Y</forename>
				<surname>Yu</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="186" to="199" />
			<date type="published" when="2008-02" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,312.38,676.55,232.12,10.36;9,312.38,686.01,232.12,10.36;9,312.38,695.48,57.34,10.36"  xml:id="b27">
	<analytic>
		<title level="a" type="main">Volume rendering of DCT-based compressed 3D scalar data</title>
		<author>
			<persName>
				<forename type="first">B.-L</forename>
				<surname>Yeo</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">B</forename>
				<surname>Liu</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="29" to="43" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
