<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/pisenberg/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.4.1" ident="GROBID" when="2016-09-09T14:57+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Distance Visualization for Interactive 3D Implant Planning</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName>
								<forename type="first">Christian</forename>
								<surname>Dick</surname>
							</persName>
						</author>
						<author>
							<persName>
								<forename type="first">Rainer</forename>
								<surname>Burgkart</surname>
							</persName>
						</author>
						<author>
							<persName>
								<forename type="first">R</forename>
								<forename type="middle">¨</forename>
								<surname>Udiger Westermann</surname>
							</persName>
						</author>
						<title level="a" type="main">Distance Visualization for Interactive 3D Implant Planning</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Index Terms—Distance visualization</term>
					<term>biomedical visualization</term>
					<term>implant planning</term>
					<term>glyphs</term>
					<term>distance fields</term>
				</keywords>
			</textClass>
			<abstract>
				<p>Fig. 1. Distance visualization for interactive (&gt; 30 fps) preoperative implant planning using color coding on the implant surface (left), oriented distance glyphs (middle), and color coding on the implant surface and on a set of additional axial slices (right). Abstract—An instant and quantitative assessment of spatial distances between two objects plays an important role in interactive applications such as virtual model assembly, medical operation planning, or computational steering. While some research has been done on the development of distance-based measures between two objects, only very few attempts have been reported to visualize such measures in interactive scenarios. In this paper we present two different approaches for this purpose, and we investigate the effectiveness of these approaches for intuitive 3D implant positioning in a medical operation planning system. The first approach uses cylindrical glyphs to depict distances, which smoothly adapt their shape and color to changing distances when the objects are moved. This approach computes distances directly on the polygonal object representations by means of ray/triangle mesh intersection. The second approach introduces a set of slices as additional geometric structures, and uses color coding on surfaces to indicate distances. This approach obtains distances from a precomputed distance field of each object. The major findings of the performed user study indicate that a visualization that can facilitate an instant and quantitative analysis of distances between two objects in interactive 3D scenarios is demanding, yet can be achieved by including additional monocular cues into the visualization.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION AND RELATED WORK</head><p>Whenever a user in an interactive computer environment is faced with the problem of positioning an object relative to another object, additional cues are required to support an instant communication of the absolute physical distance of the controlled object to the other object. Even though a number of such cues can be used in general, for example , audio cues or haptic feedback, in most environments only binocular or monoscopic views and mouse-based interaction is available. Furthermore, as for spatial stimuli the visual sense predominates, followed by audition and touch <ref type="bibr" coords="1,136.03,562.34,13.75,8.12" target="#b18">[19]</ref>, binocular or monocular visual cues are usually the preferred indicators. Psychovisual experiments, however, have indicated that stereopsis provides only relative depth information, which allows inferring on the location of an object relative to another object rather than the ab-solute distance between them. Monocular cues, such as motion effects or additional geometric structures embedded into a visualization, on the other hand, can effectively indicate absolute estimates of distance. Without such direct cues, the estimation of absolute spatial distance between objects becomes very difficult, and typically requires a mental indirection to infer an accurate estimate. Let us refer to the textbooks by Steinman et al. <ref type="bibr" coords="1,366.19,540.60,14.94,8.12" target="#b15">[16] </ref>and Schwartz <ref type="bibr" coords="1,436.35,540.60,14.94,8.12" target="#b13">[14] </ref>for a scientific review of these arguments. </p><p>An example where color is used to indicate distance is given in <ref type="figure" coords="1,529.55,566.97,14.95,8.12;1,294.12,576.93,19.33,8.12">Fig- ure 1</ref>(left): The minimum distances between points on an implant and the surface of a bone into which the implant should be placed are color-coded on the implant. In previous work, color (and iso-contours in color distributions) has been shown to be quite effective at indicating where distance falls below a critical value, and in combination with color legends distance-based coloring even supports quantitative investigations <ref type="bibr" coords="1,345.68,636.70,9.71,8.12" target="#b1">[2,</ref><ref type="bibr" coords="1,357.68,636.70,6.72,8.12" target="#b7"> 8,</ref><ref type="bibr" coords="1,366.68,636.70,10.65,8.12" target="#b17"> 18]</ref>. As can be seen, however, such visualizations fail in communicating contextual information that is required to effectively interpret distance. Regardless the specific distance measure used, such as shortest distances via distance transforms <ref type="bibr" coords="1,492.70,666.59,9.71,8.12" target="#b4">[5,</ref><ref type="bibr" coords="1,504.47,666.59,6.72,8.12" target="#b6"> 7,</ref><ref type="bibr" coords="1,513.27,666.59,10.65,8.12" target="#b11"> 12]</ref> , spatial distance always 'connects' two reference points, and the human is used to interpret distance in the context of such references. Due to this observation, distance coding in still images via connecting structures such as lines or glyphs has been shown to be very effective. Pang et al. <ref type="bibr" coords="1,305.03,716.41,14.94,8.12" target="#b9">[10] </ref> used line primitives of varying length to indicate distances between two surfaces, and in <ref type="bibr" coords="1,394.54,726.37,14.19,8.12" target="#b10">[11,</ref><ref type="bibr" coords="1,411.55,726.37,11.95,8.12" target="#b11"> 12] </ref>point-to-point distances between two selected anatomical features were visualized via arrow glyphs ac-companied by textual annotations. Without such connecting structures the user has difficulties to associate the points the color is referring to and to use her experience for interpretation. Apart from the question for an adequate visual encoding of absolute distances in still images, another aspect becomes very important in interactive environments where the user's eyes fixate on the controlled objects and track their motion and orientation. In this case, distances to other objects have to be communicated via peripheral vision, which is the ability to gather information from the environment other than the point of focus. Peripheral vision directs our attention to slight movements in the environment around us, and it is processed significantly faster than vision requiring color. To the best of our knowledge , an investigation of the potential of glyphs for revealing distances between two moving objects in interactive scenarios—taking into account the possibility to dynamically change their shape, size, color, and density— has not been performed so far. Based on the aforementioned observations, in this paper we provide novel monocular cues for effectively revealing point-to-point distances between two objects in interactive environments. Based on the mentioned previous techniques using static lines and glyphs we propose a number of extensions to exploit the human's peripheral vision, and we investigate the effectiveness of these extensions in an applicationspecific user study. Specifically, we address an application in which the user has to position an object with respect to another object that is fixed in space. The underlying application is implant planning for hip joint replacements, where in a preoperative planning phase a surgeon tries to find the patient-specific optimal implant shape, size and position . In this application, the user can interactively translate and rotate both models together or only the implant relative to the bone. The monocular cues we present indicate distance via additional geometric structures that smoothly adapt their shape, appearance, or position to changing distance distributions. Two different kinds of monocular cues are provided: For interactive scenarios we have developed dynamically changing and colored distance glyphs to effectively employ peripheral vision for gathering distance information. An example demonstrating the visual sensation produced by these glyphs is given in <ref type="figure" coords="2,63.39,414.35,30.68,8.12">Figure 1</ref> (middle). Note that even in a still image the absolute distances can be revealed much more intuitively compared to pure color coding as in <ref type="figure" coords="2,110.14,434.27,30.78,8.12">Figure 1</ref>(left). One important reason is that the glyphs serve as 'bridging' structures between the implant and the bone surface, enabling the user to associate the distance values to geometric points on the surfaces. For still images, where peripheral vision is not relevant for perceiving distances, we embed slices into the 3D visualization, and we further augment these slices by colors indicating distance (see <ref type="figure" coords="2,240.09,494.84,29.43,8.12">Figure 1</ref>, right). The advantage of this kind of visualization is that it allows for a better observation of the implant due to the sparsity of the used geometric elements, yet providing visual indicators of the spatial relationships between the two objects. For both types of visual cues, by carefully selecting the shape and appearance attributes of the used graphical primitives, critical regions where the moved implant comes close to the bone surface are identified pre-attentively, i.e., they are detected very rapidly and accurately by the low-level visual system. The low-level visual system is associated with the lateral geniculate nucleus, or simply called visual thalamus, which is part of the thalamus and responsible for reducing the optical input that is further processed by the visual cortex. In our application, the pre-attentive visual features we are exploiting to accommodate a rapid analysis of distances are hue, form, and density of glyphs. For a more elaborate discussion of the pre-attentive mechanisms of the low-level visual system let us refer to <ref type="bibr" coords="2,204.71,655.05,9.71,8.12" target="#b5">[6,</ref><ref type="bibr" coords="2,216.66,655.05,10.65,8.12" target="#b16"> 17]</ref>. Throughout this paper we will present the methodology underlying the two new approaches for visualizing spatial distances, and we will analyze the particular strengths as well as the differences and limitations of these approaches in the context of preoperative implant planning . To the best of our knowledge, this is the first time that spatial distance visualization between two objects in interactive environments is addressed other than by color. The remainder of the paper is as follows: In the next section we Calcar Region Lateral Wall <ref type="figure" coords="2,285.12,211.86,19.39,7.64">Fig. 2</ref>. Cross section through a human femur, showing the bone shell consisting of stiff cortical bone and the bone interior consisting of spongious trabecular bone. </p><p>present the medical application for which our distance visualization techniques are developed. Section 3 outlines the specific distance measures we use and describes how these measures are mapped onto meaningful graphical representations, such as glyphs and slices. The dedicated GPU implementation of all approaches, by which it is possible to achieve interactive frame rates even for large and complicated data sets, is discussed in Section 4. The result section demonstrates the applications of our techniques and compares the results to each other. We conclude the paper with a summary of the basic advantages and disadvantages of both techniques. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">MEDICAL BACKGROUND</head><p>A human femur consists of two types of tissue: The outer shell of the bone consists of stiff cortical bone, whereas the interior consists of spongious trabecular bone (see <ref type="figure" coords="2,398.20,406.41,28.90,8.12">Figure 2</ref>). This particular construction results from a natural optimization process, which allows the femur to bear maximum load at minimum weight. For total hip joint replacement , the femoral head is removed, and the inner trabecular bone has to be partially removed in order to be able to insert the implant. During preoperative planning, the patient-specific optimal implant shape, size, and position has to be determined according to certain geometrical as well as biomechanical criteria. The geometrical criteria include that the implant has to fit into the interior of the cortical bone shell, without penetrating this shell, and that the joint rotation center has to be preserved. The main biomechanical criterion is related to the stress distribution in the loaded femur, in that the stress distribution after insertion of the implant should closely match the preoperative, physiological stress distribution. Bone is a living tissue and adapts to changes of the mechanical load situation by bone formation or resorption , dependent on whether the load has increased or decreased, respectively. Paradoxically, bone resorption also occurs if the load exceeds a certain critical magnitude. The insertion of an implant changes the stress distribution in the bone, in that stresses are bypassed by the implant, which leads to a removal of stresses from certain regions of the bone (so-called stress shielding). In addition, for an optimal load transmission from the implant to the adjacent bone stock, it is important that the implant has tight press fit contact to the remaining bone shell, in particular in the calcar region and—especially for short stemmed implant designs—the lateral wall of the femur. If the implant has not sufficient contact in these regions, the stress distribution is changed significantly in that stresses are moved almost completely from regions with no contact to regions with contact. An unphysiological stress distribution can lead to a substantial resorption of bone tissue, with the consequences of fracture or loosening of the implant. Therefore, the selection of a patient-specific optimal implant shape, size and position during preoperative planning is essential for the long-term stability of the implant. In previous works, Dick and coworkers presented a computational <ref type="figure" coords="3,46.57,218.90,3.32,7.64">3</ref>. Distance rendering using oriented glyphs, located at certain seed points on the implant surface: Left: Orienting the glyphs orthogonally to the implant surface enables an effective perception of the spatial relationships . Right: Orienting the glyphs toward the respective closest point on the bone surface makes perception of the spatial relationships rather difficult. steering environment for implant planning in orthopedics <ref type="bibr" coords="3,236.58,296.00,9.71,8.12" target="#b2">[3,</ref><ref type="bibr" coords="3,248.24,296.00,6.47,8.12" target="#b3"> 4]</ref>, which computes and visualizes the stress distribution in the femur at interactive update rates, and thus allows the surgeon to interactively analyze the effect of different implant shapes, sizes, and positions on the stress distribution in the patient-specific bone. This environment so far uses semi-transparent rendering of the bone and implant surfaces to visualize the implant position three-dimensionally within the bone, which only allows for a very limited perception of the geometric relationships and absolute distances, i.e., the distances between bone and implant. In the considered application, however, the perception of the geometric relationships and absolute distances is highly important for a precise and intuitive navigation of the implant in the virtual 3D environment , for validating if the current implant configuration meets the described geometrical criteria, as well as for analyzing if a particular unphysiological stress distribution results from the implant not having sufficient contact with the bone, and in this case, how the implant has to be moved or changed in size in order to establish this contact. Therefore, the goal of the work presented in this paper is to develop dedicated visualization methods that allow for a rapid perception of the geometric relationships and absolute distances between implant and bone. In the computational steering environment, the surgeon can then flexibly switch between the distance and the stress visualization (or is provided with both visualizations simultaneously on a split screen) in order to find the patient-specific optimal implant shape, size, and po- sition. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">DISTANCE VISUALIZATION</head><p> For the particular application of preoperative implant planning, we employ a triangle mesh of the outer bone surface, a triangle mesh enclosing the trabecular region of the bone and thus separating the cortical and trabecular regions, and a triangle mesh of the implant surface. The first two meshes, which are in the following referred to as the outer and inner bone mesh, are obtained by segmentation from a CT scan. The distances which are of primary relevance for preoperative planning are those between the inner bone mesh and the implant mesh. To simplify the notation, we typically omit the differentiation between inner and outer bone mesh in the following. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Glyph-based Distance Visualization</head><p>Our first approach for the visualization of distances between bone and implant mesh is based on rendering cylindrical glyphs at selected seed points on the implant surface. We use cylindrical glyphs since these provide an intuitive means to depict distances: The height of the cylinder visualizes the represented distance, and its axis specifies the direction along which the distance Besides of adapting the shape of the glyphs, we additionally colorize the glyphs to encode the represented distance. We linearly interpolate between colors green and red, where green color is used for a distance of d max , and the highlighting red color (corresponding to the importance of small distances) for a distance of 0. This smoothly varying color map was chosen to avoid a rapid change of colors when the glyphs' sizes are changing, which would otherwise disturb the perception of size changes. The glyph seed points are computed once when a particular implant mesh is selected. In particular, we use spatially fixed seed points and a uniform seeding density. Besides the important goal of achieving visual coherence, these choices are motivated as follows: By using spatially fixed seed points, we avoid that changes of visualized distances due to moving of the implant are overlaid by changes of visualized distances due to moving of the seed points, which would distract from precisely monitoring the implant's position. By using a fixed seeding density, increasing distances (corresponding to decreasing radii of the glyphs) lead to a visual thinning out of the glyphs. For the considered application, this is in accordance with the fact that large distances are of minor interest. To determine the seed points, we proceed as follows: In the first step, we build a list of potential seed points L by iterating over the individual triangles of the implant surface mesh. For each triangle, we test if all edge lengths are at most δ . If this is the case, we add the triangle's barycenter to L . Otherwise, we perform a 1:4 split of the triangle, and proceed recursively on the newly created triangles. In the second step, we build the list of seed points L by iterating over L . For each potential seed point P, we test if all seed points already contained in L have at least a distance of δ from P (measured in 3D space). If this is the case, P is added to L, otherwise it is discarded. Since this algorithm considers the individual triangles of the implant mesh separately, it is very robust in that it is independent of the mesh quality. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Slice-based Distance Visualization</head><p> One approach for the visualization of the distances between two surfaces is to display at each surface point the distance to the nearest point on the respective other surface via color coding <ref type="bibr" coords="4,193.90,566.48,9.70,8.12" target="#b1">[2,</ref><ref type="bibr" coords="4,205.79,566.48,6.72,8.12" target="#b7"> 8,</ref><ref type="bibr" coords="4,214.70,566.48,10.65,8.12" target="#b17"> 18]</ref>. This can be realized by using a 3D distance field <ref type="bibr" coords="4,157.14,576.44,10.46,8.12" target="#b6">[7] </ref>for each of the two surfaces. Given a set of feature points Σ ⊂ R 3 , a distance field is a mapping d Σ : R 3 → R which specifies for each point x in three-dimensional space the distance to the nearest feature point: d Σ (x) = inf y∈Σ y−x 2 . A distance field for a particular surface is obtained by choosing Σ to be the set of points on this surface. To create the described visualization , for the first surface, the second surface's distance field is sampled at the points on the first surface, and vice versa. Algorithmically, a distance field can be obtained by means of a distance transform <ref type="bibr" coords="4,251.84,656.13,9.52,8.12" target="#b6">[7]</ref>. For our application of interactive 3D implant planning, this visualization approach is shown in <ref type="figure" coords="4,130.68,676.55,30.85,8.12">Figure 1</ref> (left). Here, the distance volume of the bone surface is visualized on the surface of the implant. To provide a large number of distinguishable colors for conveying absolute distance values effectively, a rainbow color map ranging from red (small distance) to violet (large distance) is used. This choice was motivated by our observation that the known shortcomings of rainbow color maps, as for instance discussed in <ref type="bibr" coords="4,171.48,736.33,9.52,8.12" target="#b0">[1]</ref>, are much less severe in <ref type="figure" coords="4,285.12,218.90,20.60,7.64">Fig. 6</ref>. Focus+context visualization: Left: To avoid that colors are washed out by the bone surface, the surface's opacity is reduced. However , this reduces the spatial context information. Right: By using a focus+context approach, the colors are saturated in the important regions, and at the same time the spatial context information is preserved. our application scenario. Since here the user's perception is supported by 3D geometry that provides additional depth cues, and the color variation on the implant changes dynamically according to the issued movements, the rainbow color map can convey a very accurate and intuitive image of absolute distances. <ref type="figure" coords="4,295.08,342.83,30.29,8.12">Figure 1</ref>(left), however, demonstrates that the spatial relationships between the nested meshes along the viewing direction cannot be recognized . As a consequence, it is not intuitively obvious how the implant has to be moved in order to optimize the distances between bone and implant with respect to the specific medical requirements, which makes navigation in an interactive setting rather difficult. To address this issue, we propose to augment the visualization by rendering additional geometric structures that bridge the volume between implant and bone. Since slicing planes are still the predominant tool for analyzing 3D data in medical diagnosis, and thus are graphical elements to which doctors are accustomed through experience, we render a set of parallel, axial slices passing through the bone and implant , as shown in <ref type="figure" coords="4,356.62,464.03,31.25,8.12" target="#fig_1">Figure 7</ref>(left). From the intersection pattern of the slices with the bone and implant the spatial relationships become directly visible. By using an orthographic projection, leading to a parallel rendering of the slices in screen space, occlusions introduced by the slices can be kept at a minimum. However, it is still difficult to relate the color-coded distances on the implant to the spatial relationships. This can be improved by visualizing color-coded distances also on the slices. Rendering the distance field of the bone not only on the implant but also on the slices results in ring-shaped structures, as illustrated in <ref type="figure" coords="4,425.25,555.35,29.96,8.12" target="#fig_1">Figure 7</ref>(middle left), with the number of rings between implant and bone being a visual clue for the distance. However, on the slices the color coding then only provides the distance of the respective point to the bone, without incorporating the distance to the implant. In particular, the colors on the slices do not change upon movements of the implant, rendering this approach as rather non-intuitive in an interactive setting. To provide the surgeon with a direct visualization of the distances between bone and implant on the slices, we first have to define a reasonable distance measure at the points in the volume between implant and bone. Considering a point x, a reasonable choice would be the minimum length of all line segments passing through x and connecting a point on the implant and bone surface, respectively (see <ref type="figure" coords="4,512.09,676.55,23.41,8.12;4,285.12,686.52,3.24,8.12">Figure  5</ref>). On the bone and implant surfaces, this definition reduces to the distance to the nearest point on the respective other surface. In case of parallel or concentric surfaces (as is the case in the current application ), this measure can be well approximated by d Bone (x)+d Implant (x), where d Bone and d Implant denote the distance fields of the bone and implant , respectively. These distance fields have to be computed only once when the respective mesh is changed. The result is illustrated in <ref type="figure" coords="5,31.50,253.10,30.13,8.12" target="#fig_1">Figure 7</ref>(middle right). To achieve a high-quality visualization, we render slices of a certain thickness (1mm) instead of infinitely thin slices (as is illustrated in <ref type="figure" coords="5,31.50,283.33,29.64,8.12" target="#fig_1">Figure 7</ref>(right) for comparison). If the view direction is falling into the slice plane, infinitely thin slices would become invisible. Furthermore, we render black contours along the intersection lines of the slices with the bone and the implant. In this way, partially overlapping projections of slices can be clearly distinguished. To color-code the distances, we employ a rainbow color scale which is obtained from the HSV color space, using a hue from 0 @BULLET = red to 270 @BULLET = violet. The red end of the scale (highlighting color) is used to encode the distance value 0, the violet end to encode a certain maximum value d max . Analogous to the glyph-based approach, to clearly indicate when the implant has left the interior of the bone, i.e., a geometrically invalid positioning of the implant, the parts of the implant which have left the interior are rendered in a distinct color. Here, we use white color, which is in high contrast to the red color used to encode the smallest distances. In this way geometrically invalid positions are immediately visible. For the 3D visualization, we use semi-transparent rendering of the bone surfaces. To hide non-important regions with large distances between bone and implant from the visualization, we use a focus+context approach (see <ref type="figure" coords="5,83.43,473.30,29.46,8.12">Figure 6</ref>) by scaling the opacity of the fragments of the outer bone surface with the factor (saturate(d Implant (x)/r)) 2 , where r denotes the radius of the focus region, and x is the world space position of a fragment. This leads to high and low opacities of the outer bone surface in regions with large and small distances between bone and implant, respectively. In this way, the important regions with small distances between bone and implant, especially the calcar region and the lateral femoral wall are clearly visible, and at the same time, the perception of the outer shape of the bone and thus of the spatial relationships is improved. Additionally, we provide the possibility to render the implant as a semi-transparent surface. This enables the surgeon to monitor the distances between bone and implant also on the back side of the implant, which are otherwise hidden by an opaque implant (see <ref type="figure" coords="5,224.49,603.15,32.63,8.12">Figure 11</ref>, right, and <ref type="figure" coords="5,47.20,613.12,33.63,8.12">Figure 12</ref> , right). Since the user can rotate the entire scene consisting of bone and implant, a clear view on the relevant parts can even be obtained when a color-coded implant surface is used. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">GPU-BASED IMPLEMENTATION</head><p> To achieve interactive update rates, we have realized our visualization methods on the GPU. Our implementation is based on the stencilrouted k-buffer <ref type="bibr" coords="5,87.89,686.52,9.52,8.12" target="#b8">[9]</ref>, which enables to render semi-transparent surfaces in correct visibility order, similar to the implementation described in <ref type="bibr" coords="5,31.50,706.45,9.52,8.12" target="#b3">[4]</ref>. Considering the complex spatial situation with multiple nested meshes, semi-transparent rendering is essential to avoid occlusions. In contrast to z-buffer-based rendering of opaque geometry, where of the set of fragments incoming to the same pixel only the fragment with the smallest depth is captured, the k-buffer allows to capture up to 8 fragments incoming to a pixel. To capture up to 32 fragments per pixel, we employ 4 k-buffer slices, which are filled by rendering the transparent geometry 4 times. For each fragment, we store 2 × 32 bits to encode an object ID, the fragment's depth in camera space, as well as the fragment's RGBA color value. Using the k-buffer, rendering of the scene is performed in three steps: In the first step, all opaque geometry is rendered into the standard frame buffer. In the second step, all semi-transparent geometry is rendered into the k-buffer. The semi-transparent geometry consists of the bone surface meshes, the implant surface mesh, as well as the glyphs for our glyph-based distance visualization method. In the third step, a full screen ray-casting pass is performed. First, for each pixel the fragments stored in the k-buffer are fetched. These fragments are then sorted according to ascending camera space depth and blended using front-to-back blending, up to the camera space depth of the opaque geometry, which is obtained by accessing the frame buffer and projecting the clip space depth back into camera space. The accumulated color value is finally blended with the color value of the opaque geometry stored in the frame buffer. For our glyph-based visualization approach, the glyphs have to be updated whenever the implant position is changed. This update is performed on the CPU. For each glyph seed point, we determine the intersection point of the ray emanating from the seed point in the direction of the outward implant surface normal with the inner bone surface. If no intersection is found, the seed point is lying outside of the inner bone surface, and the seed point is skipped. The distance value is then obtained from the distance between the seed point and the intersection point. To achieve interactive update rates, a kd-tree acceleration structure is used to determine ray/mesh intersections. The glyphs' seed points, normals, and heights are then uploaded into a buffer on the GPU, and by using a single generic cylinder triangle mesh, the glyphs are rendered as semi-transparent geometry using instanced rendering. For the slice-based distance visualization, the slices are rendered on-the-fly during the ray-casting process by analytically computing the intersections between the rays and the slicing planes. To generate the distance fields of the bone and implant used by this approach, we first create a voxelization for each of the two meshes, using the GPU-based algorithm described in <ref type="bibr" coords="5,378.24,625.49,9.52,8.12" target="#b2">[3]</ref>. We then compute a distance transform of each voxel volume, using the GPU-based algorithm described in <ref type="bibr" coords="5,527.32,635.45,13.75,8.12" target="#b12">[13]</ref>. By utilizing the GPU, these computations can be performed in less than 2 seconds for a voxel resolution of 0.25 mm, allowing the user to almost instantaneously switch between different implant shapes and sizes. The distance fields are stored in GPU memory as 3D textures and are sampled using trilinear interpolation. During the ray traversal of each pixel's stack of fragments, we maintain three flags, specifying whether the current position of the ray is lying inside the outer bone mesh, inside the inner bone mesh, and inside the implant mesh, respectively. These flags are toggled whenever a fragment of the respective mesh (identified by the fragment's object 2177 DICK ET AL: DISTANCE VISUALIZATION FOR INTERACTIVE 3D IMPLANT PLANNING ID) is encountered. The flags are used to clip the rendering of the slices at the bone and implant surfaces, to distinctly colorize the parts of the implant lying outside of the inner bone mesh, and to achieve a high-quality rendering of the inner and outer bone mesh: Since the inner and the outer bone mesh are generated in separated processes, it is possible that the inner mesh slightly sticks out of the outer mesh. This is fixed during rendering by clipping the inner mesh at the outer mesh, and by creating additional inner bone mesh fragments on-the-fly during ray-casting to close the resulting holes. The rendering of contours along the intersection lines of the slices with the bone and the implant is performed in screen space. Whenever a slice fragment is created, we test in a 5 × 5 neighborhood of adjacent pixels whether the (potential) slice fragment corresponding to the respective neighboring pixel is lying outside of the outer bone surface or within the implant. If such a pixel is found, the center fragment is a border fragment and is colored accordingly, taking into account the number of neighboring 'outside' fragments to obtain antialiased contours. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">RESULTS AND EVALUATION</head><p>All images in this manuscript were rendered in less than 30 ms on a standard desktop PC, equipped with an Intel Core 2 Quad Q9450 2.66 GHz processor, 8 GB of RAM, and an NVIDIA GeForce GTX 480 graphics card with 1536 MB of local video memory. The view port size was 1920 × 1200. To validate the effectiveness of the developed distance visualization methods, we have performed a user study. In this study, the images were created using the following visualization parameters: General parameters: α Outer Bone = 0.2 for focus+context disabled , α Outer Bone = 0.9 for focus+context enabled, α Inner Bone = 0.2, α Implant = 1.0 or 0.35, focus radius r = 30 mm. Parameters for glyphbased visualization: r · d = 5 mm 2 , r max = 2.5 mm, d max = 10 mm (i.e., red corresponds to a distance of 0 mm, green to 10 mm). Parameters for slice-based visualization: Resolution of distance fields 0.25 mm, slice spacing 15 mm, slice thickness 1 mm, d max = 16 mm (i.e., red corresponds to a distance of 0 mm, violet to 16 mm). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">User Study</head><p> For the user study we recruited 30 participants, comprised of 21 computer science and 6 medical students as well as 3 experienced orthopedic surgeons. The participants were selected to be right-handed, and to have no color vision deficiency. All participants were daily users of computers. The students were exposed to the application for the first time. The three surgeons knew the underlying application including the stress visualization, but also used the distance visualization for the first time. The study was performed using the desktop PC described above with a standard 24 inch monitor. The position of the implant was alternatively controlled using the mouse or a Sensable Phantom Omni haptic device <ref type="bibr" coords="6,336.67,298.58,14.94,8.12" target="#b14">[15] </ref> (force feedback was not implemented). Simultaneous rotations and translations of the bone and implant model were controlled by mouse or keyboard input, respectively. For each user, an individual session of about 50-60 minutes was performed. Each session consisted of a demonstration and training phase, and three ex- periments. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Demonstration and Training Phase. The goal </head><p> of the demonstration and training phase was to acquaint the participants with the visualization methods and the interaction mechanisms for controlling the implant position using the mouse and the Phantom device. To accelerate the learning process, in this phase we used a simplified geometrical setup consisting of two cylinders of different size, with the larger one (resembling the bone) being fixed. Initially, the smaller cylinder was located outside of the larger cylinder, and its main axis was rotated against the main axis of this cylinder. The task was to move the smaller cylinder (resembling the implant) such that it is concentrically centered inside the larger cylinder. Firstly, the task was demonstrated to each participant individually using all of the three distance visualization methods, i.e., color coding on the implant surface, the glyph-based approach, and the slice-based approach, as well as both the mouse and the Phantom device. During the demonstration, the meaning of the graphical representations employed in our distance visualization methods, as well as the specific mapping of mouse and Phantom inputs onto movements of the implant, was verbally explained to the participant. After the demonstration , which took about 5 minutes, the participants were asked to perform the task. For each combination of visualization method and input device, about 2 minutes of training time were granted. The entire demonstration and training phase took about 20 minutes. Experiment 1. In the first experiment, we quantitatively and qualitatively evaluated the three distance visualization methods within the interactive 3D environment. In contrast to the training phase, this experiment was performed using the real bone and implant geometry. The participants were asked to place the implant in a certain position within the bone. This target position was explained to the participants by means of a sketch showing a 2D cross section of the bone and the implant in the target position. In particular, the target position was precisely specified by the following criteria: a) the implant must be located inside the cortical bone shell without penetrating this shell, b) the distances between implant and bone in the calcar region and at the lateral wall of the femur must be minimized, and c) the rotation center of the joint must be preserved (i.e., the ball of the implant must be centered within the femoral head). The participants were asked to perform this task a total of 12 times, <ref type="figure" coords="7,31.50,137.75,19.04,7.64">Fig. 9</ref>. Time (in seconds) needed by the individual users for interactive implant positioning (Experiment 1) dependent on the input device and the distance visualization method, as well as on the implant shape. using the three distance visualization methods, two different implant shapes (CUT and G2), and the two input devices. The implant was always placed at the same starting position outside of the bone, with a different orientation than in the target position, and always the same initial view point was selected. To avoid biasing due to learning effects , with each participant we permuted the order in which the individual visualization methods, implants, and input devices were tested. During the experiment, we measured the time which was needed by the participants to navigate the implant into the target position, allowing a tolerance of 3 mm wrt translation and 5 @BULLET wrt rotation. If the participant was not able to reach the target position within a 3 minute time interval, we proceeded with the next configuration. The times measured for each individual participant are shown in <ref type="figure" coords="7,234.10,486.16,29.99,8.12">Figure 9</ref>, the average times are given in <ref type="figure" coords="7,127.19,496.12,25.30,8.12" target="#tab_1">Table 1</ref>. In addition, for each of the two implant shapes we asked the participants for a subjective ranking (first, second, third) of the three visualization methods according to their capability to communicate spatial relationships and distances. The rankings are shown in <ref type="figure" coords="7,229.79,536.34,25.30,8.12" target="#tab_2">Table 2</ref>. The results clearly demonstrate the effectiveness of our novel glyph-and slice-based distance visualization methods. Compared to pure color coding of distances, these methods allow for a significantly faster navigation of the implant into the target position. Notably, by using color only the task could not be accomplished by 6 of the users within the 3 minute time limit. For the positioning of the CUT implant (see <ref type="figure" coords="7,200.82,606.82,28.84,8.12">Figure 1</ref>), the majority of the users preferred the glyph-based approach over the slice-based approach. This is mainly due to the continuous movement of the glyphs, generating an additional visual attraction that can be processed instantly by the visual system. Especially the use of 'marshmallow'like cylindrical glyphs, which simulate quite plausibly the physical deformations of elastic glyphs under pressure, was received very positively by the users. The good matching of this approach with the users' expectation and experience in reality was given the main reason for this positive response. Considering the slice-based approach, the users criticized the fixation of the slicing planes to a few positions in the 3D domain. Due to this, a non-uniform distance distribution across the implant surface cannot easily be perceived during interactive placement of the implant. In addition, as the distance values within a slice are Implant Color Glyphs Slices CUT 0/0/90 27/63/0 63/27/0 G2 0/0/90 6/84/0 84/6/0 <ref type="figure" coords="8,22.50,234.66,22.71,7.64">Fig. 10</ref>. Left: Rendering artifacts resulting from the glyphs partially sticking out of the bone surface. Middle: Clipping the glyphs at the bone surface does not resolve these artifacts. Right: By reordering fragments along the view rays the artifacts are removed. <ref type="figure" coords="8,22.50,422.76,24.98,7.64">Table 5</ref>. Average time (in seconds) needed by the users to estimated the distance represented by a glyph, dependent on the glyph shape and the strategy to adapt glyphs to changing distances (Experiment 3). The second row shows the achieved estimation accuracy. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Mouse </head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Cylinders </head><p>arrow width) or were scaled isotropically (a smaller distance results in a smaller arrow width). In the latter case, the seeding density was increased with decreasing distance to avoid that small distances become invisible. In <ref type="figure" coords="8,93.56,514.76,29.84,8.12" target="#fig_2">Figure 8</ref>, the different options are shown next to each other. The idea behind using arrows instead of cylinders was to improve the perception of the spatial orientation of the glyphs, since an arrow head (cone) projects onto two clearly distinguishable shapes when seen from the side (triangle) or from the top (circle). Using an adaptive seeding density of the glyphs is implemented as follows: We first generate a set of uniformly distributed seed points with a minimum spacing of δ = 0.5 mm, using the strategy described in Section 3.1. In contrast to the case of using a uniform seeding density , we now create glyphs only at a subset of the seed points. In particular , we iterate over the set of seed points in a fix order, and create a glyph at the currently considered seed point if that glyph does not overlap with any previously created glyph. More precisely, a glyph with radius r at a seed point x is created, if for each of the previously created glyphs with radius r 0 and seed point x 0 the condition x−x 0 2 ≥ r +r 0 is satisfied. The radius r of the glyph (determined by the arrow head) is computed as r = 0.2d, where d denotes the height of the glyph (length of the arrow), i.e., the represented distance. Firstly, we asked the users to move the CUT implant in the interactive 3D environment and to monitor the change of distances between bone and implant, using the three different glyph options. We then asked the users for a ranking of these options according to their capability to communicate spatial relationships and distances and for comments . The rankings are given in <ref type="figure" coords="8,405.08,275.53,25.30,8.12" target="#tab_4">Table 4</ref>. For interactive positioning there was a preference of all users for squeezed cylindrical glyphs over squeezed arrow glyphs. As the key reasons for this judgment it was reported that the squeezing of arrows was observed a rather unrealistic and thus non-intuitive effect, and especially when arrows become extremely flat or thin, their usual and expected potential to indicate spatial orientation was lost, making the rendering of the arrow head unnecessary. Comparing squeezed cylindrical glyphs and isotropically scaled arrow glyphs, cylindrical glyphs were favored by over 70% of the users. Considering the arrow glyphs, many users were distracted by glyphs popping up or disappearing (this is a consequence of the adaptation of the seeding density, when larger glyphs are replaced by smaller glyphs, and vice versa), and particularly appreciated the visual coherence of the 'marshmallow'-like cylindrical glyphs. In addition, a small number of users criticized the visual clutter introduced by the increasing number of arrow glyphs when distances become small. We then asked the users to rank the different glyph options in still images. This was performed similarly as in Experiment 2 by using<ref type="figure" coords="9,31.50,359.42,43.98,7.64">Fig. 11. G2</ref>implant, front view: Distance visualization using color coding on the implant surface (left), oriented distance glyphs (middle left), and color coding on the implant surface and on a set of axial slices (middle right). Additionally, we provide the possibility to render the implant semi-transparently (right). <ref type="figure" coords="9,31.50,719.62,39.95,7.64">Fig. 12. G2</ref>implant from <ref type="figure" coords="9,119.73,719.62,32.19,7.64">Figure 11</ref>, back view. the users considered this effect to have any negative influence on the distance perception, we integrated a rendering option into our tool to reduce this effect. This rendering option is based on reordering the fragments of the semi-transparent geometry along each view ray, which is implemented using the k-buffer as described in Section 4. In our initial implementation , the fragments along each ray are sorted according to ascending camera space depth, and then blended using front-to-back blending. The reordering is now performed on the sorted stack of fragments, before front-to-back blending is applied. Conceptually, if a ray enters a glyph before entering the bone, or leaves a glyph after leaving the bone (in both cases the glyph penetrates the bone surface), we move the corresponding bone surface fragments in front or behind of the glyph surface fragment, respectively . Entering and leaving of closed surfaces is determined by maintaining flags which are toggled whenever a fragment of the respective surface is encountered. Technically, the reordering of fragments is implemented as follows: If the ray encounters an 'entering' glyph fragment (i.e., a glyph fragment at the transition from the outside to the inside of a glyph), starting from the current position, we search for 'entering' bone fragments (from both the inner and outer bone surface mesh) along the ray within a certain distance from this position. These fragments are moved in front of the glyph fragment, without changing the relative order of the 'entering' bone fragments. Analogous, if the ray encounters a 'leaving' glyph fragment, starting from the current position, we search for 'leaving' bone fragments backwards along the ray within a certain distance from this position. These fragments are moved behind of the glyph fragment. In our implementation the search distance is set to 5 mm. The front-to-back blending is then performed on the reordered stack of fragments. Even though it is clear that this approach cannot always guarantee that all transitions are fixed and depends on the specified search distance, as demonstrated in <ref type="figure" coords="10,154.74,375.22,35.34,8.12">Figure 10</ref>it can very effectively eliminate virtually all of the transitions. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">CONCLUSION AND FUTURE WORK</head><p>We have presented two different approaches for visualizing distances between two objects in 3D space. These approaches are specifically tailored to support the user in the positioning of objects in interactive environments. We have introduced novel GPU-based visualization techniques using dynamic glyphs to reveal distance, depth, and directional information, and slicing planes on which distance values are instantly updated during navigation. These approaches have been developed to support 3D implant positioning in a medical planning system, and their strengths and potential limitations in this particular application have been analyzed in a number of user experiments. In the future, we will analyze the capabilities of our approaches in other interactive applications like computational steering or virtual part assembly. The investigation of possibilities to automatically integrate distance visualization techniques into medical and technical illustrations will be another focus. From a perceptual point of view, we are very interested in the analysis of the perceptual effects that are caused by the combination of stereo rendering and the proposed distance visualization techniques. A more elaborate study of alternative or supplementary techniques for revealing distance, such as density volumes or textual annotations, in interactive environments is manda- tory. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="3,31.50,218.90,250.37,7.64;3,31.50,228.36,250.37,7.64;3,31.50,237.83,250.38,7.64;3,31.50,247.29,250.38,7.64;3,31.50,256.76,250.37,7.64;3,31.50,266.23,49.97,7.64"><head>Fig. </head><figDesc>Fig. 3. Distance rendering using oriented glyphs, located at certain seed points on the implant surface: Left: Orienting the glyphs orthogonally to the implant surface enables an effective perception of the spatial relationships . Right: Orienting the glyphs toward the respective closest point on the bone surface makes perception of the spatial relationships rather difficult. </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="5,31.50,202.28,512.99,7.64;5,31.50,211.74,339.82,7.64"><head>Fig. 7. </head><figDesc>Fig. 7. Color coding of distances on the slices: Left: No color coding of distances. Middle left: Distance to the bone. Middle right: Sum of the distance to the bone and the distance to the implant. Right: Infinitely thin slices without contours. </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="6,22.50,237.80,513.00,7.64;6,22.50,247.26,480.78,7.64"><head>Fig. 8. </head><figDesc>Fig. 8. Comparison of different glyph types and different strategies to adapt glyphs to changing distances: Left: Squeezed cylindrical glyphs, uniform seeding density. Middle: Squeezed arrow glyphs, uniform seeding density. Right: Scaled arrow glyphs, adaptive seeding density. </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="7,43.28,116.50,1.08,1.83;7,42.19,108.83,2.16,1.83;7,42.19,101.16,2.16,1.83;7,42.19,93.48,2.16,1.83;7,42.19,85.81,2.16,1.83;7,41.10,78.14,3.26,1.83;7,41.10,70.46,3.26,1.83;7,41.10,62.79,3.26,1.83;7,41.10,55.12,3.26,1.83;7,47.49,119.28,99.58,1.83;7,38.39,85.81,1.86,4.38;7,38.39,83.14,1.86,2.19;7,94.96,122.51,4.07,1.86;7,57.56,49.55,83.66,3.36;7,155.58,85.70,5.88,9.57;7,168.64,116.50,1.08,1.83;7,167.55,107.73,2.16,1.83;7,167.55,98.96,2.16,1.83;7,167.55,90.19,2.16,1.83;7,167.55,81.42,2.16,1.83;7,166.47,72.65,3.26,1.83;7,166.47,63.88,3.26,1.83;7,166.47,55.12,3.26,1.83;7,172.85,119.28,99.58,1.83;7,163.76,85.81,1.86,4.38;7,163.76,83.14,1.86,2.19;7,220.32,122.51,4.07,1.86;7,183.95,49.55,81.61,3.36;7,280.94,85.70,5.88,9.57;7,294.01,116.50,1.08,1.83;7,292.92,107.73,2.16,1.83;7,292.92,98.96,2.16,1.83;7,292.92,90.19,2.16,1.83;7,292.92,81.42,2.16,1.83;7,291.84,72.65,3.26,1.83;7,291.84,63.88,3.26,1.83;7,291.84,55.12,3.26,1.83;7,298.22,119.28,99.58,1.83;7,289.13,85.81,1.86,4.38;7,289.13,83.14,1.86,2.19;7,345.69,122.51,4.07,1.86;7,306.49,49.55,87.26,3.36;7,406.31,85.70,5.88,9.57;7,419.37,116.50,1.08,1.83;7,418.28,106.27,2.16,1.83;7,418.28,96.04,2.16,1.83;7,418.28,85.81,2.16,1.83;7,418.28,75.58,2.16,1.83;7,417.20,65.35,3.26,1.83;7,417.20,55.12,3.26,1.83;7,423.58,119.28,99.58,1.83;7,414.49,85.81,1.86,4.38;7,414.49,83.14,1.86,2.19;7,471.05,122.51,4.07,1.86;7,432.88,49.55,85.18,3.36;7,531.67,85.70,5.88,9.57"><head></head><figDesc>11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 Time (s) User Interactive Implant Positioning, Phantom, G2 Implant Color Glyphs Slices </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false" coords="7,31.50,225.84,250.38,77.91"><figDesc coords="7,31.50,225.84,28.00,7.64">Table 1.</figDesc><table coords="7,31.50,225.84,250.38,77.91">Average time (in seconds) needed by the users for interactive 
implant positioning (Experiment 1) dependent on the input device and 
the distance visualization method (columns), as well as on the implant 
shape (rows). 

Implant 
Color Glyphs 
Slices 
CUT 
0/0/30 19/11/0 11/19/0 
G2 
0/0/30 
5/25/0 
25/5/0 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false" coords="7,31.50,315.65,250.38,26.58"><figDesc coords="7,31.50,315.65,250.38,7.64;7,31.50,325.11,250.37,7.64;7,31.50,334.58,204.65,7.64">Table 2. Rankings of the distance visualization methods for interactive implant positioning (Experiment 1). The table shows the numbers of users that ranked the respective method first/second/third.</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false" coords="8,22.50,322.86,250.38,88.00"><figDesc coords="8,22.50,322.86,28.08,7.64">Table 4.</figDesc><table coords="8,22.50,322.86,250.38,88.00">Rankings of different glyph shapes as well as different strate-
gies to adapt glyphs to changing distances for interactive implant posi-
tioning and in still images (Experiment 3). The table shows the numbers 
of times each method was ranked first/second/third. 

Cylinders 
Arrows Arrows 
Squeezed Squeezed 
Scaled 
Time 
6.4 
7.2 
2.3 
Accuracy 
15% 
27% 
19% 

</table></figure>

			<note place="foot">Fig. 4. Distance rendering using oriented glyphs: Left: Rendering glyphs for all distances leads to visual cluttering. Right: By rendering glyphs only for distances up to a certain maximum value, visual cluttering can be avoided. is measured. There are distinct strategies to choose the radius of the cylinder: For example, by using a radius proportional to the cylinder&apos;s height, the glyph is scaled isotropically with a scaling factor proportional to distance. In contrast, by using a radius inverse proportional to the height (i.e., the product of radius and height is constant), the radius is increasing if the distance is decreasing, and vice versa. This suggests that the glyphs are clamped between the two surfaces, and that they are elastically deforming according to the relative movements of the surfaces , i.e., the glyphs are squeezed with decreasing distances. We use the latter strategy due to this intuitive—since physically plausible— relation between changes of distances and effects on the glyphs. In addition, for the considered medical application, small distance values are of high relevance. By increasing the radius with decreasing height, it is ensured that the glyphs representing small distances remain visi- ble. For the glyph-based approach, distances between the two surfaces are measured orthogonally to the implant surface and are determined by means of ray/triangle mesh intersection. By orienting the glyphs orthogonally to the implant surface, their orientations are changing smoothly with the implant surface, which enables an effective perception of the spatial relationships. In contrast, orienting the glyphs toward the respective closest point on the bone surface leads to abrupt changes of the glyphs&apos; orientations, which introduces visual clutter and makes perception of the spatial relationships rather difficult (see Figure 3). Since large distances are of minor relevance, we only render glyphs representing distances below a certain maximum value d max . In this way, we also avoid visual cluttering of the glyphs (see Figure 4). To avoid that glyphs suddenly pop up or disappear when the represented distance crosses d max , we fade out the glyphs by rendering them as semi-transparent objects. In particular, we linearly interpolate a glyph&apos;s alpha value from 1 to 0 for distances from d max /2 to d max . Furthermore, to avoid that the glyphs&apos; radii become arbitrary large, we clamp the radii at a certain maximum value r max . To ensure that glyphs do not overlap, we prescribe a minimum distance between each pair of seed points of δ = 2r max . We only render glyphs on those parts of the implant surface which are lying in the interior of the bone. To avoid that the glyphs are hidden by the bone surface, we render the bone meshes semi-transparently. If the implant sticks out of the bone surface, the implant is in a geometrically invalid position. Therefore, at the transition from bone interior to exterior and vice versa, we abruptly remove the glyphs (no fading out) to attract the attention of the user. In addition, we colorize the parts of the implant surface which are lying outside of the bone mesh using blue color, which is in high contrast to the other colors used for the bone and implant surfaces and the glyphs.</note>

			<note place="foot">DICK ET AL: DISTANCE VISUALIZATION FOR INTERACTIVE 3D IMPLANT PLANNING Bone Implant Bone Implant Fig. 5. Left: Distance measure (red) at points (yellow) in the volume between bone and implant (for simplicity, the 2D case is shown). Right: Approximation of this distance measure using distance fields (blue: bone distance field, magenta: implant distance field).</note>

			<note place="foot">Table 3. Rankings of the distance visualization methods in still images (Experiment 2). The table shows the numbers of times each method was ranked first/second/third. referring to 3D points that are not in the slicing plane, with increasing distances no immediate spatial correspondence is given between what is seen in the slice and the objects in the scene. In contrast, for the positioning of the significantly larger G2 implant (see Figures 11 and 12), the majority of the users indicated a strong preference of the slice-based approach over the glyph-based approach. Due to its large size, this implant has to be navigated in a very narrow surrounding, giving a rather homogeneous distance distribution on the implant. Here, it turns out that in situations were the distances between the implant and the bone are uniformly low, glyph-based approaches fail in clearly depicting these distances. In such cases the very fine differences in the distance values cannot be perceived effectively anymore, and the large number of glyphs everywhere on the implant induces visual clutter. Experiment 2. In the second experiment, we qualitatively evaluated the three distance visualization methods within 2D still images. We prepared 6 sets of images (see the additional material accompanying this paper), showing the two implants in 3 different (optimal and non-optimal) positions and from different view points. Each set consists of three images, each image showing the same implant in the same position and from the same view point, but each using a different distance visualization method. The three images of a set are simultaneously shown to the user on the monitor. With each user, we permuted the order in which the sets are presented, as well as the order of the images of each set on the screen. For each set, we asked the participant for a subjective ranking of the three visualization methods according to their capability to communicate spatial relationships and distances, analogous to Experiment 1. The rankings are given in Table 3. Interestingly, a different feedback was given than in Experiment 1. Still, both glyph-based and slice-based approaches are rated superior over the pure color coding approach. However, the results show that for 2D still images the slice-based approach is preferred by the users for both the CUT and the G2 implant. Since the slices, and the coloring on them, can very effectively depict the implant and the bone structure, in case of a 2D still image it seems very easy for our visual system to infer on the spatial relationships between the implant and the bone also in the regions between the slices. Furthermore, since slicing planes restrict the visualization to only a few regions in the domain, visual clutter is significantly reduced, giving a more undisturbed view on the relevant structures. Experiment 3. In the third experiment, we quantitatively and qualitatively evaluated the effect of differently shaped glyphs on the perception of spatial relationships and distances. Besides of the &apos;marshmallow&apos;-like cylindrical glyphs, we provided arrow glyphs where—analogous to the cylinders—the length of the arrow represents the distance, and the axis represents the directions along which the distance is measured. The glyphs were scaled either in the same way as for the cylindrical glyphs (a smaller distance results in a larger</note>

			<note place="foot" n="3"> sets of images showing the CUT implant. The rankings are shown in Table 4. The results show a clear preference of the users for the isotropically scaled arrow glyphs over the &apos;marshmallow&apos;-like cylindrical glyphs. In contrast to the dynamic view, where the arrow glyphs suffer from a limited visual coherence, in the static view the strength of arrows to better depict the glyphs&apos; orientation was observed a clear advantage over cylinders. Finally, we analyzed the different glyph options with respect to their capability to communicate absolute distances. We prepared three images , showing the CUT implant in different positions and from different view points. For each image, a different glyph option was used to depict the distances. In each image, 3 glyphs were labeled with the respective distances represented by these glyphs. The color scale was hidden from the participants. For each image, we then asked the participants to estimate the distances represented by another selected 5 glyphs, and we measured the time which was needed by the participants . The average times (per glyph) and estimation accuracies can be found in Table 5. Using isotropically scaled arrow glyphs, over 85% of the users could give the same quantitative estimate of absolute distance in one third of the time that was needed when cylindrical glyphs were used. 5.2 Technical Improvements After the study was finished, the users were asked for modifications or extensions they could imagine for improving the proposed distance visualization. A small number of users observed the change in saturation on the cap of the cylindrical glyphs when partially penetrating the white, semi-transparent bone surface mesh. Even though none of</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="10,40.76,661.31,232.12,7.22;10,40.76,670.78,232.12,7.22"  xml:id="b0">
	<analytic>
		<title level="a" type="main">Rainbow color map (still) considered harmful</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Borland</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">R</forename>
				<forename type="middle">M</forename>
				<surname>Taylor</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">Ii</forename>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer Graphics and Applications</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="14" to="17" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,40.76,680.24,232.12,7.22;10,40.76,689.71,232.11,7.22;10,40.76,699.17,213.21,7.22"  xml:id="b1">
	<analytic>
		<title level="a" type="main">Modeling and visualization of inter-bone distances in joints</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<forename type="middle">¸</forename>
				<surname>Demiralp</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">G</forename>
				<forename type="middle">E</forename>
				<surname>Marai</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Andrews</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">D</forename>
				<forename type="middle">H</forename>
				<surname>Laidlaw</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">J</forename>
				<surname>Crisco</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Grimm</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Visualization Progress</title>
		<meeting>. IEEE Visualization Progress</meeting>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="page" from="24" to="25" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,40.76,708.63,232.12,7.22;10,40.76,718.10,232.11,7.22;10,40.76,727.56,232.13,7.22;10,40.76,737.03,29.89,7.22"  xml:id="b2">
	<analytic>
		<title level="a" type="main">Computational steering for patient-specific implant planning in orthopedics</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Dick</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Georgii</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Burgkart</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Westermann</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Eurographics Workshop on Visual Computing for Biomedicine</title>
		<meeting>. Eurographics Workshop on Visual Computing for Biomedicine</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="83" to="92" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,303.38,53.99,232.12,7.22;10,303.38,63.46,232.11,7.22;10,303.38,72.92,77.27,7.22"  xml:id="b3">
	<analytic>
		<title level="a" type="main">Stress tensor field visualization for implant planning in orthopedics</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Dick</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Georgii</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Burgkart</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Westermann</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TVCG</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1399" to="1406" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,303.38,82.39,232.12,7.22;10,303.38,91.85,176.65,7.22"  xml:id="b4">
	<analytic>
		<title level="a" type="main">Meshsweeper &quot; : Dynamic point-to-polygonal-mesh distance and applications</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Guéziec</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TVCG</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="47" to="61" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,303.38,101.31,232.12,7.22;10,303.38,110.78,144.68,7.22"  xml:id="b5">
	<analytic>
		<title level="a" type="main">Fundamental issues of visual perception for effective image generation</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<forename type="middle">G</forename>
				<surname>Healey</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM SIGGRAPH Course</title>
		<imprint>
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,303.38,120.24,232.12,7.22;10,303.38,129.71,227.77,7.22"  xml:id="b6">
	<analytic>
		<title level="a" type="main">3D distance fields: A survey of techniques and applications</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<forename type="middle">W</forename>
				<surname>Jones</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">A</forename>
				<surname>Baerentzen</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Sramek</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TVCG</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="581" to="599" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,303.38,139.17,232.12,7.22;10,303.38,148.64,232.12,7.22;10,303.38,158.10,232.11,7.22;10,303.38,167.56,69.29,7.22"  xml:id="b7">
	<analytic>
		<title level="a" type="main">Estimating joint contact areas and ligament lengths from bone kinematics and surfaces</title>
		<author>
			<persName>
				<forename type="first">G</forename>
				<forename type="middle">E</forename>
				<surname>Marai</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Laidlaw</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">C</forename>
				<forename type="middle">¸</forename>
				<surname>Demiralp</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Andrews</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">C</forename>
				<forename type="middle">M</forename>
				<surname>Grimm</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">J</forename>
				<surname>Crisco</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Biomedical Engineering</title>
		<imprint>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="51790" to="799" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,303.38,177.03,232.12,7.22;10,303.38,186.50,162.42,7.22"  xml:id="b8">
	<analytic>
		<title level="a" type="main">Stencil routed A-buffer</title>
		<author>
			<persName>
				<forename type="first">K</forename>
				<surname>Myers</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">L</forename>
				<surname>Bavoil</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ACM SIG- GRAPH Technical Sketch Program</title>
		<meeting>. ACM SIG- GRAPH Technical Sketch Program</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page">21</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,303.38,195.96,232.12,7.22;10,303.38,205.43,206.63,7.22"  xml:id="b9">
	<monogr>
		<title level="m" type="main">Approaches to uncertainty visualization. The Visual Computer</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<forename type="middle">T</forename>
				<surname>Pang</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">C</forename>
				<forename type="middle">M</forename>
				<surname>Wittenbrink</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">S</forename>
				<forename type="middle">K</forename>
				<surname>Lodha</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="1997" />
			<biblScope unit="page" from="370" to="390" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,303.38,214.88,232.12,7.22;10,303.38,224.35,232.11,7.22;10,303.38,233.82,61.99,7.22"  xml:id="b10">
	<analytic>
		<title level="a" type="main">Integration of measurement tools in medical 3d visualizations</title>
		<author>
			<persName>
				<forename type="first">B</forename>
				<surname>Preim</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Tietjen</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">W</forename>
				<surname>Spindler</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">H.-O</forename>
				<surname>Peitgen</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Visualization</title>
		<meeting>. IEEE Visualization</meeting>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="21" to="28" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,303.38,243.28,232.12,7.22;10,303.39,252.75,232.12,7.22;10,303.39,262.21,212.97,7.22"  xml:id="b11">
	<analytic>
		<title level="a" type="main">Fast and flexible distance measures for treatment planning</title>
		<author>
			<persName>
				<forename type="first">I</forename>
				<surname>Rössling</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Cyrus</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">L</forename>
				<surname>Dornheim</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Boehm</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">B</forename>
				<surname>Preim</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Assisted Radiology and Surgery</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="633" to="646" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,303.38,271.67,232.12,7.22;10,303.39,281.14,232.11,7.22;10,303.38,290.60,100.07,7.22"  xml:id="b12">
	<analytic>
		<title level="a" type="main">GPU-based real-time discrete Euclidean distance transforms with precise error bounds</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Schneider</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Kraus</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Westermann</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. VISAPP</title>
		<meeting>. VISAPP</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="435" to="442" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,303.38,300.07,232.10,7.22;10,303.39,309.53,17.94,7.22"  xml:id="b13">
	<monogr>
		<title level="m" type="main">Visual Perception: A Clinical Orientation</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<forename type="middle">H</forename>
				<surname>Schwartz</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2004" />
			<publisher>McGraw-Hill</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,303.39,319.00,117.87,7.22"  xml:id="b14">
	<monogr>
		<title/>
		<author>
			<persName>
				<surname>Sensable</surname>
			</persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="10,303.39,328.46,232.12,7.22;10,303.39,337.92,181.24,7.22"  xml:id="b15">
	<monogr>
		<title level="m" type="main">Foundations of Binocular Vision: A Clinical Perspective</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<forename type="middle">B</forename>
				<surname>Steinman</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">B</forename>
				<forename type="middle">A</forename>
				<surname>Steinman</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">R</forename>
				<forename type="middle">P</forename>
				<surname>Garzia</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2000" />
			<publisher>McGraw-Hill</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,303.39,347.39,232.12,7.22;10,303.39,356.86,232.12,7.22"  xml:id="b16">
	<analytic>
		<title level="a" type="main">The control of low-level information flow in the visual system</title>
		<author>
			<persName>
				<forename type="first">K</forename>
				<surname>Suder</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">F</forename>
				<surname>Wörgötter</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Reviews in the Neurosciences</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">2-3</biblScope>
			<biblScope unit="page" from="127" to="146" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,303.39,366.32,232.11,7.22;10,303.39,375.79,232.12,7.22;10,303.39,385.25,232.10,7.22;10,303.39,394.71,142.78,7.22"  xml:id="b17">
	<analytic>
		<title level="a" type="main">Color-encoded distance visualization of cranial nerve-vessel contacts</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Süßmuth</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">W.-D</forename>
				<surname>Protogerakis</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Piazza</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">F</forename>
				<surname>Enders</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Naraghi</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">G</forename>
				<surname>Greiner</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Hastreiter</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Assisted Radiology and Surgery</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="647" to="654" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,303.39,404.18,232.12,7.22;10,303.39,413.64,214.10,7.22"  xml:id="b18">
	<analytic>
		<title level="a" type="main">Immediate perceptual response to intersensory discrepancy</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<forename type="middle">B</forename>
				<surname>Welch</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">D</forename>
				<forename type="middle">H</forename>
				<surname>Warren</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Bulletin</title>
		<imprint>
			<biblScope unit="volume">88</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="638" to="667" />
			<date type="published" when="1980" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
