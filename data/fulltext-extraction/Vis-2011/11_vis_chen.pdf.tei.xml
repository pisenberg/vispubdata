<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/pisenberg/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.4.1" ident="GROBID" when="2016-09-09T14:57+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">An Efficient Direct Volume Rendering Approach for Dichromats Labeling Consistency (e) (f) (c) (a)</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName>
								<forename type="first">Weifeng</forename>
								<surname>Chen</surname>
								<roleName>Student Member, Ieee</roleName>
							</persName>
						</author>
						<author>
							<persName>
								<forename type="first">Wei</forename>
								<surname>Chen</surname>
								<roleName>Member, Ieee</roleName>
							</persName>
						</author>
						<author>
							<persName>
								<forename type="first">Hujun</forename>
								<surname>Bao</surname>
							</persName>
						</author>
						<author>
							<affiliation>
								<orgName>(d)</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">An Efficient Direct Volume Rendering Approach for Dichromats Labeling Consistency (e) (f) (c) (a)</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract/>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Direct volume rendering (DVR) is an effective method used to display meaningful information from 3D scalar fields <ref type="bibr" coords="1,207.90,613.15,13.79,8.12" target="#b8">[10]</ref>. By assigning different opacities to various regions, DVR provides an exploratory preview of the underlying dataset without the explicit construction of an intermediate model. It is especially useful when semi-transparent effects are required to show the internal structures of a scalar field. The mappings from the scalar values to opacities are achieved by using an opacity transfer function, which is used to highlight important features while suppressing or hiding other regions. Designing an opacity transfer function is basically a volume classification problem, and plays a central role in volume visualization <ref type="bibr" coords="1,465.78,671.35,13.79,8.12" target="#b17">[18]</ref>. DVR involves another type of transfer function, namely, the color transfer function that specifies a color for each class when the opacity transfer function is selected. Using DVR <ref type="bibr" coords="1,481.02,706.39,13.79,8.12" target="#b15">[16]</ref>, the mapped colors and opacities are accumulated using a chosen color blending method (e.g. <ref type="bibr" coords="1,342.54,726.31,13.49,8.12" target="#b18">[19]</ref>). Thus the visualization result is heavily influenced by the color and opacity transfer functions, as well as the color composition mode. Despite continued research in color design <ref type="bibr" coords="2,255.66,53.35,13.79,8.12" target="#b27">[28]</ref>, transparency optimization <ref type="bibr" coords="2,122.10,63.31,10.43,8.12" target="#b3">[4] </ref>and color blending <ref type="bibr" coords="2,212.58,63.31,10.43,8.12" target="#b4">[5] </ref>for effective DVR, little attention has been paid to the color specification of the transfer function. Although well-studied color design principles <ref type="bibr" coords="2,263.22,83.23,9.68,8.12" target="#b2">[3,</ref><ref type="bibr" coords="2,22.50,93.19,11.99,8.12" target="#b22"> 23] </ref>can be applied to the color selection, perceptually deficient results may occur because the DVR process involves an additional transparency-modulated color composition process. This situation may be exaggerated when the visualization results are shown to persons with color vision deficiency (CVD) <ref type="bibr" coords="2,214.74,133.87,13.79,8.12" target="#b26">[27]</ref>. To address the challenging case, this paper proposes an approach that makes the DVR usable for those people. Instead of providing dichromats with a visualization system, we seek to modify the components of DVR to allow a user with normal vision to generate results perceivable by dichromats. This feature is especially useful because a high percentage of the population worldwide are affected by CVD <ref type="bibr" coords="2,209.70,193.75,13.70,8.12" target="#b24">[25]</ref>, and volume visualization has become a widely used communication and analysis tool for a variety of users. The task, however, is non-trivial because dichromats may miss the classification information shown in the DVR images. The main reason is that the color space of a dichromatic observer is much smaller than that of normal persons. A straightforward solution would be to choose the mapped colors of the transfer function in a CVD-friendly fashion <ref type="bibr" coords="2,104.70,274.27,9.51,8.12" target="#b2">[3]</ref>. However, choosing distinguishable colors may fail because the colors may be mixed into other colors within the opacity-weighted procedure, or even be dissolved due to the occlusions under varied viewing configurations. Alternatively, image recoloring techniques <ref type="bibr" coords="2,189.06,315.07,14.12,8.12" target="#b20">[21,</ref><ref type="bibr" coords="2,205.86,315.07,11.99,8.12" target="#b21"> 22] </ref>can be used to enhance the color distinguishability for dichromts. The pioneering work of Kuhn et al. <ref type="bibr" coords="2,100.50,334.99,14.99,8.12" target="#b10">[12] </ref>enhances the perceptibility of the volume visualization to a great degree and is further improved to preserve temporal coherence at a low cost <ref type="bibr" coords="2,150.54,354.91,13.79,8.12" target="#b12">[14]</ref>. Note that the DVR results exhibit internal structures generated by the transfer function, as well as their occlusion relationships. The image recoloring scheme solely relates to the composed colors in the image space, and consequently may lose this information even though certain image characteristics like the contrast <ref type="bibr" coords="2,84.42,404.83,14.99,8.12" target="#b12">[14] </ref>can be maintained. In some situations, it may suppress subtle details and lead to indistinguishable labeling (see <ref type="figure" coords="2,22.50,424.75,31.36,8.12">Figure 1</ref>(d)). Moreover, color-inconsistent results can occur when the viewpoint is dynamically changing (see <ref type="figure" coords="2,180.18,434.71,30.16,8.12">Figure 1</ref>(c-d)). Generally speaking, the image recoloring scheme is designed for still images, while volume visualization is an interactive and view-dependent process. In particular, the semi-transparent cue from the DVR results is unpredictable because its expressiveness is determined by multiple factors, namely, the mapped colors, opacities, lighting and their composition under certain viewing configuration. This complicates the CVD-friendly design in DVR, and consequently prevents the image recoloring scheme from being the perfect solution. In addition, the conventional color blending operation (i.e., the OVER operator in the RGB space) may lead to results that are observed as similar or even identical to one of the input colors by dichromats, and consequently induce an ambiguous perception of the volume classification information. <ref type="figure" coords="2,186.30,565.99,32.32,8.12">Figure 2</ref>compares the simulated perceptions of a deuteranope (second row) to the results by the conventional blending mode (first row) and our results (third row). Specifically, our results are generated by converting the input colors to the CVD-friendly space and employing a new color composition mode. When the opacity of the bottom left rectangle is 0.53, the simulated perception (the middle image of the second row) indicates that the top right rectangle is front of the other one, which is contradictory to the result by the conventional color blending operation (first row). The plots (see <ref type="figure" coords="2,171.42,655.75,32.56,8.12">Figure 2</ref>(b)) of the color differences (defined in Section 4.1) between two pixels A and B with respect to the opacity further confirm the deficiency of the second row: the plot in blue has a point of zero moment (i.e., the smallest difference appears when the opacity is 0.53), while the plot in red indicates that our results conform to the perception of the trichromats (i.e., the color difference is in approximate proportion to the opacity). We argue that a more sophisticated solution should take the components of the entire DVR pipeline into account, in which (a) From top to bottom: compositing two colored rectangles with respect to different composition opacities by using the conventional color blending mode; The simulated perceptions of deuteranopes with respect to the first row; our results. When the opacity of the bottom left rectangle is 0.53, the simulation gives false depth cue. (b) For results by the simulation and our approach, the color differences between two pixels A and B with respect to the opacity are plotted in blue and red, respectively. the image recoloring is an important, but not unique stage. This paper presents an optimization-based color design technique built upon the image recoloring scheme, and a novel CVD-friendly color composition mode with the following contributions: @BULLET A novel color optimization scheme, which modifies the mapped colors of the color transfer function by simulating the CVD-friendly effect obtained by the image recoloring scheme. @BULLET A new color composition mode that is performed in the reduced color space of dichromats, together with a new blending operator that preserves the perceptibility of the composition result. </p><p>Rather than introducing a novel color enhancement scheme, our approach complements the image recoloring scheme with a color optimization process and a CVD-friendly color composition mode. By integrating the new components into an interactive volume visualization system, our approach makes the DVR results more distinguishable for dichromats and also avoids the color inconsistence mentioned above (see <ref type="figure" coords="2,369.42,432.19,31.60,8.12">Figure 1</ref>and <ref type="figure" coords="2,421.26,432.19,30.23,8.12">Figure 2</ref>). Our approach does not modify the opacity transfer function, and attempts to maintain the classification information achieved by the users. In addition, the modified color transfer function is independent of the DVR pipeline, and can be reused in different volume visualization systems without changing the DVR algorithm. The entire solution is compatible with the conventional transfer function design and image recoloring methods, and favors effective communication among trichromats and dichromats. The rest of this paper is organized as follows. We briefly introduce some preliminary knowledge and related work in Section 2. Our approach is described in Section 3, followed by results and comparisons in Section 4. Conclusions and future work are given in Section 5. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">BACKGROUND AND RELATED WORK 2.1 The Dichromacy</head><p>The dichromats and anomalous trichromats are persons who are deficient in response to three types of cones of the human eye, named after their responses at long (L), medium (M) and short (S) wavelengths. The sensitivities with respect to these three wavelengths are used to characterize a color space, called the LMS space. Among Caucasians, it is estimated that 2.3% of male population are dichromats, and 5.7% of male population are anomalous trichromats. The numbers are 0.03% and 0.39% for the female population, respectively <ref type="bibr" coords="2,330.30,686.47,13.79,8.12" target="#b24">[25]</ref>. A dichromat may lose important information transmitted by chromatic colors. In other words, the LMS color space of a dichromat is much smaller than that of a person with normal vision. If two colors lead to the same color vision perception for a dichromat (see <ref type="figure" coords="2,285.06,736.27,31.84,8.12" target="#fig_2">Figure 3</ref>(a)), he or she cannot distinguish two objects labeled by these two colors, posing a challenging problem for visual labeling in visualization design. This also means that a dichromat cannot sense both aesthetic and semantics of the volume visualization without specific process. A number of simulation models <ref type="bibr" coords="3,168.06,309.19,9.68,8.12" target="#b1">[2,</ref><ref type="bibr" coords="3,182.10,309.19,11.12,8.12" target="#b14"> 15,</ref><ref type="bibr" coords="3,197.58,309.19,11.99,8.12" target="#b26"> 27] </ref>have been studied to simulate the dichromatic color perception for normal trichromats. Among them, the Brettel model <ref type="bibr" coords="3,154.74,329.11,10.43,8.12" target="#b1">[2] </ref>is the most popular one based on the reports of the unilateral dichromats (the ones with one dichromatic eye and one normal trichromatic eye) <ref type="bibr" coords="3,209.10,349.03,13.79,8.12" target="#b9">[11]</ref>. Geometrically, the perception capability of dichromats can be represented as two half-planes in the LMS color space (see <ref type="figure" coords="3,173.34,368.95,29.80,8.12" target="#fig_2">Figure 3</ref>(b)). The dichromatic perception of a color can be simulated by projecting it onto one half-plane. In this paper we use the Brettel model. Given a color denoted by <ref type="bibr" coords="3,139.26,398.28,29.48,8.97">[R, G, B] </ref>T in the RGB color space, the dichromatic simulation can be formulated as follows: </p><formula>  L M S   = T   R G B   ,   L d M d S d   = M cvd   L M S   ,   R d G d B d   = T −1   L d M d S d   (1) </formula><p>where T denotes the transformation between two color spaces. M cvd is a matrix that transforms the normal LMS values to the simulated LMS values. It is obtained from the Brettel model, and varies for different types of dichromacy. The subscript 'd' indicates that the associated variable is a simulated one of the dichromatic perception. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Color and Transparency in Volume Visualization</head><p>Volume visualization widely employs transparency-based modulation to show internal structures, which complicates the choice of color palette. In volume visualization, appropriate color design and transparency modulation are vital to enhance the perceptibility. The color design is subject to specific tasks <ref type="bibr" coords="3,229.62,576.91,13.70,8.12" target="#b22">[23]</ref>. Many principles have been proposed to provide usable color maps, like the ColorBrewer system <ref type="bibr" coords="3,148.86,596.83,9.51,8.12" target="#b2">[3]</ref>. In <ref type="bibr" coords="3,186.66,596.83,13.70,8.12" target="#b27">[28]</ref>, a knowledge-based system is proposed to capture established color design rules into a comprehensive interactive system. In particular, enhance the color accessibility for dichromats has attracted much attention in the image and video processing communities. A general approach is to transform colors from the color space of the normal trichromats to a reduced color space. This scheme has been successfully extended to volume visualization <ref type="bibr" coords="3,79.62,666.55,14.12,8.12" target="#b10">[12,</ref><ref type="bibr" coords="3,96.06,666.55,10.59,8.12" target="#b12"> 14]</ref>. Despite a large volume of literature on transfer function design, little attention has been paid to the transparency design issues in volume visualization. The psychology study indicates that the perceived transparency relates to the human perception, and is dependent on the lighting, color contrast and shape <ref type="bibr" coords="3,251.34,716.35,9.51,8.12" target="#b5">[7]</ref>. A physical model <ref type="bibr" coords="3,90.66,726.31,14.99,8.12" target="#b16">[17] </ref>is proposed to rationalize visual perception on transparency. A study reveals that the luminance is also important to express the transparency information <ref type="bibr" coords="3,444.30,53.35,9.51,8.12" target="#b6">[8]</ref>. In <ref type="bibr" coords="3,474.42,53.35,9.51,8.12" target="#b3">[4]</ref>, a suite of new measures based on psychological principles is studied to evaluate the perceptual quality of transparent structures in the DVR results. Of great importance in the context of volume visualization is the color blending operation. To maintain the hue component during the DVR, a perception-guided composition mode <ref type="bibr" coords="3,484.50,103.27,10.55,8.12" target="#b4">[5] </ref>is proposed. In this approach, the composition is performed in the color space of trichromats, and cannot be used to enhance the color perception for dichromats. Our approach employs a new CVD-friendly color composition mode that emphasizes the luminance profile of the image to enhance the transparency <ref type="bibr" coords="3,396.06,153.07,13.79,8.12" target="#b25">[26]</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Image Recoloring for Color Enhancement</head><p>Much work has been dedicated to the problem of image or video recoloring for dichromats. Existing color enhancement methods can be mainly categorized into rule-based and optimization-based approaches. The representative <ref type="bibr" coords="3,421.62,214.27,10.43,8.12">[6] </ref>of the first category uses a two-stage process: the red/green contrast is first increased, and then this information is used to adjust the brightness and blue/yellow contrast. Machado et al. <ref type="bibr" coords="3,386.94,244.15,14.87,8.12" target="#b14">[15] </ref>present a physiologically-based model that unifies the normal color vision, anomalous trichromacy, and dichromacy. Its simulation is fast: only one matrix multiplication is required for each pixel. In general, the rule-based scheme is computationally efficient, but is limited by the rules, and needs many parameter adjustments. Optimization-based methods seek to solve an objective function to achieve their goals. For instance, Rasche et al. <ref type="bibr" coords="3,468.42,313.99,14.99,8.12" target="#b20">[21] </ref>introduce a new way to preserve visual details while reducing the gamut dimension. The optimization is achieved by solving a quadratic objective function with constraints that enforce luminance consistency. Because the optimization process requires solving a large linear system, it is computationally inefficient. From the viewpoint of color mapping, computing the color transformation can be regarded as a dimension reduction problem in the color space. For instance, Ma et al. <ref type="bibr" coords="3,529.62,383.83,14.87,8.12" target="#b11">[13] </ref>employ a self-organizing color transformation (SOCT) to perform this task. In <ref type="bibr" coords="3,347.46,403.75,13.79,8.12" target="#b10">[12]</ref>, a mass-spring system is leveraged to optimize the distribution of the color in a set of quantized colors. The mass-spring system converges after several iterations, leading to better performance than previous methods. More recently, this technique was improved to support temporal coherent recoloring <ref type="bibr" coords="3,504.78,443.59,13.79,8.12" target="#b12">[14]</ref>. Our approach is built upon the image recoloring scheme, and advances it by incorporating the DVR pipeline into the color enhancement process. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">COLOR TRANSFER FUNCTION OPTIMIZATION AND COLOR</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>COMPOSITION </head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>DVR </head><p>involves three stages: specifying color and opacity transfer functions, sampling the scalar field, applying transfer functions and shading, and composing the colors and opacities. The image recoloring operation can be regarded as an additional process to the pipeline, and has to be performed for each frame (see <ref type="figure" coords="3,495.42,545.47,30.88,8.12" target="#fig_3">Figure 4</ref>(a)). In contrast, our approach employs an optimization process to modify the color transfer function, which needs to be done only once for a given transfer function. The optimization is guided by the results from the image recoloring operation, i.e., the visualization generated by the modified color transfer function is made as close as possible to the results from the image recoloring process (see <ref type="figure" coords="3,461.70,605.23,30.16,8.12" target="#fig_3">Figure 4</ref>(b)). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Optimizing the Color Transfer Function</head><p>For clarity, in this section we assume that the density of the underlying scalar field ranges from 0 to 255, and a one-dimensional transfer function is considered. The extension to higher data precision and multi-dimensional transfer function is straightforward. Suppose that there is an opacity transfer function T T T o o o and a color transfer function T T T c c c , which have M (i.e., 256) opacity entries and RGB-triples, respectively. The DVR result is denoted as I d at the image size of N (e.g., 512 × 512). Applying the image recoloring technique <ref type="bibr" coords="3,333.42,716.35,14.87,8.12" target="#b12">[14] </ref>For each pixel in a DVR image, its color is accumulated from a set of colors and opacities with the following composition operator <ref type="bibr" coords="4,257.94,316.99,14.99,8.12" target="#b15">[16] </ref>in a back-to-front order: </p><formula>C ′ i = α i C i + (1 − α i )C ′ i−1 (2) </formula><p>where α i and C i are the opacity and color of the ith sample after applying the transfer function T T T o o o and T T T c c c , respectively. The final accumulated color can be written as <ref type="bibr" coords="4,153.42,378.55,13.99,8.12" target="#b8">[10]</ref>: </p><formula>C = S ∑ i=1 α i C i i−1 ∏ j=1 (1 − α j ) (3) </formula><p>where S denotes the sample number. Let {C m , m = 1, 2, 3, ...M} be the color set of the underlying color transfer function. Applying the color transfer function to the ith sample is identical to mapping the sample to a linear combination of </p><formula>C m (m = 1, 2, ..., M): ∑ M m=1 θ m,i C m , where θ m,i denotes the weight of C m (m = 1, 2, ..., M). </formula><p>The color of the ith sample is a result of applying the color transfer function and computing its illumination using the volumetric optical model <ref type="bibr" coords="4,114.66,496.51,13.99,8.12" target="#b15">[16]</ref>: </p><formula>C i = β i M ∑ m=1 θ m,i C m (4) </formula><p>where β i denotes the volumetric illumination computed at the ith sample. Substituting Equation 4 to Equation 3 and rewriting Equation 3 as a sum of C m , yields: </p><formula>C = M ∑ m=1 C m S ∑ i=1 θ m,i β i α i i−1 ∏ j=1 (1 − α j ) (5) </formula><p>We define </p><formula>ω m = ∑ S i=1 θ m,i β i α i ∏ i−1 j=1 (1 − α j )</formula><p>, which is the accumulated weight associated with C m . From Equation 5, it is apparent that ω m is determined by the opacity transfer function T T T o o o and the volumetric illumination. Therefore, it only needs to be computed once during the optimization of {C m , m = 1, 2, 3, ...M}. Let Ct * m (m = 1, 2, ..., M) be the color triples of the intended transfer function T T T * c c c . For each pixel p k (k = 1, 2, ..., N), the color Cd * k at p k in I * d can be expressed as a linear combination of Ct * m : </p><formula>Cd * k = M ∑ m=1 ω m,k Ct * m , k = 1, 2, ..., N (6) </formula><p>where ω m,k (m = 1, 2, ..., M) are the accumulated weights associated </p><formula>with Ct * m (m = 1, 2, ..., M) at pixel p k . By treating Ct * m (m = 1</formula><p>, 2, ...M) as unknown, Equation 6 can be regarded as an over-determined equation set given that N ≫ M. This yields a linear system: </p><formula>arg min E 1 = arg min N ∑ k=1 (Cd * k −Cr k ) 2 = arg min N ∑ k=1 ( M ∑ m=1 ω m,k Ct * m −Cr k ) 2 (7) </formula><p>where Cr k is the color at p k in I r . Another concern is that the optimized transfer function T T T * c c c be as close as possible to the initial one T T T c c c because it is usually expected that the assigned colors are preserved after the optimization. Accordingly, we design another item: </p><formula>arg min E 2 = arg min M ∑ m=1 δ m (Ct * m −Ct m ) 2 (8) </formula><p>where δ m is a binary parameter specified by the user to indicate whether the mth color item should be preserved or not. Weighting two items in Equation 7 and Equation 8 with an adjustable parameter λ leads to: </p><formula>arg min E = arg min((1 − λ ) E 1 N + λ E 2 M ) (9) </formula><p>Here, the smaller λ is, the yielded DVR result is closer to I r . In our implementation, λ is initialized to be 0. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.1">Solving the linear system</head><p>Note that a volume classification derived from the opacity transfer function design yields a small number of classes. From the viewpoint of the color design <ref type="bibr" coords="4,361.62,656.59,9.68,8.12" target="#b2">[3,</ref><ref type="bibr" coords="4,375.42,656.59,10.59,8.12" target="#b27"> 28]</ref>, usually the number of color labels is smaller than 8. To perform visual labeling in DVR, a user chooses a set of distinct colors. The number of the selected colors is typically small, e.g., 4 in the example shown in <ref type="figure" coords="4,425.58,686.47,29.38,8.12">Figure 1</ref>. The pixel number N determines the number of equations in Equation 6, and the color set </p><formula>Ct * m , m = 1</formula><p>, 2, 3, ...M of T T T * c c c denotes the variable set. If all N pixels in a DVR result are employed, the linear system becomes a large over-determined minimization problem. To reduce the complexity of the linear system, we randomly sample N r pixels and </p><formula>(a) (b) (c) (d) </formula><p>(b) are (184,178,110) and (177,176,65) in RGB-triple, respectively. The colors in <ref type="figure" coords="5,80.22,418.53,29.51,7.64" target="#fig_4">Figure 5</ref>(a) and </p><p>(b) are (178,173,40) and (191,183,168), respectively. in the DVR image. Before sampling, we eliminate the background pixels since they do not contribute to the linear system (Equation 7). Mathematically, N r should be greater than M to avoid an undetermined equation set which has infinite solutions. In our experiments N r is set to be 200, which produces satisfying results. With the schemes mentioned above, the computational complexity is greatly reduced: the size of the linear system decreases from 512 2 × 256 to approximately 200 × 8 (i.e., N r = 200, M = 8). The optimization in Equation 9 is solved by using the least-squares method <ref type="bibr" coords="5,60.66,540.91,13.70,8.12" target="#b19">[20]</ref>. Solving this linear system can be done very efficiently. We denote the DVR result generated with the optimized transfer function T T T * c c c as I * d . The entire optimization process is illustrated in <ref type="figure" coords="5,31.50,571.39,30.76,8.12" target="#fig_3">Figure 4</ref>(b). <ref type="figure" coords="5,82.74,571.39,30.76,8.12" target="#fig_4">Figure 5</ref>depicts the influence of the sampling number N r on the final result I * d with λ = 0 in Equation 9. It can be seen that the final results in (b-d) are similar with the change of N r from 50 to 1000. The main reason is that the linear system (Equation 7) is over-determined (N r is much larger than the color number). Color Preservation In <ref type="figure" coords="5,122.22,621.91,28.78,8.12" target="#fig_4">Figure 5</ref>, the color of the lung part (indicated by a red circle) is changed to grey after the optimization when the color preservation is not used (λ in Equation 9 is set to be 0). By changing λ to 0.3 or 0.7, different results that preserve the color to a certain degree are obtained (see <ref type="figure" coords="5,149.58,661.75,29.39,8.12" target="#fig_5">Figure 6</ref>). The average colors in the red circles of <ref type="figure" coords="5,82.38,671.71,30.76,8.12" target="#fig_4">Figure 5</ref>(a-b) and <ref type="figure" coords="5,152.10,671.71,30.76,8.12" target="#fig_5">Figure 6</ref>(a-b) indicate that using λ can effectively modulate the degree of color preservation during the optimization. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.2">Multi-view Optimization</head><p>DVR is a view-dependent process. The color optimization approach described above only considers the solution under a single view. In some situations, the classification information shown in a DVR image is incomplete because of 3D occlusion, like the example shown in <ref type="figure" coords="5,294.06,278.35,30.52,8.12" target="#fig_6">Figure 7</ref>(a). The corresponding color optimization process may lead to unpleasing results (see <ref type="figure" coords="5,386.70,288.31,30.16,8.12" target="#fig_6">Figure 7</ref>(d)</p><p>). An entropy-based view selection <ref type="bibr" coords="5,433.02,298.27,10.43,8.12" target="#b0">[1] </ref>scheme may improve the selection of the best view for constructing the linear system, which has the potential to track all the non-zero coefficients ω m of the colors Ct * m (m = 1, 2, ..., M) in the color transfer function T T T * c c c . In our implementation, the views can be manually specified or automatically selected by assigning uniformly sampled viewing angles. The constraints obtained under additional views are added to the linear system. Our solution for the multi-view optimization takes three stages. First, multiple DVR results (see <ref type="figure" coords="5,412.38,387.91,30.52,8.12" target="#fig_6">Figure 7</ref>(b)) are generated, for each of which a linear system with respect to Equation 7 is built. Then, the linear systems are integrated by putting all constraints of each linear system together. The energy item E1 of the final linear system has the following form: </p><formula>arg min E1 = arg min H ∑ h=1 N r,h ∑ k=1 ( M ∑ m=1 ω m,k Ct * m −Cr k ) 2 (10) </formula><p>where H is the number of views considered in the multi-view optimization, and N r,h is the number of the sampled pixels with respect to the hth view. Solving the integrated system yields a result that considers the influences from multiple views. Suppose that there are 4 views, the size of the integrated linear system is 4 times larger than the size of a linear system. The effect using the multi-view optimization is shown in <ref type="figure" coords="5,303.30,547.03,30.16,8.12" target="#fig_6">Figure 7</ref>(e). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">CVD-friendly Color Composition</head><p>Transparency plays an important role in the usage of DVR for illustrating the internal structures of the underlying scalar field. The semi-transparent effect of the DVR is achieved by employing the conventional opacity-modulated color composition (Equation 2) that is performed in the color space for trichromats. The Brettel model that simulates the perception of dichromats applies a non-linear Gamma transformation to the RGB-triple input color. As a result, the composited colors from the conventional color blending mode may be mapped into a similar or identical color, causing possible information loss (see <ref type="figure" coords="5,327.54,666.55,29.27,8.12">Figure 2</ref>). Below we present two new techniques to address this problem. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1">CVD-friendly Color Blending</head><p>The research on dichromacy (see Section 2.1) indicates that the color space of dichromats is very limited, and can be represented by two half-planes in the LMS color space, and be further simplified into one plane in the CIE L*a*b* space <ref type="bibr" coords="5,408.90,736.27,13.79,8.12" target="#b10">[12]</ref>. <ref type="bibr" coords="6,179.46,173.13,13.26,7.64" target="#b12">[14] </ref>to the DVR results produced from four viewpoints, of which A corresponds to (a). The sampling pixels are shown as white crosses. (c-d) The DVR results by using the optimized color transfer function obtained from A in (b); (e) The result by employing the multi-view optimization scheme with the four images in (b). </p><formula>(b) A C B D (a) (c) (e) (d) </formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Inspired </head><p>by the hue-preserving color blending mode <ref type="bibr" coords="6,225.06,223.51,9.51,8.12" target="#b4">[5]</ref>, the color composition should be performed in the reduced color space of dichromats to prevent the result from being outside the space and meanwhile make it distinguishable for dichromats. We propose to perform the linear combination of two colors with respect to the geodesic distance on the two half-planes (see <ref type="figure" coords="6,185.10,273.31,29.92,8.12">Figure 8</ref>(b)). Compared to conventional linear combination that is performed in the 3D LMS space, this scheme ensures that the result lies in the two half-planes. The algorithm is given in Algorithm 1. Algorithm 1 CVD-friendly color blending for two colors C i and C ′ i−1 represented with RGB-triples, and an opacity α i , where C i , C ′ i−1 and α i are of the same meanings as in Equation 2. </p><formula>X i = M cvd × RGB2LMS(C i ); X ′ i−1 = M cvd × RGB2LMS(C i−1 ); IF X i and X ′ i−1 </formula><p>are on the same half-plane </p><formula>X ′ i = α i X i + (1 − α i )X ′ i−1 ; ELSE Path = GeodesicPath(X i , X ′ i−1 ); X p = Intersect(Path, L AB ); α p = DIS(X p ,X ′ i−1 ) DIS(X p ,X i )+DIS(X p ,X ′ i−1 ) ; IF α i &gt; α p X ′ i = α i −α p 1−α p X i + 1−α i 1−α p X p ELSE X ′ i = α p −α i α p X ′ i−1 + α i α p X p END IF END IF C ′ i = LMS2RGB(X ′ i ) </formula><p>*The function RGB2LMS transforms a color in the RGB color space to the LMS color space. *The function LMS2RGB transforms a color in the LMS color space to the RGB </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2">Luminance Consistency</head><p>The CVD-friendly blending can generate results with a unique luminance. However, the reduced color space of dichromats (i.e., the two half-planes), is not uniformly distributed. A region (e.g., the region marked by a green star) that is near the intersection line E in </p><formula>O (Black) 575nm 475nm O (Black) W (White) R G B (a) (b) E Fig. 8. </formula><p>The conventional OVER operator performs a 3D linear combination (a) in the RGB space. Because of the Gamma correction used in the Brettel model, the interpolation path in (a) corresponds to a curve in the LMS space (the yellow one in (b)). Simulating the dichromatic perception is equal to projecting the curve onto the two half-planes, yielding the dashed curve in yellow. The transform-and-project operation may make the result similar or even identical to one of the input colors, as demonstrated in <ref type="figure" coords="6,490.02,475.29,29.25,7.64">Figure 2</ref>. In contrast, our approach performs the interpolation along the geodesic path lying on the two half-planes (see the dashed red line in (b)). red is more compact than a region (e.g., the region marked by a yellow star) that is far from E, as shown in <ref type="figure" coords="6,416.70,536.47,30.52,8.12">Figure 8</ref>(b). This is because the simulated perception of dichromats is obtained by mapping the LMS space to two half-planes with a warping transformation (Equation 1), which leads to a distortion. This also causes a luminance-inconsistent composition result. We propose to employ an additional process to modify the luminance channel L * of the L * a * b * -triple after the color composition (Algorithm 1) is performed: </p><formula>L * (C ′ i ) = α i L * (C i ) + (1 − α i )L * (C ′ i−1 ) (11) </formula><p>where L * (·) denotes the conversion from a RGB-triple to the L * color channel. C i , C ′ i−1 , and α i are of the same meanings as in Equation 2. <ref type="figure" coords="6,295.14,666.55,30.40,8.12" target="#fig_7">Figure 9</ref>(a) is a DVR result generated with the conventional color blending mode. <ref type="figure" coords="6,348.78,676.51,31.36,8.12" target="#fig_7">Figure 9</ref>(b) shows the simulated perception for a deuteranope based on (a). Due to the color coincidence induced by the limited perception, the boundary between dentin and pulp dissolves in <ref type="figure" coords="6,332.22,706.39,31.60,8.12" target="#fig_7">Figure 9</ref>(b). With the proposed new blending mode, the boundary becomes recognizable (see <ref type="figure" coords="6,435.06,716.35,30.52,8.12" target="#fig_7">Figure 9</ref>(c)). However, the luminance of the blended color is much lighter than expected, making the visualization over-blurred. An additional optimization aiming at The DVR with the conventional over operator in the RGB space; (b) The simulated perception of a deuteranope based on (a); (c) The DVR with the CVD-friendly color blending in the LMS space (Section 3.2.1); (d) Enhancing (c) with the luminance consistency scheme described in Section 3.2.2. luminance consistency further improves the perception of the result, as shown in <ref type="figure" coords="7,75.90,256.03,30.04,8.12" target="#fig_7">Figure 9</ref>(d). Note that a person with the normal vision can observe the internal structures of a semi-transparent DVR result by means of the chromatic information, even with the conventional color blending mode. However, this does not hold for dichromats due to the limitation of the reduced color space. Our approach outperforms existing solutions in the sense that not only the distinguishability is maintained by employing a new CVD-friendly blending mode, but also the luminance consistency is preserved thanks to the luminance correction scheme. </p><formula>(a) (d) (b) (c) </formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">RESULTS</head><p>We implemented our approach in Microsoft Visual C++ and tested on a number of datasets on a PC equipped with an Intel double-core 3.0 GHz CPU, 3 GB host memory and an Nvidia GeForce GTX 280 video card with 1 GB video memory. The dataset configuration is listed in <ref type="figure" coords="7,41.70,419.95,26.26,8.12" target="#tab_1">Table 1</ref>shows the results using a 2-D transfer function (intensity vs. gradient magnitude). Other results using a 2-D transfer function with shading are demonstrated in <ref type="figure" coords="7,40.74,479.71,34.60,8.12">Figure 10</ref>(d-f). In our current implementation, we performed the optimization of the color transfer function on CPU, and modified the pipeline of a CUDA accelerated volume renderer to achieve CVD-friendly color composition. The transfer function optimization can be completed very quickly: the calculation of the coefficients ω m can achieve a rate of 20k pixels per second for the results without shading, and 4k pixels per second for the ones with shading. For a typical configuration that N r = 200 and M = 4 for Equation 9, the least-squares solver takes less than 0.1 second. More performance statistics using different configurations of N r and M are shown in <ref type="figure" coords="7,185.58,579.79,26.14,8.12" target="#tab_2">Table 2</ref>. Because the new color composition is performed whenever two colors are mixed, the overhead of the new color composition is about 15% FPS decrease. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Quantitative Evaluation</head><p>The global chromatic diversity (GCD) in an image perceived by dichromats is computed as the average of the color differences between every pair of pixels. In <ref type="bibr" coords="7,176.10,652.87,13.70,8.12" target="#b11">[13]</ref>, the efficiency of the recoloring algorithm is evaluated by comparing the global chromatic diversities of the input image and recolored image. A common definition of the color difference employs the Euclidean distance in a device-independent color space, e.g., the CIE L*a*b* color space. Given two colors </p><formula>C i (L * i , a * i , b * i ) and C j (L * j , a * j , b * j )</formula><p>, the color difference DIS is defined as: <ref type="figure" coords="7,294.06,274.29,26.61,7.64" target="#tab_3">Table 3</ref>. The global chromatic diversities of the DVR results, the simulation to the DVR images, the results of applying the image recoloring algorithm <ref type="bibr" coords="7,366.54,293.13,13.26,7.64" target="#b12">[14] </ref>to the DVR images, and our results. <ref type="figure" coords="7,330.78,303.72,14.53,6.32">Fig.1</ref><ref type="figure" coords="7,353.70,303.72,14.53,6.32" target="#fig_3">Fig.4</ref><ref type="figure" coords="7,374.22,303.72,14.53,6.32" target="#fig_4">Fig.5</ref><ref type="figure" coords="7,394.74,303.72,14.53,6.32" target="#fig_6">Fig.7</ref><ref type="figure" coords="7,418.14,303.72,14.53,6.32" target="#fig_7">Fig.9</ref><ref type="figure" coords="7,442.26,303.72,18.01,6.32">Fig.10</ref><ref type="figure" coords="7,467.58,303.72,18.01,6.32" target="#fig_11">Fig.11</ref><ref type="figure" coords="7,492.30,303.72,18.01,6.32" target="#fig_12">Fig.12</ref><ref type="figure" coords="7,516.30,303.72,18.01,6.32" target="#fig_2">Fig.13</ref>DVR DIS(i, j) ≈ 2.3 corresponds to a JND (just noticeable difference) of two colors <ref type="bibr" coords="7,333.90,383.47,13.70,8.12" target="#b23">[24]</ref>. <ref type="figure" coords="7,304.14,393.79,27.52,8.12" target="#tab_3">Table 3</ref>lists the global chromatic diversities of the DVR results, the simulated perception of a deuteranope to the DVR images, the results of applying the image recoloring algorithm <ref type="bibr" coords="7,483.42,413.71,14.99,8.12" target="#b12">[14] </ref>to the DVR images, and our results. From the statistics, we conclude that the image recoloring algorithm <ref type="bibr" coords="7,399.42,433.63,14.99,8.12" target="#b12">[14] </ref>produces images with the highest GCD values because it is designed to achieve high color contrast. By optimizing the color transfer function, our approach maintains the color consistency during interactive volume exploration, and meanwhile preserves relatively high GCD. </p><formula>DIS(i, j) = (L * i − L * j ) 2 + (a * i − a * j ) 2 + (b * i − b * j ) 2 </formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Data </head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">User Evaluation</head><p>A set of tests were performed with 25 volunteers, of which 5 subjects have color vision deficiency and 20 subjects are normal trichromats. All subjects are well educated and are familiar with computers. 96% of them had no experience with volume visualization. The persons with color vision deficiency are further classified into 3 deuteranomalous and 2 deuteranopes with the Ishihara test <ref type="bibr" coords="7,449.10,556.27,9.51,8.12" target="#b7">[9]</ref>. All the graphics user interfaces of our system and DVR results were displayed on a 24-inch wide LCD monitor at the sRGB mode. The first test was designed to verify the effectiveness of the proposed color blending mode. Each subject was presented a sequence of side-by-side result comparisons of the conventional blending mode (Equation 2) and our method for the example shown in <ref type="figure" coords="7,512.46,616.39,32.08,8.12">Figure 2</ref>(a). With changes of the opacity of the front rectangle from 0 to 1, the color of the overlapped region is changing from the color of the back rectangle to the color of the front one. In this test, all subjects noticed the discontinuous color transition in the overlapped region by the conventional blending mode (see <ref type="figure" coords="7,463.86,666.19,30.16,8.12">Figure 2</ref>and the video demonstration). The second test compared the image recoloring scheme and our approach. In particular, the algorithm presented in <ref type="bibr" coords="7,510.78,696.43,14.87,8.12" target="#b12">[14] </ref>that can achieve real-time performance and temporal coherent image recoloring effects was studied. Its key idea is to preserve the color contrast while the colors are converted to the color space of the dichromats. Each subject was allowed to freely interact with our volume visualization system, such as rotating the rendered dataset. Most of them thought that the color contrast is preserved with the image recoloring algorithm <ref type="bibr" coords="8,130.98,373.75,13.79,8.12" target="#b12">[14]</ref>, while our approach achieves a relatively lower color contrast. When there are more than 3 classes in the DVR, 22 out of 25 subjects observed that the results produced by the algorithm <ref type="bibr" coords="8,84.42,403.63,14.99,8.12" target="#b12">[14] </ref>exhibit color inconsistency like the one shown in <ref type="figure" coords="8,22.50,413.59,30.04,8.12">Figure 1</ref>(c-d). All subjects agreed that our results effectively preserve the coherence and avoid the color inconsistency. </p><formula>(a) (b) (c) (d) (e) (f) </formula><formula>(c) (b) (a) (e) (f) (d) </formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Discussions</head><p>Our approach can be regarded as an improvement to the image recoloring scheme in the context of DVR, rather than a new color design or color configuration solution. The basic motivation of the image recoloring operation is to preserve or even amplify the color contrast. Specifically, the image recoloring algorithm <ref type="bibr" coords="8,224.82,496.51,14.99,8.12" target="#b12">[14] </ref>seeks to find a vector V ab in the CIE L*a*b* space which induces the largest contrast loss, and then scale and project the input colors onto the plane defined by L* and V ab . It leverages an additional technique to preserve the temporal coherence. Yet, its main drawback in the context of DVR is that it solely maximizes the color contrast in the image space, and may sacrifice the image continuity in the boundary regions or when a semi-transparent effect is employed. <ref type="figure" coords="8,199.14,566.23,35.20,8.12" target="#fig_12">Figure 12</ref>(b) shows an example where a sharp discontinuity appears at the boundary of a ring-like object. In contrast, our approach inherently avoids the color inconsistency and preserves the temporal coherence by optimizing the color transfer function. Due to the use of a color accumulation procedure, our approach is capable of preserving important structural information that has been captured in the volume classification stage. Similar to <ref type="figure" coords="8,61.14,635.95,34.96,8.12" target="#fig_12">Figure 12</ref>(a), the structure visible in <ref type="figure" coords="8,197.46,635.95,34.96,8.12" target="#fig_12">Figure 12</ref>(c) gives a continuous visual cue. Note that our approach is compatible with all image recoloring approaches. As shown in <ref type="figure" coords="8,118.86,666.19,33.69,8.12" target="#fig_2">Figure 13</ref>, one image recoloring approach fails to enhance the contrast for the deuteranope, while another one works well. In solving Equation 9, N r pixels are sampled to construct the objective function. Using this scheme, it is possible that the coefficient of one color in the transfer function is not caught. In practice, using an adequately large N r (&gt;1000) can mostly eliminate this problem. A more sophisticated solution will be studied in the future. </p><p>In contrast to the image-based recoloring techniques <ref type="bibr" coords="8,490.02,353.83,14.24,8.12" target="#b10">[12,</ref><ref type="bibr" coords="8,507.18,353.83,11.87,8.12" target="#b12"> 14] </ref>that increase the color contrast, our approach generally lowers the color contrast. This is because ours attempts to treat the color of each pixel as an accumulation of the colors of the samples. Thus, in some situations our approach cannot produce satisfactory results by solving the linear system in Equation 9. In addition, our approach cannot yield improvement when the initial DVR is suitable for dichromats. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">CONCLUSIONS</head><p>In this paper, we have described a new DVR approach that can produce satisfactory results for dichromats. Our approach reconfigures the DVR pipeline by combining the image recoloring scheme with a new color optimization technique and a color composition mode. The integrated DVR system achieves interactive performance, and produces pleasing results that reveal correct occlusion information and preserve as much visual detail as possible for dichromats. Experimental results and user evaluation demonstrate that our approach can yield dichromats-friendly and consistent volume visualization. In the future, we plan to explore more color and transparency design schemes to make volume visualization usable for persons with other disabilities or even children. The automatic view selection can be performed by employing the entropy-based scheme <ref type="bibr" coords="8,482.34,590.95,9.51,8.12" target="#b0">[1]</ref>. Studying appropriate automatic view selection schemes is one avenue of future work. In addition, we plan to explore a sophisticated and efficient sampling strategy. A small N r may be insufficient when the image size of the DVR is large. We also plan to investigate appropriate means to extend our approach to illustrative visualization. </p><formula>(a) (b) (c) (d) </formula></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="2,285.06,160.41,250.47,7.64;2,285.06,169.89,250.41,7.64;2,285.06,179.37,250.43,7.64;2,285.06,188.73,250.38,7.64;2,285.06,198.21,250.34,7.64;2,285.06,207.69,250.31,7.64;2,285.06,217.17,250.50,7.64;2,285.06,226.65,43.14,7.64"><head></head><figDesc>Fig. 2. (a) From top to bottom: compositing two colored rectangles with respect to different composition opacities by using the conventional color blending mode; The simulated perceptions of deuteranopes with respect to the first row; our results. When the opacity of the bottom left rectangle is 0.53, the simulation gives false depth cue. (b) For results by the simulation and our approach, the color differences between two pixels A and B with respect to the opacity are plotted in blue and red, respectively. </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="3,31.50,228.69,250.26,7.64;3,31.50,238.17,246.06,7.64"><head>Fig. 3. </head><figDesc>Fig. 3. (a) Different colors may be observed as identical for a dichromat; (b) The geometric representation of the LMS space for dichromats [2]. </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="4,22.50,266.61,513.12,7.64;4,22.50,276.09,513.03,7.64;4,22.50,285.57,127.02,7.64"><head>Fig. 4. </head><figDesc>Fig. 4. Comparison between the image recoloring scheme (a) and our approach (b). In (b), the two steps indicated with the italic fonts are two new components introduced in our approach, and are described in Section 3.1 and Section 3.2. The symbols shown on the top of (b) are the variables used in the color optimization stage. </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4" coords="5,31.50,218.02,513.02,8.47;5,31.50,226.04,5.99,9.03;5,38.10,226.04,347.87,9.93;5,386.58,227.50,157.91,8.47;5,31.50,235.52,310.07,9.93;5,342.18,236.90,184.02,8.43"><head>Fig. 5. </head><figDesc>Fig. 5. The influence of the sampled pixels on the optimization result. (a) The DVR result I d and the associated color transfer function; (b-d) Results I * d with different numbers: 50, 200, and 1000, respectively. The snapshot on the top of each image I * d denotes I r that is generated by applying the image recoloring to I d , and randomly sampled pixels' positions. The optimized colors Ct * m (m = 1,2,3,4) are shown on the top of each image. </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5" coords="5,31.50,390.09,250.38,7.64;5,31.50,399.40,250.33,8.07;5,31.50,409.05,250.26,7.64;5,31.50,418.53,250.38,7.64;5,31.50,428.01,43.14,7.64"><head>Fig. 6. </head><figDesc>Fig. 6. The optimization configuration is the same as Figure 5 except that (a) λ = 0.3; (b) λ = 0.7. The average colors in the red circles of (a) and (b) are (184,178,110) and (177,176,65) in RGB-triple, respectively. The colors in Figure 5 (a) and (b) are (178,173,40) and (191,183,168), respectively. </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6" coords="6,22.50,163.65,512.91,7.64;6,22.50,173.13,512.99,7.64;6,22.50,182.61,513.02,7.64;6,22.50,192.09,257.45,7.64"><head>Fig. 7. </head><figDesc>Fig. 7. Illustration of the multi-view optimization with the Four-sphere Phantom dataset. (a) The DVR result from a certain viewpoint. (b) The results by applying the image recoloring algorithm [14] to the DVR results produced from four viewpoints, of which A corresponds to (a). The sampling pixels are shown as white crosses. (c-d) The DVR results by using the optimized color transfer function obtained from A in (b); (e) The result by employing the multi-view optimization scheme with the four images in (b). </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7" coords="7,31.50,168.09,250.31,7.64;7,31.50,177.57,250.31,7.64;7,31.50,187.05,250.31,7.64;7,31.50,196.53,250.33,7.64;7,31.50,206.01,250.43,7.64;7,31.50,215.49,48.66,7.64"><head>Fig. 9. </head><figDesc>Fig. 9. Result comparison for the Tooth dataset. (a) The DVR with the conventional over operator in the RGB space; (b) The simulated perception of a deuteranope based on (a); (c) The DVR with the CVD-friendly color blending in the LMS space (Section 3.2.1); (d) Enhancing (c) with the luminance consistency scheme described in Section 3.2.2. </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8" coords="7,67.96,419.40,213.82,8.97;7,31.50,429.91,250.36,8.12;7,31.50,439.87,250.24,8.12;7,31.50,449.83,161.39,8.12"><head></head><figDesc>. All images are rendered at the resolution of 512 × 512. Figure 10 and Figure 11 show the results for the Feet, Tooth, Head and Schaedel datasets. All results except Figure 10 are generated with 1D transfer functions. Figure 10 (a-c) </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10" coords="8,22.50,163.41,513.02,7.64;8,22.50,172.89,512.99,7.64;8,22.50,182.37,28.26,7.64"><head>Fig</head><figDesc>Fig. 10. Results for the Feet and Tooth datasets. (a,d) The DVR results and the initial transfer function; (b,e) The results by means of [14]; (c,f) Our results. 2-D transfer functions (intensity vs. gradient magnitude) are used for both datasets. Volumetric shading is additionally applied for the Tooth dataset. </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11" coords="8,22.50,315.21,512.92,7.64;8,22.50,324.69,512.99,7.64;8,22.50,334.17,169.62,7.64"><head>Fig. 11. </head><figDesc>Fig. 11. Results for the Head and Schaedel dataset. (a,d) The DVR result; (b,e) The recolored image using [14];(c,f) Our results; The bottom images of (a) and (d) show the simulated perception of a deuteranope. Note that, in (c) the chromatic details around the ear region are visualized in blue, while these details are less visible in (b). </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12" coords="9,31.50,308.37,250.46,7.64;9,31.50,317.85,250.36,7.64;9,31.50,327.33,250.43,7.64;9,31.50,336.81,250.43,7.64;9,31.50,346.17,250.38,7.64;9,31.50,355.65,250.43,7.64;9,31.50,365.13,31.50,7.64"><head>Fig. 12. </head><figDesc>Fig. 12. (a) A DVR result for the Engine dataset; (b) The result by applying the image recoloring algorithm [14]; (c) Our result; (d) from top to bottom: the pixel chromatic diversities of the marked region in (a-c). Our result exhibits smooth shapes of the internal structures, while the image recoloring operation may result in discontinuity because it increases the color contrast where the contrast is high (circled in red ellipses). </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false" coords="3,294.06,716.35,250.48,29.23"><figDesc coords="3,352.74,716.35,191.80,9.31;3,294.06,724.01,149.77,11.25;3,444.30,726.31,100.12,8.95;3,294.06,733.97,31.21,10.42;3,325.74,736.27,137.12,9.31;4,29.10,153.11,38.14,9.14;4,412.25,152.75,22.72,9.86;4,108.50,152.75,22.72,9.86;4,194.65,153.35,6.25,9.26;4,271.11,153.35,5.47,8.90;4,323.03,151.00,38.17,11.25;4,361.79,155.79,3.34,6.46;4,498.59,151.00,6.97,10.34;4,506.03,156.39,3.49,6.22">to I d yields an image I r . Our approach seeks to reconfigure T T T c c c at the size of M × 3 to T T T * c c c , with which the generated image I * d approximates I r as close as possible. T T T o o o and T T T c c c {ω k,i } {ω k,i } I d I r T T T o o o and T T T * c c c I * d</figDesc><table coords="4,23.29,111.26,507.15,146.03">Applying transfer functions 
and shading 
Specifying transfer functions 
Color composition 
Image recoloring 

(a) 

(b) 

Applying transfer functions 
and shading 

Specifying 
transfer functions 
Color composition 
Image recoloring 
Optimizing the color 
transfer function 

Applying transfer functions 
and shading 

CVD-friendly 
color composition 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false" coords="5,72.87,52.02,438.06,36.27"><figDesc coords="5,72.87,75.33,37.11,6.05;5,126.65,75.33,7.29,6.05;5,230.39,52.02,40.09,8.30;5,230.39,61.34,47.77,8.30;5,230.21,70.67,42.61,8.30;5,230.39,80.11,42.61,8.18;5,347.56,52.14,40.09,8.18;5,347.03,61.34,47.77,8.30;5,347.38,70.79,42.61,8.18;5,347.38,79.99,42.61,8.30;5,463.07,52.14,40.09,8.18;5,463.16,61.46,47.77,8.18;5,462.97,70.79,42.61,8.18;5,463.16,79.99,42.61,8.30">Ct 1 Ct 2 Ct 3 Ct 4 Ct * 1 = (0, 46, 143) Ct * 2 = (223, 210, 189) Ct * 3 = (0, 133, 255) Ct * 4 = (248, 219, 0) Ct * 1 = (0, 44, 136) Ct * 2 = (223, 210, 190) Ct * 3 = (0, 131, 255) Ct * 4 = (253, 217, 0) Ct * 1 = (0, 43, 136) Ct * 2 = (223, 210, 187) Ct * 3 = (0, 133, 255) Ct * 4 = (251, 218, 0)</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="true" coords="7,294.06,59.37,250.46,110.34"><figDesc coords="7,294.06,59.37,250.46,7.64;7,294.06,68.85,174.90,7.64">Table 1. Configurations for eight volume datasets. #C denotes the class number produced by the opacity transfer function.</figDesc><table coords="7,336.66,78.67,165.22,91.04">Data 
#size 
#C 
Engine 
256×256×128 
2 
Feet 
256×128×256 
3 
Four-sphere phantom 256×256×256 
4 
Head 
256×256×113 
2 
Schaedel 
512×512×333 12 
Teapot 
256×256×178 
2 
Tooth 
256×256×161 
3 
Torso Phantom 
256×256×256 12 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="false" coords="7,298.98,182.01,237.78,68.22"><figDesc coords="7,298.98,182.01,237.78,8.35;7,311.34,190.88,59.76,20.40">Table 2. Performance statistics in seconds using different N r and M. P P P P P P</figDesc><table coords="7,317.34,192.00,203.92,58.24">N r 

M 
4 
8 
12 
20 
30 

200 
0.0624 0.374 0.858 1.99 3.29 
1000 
0.1248 0.702 1.622 3.42 7.21 
2000 
0.2028 1.045 2.356 5.66 14.8 
3000 
0.2808 1.373 3.198 7.06 17.4 

</table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS </head><p>The authors wish to thank the anonymous reviewers for their detailed and constructive comments. The authors also thank Helwig Hauser for the Schaedel dataset. This work is partially supported by National Grand Foundation Research 973 Program of China (No. 2009CB320800), National Natural Science Foundation of China (No.60873123, No.61003193). </p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct coords="9,49.74,415.24,231.79,7.22;9,49.74,424.72,231.94,7.22;9,49.74,434.20,49.75,7.22"  xml:id="b0">
	<analytic>
		<title level="a" type="main">View selection for volume rendering</title>
		<author>
			<persName>
				<forename type="first">U</forename>
				<forename type="middle">D</forename>
				<surname>Bordoloi</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">H.-W</forename>
				<surname>Shen</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="page" from="487" to="494" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,49.74,443.68,231.97,7.22;9,49.74,453.04,232.03,7.22"  xml:id="b1">
	<analytic>
		<title level="a" type="main">Computerized simulation of color appearance for dichromats</title>
		<author>
			<persName>
				<forename type="first">H</forename>
				<surname>Brettel</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">F</forename>
				<surname>Viénot</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">D</forename>
				<surname>Mollon</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Opt. Soc. Am. A</title>
		<imprint>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="142647" to="2655" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,49.74,462.52,186.43,7.22"  xml:id="b2">
	<monogr>
		<title level="m" type="main">Colorbrewer 2.0</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Brewer</surname>
			</persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="9,49.74,472.00,231.62,7.22;9,49.74,481.48,197.11,7.22;9,264.66,481.52,17.35,7.11;9,49.74,490.96,231.79,7.22;9,49.74,500.44,17.83,7.22"  xml:id="b3">
	<analytic>
		<title level="a" type="main">Perception-based transparency optimization for direct volume rendering</title>
		<author>
			<persName>
				<forename type="first">M.-Y</forename>
				<surname>Chan</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">Y</forename>
				<surname>Wu</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">W.-H</forename>
				<surname>Mak</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">W</forename>
				<surname>Chen</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">H</forename>
				<surname>Qu</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="1283" to="1290" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,49.74,509.92,231.97,7.22;9,49.74,519.28,232.03,7.22;9,49.74,528.76,77.23,7.22;9,35.46,538.24,21.55,7.22;9,73.98,538.24,33.87,7.22;9,125.10,538.24,11.43,7.22;9,153.54,538.24,7.75,7.22;9,178.26,538.24,19.87,7.22;9,248.94,538.24,32.59,7.22;9,49.74,547.72,116.35,7.22"  xml:id="b4">
	<analytic>
		<title level="a" type="main">Hue-preserving color blending</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Chuang</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Weiskopf</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Moeller</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<editor>6] B. Dougherty and A. Wade. Daltonize</editor>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1275" to="1282" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,49.74,557.20,232.02,7.22;9,49.74,566.68,231.98,7.22;9,49.74,576.16,103.27,7.22"  xml:id="b5">
	<analytic>
		<title level="a" type="main">Low-level image cues in the perception of translucent materials</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<forename type="middle">W</forename>
				<surname>Fleming</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">H</forename>
				<forename type="middle">H</forename>
				<surname>Büelthoff</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Applied Perception</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="346" to="382" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,49.74,585.64,232.02,7.22;9,49.74,595.00,231.98,7.22;9,49.74,604.48,116.11,7.22"  xml:id="b6">
	<analytic>
		<title level="a" type="main">Transparent layer constancy</title>
		<author>
			<persName>
				<forename type="first">W</forename>
				<surname>Gerbino</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">C</forename>
				<forename type="middle">I</forename>
				<surname>Stultiens</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">M</forename>
				<surname>Troost</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">C</forename>
				<forename type="middle">M</forename>
				<surname>De Weert</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: Human Perception and Performance</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="3" to="20" />
			<date type="published" when="1990" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,49.74,613.96,232.15,7.22;9,49.74,623.44,17.83,7.22"  xml:id="b7">
	<monogr>
		<title level="m" type="main">Tests for colour-blindness</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Ishihara</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="1979" />
			<publisher>Kanehara Shuppan Co</publisher>
			<pubPlace>Tokio</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,49.74,632.92,231.90,7.22;9,49.74,642.40,54.79,7.22"  xml:id="b8">
	<monogr>
		<title level="m" type="main">The Visualization Handbook</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<forename type="middle">R</forename>
				<surname>Johnson</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">C</forename>
				<forename type="middle">D</forename>
				<surname>Hansen</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2004" />
			<publisher>Academic Press, Inc</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,49.74,651.88,231.78,7.22;9,49.74,661.36,225.19,7.22"  xml:id="b9">
	<analytic>
		<title level="a" type="main">The color perceptions of deuteranopic and protanopic observers</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<forename type="middle">B</forename>
				<surname>Judd</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Optical Society American</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="252" to="256" />
			<date type="published" when="1949" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,49.74,670.72,231.89,7.22;9,49.74,680.20,231.91,7.22;9,49.74,689.72,232.03,7.11;9,49.74,699.16,77.23,7.22"  xml:id="b10">
	<analytic>
		<title level="a" type="main">An efficient naturalness-preserving image-recoloring method for dichromats</title>
		<author>
			<persName>
				<forename type="first">G</forename>
				<forename type="middle">R</forename>
				<surname>Kuhn</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">M</forename>
				<forename type="middle">M</forename>
				<surname>Oliveira</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">L</forename>
				<forename type="middle">A F</forename>
				<surname>Fernandes</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1747" to="1754" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,49.74,708.64,232.09,7.22;9,49.74,718.12,231.86,7.22;9,49.74,727.60,101.47,7.22"  xml:id="b11">
	<analytic>
		<title level="a" type="main">Color discrimination enhancement for dichromats using self-organizing color transformation</title>
		<author>
			<persName>
				<forename type="first">Y</forename>
				<surname>Ma</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">X</forename>
				<surname>Gu</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">Y</forename>
				<surname>Wang</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Science</title>
		<imprint>
			<biblScope unit="volume">179</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="830" to="843" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,49.74,736.96,231.66,7.22;9,355.37,165.21,9.70,7.96;9,473.05,165.21,10.19,7.96;9,355.37,291.13,9.70,7.96;9,473.05,291.13,10.19,7.96"  xml:id="b12">
	<monogr>
		<title level="m" type="main">Real-time temporal-coherent (a) (b) (c) (d)</title>
		<author>
			<persName>
				<forename type="first">G</forename>
				<forename type="middle">M</forename>
				<surname>Machado</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">M</forename>
				<forename type="middle">M</forename>
				<surname>Oliveira</surname>
			</persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="9,294.06,308.37,250.43,7.64;9,294.06,317.85,250.45,7.64;9,294.06,327.33,250.38,7.64;9,294.06,336.81,250.43,7.64;9,294.06,346.17,250.50,7.64;9,294.06,355.65,100.02,7.64;9,312.42,387.64,232.15,7.22;9,312.42,397.12,85.75,7.22"  xml:id="b13">
	<analytic>
		<title level="a" type="main">Our approach is compatible with arbitrary image recoloring algorithms For instance, using the approach presented in [14] to recolor (a) yields unsatisfactory result (b), even with its exaggeration version, because the number of green pixels in (a) is low. Another image recoloring algorithm of [12] yields an effective result (c). Our result based on (c) is shown in (d). color contrast enhancement for dichromats</title>
		<author>
			<persName>
				<surname>Fig</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics Forum</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="29933" to="942" />
			<date type="published" when="2010-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,312.42,406.60,232.07,7.22;9,312.42,416.08,231.79,7.22;9,312.42,425.60,231.91,7.11;9,312.42,435.04,112.51,7.22"  xml:id="b14">
	<analytic>
		<title level="a" type="main">A physiologically-based model for simulation of color vision deficiency</title>
		<author>
			<persName>
				<forename type="first">G</forename>
				<forename type="middle">M</forename>
				<surname>Machado</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">M</forename>
				<forename type="middle">M</forename>
				<surname>Oliveira</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">L</forename>
				<forename type="middle">A F</forename>
				<surname>Fernandes</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1291" to="1298" />
			<date type="published" when="2009-11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,312.42,444.40,231.82,7.22;9,312.42,453.88,195.91,7.22"  xml:id="b15">
	<analytic>
		<title level="a" type="main">Optical models for direct volume rendering</title>
		<author>
			<persName>
				<forename type="first">N</forename>
				<surname>Max</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="99" to="108" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,312.42,463.36,231.67,7.22;9,312.42,472.84,231.79,7.22;9,312.42,482.32,69.19,7.22"  xml:id="b16">
	<monogr>
		<title level="m" type="main">Balanced and unbalanced, complete and partial transparency. Perception and Psychophysics</title>
		<author>
			<persName>
				<forename type="first">F</forename>
				<surname>Metelli</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">O</forename>
				<forename type="middle">D</forename>
				<surname>Pos</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Cavedon</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="1985" />
			<biblScope unit="page" from="354" to="366" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,312.42,491.80,232.03,7.22;9,312.42,501.28,231.86,7.22;9,312.42,510.76,232.03,7.22"  xml:id="b17">
	<analytic>
		<title level="a" type="main">The transfer function bake-off</title>
		<author>
			<persName>
				<forename type="first">H</forename>
				<surname>Pfister</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">B</forename>
				<surname>Lorensen</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Bajaj</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">G</forename>
				<surname>Kindlmann</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">W</forename>
				<surname>Schroeder</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">L</forename>
				<forename type="middle">S</forename>
				<surname>Avila</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">K</forename>
				<surname>Martin</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Machiraju</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Lee</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer Graphics and Applications</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="16" to="22" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,312.42,520.12,231.94,7.22;9,312.42,529.60,189.19,7.22"  xml:id="b18">
	<analytic>
		<title level="a" type="main">Compositing digital images</title>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Porter</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Duff</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics (Proceedingds of ACM SIGGRAPH)</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="253" to="259" />
			<date type="published" when="1984" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,312.42,539.08,231.91,7.22;9,312.42,548.56,231.99,7.22;9,312.42,558.04,50.59,7.22"  xml:id="b19">
	<monogr>
		<title level="m" type="main">Linear Models: Least Squares and Alternatives</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Rao</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">H</forename>
				<surname>Toutenburg</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Fieger</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Heumann</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Nittner</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Scheid</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="1999" />
			<publisher>Springer Series in Statistics</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,312.42,567.52,231.75,7.22;9,312.42,577.00,231.82,7.22;9,312.42,586.36,150.91,7.22"  xml:id="b20">
	<analytic>
		<title level="a" type="main">Detail preserving reproduction of color images for monochromats and dichromats</title>
		<author>
			<persName>
				<forename type="first">K</forename>
				<surname>Rasche</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Geist</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Westall</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer Graphics and Applications</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="22" to="30" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,312.42,595.84,232.09,7.22;9,312.42,605.32,217.39,7.22"  xml:id="b21">
	<analytic>
		<title level="a" type="main">Re-coloring images for gamuts of lower dimension</title>
		<author>
			<persName>
				<forename type="first">K</forename>
				<surname>Rasche</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Geist</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Westall</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics Forum</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="423" to="432" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,312.42,614.80,232.11,7.22;9,312.42,624.28,192.07,7.22"  xml:id="b22">
	<analytic>
		<title level="a" type="main">Task-based color scale design</title>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Rheingans</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of SPIE on Applied Image and Pattern Recognition</title>
		<meeting>SPIE on Applied Image and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="1999" />
			<biblScope unit="page" from="35" to="43" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,312.42,633.76,223.39,7.22"  xml:id="b23">
	<monogr>
		<title level="m" type="main">Digital Color Imaging Handbook</title>
		<author>
			<persName>
				<forename type="first">G</forename>
				<surname>Sharma</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2002" />
			<publisher>CRC Press, Inc</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,312.42,643.24,232.07,7.22;9,312.42,652.72,180.31,7.22"  xml:id="b24">
	<monogr>
		<title level="m" type="main">Color Vision: From Genes to Perception</title>
		<author>
			<persName>
				<forename type="first">L</forename>
				<forename type="middle">T</forename>
				<surname>Sharpe</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Stockman</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">H</forename>
				<surname>Jägle</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Nathans</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="1999" />
			<publisher>Cambridge University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,312.42,662.08,232.09,7.22;9,312.42,671.56,191.83,7.22"  xml:id="b25">
	<analytic>
		<title level="a" type="main">Towards a perceptual theory of transparency</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Singh</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">B</forename>
				<forename type="middle">L</forename>
				<surname>Anderson</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Review</title>
		<imprint>
			<biblScope unit="volume">109</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="492" to="519" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,312.42,681.04,232.10,7.22;9,312.42,690.52,176.35,7.22"  xml:id="b26">
	<analytic>
		<title level="a" type="main">Modeling color percepts of dichromats</title>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Wachtler</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">U</forename>
				<surname>Dohrmann</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Hertel</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Vision Research</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="issue">24</biblScope>
			<biblScope unit="page" from="2843" to="2855" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,312.42,700.00,231.97,7.22;9,312.42,709.48,231.75,7.22;9,312.42,718.96,158.47,7.22"  xml:id="b27">
	<analytic>
		<title level="a" type="main">Color design for illustrative visualization</title>
		<author>
			<persName>
				<forename type="first">L</forename>
				<surname>Wang</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Giesen</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">K</forename>
				<forename type="middle">T</forename>
				<surname>Mcdonnell</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Zolliker</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">K</forename>
				<surname>Mueller</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1739" to="1754" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
