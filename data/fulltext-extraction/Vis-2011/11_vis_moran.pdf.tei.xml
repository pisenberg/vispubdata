<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/pisenberg/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.4.1" ident="GROBID" when="2016-09-09T14:59+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Visualization of AMR Data With Multi-Level Dual-Mesh Interpolation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName>
								<forename type="first">Patrick</forename>
								<forename type="middle">J</forename>
								<surname>Moran</surname>
							</persName>
						</author>
						<author>
							<persName>
								<forename type="first">David</forename>
								<surname>Ellsworth</surname>
								<roleName>Members, Ieee</roleName>
							</persName>
						</author>
						<title level="a" type="main">Visualization of AMR Data With Multi-Level Dual-Mesh Interpolation</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Index Terms—Adaptive mesh refinement</term>
					<term>AMR</term>
					<term>Enzo</term>
					<term>interpolation</term>
					<term>ray casting</term>
					<term>isosurfaces</term>
					<term>dual meshes</term>
					<term>stitching cells</term>
				</keywords>
			</textClass>
			<abstract>
				<p>Fig. 1. Close-up of a galaxy cluster. The image shows gas density (orange and red), stars (white), and dark matter (blue). Abstract—We present a new technique for providing interpolation within cell-centered Adaptive Mesh Refinement (AMR) data that achieves C 0 continuity throughout the 3D domain. Our technique improves on earlier work in that it does not require that adjacent patches differ by at most one refinement level. Our approach takes the dual of each mesh patch and generates &quot; stitching cells &quot; on the fly to fill the gaps between dual meshes. We demonstrate applications of our technique with data from Enzo, an AMR cosmological structure formation simulation code. We show ray-cast visualizations that include contributions from particle data (dark matter and stars, also output by Enzo) and gridded hydrodynamic data. We also show results from isosurface studies, including surfaces in regions where adjacent patches differ by more than one refinement level.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Adaptive Mesh Refinement (AMR) is a technique where a simulation code automatically adjusts mesh resolution during the computational run. One of the more popular AMR schemes was introduced by Berger and Colella <ref type="bibr" coords="1,74.65,473.13,10.46,8.12" target="#b0">[1] </ref>in 1989. In their technique, the domain is decomposed into regular meshes that are nested and organized by levels. In R 3 , field data are associated with the center of each hexahedral cell, sometimes referred to as " cell-centered " data. Cell-centered data are a challenge for visualization, as many algorithms require data at the vertices of the mesh, rather than hexahedra centers. One solution to this problem is to work with the duals of the original meshes, where the centers of the hexahedra in the original meshes become the vertices in a new set of meshes. Working with the dual has the advantage of avoiding resampling of the domain, which can be costly in computational time and memory usage. One disadvantage of the dual approach is that the meshes contract by the width of one cell in each axis, leaving gaps in between. A solution to the gaps problem is to introduce " stitching cells " to fill the domain once again. Weber et al. <ref type="bibr" coords="1,215.73,602.64,14.19,8.12" target="#b20">[21,</ref><ref type="bibr" coords="1,232.75,602.64,11.95,8.12" target="#b21"> 22] </ref>described such a scheme and demonstrated how they could use their stitched dual meshing to generate crack-free isosurfaces and high-quality ume renderings. The data sets that they used as for their work were produced by Enzo <ref type="bibr" coords="1,361.56,451.48,13.75,8.12" target="#b15">[16]</ref> , one of the most widely used AMR cosmological simulation codes. In their original work, Berger and Colella <ref type="bibr" coords="1,534.04,461.44,10.46,8.12" target="#b0">[1] </ref>required that adjacent meshes in their system differ by at most one refinement level. <ref type="bibr" coords="1,360.82,481.37,45.36,8.12">Weber et al. </ref>maintained this requirement in their stitching implementation. In the years that followed, AMR continued to grow in popularity, and researchers continued to extend the technique. One extension of particular relevance here was the removal of the requirement that adjacent patches differ by at most one level in some codes, in particular, Enzo <ref type="bibr" coords="1,315.90,543.11,9.52,8.12" target="#b2">[3]</ref>. Indeed, in the data we see from current Enzo runs there are regions where patches differ by multiple refinement levels. Refinement typically occurs in regions that are of interest to the scientist, and the transition regions that surround high-refinement locations are often important as well. Clearly, we would prefer an algorithm that will work throughout current domains. We present a new technique for handling cell-centered AMR data where we work with the dual and generate stitching on the fly. Adjacent patches can differ by as many refinement levels as there are in the data set. We use this infrastructure to provide point location and interpolation with C 0 continuity throughout the domain. We demonstrate our capability with ray-cast images that include contributions from both particle (stars and dark matter) and gridded data. We also describe a capability to iterate over the dual cells and apply standard marching cell techniques in order to generate isosurfaces. In the next section we provide a brief overview of related work, followed by an introduction to the AMR terminology that we will need throughout. Next we briefly consider how our stitching technique would work in two dimensions, to build intuition, and then proceed to dual meshes and stitching in R 3 . Next we describe our isosurface and ray-casting techniques, followed by both volume rendering and isosurface results. We conclude with a brief discussion of how applicable our approach may be to other AMR systems. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">PREVIOUS WORK</head><p> In the early days of the development of AMR simulation codes, scientists found that they needed to adapt the output of their simulations in order to suit the formats expected by extant visualization algorithms and tools. For example, Norman et al. <ref type="bibr" coords="2,161.26,135.53,14.94,8.12" target="#b16">[17] </ref>describe the work they did to convert Enzo output into a form that they could visualize with the standard tools at that time. Eventually, the algorithms and tools began to catch up with the data. Weber et al. <ref type="bibr" coords="2,160.33,165.41,14.94,8.12" target="#b20">[21] </ref> developed a stitching technique that enabled them to work with the dual meshing of Enzo output and produce crack-free isosurfaces. Weber et al. <ref type="bibr" coords="2,201.87,185.33,14.94,8.12" target="#b21">[22] </ref>also developed a volume renderer that worked in terms of the stitched dual. Their stitching required that adjacent AMR patches differ by no more than one level, a requirement that also existed in the specification of the Berger-Colella scheme <ref type="bibr" coords="2,108.01,225.18,10.46,8.12" target="#b0">[1] </ref> that they were working with. In more recent work Weber et al. <ref type="bibr" coords="2,105.35,235.15,14.94,8.12" target="#b19">[20] </ref>described efforts to integrate some of their algorithms into VisIt, making AMR data a first-class object within the VisIt framework. Park et al. <ref type="bibr" coords="2,133.97,255.07,14.95,8.12" target="#b17">[18] </ref>described an interactive splatting renderer for AMR data as a case study. Kreylos et al. <ref type="bibr" coords="2,225.20,265.04,10.46,8.12" target="#b8">[9] </ref>described a direct volume renderer for AMR data and included results with data with a refinement ratio other than 2. Their work also included a remote rendering capability. Kähler <ref type="bibr" coords="2,126.86,294.93,10.46,8.12" target="#b5">[6] </ref>focused on AMR visualization in his Ph.D. research, and his thesis presents both isosurface and volume rendering algorithms designed for AMR data. Kähler et al. <ref type="bibr" coords="2,224.85,314.85,10.46,8.12" target="#b7">[8] </ref>continued on to develop a GPU-accelerated ray-caster that achieved interactive rates. Marchesin et al. <ref type="bibr" coords="2,106.97,334.78,14.94,8.12" target="#b11">[12] </ref> describe a hybrid CPU/GPU volume renderer for vertex-centered AMR data that is capable of reconstructing signals with techniques that improve on traditional trilinear interpolation . Turk et al. <ref type="bibr" coords="2,96.63,364.67,14.94,8.12" target="#b18">[19] </ref>describe a visualization tool, yt, written in Python, that supports a variety of analysis techniques for cosmological AMR data, such as Enzo, including volume rendering. There has also been previous work related to our ray-casting implementation that renders both gridded data and particle data. Levoy <ref type="bibr" coords="2,257.94,404.69,14.94,8.12" target="#b9">[10] </ref>proposed a ray tracer that handles polygonal geometry, and which could be adapted to handle spheres. Gribble et al. <ref type="bibr" coords="2,214.45,424.61,10.46,8.12" target="#b3">[4] </ref>proposed an algorithm for quickly casting rays though a large number of spheres. In <ref type="bibr" coords="2,33.13,444.54,9.52,8.12" target="#b6">[7]</ref>, Kähler et al. describe a GPU-assisted renderer that includes contributions from both gridded data and particles. The particles are maintained in an octree data structure on the GPU, rather than sampling the particle contributions onto a grid. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">ADAPTIVE MESH DATA</head><p>Adaptive mesh refinement (AMR) is based on a set of nested, regular meshes organized by levels. Introduced by Berger and Oliger <ref type="bibr" coords="2,247.00,516.80,10.46,8.12" target="#b1">[2] </ref>and further developed by Berger and Colella <ref type="bibr" coords="2,174.53,526.76,9.52,8.12" target="#b0">[1]</ref>, the approach has been adopted and extended by many computational science research groups. We denote a mesh i at a level as M ,i , and the set of meshes at level as M . A mesh M ,i is sometimes referred to as a patch. We refer to the complete set of meshes, the union of all M , as M. The mesh levels range from 0 (the coarsest) to max , the finest. We assume a single mesh at level 0, M 0,0 , the root mesh. In some AMR implementations the spacing between vertices in a single mesh may differ in each axis, but we assume the same spacing, h, in each direction. Let the spacing at level 0 be h 0 . We define an integer refinement ratio r such that h = h −1 /r. For our current data, r is always 2. Let R(M ,i ) represent the region covered by M ,i , and R(M ) represent the region covered by the set of meshes M . R(M 0 ) is the whole domain. The Berger-Colella scheme requires that for any mesh M ,i , R(M ,i ) ⊆ R(M −1 ). Furthermore, M ,i must align with cell boundaries in the next coarsest refinement level, − 1. In the early AMR work there was the additional requirement that adjacent patches must not differ by more than one refinement level. Later work relaxed this constraint. In particular, Bryan <ref type="bibr" coords="2,229.24,706.44,10.46,8.12" target="#b2">[3] </ref>removes this constraint for Enzo. Kähler <ref type="bibr" coords="2,145.68,716.40,10.46,8.12" target="#b5">[6] </ref>terms AMR data that maintain this constraint as restricted AMR. Note that without this constraint we essentially must be able to handle data that are equivalent to AMR with a refinement ratio that can be a power of the ratio of 2 used in Enzo. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Point Location In M</head><p>At initialization time we determine which level each submesh in an AMR data set belongs to and parent-child relationships. A mesh may have more than one parent, see for example M 2,0 in <ref type="figure" coords="2,483.78,113.55,30.23,8.12" target="#fig_0">Figure 2</ref>. We can obtain this information either by examining metadata that comes with the data set, or by calculating it on the fly at construction time. One of the basic operations we do most frequently once we have initialized the mesh hierarchy is point location: given a point p in the domain, locate the finest resolution mesh M ,i that contains p, and return a hexahedron cell c ∈ M ,i that contains p. Frequently, successive point-location queries exhibit spatial coherence. We optimize for this by using a small context object that stores the result of the last pointlocation query. If a last cell c ∈ M ,i is available, we begin by attempting to locate p starting from M ,i in the mesh hierarchy. If that does not succeed, then we try a parent of M ,i , working up the hierarchy until we locate a mesh containing p, or we conclude that p is outside the domain. If a mesh has multiple parents, then we arbitrarily choose the first parent in the list. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Covered Vertices</head><p>When iterating over each vertex u in a mesh M ,i , we may wish to check for two conditions: 1. u is coincident with a vertex v ∈ M +1, j , 2. u is coincident with a vertex w ∈ M ,k , and k &lt; i. </p><p>The idea is that if multiple vertices are located at the same location in the domain, then we want to process just one of them. In particular, we choose the vertex at the finest refinement level available. If multiple vertices are available at the finest level , then we arbitrarily choose the vertex from the mesh in M with the lowest index. For each M ,i we maintain a list of children meshes at level + 1, so we can test for the first condition by checking whether u is located in any of the children. For the second condition, we test whether u is contained by any mesh M ,k where k &lt; i. We provide a predicate, covered, that tests for the two conditions. Below we shall use the predicate as part of our algorithm to iterate over dual cells. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">DUAL MESHES IN R 2</head><p>We begin by considering the R 2 analog of the AMR data in R 3 that is the subject of the following sections. Many concepts translate easily between two and three dimensions, and it is much easier to illustrate the concepts in R 2 . On the left side of <ref type="figure" coords="2,435.87,507.19,31.25,8.12" target="#fig_0">Figure 2</ref>we have a simple example, with a root mesh M 0,0 , two level 1 refinement meshes M 1,0 and M 1,1 , and a single level 2 mesh M 2,0 . The data are " cell-centered, " meaning that we have a field value associated with the center of each quadrilateral cell, indicated by the white-centered markers in the figure . Excluding the vertices on the boundary of M 0,0 , which we treat as a special case, we see that each vertex in M is surrounded by a neighborhood of 4 quadrilaterals, or 3 quadrilaterals when adjacent submeshes differ in refinement level. A vertex that is surrounded by less than the maximum number of quadrilaterals is a hanging vertex. For example, in <ref type="figure" coords="2,345.29,606.82,30.65,8.12" target="#fig_0">Figure 2</ref>vertex D is a hanging vertex. We use point location in order to quickly identify the neighborhood surrounding a vertex. Let an ε-square be a square with length h max on a side. We refer to a vertex v that we are interested in obtaining the neighborhood for as a neighborhood vertex. Centering an ε-square on v, we do point location at each of the 4 corners of the square to obtain the 4 quadrilateral cells in the neighborhood of v. The 4 quadrilateral cells are unique if and only if v is not a hanging vertex. The centers of the four quadrilaterals produced by the ε-square search are the vertices of the dual cell. We refer to a degenerate edge where both vertex faces are the same as a collapsed edge, and the vertex that remains after an edge collapse as a collapsed vertex. We can detect a collapsed edge in the ε-square search result by comparing the vertex faces of each edge for equality and return a dual triangle cell with three unique vertices. </p><formula>B D A C M 0 = {M 0,0 } M 1 = {M 1,0 , M 1,1 } M 2 = {M 2</formula><p>,0 } dual with gaps dual with stitching If a collapsed edge is not a problem for an application, then we can simply always return a quadrilateral dual cell. For example, we can pass a quadrilateral with a collapsed edge to an isocontouring algorithm , and since the field values at the vertex faces of a collapsed edge must be the same, the isocontouring case tables will not conclude that a contour intersects the collapsed edge. <ref type="figure" coords="3,41.46,421.06,30.61,8.12" target="#fig_0">Figure 2</ref>provides some typical examples. Neighborhood vertex A is contained within the interior of submesh M 1,0 , and the dual of A is an axis-aligned quadrilateral with spacing h 1 . Vertex B occurs in M 1,0 and M 1,1 , both at refinement level 1. The dual of B bridges between the two meshes, is axis-aligned, and has spacing h 1 . Vertex C occurs in both M 1,1 and M 0,0 (differing in refinement level), but is not a hanging vertex. The dual of C is a (non-degenerate) quadrilateral that is not axis aligned. Finally, vertex D is a hanging vertex, and the dual of D can be handled as either a quadrilateral with a collapsed edge or as a triangle. To the right of <ref type="figure" coords="3,122.92,510.72,29.79,8.12" target="#fig_0">Figure 2</ref>, we have the complete dual mesh, with the dual cells for each submesh in blue, and the stitching cells in green. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">DUAL MESHES IN R 3</head><p> Many concepts from R 2 extend naturally to R 3 . Rather than an εsquare , we have an ε-cube. As in R 2 we have the concept of a neighborhood vertex v ∈ M which we use to identify a dual cell. Allowing for degenerate, collapsed edges, each dual cell is a hexahedron in R 3 . There are more collapsed edge configurations to handle, and we will review those cases below. Dual cells in R 3 may have non-planar quadrilateral faces, an issue that does not have an analog in R 2 . For point-location orientation tests, and in cases where we need to subdivide a general dual hexahedron into smaller cells, we subdivide quadrilateral faces into two triangles each. It is essential that we do the quadrilateral face subdivision in a consistent manner in order to avoid cracks in our isosurfaces and problems in point location when we walk over dual cells. We return to our quadrilateral subdivision method once we review the dual cell types that we will encounter in R 3 . In choosing to subdivide a quadrilateral into two triangles, we do not distinguish between planar and non-planar cases, though there are potential optimizations in the planar case. The decision whether to subdivide each dual hexahedron into smaller cells ultimately depends upon the needs of the application. If the application can tolerate hexahedra with collapsed edges and nonplanar faces, then we can present the dual hexahedra to the application as is. Otherwise, we subdivide each hexahedron into tetrahedra so that the application sees neither collapsed edges nor non-planar faces. Classifying each dual cell into one of the types below is an intermediate step towards completely subdividing each dual hexahedron into tetrahedra. <ref type="figure" coords="3,294.12,596.78,27.14,8.12" target="#tab_1">Table 1</ref>summarizes the types of dual cells that we can encounter in R 3 after edge collapses, and <ref type="figure" coords="3,399.13,606.73,30.50,8.12">Figure 3</ref>provides an example image for each. Vertices illustrated in the figure with white centers are collapsed vertices. In the most common case for a given cell, non-collapsed vertices (indicated by the solid black markers) are at a level , and the collapsed vertices (indicated by the white-centered markers) are at coarser level − 1. But if adjacent submeshes can differ by more than one refinement level, then in general neither the non-collapsed vertices nor the collapsed vertices are necessarily at the same level. Thus keep in mind that in <ref type="figure" coords="3,388.70,686.43,30.22,8.12">Figure 3</ref>some quadrilateral faces appear as axis-aligned and planar, but in general we cannot assume that. To obtain the set of dual cell types in <ref type="figure" coords="3,435.05,706.44,24.91,8.12" target="#tab_1">Table 1</ref> , we considered all possible combinations of collapsed edges for a dual hexahedron. Many combinations imply hanging vertex configurations in M that are not allowed to occur by the construction rules given in Berger-Colella <ref type="bibr" coords="3,531.80,736.33,9.52,8.12" target="#b0">[1]</ref><ref type="figure" coords="4,22.50,197.27,19.42,7.64">Fig. 3</ref>. We illustrate examples of the types of dual cells we can have in R 3 . In the top row we have a hexahedron corresponding to each type, with the edges that would be collapsed marked with an X. In the second row we illustrate the resulting cell, after the edge collapses. We indicate a vertex that was the face of a collapsed hexahedron edge (a collapsed vertex) by a white-centered marker. Dashed edges in the second row indicate diagonals that we require our diagonal-choosing algorithm to select. See Sections 5.1 and 5.2 and <ref type="figure" coords="4,400.51,225.66,27.68,7.64" target="#tab_1">Table 1.</ref>For example, a quadrilateral face with exactly two collapsed edges, where the edges share a vertex, cannot occur. A quadrilateral face with exactly three collapsed edges also cannot occur. After eliminating cases which imply configurations in M that are not allowed and consolidating cases that differ only by rotation or mirroring, we are left with the set of seven types given in <ref type="figure" coords="4,165.94,306.88,26.59,8.12" target="#tab_1">Table 1</ref>and illustrated in <ref type="figure" coords="4,257.92,306.88,14.95,8.12;4,22.50,316.84,11.45,8.12">Fig- ure</ref>3. When we need to classify a dual cell d into one of the cases in <ref type="figure" coords="4,22.50,337.01,25.64,8.12" target="#tab_1">Table 1</ref>, we test each of the 12 edges of d and generate a 12-bit code where bit i is 1 if edge i is collapsed. We use this code to look up the cell type in a map from bit encoding to type. We also use this same bit encoding to look up a permutation which rotates d into a canonical orientation, similar to the technique used by many marching cubes implementations. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Dual Cell Types in R 3</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.1">Hexahedron (Type H)</head><p> The hexahedron type corresponds to the case where we have no collapsed edges. The refinement level of each vertex may or may not be the same. If all the vertices are on the same refinement level , then the hexahedron will be axis aligned and the spacing in each axis will be h . The analogous two-dimensional case is illustrated with the dual cells specified by neighborhood vertices A and B in <ref type="figure" coords="4,189.06,468.72,28.98,8.12" target="#fig_0">Figure 2</ref>. The dual to C in <ref type="figure" coords="4,31.88,478.68,30.31,8.12" target="#fig_0">Figure 2</ref>is an example where the neighborhood is not at a uniform level. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.2">Pyramid-Prism (Type PW)</head><p>The PW (W for " wedge " ) case occurs when we have a single collapsed edge. There are four remaining quadrilateral faces. <ref type="figure" coords="4,206.11,530.69,29.89,8.12" target="#fig_1">Figure 4</ref>illustrates <ref type="figure" coords="4,74.88,664.39,31.08,8.12" target="#fig_1">Figure 4</ref>we see the diagonal choices that allow for a pyramid-prism decomposition, and to the right the diagonal choices that allow for a two pyramid decomposition. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.3">Triangular Prism (Type W)</head><p>The W ( " wedge " ) case occurs when two edges on opposite sides of a hexahedron quadrilateral face q are collapsed. The two non-collapsed edges of q are merged into one. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.4">Pyramid-Pyramid (Type PP)</head><p>The PP case occurs when we have a hexahedron with two collapsed edges where the edges are on diagonally opposite sides. See <ref type="figure" coords="4,503.12,280.38,29.02,8.12">Figure 3</ref>. We require that the remaining two quadrilateral faces be subdivided as shown by the dashed edges in <ref type="figure" coords="4,394.45,300.31,29.09,8.12">Figure 3</ref>. Without this requirement it is possible to choose diagonals such that the PP cell would be " pinched " into two tetrahedra, sharing a common edge. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.5">Tetrahedron-Tetrahedron (Type TT)</head><p> The TT case occurs when we have a hexahedron with 3 parallel collapsed edges. We require that the remaining two quadrilateral faces be subdivided as shown by the dashed edges in <ref type="figure" coords="4,448.58,371.21,29.46,8.12">Figure 3</ref>. Choices other than those illustrated in the figure result in a cell that cannot be subdivided into tetrahedra, or a subdivision that includes a collapsed, " flat " tetrahedron. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.6">Pyramid (Type P)</head><p>The P case occurs when the four edges surrounding a hexahedron quadrilateral face are collapsed. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.7">Tetrahedron (Type T)</head><p>The T case occurs when five hexahedron edges are collapsed, four as with the P case, and one additional edge in the base of the pyramid. See the right side of <ref type="figure" coords="4,359.08,493.09,29.01,8.12">Figure 3</ref>. <ref type="figure" coords="4,285.12,587.14,18.96,7.64">Fig. 5</ref> . An example where we visualize the region surrounding a neighborhood vertex (indicated by the small red square icon in the diagram) in R 3 in lower and upper half-spaces. On the left is the lower half, on the right the upper. The resulting dual cell in this example is a tetrahedron (oriented similarly to the T case illustrated on the right side of <ref type="figure" coords="4,501.48,624.99,27.82,7.64">Figure 3</ref>). <ref type="figure" coords="4,295.08,646.66,31.83,8.12">Figure 5</ref> illustrates one approach to visualizing the octants surrounding a neighborhood vertex. We indicate the neighborhood vertex by the small red square ε-cube icon at the lower middle of the lower and upper halves of the neighborhood diagram. The neighborhood vertex is a hanging vertex as seen from the hexahedra corresponding to centroids c and d. The dual hexahedron edges completely contained by the hexahedra corresponding to c and d are collapsed edges. The resulting dual cell is a tetrahedron, oriented similarly to that in <ref type="figure" coords="4,503.21,716.41,28.92,8.12">Figure 3</ref>. Note that dual vertices a and b differ by two refinement levels from dual vertex d. We cannot construct a tetrahedron case without at least 1865 MORAN AND ELLSWORTH: VISUALIZATION OF AMR DATA WITH MULTI-LEVEL DUAL-MESH INTERPOLATION a two-level difference. The tetrahedron dual cell is the one type that does not occur if we are constructing a dual stitching with restricted AMR data, i.e., data where adjacent submeshes can differ by at most one refinement level. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Choosing Diagonals and Tetrahedral Decomposition</head><p>Choosing diagonals consistently when subdividing quadrilaterals is critical to achieving crack-free isosurfaces and reliable point-location in the dual of M. We have the additional goal that our diagonal choices should allow all dual cells to be subdivided into tetrahedra, if desired. We describe our diagonal choosing algorithm, then revisit the dual cell types described above to verify that the algorithm choices match what we need to allow for a full tetrahedral decomposition. We take an approach based on examining the refinement level of each vertex in a quadrilateral face. Returning to <ref type="figure" coords="5,209.96,196.62,29.53,8.12">Figure 3</ref>, recall that for each dual cell type, some vertices remain after collapsing edges (illustrated with the white-centered markers), and some do not. Collapsed edges in the dual occur in the neighborhood of hanging vertices in M. Hanging vertices imply differences in refinement level, in particular , collapsed vertices are at a lower refinement level relative to the non-collapsed vertices in the same face. Keeping this in mind, we choose a diagonal by evaluating the refinement level of each of the four vertices and selecting the diagonal which includes the vertex at the greatest refinement level, . If this test results in a tie, then we fall back on a canonical enumeration of all the dual vertices (corresponding one-to-one with the hexahedra in M); each dual vertex has a unique integer identifier. We choose the diagonal that includes the vertex that is both at level and has the greater canonical enumeration. This choice is arbitrary, but consistent. For the H, PW and W types, there exist choices of diagonals such that it is not possible to subdivide the result into tetrahedra. Those cases do not occur using the algorithm above. For every dual cell d, there exists a vertex v ∈ d such that the diagonals algorithm will include v in the diagonal of every quadrilateral face of d that includes v. We refer to v as a maximum valence vertex. H, PW and W cells have 6, 4, and 3 remaining quadrilateral faces, respectively. This implies that we have 2 6 , 2 4 and 2 3 possible diagonal choices, respectively, for H, PW and W types. Working through the cases for each type, we have verified that if a configuration has a maximum valence vertex, then there exists a tetrahedral decomposition for that configuration. We encode the tetrahedral decompositions in tables so that given a dual cell and diagonal choices, we can quickly produce the subtetrahedra. For the TT cell type, we see that each of the two remaining quadrilateral faces has one vertex v that is not collapsed. Our algorithm will always choose the diagonal that includes v since it will always be at a greater refinement level than the other vertices of the face. In the PP case, the vertices in the choice that we want will always be at a greater level than the vertices in the opposite diagonal. Finally, for P and T cases, we can always decompose the cells into tetrahedra, no matter what choices the diagonals algorithm makes. <ref type="figure" coords="5,31.50,706.43,19.23,7.64">Fig. 6</ref>. An example region in R 2 to illustrate point location: the cells of M are outlined with dashed lines, with vertices labeled A – G. The dual mesh edges are drawn with solid lines and vertices labeled a – g. The dual patches are shaded blue, the stitching region is shaded green. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Point Location and Interpolation in the Dual of M</head><p>Point location is a prerequisite for answering field value queries at a location p in the domain. There are three steps. First, we do point location without dual cells, as described in Section 3.1. The initial step produces a hexahedron cell c containing p and parametric terms ξ c specifying the position of p within c. In step two, we choose an initial neighborhood vertex v, using ξ c to determine the vertex of c closest to p. In the third step, we walk over dual cells, starting at the dual to v, until we locate a dual cell d that contains p: Each dual stitching cell is a hexahedron, often with one or more collapsed edges. To determine whether p is contained by d, we test the orientation of p with respect to each of the six quadrilateral faces of d. The orientation test returns -1, 0 or 1, corresponding to the classification of outside, indeterminate, or inside, respectively. The predicate must handle degenerate cases. If face f is completely collapsed (e.g., the top of a pyramid cell), then orient returns 0. If face f has a single collapsed edge, then the orientation test is done with respect to the remaining triangle. Otherwise, the predicate decomposes the quadrilateral face into two triangles, using the rules described in Section 5.2 to choose the diagonal. Once a dual cell d that contains p is found, we must calculate the parametric terms ξ d in preparation for interpolation. We use a standard trilinear basis function f (ξ ), where the terms f 0 through f 7 are the field values at the vertices of d: </p><formula>d </formula><formula>f (ξ ) = (1 − ξ 0 ) (1 − ξ 1 ) (1 − ξ 2 ) f 0 + ξ 0 (1 − ξ 1 ) (1 − ξ 2 ) f 1 + (1 − ξ 0 ) ξ 1 (1 − ξ 2 ) f 2 + ξ 0 ξ 1 (1 − ξ 2 ) f 3 + (1 − ξ 0 ) (1 − ξ 1 ) ξ 2 f 4 + ξ 0 (1 − ξ 1 ) ξ 2 f 5 + (1 − ξ 0 ) ξ 1 ξ 2 f 6 + ξ 0 ξ 1 ξ 2 f 7 </formula><p>We can use the same trilinear function to interpolate vertex coordinate arguments by providing them as f 0 through f 7 . To obtain ξ d corresponding to p, we use a Newton-Raphson routine to find the values for ξ such that the magnitude of f (ξ ) − p is less than a small tolerance, where the f i terms are the physical coordinates at the vertices of d. As an example of the point-location phase, consider a region in R 2 , as illustrated in <ref type="figure" coords="5,353.70,626.74,29.86,8.12">Figure 6</ref>, with point p to locate. While our interest is in R 3 , the concepts that we are interested in have a natural analog in R 2 , and are much easier to visualize in two dimensions. In the figure, cells in M are indicated with dashed-line edges, dual cells with solid edges. Given point p to locate, start by locating a cell in M containing p: ACGB. Using the parametric terms ξ also produced by the point-location routine, choose the initial neighborhood vertex, the vertex of ACGB closest to p: G. Next, test faces and walk if necessary to find the dual containing p. The initial dual cell is afgb. Testing the faces of afgb, we find p outside af, therefore we step the neighborhood vertex in the direction of the axis corresponding to af, giving us the next neighborhood vertex: F. Once again we test faces, find p outside face ae, and step to neighborhood vertex E. The dual to E is ade. We find p inside all faces of ade, therefore our result is dual cell ade. We can significantly speed up our general-case algorithm above by distinguishing between cases where we are inside a dual patch, and cases where we are within a stitching region. As an initialization step, we mark each vertex of M that has a neighborhood that is within a stitching region. The dual to a vertex v is in a stitching region if the 8 hexahedra in the neighborhood of v are not contained by the same submesh. During point location, we check the stitching neighborhood flag for our initial neighborhood vertex v, and if v is not in a stitching region, then we can skip step three described above: testing the orientation of p with respect to dual cell faces. Furthermore, if not in a stitching region, then we can convert each component i of ξ c to its corresponding element in ξ d via the following: </p><formula>ξ d i = ξ c i + 0.5 if ξ c i &lt; 0.5 ξ c i − 0.5 otherwise. </formula><p>Computing ξ d in this manner is far cheaper than via a numeric iterative routine such as Newton-Raphson. Given a dual cell d containing a point p, and parametric terms ξ d describing the position of p within d, we obtain field values at the vertices of d, and then apply f (ξ ) to obtain our final value. Within a dual cell, f (ξ ) gives us C 0 continuity. Optionally, we can subdivide d into subtetrahedra, with C 0 continuity within each subcell. At each face shared between two dual cells, the Newton-Raphson routine produces parametric terms for each dual cell such that we are interpolating consistently within the common face, similar to the typical interpolation used with curvilinear meshes. If we choose tetrahedral decomposition, then since the decomposition is globally consistent, we have C 0 continuity both within the tetrahedra and within shared faces, guaranteeing C 0 continuity throughout the domain. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Isosurfaces in the Dual</head><p>One of the main attractions of working in the dual is that we have cells where field data are at the vertices, so we can use a standard marching cubes algorithm <ref type="bibr" coords="6,83.02,415.84,14.94,8.12" target="#b10">[11] </ref> where we process each dual cell d as a hexahedron . Optionally, we can classify each dual cell d into one of the types in <ref type="figure" coords="6,32.00,435.77,25.58,8.12" target="#tab_1">Table 1</ref> , choose diagonals for the remaining quadrilateral faces using the algorithm in Section 5.2, and decompose d into tetrahedra. Then, using the tetrahedral variation of marching cubes, we process each tetrahedron to produce its surface contribution. The main loop of the isosurface algorithm takes advantage of the duality between vertices in M and dual cells to define our iteration: </p><formula>for v ∈ M: if v ∈ ∂ M 0,0 and not covered(v) then d = dual from neighborhood vertex(v, M); process marching cell(d); endif; endfor; </formula><p>We write ∂ M 0,0 to signify the boundary of the root mesh. The dual from neighborhood vertex(v, M) method utilizes an ε-cube centered on v to locate the dual cell d corresponding to v, as described previously. We use the asymptotic decider algorithm <ref type="bibr" coords="6,212.65,605.17,14.94,8.12" target="#b14">[15] </ref>to choose in ambiguous marching cubes cases. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">VOLUME RENDERING USING RAY CASTING</head><p>We have implemented a volume rendering ray-casting application that uses the interpolation method described in the previous section. The application is designed to render output from the Enzo astrophysics simulator <ref type="bibr" coords="6,58.61,676.52,13.75,8.12" target="#b15">[16]</ref> , which uses an AMR system to calculate the gas densities and particles to represent stars and dark matter. We were particularly interested in renderings that included both the gas and particles in the same image. We render the gas using the standard adsorption and emission volume rendering model presented by Max <ref type="bibr" coords="6,172.21,726.37,13.75,8.12" target="#b12">[13]</ref> . The particles are rendered as small disks that have a constant screen size, with the idea that they are being represented as points that have been low-pass filtered to remove frequencies higher than the Nyquist limit, and thus can be sampled without aliasing. We use a disk diameter of 2.5 pixels. The opacity of each disk is calculated using a radial function, a standard cubic Smoothed Particle Hydrodynamics weighting function, which is similar to a Gaussian <ref type="bibr" coords="6,362.19,103.11,14.94,8.12" target="#b13">[14] </ref>but has finite support. The radial function is integrated along one dimension to get the disk opacity. The ray caster uses two different data structures, the AMR hierarchy for the gas plus a spatial data structure to hold the particles. The spatial data structure for the particles is based on the AMR hierarchy: particles are sorted into a series of 3D arrays that have the same dimensions and location as the AMR meshes. Each array element holds the list of particles that are located inside the corresponding AMR mesh cell. Since about 85% of the cells have no particles, and the average list size is only 4.2 particles, a simple implementation of a 3D array of pointers to dynamically-allocated arrays of particles plus a 3D array of list sizes would need much more memory than would be required to just hold the particles, in fact 95% of the particle memory would be used in overhead. This calculation is based on 64 bit pointers, 32 bit list sizes, 16 bytes of storage overhead per memory allocation, and 24 byte particles (position, mass, scalar value, and type). We reduce this overhead by using a sparse matrix format with O(1) access time to the elements. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Sparse Matrix of Particle Lists</head><p>Our sparse format is illustrated in <ref type="figure" coords="6,414.46,497.23,30.15,8.12" target="#fig_3">Figure 7</ref> . The particles are converted from a non-sparse format to a sparse format by first copying the particles to a single list, copying the particles cell-by-cell in memory layout order. The starting location of the non-empty lists are stored in an array of 32 bit integers, with the total count of particles appended to the array. The length of a particle list can be recovered by subtracting the start of a list from the next entry in the array, the start of the next list. Given this list of particle lists, an implementation could simply allocate a 3D array with each entry being either a 32 bit index to a list or, if the list is empty, a null index value. The 3D array plus the start-of-lists array would together have a memory overhead of 30% over the storage required for the particles. We instead only store part of the 3D array by considering the array as a 2D array of 1D arrays, and only storing a portion of the 1D arrays. The portion that is stored starts at the first element that points to a non-empty list, and ends at the last nonempty list pointer; we call these portions spans. All of the spans are stored in one block of storage, and a 2D array of pointers, for the two dimensions that vary the slowest, point to the corresponding spans. To avoid having to store the number of 1D array entries that were skipped, the number of skipped entries is subtracted from the pointer that is stored. This means when index for the first entry in the span is added to the pointer it points to the correct location, and subsequent entries are also pointed to correctly. In the example, the dashed arrow pointing to the span storage points to the location before the number of skipped entries is subtracted from the pointer, and the nearby solid arrow includes the subtraction. Without the subtraction, the last entry in the 'start of spans' array would be a 5. Since our sparse technique cannot be used to determine which entries of the 3D array have non-empty lists, we use a separate 3D bit vector for this. Overall, our technique reduces the amount of memory overhead to about 14% of the memory used to store the particles, or about 2.3 bytes per 3D array element. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Intersection Calculations</head><p>When casting a ray, the intersections between each ray and the two data structures are computed separately, then merged. Both intersection calculations return a list of intersections between the ray and the respective data structure. The intersections between a ray and the AMR mesh hierarchy are calculated by first finding the location where the ray enters the domain , and then stepping through the domain. When traversing a region within a single refinement level , the sampling step size is set to one fourth of the size of a cell in . When traversing a region that spans multiple refinement levels, the step size is set to one fourth of the cell spacing of the most refined mesh that makes up the current stitching cell. The samples from the meshed data are returned as intervals, with one sample at each end of the interval. Later steps in the rendering process linearly interpolate along the interval. Rays are intersected with particles using an algorithm similar to the one described by Gribble et al. <ref type="bibr" coords="7,149.14,310.51,9.52,8.12" target="#b3">[4]</ref>. This algorithm uses a 3D array which holds lists of particles as described above, and then during rendering intersects a frustum that contains several rays to find particles that may intersect one or more of the rays. While the algorithm by <ref type="bibr" coords="7,31.50,350.37,48.94,8.12">Gribble et al. </ref>uses a frustum as an acceleration technique, we use a frustum so we can find all of the constant-screen-size disks that intersect the ray. We need to use a frustum because constant-screen-size disks in an image with perspective correspond to disks that vary in size, with disks that are far from the eye being larger than ones that are close to the eye. We also adapt the earlier algorithm to handle AMR meshes. Our intersection algorithm starts by finding intersections between the frustum and the least refined mesh. Then, if any cell intersects the frustum, the algorithm recursively tests all of the refined meshes that overlap the coarser mesh. The algorithm uses a " visited " bit vector to ensure a given mesh is only tested once. When the frustum around the ray is found to intersect a cell, each particle in the cell's list of particles is tested for intersection with the ray. If the particle intersects the ray, an intersection record is stored in the list of particle intersections. The intersection record treats the particles as disks with no depth, to simplify the merging step described shortly. When all of the particle intersections have been recorded, they are sorted by depth. The final intersection step is to merge the interval intersections from the AMR hierarchy with the particle intersections. This is done by scanning through the two intersections lists at the same time, from front to back, and creating a merged list. The merging code has two primary cases. The simple case is when an interval intersection or particle intersection is found that does not overlap with another intersection . In this case, the intersection is copied directly to the merged list. The more complex case occurs when an interval intersection overlaps with one or more particle intersections. Here, the interval intersection is split at the point or points of overlap, and the split interval intersections and particle intersections are copied to the merged list in front-to-back order. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Intersection List Compositing</head><p> Once the merged list has been calculated, the final pixel color is computed from the ray intersections in the list. This is done by stepping along the intersections and using the scalar value and the appropriate transfer function to calculate the color at that position. Three different transfer functions are used, one each for the gas, stars, and dark matter. The colors along the ray are composited front-to-back using a standard numeric integration technique <ref type="bibr" coords="7,141.18,736.33,13.75,8.12" target="#b12">[13]</ref>. <ref type="figure" coords="7,294.12,239.42,19.61,7.64">Fig. 8</ref> . The counts (scale at left of graph) for mesh vertices, hexahedra , and dual (possibly degenerate) hexahedra rose from time step 0 to 10, then slowly declined through the remaining time steps. The patch count (scale at right of graph) also peaked at time step 10 then slowly declined from approximately 40 thousand to 20 thousand. The star particles count grew from 30 million initially to 54 million at the end of the run, time step 1561. The dark particles count stayed fixed at 18 million. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">RESULTS</head><p>We tested our implementation with the output from an Enzo galaxy formation study <ref type="bibr" coords="7,354.82,350.18,9.52,8.12" target="#b4">[5]</ref> . The domain was a 39.1 megaparsec box in comoving coordinates. The simulation maintained a maximum refinement level of 11 or 12 throughout the run, with the root mesh divided into 128 cells in each dimension and a refinement ratio of 2. At the finest level cells were 0.15 kiloparsecs in size. The run consisted of 1562 time steps, starting at redshift 1 and ending at redshift 0. <ref type="figure" coords="7,514.72,399.98,29.77,8.12">Figure 8</ref> summarizes how the data sizes changed over the course of the simulation . Vertex, hexahedron, dual hexahedron and patch counts peaked at time step 10, and then slowly declined to roughly half their peak values by the end of the simulation. The number of star particles grew monotonically over the course of the run; the number of dark matter particles remained constant throughout. In bytes, the study ranged between 8.1 and 13 GByte per time step, totaling to 14 TByte for the full time series. <ref type="figure" coords="7,294.12,507.54,23.96,7.64" target="#tab_2">Table 2</ref>. A summary of dual cell percentages, averaged over the full time series: we classify each dual cell by whether it is a stitching cell, and for each stitching cell the difference in refinement levels that it spans, ∆. <ref type="figure" coords="7,304.08,636.70,27.60,8.12" target="#tab_2">Table 2</ref>summarizes the classification of dual cell types over the simulation run. Even though the overall mesh cell counts decreased by a factor of two during the run, the dual type distribution was approximately the same throughout. An average of roughly 1% of the dual cells (both non-stitching and stitching) spanned more than one refinement level in the dual. Of the stitching cells alone, 3% spanned more than one refinement level. We produced our timings on systems with dual 2.93GHz Xeon processors with 12 cores and 48 GByte of shared memory. At start-up we reconstructed the mesh hierarchy and computed per-vertex flags in support of predicates that would indicate whether a vertex is on the  root-mesh boundary, covered, or in a stitching neighborhood. The initialization step took approximately 6 seconds for the largest data time steps. Internally we implemented bounding-box intersection and point location routines using integer math in order to unambiguously detect non-general-position cases. We utilized the int128 t type provided by the g++ compiler in order to evaluate orientation predicates where more than 64 bits of precision were needed, without resorting to doing extended-precision integer math in our implementation. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Dual </head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1">Isosurfaces</head><p>In order to test our isosurface capability, we computed surfaces of the density field for a wide range of thresholds, for each time step of the simulation. For a given time step, we precomputed the data range for each patch, and then for a particular isosurface threshold we skipped patches that were not in range. The remaining patches were processed in parallel. Execution times were roughly proportionate to the number of dual hexahedra tested by the marching cubes code for a given threshold. <ref type="figure" coords="8,323.44,405.21,34.41,8.12" target="#fig_7">Figure 10</ref>illustrates the relationship for data at time step 10 and 1561, corresponding to instances with the largest and smallest cell counts, respectively. At time step 10, execution times varied between 0 and 4 seconds. At time step 1561, times ranged between 0 and 1 second. Plots of the execution times for other time steps are similar in form, and are omitted to avoid cluttering the graph. Execution times at the end of the run may be smaller not only because the data were smaller, but also because the density field was less evenly distributed, allowing more patches to be skipped via the range test. <ref type="figure" coords="8,295.08,495.07,29.79,8.12" target="#fig_5">Figure 9</ref> illustrates how contributions from non-stitching and stitching regions combine to produce an isosurface. Here we see the pay-off of choosing diagonals consistently for each shared quadrilateral face in the dual mesh in that we have a surface without cracks. We shade the surface corresponding to which type of region it intersects in the dual mesh. Regions where the surface intersects dual cells in a single patch (i.e., the non-stitching regions) are shaded white. Surface contributions from stitching regions are colored blue, green, gold and magenta, corresponding to dual hexahedra spanning a difference in levels, ∆, of 0, 1, 2 and 3, respectively. Contributions from dual cells with ∆ &gt; 1 were not supported in previous work. While such cells are typically a relatively small part of the domain, our ability to handle them gives us surfaces that are complete, in particular in regions where mesh adaption has been most active. While we implemented the option of completely subdividing each dual hexahedron into tetrahedra, and then processing each tetrahedron with the tetrahedral variation of marching cubes, we did not find any advantage that justified the additional processing and output size that were consequences of that approach. <ref type="figure" coords="8,285.12,706.44,35.48,8.12">Figure 11</ref>shows example output of our ray-casting implementation. The C 0 continuous interpolation means that no interpolation artifacts can be seen in the frame. Our collaborator was pleased with the image quality, and was particularly interested in images that combined <ref type="figure" coords="9,31.50,551.55,22.97,7.64">Fig. 11</ref>. Images showing a close-up view of a galaxy cluster (a small portion of the overall domain). Gas density is shown using reds and yellows, stars are shown in white, and dark matter in blue. All of the images show the same time step (730). Top left: Volume rendering of the simulation output showing total gas density. Top right: Neutral hydrogen density and particle rendering. Bottom left: Gas density and particle rendering. Bottom right: Particle-only rendering. tributions from both particle and gridded data. An animation showing the tracking of a cluster through the full time series is included in the supplementary materials. Rendering a 1024 × 1024 image for all 1562 time steps took an average of 160 seconds per frame, excluding I/O. The time is approximately equally split between volume rendering and point rendering. A run that only performs volume rendering (showing gas density only) frames took an average of 90 seconds per frame, while a particle-only run took about the same time, 87 seconds per frame. More timing details are shown in <ref type="figure" coords="9,104.98,703.73,25.30,8.12" target="#tab_3">Table 3</ref>. Our initial volume rendering implementation took more time to render frames. We were able to decrease the rendering time by about 60% by optimizing the case where a ray sample location was inside a <ref type="figure" coords="9,487.71,726.37,26.91,8.12" target="#tab_2">Table 2</ref>that the majority of the domain is filled with non-stitching cells. Section 5.3 describes the our optimizations in point-location and interpolation. We also optimize retrieving the 8 field values in preparation for interpolation when the sample location is inside a patch. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2">Ray Casting</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">CONCLUSION</head><p>We have presented a new algorithm for stitching between dual regions in AMR data that does not require that adjacent patches differ by at most one refinement level. Our work fills a gap, so to speak, in previous work for this data type. We have shown applications of our technique in both isosurface generation and ray casting. While unrestricted AMR is not particularly common, Enzo <ref type="bibr" coords="10,169.80,154.98,14.94,8.12" target="#b15">[16] </ref> is in relatively wide usage within the astrophysics community and is the source of many interesting data sets. We expect that our approach would apply equally well for systems that implement either restricted or unrestricted AMR. Furthermore, we expect that our approach would handle cases where AMR is implemented with refinement ratios greater than 2. Larger refinement ratios introduce many of the same issues as unrestricted AMR, and we expect we could address them much the same way with our approach. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="3,31.50,329.31,195.29,8.70;3,226.80,328.21,313.70,8.74"><head>Fig. 2. </head><figDesc>Fig. 2. We illustrate a simple example of AMR data in R 2 to the left, with the dual and stitching to the right. Stitching regions are colored in green. </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="4,22.50,613.11,250.37,7.64;4,22.50,622.56,63.15,7.64;4,22.50,644.48,250.38,8.12;4,22.50,654.43,250.37,8.12;4,22.50,664.39,250.38,8.12;4,22.50,674.36,250.36,8.12;4,22.50,684.32,159.22,8.12"><head>Fig. 4. </head><figDesc>Fig. 4. The pyramid-prism and pyramid-pyramid decompositions of the dual cell type PW. how the diagonal choices for the two quadrilateral faces sharing the collapsed vertex impact the choice of decomposition of the dual cell. To the left of Figure 4 we see the diagonal choices that allow for a pyramid-prism decomposition, and to the right the diagonal choices that allow for a two pyramid decomposition. </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="6,285.12,445.32,250.38,7.64;6,285.12,454.79,130.27,7.64"><head>Fig. 7. </head><figDesc>Fig. 7. Example sparse representation of a 3D array of lists of particles. The particles are indicated by letters. </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5" coords="8,22.50,315.03,512.99,7.64;8,22.50,324.48,512.99,7.64;8,22.50,333.95,479.95,7.64"><head>Fig. 9. </head><figDesc>Fig. 9. Example image of a single connected component of an isosurface of the density field, colored by the type of dual cell that the surface intersects. The white surface corresponds to regions inside a single patch (i.e., non-stitching regions). Blue corresponds to stitching regions among patches at the same refinement level. Green, gold and magenta correspond to differences in refinement level of 1, 2, and 3, respectively. </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6" coords="8,50.97,598.71,3.25,5.61;8,46.09,584.54,8.13,5.61;8,50.97,570.37,3.25,5.61;8,46.09,556.20,8.13,5.61;8,50.97,542.03,3.25,5.61;8,46.09,527.89,8.13,5.61;8,50.97,513.72,3.25,5.61;8,46.09,499.55,8.13,5.61;8,50.97,485.38,3.25,5.61;8,46.09,471.21,8.13,5.61;8,56.92,604.56,3.25,5.61;8,83.69,604.56,13.01,5.61;8,116.16,604.56,13.01,5.61;8,148.63,604.56,13.01,5.61;8,181.06,604.56,13.01,5.61;8,213.53,604.56,13.01,5.61;8,243.56,604.56,17.89,5.61;8,32.99,539.14,5.61,25.69;8,32.99,526.14,5.61,13.00;8,32.99,513.14,5.61,13.00;8,111.37,613.33,84.20,5.61;8,86.18,462.44,129.72,5.61;8,171.91,587.89,55.60,5.61;8,171.91,593.74,55.60,5.61"><head>Execution </head><figDesc>Time (sec) Number of Dual Hexahedra Tested Isosurface Execution Time Vs. Tested Dual Cell Count 0010-dual-hexahedra 1561-dual-hexahedra </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7" coords="8,22.50,633.34,250.38,7.64;8,22.50,642.81,250.38,7.64;8,22.50,652.26,250.36,7.64;8,22.50,661.73,250.37,7.64;8,22.50,671.19,240.63,7.64"><head>Fig. 10. </head><figDesc> Fig. 10. Isosurface execution time was roughly proportional to the number of dual hexahedra tested by the marching cubes algorithm. At time step 10 (maximum mesh cell counts), execution time varied between 0 to 4 seconds, depending on isosurface threshold. At the end of the simulation (time step 1561), maximum execution time was 1 second. </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false" coords="3,331.92,366.77,174.78,94.35"><figDesc coords="3,339.29,367.86,27.68,7.64">Table 1.</figDesc><table coords="3,331.92,366.77,174.78,94.35">R 3 dual cell types, see also Figure 3. 

Type 
# Collapsed Edges 
# Remaining Q Faces 
H 
0 
6 
PW 
1 
4 
W 
2 
3 
PP 
2 
2 
TT 
3 
2 
P 
4 
1 
T 
5 
0 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false" coords="3,541.32,736.33,3.17,8.12"><figDesc coords="3,541.32,736.33,3.17,8.12">.</figDesc><table coords="4,93.75,166.47,370.04,7.64">H 

PW 
W 
PP 
TT 
P 
T 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false" coords="5,304.08,156.15,183.64,157.46"><figDesc coords="5,351.78,185.93,25.78,8.12;5,314.05,195.89,51.53,8.23;5,324.01,205.85,67.68,8.23;5,324.01,215.37,58.76,8.97;5,324.01,225.78,53.66,8.15;5,333.97,235.85,140.76,8.12;5,333.97,245.81,153.75,8.12;5,333.97,255.67,65.02,8.15;5,333.97,265.63,24.74,8.12;5,324.01,275.60,21.92,8.12;5,314.05,285.56,27.67,8.12;5,314.05,295.52,65.48,8.15;5,304.08,305.48,36.73,8.12">= true; for f in 0 .. 5: o = orient(p, d, f ); outside = o &lt; 0; if outside then v = step neighborhood vertex(v, f , M); d = dual from neighborhood vertex(v, M); all inside = false; break; endif; endfor; done = all inside; endwhile;</figDesc><table coords="5,304.08,156.15,153.75,37.93">= dual from neighborhood vertex(v, M); 
done = false; 
while not done: 
all inside </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" validated="true" coords="9,294.12,617.44,250.37,117.06"><figDesc coords="9,294.12,617.44,250.37,7.64;9,294.12,626.90,206.82,7.64">Table 3. Volume rendering timing results, summarized for rendering the entire series of 1562 time steps. The times are in seconds.</figDesc><table coords="9,294.12,646.47,218.39,88.02">Median 
Minimum 
Maximum 
Gas and particles 
160 
138 
174 
Gas only 
90 
77 
106 
Particles only 
87 
74 
98 

gle patch, i.e., not in a stitching region. Recall from </table></figure>

			<note place="foot">MORAN AND ELLSWORTH: VISUALIZATION OF AMR DATA WITH MULTI-LEVEL DUAL-MESH INTERPOLATION</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS </head><p> We would like to thank Renyue Cen for providing the Enzo simulation data set <ref type="bibr" coords="10,69.48,276.60,10.46,8.12" target="#b4">[5] </ref>used as an example in the previous sections, and for guidance with respect to some of the scientific questions motivating the work. We would also like to thank Timothy Sandstrom for providing the camera paths used in the animations that accompany this work. Finally, we would like to thank the anonymous reviewers for their constructive comments. </p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct coords="10,40.76,358.44,232.13,7.22;10,40.76,367.90,211.01,7.22"  xml:id="b0">
	<analytic>
		<title level="a" type="main">Local adaptive mesh refinement for shock hydrodynamics</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Berger</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Colella</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Computational Physics</title>
		<imprint>
			<biblScope unit="volume">82</biblScope>
			<biblScope unit="page" from="64" to="84" />
			<date type="published" when="1989" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,40.76,377.37,232.11,7.22;10,40.76,386.83,232.13,7.22;10,40.76,396.30,17.94,7.22"  xml:id="b1">
	<analytic>
		<title level="a" type="main">Adaptive mesh refinement for hyperbolic partial differential equations</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Berger</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Oliger</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Computational Physics</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="page" from="484" to="512" />
			<date type="published" when="1984" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,40.76,405.77,232.12,7.22;10,40.76,415.22,151.23,7.22"  xml:id="b2">
	<analytic>
		<title level="a" type="main">Fluids in the universe: adaptive mesh refinement in cosmology</title>
		<author>
			<persName>
				<forename type="first">G</forename>
				<forename type="middle">L</forename>
				<surname>Bryan</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Sci. Eng</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="46" to="53" />
			<date type="published" when="1999-04" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,40.76,424.69,232.12,7.22;10,40.76,434.15,232.11,7.22;10,40.76,443.62,232.13,7.22;10,40.76,453.09,33.88,7.22"  xml:id="b3">
	<analytic>
		<title level="a" type="main">A coherent grid traversal approach to visualizing particle-based simulation data</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<forename type="middle">P</forename>
				<surname>Gribble</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Ize</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Kensler</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">I</forename>
				<surname>Wald</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">S</forename>
				<forename type="middle">G</forename>
				<surname>Parker</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="758" to="768" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,40.76,462.55,232.12,7.22;10,40.76,472.01,232.10,7.22;10,40.76,481.47,54.25,7.22"  xml:id="b4">
	<analytic>
		<title level="a" type="main">Galaxy size problem at z = 3: Simulated galaxies are too small</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<forename type="middle">R</forename>
				<surname>Joung</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Cen</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">G</forename>
				<forename type="middle">L</forename>
				<surname>Bryan</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Astrophysical Journal Letters</title>
		<imprint>
			<biblScope unit="volume">692</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">1</biblScope>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,40.76,490.94,232.12,7.22;10,40.76,500.41,174.66,7.22"  xml:id="b5">
	<analytic>
		<title level="a" type="main">Accelerated Volume Rendering on Structured Adaptive Meshes</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Kähler</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Zuse Institute Berlin (ZIB)</title>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,40.76,509.87,232.12,7.22;10,40.76,519.34,232.12,7.22;10,40.76,528.80,223.25,7.22"  xml:id="b6">
	<analytic>
		<title level="a" type="main">Simultaneous GPU-assisted raycasting of unstructured point sets and volumetric grid data</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Kähler</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Abel</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">H.-C</forename>
				<surname>Hege</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of IEEE/EG Symposium on Volume Graphics</title>
		<meeting>. of IEEE/EG Symposium on Volume Graphics</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="49" to="56" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,40.76,538.26,232.12,7.22;10,40.76,547.73,232.11,7.22;10,40.76,557.19,91.88,7.22"  xml:id="b7">
	<monogr>
		<title level="m" type="main">GPU-assisted raycasting for cosmological adaptive mesh refinement simulations</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Kähler</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Wise</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Abel</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">H.-C</forename>
				<surname>Hege</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2006" />
			<publisher>A K Peters Ltd</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,40.76,566.66,232.12,7.22;10,40.76,576.13,232.11,7.22;10,40.76,585.59,220.51,7.22"  xml:id="b8">
	<monogr>
		<title level="m" type="main">Remote interactive direct volume rendering of AMR data</title>
		<author>
			<persName>
				<forename type="first">O</forename>
				<surname>Kreylos</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">G</forename>
				<forename type="middle">H</forename>
				<surname>Weber</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">E</forename>
				<forename type="middle">W</forename>
				<surname>Bethel</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">M</forename>
				<surname>Shalf</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">B</forename>
				<surname>Hamann</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">K</forename>
				<forename type="middle">I</forename>
				<surname>Joy</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,40.76,595.05,232.11,7.22;10,40.76,604.51,225.03,7.22"  xml:id="b9">
	<analytic>
		<title level="a" type="main">A hybrid ray tracer for rendering polygon and volume data</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Levoy</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics and Applications IEEE</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="33" to="40" />
			<date type="published" when="1990-03" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,40.76,613.98,232.12,7.22;10,40.76,623.45,232.12,7.22;10,40.76,632.91,178.05,7.22"  xml:id="b10">
	<analytic>
		<title level="a" type="main">Marching cubes: A high resolution 3D surface construction algorithm</title>
		<author>
			<persName>
				<forename type="first">W</forename>
				<forename type="middle">E</forename>
				<surname>Lorensen</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">H</forename>
				<forename type="middle">E</forename>
				<surname>Cline</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Graphics (Proceedings of SIGGRAPH 87)</title>
		<imprint>
			<date type="published" when="1987-07" />
			<biblScope unit="page" from="163" to="169" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,40.76,642.38,232.12,7.22;10,40.76,651.83,232.12,7.22;10,40.76,661.30,166.16,7.22"  xml:id="b11">
	<analytic>
		<title level="a" type="main">High-quality, semi-analytical volume rendering for AMR data</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Marchesin</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Deverdì Ere</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1611" to="1618" />
			<date type="published" when="2009-12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,40.76,670.77,232.11,7.22;10,40.76,680.23,212.72,7.22"  xml:id="b12">
	<analytic>
		<title level="a" type="main">Optical models for direct volume rendering</title>
		<author>
			<persName>
				<forename type="first">N</forename>
				<surname>Max</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="99" to="108" />
			<date type="published" when="1995-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,40.76,689.70,232.12,7.22;10,40.76,699.17,163.78,7.22"  xml:id="b13">
	<analytic>
		<title level="a" type="main">Smoothed particle hydrodynamics</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">J</forename>
				<surname>Monaghan</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Annual Review of Astronomy and Astrophysics</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="543" to="574" />
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,40.76,708.62,232.12,7.22;10,40.76,718.09,226.33,7.22"  xml:id="b14">
	<analytic>
		<title level="a" type="main">The asymptotic decider: Removing the ambiguity in marching cubes</title>
		<author>
			<persName>
				<forename type="first">G</forename>
				<forename type="middle">M</forename>
				<surname>Nielson</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">B</forename>
				<surname>Hamann</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Visualization &apos;91</title>
		<imprint>
			<date type="published" when="1991" />
			<biblScope unit="page" from="83" to="91" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,40.76,727.55,232.12,7.22;10,40.76,737.02,232.11,7.22;10,303.38,53.98,232.12,7.22;10,303.38,63.45,108.71,7.22"  xml:id="b15">
	<analytic>
		<title level="a" type="main">Simulating Cosmological Evolution with Enzo</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<forename type="middle">L</forename>
				<surname>Norman</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">G</forename>
				<forename type="middle">L</forename>
				<surname>Bryan</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Harkness</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Bordner</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Reynolds</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">B</forename>
				<forename type="middle">O</forename>
				<surname>Shea</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Wagner</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Petascale Computing: Algorithms and Applications . Chapman and Hall</title>
		<editor>D. Bader</editor>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,303.38,72.91,232.12,7.22;10,303.38,82.38,232.12,7.22;10,303.38,91.84,232.13,7.22;10,303.38,101.31,58.46,7.22"  xml:id="b16">
	<analytic>
		<title level="a" type="main">Diving deep: Data management and visualization strategies for adaptive mesh refinement simulations</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<forename type="middle">L</forename>
				<surname>Norman</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">M</forename>
				<surname>Shalf</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Levy</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">G</forename>
				<surname>Daues</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computing in Science and Engineering</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="36" to="47" />
			<date type="published" when="1999-08" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,303.38,110.77,232.12,7.22;10,303.38,120.23,232.12,7.22;10,303.38,129.70,150.47,7.22"  xml:id="b17">
	<analytic>
		<title level="a" type="main">Case study: Interactive rendering of adaptive mesh refinement data</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Park</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">C</forename>
				<forename type="middle">L</forename>
				<surname>Bajaj</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">V</forename>
				<surname>Siddavanahalli</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Visualization 2002</title>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2002" />
			<biblScope unit="page" from="521" to="524" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,303.38,139.16,232.11,7.22;10,303.38,148.63,232.11,7.22;10,303.38,158.09,232.11,7.22;10,303.38,167.55,17.94,7.22"  xml:id="b18">
	<analytic>
		<title level="a" type="main">yt: A Multi-Code Analysis Toolkit for Astrophysical Simulation Data</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<forename type="middle">J</forename>
				<surname>Turk</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">B</forename>
				<forename type="middle">D</forename>
				<surname>Smith</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">S</forename>
				<surname>Oishi</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Skory</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">S</forename>
				<forename type="middle">W</forename>
				<surname>Skillman</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Abel</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">M</forename>
				<forename type="middle">L</forename>
				<surname>Norman</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Astrophysical Journal Supplement</title>
		<imprint>
			<biblScope unit="volume">192</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2011-01" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,303.38,177.02,232.11,7.22;10,303.38,186.49,232.12,7.22;10,303.38,195.95,232.12,7.22;10,303.38,205.42,61.99,7.22"  xml:id="b19">
	<analytic>
		<title level="a" type="main">Visualization tools for adaptive mesh refinement data</title>
		<author>
			<persName>
				<forename type="first">G</forename>
				<forename type="middle">H</forename>
				<surname>Weber</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">V</forename>
				<forename type="middle">E</forename>
				<surname>Beckner</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">H</forename>
				<surname>Childs</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">T</forename>
				<forename type="middle">J</forename>
				<surname>Ligocki</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">M</forename>
				<forename type="middle">C</forename>
				<surname>Miller</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">B</forename>
				<forename type="middle">V</forename>
				<surname>Straalen</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">E</forename>
				<forename type="middle">W</forename>
				<surname>Bethel</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 4th High-End Visualization Workshop</title>
		<meeting>the 4th High-End Visualization Workshop</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="18" to="22" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,303.38,214.88,232.11,7.22;10,303.38,224.34,232.12,7.22;10,303.38,233.81,232.12,7.22;10,303.38,243.27,232.11,7.22;10,303.38,252.74,34.54,7.22"  xml:id="b20">
	<analytic>
		<title level="a" type="main">Extraction of crack-free isosurfaces from adaptive mesh refinement data</title>
		<author>
			<persName>
				<forename type="first">G</forename>
				<forename type="middle">H</forename>
				<surname>Weber</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">O</forename>
				<surname>Kreylos</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">T</forename>
				<forename type="middle">J</forename>
				<surname>Ligocki</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">M</forename>
				<surname>Shalf</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">H</forename>
				<surname>Hagen</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">B</forename>
				<surname>Hamann</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">K</forename>
				<forename type="middle">I</forename>
				<surname>Joy</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Data Visualization 2001: Proceedings of the Joint Eurographics -IEEE TVCG</title>
		<imprint>
			<publisher>Springer Verlag</publisher>
			<date type="published" when="2001-03" />
			<biblScope unit="page" from="25" to="34335" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,303.38,262.20,232.11,7.22;10,303.38,271.67,232.13,7.22;10,303.38,281.13,232.10,7.22;10,303.38,290.59,102.97,7.22"  xml:id="b21">
	<analytic>
		<title level="a" type="main">High-quality volume rendering of adaptive mesh refinement data</title>
		<author>
			<persName>
				<forename type="first">G</forename>
				<forename type="middle">H</forename>
				<surname>Weber</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">O</forename>
				<surname>Kreylos</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">T</forename>
				<forename type="middle">J</forename>
				<surname>Ligocki</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">M</forename>
				<surname>Shalf</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">H</forename>
				<surname>Hagen</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">B</forename>
				<surname>Hamann</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">K</forename>
				<forename type="middle">I</forename>
				<surname>Joy</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">K.-L</forename>
				<surname>Ma</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Vision, Modeling &amp; Visualization</title>
		<imprint>
			<date type="published" when="2001-11" />
			<biblScope unit="page" from="121" to="128" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
