<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/pisenberg/grobid/grobid-0.6.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">EmbeddingVis: A Visual Analytics Approach to Comparative Network Embedding Inspection</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quan</forename><surname>Li</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Engineering</orgName>
								<orgName type="institution">The Hong Kong University of Science and Technology</orgName>
								<address>
									<addrLine>Hong Kong 2 WeChat</addrLine>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">Tencent Technology (Shenzhen) Co., Ltd</orgName>
								<address>
									<settlement>Shenzhen</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristanto</forename><forename type="middle">Sean</forename><surname>Njotoprawiro</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Engineering</orgName>
								<orgName type="institution">The Hong Kong University of Science and Technology</orgName>
								<address>
									<addrLine>Hong Kong 2 WeChat</addrLine>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">Tencent Technology (Shenzhen) Co., Ltd</orgName>
								<address>
									<settlement>Shenzhen</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hammad</forename><surname>Haleem</surname></persName>
							<email>hhaleem@connect.ust.hk</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Engineering</orgName>
								<orgName type="institution">The Hong Kong University of Science and Technology</orgName>
								<address>
									<addrLine>Hong Kong 2 WeChat</addrLine>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">Tencent Technology (Shenzhen) Co., Ltd</orgName>
								<address>
									<settlement>Shenzhen</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiaoan</forename><surname>Chen</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><forename type="middle">Yi</forename><surname>¶2</surname></persName>
							<email>chrisyi@tencent.com</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaojuan</forename><surname>Ma</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Engineering</orgName>
								<orgName type="institution">The Hong Kong University of Science and Technology</orgName>
								<address>
									<addrLine>Hong Kong 2 WeChat</addrLine>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">Tencent Technology (Shenzhen) Co., Ltd</orgName>
								<address>
									<settlement>Shenzhen</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">EmbeddingVis: A Visual Analytics Approach to Comparative Network Embedding Inspection</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2021-02-19T20:15+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
				<p>Figure 1: EmbeddingVis consists of (1) control panel, (2) graph view, (3) cluster transition view, (4) pairwise ranking view and (5) structural view. Using EmbeddingVis to verify preserved metrics at the instance level: (a) users lasso a cluster of nodes and the corresponding nodes are highlighted and linked across different embedding spaces (b1-e1). Clicking one &quot;hub&quot; node in this cluster (label 20) in the graph view generates four neighbor ranking lists of this &quot;hub&quot; node: (b2) the graph space, (c2) DeepWalk, (d2) struc2vec, and (e2) node2vec. The highlighted rectangles (c2, d2, e2) indicate the preserved metrics by each embedding. (f) Users can click &quot;Filter&quot; to highlight the nodes of each ranking list in the cluster transition view (b3-e3). (g) The Euclidean distance between adjacent nodes in struc2vec is more volatile compared with that in the other two spaces.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>space to a two-dimensional display. Although the existing visualization methods allow simple examination of the structure of embedding space, they cannot support in-depth exploration of the embedding vectors. In this paper, we design an exploratory visual analytics system that supports the comparative visual interpretation of embedding vectors at the cluster, instance, and structural levels. To be more specific, it facilitates comparison of what and how node metrics are preserved across different embedding models and investigation of relationships between node metrics and selected embedding vectors. Several case studies confirm the efficacy of our system. Experts' feedback suggests that our approach indeed helps them better embrace the understanding of network embedding models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Index Terms:</head><p>Human-centered computing-Visualization-Visualization application domains-Visual analytics; Humancentered computing-Visualization-Visualization design and evaluation methods</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Data mining and machine learning (ML) enable the discovery of insights into information networks, such as social and paper citation networks. Identifying an appropriate graph representation is necessary prior to conducting any analysis. A direct and conventional IEEE Conference on Visual Analytics Science and Technology (VAST) 21-26 October 2018, Berlin, Germany 978-1-5386-6861-0/18/$31.00 ©2018 IEEE representation is the adjacency matrix, whereas edges between nodes are indicated as entries in a matrix. However, this representation frequently suffers due to its quadratic size and potential sparsity and is thus not well suited for many analysis tasks <ref type="bibr" target="#b38">[39]</ref>. Researchers and practitioners have recently found network embedding as a promising and powerful alternative to large network representation <ref type="bibr" target="#b4">[5]</ref>.</p><p>Network embedding represents a graph in a low-dimensional vector space while preserving as much graph information as possible <ref type="bibr" target="#b4">[5]</ref>. Thus, mining tasks performed on the original network, such as node classification <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b42">43,</ref><ref type="bibr" target="#b45">46]</ref>, clustering <ref type="bibr" target="#b21">[22]</ref>, and link prediction <ref type="bibr" target="#b25">[26]</ref>, can be instead conducted in its embedding space. ML researchers have proposed numerous network embedding techniques that emphasize different items to be preserved in the vector space, such as characteristics of nodes, edges, substructures, or entire graphs. Cai et al. <ref type="bibr" target="#b4">[5]</ref> classified existing network embedding techniques into five categories, namely, (1) matrix factorization-based methods, such as singular value decomposition and spectral decomposition (eigen-decomposition) <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b33">34]</ref>; (2) deep learning (DL)-based methods with or without random walk <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b43">44,</ref><ref type="bibr" target="#b45">46]</ref>; (3) edge reconstruction-based methods, including maximizing edge reconstruct probability or minimizing distance-based loss or margin-based ranking loss <ref type="bibr" target="#b26">[27,</ref><ref type="bibr" target="#b42">43]</ref>; (4) graph kernel-based methods <ref type="bibr" target="#b50">[51]</ref>; and (5) generative model-based methods that incorporate latent semantics <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b49">50]</ref>. In this study, we mainly focus on DL-based methods, especially those with random walk, due to their effectiveness and robustness in the absence of feature engineering <ref type="bibr" target="#b4">[5]</ref>. Furthermore, these methods present only a few barriers to entry for individuals who aim to explore embeddings and are more general than the others because they consider the intrinsic features of a graph while the others explicitly define a few optimization objectives <ref type="bibr" target="#b4">[5]</ref>.</p><p>Although network embeddings have demonstrated promising performance in various mining tasks, the inner structure of an embedding space and the items preserved in it are not transparent to users for several reasons. (1) Abstract Representation. The basis vectors in a typical embedding, which differ from conventional "highdimensional" vectors, have no explicit meaning <ref type="bibr" target="#b41">[42]</ref>. In other words, the actual value of an embedding vector is difficult to interpret and cannot be intuitively mapped to certain graph features. Therefore, vectors from different embedding spaces are not directly comparable, thus obscuring the proper evaluation and leveraging of embedding models for users. Understanding abstract vector representations can be compared with the efforts in "understanding what specified input maximizes the activation of a particular element in the neural network" <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b38">39]</ref>. (2) Inefficient Exploration. Users must often undergo trial-and-error processes to manually inspect embedding results due to the stochastic nature of the construction procedure; these processes include random walk-based sampling and non-transparent hyper-parameters. Thus, users demand an intuitive interactive mechanism for the effective comparison and understanding of different embedding results, allocation of computational and human resources, and making informed decisions. (3) Shallow-Level Analysis. Visualization tools such as Embedding Projector <ref type="bibr" target="#b41">[42]</ref> by Google Brain, have been developed to help interpret embeddings adopted by ML models. By projecting a single embedding space on a 2D/3D display, these tools can facilitate the investigation of the global geometry distribution and local neighbors of a selected vector point. Fine-grained analyses, such as studying and comparing capabilities to retain semantic and (or) structural information across different embedding models, are challenging despite the support of these tools for similarity comparisons that are based on attained embedding vectors. The authors of Embedding Projector also indicated that "it could be useful to visually compare two embeddings when developing multiple models." To achieve this purpose, nontrivial visualization is required to overcome the difficulties in analyzing and comparing different embedding results. Furthermore, empirical studies on the extent to which a visualization system can resolve breakdowns in ML practitioners' understanding of embeddings and bridge their knowledge with the investigation of embedding results are limited.</p><p>In this study, we propose EmbeddingVis, an interactive visual analytics system that helps ML practitioners understand and compare different embedding models. We conduct an observational study of collaboration partner experts' current practices in social network analysis and identify their primary needs and concerns regarding the use of network embedding. We then investigate what and how node metrics are preserved by selected embedding models through a regression analysis. We also propose the use of the "average distance vector" for depicting structural characteristics in studying the capability of an embedding model. On the basis of these objectives, we develop a visualization system to support fine-grained analysis at the cluster, instance, and structural levels. Several cases evaluate the efficacy of our system. Our primary contributions are as follows:</p><p>• We identify node metric correlations between the graph space and the embedding space and propose the use of the "average distance vector" to depict structural characteristics. • We develop suitable interactive visualizations enhanced with new features to support fine-grained analysis of embedding vectors from the cluster, instance, and structural perspectives. • We showcase an experience of working with ML practitioners and several cases to verify the efficacy of our system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK</head><p>Literature that overlaps with those of this work can be categorized into three groups: embedding model evaluation, explanation of embedding vector space, and visual comparison.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Evaluation of Embedding Models</head><p>Evaluating embedding models usually requires applying the embeddings to ML tasks. In network compression, Wang et al. <ref type="bibr" target="#b45">[46]</ref> and Ou et al. <ref type="bibr" target="#b33">[34]</ref> reconstructed the original graph from the embedding space and evaluated the reconstruction error. In node classification, the missing label of a node can be inferred from the links in the network using tagged nodes <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b42">43,</ref><ref type="bibr" target="#b45">46]</ref>. In clustering, Li et al. <ref type="bibr" target="#b21">[22]</ref> evaluated the effectiveness of DeepWalk <ref type="bibr" target="#b35">[36]</ref> and LINE <ref type="bibr" target="#b42">[43]</ref> and found that they performed similarly. Link prediction can predict future interactions or links that may occur in a growing network, such as prediction of possible friendships <ref type="bibr" target="#b25">[26]</ref>. Visualization also helps in analyzing embedding results. For example, the effectiveness of DeepWalk is illustrated by visualizing the Zachary's Karate Club network <ref type="bibr" target="#b35">[36]</ref>. LINE visualizes the DBLP co-authorship network and shows that LINE can cluster authors from the same field <ref type="bibr" target="#b42">[43]</ref>. However, all these methods simply project the embedding space to a 2D plane. Although Embedding Projector helps explore neighborhoods for individual nodes <ref type="bibr" target="#b41">[42]</ref>, fine-grained analysis is still limited.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Explanation of Embedding Vector Space</head><p>Interpreting embedding space has recently attracted researchers' attention. Dimensionality reduction techniques, such as t-distributed stochastic neighbor embeddings (t-SNE) <ref type="bibr" target="#b29">[30]</ref>, principal component analysis (PCA) and Multidimensional scaling (MDS), are used to create 2D embedding for exploring overall structures and linear relationships <ref type="bibr" target="#b32">[33]</ref>. For example, Liu et al. <ref type="bibr" target="#b28">[29]</ref> introduced a new embedding to visualize semantic and syntactic analogies and thus determine whether the resulting view captures significant structures. Similarly, network embedding represents each graph node as a low-dimensional vector <ref type="bibr" target="#b35">[36]</ref>. Although the decomposition method based on eigenvalue provides some formal guarantee for the preserved node properties, methods based on random walk are essentially random and heavily dependent on hyper-parameter settings <ref type="bibr" target="#b38">[39]</ref>. The embedding vector and the internal structure of the embedding space must still be explained intuitively. Rizi et al. <ref type="bibr" target="#b38">[39]</ref> cast the explanation of embedding vectors into a problem of learning to rank these vectors using RankSVM. However, the authors considered only the ranking labels of nodes and ignored the concrete similarity values, and the experimental accuracy was only 60%. Gu et al. <ref type="bibr" target="#b11">[12]</ref> proposed a flow structure-based metric to inspect the embedding space behind the random walk algorithm. Their results showed that the implicit metric space constructed by the flow distance is similar to the DeepWalk and node2vec embedding space. Unlike the above-mentioned authors, we leverage regression analysis to capture what and how node metrics are preserved by embedding models and further visually identify their importance at the instance level. We also propose a novel approach to leveraging embedding vectors for depicting structural characteristics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Comparative Visualization</head><p>Visual comparison of embeddings belongs to the topic of comparative visualization, which is a basic and common visualization task. Gleicher et al. <ref type="bibr" target="#b8">[9]</ref> summarized three categories of comparative visualization, namely, juxtaposition (i.e., side-by-side), superposition, and explicit encoding (i.e., visual display of differences or correlations). Many visualization methods have been proposed. For example, two juxtaposed identical objects are linked through VisLink <ref type="bibr" target="#b7">[8]</ref>. Alper et al. <ref type="bibr" target="#b1">[2]</ref> used the node-link graph and the adjacency matrix to compare different connectivity data in the weighted graph form in brain connectivity analysis. Lineup <ref type="bibr" target="#b9">[10]</ref> supports sorting items on the basis of multiple heterogeneous attributes with various scales and semantics. This method also compares multiple alternative rankings on the same groups of items. In this work, we mainly use the juxtaposition style to allow users to conduct comparative analysis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">BACKGROUND AND OBSERVATIONAL STUDY</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">About Network Embedding</head><p>A sensible embedding should make key information more accessible for intended tasks than extracting that directly from the original data <ref type="bibr" target="#b4">[5]</ref>. In particular, the capability to preserve graph homogeneity and (or) structural functionality determines the quality of a network embedding algorithm. Here, we briefly introduce the network embedding algorithms showcased in this paper, namely, DeepWalk <ref type="bibr" target="#b35">[36]</ref>, node2vec <ref type="bibr" target="#b10">[11]</ref>, and struc2vec <ref type="bibr" target="#b37">[38]</ref>. DeepWalk is the first to apply the idea of word2vec <ref type="bibr" target="#b31">[32]</ref> to network embedding. It uses a random walk to sample node sequences, which correspond to word sequences (sentences) in a document, and embeds the nodes using the word2vec learning algorithm. The framework of node2vec is similar to that of DeepWalk, except that node2vec provides a trade-off between breadth-first-search (BFS) and depth-first-search (DFS) strategy in the random walk process. Unlike the main ideas of preceding models, that of struc2vec is built on the observation that structural similarity does not necessarily depend on hop counts; neighboring nodes can be different and distant nodes can be similar. Without using node or edge attributes, struc2vec employs a hierarchy to encode the structure of nodes and conducts a weighted random walk down a multi-layer graph representation of the hierarchy to generate the structural context of every node.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Experts' Conventional Practice and Bottlenecks</head><p>To understand how (well) network embedding gets used in practice, we worked with a team of experts from WeChat 1 . They were two ML practitioners (E.1-2) and two data scientists (E.3-4). A considerable part of their job is to analyze and predict social influence <ref type="bibr" target="#b13">[14]</ref> and its diffusion process on a social network of interest, and develop applications such as social marketing accordingly. They have identified that both pairwise features (impact of friends on a user) and structural features (the topological structure of these active neighboring friends) <ref type="bibr" target="#b44">[45]</ref> are important for capturing the complicated mechanism of social influence. They try to quantify and incorporate such knowledge into ML models via feature engineering to predict how possible a user would conduct a specified behavior.</p><p>Conventionally, the experts take a graph-based heuristic approach to encoding pairwise features in their ML models, such as the number of common friends of two users (i.e., more shared friends meaning stronger influence on each other) and the expected length of a random walk starting from one user to the other (i.e., shorter length suggesting a stronger influence down the path). Similarly, they employ heuristic statistics, such as the number of components and communities, to quantify structural features. Although these graph-based measures do capture some useful information in the graph, the computational time grows rapidly as the network size increases. Besides, feature engineering is a task-dependent process, and its outcome of one application may not be generalizable to other tasks. Envisioning an effortless method, the experts attempted to vectorize the factors for social influence using network embedding.</p><p>However, the experts encountered the following issues when trying to engage network embedding in their ML models. (1) Understanding Obstacles. The experts design several metrics, such as k-core and betweenness, to represent node features. These metrics are insufficient for depicting entire networks, but they are particularly easy to understand. In contrast, the embedding vectors are rather abstract as dimensions in a typical embedding space do not have a particular meaning <ref type="bibr" target="#b41">[42]</ref>. "Some embedding models are still like a baffling mystery to laymen," said E.3. "If we know what specific graph information is captured by an embedding, then we would be more confident in using it," said E.4. (2) Inconvenient Comparison. There is no intuitive way to compare the quality of various embedding models, largely due to the stochastic nature of their construction process and the non-transparent hyper-parameters involved. Traditionally, the experts conduct trial-and-error to examine different embeddings on some manually assembled input cases, thereby consuming considerable time. Thus, they demand a more intuitive and interactive technique of inspecting embedding than the conventional method. (3) Limited Analysis. The experts commonly project hundreds of dimensions to an approachable 2D/3D space through dimensionality reduction and visually search for any correlation or pattern that "well fit with our understanding of how the model should and does work," said E.1. However, unlike word2vec, in which the pairwise word similarity can be easily obtained through their literal meanings, no universal measurement is available to define graph node similarity. Furthermore, calculating pairwise similarity on the basis of the attained embedding vectors is easy, whereas fine-grained analysis, such as comparing capabilities to retain semantic and (or) structural information among embedding models, is challenging.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Experts' Needs and Expectations of Embedding</head><p>To ensure that the ontological structure of our approach fits well into domain tasks, we interviewed the experts (E.1-4) in two separate sessions to identify the experts' primary concerns about the use of network embedding and potential obstacles in their path to efficient obtaining knowledge. At the end of the interviews, the need for a visualization system to ground the team's conversation <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b24">25]</ref> with embedding emerged as a key theme among the feedback collected. Despite differences in individual expectation for such a system, certain requirements were expressed across the board.</p><p>R.1 Identifying node metrics preserved by different embedding models or by versions with different hyper-parameters. All the experts were interested in knowing what node metrics in the original graph may better describe node similarity in an embedding space. Such information can help them interpret the meaning of "neighbor" and "community" in the embedding space, and ultimately determine whether conducting operations like clustering on the resulting vector representations of nodes is appropriate for their intended task.</p><p>R.2 Analyzing the capability of embedding vectors to retain assorted structural characteristics. E.1 mentioned that "network embedding result only makes sense when we conduct a pairwise node comparison," and E.3 commented that "a single node's embedding vector itself provides no additional structural information derived from the original topological space." Therefore, they were interested in determining whether leveraging embedding vectors to describe structural characteristics of interest is practical and whether such a capability differs across various embedding models.</p><p>R.3 Exploring cluster geometry of nodes in embedding space. The embedding projection will inevitably create clusters. Therefore, E.3-4 expressed a desire to observe the global geometry of the embedding space to facilitate cluster findings and understanding.</p><p>R.4 Exploring the neighbors of a particular node. A conventional method for E.3-4 to assess the output quality of an embedding was confirming whether the nearby neighbors of a node in the vector space were semantically related. Exploring the neighbors of a given node in 2D and the original embedding space are both important because the 2D embedding may distort neighborhood information.</p><p>R.5 Analyzing pairwise node similarity. Considering there is no one single universal definition of node similarity, all the experts required to show the various relatedness of nodes in a pairwise manner. For example, E.2 said that "if two nodes show similar features in terms of topological structures or comparable centralities, they may be accounted as similar nodes."</p><p>R.6 Highlighting nodes simultaneously in different spaces. All the experts were interested in linking the points in the embedding spaces with their corresponding nodes in the original graph for intuitive observation and comparison, so that they could observe the nodes of interest and their contexts in different embedding spaces.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">EMBEDDINGVIS</head><p>EmbeddingVis is a web-based visual analytics system that assists users in studying and comparing embedding spaces. This system was developed under the full-stack MEAN.js (i.e., MongoDB, ExpressJS, AngularJS, and Node.js) framework. As shown in <ref type="figure" target="#fig_0">Fig. 2</ref>, to start the exploration, users can select a network dataset and three underlying modules, namely, the embedding module, the regression-based pairwise node metric module, and the structural feature module, further process this dataset. To be specific, the embedding module applies the network embedding models to the dataset. The regression-based pairwise node metric module extracts the node metrics from the data and generates the feature importance for each metric. The structural feature module extracts the 'focal node'-'neighborhood' information of the network. The outputs of these modules are fed into the visualization module, which provides three levels of analysis, namely, the cluster level as the cluster transition view, the instance level as the pairwise ranking view, and the structural level as the structural view. This module also provides rich real-time interactions that enable the experts to effectively inspect the embedding results in a fine-grained comparative manner. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Regression-based Pairwise Node Metric Analysis</head><p>We fit the graph space to the embedding space using regression analysis (R.1) to understand what and how node metrics are potentially preserved by embedding vectors. Regression analysis has been long used to model the relationship between variables and estimate how a dependent variable responds to changes <ref type="bibr" target="#b2">[3]</ref>. We regard each designated metric as an observed variable and use its underlying combination to regress the embedding space. We then weigh each metric in terms of its contribution to the prediction by using the feature importance. We approximate the similarity defined by pairwise embedding vectors through a regression model based on a list of selected metrics as</p><formula xml:id="formula_0">sim (Y u ,Y v ) ∼ reg(w 1 • p 1 (u, v), w 2 • p 2 (u, v), ..., w k • p k (u, v)),</formula><p>where sim computes the pairwise similarity of u and v based on their embedding vectors Y u and Y v , and p i computes the pairwise similarity of u and v based on the studied metric i.</p><p>Node metrics. Numerous measures have been proposed to highlight a node's situation in its network. A few of these measures are on the local level, while others are on the global level <ref type="bibr" target="#b17">[18]</ref>. Apart from the well-known measures (1) Degree, (2) Eccentricity, (3) Closeness, (4) Betweenness, (5) Eigenvector, (6) PageRank, and (7) Clustering Coefficient, the following typical state-of-the-art measures are adopted in this study: (8) Average Nearest Neighbors Degree (knn): 1 k i ∑ j a i j k j studies the surroundings where a node is situated. This measure is based on the observation that a node with low degree may be surrounded by nodes of various sizes, which may directly influence its own centrality and growth potential <ref type="bibr" target="#b17">[18]</ref>. <ref type="formula">9</ref>Within Module Degree:</p><formula xml:id="formula_1">(K i − K S i )/σ K S i ,</formula><p>where K i is the degree of node i in the community S i , K S i is the average degree of all nodes in the community S i , and σ K S i is the standard deviation, indicates how well connected a node is to other nodes in the same community. (10) Participation Coefficient:</p><formula xml:id="formula_2">1 − ∑ M m=1 ( k i,m k i ) 2 ,</formula><p>where the term k i,m denotes the number of connections between node i and other nodes within community m, and k i,m /k i indicates the ratio of connections a node has within its own community. (11) Leverage Centrality:</p><formula xml:id="formula_3">1 k i ∑ N i k i −k j k</formula><p>i +k j considers the degree of a node "relative to its neighbors". A feature signature vector V 1 for each node is then constructed using these metrics and V 1 will be leveraged in Section 4.3.1.</p><p>Identifying preserved node metrics. We conduct an experiment to approximate the similarity of two embeddings Y u and Y v by the preceding node metrics. We compute the correlation between pairwise nodes in the embedding and metric spaces primarily to identify what and how node metrics are preserved by different embedding models. We attain the preceding defined node metrics of each node in a given network. For each pair of nodes, we compute the Euclidean distance in the metric space. We also obtain the pairwise Euclidean distance by the embedding vectors generated from the embedding models (DeepWalk, node2vec, and struc2vec in this paper) to understand which nodes remain close to each other after embedding.</p><p>Dataset. We evaluate our regression approach on several realworld datasets, namely, (1) csphd <ref type="bibr" target="#b34">[35]</ref>, which contains the ties between Ph.D. students and their advisors in theoretical computer science and has 1025 nodes and 1043 edges; (2) citeseer <ref type="bibr" target="#b19">[20]</ref>, which contains 3312 publications and 4732 connections among them; (3) wiki <ref type="bibr" target="#b39">[40]</ref>, which contains 2405 web pages with 17981 links and is denser than citeseer; (4) email <ref type="bibr" target="#b51">[52]</ref>, a dataset from a large European research institution with 1005 nodes and 25571 edges.</p><p>Parameter settings. Following the same parameters used for comparing different embeddings <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b37">38,</ref><ref type="bibr" target="#b38">39]</ref>, we set the parameters for all models as follows: window size 10, embedding dimension 128, number of random walks for each node 10, and walk length 80. For node2vec, two hyper-parameters p and q control the sampling strategy of random walks. We consider three parameter permutations of .004, 1, and 256 in our experiment. Therefore, nine groups of parameters are available. The parameters in struc2vec are the same as those in DeepWalk. Experiments. We compare the performances of four regression models, namely, Decision Tree Regression, LinearRegression, BayesRidge, and Lasso, to understand the underlying governing equation that helps associate an individual metric with the network embedding techniques. We split the data into 80% training subset and 20% test subset and apply these regression models on the previously mentioned datasets. <ref type="figure" target="#fig_1">Fig. 3</ref> shows the average R 2 scores 2 (the coefficient of determination statistically measuring how well the regression line approximates the real data) of these regression models on all datasets, and the results indicate that Decision Tree Regression can predict the pairwise node distance in the embedding space with sufficiently high accuracy. We then leverage Decision Tree Regression and extract the feature importance for each node metric. We multiply the feature importance with the R 2 score of each embedding model and rank each of these features. Only the embedding models with R 2 scores higher than 0.70 are selected. Therefore, a prominent feature extracted from an embedding model with a high R 2 score represents a high correlation between the distance of two nodes in the embedding space and the selected node metric. After ranking all features, we select all different metrics with scores higher than the 50 th percentile. These metrics are presented in <ref type="table" target="#tab_0">Table 1</ref>. Evidently, within module degree overwhelms the other metrics in DeepWalk and node2vec, while struc2vec mostly preserves degree. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Structural Feature Measurement</head><p>In this section, we study and compare the capability of embedding models to depict the structural characteristics (R.2). The motivation is that the embedding results can be understood only when we compare one embedding vector with another, and a single embedding vector alone does not provide any structural information of the graph. Unlike the previous pairwise node similarity analysis, here we consider the structure of the 'focal node'-'neighborhood'.</p><p>Our approach comprises two steps. First, on the basis of studies <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b48">49]</ref>, we select the following metrics that can represent the 'focal node'-'neighborhood' characteristics, namely, (1) number of alters of the focal node (degree): |V u − u|; (2) number of edges among neighbors (edges num):</p><formula xml:id="formula_4">|E u | − n u ; (3) density of the neighborhood (density): L u /(n u (n u − 1)/2); (4) number of focal node's 2-step neighborhood (twoalter num): |w ∈ V v , v ∈ V u , w / ∈ V u |; (5)</formula><p>average number of neighbors of neighbors' networks (average alter alter num):</p><formula xml:id="formula_5">avg(n v ), v ∈ V t u − u;<label>(6)</label></formula><p>2 https://en.wikipedia.org/wiki/Coefficient of determination average degree of neighborhood (average degree):</p><formula xml:id="formula_6">∑ 1+n i=1 n i /1 + n u ; (7) clustering coefficient: |{e jk : v j , v k ∈ N i , e jk ∈ E}|/k i (k i − 1)</formula><p>. A feature signature vector V 2 of a focal node is then constructed using these seven metrics. Second, we obtain the links from the focal node to its neighbors and calculate the Euclidean distances on the basis of the embedding vectors of the links' nodes. The rationale is that a graph's structure is decided by node position, which can be described by the distribution of distances between the links' nodes <ref type="bibr" target="#b44">[45]</ref>.</p><p>We cluster the 'focal node'-'neighborhood' structures by kmeans on the basis of the preceding metrics mentioned. We compute the distance between the 'focal node'-'neighborhood' structures using Canberra Distance <ref type="bibr" target="#b3">[4]</ref>:</p><formula xml:id="formula_7">dCan(U,V ) = ∑ n i (|U i −V i |/(U i +V i ))</formula><p>, where U and V represent the feature signatures of two 'focal node'-'neighborhood' structures. We replace the distance function in kmeans with Canberra Distance because its computation is inexpensive, it is sensitive to slight changes, and it normalizes the absolute difference of individual comparisons <ref type="bibr" target="#b48">[49]</ref>. As shown in <ref type="figure">Fig. 4</ref>, we then obtain the 'focal node'-'neighborhood' structures for each cluster and attain the pairwise links between the focal node and its neighbors for each of them. Next, we sort the distances on the basis of the embedding vectors of the link nodes to create a distance vector for each 'focal node'-'neighborhood' structure. Following this pipeline, we average the values of each dimension of the distance vectors in this cluster and obtain the "average distance vector" that represents this cluster. This method is adopted to determine how the values of each dimension of the average distance vector change. The use of the feature signature vector V 2 and the corresponding visual designs are introduced in Section 4.3.3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Visualization</head><p>The basic design principle behind EmbeddingVis is leveraging or augmenting familiar visual metaphors to enable experts to focus on analysis <ref type="bibr" target="#b30">[31]</ref>. We strictly follow the mantra "overview first, zoom and filter, then details-on-demand," <ref type="bibr" target="#b40">[41]</ref> which guides users in clearly exploring the embedding vectors. On the basis of these principles and the preceding requirements mentioned, we develop three visualizations that allow the outputs of embedding models to be easily inspected at the cluster, instance, and structural levels. Specifically, we design a cluster transition view to illustrate the neighboring changes in different embedding results, a lineup-based pairwise ranking view to facilitate the exploration of node neighbors and a structural view to show the distance distribution of 'focal node'-'neighborhood' structures across different embedding models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.1">Cluster-Level as Cluster Transition View</head><p>Dimensionality reduction techniques, such as t-SNE, PCA and MDS, which create low-dimensional embeddings and preserve local similarities to convey neighborhood structure <ref type="bibr" target="#b12">[13]</ref>, have been widely adopted to explore or illustrate the patterns inside a model's learned representation features and generate an overview of embedding results <ref type="bibr" target="#b36">[37]</ref>. For example, Liu et al. <ref type="bibr" target="#b28">[29]</ref> adopted projection to demonstrate the model's effectiveness in preserving word-level semantic relationships such as analogy and cluster gatherings. Although it is popular to view local neighborhoods in embeddings, projecting in the last step alone provides only an overall structure of the learned representations. Analyzing and comparing several embeddings at the cluster level still requires a more elaborated overview. <ref type="figure">Figure 4</ref>: Structural feature measurement. (a) Suppose we have three "focal node"-"neighborhood" networks in a cluster. For each network, (b) we obtain pairwise links between the "focal node" and its neighbors, (c) calculate and rank the Euclidean distance based on the embedding vectors of the links' nodes. (d) We use the distance vectors to represent the structural information of each "focal node"-"neighborhood" network. (e) We average the value on each dimension, and (f) is the "average distance vector" that represents the structural information of this cluster.</p><p>Visual Encoding and Interaction. We design a cluster transition view <ref type="figure">(Fig. 5)</ref> to analyze the distribution of a collection of nodes in different embedding spaces <ref type="figure" target="#fig_1">(R.1, R.3)</ref>. This view contains a parallel coordinate plot (PCP) and a t-SNE embedded transition diagram <ref type="figure">(Fig. 5(a, b-e)</ref>). The PCP <ref type="bibr" target="#b15">[16]</ref> displays the metric value distribution of the entire network nodes and the histogram distribution of each metric on each axis. Users can brush on axes to filter nodes. The t-SNE embedded transition diagram connects the t-SNE projections from different spaces, that is, the original graph space as the first, and three selected embedding spaces as the second, third, and fourth (In this paper, we set the number of comparative embedding spaces to three). We construct the original graph space 2D embedding using t-SNE projection on the basis of the feature vector V 1 (see node metrics in Section 4.1) of each node. The three embedding spaces can be dynamically removed and added ( <ref type="figure">Fig. 5</ref>(red box with X mark)), thus users would not be overwhelmed by different combinations or orders of the embedding spaces. Users can also lasso nodes on any t-SNE projection space and all identical ones will be connected via curves. Furthermore, the PCP will highlight the lassoed nodes to show their metric value distributions.</p><p>We select t-SNE as the dimensionality reduction technique because it shows superiority in generating 2D projection that "can reveal meaningful insights about data, e.g., clusters and outliers" <ref type="bibr" target="#b16">[17]</ref>. It is more visually interpretable results than naive eigen-analysis, and depending on the distribution, more intuitive than MDS results, which preserve global structure more at the expense of local structure retained by t-SNE <ref type="bibr" target="#b12">[13]</ref>. Regarding the design, initially, we use interactive animation to track the transition of nodes between two embedding spaces. However, our collaboration experts reported that tracking the nodes in an animated manner requires a mental map comparison, which is "demanding, especially when involving simultaneous tracking of additional nodes." Therefore, we develop the cluster transition view based on the juxtaposition comparative visualization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.2">Instance-Level as Pairwise Ranking View</head><p>Although 2D displays convey additional information about neighborhood structure, it remains unclear how much of it is noise that is captured in the process as opposed to relevant semantic structure. This makes interpretation, and in particular comparison across embeddings challenging <ref type="bibr" target="#b12">[13]</ref>. Moreover, ML experts often need to explore the properties of an embedding at the instance level. For example, an engineer working on a recommendation system who creates an embedding algorithm for songs might verify that the nearest neighbors of "Stairway to Heaven" contain "Whole Lotta Love" rather than "Let It Go" <ref type="bibr" target="#b41">[42]</ref>. Applying embedding to rank the neighboring nodes and measuring its performance are also meaningful in network analysis. First, sparsity problems frequently occur in social networks. For example, Bob has 140 friends, and only 20 of them frequently communicate with him. For other friends, relying only on scarce communication behaviors to rank intimacy is difficult. Second, in some scenarios, such as communication networks, some persons, such as insurance agents, communicate frequently with Bob only for a short while for business reasons. If we rank the intimacy between Bob and his friends on the basis of their communication frequency, then these "business acquaintances" may be assigned unreasonably high rankings. Third, no universal measurement is available for defining node similarity. Thus, exploring the neighboring information can help experts assess the output quality of an embedding because neighbors may have similar features (R.4-5).</p><p>After discussing with the experts, we adopt the preceding metrics (Section 4.1) to evaluate the neighboring information at the instance level. Users can then conduct a detailed comparison between two neighboring nodes in terms of metrics. However, manually selecting nodes for comparison is cumbersome, especially when the graph is complicated and no clear cues are available for users to decide which nodes to compare. Therefore, we convert pairwise comparison to ranking comparison to quantify different embedding ranking qualities and understand how (well) node metrics are preserved. <ref type="figure">Figure 5</ref>: The cluster transition view consists of (a) node metric parallel coordinates plot and t-SNE projection spaces by (b) the original graph, (c) DeepWalk, (d) struc2vec, and (e) node2vec. Users can filter nodes by either (1) brushing a certain range of values in an axis or (2) lassoing nodes in any t-SNE space, and all the identical nodes will be connected by curves. (3) The number indicates the iteration number of t-SNE. When clicking the red box with X mark, the corresponding embedding space will be removed. Ranking Measurement. To measure the ranking quality of different embeddings, we use Discounted Cumulative Gain (DCG) which is widely used to measure the efficacy of search engines <ref type="bibr" target="#b46">[47]</ref>. The DCG accumulated at a particular rank position k is defined as <ref type="bibr">i+1)</ref> . By standardizing the queries, all relevant documents are sorted in the corpus according to their relative correlation, and the possible DCG is generated by the position k, which is called Ideal DCG (IDCG). Therefore, we use normalized discounted cumulative gain (NDCG):</p><formula xml:id="formula_8">DCG k = ∑ k i=1 rel i log 2 (i+1) = rel 1 + ∑ k i=2 rel i log 2 (</formula><formula xml:id="formula_9">NDCG k = DCG k /IDCG k , where IDCG is defined as IDCG k = ∑ |REL| i=1 2 rel i −1 log 2 (i+1)</formula><p>and |REL| represents the list of relevant documents (ordered by their relevance) in the corpus up to position k. Compare Rankings Between Models. Confirming the nearby neighbors of a node is necessary for evaluating and trusting an embedding model. That is, multiple rankings from different embedding models must be placed into context with one another, thereby allowing users to compare multiple models simultaneously. <ref type="bibr" target="#b3">(4)</ref> Interactive Operations. Interactive mechanisms on the ranking in the original graph space, such as sorting by a certain node metric, should be provided to enable users to determine the difference between embedding models reflected on rankings. Thus, users can witness the response of embedding spaces and the overlaps of neighbors between the original graph space and the embedding space.</p><p>Visual Encoding and Interaction. Inspired by Lineup <ref type="bibr" target="#b9">[10]</ref>, we design a pairwise ranking view to help users conduct instance level analysis. We present each node metric ( <ref type="figure" target="#fig_2">Fig. 6(a)</ref>) as a separate column. These columns adopt bars with different colors to represent the normalized values for each node metric. The top row in each ranking always represents the currently selected node <ref type="figure" target="#fig_2">(Fig. 6(b)</ref>), and the rows below represent the neighbors of the selected node <ref type="figure" target="#fig_2">(Fig. 6(c)</ref>). We add an additional bar ( <ref type="figure" target="#fig_2">Fig. 6(d1)</ref>) to represent the number of shared friends between the neighboring node and the selected node. To compare the neighboring rankings, we line up the four rankings horizontally <ref type="figure" target="#fig_2">(Fig. 6(1-4)</ref>), each having its own neighboring node order, and connect identical nodes across the neighboring rankings with lines (linked and highlighted black rectangles in <ref type="figure" target="#fig_2">Fig. 6</ref>). These rankings are that in the original graph space (The ranking is based on the neighbors of the selected node in the original graph) and those from the three embedding spaces (The rankings are based on the Cosine or Euclidean similarity between the neighbor node and the selected node and determined using the embedding vector from the corresponding embedding model). We design a small bar <ref type="figure" target="#fig_0">(Fig. 6(d2)</ref>) and use its length to encode the number of embedding spaces which capture the corresponding node in their neighboring ranking list (Since we support three embedding spaces for simultaneous comparison and if all spaces capture a node in their ranking lists, the length of the bar is 3). The similarity measures based on Cosine or Euclidean distance are encoded by two curve areas ( <ref type="figure" target="#fig_2">Fig. 6(e)</ref>) that lie on both sides of the columns. Here, we visualize the similarity change of two adjacent nodes, i.e., a peak indicates a considerable change of similarity between the two adjacent nodes. This method can resolve the ranking ambiguity of two nodes with the same similarity. As shown in <ref type="figure" target="#fig_2">Fig. 6(f)</ref>, changes in the option of Cosine or Euclidean distance will influence only the ranking of neighboring nodes in the embedding spaces. Two alignment strategies are provided, namely, the use of stacked and aligned bars. The two strategies can be toggled dynamically. Operations such as sorting by eigenvector ( <ref type="figure" target="#fig_2">Fig. 6(g)</ref>) between the selected node and all the other nodes in the whole graph will influence the order in the original graph space, i.e., the first column. We add a filter slider <ref type="figure" target="#fig_2">(Fig. 6(h)</ref>) that controls the length of neighboring rankings due to limited vertical space. The NDCG scores <ref type="figure" target="#fig_2">(Fig. 6(i)</ref>) on top of each embedding column indicate the ranking qualities of different embeddings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.3">Structure-Level as Structural View</head><p>To understand the capability of embedding models to depict the structural characteristics, we obtain the links of each 'focal node'-'neighborhood' structure from the focal node to its neighbors and calculate the Euclidean distance on the basis of their embedding representations, namely, the "distance vector". We then obtain the "average distance vector" for each cluster of 'focal node'-'neighborhood' structures (Section 4.2). We design a structural view to help visualize the distance distribution of 'focal node'-'neighborhood' structure clusters across different embeddings (R.2).</p><p>Visual Encoding and Interaction. As shown in <ref type="figure" target="#fig_4">Fig. 7(a)</ref>, we construct the graph space using t-SNE projection of the feature vector V 2 (Section 4.2) of each 'focal node'-'neighborhood' structure. Users can change cluster number in kmeans. Colors in the 2D spaces represent clusters. The stacked bars in <ref type="figure" target="#fig_4">Fig. 7(e)</ref> show the distribution of Euclidean distance on the basis of embedding vectors from each embedding indicated by a color. X axis shows the distance bins, and the bar length shows the number of distances under each bin. In <ref type="figure" target="#fig_4">Fig. 7(c-d)</ref>, the highlighted curves represent the "average distance vector" of a cluster (e.g., cluster 3 in <ref type="figure" target="#fig_4">Fig. 7(b)</ref>). X axis represents the dimension index of the "average distance vector", and Y axis is the value at the corresponding dimension. In other words, the maximum value of X axis indicates the maximum degree of the network. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Interactions Among the Views</head><p>Apart from the most defining capabilities of EmbeddingVis, rich interactions are integrated to catalyze an efficient in-depth analysis (R.6). (1) Filtering and Highlighting. Users can select/lasso nodes in the graph view or in the cluster transition view to inspect nodes or areas of interest, and the system will automatically highlight the corresponding information in all the other views. (2) Linking. Views are automatically linked through nodal correspondence. The coordinated interactions among these nodes facilitate examination of a variety of information at different granularities, such as the cluster and instance levels, thus forming convenient hypothesis generation and verification. (3) Animation. The projection in the cluster transition view and operations in the pairwise ranking view provide an intuitive process of cluster formation and ranking changes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">EVALUATION</head><p>In this section, we demonstrate system efficacy by conducting two case studies. The first case evaluates node metrics preserved by embedding models. The second case compares the effects of hyperparameters in different versions of an embedding. Before introducing the two cases, we first report how the experts familiarized themselves with the system by using one of their familiar networks. E.3-4 first used the social network of their department to observe the performance of and the difference across embedding models. This dataset comprises 324 employees working in seven groups. As shown in <ref type="figure">Fig. 5</ref>, the experts first examined the metric distribution in parallel coordinates in the cluster transition view and obtained an overview of the network, such as degree distribution and within module degree distribution. They then loaded the three embedding results from DeepWalk, struc2vec, and node2vec. After sufficient iterations of t-SNE projection, they observed that several clusters were formed in DeepWalk and node2vec space, while struc2vec had a long and continuous "tail". The experts selected one cluster in DeepWalk space and all the correspondences were highlighted and connected. DeepWalk and node2vec preserved the nodes in a cluster well, while struc2vec dispersed these nodes. The experts were interested in knowing the position of the department leader; therefore, they clicked the corresponding node in the graph view ( <ref type="figure" target="#fig_5">Fig. 8(1.  Click a node)</ref>). This node linked to several nodes in each cluster (indicated by arrows) other than its nearby neighbors. The experts then speculated that the long "tail" in struc2vec projection space indicated the department hierarchy. Therefore, they lassoed a part of the "tail" and confirmed their hypothesis <ref type="figure" target="#fig_0">(Fig. 8(2. Lasso nodes)</ref>). The interns were distributed at the end of the "tail," and struc2vec could accurately identify them. Another interesting finding was the different group statuses in the entire department ( <ref type="figure" target="#fig_1">Fig. 8(3. Lasso nodes)</ref>). "What a pity! Our group is on the periphery of the department," said E.3. This finding could be observed from the original graph, DeepWalk, or node2vec spaces. These observations confirmed the capability of struc2vec to capture the structural identity <ref type="bibr" target="#b37">[38]</ref>, while DeepWalk and node2vec focused on the local neighboring structures. (1) Click a node in graph view and the identical ones are linked via a curve (inter-embedding link). Links from this node to its neighbors are also shown (inner-graph links). The widths of the two types of links are different. (2) Lasso several nodes in struc2vec and the graph view shows that they correspond to department interns. <ref type="formula">3</ref>The lassoed nodes represent two groups of employees.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Case One: Verifying Preserved Node Metrics</head><p>This case uses the preceding csphd dataset mentioned to verify the node metrics preserved by different embedding models.</p><p>Verifying Preserved Metrics at Cluster Level. The regressionbased pairwise node metric analysis (Section 4.1) enables us to understand the correlation of metrics between a node-node pair in the graph space and the embedding space. For example, we have identified that the most preserved node metric by DeepWalk is within module degree, while degree is the most preserved metric by struc2vec, followed by leverage centrality, etc. To verify these preserved metrics at the cluster level, as shown in <ref type="figure" target="#fig_6">Fig. 9</ref>, we brushed several nodes from the axis of within module degree and observed that the corresponding nodes were closely gathered in DeepWalk and node2vec; by contrast, struc2vec split some of the nodes apart. Similarly, when we selected nodes with similar degree or leverage centrality, struc2vec maintained the closeness of these nodes well, while the other spaces could not closely preserve nodes (R.1, R.3).</p><p>Verifying Preserved Metrics at Instance Level. We analyzed the neighboring information and compared the ranking performance of each embedding to further verify the preserved metrics at the instance level (R. <ref type="bibr" target="#b3">[4]</ref><ref type="bibr" target="#b4">[5]</ref>. We first lassoed a cluster of nodes and the corresponding nodes will be highlighted and linked across embedding spaces <ref type="figure">(Fig. 1(b1-e1)</ref>). We then select a "hub node" (label 20) in this cluster, and the top row in the pairwise ranking view shows its metric distribution ( <ref type="figure">Fig. 1(a)</ref>). As shown in <ref type="figure" target="#fig_0">Fig. 1(d2)</ref>, all the neighboring nodes had similar value distributions on leverage centrality, participation coefficient, knn, PageRank, and degree in struc2vec, while eccentricity and within module degree were preserved better by DeepWalk <ref type="figure" target="#fig_0">(Fig. 1(c2)</ref>) and node2vec <ref type="figure" target="#fig_0">(Fig. 1(e2)</ref>). We then highlighted the nodes of each ranking list in each t-SNE projection space in the cluster transition view by clicking "Filter" button ( <ref type="figure">Fig. 1(f)</ref>). Clearly, all the highlighted nodes in the lassoed cluster were captured by the neighboring ranking list of DeepWalk <ref type="figure" target="#fig_1">(Fig. 1(c3)</ref>) and node2vec <ref type="figure" target="#fig_1">(Fig. 1(e3)</ref>) because they all converged to a single cluster. However, most of them were not preserved closely by struc2vec because they were split into several clusters ( <ref type="figure" target="#fig_1">Fig. 1(d3)</ref>). DeepWalk and node2vec maintained the local neighborhoods of the selected node <ref type="figure" target="#fig_1">(Fig. 1(c3, e3)</ref>), while struc2vec could maintain the "hub" nodes that are similar to the selected node together ( <ref type="figure" target="#fig_1">Fig. 1(d3)</ref>), of which the Euclidean distance between them may be more volatile <ref type="figure">(Fig. 1(g)</ref>). The NDCG scores of the rankings also confirmed our findings. We fixed the selected node (the top row of each ranking) and sorted all the other graph nodes using Euclidean distance with the selected node on the basis of the node metrics of leverage centrality, participation coefficient, PageRank, degree, and within module degree. For example, when sorting by leverage centrality, participation coefficient, PageRank, and degree in the graph space, DeepWalk and node2vec return 0.109, thereby indicating they fail to preserve well these metrics, compared with 0.6-0.8 NDCG scores of struc2vec. When sorting by within module degree, struc2vec fails to maintain the nodes with similar within module degree close with NDCG score of 0.125, while DeepWalk and node2vec return 0.556.</p><p>Summarizing the Takeaways. The experts (E.1-2) obtained an intuitive understanding of the preserved node metrics by the showcased embedding models. For example, in the third row of <ref type="figure" target="#fig_6">Fig. 9</ref>, E.1 observed that struc2vec placed the nodes with high positive values of leverage centrality together (indicated by the red circle): "nodes with positive values of leverage centrality may influence their neighbors as the neighbors tend to have fewer connections with others." They also found that participation coefficient and PageRank were well preserved by struc2vec. Participation coefficient and PageRank are the metrics that specify whether nodes are truly "hub" nodes, while DeepWalk and node2vec preserve the nodes which are "bound to local links" reflected by within module degree, "these nodes do not play the role of connectors between clusters," said E.2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Case Two: Understanding Hyper-Parameters</head><p>This case shows how EmbeddingVis helped E.1-2 understand the effect of hyper-parameters p and q in node2vec by using csphd and a synthetic dataset. As claimed in <ref type="bibr" target="#b10">[11]</ref>, p and q control the searching strategy of random walk, i.e., a high value of p will explore the network in a moderate manner, while a low value will lead the walk to backtrack a step and maintain the closeness of walk "local" to the starting node. Meanwhile, q differentiates the searching between "inward" (BFS with q &gt; 1) and "outward" (DFS with q &lt; 1) nodes.</p><p>Revisiting Degrades Performance by p. The regression analysis (Section 4.1) enables the experts to learn the average regression accuracy of the nine versions of node2vec, among which six could achieve over 0.95 R 2 score. However, the versions of (p = 1, q = 256), (p = 0.004, q = 1) and (p = 0.004, q = 256) could achieve only approximately 0.7-0.8. Hence, the experts showed interests in these versions and loaded their corresponding embedding results. From the previous case study, E.2 obtained the insight that node2vec preserved within module degree; therefore, he filtered a small range of nodes with similar within module degree <ref type="figure" target="#fig_7">(Fig. 10(a)</ref>). The cluster transition view immediately responded to his operation and displayed the node transition across the three embedding spaces. He found that the embedding space with p = 0.004 and q = 256 had the worst performance; it did not maintain the nodes as closely as those in the two other spaces. However, compared with p = q = 1 of node2vec in <ref type="figure" target="#fig_6">Fig. 9</ref>, all three versions failed to maintain the nodes sufficiently closely. The expert confirmed that "revisiting an already visited node would limit the scope of the walks around the starting node, so the local neighboring nodes could not be preserved well."</p><p>Differences Between DFS and BFS by q. The experts shifted their attention to whether q could significantly differentiate embedding results. They selected three groups of parameters, namely, (p = 256, q = 0.004), (p = 256, q = 1), and (p = 256, q = 256) for comparative analysis. However, after either inspecting t-SNE embedding spaces or selecting nodes in graph view and comparing the pairwise neighbor rankings, they did not observe significant differences: "I cannot explain this," said E.1. "Can you find some structures, of which the connectivities inside a community are high but the community has some 'bridge' nodes that link to other communities?" suggested by E.2. To narrow down the analysis, we generated a synthetic network utilizing the Barabási-Albert model <ref type="bibr" target="#b0">[1]</ref> and an algorithm proposed by Lancichinetti et al. <ref type="bibr" target="#b18">[19]</ref>, which specifically focuses on creating benchmark graphs with complex community structures and allows for generation of realistic synthetic networks. <ref type="figure" target="#fig_4">Fig. 7</ref> and <ref type="figure">Fig. 11</ref> show the analysis process for this dataset. We shifted to the structural view and clustered the network nodes into three ( <ref type="figure" target="#fig_4">Fig. 7(a)</ref>) on the basis of the seven structure-related metrics (Section 4.2) (R.2). We selected one cluster <ref type="figure" target="#fig_4">(Fig. 7(b)</ref>) and observed its "average distance vector", which was generated by the three versions of node2vec. At the beginning <ref type="figure" target="#fig_4">(Fig. 7(c)</ref>), the distance of p = 256 and q = 256 version was lower than the distances from the other two versions; however, the distance exceeded them as the degree increased ( <ref type="figure" target="#fig_4">Fig. 7(d)</ref>). The experts were curious about this "turning point." "Interesting. No matter how I change the number of clusters, this always happens," said E.2. The network degree varied from 12 to 24, thereby indicating that a node in this network had at least 12 neighbors. We then turned to the graph view and clicked one node <ref type="figure">(Fig. 11(1)</ref>), which was identified as having a tightly knit community comprising approximately 12 neighbors and two distant nodes <ref type="figure" target="#fig_0">(Fig. 11(2-3)</ref>) functioning as "bridge nodes" connecting to other communities. The two "bridge nodes" had no other links to the selected node community and shared no common friends with the selected node (indicated by red rectangles in <ref type="figure">Fig. 11</ref>). When we hovered on them, we identified that the first two versions of node2vec captured them but the third one failed to capture these nodes in its ranking list of top 50 neighbors. We also attempted a few other nodes and discovered the same phenomenon. "This version of node2vec conducts only a BFS-like (not BFS) strategy. Since the two 'bridge nodes' have no links to any other nodes in the community, it has a great chance to miss them when q is high," said E.2.</p><p>Summarizing the Takeaways. The experts were convinced by what we identified through the analytical exploration. A small p would easily lead to a frequent revisiting of an already visited node. However, the claimed difference that q differentiates the random walk between BFS and DFS could not be easily observed. E.2 responded that "the average distance vector in structural view helps us understand that a higher value of q can keep the 'focal node'-'neighborhood' structure much closer if they have a strong connectivity among neighbors of the focal node, but it tends to ignore those neighbors with no other links to the community." "In realworld networks, the structure is much more complicated and tuning q alone could not significantly affect the embedding," said E.1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">DISCUSSION</head><p>We conducted a half an hour semi-structured interview with our experts (E.1-4). We first asked them to evaluate the experimental results and the use of "average distance vector" to depict structural characteristics empirically. E.1-2 reported that "the high accuracy of decision tree regression indicates that the embeddings preserve node metrics in a non-linear way." They felt that "the results make sense" after confirming the preserved metrics through interactive analysis. E.4 stated that "it is practical to use embedding vectors to describe structural information since the trend of a cluster's 'average distance vector' curve is similar across models." System Usability. All the experts appreciated the capability of EmbeddingVis to support interactive exploration and comparison among embedding models. E.1-2 suggested that our system would greatly boost their work efficiency. Conventionally, they have to manually sample some data they are familiar with, run the embedding algorithms on the example inputs, and then check how well the outputs match their intuition. "Previously, we could only examine embeddings with our familiar networks. But now I can also explore other unfamiliar graphs." E.2 described his past experience of comparing the neighbor rankings from different embedding models as trial-and-error. "All I got each round was a single ranking score and could not dig deeper to find the underlying cause. This is quite stressful and time-consuming." With our system, they could easily and intuitively compare interesting nodes/clusters and their distributions in different embedding spaces. "I can explore different but interconnected information about a node/cluster in various views," said E.2. They commented that "EmbeddingVis is very useful because it provides a novel and highly interactive way to uncover the relationships between metrics and embedding vectors."</p><p>Visual Design. We drew inspiration from the observational study of the experts' conventional practices to inform the system design, such as analyzing the network pairwise/structural features, 2D projection clustering analysis, and ranking measurement. We deliberately selected familiar visual metaphors so that the experts could quickly get accustomed to the visual encodings and designs. After being introduced to the basic views and functions of EmbeddingVis, they developed a path through the system for exploration.</p><p>Generalizability. We discussed with the experts (E.3-4) which component(s) of our system can be directly applied to other analytical scenarios and which one(s) need customization to further explore the potential of EmbeddingVis. Two findings were obtained: (1) Visual Design Generalization. E.3 mentioned that our system is already very general in terms of the metrics incorporated. But if we allow users to modify the metrics list, the system would be very applicable to other scenarios. "I would personally like to add a few business-related metrics derived from historical data to the system, e.g., whether this user has ever clicked on a targeted advertisement," said E.3. (2) Embedding Model Generalization. Although we only showcase three embedding models in this paper, other types, e.g., LINE <ref type="bibr" target="#b42">[43]</ref>, SDNE <ref type="bibr" target="#b45">[46]</ref> can be included with simple configuration.</p><p>Scalability. First, we have used more than ten colors to differentiate metrics and keep the color encoding consistent across all the views. However, we are fully aware that only a small number of colors can be effectively used as category labels <ref type="bibr" target="#b47">[48]</ref>. If there are more metrics, then we should support dynamic filtering to display the desired metrics. Second, in this paper, considering the time consumed in generating the metrics and the embedding results, we only use networks with 1000 to 3000 nodes for demonstration. For a larger network, we can sample the nodes or use GPU to accelerate the computing process. We also envision the scalability issues with the visualization when dealing with larger network data. Two findings arose: (1) Remove iteration process. Currently, we leverage t-SNE and directly visualize its iterative process in the front-end. When dealing with larger networks, we should remove the iterative process to the backend and only preserve the coordinates of points in the final step. (2) Replace with canvas. Switching the current SVG-based visualization to canvas-based WebGL rendering could significantly boost the visualization performance for larger networks.</p><p>Limitation. We may fail to capture a few metrics with a possibly high correlation between the graph space and the embedding space due to limited datasets we used or to weigh the feature importance of node metrics by averaging over all datasets. We focused only on two hyper-parameters with limited settings and maintained the similarity of other parameters, such as window size, and we only worked with a small team of experts (E.1-4) in the evaluation and thus could not provide a quantitative assessment of the system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">CONCLUSION AND FUTURE WORK</head><p>In this paper, we propose EmbeddingVis to enable a comparative inspection of embedding vectors at the cluster, instance, and structural levels. Case studies and experts' feedback verify the efficacy of our system. Several ways are available to improve the system. First, we plan to perform a systematic evaluation that involves additional experts. We can then iteratively refine the system based on the feedback. Second, we will involve more embedding models and more specific tasks. Third, we also want to study how a model changes over time, i.e., how the performance of an embedding model changes over the iterative process and when it reaches a sufficiently good result. Currently, we only work with the final embedding results after a fixed number of iterations.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :</head><label>2</label><figDesc>The network dataset is processed by three underlying modules (embedding module, regression-based pairwise node metric module, and structural feature module). The outputs (graph layout coordinates, node metrics information, structural information and embedding vectors of nodes) are then fed into visualization module.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 :</head><label>3</label><figDesc>X axis is the average R 2 score over all datasets. Y axis indicates different embeddings. Decision Tree overwhelms the others and three versions of nodevec have a comparatively lower performance.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 6 :</head><label>6</label><figDesc>Pairwise ranking view contains four ranking lists in (1) the original graph and (2, 3, 4) three selected embedding spaces. (a) 11 metrics are displayed as legends. (b) The top row in each ranking represents the selected node. (c) Top N neighbors of the selected node. (d1) Number of shared friends between the neighbor and the selected node. (d2) The length of the black bars indicate how many embedding spaces contains the corresponding node. (e) Curve areas indicate the similarity changes of two adjacent nodes. (f) Control options for distance calculation and layout. (g) Users can click a metric to order the graph nodes based on the clicked metric. (h) Users can control the length of displayed neighboring ranking list. (i) The NDCG score measures the ranking quality of each ranking list.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>Design Criteria. To facilitate the exploration and comparison of neighboring information of a selected node across different embeddings, the pairwise ranking view should meet the following design criteria: (1) Encode Ranking Similarity. Users should be able to rapidly grasp the rankings that are determined by pairwise node similarities. (2) Encode Ranking Causes. Users must be able to evaluate the details of each node, such as node metric distribution and similarity ranking, to understand how the rankings are determined.<ref type="bibr" target="#b2">(3)</ref> </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 7 :</head><label>7</label><figDesc>(a) Nodes are clustered into three. (b) Hover on one cluster and observe its "average distance vector" curves generated by three versions of node2vec. (c, d) A "turning point" occurs at the curve of (p=256,q=256) (indicated by the yellow curve).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 8 :</head><label>8</label><figDesc>Figure 8: (1) Click a node in graph view and the identical ones are linked via a curve (inter-embedding link). Links from this node to its neighbors are also shown (inner-graph links). The widths of the two types of links are different. (2) Lasso several nodes in struc2vec and the graph view shows that they correspond to department interns. (3) The lassoed nodes represent two groups of employees.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 9 :</head><label>9</label><figDesc>Verify preserved metrics at the cluster level: (a) Filter nodes with similar within module degree, degree, leverage centrality and observe distributions and transitions of the corresponding nodes in (b) DeepWalk, (c) struc2vec, (d) node2vec (p=q=1) and (e) graph view.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 10 :</head><label>10</label><figDesc>Nodes with similar within module degree are filtered and all identical ones are linked across three versions of node2vec spaces.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 11 : ( 1 )</head><label>111</label><figDesc>Click a node (label 597) and generate its neighbor ranking lists for graph space and three node2vec spaces. (2, 3) Two neighbors have no other links to the selected node's community. They are only captured by the first two versions in their top 50 ranking lists.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>The average ranking of feature importances of node metrics for different embedding models on all datasets.</figDesc><table><row><cell></cell><cell cols="8">DeepWalk p=0.004, q=0.004 p=1, q=0.004 p=256, q=0.004 p=256, q=256 p=1, q=1 p=256, q=1 struc2vec</cell></row><row><cell>Degree</cell><cell>0.33%</cell><cell>0.23%</cell><cell>0.24%</cell><cell>0.30%</cell><cell>0.22%</cell><cell>0.21%</cell><cell>0.27%</cell><cell>70.98%</cell></row><row><cell>Betweenness</cell><cell>4.30%</cell><cell>4.10%</cell><cell>4.07%</cell><cell>3.89%</cell><cell>4.62%</cell><cell>4.03%</cell><cell>4.01%</cell><cell>5.18%</cell></row><row><cell>Leverage Centrality</cell><cell>6.88%</cell><cell>6.43%</cell><cell>5.14%</cell><cell>4.84%</cell><cell>6.09%</cell><cell>6.55%</cell><cell>5.22%</cell><cell>3.00%</cell></row><row><cell>KNN</cell><cell>8.82%</cell><cell>7.51%</cell><cell>5.79%</cell><cell>5.53%</cell><cell>8.09%</cell><cell>7.86%</cell><cell>5.89%</cell><cell>1.69%</cell></row><row><cell>Closeness</cell><cell>9.82%</cell><cell>8.35%</cell><cell>8.00%</cell><cell>7.69%</cell><cell>8.20%</cell><cell>7.80%</cell><cell>8.16%</cell><cell>1.77%</cell></row><row><cell>PageRank</cell><cell>14.50%</cell><cell>12.89%</cell><cell>10.53%</cell><cell>10.60%</cell><cell>13.65%</cell><cell>13.15%</cell><cell>9.50%</cell><cell>11.00%</cell></row><row><cell>Within Module Degree</cell><cell>41.93%</cell><cell>50.02%</cell><cell>57.73%</cell><cell>58.82%</cell><cell>49.29%</cell><cell>49.62%</cell><cell>58.79%</cell><cell>2.03%</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">https://www.wechat.com/en/</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS</head><p>We are grateful for the valuable feedback and comments provided by Prof. Huamin Qu and the anonymous reviewers. This research was supported in part by WeChat-HKUST Joint Lab on AI Technology (WHAT LAB) grant#1617170-0 and HK RGC GRF 16213317.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Statistical mechanics of complex networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Albert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A.-L</forename><surname>Barabási</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Reviews of modern physics</title>
		<imprint>
			<biblScope unit="volume">74</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">47</biblScope>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Weighted graph comparison techniques for brain connectivity analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Alper</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Bach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Henry Riche</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Isenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-D</forename><surname>Fekete</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the SIGCHI conference on human factors in computing systems</title>
		<meeting>the SIGCHI conference on human factors in computing systems</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="483" to="492" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Illusions in regression analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Armstrong</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Netsimile: A scalable approach to size-independent network similarity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Berlingerio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Koutra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Eliassi-Rad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Faloutsos</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1209.2684</idno>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">W</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K. C.-C</forename><surname>Chang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1709.07604</idno>
		<title level="m">A comprehensive survey of graph embedding: Problems, techniques and applications</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Grarep: Learning graph representations with global structural information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th ACM International on Conference on Information and Knowledge Management</title>
		<meeting>the 24th ACM International on Conference on Information and Knowledge Management</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="891" to="900" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Heterogeneous network embedding via deep architectures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G.-J</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">C</forename><surname>Aggarwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">S</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</title>
		<meeting>the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="119" to="128" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Vislink: Revealing relationships amongst visualizations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Collins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Carpendale</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1192" to="1199" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Visual comparison for information visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gleicher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Albers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Walker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Jusufi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">D</forename><surname>Hansen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">C</forename><surname>Roberts</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Visualization</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="289" to="309" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Lineup: Visual analysis of multi-attribute rankings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gratzl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lex</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Gehlenborg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Pfister</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Streit</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on visualization and computer graphics</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2277" to="2286" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">node2vec: Scalable feature learning for networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Grover</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd ACM SIGKDD international conference on Knowledge discovery and data mining</title>
		<meeting>the 22nd ACM SIGKDD international conference on Knowledge discovery and data mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="855" to="864" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">The hidden flow structure and metric space of network embedding algorithms based on random walks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Lou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Scientific reports</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">13114</biblScope>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Interactive analysis of word vector embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Heimerl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gleicher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Graphics Forum</title>
		<imprint>
			<publisher>Wiley Online Library</publisher>
			<date type="published" when="2018" />
			<biblScope unit="volume">37</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Acceptance of blog usage: The roles of technology acceptance, social influence and knowledge sharing motivation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-L</forename><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-C</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information &amp; management</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="65" to="74" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Label informed attributed network embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Hu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Tenth ACM International Conference on Web Search and Data Mining</title>
		<meeting>the Tenth ACM International Conference on Web Search and Data Mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="731" to="739" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Parallel coordinates for visualizing multi-dimensional geometry</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Inselberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Dimsdale</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Graphics</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1987" />
			<biblScope unit="page" from="25" to="44" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Pixelsne: Visualizing fast with just enough precision via pixel-aligned stochastic neighbor embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Choo</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.02568</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Graph-based model for distribution systems: Application to planning problem</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Labrini</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
		<respStmt>
			<orgName>University of Waterloo</orgName>
		</respStmt>
	</monogr>
	<note>Master&apos;s thesis</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Benchmark graphs for testing community detection algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lancichinetti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Fortunato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Radicchi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Physical review E</title>
		<imprint>
			<biblScope unit="volume">78</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">46110</biblScope>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Digital libraries and autonomous citation indexing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lawrence</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">L</forename><surname>Giles</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Bollacker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="67" to="71" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Probabilistic latent document network embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">M</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">W</forename><surname>Lauw</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE International Conference on Data Mining (ICDM)</title>
		<meeting>IEEE International Conference on Data Mining (ICDM)</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="270" to="279" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Attributed network embedding for learning in a dynamic environment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Dani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 ACM on Conference on Information and Knowledge Management</title>
		<meeting>the 2017 ACM on Conference on Information and Knowledge Management</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="387" to="396" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">A visual analytics approach for understanding egocentric intimacy network evolution and impact propagation in mmorpgs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ming</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Qu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE Pacific Visualization Symposium (PacificVis)</title>
		<meeting>IEEE Pacific Visualization Symposium (PacificVis)</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="31" to="40" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">A multi-phased co-design of an interactive analytics system for moba game occurrences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 on Designing Interactive Systems Conference</title>
		<meeting>the 2018 on Designing Interactive Systems Conference</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1321" to="1332" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">A visual analytics approach for understanding reasons behind snowballing and comeback in moba games</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">Y</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on visualization and computer graphics</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="211" to="220" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Attributed social network embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T.-S</forename><surname>Chua</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1705.04969</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Learning entity and relation embeddings for knowledge graph completion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="2181" to="2187" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Deeptracker: Visualizing the training process of convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Qu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Intelligent Systems and Technology</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note>To appear in</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Visual exploration of semantic relationships in neural word embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P.-T</forename><surname>Bremer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">J</forename><surname>Thiagarajan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Srikumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Livnat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Pascucci</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on visualization and computer graphics</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="553" to="562" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Visualizing data using t-sne</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">V D</forename><surname>Maaten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of machine learning research</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="2579" to="2605" />
			<date type="published" when="2008-11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Liverac: interactive visual exploration of system management time-series data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Mclachlan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Munzner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Koutsofios</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>North</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the SIGCHI Conference on Human Factors in Computing Systems</title>
		<meeting>the SIGCHI Conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2008" />
			<biblScope unit="page" from="1483" to="1492" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Efficient estimation of word representations in vector space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1301.3781</idno>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Graph embedding and dimensionality reduction-a survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Nishana</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Surendran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Science &amp; Engineering Technology (IJCSET)</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="29" to="34" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Asymmetric transitivity preserving graph embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd ACM SIGKDD international conference on Knowledge discovery and data mining</title>
		<meeting>the 22nd ACM SIGKDD international conference on Knowledge discovery and data mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1105" to="1114" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">The sigact theoretical computer science genealogy: Preliminary report</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Parberry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">S</forename><surname>Johnson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Deepwalk: Online learning of social representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Perozzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Al-Rfou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Skiena</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 20th ACM SIGKDD international conference on Knowledge discovery and data mining</title>
		<meeting>the 20th ACM SIGKDD international conference on Knowledge discovery and data mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="701" to="710" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Visualizing the hidden activity of artificial neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">E</forename><surname>Rauber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">G</forename><surname>Fadel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">X</forename><surname>Falcao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">C</forename><surname>Telea</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on visualization and computer graphics</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="101" to="110" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">struc2vec: Learning node representations from structural identity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">F</forename><surname>Ribeiro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">H</forename><surname>Saverese</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">R</forename><surname>Figueiredo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</title>
		<meeting>the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="385" to="394" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Properties of vector embeddings in social networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Salehi Rizi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Granitzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Ziegler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Algorithms</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">109</biblScope>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Collective classification in network data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Sen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Namata</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bilgic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Getoor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Galligher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Eliassi-Rad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">AI magazine</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">93</biblScope>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">The eyes have it: A task by data type taxonomy for information visualizations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Shneiderman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Craft of Information Visualization</title>
		<imprint>
			<publisher>Elsevier</publisher>
			<date type="published" when="2003" />
			<biblScope unit="page" from="364" to="371" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Smilkov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Thorat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Nicholson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Reif</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">B</forename><surname>Viégas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Wattenberg</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.05469</idno>
		<title level="m">Embedding projector: Interactive visualization and interpretation of embeddings</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Line: Large-scale information network embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Mei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th International Conference on World Wide Web</title>
		<meeting>the 24th International Conference on World Wide Web</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1067" to="1077" />
		</imprint>
	</monogr>
	<note>International World Wide Web Conferences Steering Committee</note>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Learning deep representations for graph clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T.-Y</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1293" to="1299" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Structural diversity in social contagion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ugander</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Backstrom</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Marlow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kleinberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the National Academy of Sciences</title>
		<imprint>
			<biblScope unit="volume">109</biblScope>
			<biblScope unit="issue">16</biblScope>
			<biblScope unit="page" from="5962" to="5966" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Structural deep network embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd ACM SIGKDD international conference on Knowledge discovery and data mining</title>
		<meeting>the 22nd ACM SIGKDD international conference on Knowledge discovery and data mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1225" to="1234" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">A theoretical analysis of ndcg ranking measures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T.-Y</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th Annual Conference on Learning Theory (COLT 2013)</title>
		<meeting>the 26th Annual Conference on Learning Theory (COLT 2013)</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title level="m" type="main">Information visualization: perception for design</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Ware</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
			<publisher>Elsevier</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">egoslider: Visual analysis of egocentric network evolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Pitipornvivat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Qu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on visualization and computer graphics</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="260" to="269" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Ssp: Semantic space projection for knowledge graph embedding with text descriptions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="3104" to="3110" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Deep graph kernels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Yanardag</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Vishwanathan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</title>
		<meeting>the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1365" to="1374" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Local higherorder graph clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">R</forename><surname>Benson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Leskovec</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">F</forename><surname>Gleich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</title>
		<meeting>the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="555" to="564" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
