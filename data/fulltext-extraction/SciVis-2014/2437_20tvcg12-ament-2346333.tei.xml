<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/pisenberg/grobid/grobid-0.6.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Low-Pass Filtered Volumetric Shadows</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><roleName>Student Member, IEEE</roleName><forename type="first">Marco</forename><surname>Ament</surname></persName>
							<email>ament@kit.edu</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><roleName>Member, IEEE</roleName><forename type="first">Filip</forename><surname>Sadlo</surname></persName>
							<email>sadlo@visus.uni-stuttgart.de</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carsten</forename><surname>Dachsbacher</surname></persName>
							<email>dachsbacher@kit.edu</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Weiskopf</surname></persName>
							<email>weiskopf@visus.uni-stuttgart.de</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">Karlsruhe Institute of Technology</orgName>
								<address>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">University of Stuttgart</orgName>
								<address>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="institution">Karlsruhe Institute of Technology</orgName>
								<address>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="institution">University of Stuttgart</orgName>
								<address>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Low-Pass Filtered Volumetric Shadows</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="DOI">10.1109/TVCG.2014.2346</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2021-02-19T19:34+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Direct volume rendering</term>
					<term>volume illumination</term>
					<term>soft shadows</term>
					<term>filtered shadows</term>
					<term>summed area table</term>
				</keywords>
			</textClass>
			<abstract>
				<p>Member, IEEE Computer Society (a) (b) (c) (d) Fig. 1. Volume renderings of a numerical flow simulation data set. (a) Volumetric ambient occlusion and specular highlights provide only local visual cues for perception of spatial depth. (b) Illumination from three orthodirectional light sources with single scattering provides global visual cues but introduces disturbing patterns and is too dark. The same setup visualized with our novel model using (c) a small and (d) a large volumetric region for low-pass filtering to avoid disturbing high-frequency shadow patterns.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Shadows can provide important visual cues to improve the perception of objects and features. Several user studies have shown that shadows are beneficial to determine the size and composition of objects <ref type="bibr" target="#b43">[44]</ref> or to position objects relative to each other with improved accuracy <ref type="bibr" target="#b16">[17]</ref>. The study by Langer and Bülthoff <ref type="bibr" target="#b23">[24]</ref> demonstrated that human perception associates low luminance with spatial depth. For direct volume rendering (DVR), Lindemann and Ropinski <ref type="bibr" target="#b26">[27]</ref> conducted a user-study that evaluated several advanced illumination techniques for interactive DVR, where participants had to estimate the relative depth and size of volumetric features. It was shown that subtle shadows are beneficial compared to local illumination <ref type="bibr" target="#b32">[33]</ref>.</p><p>One of the simplest methods to compute shadows is volumetric ambient occlusion <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b40">41</ref>] that estimates local extinction in a small ambient sphere around each sample point. Depending on the radius, occluders of different size create local soft shadows. Moreover, volumetric ambient occlusion can be computed very efficiently by summing up the local extinction with summed area tables (SAT) <ref type="bibr" target="#b38">[39]</ref>. Ambient occlusion supports the visual identification of concavities and structures that have about the same size as the ambient radius. In con- trast, directional shadows, e.g., from a single scattering model <ref type="bibr" target="#b28">[29]</ref>, account for occluders on a large scale and over long distances. However, on a small scale, directional shadows can lead to high-frequency patterns of alternating illuminated and shadowed areas. In computer graphics, crepuscular rays play an important role <ref type="bibr" target="#b8">[9]</ref>, but in visualization, they can be visually distracting.</p><p>A common alternative are directional soft shadows due to extended light sources or multiple scattering. For interactive DVR, simplified illumination models have been developed that approximate multiple scattering by sampling and integrating over volumetric primitives like cones <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b39">40,</ref><ref type="bibr" target="#b42">43]</ref> or tubes <ref type="bibr" target="#b0">[1]</ref> as illustrated in <ref type="figure" target="#fig_1">Figures 2(a)</ref>-(c). Common to all these methods is the repeated execution of local operations like blurring or averaging, which act as a low-pass filter inside the volumetric primitives. Although this effectively smoothes hard shadows, it can be computationally expensive because the volumetric primitives must be sampled either with some kind of shadow rays or slices. Moreover, these sampling schemes must be performed once for each light source, which strongly decreases performance.</p><p>For visualization, soft shadows are often more preferred compared to hard shadows, because the latter can lead to strong visual masking effects <ref type="bibr" target="#b10">[11]</ref>, which can diminish the perception and visual detectability of spatial details. Typically, hard shadows exhibit high contrast and they create disturbing visual patterns that cannot be distinguished easily from the actual volumetric features that cast the shadows. With time-dependent data sets or moving light sources, both effects often lead to noticeable visual flickering. The goal of this paper is to employ low-frequency shadows to reduce these masking effects for improved perception in volume visualization.</p><p>Our contribution is a novel optical model for directional soft shadows that builds on efficient spatial filtering and does not require expensive shadow ray marching. In particular, the performance of our approach neither depends on the sampling rate of shadow rays nor on the width of the filter as opposed to previous techniques. We can directly control the fuzziness of volumetric shadows for each ray sample by means of a single user-controlled parameter. We show that even a simple box filter is capable of generating high-quality shadows of arbitrary softness. Previous approaches <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b38">39]</ref> employed SATs that are aligned with the data set to achieve similar effects. However, the main idea of our approach is to carefully align the SATs with the directional and point light sources, as briefly illustrated in <ref type="bibr">Figures 2(d)</ref> and (e), which enables higher computational efficiency. As a unique feature, our approach supports up to six orthodirectional light sources without multiple shadow ray marching by reusing the same SAT, which offers high flexibility for many-point lighting setups with high performance and comparatively low memory consumption. Only if more than six ortho-directional light sources are required, multiple SATs need to be computed and stored. Furthermore, no precomputation step is required, which allows one to interactively explore, illuminate, and visualize even time-dependent data sets without any preprocessing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK</head><p>The radiative transfer equation (RTE) by Chandrasekhar <ref type="bibr" target="#b3">[4]</ref> describes physically based light transport in participating media. However, in visualization, simplified optical models <ref type="bibr" target="#b28">[29]</ref> are often employed due to their higher performance. The survey by Jönsson et al. <ref type="bibr" target="#b19">[20]</ref> provides a comprehensive overview of advanced illumination techniques that are commonly employed in interactive DVR.</p><p>Local shadows are a common alternative to directional shadows. Stewart <ref type="bibr" target="#b40">[41]</ref> computes the local occlusion of diffuse ambient light in the vicinity of each point to shade isosurfaces. Moreover, ambient occlusion can also be employed for illustrative visualizations as demonstrated by Ruiz et al. <ref type="bibr" target="#b36">[37]</ref>. Hernell et al. <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b14">15]</ref> compute attenuation in the direct neighborhood of each voxel on a multiresolution grid by casting shadow rays over the sphere of directions, which can be expensive and must be recomputed whenever the transfer function changes. To obtain a vicinity representation that is independent of the transfer function Ropinski et al. <ref type="bibr" target="#b35">[36]</ref> employ clustered histograms of the surrounding scalar values of each voxel. However, it can take hours to precompute and cluster the histograms of each data set. The fastest ambient occlusion methods rely on the observation that no directional information of the surrounding occluders is accounted for. This allows one to employ order-independent summation of the extinction in the neighborhood of each voxel as shown by Díaz et al. <ref type="bibr" target="#b6">[7]</ref> and Schlegel et al. <ref type="bibr" target="#b38">[39]</ref>, who exploit SATs <ref type="bibr" target="#b5">[6]</ref> for fast summation. In addition, the computation of SATs can be strongly accelerated with the GPU-friendly algorithm by Hensley et al. <ref type="bibr" target="#b12">[13]</ref>.</p><p>Directional shadows provide additional cues for large-scale occlusion and are an important building block of many illumination algorithms in DVR. Behrens and Ratering <ref type="bibr" target="#b1">[2]</ref> computed attenuation from a distant light source with a slice-based approach and superimposed a shadow volume with the original scalar field to render directional shadows. A different approach by Zhang and Crawfis <ref type="bibr" target="#b46">[47]</ref> computes shadows with volume splatting. A more GPU-friendly technique is described by Hadwiger et al. <ref type="bibr" target="#b11">[12]</ref>, who adapt deep shadow maps <ref type="bibr" target="#b27">[28]</ref> to GPU-based DVR. Salvi et al. <ref type="bibr" target="#b37">[38]</ref> introduce adaptive volumetric shadow maps that store a piecewise linear approximation of the transmittance along shadow rays instead of a dense uniform array. For interactive DVR, Weber et al. <ref type="bibr" target="#b44">[45]</ref> present a many-light algorithm that employs adaptive cube shadow maps <ref type="bibr" target="#b37">[38]</ref> to efficiently evaluate transmittance for each virtual light source to compute multiple scattering. However, the method requires progressive updates when the transfer function changes. Kronander et al. <ref type="bibr" target="#b22">[23]</ref> compute directional visibility information for each voxel on a multiresolution grid with truncated spherical harmonics at the cost of rather high storage requirements.</p><p>Soft shadows can occur in the presence of area light sources or when light arrives from more than one direction, e.g., due to multiple scattering. Kniss et al. <ref type="bibr" target="#b20">[21]</ref> approximate multiple scattering by sampling a cone pointing toward the light source and forwarddirected scattering is estimated by repeated blurring operations using half angle slicing, which can also be parallelized <ref type="bibr" target="#b29">[30]</ref>. In general, sampling a volumetric cone is a common element of several subsequent papers. Schott et al. <ref type="bibr" target="#b39">[40]</ref> present directional occlusion shading that computes attenuation in a cone pointed toward the observer to approximate backward-directed scattering for a single head light. Soltészová et al. <ref type="bibr" target="#b42">[43]</ref> presented a more general approach that iteratively filters opacity within tilted light cones on a view-aligned slice stack to support more directions for illumination. Patel et al. <ref type="bibr" target="#b31">[32]</ref> further extended the latter method for polygonal models combined with a faster convolution computation. However, both approaches <ref type="bibr" target="#b31">[32,</ref><ref type="bibr" target="#b42">43]</ref> are restricted in the placement of the light sources to a hemisphere. In contrast, our approach allows for arbitrary placement of light sources. Ropinski et al. <ref type="bibr" target="#b34">[35]</ref> blur light within a given cone centered around the incoming light direction and utilize an illumination volume for ray casting. Schlegel et al. <ref type="bibr" target="#b38">[39]</ref> efficiently aggregate extinction in an order-independent fashion by approximating a cone with a series of cuboids that are used to evaluate a volume-aligned SAT. However, in addition to the computation of the SAT, their method still requires the sampling of the shadow cone. In contrast, our main contribution is to employ light source-aligned SATs to avoid this expensive sampling. Crassin et al. <ref type="bibr" target="#b4">[5]</ref> sample a prefiltered voxelized cone to estimate occlusion for geometry-based scenes by means of mipmaps and a hierarchical octree representation. Ament et al. <ref type="bibr" target="#b0">[1]</ref> employ preintegrated scattering to compute soft shadows along a tube of finite radius. However, similar to all cone-based techniques, the tube needs to be sampled by casting rays to all light sources. In contrast, our method does not require any shadow ray marching at all and supports efficient handling of multiple light sources, which is important for three-point lighting setups <ref type="bibr" target="#b48">[49]</ref>. Traditionally, soft shadows and their efficient computation play also an important role in surface-based graphics, e.g., by employing shadow maps with percentage-closer filtering <ref type="bibr" target="#b9">[10]</ref>. Lauritzen <ref type="bibr" target="#b24">[25]</ref> employed SATs in combination with variance shadow maps; however, filtering is applied to the moments of the depth distribution for smooth 2D shadows, whereas our approach aims for volumetric shadows and we refer the reader to the course notes by Eisemann et al. <ref type="bibr" target="#b7">[8]</ref> for a more detailed discussion.</p><p>Sundén et al. <ref type="bibr" target="#b41">[42]</ref> employ plane sweeping in image space to render advanced lighting effects with low memory demands, but only one point or directional light source is supported. The volume ren- dering technique by Zhang and Ma <ref type="bibr" target="#b47">[48]</ref> approximates global illumination with a convection-diffusion model by assuming an optically thick medium. The method achieves interactive performance, but the softness of the shadows cannot be controlled. For visualization, full global illumination of participating media is usually too expensive, too hard to control, or does not allow interactive control over all parameters, which can be very time-consuming for data exploration. For a detailed discussion of full global illumination of participating media, the reader is referred to the survey of Cerezo et al. <ref type="bibr" target="#b2">[3]</ref>. Wyman et al. <ref type="bibr" target="#b45">[46]</ref> employ spherical harmonics to precompute global illumination, but the method is limited to isosurfaces. Interactivity of volumetric Monte Carlo simulations is usually achieved by heavy restrictions, e.g., by constraining the expensive scattering computations to selected isosurfaces <ref type="bibr" target="#b33">[34]</ref> or by relying on progressive refinement <ref type="bibr" target="#b21">[22]</ref>. Jönsson et al. <ref type="bibr" target="#b18">[19]</ref> present an algorithm that allows one to interactively edit the transfer function for volumetric photon mapping <ref type="bibr" target="#b17">[18]</ref> by tracking the history of photon trajectories. However, time-dependent data sets or moving light sources still require an expensive recomputation of all photons.</p><formula xml:id="formula_0">θ θ L i L i L i L i L i r w (a) (b) (c) (d) (e)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">BASICS OF VOLUMETRIC ILLUMINATION</head><p>Before we introduce our approach in Section 4, we briefly recapitulate the notation and basic principles of volumetric illumination. We build our approach on the single scattering illumination model <ref type="bibr" target="#b28">[29]</ref> in participating media. The total radiance L(x, ω) at position x in direction ω is the sum of the attenuated radiance L b (x b , ω) from a boundary condition at position x b and the integrated in-scattered radiance L i (x, ω):</p><formula xml:id="formula_1">L(x, ω) = T (x b , x)L b (x b , ω) + x x b T (x , x)σ t (x )L i (x , ω) dx ,<label>(1)</label></formula><p>where σ t (x) is the extinction coefficient. The transmittance T (x 1 , x 2 ) between any two points x 1 and x 2 is:</p><formula xml:id="formula_2">T (x 1 , x 2 ) = e −τ(x 1 ,x 2 ) = e − x 2 x 1 σ t (x ) dx ,<label>(2)</label></formula><p>where</p><formula xml:id="formula_3">τ(x 1 , x 2 ) is the optical depth. Furthermore, in Eqn. (1), L i (x, ω)</formula><p>describes the amount of radiance that arrives from all directions at point x and that is scattered into direction ω:</p><formula xml:id="formula_4">L i (x, ω) = Ω P(x, ω , ω)T (x b , x)L b (x b , ω ) dω ,<label>(3)</label></formula><p>where Ω denotes the sphere of all directions and the normalized phase function P(x, ω , ω) describes the probability density of radiance being scattered from the incident direction ω to direction ω. With single scattering, only one scattering event is accounted for; hence, in Eqn. <ref type="formula" target="#formula_4">3</ref>, incoming radiance depends only on the attenuated radiance L b (x b , ω) from the boundary conditions such as light sources or the background.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">THE TECHNIQUE</head><p>In this section, we present our novel technique for efficient soft shadows. First, we discuss the theory of our filtered volumetric shadows in Section 4.1, before we introduce an efficient algorithm that computes volumetric shadows of arbitrary softness in Sections 4.2 and 4.3. Afterward, we show how interactive DVR with our shadow technique is performed in Section 4.4. Since our approach is related to a series of previous methods that also employ filter-like operations, we provide a discussion of similarities and differences in Section 4.5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Filtered Volumetric Shadows</head><p>We begin our approach with Eqn. (3). Traditionally, radiance L b (x, ω) from the boundary conditions is attenuated by integrating the extinction along a 1D ray, i.e, the optical depth τ, as shown in Eqn. <ref type="bibr" target="#b1">(2)</ref>. The core element of our novel technique is to substitute τ with the filtered optical depthτ:</p><formula xml:id="formula_5">τ →τ(x 1 , x 2 ) = 1 A U −U V −V τ x 1 (u, v), x 2 (u, v) f (−u, −v) dv du,<label>(4)</label></formula><p>where f is an arbitrary 2D filter function over a finite area A with parameter range [−U,U]×[−V,V ] (both measured in unit distances). We specify the domain for filtering with two parametrized surface patches x 1 (u, v) and x 2 (u, v) that will be defined later in more detail to control the type of the light source and the shape of the soft shadows. For now, we only require that x 1 = x 1 (0, 0) and x 2 = x 2 (0, 0). <ref type="figure" target="#fig_2">Figure 3</ref> shows two examples of how Eqn. (4) can be employed for directional and point light sources, respectively. For each sample point of an eye ray, a local area patch is aligned with its normal vector toward the light source. The area patches span volumetric primitives (cuboid and spherical pyramid) that are conceptually sampled with shadow rays to compute τ</p><formula xml:id="formula_6">x 1 (u, v), x 2 (u, v) . Afterward, this 2D</formula><p>distribution is convolved with the filter f as indicated by the concentric circles in <ref type="figure" target="#fig_2">Figure 3</ref> and the filter controls the relative contribution of τ for total attenuation. In this way, soft shadows can be achieved with a low-pass filter and the softness can be controlled by the size and shape of the filter kernel.</p><p>The computation of the filtered optical depth in Eqn. (4) requires the solution of an integral over a 3D domain: For each pair of points x 1 and x 2 , the solution of the 1D integral in Eqn. (2) is needed. A numerical solution of the integrals could be obtained with Monte Carlo integration or, as in our case, with Riemann sums, which fits well to our approach with SATs in the next section:</p><formula xml:id="formula_7">τ(x 1 , x 2 ) ≈ 1 A I ∑ i=1 J ∑ j=1 τ x 1 (u i , v j ), x 2 (u i , v j ) f (−u i , −v j ) ∆v ∆u,<label>(5)</label></formula><p>where I and J are the number of discrete samples of the 2D filter ker- nel. Similarly, the non-filtered optical depth becomes:</p><formula xml:id="formula_8">τ x 1 , x 2 ≈ K ∑ k=1 σ t x 1 + w k x 2 − x 1 x 2 − x 1 ∆w,<label>(6)</label></formula><p>where K is the number of discrete ray samples. In general, computing the solutions of Eqns. <ref type="formula" target="#formula_7">5</ref>and <ref type="formula" target="#formula_8">6</ref>is very expensive because three dimensions need to be sampled in contrast to only one dimension for classic single scattering. Moreover, the computation must be performed for each eye ray sample. Even when a shadow cache is employed to accelerate rendering, an expensive recomputation is necessary whenever the transfer function, lighting setup, or time step changes. Therefore, we introduce an efficient technique that avoids this repeated shadow ray marching in the next section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Efficient Box Filtering</head><p>Our goal for filtered volumetric shadows is an efficient and direct control over the softness of shadows. A user must be able to suppress high-frequency patterns due to hard shadows, but in a controlled manner without introducing excessive blur. Therefore, we focus on lowpass filters and their efficient application. A simple low-pass filter is the convolution with a box kernel, i.e., each sample in the filter domain is weighted with a constant value.</p><p>In interactive DVR, directional and point light sources are probably the two most commonly employed types of light sources because they allow flexible lighting setups and they can be sampled efficiently. Directional light sources generate parallel volumetric shadows and provide illumination from far distant emitters. In contrast, point light sources generate perspective volumetric shadows and they can be placed inside the data set for close-range illumination effects. In the following sections, we show how box filtering can be computed efficiently for both types of light sources.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1">Directional Light Sources</head><p>By definition, light from a directional light source arrives from parallel directions at each point. As illustrated in <ref type="figure" target="#fig_2">Figure 3</ref>(a), we model the parallel shape of the resulting shadows with a cuboid-shaped filter domain that is spanned by the following two surface patches:</p><formula xml:id="formula_9">x 1 (u, v) = x 1 + u • r u + v • r v ,<label>(7)</label></formula><p>x</p><formula xml:id="formula_10">2 (u, v) = x 1 (u, v) + w max • r w ,<label>(8)</label></formula><p>where w max is the distance from x 1 (0, 0) to the intersection point with the bounding box of the data set and r u , r v , and r w are orthonormal unit vectors:</p><formula xml:id="formula_11">r u × r v = r w = l,<label>(9)</label></formula><p>where l is the light vector that points in direction of the light source. Then, the set of points:</p><formula xml:id="formula_12">C = x 1 (u, v) + w • r w : (u, v, w) ∈ [−U,U] × [−V,V ] × [0, w max ]</formula><p>(10) defines a cuboid that is aligned with the directional light source as illustrated in <ref type="figure" target="#fig_2">Figure 3</ref>(a). Furthermore, we set the generic filter function in Eqn. (5) to a box kernel:</p><formula xml:id="formula_13">f (u, v) = 1.<label>(11)</label></formula><p>Note that the normalization factor 1/A is already included in Eqn. <ref type="bibr" target="#b4">(5)</ref>. Then, the box-filtered optical depth becomes:</p><formula xml:id="formula_14">τ(x 1 , x 2 ) ≈ 1 A I ∑ i=1 J ∑ j=1 K ∑ k=1 σ t x i, j,k ∈ C ∆V,<label>(12)</label></formula><p>where ∆V = ∆u ∆v ∆w is the size of the volume element. Essentially, Eqn. <ref type="formula" target="#formula_14">12</ref>is a 3D box filter with the cuboid C as filtering domain. However, the triple sum in Eqn. <ref type="formula" target="#formula_14">12</ref>is still expensive to calculate with naive looping. Therefore, we employ a 3D-SAT and align it with the directional light source so that one of its six faces is orthogonal to the light vector l. The bounding box of our SAT contains the entire volume, but it is not aligned with the orientation of the data set and has its own Cartesian coordinate system defined by the unit vectors r u , r v , and r w , according to Eqn. <ref type="bibr" target="#b8">(9)</ref>. Note that this is a crucial element of our approach and is different from all previous approaches that also employed SATs for DVR <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b38">39]</ref>. For the sake of clarity, we call our approach Cartesian SAT (CSAT) for the remainder of this paper. The CSAT sums up σ t (x i, j,k ) ∆V for a set of discrete positions x i, j,k of the data set, but in its own frame of reference and once it is computed, the box-filtered optical depth simplifies to:</p><formula xml:id="formula_15">τ(x 1 , x 2 ) ≈ 1 A CSAT(C),<label>(13)</label></formula><p>where CSAT(C) evaluates the cuboid region C of the CSAT in constant time with only eight elementary data references. No additional marching along shadow rays is required as opposed to the methods by Schlegel el al. <ref type="bibr" target="#b38">[39]</ref> or by Ament et al. <ref type="bibr" target="#b0">[1]</ref> as illustrated in Figures 2(b) and 2(c), respectively. Furthermore, we employ a quadratic surface patch for filtering, which leads to −V = −U, V = U, and J = I. In this way, only a single parameter is required to control the size of the filtering domain and thereby the softness of the resulting shadows. Another important feature of our approach is that computation time is independent of the filter size and thereby independent of the softness of the shadows.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2">Orthodirectional Light Sources</head><p>A straightforward extension of the previously introduced algorithm allows us to compute box-filtered shadows for up to six orthogonal directional light sources with the same CSAT. In the following, we denote the i-th light source with a subscript index i and we set the light vector of the primary light source to l 1 = l. With six mutual orthogonal light vectors l i • l j = 0 for i, j = 1,...,6 and i = j, we can define six coordinate systems:</p><formula xml:id="formula_16">r u,i × r v,i = r w,i = l i .<label>(14)</label></formula><p>Following the same steps as in the previous section, we obtain similar expressions for Eqns. (7), <ref type="bibr" target="#b7">(8)</ref>, and <ref type="bibr" target="#b9">(10)</ref>. Finally, the box-filtered optical depth for all six directional light sources becomes:</p><formula xml:id="formula_17">τ i (x 1 , x 2 ) ≈ 1 A CSAT(C i ), i = 1,...,6.<label>(15)</label></formula><p>In this way, we can efficiently compute filtered shadows for manylight settings to illuminate a data set from six orthogonal directions and to better convey the 3D shape of volumetric features. Note that if more than six orthodirectional light sources are required, multiple CSATs become necessary. However, in many cases, three light sources already yield good results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.3">Point Light Sources</head><p>Emitted light from a point light source naturally follows a spherical geometry. As illustrated in <ref type="figure" target="#fig_2">Figure 3</ref>(b), we model the perspective shape of the resulting shadows by using a spherical pyramid instead of a cuboid as filtering domain. Then, we transform the spherical geometry of propagating rays to computational space with a Cartesian coordinate system where rays propagate again in parallel and we can employ 3D-SATs for point light sources as well.</p><p>We define a spherical coordinate system with azimuth angle φ , polar angle θ , and radius r and set its origin (φ = 0, θ = 0, r = 0) to the position x L of the point light source. First, we span the tangential plane at sample point x 1 with spherical coordinates</p><formula xml:id="formula_18">x S 1 = (φ 1 , θ 1 , r 1 ): x t (u, v) = x 1 + u • r φ (φ 1 ) + v • r θ (φ 1 , θ 1 ),<label>(16)</label></formula><p>where r φ and r θ are orthonormal tangential vectors:</p><formula xml:id="formula_19">r φ (φ ) = − sin(φ )r x + cos(φ )r y ,<label>(17)</label></formula><formula xml:id="formula_20">r θ (φ , θ ) = cos(θ ) cos(φ )r x + cos(θ ) sin(φ )r y − sin(θ )r z ,<label>(18)</label></formula><p>and r x , r y , and r z are the orthonormal vectors defining the Cartesian world space. Furthermore, the radial unit vector r r points in the opposite direction of the light vector l:</p><formula xml:id="formula_21">r φ × r θ = r r = −l.<label>(19)</label></formula><p>In the second step, we project all points of the tangential plane x t <ref type="bibr">(u, v)</ref> onto the surface of the sphere and we get two curved area patches:</p><formula xml:id="formula_22">x 1 (u, v) = x L + R • x t (u, v) − x L x t (u, v) − x L ,<label>(20)</label></formula><p>x</p><formula xml:id="formula_23">2 (u, v) = x 1 (u, v) − w max • r r ,<label>(21)</label></formula><p>where</p><formula xml:id="formula_24">R = x t (0, 0) − x L</formula><p>is the radial distance from the sample position x 1 = x t (0, 0) to the point light source x L and w max is the distance from the sample position to the intersection point with the bounding box of the data set. Then, the set of points:</p><formula xml:id="formula_25">S = x 1 (u, v) − w • r r : (u, v, w) ∈ [−U,U] × [−V,V ] × [0, w max ]<label>(22)</label></formula><p>defines a (cropped) spherical pyramid with its peak located at the position of the point light source as illustrated in <ref type="figure" target="#fig_2">Figure 3(b)</ref>. Note that we use this more complicated description in Cartesian coordinates to obtain spherical pyramids of equal base area A in each direction, which would not be possible in spherical coordinates. However, we can now transform all points x ∈ S from Cartesian coordinates to spherical coordinates x S ∈ S. Then, we can write the box-filtered optical depth for point light sources as follows:</p><formula xml:id="formula_26">τ(x 1 , x 2 ) ≈ 1 A I ∑ i=1 J ∑ j=1 K ∑ k=1 σ t x S i, j,k ∈ S ∆V,<label>(23)</label></formula><p>where ∆V = r 2 sin(θ )∆r ∆θ ∆φ is the size of the spherical volume element. We observe that Eqn. (23) has a form similar to Eqn. <ref type="bibr" target="#b11">(12)</ref> and we can also employ a 3D-SAT to accelerate filtering. However, in this case, summation needs to be performed over a spherical pyramid and not a cuboid. Therefore, we employ a SAT with spherical coordinate system r φ , r θ , and r r , according to Eqn. <ref type="bibr" target="#b18">(19)</ref>. Moreover, in contrast to the CSAT, the origin of this spherical SAT (SSAT) is located at the position of the point light source. The spherically shaped bounding box of the SSAT contains again the entire volume. However, if the point light is located outside of the data set, only a fraction of the entire sphere is required. Note that the SSAT is actually a regular grid in the computational domain where the SSAT sums up σ t (x S i, j,k ) ∆V for a set of discrete positions. However, these positions must be transformed to Cartesian world space before sampling the data set. As soon as the SSAT is computed, the box-filtered optical depth becomes:</p><formula xml:id="formula_27">τ(x 1 , x 2 ) ≈ 1 A SSAT(S),<label>(24)</label></formula><p>where SSAT(S) evaluates the spherical pyramid S of the SSAT in constant time and again no additional shadow rays are required. Note that, in contrast to orthodirectional light sources, every point light source requires its own SSAT. Therefore, for large data sets, the number of point light sources can be limited by computation time and memory requirements; in this case, a fallback to orthodirectional light sources with a single CSAT is possible.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Higher-Order Filtering</head><p>The Fourier transform of a box kernel is a Sinc function and its infinite support and oscillations in frequency domain could become problematic for certain frequencies of the filtered function τ of Eqn. <ref type="bibr" target="#b4">(5)</ref>. Therefore, we evaluate higher-order filters to compare their quality and performance with box filtering. In general, filtering with higherorder kernels f cannot be achieved directly with a 3D-SAT because the weight of the filter depends on the position on the surface patch. However, instead of shadow ray marching for each pair of points x 1 and x 2 in Eqn. (4), we can still employ the same 3D-SATs of the previous sections to quickly approximate the non-filtered optical depth τ of the innermost 1D integral. For the directional light source, we decompose the cuboid C = C i, j of Eqn. (10) into a set of disjoint smaller cuboids C i, j . By looking again at our general model of Eqn. (5), we obtain the filtered optical depth with:</p><formula xml:id="formula_28">τ(x 1 , x 2 ) ≈ 1 A I ∑ i=1 J ∑ j=1 CSAT(C i, j ) f (−u i , −v j ).<label>(25)</label></formula><p>Similarly, the spherical pyramid of Eqn. (22) can be decomposed with S = S i, j . In this way, the repeated shadow ray marching can be avoided, but the summation over the surface area of the 2D filter still needs to be computed explicitly, in contrast to box filtering.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Interactive Direct Volume Rendering</head><p>For volume rendering, we assume that the data set is stored on a discrete Cartesian grid that samples a scalar field s : R 3 → R and a transfer function maps these scalar values to color and extinction. Our algorithm consists of two passes that are both summarized in Algorithm 1. First, depending on the type of light source, the CSAT or SSAT is recomputed whenever the transfer function, lighting setup, or data set changes. Then, we compute the filtered optical depth with filter sizes A CSAT and A SSAT by evaluating the CSAT or SSAT, following Eqns. <ref type="bibr" target="#b14">(15)</ref> and <ref type="bibr" target="#b23">(24)</ref>, to compute the filtered optical depth according to Eqn. (4) and to store the resulting transmittance in a shadow cache. Similar caches are employed regularly in interactive DVR <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b38">39]</ref>. We follow this practice to conduct a fair comparison, although our algorithm is capable of interactive frame rates even without any caching. Note that for all six orthodirectional lights, the CSAT must be computed only once, whereas the SSAT must be computed for each point light.</p><p>In the second pass, ray casting from the camera is employed. At each ray sample position x, the emitted radiance L b from all active light sources is attenuated with the transmittance from the shadow cache and multiplied with the phase function, according to Eqn. <ref type="bibr" target="#b2">(3)</ref>. In an alternative implementation without any shadow cache, the CSAT and SSAT would be directly evaluated at this place and the first pass would only recompute the SATs. Finally, the color and extinction are read from the transfer function for compositing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Discussion</head><p>There are several previous methods <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b39">40,</ref><ref type="bibr" target="#b42">43]</ref> that employ building blocks similar to our technique for rendering soft shadows. The one that is closest to our approach is the method by Schlegel et al. <ref type="bibr" target="#b38">[39]</ref>. The authors compute a SAT that is aligned with the data set. For each ray sample, a cone is directed toward each light source and is approximated by a series of cuboids with ray marching. For each cuboid, the SAT is evaluated to compute the aggregated extinction. The authors report 40 to 80 cone samples for typical data set sizes and transfer functions with a minimum of at least 12 cone Algorithm 1 Our low-pass shadows rendering algorithm.</p><p>Require: filter size A CSAT , filter size A SSAT , transfer function TF, directional light DL, orthodirectional light OL, point light PL, data set DS, phase function PF, shadow cache SC, radiance L b (background and emitters) 1: /* First pass */ 2: if hasChanged(TF, DL, PL, DS) then 3:</p><p>CSAT = recomputeCSAT(DL, DS, TF); 4:</p><p>for all orthodirectional light sources OL ∈ DL do 5: SC = updateShadowCache(OL, CSAT, A CSAT ); 6: end for 7:</p><p>for all point light sources PL do 8:</p><p>SSAT = recomputeSSAT(PL, DS, TF); 9: SC = updateShadowCache(PL, SSAT, A SSAT ); 10:</p><p>end for 11: end if 12: /* Second pass */ 13: for all pixels P do 14: L = 0; T = 0; 15: ray = computeEyeRay(P); 16:</p><p>while rayCastingNotFinished(ray) do 17:</p><p>x = getRayPosition(ray); L i = 0; 18:</p><p>for all active OL ∈ DL do 19:</p><formula xml:id="formula_29">L i = L i + PF(x, OL) • SC(x, OL) • L b (OL); 20:</formula><p>end for 21:</p><p>for all active PL do 22:</p><formula xml:id="formula_30">L i = L i + PF(x, PL) • SC(x, PL) • L b (PL); 23:</formula><p>end for 24:</p><p>(L, T ) = composite(x, TF, L, T , L i ); 25:</p><p>end while 26:</p><p>return T • L b + L; 27: end for samples until artifacts become visible. With our approach, we also require the computation of the CSAT or SSAT, which is computationally equivalent to the SAT by Schlegel et al. assuming the same resolution. However, we do not require shadow ray marching and we gain a theoretical performance speedup of one order of magnitude because we require only one lookup in the SAT instead of several ones. In Section 6, we compare this method with our approach.</p><p>The method by Ament et al. <ref type="bibr" target="#b0">[1]</ref> also shares common elements with our approach because the authors employ a tube-shaped volume and SATs for illumination. Just like Schlegel et al. <ref type="bibr" target="#b38">[39]</ref>, their SAT is aligned with the volume. However, in contrast to our approach, the tube is approximated by a series of spheres and for each sphere the ambient extinction coefficient must be sampled. In addition, a preintegration table must accessed in each step to evaluate scattering in each sphere. The authors report spherical radii of up to 14 voxels, which results in step sizes of up to 28 voxels. For typical data set sizes, this still requires about 10 sphere samples for shadow ray marching. Again, with our approach, we do not require such sampling steps and we do not require any preprocessing or preintegration tables. However, our method does not explicitly simulate multiple scattering. Therefore, we evaluate the quality and performance of both methods in Section 6.</p><p>The techniques byŠoltészová et al. <ref type="bibr" target="#b42">[43]</ref> and Patel et al. <ref type="bibr" target="#b31">[32]</ref> also achieve efficient soft shadows, albeit by iterative convolution within tilted light cones that are intersected with a view-aligned slice stack. The main advantage of these methods is that no storage for a SAT is required, although some additional memory is also needed for a layered depth image <ref type="bibr" target="#b31">[32]</ref>. However, the most significant difference to our approach is that both techniques <ref type="bibr" target="#b31">[32,</ref><ref type="bibr" target="#b42">43]</ref> are restricted in the positioning of light sources. With front-to-back rendering, light sources can be located only in the hemisphere behind the observer or, alternatively, in the hemisphere in front of the observer with back-to-front rendering. Consequently, light sources cannot be anchored with the data set but only with the observer, which is not the case with our approach.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">IMPLEMENTATION</head><p>For our implementation on the GPU, we employ CUDA and we make use of 3D textures for storing the data set, the SATs, and the optional shadow cache. Furthermore, we provide gradient-based Phong illumination <ref type="bibr" target="#b32">[33]</ref>. The computation of the CSAT and SSAT on the GPU is performed in computational space, which is a regular grid in both cases. Therefore, the double-buffering algorithm by Hensley et al. <ref type="bibr" target="#b12">[13]</ref> can be directly applied to our approach by simply transforming the positions from computational space into world space. In general, low floating point precision is a known issue for SATs, which can lead to artifacts. Therefore, we implemented the bias technique by Hensley et al. <ref type="bibr" target="#b12">[13]</ref> to improve precision. For performance comparison, we also implemented box-filtering without SATs by directly casting shadow rays. Furthermore, we implemented Gaussian filtering with both shadow rays and SATs according to Section 4.3.</p><p>In addition, we implemented other volume rendering algorithms that are similar to our approach and that are also capable of generating volumetric shadows for interactive DVR. We compare with volumetric ambient occlusion based on SATs <ref type="bibr" target="#b38">[39]</ref> due to its high performance and relevance. For directional shadows, we implemented single scattering as a basic reference and to demonstrate that hard shadows can be problematic for volume visualization. For soft shadows, we implemented the methods by Schlegel et al. <ref type="bibr" target="#b38">[39]</ref> and by Ament et al. <ref type="bibr" target="#b0">[1]</ref>. All comparison methods are also written in CUDA and for a fair comparison, we also employ shadow and illumination caches.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">RESULTS</head><p>We present results with different data sets exhibiting volumetric structures of different scale and frequency to evaluate our approach. We study our low-pass filtering of shadows with a Fourier analysis of one artificial and six real-world data sets. Furthermore, we compare our soft shadows with single scattering to demonstrate the benefit for visualization in terms of perception, especially for time-dependent data, which is shown in the supplemental video. Finally, we discuss the benefit of our method in terms of quality and performance with respect to two previous state-of-the-art techniques <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b38">39]</ref>.</p><p>All results were obtained with an Intel Core i7 3.4 GHz CPU, 16 GB RAM, and an NVIDIA GTX Titan GPU. For a fair comparison, we employ a shadow cache with the same resolution (equal to the corresponding data set) for all results and methods. In particular, for our comparisons with the SAT-based methods by Schlegel et al. <ref type="bibr" target="#b38">[39]</ref> and Ament et al. <ref type="bibr" target="#b0">[1]</ref>, we use the same resolutions for our CSAT and SSAT as for their respective volume-aligned SATs, namely half the resolution of the corresponding data set. In this way, memory consumption and computation times can be compared directly. <ref type="figure">Figure 1</ref> shows volume renderings of one time step of a numerical shock wave simulation (256 × 256 × 256). In <ref type="figure">Figure 1(a)</ref>, SATbased volumetric ambient occlusion <ref type="bibr" target="#b38">[39]</ref> and specular highlights are employed for local shadows and illumination to visualize the surface characteristics and concavities, but the perception of spatial depth is limited. In <ref type="figure">Figure 1(b)</ref>, three orthodirectional light sources and single scattering are employed to compute directional shadows, which provide additional cues for the depth order, but the hard and dark shadows limit their usefulness. In <ref type="figure">Figure 1(c)</ref>, we visualize the same setup with our method using one CSAT and a small filter width of 3 voxels (with respect to the resolution of the data set), which already helps us balance illumination. By increasing the filter width to 9 voxels in <ref type="figure">Figure 1(d)</ref>, the remaining shadow streak patterns are filtered and only the large-scale structures cast soft shadows, which help understand the spatial arrangement. The accompanying video further demonstrates the benefit when the data set is rotated relative to the light sources. Due to the shadow cache, ray casting from the camera runs at 92 frames per second (fps) for all four results. However, shadow computation times vary significantly: Ambient occlusion requires 9 ms, single scattering 201 ms, and our approach 17 ms for both filter sizes.</p><p>In <ref type="figure" target="#fig_3">Figure 4</ref>, we evaluate the filtering quality of our low-pass shadows with an artificial data set (177 × 27 × 64), using signal-processing methodology <ref type="bibr" target="#b30">[31]</ref>. A directional light source illuminates a volumetric occluder from above and casts shadows on an opaque plane on the bottom. The opacity of the occluder is modeled with a chirp function and we provide nonfiltered single scattering as a baseline for comparison. Rendering with box filtering and a filter size of 9 voxels leads to extinction of certain frequencies. In the frequency domain, the box filter is a Sinc function and the multiplication with the Fourier transform of the chirp function shows that two frequencies are deleted (red arrows). The inverse Fourier transform illustrates the spatial location RAPS Shock Wave <ref type="figure">(Fig. 1)</ref> RAPS Combustion <ref type="figure" target="#fig_5">(Fig. 6</ref>) RAPS Vortex Cascade <ref type="figure" target="#fig_6">(Fig. 7)</ref> RAPS Manix <ref type="figure">(Fig. 8</ref>) RAPS Supernova <ref type="figure">(Fig. 1, SR)</ref> RAPS Engine <ref type="figure" target="#fig_1">(Fig. 2, SR</ref> of the erased frequencies, which closely matches the rendered image. For comparison, we use the Gaussian filter because it has optimal falloff in both frequency and spatial domains. Multiplication with the Fourier-transformed chirp function leads to continuous damping and the inverse Fourier transform also exhibits steady smoothing. However, there is a significant drop of performance. Direct sampling with shadow rays is about four orders of magnitude slower than our optimized box filtering and even with CSAT acceleration, according to Section 4.3, higher-order filtering remains too expensive for interactive DVR. Moreover, the visual impact of postaliasing remains subtle with box filtering, even with such an artificially constructed data set, because no disturbing artifacts are introduced for visualization. The previous example was specifically designed as most extreme stress test for filtering. However, real-world data sets do not exhibit such artificial frequency patterns. In <ref type="figure" target="#fig_4">Figure 5</ref>, we provide a spectral analysis of real-world data sets. According to the Fourier projectionslice theorem <ref type="bibr" target="#b25">[26]</ref>, an attenuation-only volume rendering from a certain direction can be obtained by extracting (and inverse-transforming) a perpendicular slice that passes through the origin of the frequency domain representation of the classified volume. In our case, we employ the direction of incoming light for integration of optical depth. However, since we are interested in all possible lighting setups, we require an aggregated evaluation of all possible slices (incoming light directions) that pass through the origin, which is equivalent to the entire 3D Fourier transform of the classified data set. For a compact analysis, we compute radially averaged power spectra (RAPS) of the classified and Fourier-transformed data sets of this paper and plot them logarithmically in <ref type="figure" target="#fig_4">Figure 5</ref>. By comparing to the spectra of typical box and Gaussian filters, it can be observed that most of the energy of all RAPS plots is left of the problematic oscillations of the Sinc functions. Therefore, only negligible energy contributes to postaliasing and, on average, box filtering yields quality close to the Gaussian filter. In <ref type="figure" target="#fig_5">Figure 6</ref>, we compare box and Gaussian filtering with the timedependent Combustion 1 data set (480 × 720 × 120), showing vorticity magnitude. In <ref type="figure" target="#fig_5">Figure 6</ref>(a), we employ a box kernel with a width of 9 voxels and a comparable Gaussian kernel (σ = 7) in <ref type="figure" target="#fig_5">Figure 6</ref>(b). Furthermore, in <ref type="figure" target="#fig_5">Figure 6</ref>(c), we provide a false-color image that shows the difference of luminance of Figures 6(a) and (b) in CIELAB color space (values ranging from 0 to 100). The boxes highlight areas where luminance differs the most; however, the absolute difference remains well below 2 % of the possible range, which can be hardly distinguished in the original images. The supplemental video shows that the difference remains in the 10 % range for all 122 time steps. <ref type="figure" target="#fig_6">Figure 7</ref> shows one time step of a discontinuous Galerkin flow simulation <ref type="bibr" target="#b15">[16]</ref>, resampled on a uniform grid (529 × 529 × 529) with the λ 2 vortex criterion for volume visualization. The simulation shows the creation of a turbulent cascade from two single, perpendicular large-scale vortices that break up, reconnect, and develop into a cascade of vortices. In <ref type="figure" target="#fig_6">Figure 7</ref>(a), single scattering and illumination from two point light sources are employed; however, shadows are too dark, which strongly limits visibility. For a fair comparison, we manually reduce optical depth for shadow computation in <ref type="figure" target="#fig_6">Figure 7</ref>(b) by a factor of ten to allow more light to enter the medium. Although visibility is improved, the hard shadows and vortex features visually interfere with each other due to similar scale, hampering perception of depth. In <ref type="figure" target="#fig_6">Figure 7</ref>(c), we employ our method with two SSATs and a small filter size of 3 voxels, which already reduces the distracting streak patterns. By successively increasing the filter size to 7 voxels in <ref type="figure" target="#fig_6">Figure 7</ref>(d) and 11 voxels in <ref type="figure" target="#fig_6">Figure 7</ref>(e), shadows become increasingly softer, which helps perceive the spatial structure. Furthermore, the performance of  shadow computation remains independent of the filter size. The benefit of our method can be experienced best in the supplemental video, where the time-dependency of the data set leads to strong visual flickering for single scattering or too small filter sizes. In addition, our method (170 ms) outperforms single scattering (2336 ms) in terms of shadow computation time by more than an order of magnitude. In <ref type="figure">Figure 8</ref>, we compare our method with SAT-based cone shadows by Schlegel et al. <ref type="bibr" target="#b38">[39]</ref> and ambient volume scattering by Ament et al. <ref type="bibr" target="#b0">[1]</ref>. We employ the Manix 2 data set (512×512×512) and three orthodirectional light sources. <ref type="figure">Figure 8</ref>(a) is visualized with cone shadows using a small cone angle for distinct but slightly smoothened shadows as shown in the highlighted box. For artifact-free rendering, a step size of 15 voxels is necessary for cone marching and shadow computation requires 1484 ms. In <ref type="figure">Figure 8(b)</ref>, the same setup is rendered with our method using one CSAT and a filter size of 5 voxels to obtain similar quality and softness of the shadows. Full computation of all shadows requires 90 ms. In <ref type="figure">Figure 8</ref>(c), we employ ambient scattering and visually resemble a similar quality and softness of the shadows. However, since this method approximates multiple scattering, a direct comparison is difficult. We achieved the best visual match by using a scattering albedo of 0.6. The softness of the shadows is inherently coupled to the ambient radius of the method, which in turn is coupled to the step size of shadow ray marching. For this result, we employed a radius of 8 voxels, which leads to a step size of 16 voxels and shadow recomputation takes 912 ms. Due to the shadow cache, all methods render with similar performance. Our method and cone shadows render at 67 fps, whereas ambient scattering runs only at 54 fps due to the additional view-dependent lookup in the scattering table. We repeat the latter evaluation in <ref type="figure">Figures 8(d)</ref>-(f) but with a larger cone angle, filter size, and ambient radius, respectively, to demonstrate that all three methods can increase the softness of the shadows with similar quality. However, shadow computation times significantly differ again with 1484 ms in <ref type="figure">Figure 8</ref> In terms of performance, our method is superior because no shadow ray marching is required. However, for a thorough comparison, we increase the step sizes of both other methods <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b38">39]</ref> until the performance of shadow computation (for example when the transfer function changes) is similar to our technique, which requires a very large step size. <ref type="figure">Figure 8(g)</ref> shows the result for ambient scattering. Since the ambient sphere of each point is almost as large as the entire data set, directional shadows are missing almost completely. In <ref type="figure">Figure 8(h)</ref>, the result for cone shadows is presented. The cone of each sample point in  <ref type="figure">Fig. 8</ref>. Visualization of the Manix data set using three orthodirectional light sources and three different methods. Similar quality: (a) Cone shadows <ref type="bibr" target="#b38">[39]</ref> with a small cone angle for hard shadows. (b) Our method with a small filter size and comparable shadows. (c) Ambient scattering <ref type="bibr" target="#b0">[1]</ref> with a small ambient radius. (d) Cone shadows with a large cone angle for softer shadows. (e) Our method with a larger filter size for similar shadows. (f) Ambient scattering with larger radius. Similar performance: (g) Ambient scattering with similar performance than our approach; directional shadows are largely missing. (h) Cone shadows with similar performance than our approach; shadows are inconsistent.</p><p>the volume is approximated with only one cuboid to achieve the same performance as our method. However, this leads to strongly inconsistent shadows because of the volume-aligned SAT and the direction of all shadows is inherently aligned with the main axes of the data set. Furthermore, the size of the cuboid varies strongly for different sample points, which leads to noticeable artifacts.</p><p>In <ref type="table">Table 1</ref>, we summarize performance measurements and memory requirements of the SATs. In all cases, our approach with filtered shadows (FS) can reach a significant performance boost compared to single scattering (SS), cone shadows (CS), and ambient scattering (AS) when the transfer function changes. A minor disadvantage of our method is that the CSAT and SSAT need to be recomputed when the light sources move. In this case, cone shadows and ambient scattering only need to update the shadow cache; however, shadow ray marching is still much more expensive than our full recomputation, since the SATs can be computed very efficiently in contrast to ray marching. For example, with the Manix data set, recomputation of the CSAT requires only 26 ms, whereas ray marching is in the order of 1 s. In fact, our approach is almost as fast as ambient occlusion (AO) as long as one SAT is sufficient. Only if multiple SATs are required, like for the Vortex Cascade, AO remains notably faster than our method, but it does not provide directional shadows. Nonetheless, the transfer function or lighting setup are typically not changed for each frame by a user and a recomputation of the shadows is not necessary. In this case, the compared methods (SS, CS, AS, AO) still provide high rendering performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">CONCLUSION</head><p>We have introduced an efficient technique for low-pass filtered volumetric shadows for interactive DVR to reduce disruptive hard shadow edges and noise-like visual patterns in the presence of fine structures due to single scattering illumination. Moreover, soft shadows are particularly beneficial for time-dependent data or when the data set is rotated relative to the light sources. The unique feature of our approach is that shadows of arbitrary softness can be computed without explicit shadow ray marching and at no extra cost.</p><p>With our current approach, a user needs to adjust the filter size interactively. However, in future work, it could be possible to automatically determine an ideal filter size, e.g., based on signal theory or with a perception-driven metric. In this way, the kernel size could be adapted to the transfer function or viewpoint, which would allow one to automatically filter disturbing patterns, but preserve as much details as possible by avoiding too strong blurring when no high-frequency shadows are present. Furthermore, a user study could evaluate and quantify the benefit of such an approach.</p><p>Our current implementation can be limited by memory constraints if more than six orthodirectional lights or several point lights are used. However, this is only a limitation of our implementation, which could be improved with an interleaved computation scheme so that only a single SAT is required in terms of memory consumption: as soon as one SAT is computed, the contribution of each light source could be added to the shadow cache and then the same SAT could be employed to compute the shadows of the next light source.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>For</head><label></label><figDesc>information on obtaining reprints of this article, please send e-mail to: tvcg@computer.org. Manuscript received 31 Mar. 2014; accepted 1 Aug. 2014 ate of publication 2014; date of current version 2014. 11 Aug. 9 Nov. D . Digital Object Identifier 10.1109/TVCG.2014.2346 33</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Illustrative comparison of techniques for approximating soft shadows in interactive DVR. (a) Slice-based sampling of a cone with repeated blurring operations. (b) Cuboid-based sampling of a cone with a volume-aligned SAT<ref type="bibr" target="#b38">[39]</ref>. (c) Sphere-based sampling of a tube with preintegrated scattering<ref type="bibr" target="#b0">[1]</ref>. (d) Novel technique for directional light sources. Our first approach introduces a light source-aligned SAT and does not require additional sampling with ray marching. (e) Novel technique for point light sources. Our second approach introduces a spherical SAT located at the position of the point light source and also does not require any shadow ray marching.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .</head><label>3</label><figDesc>Illustration of filtered volumetric shadows for one sample point of the eye ray. (a) For directional light sources, a planar area patch spans a cuboid pointed toward the light source. Conceptually, the patch is discretized and for each point a shadow ray is casted to compute the optical depth τ. Then, a 2D filter is employed to computeτ according to Eqn. (4). (b) For point light sources, a curved area patch spans a spherical pyramid and the filter is applied on the curved patch.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 4 .</head><label>4</label><figDesc>Comparison of different filter kernels with an artificial data set and incoming light from above of a directional light source. A volumetric occluder casts shadows on the opaque plane on the bottom. The opacity of the occluder is given by a chirp function with varying frequencies.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 5 .</head><label>5</label><figDesc>) Spectrum Gaussian (σ = 0.85) Spectrum Gaussian (σ = 1.45) Spectrum Gaussian (σ = 3.10) Spectrum Box (3Radially averaged power spectra (RAPS) of all real-world data sets of this paper and of the supplemental results (SR) as well as spectra of typical box and Gaussian filter kernels.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 6 .</head><label>6</label><figDesc>Visualization of the time-dependent Combustion data set. (a) Box filter: changing the transfer function or lighting setup requires 63 ms. Rendering is performed with 81 fps. (b) Comparable Gaussian filter: changing the transfer function or lighting setup requires 12.2 s. Rendering is also performed with 81 fps. (c) Difference image of (a) and (b).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 7 .</head><label>7</label><figDesc>Visualization of the time-dependent Vortex Cascade data set using two point light sources. (a) Illumination with single scattering leads to dark and hard shadows. (b) Manual down-scaling of the optical depth for shadow computation illuminates the inner structures, but introduces noise-like patterns due to high-frequency shadows and high contrast. Our low-pass filtered shadows with two SSATs and increasing box filter sizes of (c) 3, (d) 7, and (e) 11 voxels successively remove the disturbing light and shadow streaks. The supplemental video shows the entire animation.Table 1. Overview of performance for all real-world data sets of this paper using a viewport size of 512 2 pixels. The computation times for changing the transfer function (TF) and moving the light sources (LS) are not included in the rendering performance. Rendering methods: single scattering (SS), SAT-based ambient occlusion (AO), SAT-based cone shadows (CS), SAT-based ambient scattering (AS), our filtered shadows (FS) with box kernel. Light sources: orthodirectional light (OL), point light (PL). The Engine and Supernova are shown in the supplemental results (SR).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head></head><label></label><figDesc>(d), 90 ms in Figure 8(e), and 790 ms in Figure 8(f).</figDesc></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">http://vis.cs.ucdavis.edu/VisFiles/pages/combustion.php</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">http://www.osirix-viewer.com/datasets/</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS</head><p>This work was partially funded by Deutsche Forschungsgemeinschaft (DFG) under grant WE 2836/2-2 (Astrographik) and the Cluster of Excellence in Simulation Technology (EXC 310/1). The authors thank OsiriX, Kwan-Liu Ma, Jackqueline Chen, Andrea Beck, John Blondin, and all collaborators of http://volvis.org for providing data sets.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Ambient volume scattering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ament</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Sadlo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Weiskopf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Vis. Comput. Graph</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2936" to="2945" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Adding shadows to a texture-based volume renderer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Behrens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ratering</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the IEEE Symposium on Volume Visualization</title>
		<meeting>of the IEEE Symposium on Volume Visualization</meeting>
		<imprint>
			<date type="published" when="1998" />
			<biblScope unit="page" from="39" to="46" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A survey on participating media rendering techniques</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Cerezo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Pérez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Pueyo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">J</forename><surname>Seron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">X</forename><surname>Sillion</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Vis. Comput</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="303" to="328" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Radiative Transfer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chandrasekhar</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1960" />
			<publisher>Dover</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Interactive indirect illumination using voxel cone tracing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Crassin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Neyret</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sainz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Green</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Eisemann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Graph. Forum</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1921" to="1930" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Summed-area tables for texture mapping</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">C</forename><surname>Crow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIGGRAPH Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="207" to="212" />
			<date type="published" when="1984" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Real-time ambient occlusion and halos with summed area tables</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Díaz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P.-P</forename><surname>Vázquez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Navazo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Duguet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computers &amp; Graphics</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="337" to="350" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Casting shadows in real time</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Eisemann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Assarsson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Schwarz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Wimmer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM SIGGRAPH Asia Courses</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Epipolar sampling for shadows and crepuscular rays in participating media with single scattering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Engelhardt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Dachsbacher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM SIGGRAPH Symposium on Interactive 3D Graphics and Games</title>
		<meeting>the ACM SIGGRAPH Symposium on Interactive 3D Graphics and Games</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="119" to="125" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Percentage-closer soft shadows</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Fernando</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM SIGGRAPH Sketches</title>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">A model of visual masking for computer graphics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Ferwerda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Shirley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">N</forename><surname>Pattanaik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Greenberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACM SIG-GRAPH</title>
		<meeting>ACM SIG-GRAPH</meeting>
		<imprint>
			<date type="published" when="1997" />
			<biblScope unit="page" from="143" to="152" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">GPU-accelerated deep shadow maps for direct volume rendering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hadwiger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kratz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Sigg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Bühler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the ACM SIG-GRAPH/Eurographics Symposium on Graphics Hardware</title>
		<meeting>of the ACM SIG-GRAPH/Eurographics Symposium on Graphics Hardware</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="49" to="52" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Fast summed-area table generation and its applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hensley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Scheuermann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Coombe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lastra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Graph. Forum</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="547" to="555" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Interactive global light propagation in direct volume rendering using local piecewise integration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Hernell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Ljung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ynnerman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the IEEE/EG International Symposium on Volume and Point-Based Graphics</title>
		<meeting>of the IEEE/EG International Symposium on Volume and Point-Based Graphics</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="105" to="112" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Local ambient occlusion in direct volume rendering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Hernell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Ljung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ynnerman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Vis. Comput. Graph</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="548" to="559" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Explicit discontinuous Galerkin methods for unsteady problems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Hindenlang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Gassner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Altmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Beck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Staudenmaier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-D</forename><surname>Munz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computers &amp; Fluids</title>
		<imprint>
			<biblScope unit="volume">61</biblScope>
			<biblScope unit="page" from="86" to="93" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">The relative contributions of stereo, lighting, and background scenes in promoting 3d depth visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">S</forename><surname>Hubona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">N</forename><surname>Wheeler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">W</forename><surname>Shirah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Brandt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Comput.-Hum. Interact</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="214" to="242" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Efficient simulation of light transport in scenes with participating media using photon maps</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">W</forename><surname>Jensen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">H</forename><surname>Christensen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACM SIGGRAPH</title>
		<meeting>of ACM SIGGRAPH</meeting>
		<imprint>
			<date type="published" when="1998" />
			<biblScope unit="page" from="311" to="320" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Historygrams: Enabling interactive global illumination in direct volume rendering using photon mapping</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Jönsson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kronander</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Ropinski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ynnerman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Vis. Comput. Graph</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="2364" to="2371" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Interactive volume rendering with volumetric illumination</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Jönsson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Sundén</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ynnerman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Ropinski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Eurographics STAR program</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="53" to="74" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Interactive translucent volume rendering and procedural modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kniss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Premože</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Hansen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ebert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of IEEE Visualization</title>
		<meeting>of IEEE Visualization</meeting>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="109" to="116" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Exposure render: An interactive photo-realistic volume rendering framework</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kroes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">H</forename><surname>Post</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">P</forename><surname>Botha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS ONE</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page">38586</biblScope>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Efficient visibility encoding for dynamic illumination in direct volume rendering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kronander</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Jönsson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Low</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Ljung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ynnerman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Unger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Vis. Comput. Graph</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="447" to="462" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Depth discrimination from shading under diffuse lighting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Langer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Bülthoff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Perception</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="649" to="660" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Summed-area variance shadow maps</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lauritzen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">GPU Gems 3</title>
		<editor>H. Nguyuen</editor>
		<imprint>
			<publisher>Addison-Wesley Professional</publisher>
			<date type="published" when="2007" />
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="157" to="181" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Volume rendering using the Fourier projection-slice theorem</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Levoy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Conference on Graphics Interface</title>
		<meeting>of the Conference on Graphics Interface</meeting>
		<imprint>
			<date type="published" when="1992" />
			<biblScope unit="page" from="61" to="69" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">About the influence of illumination models on image comprehension in direct volume rendering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Lindemann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Ropinski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Vis. Comput. Graph</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="1922" to="1931" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Deep shadow maps</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Lokovic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Veach</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACM SIG-GRAPH</title>
		<meeting>of ACM SIG-GRAPH</meeting>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="page" from="385" to="392" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Optical models for direct volume rendering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Max</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Vis. Comput. Graph</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="99" to="108" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Sort first parallel volume rendering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Moloney</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ament</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Weiskopf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Möller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Vis. Comput. Graph</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1164" to="1177" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Discrete-Time Signal Processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">V</forename><surname>Oppenheim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">W</forename><surname>Schafer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">R</forename><surname>Buck</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998" />
			<publisher>Prentice Hall</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Instant convolution shadows for volumetric detail mapping</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Patel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Šoltészová</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Nordbotten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bruckner</surname></persName>
		</author>
		<idno>154:1-154:18</idno>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Graph</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">5</biblScope>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Illumination for computer generated pictures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">T</forename><surname>Phong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Communications of the ACM</title>
		<imprint>
			<date type="published" when="1975" />
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="311" to="317" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">GPU-based Monte-Carlo volume raycasting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Rezk-Salama</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Pacific Conference on Computer Graphics and Applications</title>
		<meeting>of the Pacific Conference on Computer Graphics and Applications</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="411" to="414" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Interactive volumetric lighting simulating scattering and shadowing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Ropinski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Döring</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Rezk-Salama</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of IEEE Pacific Visualization Symposium</title>
		<meeting>of IEEE Pacific Visualization Symposium</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="169" to="176" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Interactive volume rendering with dynamic ambient occlusion and color bleeding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Ropinski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Meyer-Spradow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Diepenbrock</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Mensmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Hinrichs</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Graph. Forum</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="567" to="576" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Obscurance-based volume rendering framework</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ruiz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Boada</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Viola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bruckner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Feixas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sbert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the IEEE/EG International Symposium on Volume and Point-Based Graphics</title>
		<meeting>of the IEEE/EG International Symposium on Volume and Point-Based Graphics</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="113" to="120" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Adaptive volumetric shadow maps</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Salvi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Vidimce</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lauritzen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">E</forename><surname>Lefohn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Graph. Forum</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1289" to="1296" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Extinction-based shading and illumination in GPU volume ray-casting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Schlegel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Makhinya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Pajarola</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Vis. Comput. Graph</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="1795" to="1802" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">A directional occlusion shading model for interactive direct volume rendering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Schott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Pegoraro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Hansen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Boulanger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Bouatouch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Graph. Forum</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="855" to="862" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Vicinity shading for enhanced perception of volumetric data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">J</forename><surname>Stewart</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of IEEE Visualization</title>
		<meeting>of IEEE Visualization</meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="355" to="362" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Image plane sweep volume illumination</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Sundén</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ynnerman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Ropinski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Vis. Comput. Graph</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2125" to="2134" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">A multidirectional occlusion shading model for direct volume rendering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Šoltészová</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Patel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bruckner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Viola</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Graph. Forum</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="883" to="891" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Perceiving spatial relationships in computer-generated images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wanger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ferwerda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Greenberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Comput. Graph. Appl</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="44" to="58" />
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Interactive direct volume rendering with many-light methods and transmittance caching</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Weber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kaplanyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Stamminger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Dachsbacher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the International Workshop on Vision, Modeling, and Visualization</title>
		<meeting>of the International Workshop on Vision, Modeling, and Visualization</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="195" to="202" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Interactive display of isosurfaces with global illumination</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wyman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Parker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Shirley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Hansen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Vis. Comput. Graph</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="186" to="196" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Shadows and soft shadows with participating media using splatting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Crawfis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Vis. Comput. Graph</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="139" to="149" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Fast global illumination for interactive volume visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K.-L</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the ACM SIGGRAPH Symposium on Interactive 3D Graphics and Games</title>
		<meeting>of the ACM SIGGRAPH Symposium on Interactive 3D Graphics and Games</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="55" to="62" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Lighting design for globally illuminated volume rendering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K.-L</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Vis. Comput. Graph</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2946" to="2955" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
