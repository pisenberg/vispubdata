<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/pisenberg/grobid/grobid-0.6.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Fast and Memory-Efficient Topological Denoising of 2D and 3D Scalar Fields</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Günther</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alec</forename><surname>Jacobson</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><surname>Reininghaus</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hans-Peter</forename><surname>Seidel</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olga</forename><surname>Sorkine-Hornung</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tino</forename><surname>Weinkauf</surname></persName>
						</author>
						<title level="a" type="main">Fast and Memory-Efficient Topological Denoising of 2D and 3D Scalar Fields</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="DOI">10.1109/TVCG.2014.23464</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2021-02-19T19:36+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Numerical optimization</term>
					<term>topology</term>
					<term>scalar fields</term>
				</keywords>
			</textClass>
			<abstract>
				<p>(a) Noisy input scalar field. (b) All minima and maxima of the noisy input data. (c) Extrema above a certain noise level (persistence) are selected. (d) Filtered output scalar field contains only the selected extrema. Figure 1. Our method filters scalar fields with explicit control over the removal and the preservation of minima (blue spheres) and maxima (red spheres). The result is smooth and topologically clean.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Noise and sampling artifacts hinder the visual analysis of measurements and simulated data. For example, an isocontour visualization of a noisy scalar field contains a large number of small connected components which make it difficult to see the big picture. As another example, gradient estimation is often negatively affected by noise in a scalar field.</p><p>Many methods exist to smooth or denoise scalar fields. Some of them focus on statistical features in the data, e.g., a Gaussian blur or a median filter. Other methods aim to maintain spatial features while smoothing the data, e.g., a bilateral filter preserves edges in an image. The method presented in this paper falls into the category of denoising methods that maintain spatial features. In particular, we focus on topological features: the minima and maxima of a scalar field. The input of our method is a scalar field and a subset of its minima and maxima. The output is a smoothed version of the scalar field that contains only the selected minima/maxima, and is otherwise as close as possible to the original data. The values and positions of the selected extrema are preserved, while all other extrema are removed from the data.</p><p>Such a filter provides control over the topology, which can be beneficial for subsequent visualization methods. For example, the appearance of connected components in an isocontour visualization is a matter of topology: removing the noise-induced extrema (e.g., identified using persistence <ref type="bibr" target="#b6">[7]</ref>) leads to fewer and larger connected components, which provides an isocontour visualization with less clutter.</p><p>We extend previous work <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b23">24]</ref> on topological denoising filters. Our method follows the same computation pipeline, which has two main stages. First, the extrema of a scalar field are extracted and filtered (Section 3). Second, the denoised scalar field is obtained as the solution of a discrete optimization problem -we call this "numerical reconstruction" (Section 4). The improvements over the previous work are due to the following contributions:</p><p>• For the extraction and filtering part of the pipeline, we propose a direct coupling of Forman's discrete Morse theory <ref type="bibr" target="#b7">[8]</ref> to our numerical optimization scheme, where the output of the former serves directly as the input to the latter. In contrast to <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b23">24]</ref>, this eliminates the need to remesh the domain and solve another optimization problem to get a representative function. (Section 3. • We propose a topological simplification scheme that allows user intervention. Compared to previous work, this provides more flexible control over the topology. (Section 3.2.2) • For the numerical reconstruction, we propose a scheme to iteratively improve the quality of the solution. The result is notably smoother and closer to the original data than in previous work. (Section 4.2) • For the numerical reconstruction, we propose a novel domain decomposition, which leads to a significant speed-up (6 minutes vs. previously 6.5 hours for 64 <ref type="bibr" target="#b2">3</ref> ) and a significant reduction of the memory requirements (3 GB vs. previously 10 GB for 64 <ref type="bibr" target="#b2">3</ref> ). With this contribution, our method achieves, in contrast to previous work, practicable computation times for 3D scalar fields. (Section 4.3)</p><p>We extensively evaluate and discuss our method in Section 5, show applications in Section 6, and conclude with a discussion of possible future research directions in Section 7.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK</head><p>Methods for smoothing scalar data while preserving its salient features are sought after in many domains. In image processing, typical features are intensity edges; methods such as bilateral filtering <ref type="bibr" target="#b21">[22]</ref> or non-local means <ref type="bibr" target="#b2">[3]</ref> attempt to denoise images without blurring strong edges.</p><p>In signal and geometry processing, Laplacian smoothing techniques were adapted to interpolate the values at some prescribed points <ref type="bibr" target="#b18">[19]</ref>. Such methods cannot guarantee exact preservation of extrema, and new (unwanted) extrema can even emerge in the output <ref type="bibr" target="#b8">[9]</ref>. The technique in <ref type="bibr" target="#b8">[9]</ref> tracks a given 2D filter, e.g. Laplacian or anisotropic diffusion, and stops it before unwanted changes of the isocontour topology occur. Scalar field topology is related to the more general notion of vector field topology. An approach to a continuous topology simplification of 2D vector fields is presented by Tricoche et al. <ref type="bibr" target="#b22">[23]</ref>. Based on the topological graph structure and certain relevance measures, pairs of critical points are removed by local changes to the vector values at the grid nodes. The method does not guarantee successful removal of all critical points that are scheduled for removal, and smoothness criteria of the result are not addressed. Theisel <ref type="bibr" target="#b19">[20]</ref> and Weinkauf et al. <ref type="bibr" target="#b25">[26]</ref> construct a 2D or 3D vector field based on a given topological skeleton. Such methods create piecewise-linear vector fields with C 0 -continuity and cannot avoid the appearance of additional critical points.</p><p>Topology design and control is also of high interest for functions on surfaces. Recently, Tierny et al. <ref type="bibr" target="#b20">[21]</ref> proposed an interactive combinatorial algorithm to edit a scalar field on a surface with a user-prescribed topology. This 2D approach uses an iterative heuristic, but shows very good practical performance. However, its extension to 3D is an open problem. Chen et al. <ref type="bibr" target="#b5">[6]</ref> use Morse decomposition to edit the topology of vector fields on surfaces. Harmonic functions have been used for constructing Morse functions on surfaces <ref type="bibr" target="#b16">[17]</ref>. Topological control is beneficial for binary image segmentation as well <ref type="bibr" target="#b4">[5]</ref>.</p><p>A number of methods exist that exploit the topological simplification of the Morse-Smale complex to simplify 2D scalar fields. Bremer et al. <ref type="bibr" target="#b1">[2]</ref> smooth the function in the interior of a Morse-Smale cell after each cancellation step to adhere to the altered topological structure. The resulting scalar field is C 0 -continuous between Morse-Smale cells. Alternative approaches for 2D scalar fields are given by Weinkauf et al. <ref type="bibr" target="#b23">[24]</ref> and Jacobson et al. <ref type="bibr" target="#b14">[15]</ref>, where the scalar field is reconstructed from a given subset of the original topology. Both methods employ optimization to construct a 2D scalar field that conforms to the prescribed topology, and is also smooth and close to the input data. It has also been shown in this context that explicit control over the topology of a scalar field has interesting applications for animating characters <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b14">15]</ref> -this requires the topological design of very small 3D scalar fields.</p><p>The work presented in this paper is an extension of <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b23">24]</ref> to larger data sets. The extension is non-trivial, since directly applying the methods of <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b23">24]</ref> to 3D data leads to impractical performance, including excessive memory use and computation times in the order of several hours (6.5 hours for 64 <ref type="bibr" target="#b2">3</ref> ). Our solution is a novel domain decomposition approach. While standard decomposition techniques may <ref type="figure" target="#fig_7">Figure 2</ref>. The directed acyclic graph G encodes the monotonicity on the input grid with respect to the selected extrema K min ∪ K max . It is shown here using arrows pointing into the direction of a larger neighbor. All neighbors of a minimum (blue) are larger than the minimum itself. For a maximum (red), all neighbors are smaller. All other vertices (white) are described as non-extremal points by having at least one larger and one smaller neighbor.</p><p>introduce spurious extrema, we propose an iterative processing of the decomposed blocks which communicates the information in-between blocks. This results in a smooth output, avoids spurious extrema, and guarantees that only the user-selected extrema are present. This divide and conquer approach leads to significantly faster computation times in the order of a few minutes (6 minutes for 64 <ref type="bibr" target="#b2">3</ref> ), and also opens the door to a parallel and distributed computation -decreasing the computation times even further. Additionally, we provide an iterative scheme to drastically improve the quality of the solution, and a direct coupling between the topology extraction and the numerical optimization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">EXTREMA EXTRACTION AND FILTERING</head><p>This section discusses the extraction and filtering of extrema in a 2D or 3D scalar field. In Section 4, we will feed the filtered extrema to the numerical reconstruction, which generates a smooth scalar field containing only these extrema and being otherwise as close as possible to the input scalar field.</p><p>Let G be a uniform grid in IR <ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b2">3</ref> with vertices v i ∈ V and let s be a scalar field defined on that grid. Let K min ⊂ V and K max ⊂ V denote the minima and maxima of s , respectively. 1 Our goal is now to extract these extrema and allow the user to select some of them, i.e., we have a subset of minima K min ⊆ K min and a subset of maxima K max ⊆ K max . We often refer to K min ∪ K max as selected extrema.</p><p>The second input to the numerical reconstruction is the monotonicity graph G = (V, E ). It is a connected, directed acyclic graph on the input grid G, where V denotes the vertices of G and E is a set of directed edges between neighboring vertices. <ref type="figure" target="#fig_7">Figure 2</ref> gives a 2D illustration. The edge-set E includes all edges emanating from K max , all edges incident on K min , and at least one edge pointing in and one edge pointing out of all other vertices. Loosely speaking, G represents gradient information -it points into the direction of a larger neighbor. It describes that all neighbors of a minimum/maximum are larger/smaller than the extremum itself. Most importantly, it describes that any other vertex cannot be an extremum, since it has at least one incoming and one outgoing edge.</p><p>In general, a given set of extrema can be represented by many possible graphs G . We will propose different schemes for constructing valid monotonicity graphs in the following. A comparison of different monotonicity graphs is given in Section 5.3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Approaches without Morse Theory</head><p>The extraction and filtering methods in this section are easy to implement but the resulting monotonicity graph is unaware of the input scalar field. Consequently, a subsequent numerical reconstruction requires usually more iterations to converge compared to the methods from Section 3.2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.1">Non-Topological Extraction and Filtering</head><p>A simple algorithm for extracting the extrema of a scalar field is this: Visit each vertex v i . If all of its neighbors are larger/smaller, then v i is a minimum/maximum. One may now use any selection criteria to define a set of selected extrema. Now we construct a cheap-to-compute, yet unsmooth and dataunaware scalar field s a that contains only the selected extrema. This corresponds to the representative function in <ref type="bibr" target="#b14">[15]</ref>. We solve the following Laplace problem:</p><formula xml:id="formula_0">L s a = 0 (1) s.t. s a (v i ) = 0 ∀v i ∈ K min (2) s a (v i ) = 1 ∀v i ∈ K max (3)</formula><p>where L denotes the finite-difference discretization of the Laplace operator on regular grids. The result s a is a harmonic function, for which the maximum principle of discrete harmonic functions guarantees that, when choosing the Dirichlet boundary conditions as above, the locations in K min and K max become the only minima and maxima, respectively. As proposed in <ref type="bibr" target="#b14">[15]</ref>, a monotonicity graph is built from s a by constraining all edges around an extremum as well as the two edges around every other vertex corresponding to the steepest ascent and descent.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.2">Persistence Pairs</head><p>Persistence <ref type="bibr" target="#b6">[7]</ref> provides an alternative way for selecting the extrema of a scalar field. The algorithm tracks the topological changes in the evolution of the sublevel sets in a scalar field, amongst which we find the minima and maxima of the scalar field. Most importantly, persistence provides an "importance" for each extremum. Noise-induced extrema have a low persistence while dominant ones have a high persistence. This is very useful for filtering extrema. Fast algorithms <ref type="bibr" target="#b11">[12]</ref> and opensource implementations <ref type="bibr" target="#b1">2</ref>  <ref type="bibr" target="#b0">[1]</ref> for computing persistence are available.</p><p>A monotonicity graph can be computed from the selected extrema using a representative function as described above.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Approaches based on Morse Theory</head><p>The extraction and filtering methods in this section are more involved. In contrast to above, the monotonicity graph is initially constructed from the input scalar field and then carefully modified in combination with the extrema filtering. Hence, the monotonicity graph is dataaware and a subsequent numerical reconstruction usually requires less iterations to converge compared to the methods from Section 3.1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1">Classic Topological Simplification</head><p>In the following, we recapitulate the main idea of <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b23">24]</ref> before we present an algorithmic extension yielding a more direct and simpler optimization strategy in which a representative function is not needed.</p><p>In <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b23">24]</ref>, the Morse-Smale complex of the input scalar field is computed based on discrete Morse theory <ref type="bibr" target="#b7">[8]</ref>. The complex consists of the critical points (minima, maxima, saddles) and the separatrices connecting the critical points. Filtering is done by means of topological simplification in which extremum-saddle pairs are repeatedly removed from the Morse-Smale complex (subject to certain conditions). In <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b23">24]</ref>, the simplified Morse-Smale complex is used to construct a data-aware representative function using an algorithm that requires an explict remeshing of the domain and solving optimization problems in a pre-processing step.</p><p>In this work, we propose a simpler approach which provides a direct coupling between Forman's discrete Morse theory and our numerical reconstruction presented in Section 4.</p><p>We exploit the fact that discrete Morse theory allows us to encode the Morse-Smale complex in a so-called discrete gradient field. It encodes the monotonicity of the scalar field -very much like our monotonicity graph G . Furthermore, the topological simplification of the Morse-Smale complex can be done by working directly on the discrete gradient. For more details and schematic illustrations regarding the simplification process in discrete Morse theory, we refer to <ref type="bibr" target="#b10">[11]</ref>. The only caveat is that the discrete gradient is defined on the cell complex of the domain, whereas we require a vertex-based representation of the monotonicity graph G . We circumvent this issue by doing all topological computations, including the discrete gradient and the Morse-Smale complex, on an auxiliary grid with a halved resolution. More precisely, the resolution for each dimension is 1 + (N − 1)/2, where N refers to the resolution of the input grid in that dimension. <ref type="bibr" target="#b2">3</ref> The cell complex of the auxiliary grid has a 1:1 correspondence to the vertices of the input grid, i.e., the discrete gradient can be directly used as the monotonicity graph. A representative function is not required.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2">Extrema Cancellation with User Control</head><p>The order of a classic topological simplification is usually determined by an importance measure for critical points such as persistence, i.e., the method is completely automated.</p><p>In the following, we introduce an algorithm for removing a userselected set of extrema K u from the Morse-Smale complex and the corresponding discrete gradient g. This algorithm works in 2D and 3D, and can be run standalone or after a classic topological simplification as described above.</p><p>Background. Let p denote a path 4 in a discrete gradient g. If two critical points a and b are connected by one and only one path p, then we call p a cancellation path. As given by Forman <ref type="bibr" target="#b7">[8]</ref>, reversing the flow direction along p creates a new discrete gradient g where a and b are no longer critical.</p><p>Algorithm. First, we create a priority queue into which we insert saddles as follows. For each saddle s, find the extremum e ∈ K u to which s is connected by a cancellation path and to which it has the smallest height difference in the input scalar field | s(s) − s(e)|. If e exists, push s into the priority queue according to the value of the height difference.</p><p>We process the queue as follows. Pop the top element s off the queue. Again, find the extremum e ∈ K u with the smallest height difference that is connected to s by a cancellation path p. If such a cancellation path does not exist anymore, then ignore the saddle and proceed with the queue. Otherwise, compare the new height difference to the height difference of the next saddle in the queue. If it is larger, then reinsert s into the priority queue with the new value. If it is smaller, then do the actual cancellation: reverse the flow in g along p and remove the extremum from K u . Proceed with the queue.</p><p>With respect to the number of critical points, the time complexity of this algorithm is cubic in the worst case, but linear in practice. The memory complexity is always linear. The monotonicity graph is obtained from the simplified g as with classic topological simplification.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">NUMERICAL RECONSTRUCTION</head><p>Equipped with a set of selected extrema and a corresponding monotonicity graph, we come now to the main part of our method: the reconstruction of a smooth scalar field containing only the selected extrema and following the prescribed monotonicity. This works for both 2D and 3D scalar fields.</p><p>We begin with a recapitulation of the optimization problem introduced in <ref type="bibr" target="#b14">[15]</ref>. Given the mathematical formulation, we propose an iterative reconstruction scheme which converges to a smooth scalar field and minimizes the distance to the input field. In the last part of this section, we present our new domain decomposition approach allowing an efficient solving of the optimization problem. For explanations, we use a 3D data set with a spherical function distorted by salt &amp; pepper noise <ref type="figure" target="#fig_0">(Figure 3, right)</ref>. The range of the noise exceeds the range of the spherical function by a factor of two. This is a demanding scenario where a simple smoothing filter is not able to remove the noise, but our topology-based approach is able to do so. Filtering is straightforward: we select one single maximum in the center of the data set (results are shown in <ref type="figure">Figure 7a</ref>). In 2D, we use the same vorticity data set that has been used in <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b23">24]</ref>  <ref type="figure" target="#fig_0">(Figure 3</ref>, left). Extrema are filtered here like in the previous work using a persistence threshold of 18.6 (results are shown in <ref type="figure">Figure 5</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Problem Setup and Modeling</head><p>Let G be a uniform grid in IR <ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b2">3</ref> with vertices v i ∈ V and let s be the original scalar field defined on that grid. Let K min ∪ K max ⊂ V be the selected extrema of s . Our goal is to find a new scalar field s with the following properties: We assume that the set of selected extrema does not contradict the Morse inequalities. For example, a non-constant function on G must have at least one minimum. We also assume that at least one selected minimum is smaller than all selected maxima and vice-versa.</p><p>Many functions exist that fulfill the topological requirements I &amp; II, i.e., they have exactly the same set of extrema. This is still true when requiring specific values for these extrema (requirement III). However, the requirements IV &amp; V provide a way of measuring the suitability of such functions by means of an energy <ref type="bibr" target="#b3">(4)</ref> with a vertex-wise least-squares energy for the data term E D (requirement IV), a Laplacian energy E L for the smoothness term (requirement V), and the factor w D for balancing their weight. In contrast to previous works <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b23">24]</ref>, which use finite elements on irregular triangle/tetrahedral meshes, we work on a regular grid. Hence, we employ a finite-difference discretization of the bi-Laplacian operator L L.</p><formula xml:id="formula_1">E(s) = w D E D (s) + E L (s) = w D ∑ s(v i ) − s(v i ) 2 + Ls 2</formula><p>The requirements I-V translate to the "ideal" discrete optimization problem <ref type="bibr" target="#b14">[15]</ref> as follows:</p><formula xml:id="formula_2">IV &amp; V: arg min s E(s)<label>(5)</label></formula><p>subject to the constraints  See the text for a detailed description.</p><formula xml:id="formula_3">I: s(v j ) &gt; s(v i ) ∀v j ∈ N (v i ), ∀v i ∈ K min (6) I: s(v j ) &lt; s(v i ) ∀v j ∈ N (v i ), ∀v i ∈ K max (7) II: s(v i ) &gt; min v j ∈N (v i ) s(v j ) ∀v i / ∈ K min ∪ K max (8) II: s(v i ) &lt; max v j ∈N (v i ) s(v j ) ∀v i / ∈ K min ∪ K max (9) III: s(v i ) = s(v i ) ∀v i ∈ K min ∪ K max (10)</formula><p>where we denote the grid neighbors of vertex</p><formula xml:id="formula_4">v i with the set N (v i ).</formula><p>The constraints (8) &amp; (9) are non-linear inequality constraints. They are non differentiable, and they describe a generally non-convex feasible region. Solving with such constraints directly leads to impracticable running times. Instead, we use the monotonicity graph G = (V, E ) to conservatively linearize these constraints. It enforces that all neighbors of a minimum/maximum are larger/smaller than the extremum itself. Any other vertex cannot become an extremum since it has at least one incoming and one outgoing edge. It allows us to convexify the feasible region <ref type="bibr" target="#b14">[15]</ref>:</p><formula xml:id="formula_5">IV &amp; V: arg min s E(s)<label>(11)</label></formula><p>subject to the constraints</p><formula xml:id="formula_6">I &amp; II: s(v i ) &gt; s(v j ) ∀(v i , v j ) ∈ E (12) III: s(v i ) = s(v i ) ∀v i ∈ K min ∪ K max<label>(13)</label></formula><p>In other words, the linear constraints (12) define a convex subspace of the larger feasible region described by the topological requirements I &amp; II. The resulting optimization problem is a quadratic program which can be efficiently optimized via conversion to a conic program (see <ref type="bibr" target="#b14">[15]</ref> for details). We solve it using the software package MOSEK <ref type="bibr" target="#b15">[16]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Iterative Convexification</head><p>In the following, we explore the relationship between the "ideal", nonlinear optimization problem (5) and the convex, linear optimization problem <ref type="bibr" target="#b10">(11)</ref>. Based on our observations, we propose a scheme to iteratively decrease the energy of the solution while remaining feasible. <ref type="figure" target="#fig_3">Figure 4a</ref> is a 2D illustration of the high-dimensional, non-linear optimization problem <ref type="bibr" target="#b4">(5)</ref>. The energy is symbolized by concentric, elliptic isolines with a global energy minimum depicted by the blue dot. The "ideal" constraints (6)-(10) partition the domain into a feasible region where they are fulfilled (white), and an infeasible region where they are not fulfilled (red). <ref type="bibr" target="#b4">5</ref> Figure 4b illustrates the linear optimization problem <ref type="bibr" target="#b10">(11)</ref>. The linear inequalities (12) define overlapping halfspaces (shown with green overlays). They form a convex subset of the feasible region, visible Normalized E(s i ) <ref type="figure">Figure 5</ref>. We can significantly decrease the energy of the solution by iteratively convexifying the feasible region. The upper inset corresponds to the result from <ref type="bibr" target="#b14">[15]</ref>. We can significantly improve this result with our iterative scheme as shown in the lower inset. Compare also to the input data set from <ref type="figure" target="#fig_0">Figure 3</ref>.</p><p>as the white region not covered by the green overlays. Note that the unique minimum of the energy within this convex subset can always be found using quadratic or conic programming <ref type="bibr" target="#b17">[18]</ref>. Previous methods <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b23">24]</ref> stop here. The reconstructed scalar field s contains only the selected extrema but the energy E(s) may still be high. We propose the following scheme to further decrease the energy:</p><p>1. We construct a new monotonicity graph G k+1 from the previous optimization result s k as follows:</p><p>• Around the selected extrema, it contains the same edges as G k .</p><p>• For every other vertex v i , we define two directed edges</p><formula xml:id="formula_7">(v min i , v i ) and (v i , v max i ) where v min i , v max i</formula><p>refer to the smallest and largest neighbor of v i in s k .</p><p>2. We solve the optimization problem (11) using the new monotonicity graph G k+1 , which defines another convex subset of the feasible region.</p><p>We may repeat this process until convergence, which is guaranteed because the energy of our iterative solutions E(s k ) is monotonically decreasing. This can be seen as follows. Since the constraints are constructed according to s k , we know that the feasible subset they describe is nonempty: it contains at least s k . Optimizing <ref type="bibr" target="#b10">(11)</ref> for the next solution s k+1 guarantees that E(s k+1 ) ≤ E(s k ), since s k+1 is the unique global minimum in the feasible subset. <ref type="figure" target="#fig_3">Figures 4c-d</ref> show this. However, we are not guaranteed to find the feasible global minimum or even a feasible local minimum. Our heuristic, in general, will be an approximation of the complex, non-convex feasible region. Still, this moving convex window will always reduce the energy or keep it on the same level, but never increase it. In fact, we observed for all our examples enormous energy reductions in the first few iterations, with diminishing returns afterwards. This makes it superior to running just one convexification and solving one optimization. <ref type="figure">Figure 5</ref> plots the energy reductions and compares the result from <ref type="bibr" target="#b14">[15]</ref> without iteration to our new result with iteration. A similar plot is shown for a 3D data set in <ref type="figure">Figure 7b</ref>.</p><p>Our process of iteratively redefining the convex feasible set and solving QPs is related to Sequential Quadratic Programming (SQP). However, generic SQP assumes all nonlinear inequality constraints are at least twice continuously differentiable <ref type="bibr" target="#b17">[18]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Domain Decomposition</head><p>We propose an approach to a domain decomposition of the optimization problem defined in equation <ref type="bibr" target="#b10">(11)</ref>. It leads to substantially faster computation times and requires significantly less memory -even when  executed on a single thread. This approach is the key to handling 3D scalar fields with a practicable performance. It also speeds up the optimization in the 2D case compared to the state of the art. Furthermore, the domain decomposition can be used to parallelize and even distribute the computations, which leads to even faster computation times. Consider a domain decomposition of the underlying grid G into blocks of maximal size n 3 (or n 2 in 2D). Such a decomposition creates a conflict with the monotonicity constraints <ref type="bibr" target="#b11">(12)</ref>. These constraints form chains along which the function is monotonically increasing. The decomposition interrupts these chains, which means that a naive independent optimization of each block may introduce unwanted extrema. It is a classic dependency problem: when optimizing a block B, we need to know the values of the neighboring blocks at the boundary in order to correctly enforce the monotonicity constraints <ref type="bibr" target="#b11">(12)</ref>. On the other hand, the neighboring blocks need the same input from the block B as well. Introducing "thick" boundaries between blocks is not a solution since they still interrupt the monotonicity chains.</p><p>Our solution is twofold by (i) fixing appropriate values at the block boundaries, and (ii) shifting the block boundaries in a repeated process to ensure that every vertex is at least once subject to the optimization.</p><p>First, we decouple each block from the rest of the domain by fixing the values at its boundary using a cheap-to-compute approximation s a of the solution, which conforms to the monotonicity constraints <ref type="bibr" target="#b11">(12)</ref>, but may exhibit a high energy, i.e., it may not be smooth or close to the input data. We only require s a to be consistent with <ref type="bibr" target="#b11">(12)</ref>. We propose two versions:</p><p>• Based on a given monotonicity graph G , we minimize the data energy E D subject to the constraints <ref type="bibr" target="#b11">(12)</ref> and <ref type="bibr" target="#b12">(13)</ref>. This is significantly faster and more memory-efficient than the actual optimization problem (11) since E D exhibits maximal sparsity.</p><p>• We construct s a using the method described in Section 3.1.1, where we solve a discrete Laplacian system with the selected extrema as Dirichlet boundary. From that we can easily derive a monotonicity graph G , see Section 3.1.1 for details.</p><p>In either case, we have a feasible approximation s a and a corresponding monotonicity graph G . Each block is now decoupled from the rest of the domain by fixing its boundary to the values of s a , while the inner vertices of the block are free. The blocks can now be optimized independently. <ref type="figure" target="#fig_6">Figure 6a</ref> illustrates this for a 2D example. Every vertex needs to be subjected to the optimization, otherwise the resulting scalar field is not smooth at the fixed vertices. For a 3D data set, we shift the domain decomposition by a fourth of the block size into all three directions. For a 2D data set, we shift it by a third of the block size, as illustrated in <ref type="figure" target="#fig_6">Figure 6b</ref>. This gives us different blocks and most (but not all) of the former boundary vertices are now free. The new boundary vertices are fixed to the values from the previous optimization run. Now, we perform a second optimization for each new block independently. In 3D, we need to shift the decomposition two more times to make sure that every vertex is free during at least one of the four optimization runs. In 2D, we only need to shift twice and run three optimizations in total, see <ref type="figure" target="#fig_6">Figure 6c</ref>.  <ref type="figure">Figure 7</ref>. Comparison of the decomposed optimization to the global optimization. The low normalized L 2 distance (around 10 −2 ) proves that the results are very similar, which can also be observed in the snapshots. The high energy in the first iteration of the decomposition scheme is due to the rough approximation s a , but this is quickly rectified in the following iteration, where both energies match up. For all practical purposes, both schemes converged with the second iteration.</p><p>Our decomposed optimization scheme benefits from the behavior described in Section 4.2, namely that repeated optimizations decrease the energy. Furthermore, one may apply the iterative convexification as an outer loop to the decomposed optimization to decrease the energy even further.</p><p>Rationale. Theoretically, quadratic programming complexity scales superlinearly with respect to the number of variables, thus solving the individual quadratic programs for each block will be asymptotically faster than solving the global system -even when executed sequentially. Practically, the observed computation times for the global optimization show a quadratic behavior with respect to the number of variables (see <ref type="figure">Figure 8b</ref> in the next section), which makes the domain decomposition scheme even more beneficial.</p><p>The decomposition into individual blocks can be interpreted as new constraints restricting the convex feasible set introduced in Section 4.2 even further. Applying the iterative convexification of Section 4.2 will reduce the energy (4) until convergence. However, it is not guaranteed that the global and the decomposed optimization end in the same local energetic minimum because of the highly non-linear character of the underlying energy landscape. In practice, however, the solutions of the global and decomposed optimization converge empirically to the same scalar field, and we see enormous benefits both in terms of final energy and performance (see next section).</p><p>Block Size. A strategy for choosing the block size n has to take into account that, generally speaking, smaller n lead to faster computation times and lower memory consumption, while larger n lead to lower energies of the solution. Based on the performance figures discussed in the next section, it is straightforward to decide for a block size on a given machine.</p><p>Number of Blocks. Let the grid G be of size N 3 and the blocks of size n 3 . Assume that d = N/n is an integer. It is easy to see that the initial domain decomposition consists of d 3 blocks. Shifting the domain decomposition introduces 3d 2 + 3d + 1 additional blocks. Example: a 64 3 grid is initially decomposed into 64 blocks of size 16 <ref type="bibr" target="#b2">3</ref> , i.e., d = 4. Shifting the decomposition creates 61 additional (smaller) blocks, making for a total of 125 blocks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">EVALUATION AND DISCUSSION</head><p>In the following, we evaluate and discuss our method. We start with an evaluation of our main contribution, followed by a demonstration of the whole method using a simple data set, which serves to highlight the characteristics of the method. We end the section with a discussion of the role of the monotonicity graph.</p><p>Unless stated otherwise, all results have been computed on a laptop with an Intel Xeon E31225 (3.1GHz) CPU and 16 GB RAM.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Evaluation of the Domain Decomposition</head><p>In the following, we evaluate the decomposed optimization scheme regarding its performance and its convergence to the global optimization.  <ref type="table">Table 2</ref>. Measured performances of the global and the domain decomposition approach for 3D data. The latter can benefit even further from parallel execution. Computation times measured using a single thread.</p><p>Convergence. <ref type="figure">Figure 7</ref> compares the results of both schemes against each other for the spherical salt &amp; pepper data set (compare to <ref type="figure" target="#fig_0">Figure 3</ref>). First, it has to be noted that the strong salt &amp; pepper distortions could successfully be removed. Most importantly, the global scheme and the decomposition scheme yield visually identical results, which is supported by the very low normalized L 2 distance. We observed the same convergence for other data sets, too.</p><p>Note how the two different computation schemes start their iterations with very different energies. This is due to the approximation s a that we require for the decomposed optimization. Here, we used the version where we minimize the data energy E D as described earlier. While s a fulfills all monotonicity constraints, it is not smooth, which leads to the very high energy in the first decomposed iteration. However, the global and decomposed optimizations converged to visually the same result with the second iteration. We observed similar behavior in all our experiments. The convergence evaluation for the 2D vorticity data set can be found in the supplemental material.</p><p>Performance. <ref type="figure">Figures 8a-b</ref> reveal why directly applying the method of <ref type="bibr" target="#b14">[15]</ref> to 3D data sets is impracticable. Here we see for the global optimization that the memory consumption increases exponentially with the number of free vertices, and the computation time increases quadratically (note that both plots have log-log axes). For these plots, we computed a 64 3 data set globally: one iteration computes for 6.5 hours requiring almost 10 GB of main memory.</p><p>The decomposition approach is significantly faster and more memory efficient. One iteration for the same 64 3 data set computes for 6 minutes with a block size of 16 3 on 6 threads, thereby requiring 3 GB of main (c) Parallel performance on a shared-memory machine for a 64 3 data set with blocks of size 16 3 . <ref type="figure">Figure 8</ref>. Memory consumption and computation times for different block sizes. The rightmost plot reveals that the parallel algorithm can be memory-bound on shared-memory machines (indicated by the dashed line).</p><p>memory. This includes already the four required shifts of the domain decomposition.</p><p>Interestingly, we found that the performance of the used optimization package MOSEK does not noticeably depend on the content of the data set, but only on its size. <ref type="bibr" target="#b5">6</ref> This is good news, since it allows us to predict the performance for a given data set and block size rather accurately from the measurements shown in <ref type="figure">Figures 8a-b</ref>. Assume we want to compute the decomposed optimization for a 64 3 data set with a block size of 16 <ref type="bibr" target="#b2">3</ref> . As discussed above, this makes 439 blocks including all shifts (smaller blocks will appear then, but we use the higher estimate here to be on the safe side). Each 16 3 block computes for 5 seconds on our hardware. This makes for a runtime prediction of 2195 seconds, which matches the measured time of 2110 seconds quite nicely (see <ref type="table">Table 2</ref> and <ref type="figure">Figure 8c</ref>). Note that these numbers are for computing on a single thread. How this scales to several threads is discussed below.</p><p>Side-by-side overviews of measured performance figures for the global and decomposed optimization are given in <ref type="table" target="#tab_2">Tables 1-2</ref> for 2D/3D data sets. Note that the decomposed optimization provides significant speedups over the global approach for 3D data sets and large 2D data sets. Furthermore, we can speedup the decomposed optimization even further by optimizing the blocks in parallel.</p><p>Scalability. Since we completely decoupled the blocks in our domain decomposition, the decomposed optimization can scale linearly with the number of parallel threads or processes. Since there is no need for communication between processes, it can easily run on clusters, where inter-process communication is usually difficult to implement, and achieve optimal scalability.</p><p>An interesting question, however, is how it scales on a sharedmemory machine where parallel threads compete for access to the memory, which is usually the case on standard workstations. <ref type="figure">Figure  8c</ref> shows the scaling behavior on a machine with 96 GB main memory and 2 Intel XEON X5650 (2.66 GHz) with 6 cores each. As the plot indicates, the memory is fast enough to answer to two threads (speedup: 1.9), but we start to become memory-bound around 4-6 threads preventing an optimal usage of the available cores.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Data Weight, Single Cancellation, and Noise</head><p>In the following, we use simple experiments with the data set from <ref type="figure" target="#fig_11">Figure 9a</ref> to evaluate our method and provide an intuition about its specific characteristics.</p><p>The first experiment answers the question of what happens if all extrema of the scalar field are selected. We extracted the extrema from <ref type="figure" target="#fig_11">Figure 9a</ref>, kept all of them, and ran the numerical reconstruction. <ref type="figure" target="#fig_11">Figure 9c</ref> shows the results for two different data weights. As expected, the topology of the smoothed versions coincides with the original data: the extrema are at the same location and have the same value, and there are no additional extrema. This scenario nicely shows the influence of the data weight w D from Equation <ref type="formula">4</ref>: lower values emphasize the Laplacian energy E L , higher values bring out the data term E D .</p><p>The second experiment in <ref type="figure" target="#fig_11">Figure 9b</ref> shows what happens when we remove a single extremum. Note the targeted change in the middle of the domain where a single minimum has been removed. In all other aspects the data coincides with the right image of <ref type="figure" target="#fig_11">Figure 9c</ref>, since we use the same data weight. We can see from this that surgical operations are possible with our method: removing an extremum only has an effect in its immediate neighborhood, i.e., its Morse cell. Other parts of the domain are unaffected, since the extrema and the monotonicity graph are still the same there.</p><p>The third experiment demonstrates the utility of our approach when denoising data. We added 10% white noise to the data set, which created over 2000 additional minima and maxima. This is shown in the left image of <ref type="figure" target="#fig_10">Figure 9d</ref>. Persistence is a powerful topological tool to assess the importance of critical points. The critical points with the largest persistence are shown as large spheres. We instructed our method to keep only those while smoothing the data. The result is shown in the right image of <ref type="figure" target="#fig_10">Figure 9d</ref>. How to work with persistencebased denoising will be explained in more detail in Section 6 using a real data set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Comparison of Different Monotonicity Graphs</head><p>We presented two classes of methods for extracting and filtering extrema in Sections 3.1 and 3.2. They have different properties regarding their implementational effort and their computation time, as discussed previously. The convergence times for the subsequent reconstruction is shown in <ref type="table">Table 3</ref>. Summarized, the approaches without Morse theory (Section 3.1) are easier to implement, but they create a data-unaware monotonicity graph that generally leads to more iterations until convergence. Approaches based on Morse theory (Section 3.2) are more involved, but the subsequent optimization benefits from the data-aware monotonicity graph by generally converging with fewer iterations.</p><p>The most important observation is that the final reconstruction results are very similar as proven by their normalized L 2 distances, see the rightmost column in <ref type="table">Table 3</ref>. This agrees with the results of a larger experiment that we provide in the supplemental material. Our findings and our experience suggest that the choice for a specific monotonicity graph construction method can be guided by implementational effort and computation time -the iterative convexification seems to be able to make up for unfavorable start conditions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Monoton.</head><p>Energy  <ref type="table">Table 3</ref>. Results for running the optimization using different monotonicity graphs, where "harmonic" refers to the solution of the Poisson problem (1), and "topology" to the approach using discrete Morse theory.    </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">APPLICATIONS</head><p>Hurricane Isabel. Topological structures are often filtered by their persistence <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b24">25]</ref>. Loosely speaking, the persistence P measures the prominence of a critical point in the data. The plot in <ref type="figure" target="#fig_9">Figure 10d</ref> shows this for a slice of the temperature of the Hurricane Isabel data set. The number of critical points drops drastically around P = 10 0 : only few critical points have higher persistence values while most of them have lower persistence. Using our numerical reconstruction and persistence-based filtering, we can create a hierarchy of increasingly smoother scalar fields. Here, we show this using two persistence thresh-olds in <ref type="figure" target="#fig_9">Figures 10b-c</ref>. Compare this to the original data in <ref type="figure" target="#fig_9">Figure 10a</ref>.</p><p>Another interesting observation in <ref type="figure" target="#fig_9">Figure 10</ref> can be made regarding the white isolines. They represent the five different isovalues {0, 2, 4, 6, 10}. They are highly distorted for the original, unfiltered data. This is due to the large amount of small-scale extrema. In fact, this data set contains 14492 extrema. The denoised data in <ref type="figure" target="#fig_9">Figures 10b-c</ref> contains only the most persistent 279 and 12 extrema, respectively. It is known (e.g., <ref type="bibr" target="#b3">[4]</ref>) that the number of extrema influences the number of connected components of an isoline visualization. Hence, the filtered data sets show less cluttered isolines. Note also that our denoising method preserves the value range in the data set, which makes the isolines directly comparable. Most importantly, the maximum temperature in all three versions of the data set is the same: 13.1 • C.</p><p>Teaser. We use persistence-based filtering also in <ref type="figure">Figure 1</ref> to identify noise-induced minima and maxima in a 3D data set and remove them using our method. The volume rendering of the input scalar field <ref type="figure">(Figure 1a</ref>) reveals the high level of noise, which creates a large number of local minima and maxima <ref type="figure">(Figure 1b)</ref>. The majority of these extrema have a low feature strength, i.e., their persistence is rather low. In <ref type="figure">Figure  1c</ref>, we only keep extrema with a persistence of at least 85% of the data range (9 maxima and 19 minima). The result of our reconstruction is a smooth and topologically clean scalar field <ref type="figure" target="#fig_10">(Figure 1d</ref>). <ref type="figure" target="#fig_7">Figures 11-12</ref> contains very thin blood vessels obstructed by a high noise level. Smoothing such a challenging data set with a simple Gaussian blur inadvertently interrupts the blood vessels <ref type="figure" target="#fig_7">(Figure 12</ref>), or better to say, an isosurface showing a blood vessel disintegrates into several connected components when smoothing without topological control.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Aneurism. The aneurism data set in</head><p>Our method provides such control as shown in <ref type="figure">Figure 11</ref>. In this example, we zoomed on one of the thinner vessels. <ref type="figure">Figure 11b</ref> shows the large number of local extrema. We know from topology that every local minimum gives rise to a component of an isosurface. This guides our strategy for filtering this data set: we keep one sole minimum which is connected to the vessel <ref type="figure">(Figure 11c</ref>). This enforces a singlecomponent isosurface as shown in <ref type="figure" target="#fig_10">Figure 11d</ref>. Note how the general appearance of the vessel is preserved. This shows the useful ability of our method to enforce topological constraints while denoising: the noise has been removed and the thin vessel structure has been preserved.</p><p>Lymphatic Capillary Network. To demonstrate the potential of our method for the task of image segmentation, we consider a biological data set. <ref type="figure" target="#fig_0">Figure 13a</ref> depicts a 2D image of a lymphatic capillary network. Here, biologists are interested in segmenting the tubular structures of the lymphatic vessels to reveal their patterns and connectivity.  <ref type="figure">Figure 11</ref>. Aneurism data set. Denoising with explicit control over the topology is useful in scenarios like this, where a thin blood vessel structure can be preserved including its delicate appearance, while the noise has been removed.  Unfortunately, the imaging process introduces noise and other artifacts causing discontinuities in the data. This can be observed in the lower left corner where a vessel is interrupted due to poor acquisition.</p><p>Naively thresholding the original raw data fails to connect this region of the vessel and introduces many speckles of noise throughout the segmentation (see <ref type="figure" target="#fig_0">Figure 13b</ref>). Applying simple Gaussian smoothing before thresholding removes most of the speckles <ref type="figure" target="#fig_0">(Figure 13c</ref>), yet the lymphatic vessel remains interrupted. This is because smoothing is only a local operation and cannot enforce such topological constraints.</p><p>In contrast, our method allows the biologist to select connected components of the background (minima) and foreground (maxima). The boundary of the domain is set to the global minimum to reduce the number of minima that have to be placed. After applying our method, a threshold segmentation is forced to have the desired connectivity. <ref type="figure" target="#fig_0">Figure 13d</ref> shows this. Note that also all speckles are removed. This shows that topological denoising has utility beyond mere smoothing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">CONCLUSIONS AND FUTURE WORK</head><p>We presented a topological denoising method that has significantly faster computation times and lower memory consumption than previous methods due to our novel domain decomposition approach. For the first time, this class of algorithms achieves practicable computation  <ref type="figure" target="#fig_0">Figure 13</ref>. Segmentation of a lymphatic capillary network with topological control. Our method denoises the data and enforces topological constraints such that a subsequent threshold segmentation reveals the connectivity of the network as desired by the biologists.</p><p>times for 3D scalar fields and large 2D data sets. Furthermore, we proposed an iterative scheme to drastically lower the energy of the solution by repeated convexification of the non-linear, non-convex feasible region. Regarding the extraction and filtering of extrema, we proposed a simple coupling between topological algorithms and the numerical reconstruction as well as a topological simplification scheme that allows user intervention. This leads to a versatile and powerful denoising method which we demonstrated using several examples. Note that our contributions, in particular the domain decomposition and the iterative convexification, do not depend on a particular choice of the energy. In fact, our chosen energy (4) can be replaced by other formulations. This could be of interest in order to accommodate application-specific requirements. Our proposed method can also be extended to unstructured grids. As discussed in Section 3.2.1, the optimization requires an auxiliary grid, in which each of its vertices corresponds to a cell of the cell complex. Since this is difficult to achieve when we coarsen an unstructured grid, an explicit refinement would be necessary introducing a significant memory overhead.</p><p>Another interesting topic for future research is whether a domain decomposition approach can be developed that has a "natural" decoupling of its blocks. In particular, one could consider a topology-based decomposition of the domain, i.e., into Morse cells or Morse-Smale cells. However, no guarantees can be made about the size of those cells. One may end up with highly unbalanced block sizes, which can lead to poor performance. Also, it may be difficult to shift such a decomposition such that all vertices are free at least once.</p><p>A multi-resolution approach to the numerical optimization could lower the computation times even further. However, the main challenge is to represent all selected extrema at all resolution levels.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 3 .</head><label>3</label><figDesc>Explanatory data sets. (left) 2D vorticity data set from<ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b23">24]</ref> shown as terrain. (right) 3D spherical function distorted by very strong salt &amp; pepper noise.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>I: The selected extrema appear as extrema in s of the same type. II: s has no other extrema. III: s interpolates the original scalar values at the selected extrema. IV: s approximates the original scalar field at all other vertices. V: s minimizes a smoothness energy.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>(a) "Ideal" optimization problem (5). (b) Convex subregion defined by (12). (c) Second iteration. (d) Third iteration.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 .</head><label>4</label><figDesc>Illustration of the non-linear optimization problem (5) and our scheme to iteratively decrease the energy of the solution by repeated convexification of the feasible region using the linear constraints<ref type="bibr" target="#b11">(12)</ref>.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>(a) Initial decomposition into blocks of maximal size n × n. The values at the inner boundaries are fixed.(b) Shift of the decomposition by n/3, which frees most formerly fixed vertices, except for the few highlighted.(c) After a final shift of the decomposition by n/3, all vertices have been free at least once.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 6 .</head><label>6</label><figDesc>Scheme of the repeated domain decomposition for a 2D scalar field. In 3D, we need four decompositions shifted by n/4.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>2 (</head><label>2</label><figDesc>(a) The converged results of the global (left) and the decomposed (right) optimization are visually identical. c) Normalized L 2 distance between the converged result s * of the global optimization and different iterations s i of the decomposed optimization.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head></head><label></label><figDesc>Result for P = 0.4. 279 extrema. (c) Result for P = 1.5. 12 extrema. (d) Critical points over persistence P. The two vertical lines give the persistence values for (b) and (c).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 10 .</head><label>10</label><figDesc>Temperature in the Hurricane Isabel data set (slice z = 20). Using persistence-based filtering, we create a hierarchy of scalar fields: with increasing persistence P, our method creates increasingly smoother versions of the data. Note how the isolines (white) become less cluttered.(a) Original Data. (b) One minimum removed. w D = 10. (c) All extrema are kept. The data weight differs. Left: w D = 1. Right: w D = 10.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>( d )</head><label>d</label><figDesc>Over 2000 noise-induced extrema are filtered using persistence. w D = 10.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Figure 9 .</head><label>9</label><figDesc>Three experiments reveal the characteristics of our method.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head></head><label></label><figDesc>(a) Overview with zoom-in region. (b) All minima and maxima. (c) One sole minimum selected to remain after the optimization. (d) The filtered data set reveals the thin vessel without obstructing noise.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head></head><label></label><figDesc>(a) Subtle Gaussian smoothing cannot remove all noise. (b) Aggressive Gaussian smoothing interrupts the blood vessel.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>Figure 12 .</head><label>12</label><figDesc>Aneurism data set smoothed using a Gaussian filter. Compare to our method inFigure 11.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head></head><label></label><figDesc>(a) Original data with selected extrema. (b) Threshold segmentation of original. (c) Threshold segmentation after applying a Gaussian filter. (d) Threshold segmentation after applying our method.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>•</head><label></label><figDesc>David Günther is with Institut Mines-Télécom, Télécom ParisTech, CNRS LTCI, Paris, France. E-mail: gunther@telecom-paristech.fr. • Alec Jacobson is with Columbia University, New York, USA. E-mail: jacobson@cs.columbia.edu. • Jan Reininghaus is with IST Austria, Vienna, Austria. E-mail: jan.reininghaus@ist.ac.at. • Olga Sorkine-Hornung is with ETH Zürich, Zürich, Switzerland. E-mail: sorkine@inf.ethz.ch.</figDesc><table /><note>• Tino Weinkauf and Hans-Peter Seidel are with Max Planck Institute for Informatics, Saarbrücken, Germany. E-mail: {weinkauf,hpseidel}@mpi-inf.mpg.de.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 1 .</head><label>1</label><figDesc>Measured performances of the global and the domain decomposition approach for 2D data. The latter can benefit even further from parallel execution. Computation times measured using a single thread.</figDesc><table><row><cell></cell><cell>Block</cell><cell cols="2">256 2</cell><cell></cell><cell>512 2</cell><cell cols="2">1024 2</cell></row><row><cell></cell><cell cols="7">size GB minutes GB minutes GB minutes</cell></row><row><cell>global</cell><cell></cell><cell>0.5</cell><cell>1.5</cell><cell>1.7</cell><cell>11.9</cell><cell>7.4</cell><cell>120</cell></row><row><cell>domain</cell><cell cols="2">64 2 0.5</cell><cell>1.9</cell><cell>0.5</cell><cell>6.6</cell><cell>0.5</cell><cell>24.3</cell></row><row><cell>decomposition</cell><cell cols="2">128 2 0.5</cell><cell>3.3</cell><cell>0.5</cell><cell>9.9</cell><cell>0.5</cell><cell>33.9</cell></row><row><cell></cell><cell></cell><cell>Block</cell><cell></cell><cell>64 3</cell><cell></cell><cell>128 3</cell></row><row><cell></cell><cell></cell><cell cols="5">size GB minutes GB minutes</cell></row><row><cell cols="2">global</cell><cell></cell><cell>10</cell><cell>390</cell><cell>n/a</cell><cell>n/a</cell></row><row><cell cols="2">domain decomposition</cell><cell cols="2">8 3 16 3 0.5 0.4 24 3 0.6</cell><cell>36 35 168</cell><cell>0.4 0.5 0.6</cell><cell>251 223 921</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">Note that a trilinearly interpolated function attains its minima and maxima always at the vertices of the grid. Hence, it is reasonable to define the extrema as a subset of the vertices.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">DIPHA: http://dipha.googlecode.com/</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">Note that this procedure neglects extrema whose Morse cell is smaller than a 1-ring in the input grid. This is not an issue in our target applications, since we want to remove small features anyway. An alternative is to double the resolution of the input grid and supersample the data first.<ref type="bibr" target="#b3">4</ref> This concept is similar to an integral curve in a smooth gradient field.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5">Note that the depictions inFigure 4are artistic interpretations. In general, the feasible region is nearly impossible to chart. It is generally not convex and perhaps even high-genus.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6">The performance of MOSEK is mainly determined by the quadratic coefficient matrix of (4). This matrix does not depend on the data itself, but just on the vertex connectivity in the grid, which is the same for every uniform grid.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS</head><p>This research is supported and partially funded by the RTRA Digiteo un-TopoVis project (2012-063D), the TOPOSYS project (FP7-ICT-318493-STREP), the ERC grant iModel (StG-2012-306877), the SNF award (200021_137879), the Intel Doctoral Fellowship, and MPC-VCC. We thank Michael Sixt and Kari Vaahtomeri for the biological data set.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Clear and compress: Computing persistent homology in chunks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Bauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kerber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Reininghaus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Topological Methods in Data Analysis and Visualization III</title>
		<imprint>
			<publisher>Springer International Publishing</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="103" to="117" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A topological hierarchy for functions on triangulated surfaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P.-T</forename><surname>Bremer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Edelsbrunner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Hamann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Pascucci</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TVCG</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="385" to="396" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A review of image denoising algorithms, with a new one. Multiscale Modeling and Simulation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Buades</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Coll</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Morel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM interdisciplinary journal</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="490" to="530" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Path seeds and flexible isosurfaces -using topology for exploratory visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Carr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Snoeyink</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Data Visualization 2003. Proc. VisSym 03</title>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="49" to="58" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Enforcing topological constraints in random field image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Freedman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">H</forename><surname>Lampert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="2089" to="2096" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Vector field editing and periodic orbit extraction using Morse decomposition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Mischaikow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">S</forename><surname>Laramee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Pilarczyk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TVCG</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="769" to="785" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Topological persistence and simplification. Discrete and Computational Geometry</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Edelsbrunner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Letscher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zomorodian</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="511" to="533" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Morse theory for cell-complexes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Forman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Mathematics</title>
		<imprint>
			<biblScope unit="volume">134</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">3</biblScope>
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Controlled-topology filtering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">I</forename><surname>Gingold</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Zorin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ACM SPM</title>
		<meeting>ACM SPM</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="53" to="61" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Extraction of dominant extremal structures in volumetric data using separatrix persistence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Günther</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H.-P</forename><surname>Seidel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Weinkauf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics Forum</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="2554" to="2566" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Topological analysis of discrete scalar data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Günther</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
		<respStmt>
			<orgName>Saarland University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">PhD thesis</note>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Efficient computation of 3D Morse-Smale complexes and persistent homology using discrete Morse theory. The Visual Computer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Günther</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Reininghaus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wagner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Hotz</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="959" to="969" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Combinatorial construction of Morse-Smale complexes for data analysis and visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gyulassy</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
		<respStmt>
			<orgName>University of California, Davis</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">PhD thesis</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Bounded biharmonic weights for real-time deformation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Jacobson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Baran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Popović</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Sorkine</surname></persName>
		</author>
		<idno>78:1-78:8</idno>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Graphics (ACM SIGGRAPH)</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">4</biblScope>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Smooth shape-aware functions with controlled extrema</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Jacobson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Weinkauf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Sorkine</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. SGP)</title>
		<meeting>SGP)</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="1577" to="1586" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<ptr target="http://www.mosek.com/.4" />
		<title level="m">The MOSEK optimization software</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Fair Morse functions for extracting the topological structure of a surface mesh</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Ni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Garland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">C</forename><surname>Hart</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Graphics (Proc. ACM SIGGRAPH)</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="613" to="622" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Numerical Optimization, Second Edition. Springer Series in Operations Research</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Nocedal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wright</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006" />
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">A signal processing approach to fair surface design</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Taubin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ACM SIGGRAPH</title>
		<meeting>ACM SIGGRAPH</meeting>
		<imprint>
			<date type="published" when="1995" />
			<biblScope unit="page" from="351" to="358" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Designing 2D vector fields of arbitrary topology</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Theisel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics Forum</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="595" to="604" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Generalized topological simplification of scalar fields on surfaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tierny</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Pascucci</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Transactions on Visualization and Computer Graphics (Proc. VisWeek)</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="2005" to="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Bilateral filtering for gray and color images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Tomasi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Manduchi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICCV</title>
		<meeting>ICCV</meeting>
		<imprint>
			<date type="published" when="1998" />
			<biblScope unit="page" from="839" to="846" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Continuous topology simplification of planar vector fields</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Tricoche</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Scheuermann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Hagen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Visualization</title>
		<meeting>Visualization</meeting>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="page" from="159" to="166" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Topology-based smoothing of 2D scalar fields with C 1 -continuity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Weinkauf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Gingold</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Sorkine</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Graphics Forum (Proc. EuroVis)</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="1221" to="1230" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Separatrix Persistence: Extraction of salient edges on surfaces using topological methods</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Weinkauf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Günther</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Graphics Forum (Proc. SGP &apos;09)</title>
		<imprint>
			<date type="published" when="2009-07" />
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="1519" to="1528" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Topological construction and visualization of higher order 3D vector fields</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Weinkauf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Theisel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H.-C</forename><surname>Hege</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H.-P</forename><surname>Seidel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Graphics Forum (Proc. Eurographics</title>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="469" to="478" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
