<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/pisenberg/grobid/grobid-0.6.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Sparse PDF Volumes for Consistent Multi-Resolution Volume Rendering</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronell</forename><surname>Sicat</surname></persName>
							<email>ronell.sicat@kaust.edu</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jens</forename><surname>Krüger</surname></persName>
							<email>jens.krueger@uni-due.de</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Torsten</forename><surname>Möller</surname></persName>
							<email>torsten.moeller@univie.ac.at</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Markus</forename><surname>Hadwiger</surname></persName>
							<email>markus.hadwiger@kaust.edu</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">•</forename><surname>Torsten Möller</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">King Abdullah University of Science and Technology (KAUST)</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">University of Duisburg-Essen</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="institution">University of Vienna</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Sparse PDF Volumes for Consistent Multi-Resolution Volume Rendering</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="DOI">10.1109/TVCG.2014.2346324</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2021-02-19T19:34+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Multi-resolution representations</term>
					<term>sparse approximation</term>
					<term>pursuit algorithms</term>
					<term>large-scale volume rendering</term>
				</keywords>
			</textClass>
			<abstract>
				<p>Sparse pdf volumes store probability density functions (pdfs) of voxel neighborhoods in multi-resolution volumes. This enables consistent multi-resolution volume rendering, i.e., equivalent visualizations independent of resolution level. We compare (a) the original 512 3 Shepp-Logan volume against (b,c,d,e) a down-sampled 128 3 volume using (b) standard low-pass filtering and down-sampling (1 byte/voxel), (c) one Gaussian per voxel (3 bytes/voxel), (d) our sparse pdf volume (4 bytes/voxel), and (e) a full histogram (256 bins) per voxel as &quot;ground truth&quot; (512 bytes/voxel). The PSNR between the pdfs encoded in (d) vs. (e) is 44 dB.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>The resolution of volume data has increased significantly over the last decade <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b25">26]</ref>, due to high-resolution data acquisition modalities such as modern CT scanners <ref type="bibr" target="#b24">[25]</ref> or electron microscopes <ref type="bibr" target="#b15">[16]</ref>, and large-scale simulations <ref type="bibr" target="#b4">[5]</ref>. However, although the resolution of display hardware has also increased considerably, the gap between the resolution of large-scale volume data and practically feasible output resolutions for visualization is often significant. The most common approach to alleviating this problem is the use of multi-resolution techniques, i.e., the representation of volume data with multiple lowpass filtered and successively down-sampled resolution levels. Multiresolution volume rendering using data structures such as octrees or 3D mipmaps considerably helps with (1) avoiding aliasing artifacts due to under-sampling, and (2) speeding up the visualization by decreasing the amount of data that needs to be accessed for rendering.</p><p>However, applying a low-pass filter and down-sampling the original volume changes it by replacing the original data points by fewer data points that represent weighted averages of the original data. <ref type="figure" target="#fig_4">Figs. 1 (a)</ref> and (b) illustrate this problem by showing the visual differences and the different histograms of data values between (a) the original volume, and (b) the volume down-sampled by a factor of four in each dimension. These differences can be explained by understanding that, in (b), the transfer function is applied to data with a different distribu-tion, i.e., the histogram shown on top. This problem has been observed before <ref type="bibr" target="#b35">[36,</ref><ref type="bibr" target="#b39">40]</ref>, but it is difficult to solve without either a significant increase in memory footprint or only moderate gains in quality.</p><p>One often overlooked but important consequence of working with low-pass filtered data is that the application of non-linear operators, such as a transfer function, is incompatible and yields visualization results that are inconsistent between resolution levels. From a user perspective, this has the highly undesirable consequence that the visual result of an interactive transfer function specification depends on which resolution level the user was looking at when designing the transfer function. Together with the fact that a transfer function for high-resolution volume data can often either only be designed for a zoomed-out, significantly down-sampled view of the whole volume, or a zoomed-in, but partial view, this issue is becoming more and more problematic when working with large-scale volume data. In this paper, we refer to this phenomenon as inconsistency artifacts in multiresolution volume rendering. In order to avoid erroneous data analysis based on transfer functions that were specified for down-sampled data, it is important to avoid or at least reduce these inconsistency artifacts.</p><p>To tackle these challenges, we present the following contributions for consistent multi-resolution volume rendering based on probability density functions (pdfs) of voxel neighborhoods (footprints):</p><p>(1) A compact, sparse representation of pdfs. The crucial insight is that instead of storing individual 1D pdfs, we use 4D pdfs in the joint space × range domain of the volume. This enables a quality similar to storing full histograms, but requires considerably less storage.</p><p>(2) The sparse pdf volume data structure that is optimized for efficient parallel volume classification and rendering on GPUs. Our approach uses only simple and fast convolutions at run time.</p><p>(3) A novel approach for computing a sparse 4D function (pdf) approximation in a multi-resolution hierarchy via a greedy pursuit algorithm for the iterative simplification of 4D Gaussian mixtures.</p><p>(4) An out-of-core framework for efficient parallel computation of sparse pdf volumes for large-scale volume data. We map the 3D input volume (brick by brick) to a pdf in the 4D joint space × range domain (Sec. 4.1). This pdf is represented as a mixture of 4D Gaussians, which is then iteratively simplified to compute a multi-resolution hierarchy of sparse 4D pdfs (Sec. <ref type="bibr">4.2)</ref>. Run time (right side): The sparse pdf volume data structure storing the sparse 4D pdfs allows dynamically applying transfer functions through simple look-ups in pre-computed 1D tables, followed by 3D convolution (Sec. 4.3), for volume rendering.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK</head><p>Multi-resolution volume rendering. The most common approach for handling large data in volume visualization is to use multi-resolution techniques <ref type="bibr" target="#b37">[38]</ref>, usually utilizing hierarchical data structures such as octrees <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b36">37]</ref> or 3D mipmaps <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b20">21]</ref>. These representations store iteratively pre-filtered and down-sampled versions of the original volume at discrete resolution levels. Furthermore, several methods use multiple levels-of-detail for a single volume rendering, i.e., they allow for mixed-resolution rendering <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b36">37]</ref>.</p><p>However, all of these approaches can suffer from inconsistency artifacts as described above. In mixed-resolution volume rendering, these problems additionally manifest as artifacts in the transition regions between adjacent regions that are rendered with different resolutions. In this paper, our main focus is achieving consistent results when switching between resolution levels. However, our approach would also further reduce transition artifacts in mixed-resolution rendering.</p><p>Volume compression. Our goal of using a sparse representation is not reducing the size of the volume itself as in compression techniques, but to represent more information, i.e., probability density functions in a 4D space, albeit in a compact way. Hence, we are not competing with 3D volume compression techniques, e.g., based on sparse coding <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b38">39]</ref>, tensor approximations <ref type="bibr" target="#b33">[34]</ref>, or compressing floating point values <ref type="bibr" target="#b22">[23]</ref>. While compression has been applied to pdfs before <ref type="bibr" target="#b11">[12]</ref>, we view our approach more as a sparse representation that is optimized for rendering rather than as a general compression technique.</p><p>Distribution-based multi-resolution volume rendering. Younesy et al. <ref type="bibr" target="#b39">[40]</ref> were the first to show that inconsistency artifacts in multiresolution volume rendering can be reduced by applying the transfer function to histograms of voxel neighborhoods. However, storing full histograms, e.g., with 256 bins per voxel, incurs an impractical storage overhead. Younesy et al. then only stored the mean and standard deviation per voxel, yielding only moderate quality improvements. Histograms can also be approximated via a Gaussian Mixture Model with N components, storing N means, standard deviations, and weights per voxel <ref type="bibr" target="#b23">[24]</ref>. However, the associated storage overhead can be impractical, and reconstruction during rendering is computationally expensive.</p><p>The hixel representation <ref type="bibr" target="#b35">[36]</ref> represents the uncertainty in largescale data sets via quantized histograms of voxel neighborhoods.</p><p>Hadwiger et al. <ref type="bibr" target="#b16">[17]</ref> sparsely encoded pixel neighborhood distributions in their sparse pdf maps data structure to accurately apply nonlinear image operations to multi-resolution gigapixel images. Instead of approximating distributions individually, they fitted 3D Gaussians in the combined space × range domain of the image in order to exploit coherence in this 3D domain. However, their approach required long pre-computation times of around two minutes per megapixel, using iterative Matching Pursuit <ref type="bibr" target="#b27">[28]</ref> to fit Gaussians to sampled 3D distributions. In the present paper, we completely avoid a sampled interme-diate representation and work completely in continuous 4D space.</p><p>Our approach builds on the work by Younesy et al. <ref type="bibr" target="#b39">[40]</ref> and Hadwiger et al. <ref type="bibr" target="#b16">[17]</ref>. We use voxel neighborhood distributions for consistent multi-resolution volume rendering and work in a higherdimensional domain. Our sparse pdf volume representation is able to capture even multi-modal distributions without incurring impractical memory requirements, and enables fast reconstruction and classification via simple and fast convolutions at run time. Pre-processing is made scalable via iterative simplification of 4D Gaussian mixtures.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">BASICS</head><p>We first describe the challenge of consistent multi-resolution volume rendering in more detail, and define the basic model that we are using.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Consistent multi-resolution volume rendering</head><p>Multi-resolution volumes comprise a hierarchy of successively coarser resolutions computed from the original volume. This results in a discrete set of resolution levels, where we will denote the original volume as level 0 . Resolution reduction is performed by first applying a low-pass filter (also called pre-filter <ref type="bibr" target="#b18">[19]</ref>) to level m , and then downsampling to obtain level m+1 . It is common to reduce the resolution by a factor of two in each dimension from m to m+1 , but other factors <ref type="bibr" target="#b29">[30]</ref> or anisotropic reductions are also possible <ref type="bibr" target="#b15">[16]</ref>. In this work, we will use a down-sampling factor of two. However, this is not an inherent restriction of our method, and other factors could also be used.</p><p>Applying a low-pass filter before down-sampling is crucial for avoiding aliasing artifacts. However, this filtering process substitutes each voxel by a weighted average of its neighborhood, where the weights depend on the filter kernel used. When one computes the histogram of a given resolution level m (e.g., <ref type="figure" target="#fig_4">Fig. 1 (b)</ref>), it is easy to see that this process changes the distribution of values in the volume. More specifically, each voxel in level m corresponds to the footprint <ref type="bibr" target="#b14">[15]</ref> of this voxel in level 0 , with the size of these footprints growing from level to level. An accurate representation of a given voxel would be the distribution of values in the voxel's footprint in the original volume. Nevertheless, standard multi-resolution approaches substitute this distribution by a single value, for example the mean of the distribution when a box filter is used for low-pass filtering.</p><p>An accurate representation of voxel footprint distributions would therefore provide the conceptual basis for consistent multi-resolution volume rendering. However, the first major obstacle to using this idea in practice is the storage overhead associated with each distribution. For quantized 8-bit volume data, each histogram can be stored as a 256-bin histogram, which is already impractical. Naturally, this problem becomes more acute with 12-or 16-bit data. A second major hurdle in practice is applying a transfer function to the distribution, which for an n-bin histogram also requires O(n) operations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Basic model</head><p>We formalize the above ideas by treating each voxel at position p in a multi-resolution volume as the realization of a random variable X p , with an associated probability density function f p (r). The argument r corresponds to the range of the volume, and for intensity (singlechannel) volumes, f p (r) is a 1D function of r. Likewise, a 1D transfer function t(r) is defined over the same r, i.e., the domain of the transfer function is the range of the volume. The function t(r) is then applied to the voxel X p by computing the expectation of t applied to X p :</p><formula xml:id="formula_0">E t(X p ) = t(r) f p (r)dr.<label>(1)</label></formula><p>We observe that from this viewpoint, standard multi-resolution volume rendering could be "emulated" by simply first computing the expectation (mean) of X p as E X p , and then applying t(r) to the obtained mean. That is, instead of computing E t(X p ) , we would first compute E X p , and then compute t(E X p ). This is in essence what is done in standard multi-resolution volume rendering, where the E X p are pre-computed and stored. In contrast, however, our goal is to store the f p (r) instead. Then Eq. 1 allows applying the transfer function t(r) directly to the complete distribution f p (r) instead of to just its mean. The big practical challenges now are (1) how all f p (r) can be stored compactly, and (2) how Eq. 1 can be evaluated efficiently. <ref type="figure" target="#fig_0">Fig. 2</ref> depicts an overview of our method. The most crucial property of our approach is that it works in the 4D joint space × range domain of the 3D spatial volume domain together with its 1D intensity range. We define this 4D domain in Sec. 4.1. We then exploit the fact that even though volume data are usually not sparse in 3D, they are sparse with respect to a certain basis in 4D, even in a multi-resolution hierarchy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">METHOD OVERVIEW</head><p>A sparse pdf volume then comprises a hierarchy of resolution levels m of progressively smoother functions in 4D, where each m is represented by a mixture of 4D Gaussians. Crucially, the number of Gaussians in each level m is proportional to its spatial resolution. We give an overview of this hierarchy in Sec. 4.2, and the details in Sec. 5. Sec. 6 describes the corresponding data structure for efficient storage, while at the same time facilitating fast parallel access on GPUs. Sec. 7 describes classification (via transfer functions) and volume rendering.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Joint 4D space × range domain</head><p>Usually, volume data comprise a three-dimensional scalar function V(x, y, z), whose domain is a subset of 3D space, U ⊂ R 3 , and whose range (or co-domain) is the 1D intensity axis R:</p><formula xml:id="formula_1">V(x, y, z) : U ⊂ R 3 → R.<label>(2)</label></formula><p>We now join the domain and co-domain of V via the Cartesian product to obtain the 4D joint space × range domain of a new functionV:</p><formula xml:id="formula_2">V(x, y, z, r) :Û ⊂ R 3 × R → R.<label>(3)</label></formula><p>We defineV(x, y, z, r) as the "joint probability" of spatial locations (x, y, z) occurring together with a specific intensity value r, via:</p><formula xml:id="formula_3">V(x, y, z, r) := δ if ∃ V(x, y, z) with V(x, y, z) = r, 0 otherwise,<label>(4)</label></formula><p>where δ is the Dirac delta <ref type="bibr" target="#b0">1</ref> . Instead of assuming exactly occurring values, we now take the viewpoint of kernel density estimation <ref type="bibr" target="#b32">[33]</ref> and substitute each delta peak by a 4D Gaussian kernel</p><formula xml:id="formula_4">G (σ σ σ s ,σ r ) : V(x, y, z, r) := k−1 ∑ i=0 G (σ σ σ s ,σ r ) ((x, y, z, r) − µ µ µ i ) ,<label>(5)</label></formula><p>1 The Dirac delta integrates to 1. Note that in order to obtain a properly normalized 4D pdf,V in Eq. 4 would have to be multiplied by 1/k, where k is the number of voxels. However, to avoid computing with unnecessarily small numbers, we neglect normalization for now and normalize later where needed.</p><p>where each voxel i from the original volume with k voxels is mapped to a Gaussian G (σ σ σ s ,σ r ) (•) in 4D, centered at µ µ µ i := (p i , r i ), corresponding to the voxel's original 3D position p i := (x i , y i , z i ), and its 1D intensity value r i . G (σ σ σ s ,σ r ) (•) is a separable 4D kernel in space × range:</p><formula xml:id="formula_5">G (σ σ σ s ,σ r ) (x) := (G σ s ⊗ G σ s ⊗ G σ s ⊗ G σ r )(x),<label>(6)</label></formula><p>via the tensor product ⊗ of 1D Gaussians with spatial standard deviation σ s (assuming isotropic voxels), and range standard deviation σ r .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">A hierarchy of 4D Gaussian mixtures</head><p>Our goal is now to compute an entire multi-resolution hierarchy, with each level m defined similarly to Eq. 5, but as a more general mixture of k m individually weighted 4D Gaussians, with weights c i :</p><formula xml:id="formula_6">V m (x, y, z, r) := k m −1 ∑ i=0 c i G (σ σ σ s ,σ r ) ((x, y, z, r) − µ µ µ i ) .<label>(7)</label></formula><p>We want to emphasize that a major difference of our approach to a general Gaussian Mixture Model is that all of the Gaussians comprising a givenV m are constrained to have the same standard deviation (σ σ σ s , σ r ). This property is crucial to enabling the use of convolutions for efficiency, and not having to store the σ 's of all Gaussians. Our hierarchy will therefore be a set of n resolution levels</p><formula xml:id="formula_7">{V m } with m ∈ {0, .., n − 1}. EachV m is the 4D pdf of level m in the form of Eq. 7, with k m Gaussians c i G (σ σ σ s ,σ r ) centered at µ µ µ i . With (σ σ σ s , σ r ) known, eachV m can be stored solely as a set of k m tuples {(µ µ µ i , c i )}.</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1">Initial Gaussian mixture</head><p>We start the hierarchy withV 0 for resolution level 0 . InV 0 , we set the spatial standard deviation σ s such that it corresponds to one voxel (we use σ s = 0.3), and set the range standard deviation σ r to a fixed value (we use σ r = 4/256). We set all</p><formula xml:id="formula_8">c i = 1 ( √ 2π) 4 σ 3 s σ r</formula><p>, so each Gaussian integrates to 1 (cf. Sec. 5.3). Note, however, that in allV m with m &gt; 0, the coefficients c i will be determined by minimizing an error function.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2">Hierarchy computation</head><p>We then compute the Gaussian mixture of each levelV m with m &gt; 0 from the preceding levelV m−1 . In order to avoid incurring aliasing artifacts later on, we first have to low-pass filterV m−1 . This can be done very efficiently by simply updating the spatial standard deviation σ s and the coefficients c i accordingly. See Sec. 5.3.2 and Appendix A.2. Our goal is now to representV m with fewer Gaussians thanV m−1 . IfV m−1 is represented by k m−1 Gaussians, and we would like to keep the typical down-sampling rate of 2 3 for 3D Cartesian volumes, we target k m = k m−1 /2 3 Gaussians forV m . We do this by computing a sparse approximation toV m via a greedy pursuit algorithm built on convolutions (Secs. 5.2 and 5.3) and mode finding (Sec. 5.4).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Volume classification from 4D representation</head><p>Given the representation ofV m as in Eq. 7 (via the set {(µ µ µ i , c i )}), our goal for volume rendering is to be able to evaluate Eq. 1 for any voxel with a given position p via the corresponding voxel footprint pdf f p (r).</p><p>In principle, each f p (r) can be obtained from the 4D pdf given by Eq. 7 by extracting the "conditional probability" of r, given voxel position p. This can be done by simply obtaining a function of r at p and re-normalizing. However, in order to facilitate fast parallel classification of entire voxel bricks, we employ a method that avoids the reconstruction of individual f p (r) entirely, and apply the transfer function in parallel to all voxels in a brick via 1D look-ups and 3D convolution. This greatly facilitates efficient GPU implementation. See Sec. 7.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">SPARSE PDF VOLUME COMPUTATION</head><p>Our goal is the computation of eachV m for resolution level m with m &gt; 0, such that it approximates the low-pass filtered mixtureV m−1 well. Both functions are given in the form of Eq. 7. The crucial goal is now to representV m with fewer Gaussians thanV m−1 , i.e., k m &lt; k m−1 . This is a reasonable assumption, because low-pass filtering makes these functions successively smoother. Our basic idea for this approximation is that eachV m should be represented as a sparse signal, with respect to a chosen dictionary of atoms ("basis functions") <ref type="bibr" target="#b8">[9]</ref>:</p><formula xml:id="formula_9">min c c 0 subject to Hc = v,<label>(8)</label></formula><p>where H denotes the dictionary with the atoms viewed as column vectors, and c is the coefficient vector that determines the linear combination that should best approximate a signal v, given H. Our dictionary H consists of translates of Gaussians (see Sec. 5.3), and the target signal v to approximate is a chosenV m after low-pass filtering. In order to obtain a sparse representation, c should have as few non-zero elements as possible, which is indicated by the L 0 pseudo-norm • 0 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Pursuit algorithms</head><p>In principle, finding the solution to Eq. 8 is an NP-hard problem <ref type="bibr" target="#b8">[9]</ref>. However, pursuit algorithms compute good approximations using greedy iterative strategies to obtain a sparse c. In each iteration, the atom from the dictionary H that approximates the current residual best is picked by projecting the residual into the dictionary <ref type="bibr" target="#b8">[9]</ref>. Our method is based on the Matching Pursuit algorithm <ref type="bibr" target="#b27">[28]</ref>. However, we employ a novel variant that is specialized for a dictionary that consists of translates of a Gaussian kernel, which facilitates the use of fast convolutions (Sec. 5.2). In contrast to earlier work for images <ref type="bibr" target="#b16">[17]</ref>, our strategy for volumes does not make use of a sampled pdf (i.e., histogram) representation, which is crucial to scaling from 2D image data to 3D volume data. Instead, our approach for volumes works almost completely in continuous 4D space, using continuous 4D Gaussian atoms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Dictionary projection as convolution</head><p>For brevity, in the following explanations we describe the 1D case of approximating a general 1D function g(x). However, one can always think of g(x) below as corresponding to an actual 4D functionV m . We want to project the function g(x), which we want to approximate, onto dictionary atoms h µ (x), where the parameter µ selects the atom. This projection is obtained via the inner product of the two functions. The inner product of two (real) functions g and h µ is defined as:</p><formula xml:id="formula_10">g, h µ := ∞ −∞ g(x) h µ (x) dx.<label>(9)</label></formula><p>The (scalar) coefficient of g with respect to h µ is obtained from projection using Eq. 9 with a dictionary atom that has unit norm:</p><formula xml:id="formula_11">h µ 2 = 1,<label>(10)</label></formula><p>where • 2 denotes the L 2 norm induced by the inner product, i.e., h 2 := (h, h) (see <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b26">27]</ref>). All of our dictionary atoms are translates of the same kernel h(x), where h is symmetric around zero, i.e., h(x) = h(−x). h µ then denotes the dictionary atom centered at x = µ, defined as:</p><formula xml:id="formula_12">h µ (x) := h(x − µ).<label>(11)</label></formula><p>This will allow us to carry out most operations as simple convolutions. The convolution (denoted by ) of two functions g and h is defined as:</p><formula xml:id="formula_13">(g h)(x) := ∞ −∞ g(t) h(x − t) dt.<label>(12)</label></formula><p>In order to determine the dictionary atom that approximates the function g(x) best, we have to determine which atom results in the largest inner product <ref type="bibr" target="#b8">[9]</ref>, i.e., we must determine the maximizer of Eq. 9:</p><formula xml:id="formula_14">max h µ g, h µ .<label>(13)</label></formula><p>Because we define all dictionary atoms as translates of the same kernel h(x), the maximum inner product of all h µ can be computed from the convolution of g and h (compare Eqs. 9 and 12, using Eq. 11):</p><formula xml:id="formula_15">max h µ g, h µ = max x (g h)(x).<label>(14)</label></formula><p>The value of x that maximizes the right-hand side of Eq. 14 is the maximizer of Eq. 13 with the h µ where µ = x. Thus, the crucial observation is that in order to find the dictionary element that approximates g(x) best, we simply have to find the maximum of the function (g h)(x).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Gaussian dictionaries and Gaussian mixtures</head><p>We define a Gaussian centered at x = µ with standard deviation σ as:</p><formula xml:id="formula_16">G σ (x; µ) := e − (x−µ) 2 2σ 2 , or abbreviated (15) G σ (x) := G σ (x;0) if µ = 0.<label>(16)</label></formula><p>Note that our definition of G σ is not normalized. We do this because we will need different normalization weights for different purposes. A weighted Gaussian is then cG σ (x; µ), with a scalar coefficient c. <ref type="bibr" target="#b1">2</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.1">Gaussian dictionaries</head><p>We use a dictionary h µ (x), with different µ, defined as Gaussians:</p><formula xml:id="formula_17">h µ (x) := c h G σ (x; µ),<label>(17)</label></formula><p>with</p><formula xml:id="formula_18">c h = π − 1 4 / √ σ , so that h µ (x) 2 = 1.</formula><p>We intentionally use dictionaries with a fixed standard deviation σ for all h µ (x). This is crucial in order to enable simple convolutions to be used both for dictionary projection (Sec. 5.2), and for classification at run time (Sec. 7).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.2">g(x) as Gaussian mixture</head><p>The function g(x) that we want to approximate is given as a mixture of k Gaussians with identical σ , but different weights c i and positions µ i :</p><formula xml:id="formula_19">g(x) := k−1 ∑ i=0 c i G σ (x; µ i ).<label>(18)</label></formula><p>Our approach needs to perform two main operations on g(x):</p><p>1. Low-pass filter g(x) before spatial down-sampling.</p><p>2. Compute the maximum of the convolution from Eq. 14 for dictionary projection (Sec. 5.2), with h µ (x) as defined in Eq. 17.</p><p>Both of these operations can be computed directly on g(x) given as a Gaussian mixture (Eq. 18). We operate directly on the mixture represented by the set {(µ µ µ i , c i )}. We simply modify the c i and the (global) standard deviation σ that is associated with the mixture. All positions µ µ µ i stay the same. For details see Appendix A.1 (convolution), Appendix A.2 (low-pass filtering), and Appendix A.3 (projection).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Pursuit via mode finding</head><p>We employ a greedy pursuit algorithm for the computation of the sparse approximation of eachV m given in the form of Eq. 7. The Matching Pursuit algorithm <ref type="bibr" target="#b27">[28]</ref> computes a greedy signal approximation in an iterative way, where in each iteration a residual function is reduced until a pre-defined L 2 error threshold is reached. In the beginning, the residual is initialized to the original signal. Then, in every iteration the dictionary atom that has the largest inner product with the current residual is picked, because it approximates it best <ref type="bibr" target="#b27">[28]</ref>. The corresponding coefficient is given by the same inner product, since it corresponds to the projection of the residual onto the chosen atom. In every iteration, the contribution of each atom is subtracted out from the residual, and the whole procedure starts again until the error is small enough, yielding the desired sparse signal representation <ref type="bibr" target="#b8">[9]</ref>. Algorithm 1 shows these steps in our framework. Each atom in our dictionary is a Gaussian h µ (x) as defined in Eq. 17. In 4D, each projection into the dictionary is a tuple <ref type="figure">(µ µ µ, c)</ref>, where µ µ µ selects the dictionary atom, and c is the corresponding coefficient. All our 4D Gaussian mixtures then correspond to sets G = {(µ µ µ i , c i )} of such tuples.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4.1">Projection in 4D using mode finding</head><p>A fundamental step in Algorithm 1 is finding the atom that results in the largest inner product with the residual (see Eq. 14). Instead of looking at each atom individually-as in standard Matching Pursuitwe exploit the property that the atom we are looking for corresponds to the maximum of the right-hand side of Eq. 14, which is attained at one of its modes. The convolution in Eq. 14 is derived in Appendix A.3.</p><p>We can therefore perform the projection step via a mode finding procedure in a Gaussian mixture. For mode finding, we employ the fixedpoint iteration approach described by Carreira-Perpiñán <ref type="bibr" target="#b2">[3]</ref>. Another similar alternative would be to use a mean shift procedure <ref type="bibr" target="#b5">[6]</ref>. <ref type="figure" target="#fig_1">Fig. 3</ref> depicts the individual steps of our approach for a simplified example illustrated in 2D (1D space × 1D range). We start with a given mixtureV m , subject it to spatial low-pass filtering to prevent aliasing (Eq. 35), further convolve it with the dictionary kernel h (Eq. 37), and then find the modes of this intermediate mixture. We start the mode finding procedure at the known modes of the mixtureV m , and iterate to stationary points of the intermediate mixture. At this stage, it is quite common that nearby starting points converge to the same mode. The intermediate mixture corresponds to the function g h in Eq. 14, and the coefficient that we are looking for (c in Algorithm 1) is the function value at the 4D position of the maximum mode.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4.2">Parallel pursuit via mode finding</head><p>Standard Matching Pursuit <ref type="bibr" target="#b27">[28]</ref> is a completely sequential algorithm, where only one atom is selected in each iteration. In our context, this means determining the maximum mode of the intermediate mixture, as described above. However, in order to speed up the fitting process, we want to perform multiple mode searches in parallel in each iteration. Re-compute approximation error E 2 = r(x) 2 ; 9: end while</p><p>In each iteration, we would like to find several non-overlapping modes in parallel, in order to select multiple atoms in parallel. We define non-overlapping modes such that the centroids of the atoms are not within distance ωσ of one another, where σ is the standard deviation of the atoms, and ω is a configurable overlap parameter. Setting ω appropriately ensures that the corresponding coefficients do not interfere with each other, because adding multiple overlapping atoms to the mixture at the same time incurs fitting errors due to incorrect coefficients. For overlapping modes, we always retain the largest one and discard the rest. The non-overlapping modes chosen in each iteration are added to the target mixture, and the residual is updated by subtracting the same atoms (Algorithm 1). The next iteration then continues from the previously known modes plus the newly added modes.</p><p>We found that this approach produces good results. However, in order to further speed up the pursuit process, we introduce two simple heuristics. Our first heuristic is to set ω to a value that allows minimal overlap among parallel coefficients. In our computations, we typically set ω = 3 for the spatial dimensions, and ω = 2 for the range. This allows us to put more parallel coefficients in each pursuit iteration with the trade-off of incurring a small error in the coefficient values. Note that setting ω large enough so that the overlap region covers the whole domain is equivalent to standard serial Matching Pursuit.</p><p>The second heuristic that we use is to optionally reduce the number of parallel searches that we do after the first pursuit iteration. The reason for this is that as the number of Gaussians in the residual grows, the parallel mode search also becomes slower, since (1) ideally to find all the modes, we have to do more searches starting from each Gaussian centroid in the residual, and (2) there are more Gaussian components in the mixture that need to be evaluated during the search. Conceptually, reducing the number of starting positions for the parallel mode search should have a minimal impact on the method since most of the searches converge to the same mode. Currently we pick around 1/8 of the possible starting positions in each iteration and just change the starting positions in the next iteration by making them spatially well distributed, i.e., we rotate over even and odd combinations of the x, y, and z positions of the starting points. We only apply this heuristic after doing the first parallel mode search iteration where we use all the possible starting points, i.e., all modes of the initial residual. <ref type="figure">Fig. 4</ref> illustrates the data structure that we use to compactly encode theV m of a sparse pdf volume. We assume a bricked volume to facilitate large-scale out-of-core volume rendering. That is, the original volume (resolution level 0 ) is subdivided into bricks of fixed size. Our current implementation uses a brick size of 64 3 voxels, plus four ghost voxels in each spatial dimension. Using smaller brick sizes incurs an impractical storage overhead for ghost voxels <ref type="bibr" target="#b10">[11]</ref>, while larger brick sizes lead to slower pre-processing, since Matching Pursuit has quadratic complexity. All bricks of level 0 are stored in the usual way, with one scalar per voxel. The bricks of all levels m with m &gt; 0 are stored in the following sparse pdf volume encoding: We first sort the For each voxel p, we also count how many (p i , r i , c i ) with p = p i there are, and store this count in a coefficient count brick at position p. We now drop the p i coordinate from each (p i , r i , c i ), and store the tuples (r i , c i ) in a coefficient info array. We do not need to explicitly store the p i , because the tuples (r i , c i ) of each p can be indexed according to the count of tuples of p (see below). This results in the following data structure per brick (see <ref type="figure">Fig. 4</ref>): Furthermore, for 8-bit data sets we can quantize the r i to 8 bits. The complete encoding then requires: For level 0 : 1 byte per voxel. For all m with m &gt; 0: 1 byte per voxel, plus 3 bytes per coefficient. This encoding results in sparse pdf volume sizes that are still similar to standard representations (see <ref type="table" target="#tab_3">Table 3</ref>), while encoding full pdfs. In order to save memory, we do not store indexes to the tuples (r i , c i ) on disk. However, at run time, for each p we need to be able to access all (r i , c i ) that originally came from a tuple (p i , r i , c i ) with p = p i . Therefore, after loading the sparse pdf data structure for rendering, we compute the prefix sum <ref type="bibr" target="#b17">[18]</ref> of the coefficient count brick. This results in an index brick, where the entry at each voxel p points to the corresponding location of the first tuple (r i , c i ) of p in the coefficient info array. All other tuples of p are located in consecutive memory locations, and their count is given by the coefficient count brick entry p.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">SPARSE PDF VOLUME DATA STRUCTURE</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">RUN TIME CLASSIFICATION</head><p>This section describes how Eq. 1 can be evaluated using our representation of 4D pdfs as 4D Gaussian mixtures (Eq. 7) instead of requiring individual 1D pdfs f p (r). We first derive the basic method (Sec. 7.1), and then describe its efficient implementation in practice (Sec. 7.2).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1">Basic method</head><p>Our goal at run time is to apply a transfer function t(r) to the data at any given voxel position p. According to Eq. 1, we do this by applying t(r) to the 1D voxel footprint pdf f p (r). The latter is now contained in the 4D Gaussian mixture given by Eq. 7. We therefore insert Eq. 7 into Eq. 1, and evaluate for a fixed 3D voxel position p :</p><formula xml:id="formula_20">= (x, y, z): E t(X p ) = t(r) f p (r)dr,<label>(19)</label></formula><formula xml:id="formula_21">= t(r) 1 w p k−1 ∑ i=0 c i G (σ σ σ s ,σ r ) ((p, r) − µ µ µ i )dr,<label>(20)</label></formula><p>where G (σ σ σ s ,σ r ) = G σ σ σ s ⊗G σ r is a separable 4D Gaussian kernel, and our expression for f p (r) is a 1D pdf due to the normalization factor w p :</p><formula xml:id="formula_22">w p := k−1 ∑ i=0 c i G (σ σ σ s ,σ r ) ((p, r) − µ µ µ i )dr.<label>(21)</label></formula><p>If we now split up µ µ µ i =: (p i , r i ) into spatial (p i ) and range (r i ) coordinates, respectively, and exploit that G (σ σ σ s ,σ r ) is separable, we get:</p><formula xml:id="formula_23">E t(X p ) = 1 w p k−1 ∑ i=0 c i G σ σ σ s (p − p i ) t(r)G σ r (r − r i )dr.<label>(22)</label></formula><p>Noting that all kernels G σ r are the same, we can write the integral in Eq. 22 as a convolution, which significantly simplifies the equation to:</p><formula xml:id="formula_24">E t(X p ) = 1 w p k−1 ∑ i=0 c i G σ σ σ s (p − p i )t(r i ),<label>(23)</label></formula><p>where the new functiont(r) is defined as follows (cf. Eq. 12):</p><formula xml:id="formula_25">t(r) := (t G σ r )(r) = b a t(x)G σ r (x − r)dx,<label>(24)</label></formula><p>where we have now denoted the interval of integration as </p><formula xml:id="formula_26">w p = k−1 ∑ i=0 c i G σ σ σ s (p − p i )Ḡ σ r (r i ),<label>(25)</label></formula><p>where the new functionḠ σ r (r) is defined as (cf. Eq. 24):</p><formula xml:id="formula_27">G σ r (r) := b a G σ r (x − r) dx,<label>(26)</label></formula><p>which is the integral of G σ r (•) centered at r and clamped to r ∈ [a, b].</p><p>These derivations now yield the crucial observation thatt(r) can be pre-computed via a single 1D convolution (Eq. 24) for a given transfer function t(r), and that Eq. 23 can be computed as a sum of simple look-ups and 3D (not 4D) convolutions. Similarly forḠ σ r (r). This makes run time classification very efficient and easy to implement.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2">Practical implementation</head><p>We now denote the spatial 3D neighborhood of voxel p as N (p), and obtain Gaussian mixture coefficients (µ µ µ i , c i ) = (p i , r i , c i ) from the data structure described in Sec. 6. We can then write Eq. 23 as:</p><formula xml:id="formula_28">E t(X p ) = 1 w p ∑ q∈N (p) G σ σ σ s (p − q) ∑ (q i ,r i ,c i ) q=q i c it (r i ).<label>(27)</label></formula><p>We note that the second sum in Eq. 27 can be computed once per voxel p, and then used in all spatial convolutions involving this voxel. This enables evaluating Eq. 27 as follows. We first use simple look-ups and summations to compute two intermediate bricks T (p) and N(p):</p><formula xml:id="formula_29">T (p) := ∑ (p i ,r i ,c i ) p=p i c it (r i ), and N(p) := ∑ (p i ,r i ,c i ) p=p i c iḠσr (r i ).<label>(28)</label></formula><p>Then, both bricks T (p) and N(p) are convolved in the 3D spatial domain with G σ σ σ s (•), and the classified output brick is obtained by dividing each voxel in T by the corresponding normalization factor in N:</p><formula xml:id="formula_30">E t(X p ) = T G σ σ σ s (p) N G σ σ σ s (p) .<label>(29)</label></formula><p>We  <ref type="figure">Fig. 5</ref>: Out-of-core distributed pre-processing pipeline. From the input volume bricks, the bricking server creates a fitting request with the initial 4D Gaussian mixture which it sends to an available fitting server. The fitting server then computes the sparse Gaussian mixture that approximates the input mixture best and sends the result back. The bricking server then compactly encodes the result into the output data structure which is reloaded later on to compute the next level.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">IMPLEMENTATION FOR LARGE-SCALE VOLUME DATA</head><p>This section describes our implementation of the sparse pdf volume pre-computation step that scales to large volume data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.1">Scalable out-of-core pre-computation</head><p>We have implemented the pre-computation of sparse pdf volumes in a scalable distributed framework illustrated in <ref type="figure">Fig. 5</ref>. This framework is realized entirely out-of-core, so that data sets of arbitrary size can be processed. The framework is split up into two main distributed components: (1) a bricking server, and (2) one or several fitting servers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.1.1">Bricking server</head><p>The bricking server first reads the processing parameters and streams through the input volume. During this process, it subdivides the volume into bricks of pre-defined size, which in our case are 64 3 voxels. Each of these bricks is immediately written back to disk into level 0 of the output data structure. A parallel thread then goes through each set of 2 × 2 × 2 bricks in 0 , i.e., a neighborhood of 128 3 voxels. This neighborhood in turn corresponds to one 64 3 brick in level 1 . The server then creates a corresponding fitting request and pushes it into a request queue. Each fitting request consists of the fitting parameters (σ of Gaussian atoms, target size of output Gaussian mixture), together with the list of 4D Gaussian components that are the kernel density estimate of the voxel data. Once a fitting server finishes processing a fitting request from the request queue, it sends back the resulting output 4D Gaussian mixture to the bricking server. The bricking server then writes it into the output sparse pdf volume on disk. Once level 1 is complete, the bricking server goes through each 2 × 2 × 2 brick neighborhood in 1 , which likewise now represents the Gaussian mixture of a 128 3 voxel neighborhood in 1 , and thus a 64 3 brick in level 2 .</p><p>It then creates the corresponding new fitting request. This process is repeated in an identical manner for all remaining resolution levels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.1.2">Fitting server</head><p>The second component of our framework are the fitting servers, which fit a sparser Gaussian mixture to an input Gaussian mixture using the parallel pursuit described in Sec. 5.4. Each fitting server connects to the bricking server via a TCP/IP link. Once connected, the bricking server assigns a thread to the new fitting server and sends a fitting request from the request queue. After the transmission, the corresponding thread will pause and wait for the result to be returned. The fitting servers take the fitting request, i.e., an input Gaussian mixture, and process it in-core. The input Gaussian mixture is uploaded to the GPU and processed via the CUDA part of our framework (Sec. 8.2). Once the fitting is completed, the result is sent back to the bricking server where the responsible worker thread wakes up and receives the sparse Gaussian mixture data. This data is integrated into the output sparse pdf volume. Should the fitting server not return the result within a  <ref type="figure">Fig. 6</ref>: Pdf approximation error analysis for the Visible Human data set. (Left) We plot the peak signal-to-noise ratio (PSNR) of the approximated pdf against the ground truth 256-bin histogram, averaged over all bricks. Sparse pdf volumes preserve the pdf information best (highest PSNR values), and across all resolution levels. (Right) We plot pdf approximation error distributions (histograms of error values, i.e., differences). Sparse pdf volumes have consistently smaller error values in all resolution levels, compared to the standard down-sampled and single Gaussian representation <ref type="bibr" target="#b39">[40]</ref>, respectively. The latter two exhibit large errors because they can only represent a single value and a single mode, respectively. Each error value is computed as the pointwise difference between ground truth pdf and approximated pdf in 4D.</p><p>pre-defined timeout, or should the TCP/IP link be terminated, then the worker thread also wakes up and pushes the corresponding fitting request back to the queue so that another fitting server can take over.</p><p>An almost arbitrary number of fitting servers can connect to one bricking server. Due to the use of simple TCP/IP links, the fitting servers can be located anywhere as long as they can reach the bricking server via the network. These connections can be established dynamically during the run time of the system, i.e., a new fitting server can connect at any time, and existing servers can disconnect or fail without terminating the overall computation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.2">Parallel pursuit on the GPU</head><p>In order to reduce pre-computation times, we use a CUDA implementation of the parallel Matching Pursuit that is executed in the fitting servers. Other GPU and compute languages such as OpenCL could also be used without much difference. During the whole pursuit process, we maintain two Gaussian mixtures: (1) the residual, and (2) the detected modes in each iteration. Since our Gaussian mixtures are sparse in the whole 4D domain, and in order to facilitate fast neighborhood searches, we use a linked list-based hash table <ref type="bibr" target="#b31">[32]</ref> to store each Gaussian mixture. This hash table, with a hashing function based on the work of Teschner et al. <ref type="bibr" target="#b34">[35]</ref>, allows us to quickly insert multiple Gaussian components using atomic operations on the GPU.</p><p>We first copy the input Gaussian mixture into the residual hash table by simply assigning a single thread for each component and performing parallel inserts into the residual hash table. Then, in each iteration of the parallel pursuit, we deploy as many threads as there are parallel mode searches to carry out. Each thread performs mode finding using fixed-point iteration <ref type="bibr" target="#b2">[3]</ref>, starting from the 4D position of the residual Gaussian component assigned to it. Once the modes have been detected, each thread inserts its mode into the modes hash table.</p><p>We then perform a parallel search for overlaps using one thread per entry in the modes hash table. The maximum non-overlapping modes are then inserted into the residual hash table, and the process is repeated until the error threshold is met or the target number of output Gaussian components is reached. Once the pursuit process is finished, the fitting server copies the result from the GPU to the CPU, and sends the obtained Gaussian mixture to the bricking server.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9">RESULTS AND COMPARISONS</head><p>This section provides qualitative comparisons and quantitative results. We have used the Shepp-Logan phantom (512 3 ), the Visible Human (512 2 × 1884), and a rat brain blood vessel (microvasculature) data set (1024 3 ) acquired using knife-edge scanning microscopy <ref type="bibr" target="#b28">[29]</ref>. In this paper, all data sets use 8-bit voxels. However, processing 12-or 16-bit data is straightforward, since we operate in a continuous 4D domain. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9.1">Consistent multi-resolution volume rendering</head><p>The pdf approximation error analysis in <ref type="figure">Fig. 6</ref> shows that sparse pdf volumes preserve the voxel neighborhood pdfs in each resolution level much better than standard low-pass filtering and down-sampling, as well as the single Gaussian approximation <ref type="bibr" target="#b39">[40]</ref>, respectively. This is the key to consistent volume rendering results even for coarse resolutions. The ground truth for our error analysis is the full 256-bin histogram (smoothed using σ r in Eq. 6), since this is the function that we want to preserve. PSNR values are computed against this histogram. <ref type="figure" target="#fig_4">Fig. 1 (b)</ref> shows that iteratively low-pass filtering and downsampling the Shepp-Logan phantom introduces new values in the data which leads to inconsistency artifacts in multi-resolution volume rendering. <ref type="figure" target="#fig_4">Fig. 1 (c)</ref> shows that using a single Gaussian to represent voxel neighborhood pdfs is not sufficient to capture the multi-modal nature of pdfs in lower resolutions, which also results in similar artifacts. In contrast, sparse pdf volumes are able to accurately encode pdfs leading to (d) more consistent multi-resolution volume renderings that are almost equivalent to (e) the ground truth using a full histogram with 256 bins. Similarly, <ref type="figure" target="#fig_7">Figs. 7 (e,f,g</ref>) show that the coarser resolutions of  <ref type="figure" target="#fig_7">Figs. 7 (b,c,d</ref>). Even small details as in the blood vessel data set depicted in <ref type="figure" target="#fig_8">Fig. 8</ref> are consistently retained in the multi-resolution volume rendering using sparse pdf volumes <ref type="figure" target="#fig_8">(Figs. 8 a,d,e</ref>). This is in contrast to standard pre-filtering and down-sampling, where details dramatically disappear in the coarser resolution levels <ref type="figure" target="#fig_8">(Figs. 8 c,f,g</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9.2">Performance and scalability</head><p>Pre-computation scalability. <ref type="table">Table 1</ref> gives pre-computation times for the data sets that we have used. We have used 16 fitting server processes, each with a 3.07 GHz Intel Xeon CPU and NVIDIA Tesla M2070Q (Fermi) GPU. On a single node, these times would roughly be larger by a factor of 16. Very importantly, despite the quadratic complexity of Matching Pursuit in general, our pre-computation times scale linearly with the data size, since we are subdividing the data into bricks and perform the pursuit on each brick independently. On average, a fitting server takes 5 minutes to process each 64 3 brick. Our pre-computation step also scales well in terms of memory requirements with respect to the dimensionality of the domain (4D), since we do not need to re-sample the pdf information for the fitting process. This is in contrast to our earlier work <ref type="bibr" target="#b16">[17]</ref>. Moreover, our pre-computation method would also effortlessly scale to 12-or 16-bit data, since mode finding always operates in a continuous 4D domain.</p><p>Classification performance. Using the optimized classification scheme described in Sec. 7.2, we achieve high classification performance at run time, as illustrated in <ref type="table" target="#tab_2">Table 2</ref> (timings measured on NVIDIA Geforce Titan Black (Kepler) GPU). We execute the classification step only when the transfer function changes, and also classify only the currently visible bricks. In order to do this, we have integrated volume classification and rendering with sparse pdf volumes into an existing large-scale out-of-core ray-caster <ref type="bibr" target="#b15">[16]</ref>. Apart from the modified classification of bricks, the volume renderer did not need to be modified at all. Based on the classification approach described in Sec. 7.2, the volume renderer performs pre-classified volume render- <ref type="table">Table 1</ref>: Pre-computation times using parallel pursuit (with 16 parallel fitting server processes) and the average time for one 64 3 brick. Note that # bricks is given for level 0 , but fitting starts at level 1 .</p><p>Data   ing <ref type="bibr" target="#b9">[10]</ref>. That is, the ray-caster fetches pre-classified RGBA values from the volume bricks, which are stored in an RGBA cache texture. An important consequence is that volume rendering frame rates are independent of the sparse pdf volume method. Rendering performance is exactly the same as for standard pre-classified volume rendering. Storage requirements. <ref type="table" target="#tab_3">Table 3</ref> summarizes the storage required for each of our test data sets in comparison with standard volume representations. For a fair comparison, we use a brick size of 64 <ref type="bibr" target="#b2">3</ref> and four ghost (boundary) voxels in each spatial dimension throughout. We compare with an octree with 8 bits per voxel, single Gaussian (µ, σ ) <ref type="bibr" target="#b39">[40]</ref> with 24 bits per voxel (8-bit quantized µ, 16-bit float σ ), and the full histogram representation with 256 bins and a 16-bit float per bin. Note that these values include the fixed storage requirement of level 0 (8 bits per voxel). The coarsest levels for D1, D2, and D3 that we have computed are levels 3 (D1), 4 (D2), and 4 (D3), respectively. Coarser resolution levels would already be smaller than a single brick for the entire volume. All sparse pdf volume representations used in this paper use 64 3 coefficients in each 64 3 voxel brick, i.e., on average (over the brick) there is a single coefficient per each voxel. This fact together with <ref type="table" target="#tab_3">Table 3</ref> shows that the sparse pdf volume representation is able to find a very good balance between storage overhead and the quality of the encoded pdf information. In all results, we have used σ s = 0.6 and σ r = 4/256 for the dictionary Gaussian h µ .</p><p>Volume compression. We have not performed a direct comparison with volume compression methods, since we believe that our goals are quite different. It would, however, be possible to use a general compression method on top of the sparse pdf volume representation, i.e., performing an additional compression step after the sparse pdf volume has been computed. This, however, would require de-compressing before volume classification. In contrast, an important property of sparse pdf volumes is that classification is performed directly on the sparse representation, i.e., without any explicit "de-compression" step.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="10">LIMITATIONS AND FUTURE WORK</head><p>Pre-classification. Our fast classification method (Sec. 7.2) is limited to pre-classified volume rendering. While our general approach (Sec. 7.1) in principle also supports post-classification, the required spatial 3D convolution (Eq. 23) could pose a performance bottleneck.</p><p>Shading. While we have not described volume shading in this work, gradients for shading can be estimated via one of two ways, e.g., using central differences: (1) Estimating gradients on the alpha channel of the classified RGBA voxels, i.e., estimating gradients af-ter applying the transfer function <ref type="bibr" target="#b7">[8]</ref>; or (2) Computing the expected value of the volume intensity itself and estimating the gradient there.</p><p>Data properties. Our method may break down for data without spatial coherence, e.g., random volumes. We are currently exploring additional strategies to adapt to special cases in the data and allow a hybrid mixture of pdf representations in the same data structure, which could then better adapt to data properties and user requirements.</p><p>Other grid types and mixed-resolution rendering. While our main goal were volume data on regular grids, our representation could be extended to other grid types. The major requirements would be to define the voxel footprint in the multi-resolution hierarchy, and to be able to gather samples in the corresponding neighborhood. In addition to other regularly sampled grids, such as BCC grids, computing a sparse pdf volume for irregular or adaptive grids, e.g., AMR data, could be particularly interesting. We are also planning to explore the reduction of transition artifacts in mixed-resolution volume rendering.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="11">CONCLUSIONS</head><p>Our sparse pdf volume representation for large-scale volume data compactly and accurately encodes the hierarchical pdf information of large multi-resolution volumes, which facilitates consistent multi-resolution volume rendering. In contrast to standard volume compression methods, our goal is not to reduce the memory size of the volume itself, but to encode much more information without requiring an impractical amount of additional storage, as well as avoiding explicit decompression for volume rendering. Our representation supports fast direct classification using the sparse encoding. We have shown that the representation of pdfs as a mixture of 4D Gaussians, and the corresponding parallel simplification, make pre-processing fast enough to achieve practical pre-computation times for large volume data.</p><p>Nevertheless, the pre-computation times are still the main bottleneck of our method and would be important to reduce in future work. However, it is a crucial property of our method that once a sparse pdf volume has been pre-computed, it does not require much more storage than standard methods that encode much less information, and facilitates real-time volume rendering with interactive transfer function changes with minimal changes to existing volume renderers.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>ForFig. 2 :</head><label>2</label><figDesc>information on obtaining reprints of this article, please send e-mail to: tvcg@computer.org. Manuscript received 31 Mar. 2014; accepted 1 Aug. 2014 ate of publication 2014; date of current version 2014Method overview. Pre-computation (left side):</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 3 :</head><label>3</label><figDesc>Parallel pursuit via mode finding starts from (a) the input Gaussian mixture (centroids denoted by +), which is the kernel density estimate of the original volume, or a previously simplified mixture. (b) The mixture is low-pass filtered in the spatial domain. (c) The intermediate mixture for mode finding is obtained via convolution with the dictionary kernel. We then perform parallel pursuit iterations in this mixture. We find all its modes (• and ) in parallel, but retain only the largest non-overlapping modes (•). A fixed-point mode search in the first iteration is illustrated for each step (•) from one example centroid.(d) The output Gaussian mixture consists of one component per retained mode.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Algorithm 1 7 :</head><label>17</label><figDesc>Approximating g(x) with Matching Pursuit Input: g(x) given as Gaussian mixture (Eq. 18)G = {(µ µ µ i , c i )} Output: Simplified Gaussian mixtureg(x) (Eq. 18)G = {(µ µ µ k , c k )} 1: Set output mixtureg(x) = 0; [G ← / 0]; 2: Set residual r(x) = g(x); [R ← G]; 3: Set L 2 approximation error E 2 = r(x) 2 ; 4: while E 2 &gt; ε do5: Find maximizer max h µ r, h µ as c = max µ (r h)(µ) (Eqs. 14 and 37 with r(x) instead of g(x); Sec. 5.4.1) 6: Grow mixtureg(x) ←g(x) + ch µ (x); [G ←G ∪ {(µ µ µ, c)}]; Reduce residual r(x) ← r(x) − ch µ (x); [R ← R ∪ {(µ µ µ, −c)}];8:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>1 Fig. 4 :</head><label>14</label><figDesc>The sparse pdf volume data structure consists of the bricked input volume ( 0 ) and the coarser resolution levels m with m &gt; 0. For each of the latter, we store (1) a coefficient count brick with one count per voxel p, and (2) a coefficient info array. Together, these encode the list of 4D Gaussian mixture components for each coarse level.set of mixture components {(µ µ µ i , c i )} = {(p i , r i , c i )} comprisingV m according to spatial voxel position p.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>1 .</head><label>1</label><figDesc>A coefficient count brick stores one 8-bit count per voxel p. This is the number of coefficients that are associated with the same spatial position p as the voxel, i.e., #(p i , r i , c i ) with p = p i . 2. A coefficient info array stores all tuples (r i , c i ) of the brick, with a 16-bit half float each for r i and c i , respectively. All tuples from the same voxel p are stored contiguously in memory.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>[a, b], corresponding to the domain of t(r), e.g., r∈ [0, 1] ⊂ R. (Note that G σ r (x) = G σ r (−x), and therefore G σ r (x − r) = G σ r (r − x)).Similarly, Eq. 21 simplifies to (cf. Eq. 23):</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 7 :</head><label>7</label><figDesc>Visible Human. (a) Volume rendering level 0 (512 2 × 1884). Comparison of volume rendering coarser levels (b, e) 1 (256 2 × 942), (c, f) 2 (128 2 × 471), and (d, g) 3 (64 2 × 235). (Top row) Sparse pdf volumes. (Bottom row) Standard pre-filtering and down-sampling. The logarithmic histograms of the standard data representations are shown on the top along with the transfer function. The standard representation loses more and more of the bones and teeth toward the coarser levels due to low-pass filtering (observe the changing histograms). Sparse pdf volumes are able to maintain much better consistency with the original rendering, keeping the important features of the bones and teeth intact.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 8 :</head><label>8</label><figDesc>Blood Vessels. (Left) Consistent multi-resolution volume rendering using sparse pdf volumes preserves details in the data for levels (a) 1 , (d) 2 , (e) 3 in contrast to (Right) standard pre-filtering and down-sampling for the same levels (c) 1 , (f) 2 , (g) 3 . The boxes in (d) and (f) correspond to the zoom-in into level 0 (1024 3 ) in (b). the visible human increasingly lose important values such as the bones and teeth due to spatial pre-filtering and down-sampling, leading to inconsistent results across levels. In comparison, sparse pdf volumes are able to retain the information of the bones and teeth, leading to reduced inconsistency artifacts, as shown in the smooth transitions from level to level in</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>Classification times. We report average times per 64 3 brick (total/brick), consisting of the time for computing Eq. 28 (c i 's/brick) and Eq. 29 ( /brick). We also state the total time for classifying all bricks of resolution level 1 (D1: 256 3 ; D2: 256 2 × 942; D3: 512 3 ).</figDesc><table><row><cell>Data set</cell><cell>total 1</cell><cell cols="2">total / brick c i 's / brick</cell><cell>/ brick</cell></row><row><cell>D1: Shepp-Logan</cell><cell>130 ms</cell><cell>2.03 ms</cell><cell>0.24 ms</cell><cell>1.79 ms</cell></row><row><cell>D2: Visible Human</cell><cell>526 ms</cell><cell>2.19 ms</cell><cell>0.37 ms</cell><cell>1.82 ms</cell></row><row><cell>D3: Blood Vessels</cell><cell>1,106 ms</cell><cell>2.16 ms</cell><cell>0.36 ms</cell><cell>1.80 ms</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 :</head><label>3</label><figDesc>Storage requirements comparison. The total storage requirements of sparse pdf volumes (ours) are comparable to standard representations. Column (µ, σ ) is [40]; histogram stores 256 bins.</figDesc><table><row><cell>Data set</cell><cell>octree</cell><cell>(µ, σ )</cell><cell>ours</cell><cell>histogram</cell></row><row><cell>D1: Shepp-Logan</cell><cell>175 MB</cell><cell>219 MB</cell><cell>241 MB</cell><cell>11, 361 MB</cell></row><row><cell>D2: Visible Human</cell><cell>659 MB</cell><cell>826 MB</cell><cell>909 MB</cell><cell>43, 257 MB</cell></row><row><cell>D3: Blood Vessels</cell><cell cols="4">1, 404 MB 1, 755 MB 1, 930 MB 91, 044 MB</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">For example, a Gaussian pdf f (x) requires R f (x) dx = 1, and therefore f (x) = 1 √ 2πσ G σ (x; µ), where c = 1 √ 2πσ . See also Appendix A.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS</head><p>This work was partially supported by King Abdullah University of Science and Technology (KAUST). We would also like to thank Thomas Theußl and Johanna Beyer; and John Keyser for the data set in <ref type="figure">Fig. 8</ref>.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A DERIVATIONS INVOLVING WEIGHTED GAUSSIANS</head><p>This appendix summarizes the most important basic computations involving weighted Gaussians that are used in the main part of the paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.1 Convolution of weighted Gaussians</head><p>We define a weighted Gaussian as cG σ (x; µ), with G σ (x; µ) as defined by Eq. 16 (note that our G σ are not normalized). The convolution of two weighted Gaussians results again in a weighted Gaussian:</p><p>with weights c n , standard deviations σ n , and positions µ n , where:</p><p>We note that for two Gaussian pdfs (c 0 = 1</p><p>results again in a Gaussian pdf, because then Eq. 33 gives</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2 Low-pass filtering g(x)</head><p>We compute the low-pass filtered g(x) from our definition of g(x) as a Gaussian mixture (Eq. 18) via convolution with a Gaussian low-pass filter kernel w(x)</p><p>which again is a Gaussian mixture, with σ filt = σ 2 + σ 2 w (cf. Eq. 32). For a down-sampling factor of 2, we desire σ filt := 2σ . Therefore, we use σ w := √ 3σ . Convolution with this filter therefore scales each c i by a factor c s = 1/2 (cf. Eq. 33). We therefore get:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.3 All inner products of g(x) as a convolution</head><p>Similarly, the convolution in Eq. 14 can be computed from our definition of g(x) as a Gaussian mixture (Eq. 18) convolved with the dictionary Gaussian h(x)</p><p>which again is a Gaussian mixture, with σ proj = σ 2 + σ 2 h , and each c i scaled by the factor c p =</p><p>). If we use σ h := σ , i.e., we project into a dictionary of Gaussians of the same width as the mixture Gaussians in Eq. 18, we get σ proj = √ 2σ , and thus:</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">High Performance Visualization: Enabling Extreme-Scale Scientific Insight</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">W</forename><surname>Bethel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Childs</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Hansen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
			<publisher>CRC Press/Francis-Taylor Group</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Smooth mixed-resolution GPU volume rendering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Beyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hadwiger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Möller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fritz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE/Eurographics Symposium on Volume and Point-Based Graphics</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="163" to="170" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Mode-finding for mixtures of Gaussian distributions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Carreira-Perpiñán</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1318" to="1323" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">A Course in Approximation Theory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Cheney</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Light</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
			<publisher>American Mathematical Society</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">A scalable, hybrid scheme for volume rendering massive data sets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Childs</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Duchaineau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K.-L</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Eurographics Symposium on Parallel Graphics and Visualization</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="153" to="161" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Mean shift: a robust approach toward feature space analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Comaniciu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Meer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="603" to="619" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">GigaVoxels: Rayguided streaming for efficient and detailed voxel rendering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Crassin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Neyret</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lefebvre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Eisemann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM SIG-GRAPH Symposium on Interactive 3D Graphics and Games</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="15" to="22" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Volume rendering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">A</forename><surname>Drebin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Carpenter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Hanrahan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACM SIGGRAPH 1988</title>
		<meeting>ACM SIGGRAPH 1988</meeting>
		<imprint>
			<date type="published" when="1988" />
			<biblScope unit="page" from="65" to="74" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Sparse and Redundant Representations: From Theory to Applications in Signal and Image Processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Elad</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010" />
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Real-Time Volume Graphics. A. K. Peters, Ltd</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Engel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hadwiger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kniss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Rezk-Salama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Weiskopf</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">An analysis of scalable GPU-based ray-guided volume rendering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Fogal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Schiewe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Krüger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Symposium on Large Data Analysis and Visualization</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="43" to="51" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Compressing probability distributions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Gagie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Processing Letters</title>
		<imprint>
			<biblScope unit="volume">97</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="133" to="137" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">COVRA: A compressiondomain output-sensitive volume rendering architecture based on a sparse representation of voxel blocks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Gobbetti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Iglesias Guitián</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Marton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics Forum</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">34</biblScope>
			<biblScope unit="page" from="1315" to="1324" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">A single-pass GPU ray casting framework for interactive out-of-core rendering of massive volumetric datasets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Gobbetti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Marton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Iglesias Guitián</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Visual Computer</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="787" to="806" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Creating raster omnimax images from multiple perspective views using the elliptical weighted average filter</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Greene</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Heckbert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer Graphics and Applications</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="21" to="27" />
			<date type="published" when="1986" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Interactive volume exploration of petascale microscopy data streams using a visualizationdriven virtual memory approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hadwiger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Beyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W.-K</forename><surname>Jeong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Pfister</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2285" to="2294" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Sparse PDF maps for non-linear multi-resolution image operations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hadwiger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Sicat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Beyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Krüger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Möller</surname></persName>
		</author>
		<idno>133:1-133:12</idno>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Graphics</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">6</biblScope>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Parallel prefix sum (scan) with CUDA</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Harris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sengupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">D</forename><surname>Owens</surname></persName>
		</author>
		<editor>H. Nguyen, editor, GPU Gems 3. Addison-Wesley Professional</editor>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Fundamentals of texture mapping and image warping</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Heckbert</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1989" />
		</imprint>
		<respStmt>
			<orgName>U.C. Berkeley</orgName>
		</respStmt>
	</monogr>
	<note>Master&apos;s thesis</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Multiresolution techniques for interactive texture-based volume visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Lamar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Hamann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">I</forename><surname>Joy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE Visualization</title>
		<meeting>IEEE Visualization</meeting>
		<imprint>
			<date type="published" when="1999" />
			<biblScope unit="page" from="355" to="362" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Gaze-directed volume rendering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Levoy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Whitaker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Symposium on Interactive 3D Graphics</title>
		<meeting>Symposium on Interactive 3D Graphics</meeting>
		<imprint>
			<date type="published" when="1990" />
			<biblScope unit="page" from="217" to="223" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Time-critical multiresolution volume rendering using 3d texture mapping hardware</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H.-W</forename><surname>Shen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2002 IEEE Symposium on Volume Visualization and Graphics</title>
		<meeting>the 2002 IEEE Symposium on Volume Visualization and Graphics</meeting>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="29" to="36" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Fast and efficient compression of floatingpoint data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Lindstrom</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Isenburg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1245" to="50" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Gaussian mixture model based volume visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Levine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P.-T</forename><surname>Bremer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Pascucci</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Symposium on Large Data Analysis and Visualization</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="73" to="77" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Adaptive sampling in single pass, GPU-based raycasting of multiresolution volumes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Ljung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Volume Graphics</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="39" to="46" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Nextgeneration visualization technologies: Enabling discoveries at extreme scale</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K.-L</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Moreland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ross</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SciDAC Review</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="12" to="21" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">A Wavelet Tour of Signal Processing: The Sparse Way</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mallat</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
			<publisher>Academic Press</publisher>
		</imprint>
	</monogr>
	<note>3rd edition</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Matching pursuits with time-frequency dictionaries</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mallat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Signal Processing</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="3397" to="3415" />
			<date type="published" when="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Fast macro-scale transmission imaging of microvascular networks using KESM</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Mayerich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kwon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Sung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">C</forename><surname>Abbott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Keyser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Choe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biomedical Optics Express</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="2888" to="2896" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Discrete-time Signal Processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">V</forename><surname>Oppenheim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">W</forename><surname>Schafer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">R</forename><surname>Buck</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999" />
			<publisher>Prentice-Hall</publisher>
		</imprint>
	</monogr>
	<note>2nd edition</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Visualization of big SPH simulations via compressed octree grids</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Reichl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Treib</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Westermann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Big Data</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="71" to="78" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">CUDA by Example: An Introduction to General-Purpose GPU Programming</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sanders</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Kandrot</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010" />
			<publisher>Addison-Wesley Professional</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Density Estimation for Statistics and Data Analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">W</forename><surname>Silverman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1986" />
			<publisher>Chapman and Hall/CRC</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">TAMRESH: Tensor approximation multiresolution hierarchy for interactive volume visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">K</forename><surname>Suter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Makhynia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Pajarola</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics Forum</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="151" to="160" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Optimized spatial hashing for collision detection of deformable objects</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Teschner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Heidelberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Pomerantes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gross</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Vision, Modeling, and Visualization</title>
		<meeting>Vision, Modeling, and Visualization</meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="47" to="54" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Analysis of large-scale scalar data using hixels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Thompson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Levine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">C</forename><surname>Bennett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P.-T</forename><surname>Bremer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gyulassy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Pascucci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">P</forename><surname>Pébay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Symposium on Large Data Analysis and Visualization</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="23" to="30" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Level-of-detail volume rendering via 3D textures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Weiler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Westermann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Hansen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Zimmermann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Ertl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Symposium on Volume Visualization</title>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="page" from="7" to="13" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">A multiresolution framework for volume rendering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Westermann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Symposium on Volume Visualization</title>
		<meeting>Symposium on Volume Visualization</meeting>
		<imprint>
			<date type="published" when="1994" />
			<biblScope unit="page" from="51" to="58" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Volumetric data reduction in a compressed sensing framework</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Sakhaee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Entezari</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics Forum</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="111" to="120" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Improving the quality of multiresolution volume rendering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Younesy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Möller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Carr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Eurographics/IEEE-VGTC Symposium on Visualization (EuroVis)</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="251" to="258" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
