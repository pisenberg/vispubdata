<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/pisenberg/grobid/grobid-0.6.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Predicate-based Focus-and-Context Visualization for 3D Ultrasound</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Schulte Zu Berge</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maximilian</forename><surname>Baust</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ankur</forename><surname>Kapoor</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nassir</forename><surname>Navab</surname></persName>
						</author>
						<title level="a" type="main">Predicate-based Focus-and-Context Visualization for 3D Ultrasound</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="DOI">10.1109/TVCG.2014.2346317</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2021-02-19T19:34+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Direct Volume Rendering</term>
					<term>Ultrasound</term>
					<term>Classification</term>
					<term>Predicate Function</term>
					<term>User Interface</term>
				</keywords>
			</textClass>
			<abstract>
				<p>Fig. 1: Our predicate-based classification approach allows for more insightful visualization of 3D ultrasound volumes. Here, traditional transfer function-based techniques suffer from occlusion of inner target anatomy such as the carotid artery (a). Facilitated through the predicate histogram, our technique is capable of yielding a focus-and-context visualization of not only the surrounding tissue (b), but also the target anatomy itself (c).</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Direct volume visualization techniques such as volume ray casting are today's state-of-the-art algorithms for the visualization of threedimensional medical images. In order to approximate the physics of light transport, most techniques use global transfer functions for the classification step of the classic volume rendering pipeline. While they yield impressive results for images from tomographic reconstructions such as computed tomography (CT) or magnetic resonance imaging (MRI), global 1D transfer functions reach their limits when being applied to 3D ultrasound images. Though they have recently become part of clinical practice due to the advances in today's 3D freehand ultrasound systems, effective and generic visualization tools are still missing for this imaging modality. This is mainly because several characteristics of B-mode ultrasound (brightness mode ultrasound where pixel intensities relate to the change of acoustic impedance and thus the reflectance of the sound wave) let its volumetric visualization suffer from severe occlusion artifacts as shown in <ref type="figure" target="#fig_2">Figure 2</ref>.</p><p>In lack of better alternatives, clinicians prefer to look at 2D slices extracted from 3D ultrasound volumes. Such multi-planar reconstructions (MPRs) allow for the visualization of arbitrary planes, which is not directly possible with 2D ultrasound. However, MPRs are hardly able to expose spatial context and connectivity information to the clinician. Rendering extracted geometry from the image obtained by seg-   mentation algorithms, as an alternative, may show connectivity information but does no longer expose the original image data (i.e. ultrasound intensities) and in particular the speckle texture, which is an essential part of ultrasound imaging. Therefore, this kind of indirect visualization is not well suited for many clinical routines.</p><p>In order to achieve clinically helpful direct volume visualization, we propose a completely novel approach to the classification stage together with an intuitive tool for setting up the rendering result: We introduce the concept of point predicates, which evaluate both local and global features of the ultrasound image and are defined on every sampling point. This facilitates to perform classification also based on high-level non-local information such as speckle or texture or even anatomical models/segmentations. By further annotating each predicate with an importance factor, we can naturally implement relevancebased visualization ensuring that important anatomies are always visible in the rendering, while preserving context information where possible in order to show better spatial clues.</p><p>Despite the recent advances regarding quality, interactiveness, and usability, volumetric visualization still has not been fully accepted by most clinicians for their workflow and is, if at all, only used for publications or patient presentations. Even with CT imaging, where the image intensities (Hounsfield units) directly correspond to a physical property that allows for direct discrimiation of tissue types, most radiologists still prefer to scroll through the stack of 2D slices and make up the 3D model in their minds instead of looking at 3D visualizations. This is mainly due to the lack of usability of today's classification approaches, where changing the volume rendering to show different anatomy relates to adaption of the transfer function. The limited expressiveness and intuitiveness, as well as the high dimensionality of the parameter domain, in particular with multi-dimensional transfer functions, makes their setup a tedious and cumbersome task that many clinicians have difficulties with <ref type="bibr" target="#b19">[20]</ref>.</p><p>With this issue in mind, we further introduce the predicate histogram as an effective tool for reducing the dimensionality of the predicate configuration space and facilitating its manipulation. Together with the descriptive semantics of predicates, it provides the user with easy and intuitive interaction with the point predicates to setup the rendering. This user interface was designed to allow for interactive exploration of clinically relevant information and switching between visualizations of different target anatomies with minimal efforts in a highly intuitive way. This is further enriched by a scribble technique providing a painting metaphor to specify classification directly in the image domain.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK</head><p>Our proposed method has three important properties:</p><p>1. It is particularly designed for the visualization of ultrasound volumes.</p><p>2. It integrates different levels of information, ranging from lowlevel local image intensities to even anatomical models, into a single consistent formulation that is exposed to the user using an intuitive widget.</p><p>3. It exploits illustrative focus-and-context rendering techniques.</p><p>Since the body of literature on volume rendering techniques is large, we focus this section on the most closely related works regarding the above topics and refer the interested reader to the book of Preim and Botha <ref type="bibr" target="#b15">[16]</ref> for a more exhaustive overview.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Visualization of Ultrasound Volumes</head><p>Compared to tomographic imaging modalities such as CT or MRI, where direct volume rendering can show very distinct visualizations of the anatomy, B-mode ultrasound images provide special challenges to classification causing these techniques to fail in yielding helpful visualizations. Since ultrasound imaging exploits the echo generated by density changes at tissue interfaces of different acoustic impedance, it rather shows the changes in physical properties than the physical properties themselves. As a consequence, ultrasound images are fundamentally different to those obtained from tomographic imaging modalities. In addition to this gradient-like nature, ultrasound is a highly directional modality and suffers from a considerable amount of noise. These properties prohibit the straightforward application of standard classification techniques for direct volume visualization (cf. <ref type="figure" target="#fig_2">Figure  2</ref>).</p><p>One of the few methods, besides the early work of Sakas et al. <ref type="bibr" target="#b18">[19]</ref>, specifically targeting these challenges for visualization, is the work of Fattal and Lischinski <ref type="bibr" target="#b4">[5]</ref>, who propose a variational approach to opacity classification that allows to extract smooth surfaces from 3D ultrasound volumes. However, their work is mostly attributed to fetal ultrasound, since it basically shows only a single surface and does not allow for blending of multiple layers. Mann et al. propose a volumetric ultrasound system augmenting B-mode ultrasound intensities with elasticity information using two-dimensional transfer functions in order to yield more distinct visualizations <ref type="bibr" target="#b13">[14]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Multi-Dimensional Classification Schemes</head><p>While exploiting additional information during classification and therefore introducing multi-dimensional transfer functions <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b14">15]</ref> (for instance based on post-processing) is a viable way towards useful 3D ultrasound visualization, it significantly increases the parameter domain to setup the rendering. Designing effective user interfaces for transfer function and rendering setup is an extensive and important field of research, as especially non-expert users have difficulties with mapping the complex parameter domain to semantic features for visualization. Therefore, Rezk-Salama et al. propose using principal component analysis to map a small set of semantic parameters to the potentially large transfer function parameter space and claim that this can be learned from clinicians <ref type="bibr" target="#b19">[20]</ref>. <ref type="bibr">Wang</ref>   <ref type="bibr" target="#b16">[17]</ref>, who implement a fuzzy logic evaluation of the semantic descriptions on the GPU and combine it with interaction-dependent rendering. While they achieve impressive relevance-based rendering results, their work is mostly focused on integrating user interaction into the visualization and does not address the special challenges of ultrasonic images.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Focus-and-Context Visualization</head><p>Illustrative relevance-based visualization is an efficient technique to tackle occlusion problems in volume visualization. They extend the classic direct volume rendering compositing scheme towards focusand-context rendering that defines a focus region, which must not be occluded, and context regions that are shown with less priority for better spatial understanding. Approaches not relying on transfer functions, such as the Importance-Based Accumulated Transparency Modulation introduced by Wan and Hansen <ref type="bibr" target="#b25">[26]</ref> extend the Maximum Intensity Difference Accumulation (MIDA) compositing scheme to allow relevance-based visualization without the need to setup a transfer function for classification. The work of Bruckner et al. allows for context-preserving see-through rendering by evaluating local shading information with two global parameters, which however do not have a direct semantic meaning <ref type="bibr" target="#b1">[2]</ref>. The ClearView technique of Krüger et al. exploits curvature information as well as distance metrics to determine sample importances and introduces different shading and compositing techniques to map relevance to optical properties <ref type="bibr" target="#b12">[13]</ref>. De Moura Pinto and Freitas introduce a further importance-aware compositing scheme, which is mathematically motivated and justified and integrates very well with the standard direct volume rendering pipeline <ref type="bibr" target="#b2">[3]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Our Approach</head><p>Our approach is inspired by line predicates used in flow visualization, where streamline tracking yields an extensive number of streamlines that represent the global connectivity of the data very well, but at the same time it greatly suffer from occlusion of important features. Here, line predicates offer an effective technique to filter the flow field for certain features such as vortices or high-velocity jets <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b0">1,</ref><ref type="bibr" target="#b11">12]</ref>. However, since line predicates are applied to geometry representations and simply toggle streamline visibility, they are very limited to this specific application. Our approach can thus be seen as a generalization of this idea providing a consistent formulation for relevance-based rendering with particular focus and application on 3D ultrasound visualization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">METHODS</head><p>Our predicate-based approach is designed to fully integrate into a standard volume rendering pipeline and consists of three steps, as illus-trated in the schematic diagram of <ref type="figure">Figure 3</ref>. We define a point predicate P as a boolean-valued function f P on the image domain X augmented with an importance factor κ P and a color modulation δ P :</p><formula xml:id="formula_0">P := f P : X → {true, false}, κ P , δ P .<label>(1)</label></formula><p>After selecting the predicates to apply from the point predicate library, the user specifies the rendering outcome by configuring κ P and δ P . This process is heavily supported by the predicate histogram, which we propose as a user interface for rendering setup. During the classification stage of the rendering, the ray caster applies each predicate to each sampling point yielding a color modulation for each sample, which are eventually accumulated using a focus-and-context compositing technique exploiting the predicates' importance factors.</p><p>The term point predicate suggests that the predicate can be evaluated at every point within the image domain X. However, it is essential that predicates are not limited to local values but also to features of local environments or even of global nature, such as texture information or anatomical models and segmentations. Furthermore, we do not pose any presumptions on the spatial representation of X.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Predicate Library</head><p>Our current implementation consists of a point predicate library based on a variety of methods to evaluate both local and global features in the image.</p><p>Range-based predicates apply to intervals of scalar measures in the image such as intensity and gradient magnitude. While their sole expressiveness is rather limited, prone to inter-data set variability, and in particular does not go beyond traditional 1D/2D transfer functions, they are an essential part in combination with the other predicates. For instance, since high curvature regions often carry important visual depth and context cues, assigning high importance values to the gradient magnitude predicates may yield significant visual improvements.</p><p>Due to the direction dependency of ultrasound images, directionbased predicates are an important factor for our predicate-based 3D ultrasound visualization. They exploit additional information on the ultrasound scanning direction, which we annotate to the compounded ultrasound volume. The gradient angle predicate evaluates the scanline direction in a local context by computing the angle between scanline and the smoothed gradient. Since the reflection of the ultrasound wave depends on the incident angle with the interface, this ultrasound specific point predicate is a powerful tool to highlight or mask certain structures.</p><p>As a third group we implemented a variety of predicates based on derived measures. Since they apply a configurable threshold to the derived measure, they can be seen as extension to the range-based predicates.</p><p>The Signal-to-Noise ratio predicate computes the variance-based SNR of the ultrasound image in a local neighborhood of the sample position and can be used to select regions with certain entropy. We therefore build for each voxel the weighted variance within a uniform 7x7x7 kernel and perform windowing on the results. The windowing parameters are user-controlled in our current implementation, since an elaborate evaluation is beyond the scope of this work.</p><p>Furthermore, we implemented a GPU version of Frangi's vesselness filter <ref type="bibr" target="#b5">[6]</ref> and bound its results to a vesselness predicate. By computing local Hessians for each voxel on multi-level Gaussians of the ultrasound volume and performing an eigenvalue analysis, the Frangi filter provides a scalar measure of presence of tubular structures. Therefore, this predicate is particularly useful in vascular imaging.</p><p>The presence of ultrasound confidence maps <ref type="bibr" target="#b8">[9]</ref> can be exploited with the confidence predicate. Confidence Maps compute a relative per-pixel attenuation of the ultrasound signal using a random-walks approach. This attenuation could be interpreted as uncertainty information and therefore directly be integrated into the volume rendering pipeline. Our experiments however show only limited use of the additional information, which may be an issue with the confidence maps themselves. Nevertheless, we think that this is a promising direction for future work to integrate uncertainty visualization into our pipeline since future work on Confidence Maps, such as <ref type="bibr" target="#b7">[8]</ref>, may improve their quality and validity.</p><p>Finally, we implemented a label predicate that evaluates on optionally existing labeling information of the image in two different ways. For our evaluation in Section 6 we performed a manual segmentation on the data sets partitioning the ultrasound volumes into semantic layers of anatomy such as skin, muscle and bone. This was performed in the style of Surface Function Actives segmentation <ref type="bibr" target="#b3">[4]</ref>, which could yield a similar result in a (semi-)automatic fashion <ref type="bibr" target="#b9">[10]</ref>. The segmentation layers were stored as B-spline surfaces in voxel space. With these, the label predicate can then directly determine to which layer the current sample belongs. The second version of the label predicate uses a 3D voxel grid as input data, where each voxel stores a bit mask with the labeling information. With the cost of discretization, this predicate allows the same evaluation of segmentation information but in a more generic way. This yields a very natural way to seamlessly integrate segmentations into the ray casting process and offers a powerful tool to accurately define importance factors or color modulations for specific regions.</p><p>As our work focuses on providing a novel approach together with a high-level tool, the presented point predicate library is certainly not complete, but rather provides a proof-of-concept implementation. Future work by the community may yield a variety of further applicationdependent predicates that evaluate both local and global features in the image to yield even better classification results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Predicate Combination</head><p>To allow sufficient generality, we keep the individual predicates simple with each just evaluating a single feature in the image domain. We achieve further flexibility by assembling multiple predicates P 1 ,...,P n into meta predicates using combination operators. Our boolean formulation of the predicate function therefore yields the classic boolean operators:</p><p>NOT: P 1 yields the negation of the original predicate and allows to semantically complement the accepted domain of the original predicate.</p><p>AND: P 1 ∧ ••• ∧ P n yields a predicate that satisfies the constraints of all predicates P 1 through P n . Often it is desired to have this operation in order to semantically restrict the accepted domain to the intersection of the accepted domains of each predicate, as also shown in <ref type="figure" target="#fig_3">Figure 4</ref> where the second and the third predicate from the left are of this type.</p><p>OR: P 1 ∨ ••• ∨ P n yields a predicate that satisfies the constraints of either of the predicates P 1 through P n . Since our formulation computes the final sample importance by computing a weighted sum of the predicates' importances (cf. Section 3.4), the OR operator can also be obtained by suitable setup of the importance factors. The point predicates to apply are selected from the user or, alternatively, given by a workflow model later potentially learned specifically for the given anatomy and application. Each predicate has a small set of parameters, defining the predicate importance κ and an optional color modulation δ having components hue δ <ref type="bibr">(H)</ref> and saturation δ <ref type="bibr">(S)</ref> . Certain predicates may have further optional parameters defining where the predicate yields true (e.g. intensity range).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Predicate Selection &amp; Setup</head><p>We propose to combine predicate selection and configuration via the predicate histogram, a single intuitive widget as shown in <ref type="figure" target="#fig_3">Figure  4</ref>. The heights of the bars directly represent the relative importance weighting of the predicates, while their fill color shows the color modulation. The user can manipulate the importance of each predicate with intuitive drag and drop interaction on the histogram bar and will directly see the results of his/her actions, as the predicate-based rendering is evaluated in real-time. In order to further reduce the parameter space without losing flexibility, the predicate histogram normalizes the sum of the predicates weights:</p><formula xml:id="formula_1">∑ j κ j = 1.<label>(2)</label></formula><p>Hence, increasing the importance of one predicate automatically decreases the importances of the other predicates and vice versa. We place two additional sets of manipulators around the predicate histogram widget, which allow controlling additional parameters of the currently selected predicate: Two vertical sliders on the left allow the user to configure the color modulation in terms of hue and saturation. The resulting color is visualized in the predicate histogram as fill color of the corresponding bar. Furthermore, widgets to control feature specific predicate parameters (such as the range where the predicate yields true) are placed below the histogram in a horizontal layout.</p><p>The predicate selection process is currently a fully manual task of explorative nature. However, we argue that achieving satisfying rendering results is significantly more intuitive and easier than with traditional 1D/2D transfer functions, since the parameter space of our point predicate technique is much more expressive due to its semantic nature and the whole process runs in real-time providing interactive feedback. Furthermore, the predicate histogram reduces the parameter space effectively in size through the normalization of predicate importances (cf. Equation (2)).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Classification &amp; Compositing</head><p>For classification and compositing, our predicate-based ray caster evaluates the selected predicates on each input sample point s to compute the sample importance κ(s) and sample color modulation δ (s). As we wish the individual importances to contribute in an additive manner, we define κ(s) as</p><formula xml:id="formula_2">κ(s) = ∑ n j=1 χ j (s)I(κ j ) ∑ n j=1 χ j (s) ,<label>(3)</label></formula><p>where I(κ j ) denotes the impact function for predicate j and χ j (s) the characteristic function for predicate j (i.e. indicating whether f j (s) is true). We would like the following two conditions to hold:</p><p>1. A non-linear amplification of importance differences, meaning that</p><formula xml:id="formula_3">κ i ∼ κ j ⇒ I(κ i ) ∼ I(κ j ) but κ i &lt; κ j ⇒ I(κ i ) I(κ j )</formula><p>. This allows for better usability since the user does not need to be pixel-perfect when assigning the same importance to multiple predicates. This condition can be rewritten to</p><formula xml:id="formula_4">κ i − κ j &lt; I(κ i ) − I(κ j ),<label>(4)</label></formula><p>which holds for all differentiable I with I (x) &gt; 1.</p><p>2. In the case of all predicates having the same importance factor assigned, we wish κ(s) to be always 1:</p><formula xml:id="formula_5">∀i, j : κ i = κ j ⇒ ∀s : κ(s) = 1.<label>(5)</label></formula><p>Experimentally, we found I(κ j ) := (n • κ j ) 2 , where n is the total number of predicates, to yield good results and satisfy both conditions. This gives us the following full definition (cf. Equation <ref type="formula" target="#formula_2">3)</ref>:</p><formula xml:id="formula_6">κ(s) = ∑ n j=1 χ j (s) • (n • κ j ) 2 ∑ n j=1 χ j (s) .<label>(6)</label></formula><p>It should be noted that one certainly can select very small κ i , κ j , so that n • κ i &lt; 0.5 and n • κ j &lt; 0.5 violate the first condition. However, in such cases there is at least one κ k with n • κ k &gt; 1 due to Equation (2). We argue that this effect is even desirable as predicate k shall have the major impact on the visualization and we can neglect the importance difference between predicates i and j.</p><p>In order to specify the optical properties of the sample s, we compute the sample color modulation in terms of hue δ (H) (s) and saturation δ (S) (s) in HSL color space. The sample luminance as well as its opacity are set to the original ultrasound intensity. This serves two goals: It reduces the dimensionality of the parameter space, and even more importantly allows to retain the appearance of the original ultrasound data, which we see as an essential part of ultrasound visualization. The color modulation is computed in an additive manner using the predicate contributions</p><formula xml:id="formula_7">ω j (s) := χ j (s) • (n • κ j ) 2<label>(7)</label></formula><p>as weights. The hue modulation is additionally weighted by the saturation modulation to avoid undesirable effects in cases where large hue shifts with small saturation modulations are combined with small hue shifts with large saturation modulations.</p><formula xml:id="formula_8">δ (S) (s) = 1 ∑ n j=1 ω j (s) • n ∑ j=1 ω j (s) • δ (S) j , δ (H) (s) = 1 ∑ n j=1 ω j (s)δ (S) j • n ∑ j=1 ω j (s)δ (S) j • δ (H) j .<label>(8)</label></formula><p>With sample importance, color and opacity set, the samples are fed into a focus and context compositing scheme. While our proposed method should work with most relevance-based compositing techniques, we use use the one proposed by De Moura Pinto and Freitas <ref type="bibr" target="#b2">[3]</ref>, which has various desirable properties:</p><p>1. Its well motivated front-to-back recurrence scheme formulation allows straightforward integration into standard ray casters.</p><p>2. In the absence of importance values or with all samples being equally important, it resolves to the standard emissionabsorption-based volume rendering integral.</p><p>3. Its input parameters are clear and limited to a scalar importance value besides the standard optical properties of color and opacity. We therefore map κ(s) to I s , δ (s) to C s and I(s) to α s as introduced in <ref type="bibr" target="#b2">[3]</ref>.</p><p>The full recurrence scheme for compositing can be found in the Appendix.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">EXTENSIONS</head><p>Our technique integrates very well into the existing volume rendering pipeline. This is also valid for a variety of possible extensions that current state-of-the-art methods provide to facilitate standard transfer function-based classification, such as data driven techniques to generate transfer function presets, shape-based transfer functions, or imagedriven transfer function setup where the user can manipulate the classification by direct interaction with the original image. Many of these works can be easily transferred to our predicate-based approach for direct volume rendering. As an example, we present how to integrate a scribble technique into our framework similar to the interface proposed by Tzeng et al. <ref type="bibr" target="#b24">[25]</ref> and the stroke-based transfer function design by Ropinski et al. <ref type="bibr" target="#b17">[18]</ref>.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Scribble-based Predicate Histogram Setup</head><p>While the predicate histogram widget already provides an intuitive metaphor to setup the predicate configuration, it still requires the user to perform an implicit mapping between the semantic meaning of each predicate and its corresponding features in the image. To further facilitate the predicate importance setup, we implemented a scribble technique that offers the user the possibility to directly interact with the ultrasound image by using a painting metaphor to mark focus and context regions in cross-sectional slice views of the volume as illustrated in <ref type="figure" target="#fig_4">Figure 5</ref>. The scribbles yield a set of positive samples that should be emphasized in the volume rendering and a set of negative samples that should be less prominent. Since emphasizing certain regions relates to increasing the importances of the corresponding predicates and since decreasing importances results in decreased visibility, we transform the scribbles into a modulation of the predicate importances κ i .</p><p>For each predicate i we denote the number of positively labeled samples where the predicate yields true by N + i and the number of negatively labeled samples where the predicate yields true by N − i . We compute an importance modulation vector m as</p><formula xml:id="formula_9">m i = q N + i − N − i ∑ j N + j − N − j ,<label>(9)</label></formula><p>where q describes the percentage by which the current predicate histogram is altered through the scribbles, which we empirically set to 0.25. In order to keep the predicate histogram in its normalized state (Equation (2)), we first normalize m so that ∑ j m j = 0 before we update each importance κ i by adding m i . This approach can certainly be extended with more elaborate importance modulation or even automatic predicate parameter configuration. However, since this is beyond the scope of this paper we consider it as future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">IMPLEMENTATION</head><p>We implemented our predicate-based ray casting technique entirely using OpenGL 4 and GLSL, so that apart from setting up the predicate logic, all evaluations and computations are performed on the GPU using a single fragment shader. Furthermore, our formulation is designed to seamlessly integrate into the standard direct volume rendering pipeline.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Predicate Selection &amp; Setup</head><p>The client-side selection and setup is automatically transformed into shader code, for which we use a building block like system similar to the shader templates in <ref type="bibr" target="#b16">[17]</ref>. Every point predicate provides three blocks:</p><p>1. A GLSL header defining uniform names for the predicate parameters and further optional definitions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2.</head><p>A closed GLSL expression defining how to evaluate the predicate with respect to the input data.</p><p>3. A function to setup the shader, which is called by the renderer (prior to rendering) and assigns the parameter values to the corresponding uniforms.</p><p>The classification scheme from Equations <ref type="bibr" target="#b5">(6)</ref> and <ref type="formula" target="#formula_8">8</ref>is transformed into a single GLSL function combining the evaluation expressions and yielding the final sample intensity and color modulation. Together with the predicates' GLSL headers, the predicate evaluation function is injected into the renderers fragment shader. Meta predicates are easily implemented using a composite pattern. Potentially expensive recompilation of the shader has to be performed only when the set of selected point predicates changes, as this is the single event changing the definition of uniform variables and predicate expressions. Subsequent rendering setup by configuring the predicates' importance factors, color modulations, and optional parameters is entirely implemented by updating the uniform values, which is even less overhead than an update of the transfer function texture as performed by traditional transfer function-based renderers.</p><p>To implement the proposed scribble technique, we need to encode for each pixel which predicates yield true. This is easily done by generating a 3D volume where each voxel encodes the results of the predicates' characteristic functions in a bit mask.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Integration into the Standard DVR Pipeline</head><p>Integrating our predicate-based classification and compositing into a standard GLSL ray caster is straightforward and needs only minimal changes in the shader code: Instead of a texture lookup on the transfer function, the shader gathers all necessary input data for the predicates and calls the predicate evaluation function yielding final sample importance and color modulation. The color modulation is then applied to sample intensity in HSL space, yielding the sample color value and opacity. Together with the sample importance they are directly fed into the compositing scheme as defined in <ref type="bibr" target="#b2">[3]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">RESULTS</head><p>For evaluation we acquired ultrasound sweeps of three distinct anatomies (shoulder, carotid artery, and achilles tendon) using an ACUSON S2000 TM ultrasound machine equipped with an Acuson 9L4 linear transducer and electromagnetic tracking hardware. These sweeps were reconstructed using an advanced backward compounding algorithm exploiting frame orientation information to yield high quality volumes. Further details on this algorithm can be found in <ref type="bibr" target="#b21">[22]</ref>.  The resulting volumes have a resolution of 512 3 voxels for the shoulder data set and of 384 3 voxels for the carotid and the achilles tendon data set.</p><p>After discussions with clinicians we identified clinically relevant features for each data set: For the shoulder data set, the clinicians were interested in seeing the bone surface in context with the muscle layer. <ref type="figure" target="#fig_5">Figure 6</ref> shows possible visualization results of our technique in conjunction with the predicate histogram used. 3D Visualization of carotid ultrasound specifically needs to show the path of the carotid artery and its bifurcation in a spatial context, as shown in <ref type="figure" target="#fig_6">Figures 1  and 7</ref>. Finally, for the achilles tendon acquisition, the clinicians need to see the tendon in its whole shape in order to identify possible tears or other lesions. <ref type="figure" target="#fig_7">Figure 8</ref> shows the results of our approach.</p><p>To support our predicate-based approach to classification, we performed a manual segmentation on the data sets partitioning the ultrasound volumes into semantic layers of anatomy such as skin, muscle and bone (cf. Section 3.1 on label predicate).</p><p>To evaluate the transferability of the predicate histogram setup, we applied the same configuration to both our carotid ultrasound data sets. As depicted in <ref type="figure">Figure 9</ref>, a single predicate histogram was able to create a proper visualization for both data sets. This suggests that our formulation allows to reuse a predicate histogram, which was created for a specific data set, for a different data set of the same anatomy as valid preset, so that the user does not need to start the exploration and tuning from scratch.</p><p>All results presented in this work were acquired in interactive sessions with a nVidia GeForce 670 GTX GPU. While implementing a performance-optimized rendering was not our main goal, our implementation is still capable of generating sufficient frame rates for interactive renderings as shown in <ref type="table">Table 1</ref>. The decreased performance in comparison to standard 1D transfer function-based direct volume rendering is mainly because the illustrative focus-and-context rendering does no longer allow for early ray termination.  <ref type="table">Table 1</ref>: Frame rates of our predicate-based approach compared to standard 1D transfer function-based direct volume rendering for different data sets on a GeForce 670 GTX, viewport size 800x600.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">DISCUSSION</head><p>In the previous section, we compared our rendering results only to standard direct volume rendering with a 1D grayscale transfer function, which may raise the question how our technique compares to other related visualization techniques referenced in Section 2. The main issue is that most of these techniques are not applicable to ultrasound data. Ultrasound intensities are of highly context-sensitive nature (cf. Section 2.1) so that transfer functions solely relying on local information, such as intensity and gradient, neither improve the visual outcome nor are a suitable domain for defining color. Since our results rely to some extent on segmentation output, our approach can be seen as specialization of multi-volume rendering techniques, which could yield similar results. However, we would like to stress that the focus of our work is the full integration of a large variety of classification techniques into a single consistent formulation in combination with an intuitive user interface that allows for highly interactive exploration of the data. One side effect of relevance-based rendering is the limited depth perception, in particular in still images. It is an inherent property of this approach that features, which would usually be occluded, pop out if they are assigned with a higher importance factor than features in the front. The correct depth perception can however still be perceived for instance through motion parallax in dynamic scenes as shown in our video in the supplementary material. Furthermore, the used compositing scheme <ref type="bibr" target="#b2">[3]</ref> ensures a correct depth ordering in case of uniform importances so that the depth perception of the individual features themselves remains intact.</p><p>A very important aspect is the intuitiveness of our predicate his-togram based on the semantic nature of the predicates. Therefore, it is essential to provide the predicates and their settings with easily comprehendable naming. Since all the user needs to do is deciding whether he/she wants to see more or less of a certain feature and adjust the corresponding bar in the predicate histogram accordingly, this can also be considered as an implicit parameter space reduction It should be noted that the focus of this paper is the introduction of the predicate concept and the predicate histogram, as well as the demonstration its potential on selected examples. An exhaustive study regarding the selection of suitable features for defining predicates is beyond the scope of this paper, as are techniques for automatic segmentation of specific anatomies. For a detailed overview on suitable segmentation techniques, we refer the interested reader to the book of Szeliski <ref type="bibr" target="#b23">[24]</ref> or the survey paper of Heimann and Meinzer <ref type="bibr" target="#b6">[7]</ref>. Due to our generic formulation, segmentation results obtained by such techniques or even the techniques themselves can be easily transferred into predicates and integrated into our visualization concept.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">CONCLUSION</head><p>In this work, we introduced a novel consistent formulation for predicate-based classification of volumetric image data. It does not only allow for integration of both local and global image information and even anatomical models, but also naturally extends to illustrative focus-and-context visualization. While our technique does not make any a-priori assumptions on the type of input data or its spatial representation, it was designed for the specific application of direct volume visualization to 3D ultrasound volumes, for which it yields superior results in terms of occlusion and distinctly exposing selected image features than traditional global transfer function-based visualization.</p><p>To complement our approach, we additionally proposed the predicate histogram as an effective means for reducing the potentially high dimensionality of the predicate configuration domain.</p><p>It provides the user with an intuitive interface showing an overview over the parameter space, as well as with interaction metaphors to interactively manipulate the visualization result in real-time. Especially in combination with the implemented scribble technique, the predicate histogram can be modified by direct interaction with the rendered ultrasound image. Thus, we obtain an intuitive workflow, which allows also non-expert users to obtain insightful visualizations. The whole framework is designed to seamlessly integrate in the standard volume rendering pipeline without significantly increasing the computational burden and thus allowing for a real-time interaction with the system.</p><p>While directly integrating adequate segmentation technique into our predicate formulation might be one aspect of future work, other aspects are the application of our technique to other imaging modalities and multi-modal data sets. We imagine the predicate domain to be well suited for machine learning approaches, which could generate application-specific workflow models to automatically provide predicate histogram presets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>APPENDIX</head><p>The detailed recurrence scheme for the relevance-based compositing of our technique is as follows. The equations are the same as in <ref type="bibr" target="#b2">[3]</ref> but adapted to our naming conventions.</p><p>Let κ(s) be the computed sample importance, C(s) be the sample color and α(s) be the sample opacity as we defined in Section 3.4. Then we define the visibility factor vis(κ(s), κ i ) of the current sample κ(s) compared to the accumulated importance κ i as vis(κ(s), κ i ) = 1 − exp(κ i κ(s)),</p><p>as well as the modulation factor m as</p><formula xml:id="formula_11">m =      1 κ(s) ≤ κ i , 1 1 − α i ≥ vis(κ(s), κ i ), 1−vis(κ(s),κ i ) α i else.<label>(11)</label></formula><p>The incremental front-to-back compositing scheme is defined by: </p><formula xml:id="formula_12">C i+1 = mC i + (1 − mα i )C(</formula></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>For</head><label></label><figDesc>information on obtaining reprints of this article, please send e-mail to: tvcg@computer.org. Manuscript received 31 Mar. 2014; accepted 1 Aug. 2014 ate of publication 2014; date of current version 2014. 11 Aug. 9 Nov. D . Digital Object Identifier 10.1109/TVCG.2014.2346317</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>(a) Standard DVR of carotid ultrasound volume (b) Intensity distribution and applied TF of the above visualization</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 2 :</head><label>2</label><figDesc>Occlusion artifacts of traditional methods: (a) While one can see the outer shell of the different layers, clinical relevant information such as the path and shape of the carotid artery and its bifurcation are hidden. (b) Due to the homogeneous distribution of ultrasound intensities and their highly context-sensitive nature, there is no chance in discriminating relevant features through their intensities.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 4 :</head><label>4</label><figDesc>Our proposed widget shows the predicate histogram and allows an easy and intuitive configuration of the point predicates for relevance-based rendering: The main area shows the distribution of predicate importances and enables easy manipulation using drag and drop. Two sets of controls allow for further manipulation of the currently selected predicate: The sliders on the left set up the color modulation; the controls on the bottom set up optional predicate parameters.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 5 :</head><label>5</label><figDesc>Scribbles painted into cross-sectional slice views (c) Predicate Histogram After Applying Scribbles Illustration of scribble-based Predicate Histogram Setup: (a) shows the original predicate histogram. (b) By delineating image features to show (green scribble along bone structure) and image features to hide (red scribble in skin layer) in the cross-sectional MPRs, the user can configure the predicate histogram directly in the image domain. (c) shows the updated predicate histogram after applying the scribbles.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 6 :</head><label>6</label><figDesc>Visualization results for the shoulder data set together with the used predicate histograms: Compared to the standard transfer functionbased visualization (a), (b) was generated by exploiting the SNR Range predicate to mark fibrous structures in the muscle layer. The final rendering (c) additionally highlights the bone surface as focus region.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 7 :</head><label>7</label><figDesc>Visualization results for the second carotid artery data set together with the used predicate histograms: Compared to the standard transfer function-based visualization (a), the predicate setup in (b) removes the skin layer and highlights vascular structures. The vesselness predicate in (c) allows to further show the vessel path (the bifurcation is only partly present in this data set and thus can not be seen).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 8 :</head><label>8</label><figDesc>Visualization results for the achilles tendon data set together with the used predicate histograms: Compared to the standard transfer function-based visualization (a), (b) highlights the target anatomy (achilles tendon) through the gradient angle predicate and the corresponding label predicate. (c) Shows the final rendering with highlighted fibrous muscle structures as context information using the SNR range predicate.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>(a) Carotid ultrasound data set 1 ( 2 Fig. 9 :</head><label>129</label><figDesc>b) Used predicate histogram (c) Carotid ultrasound data set Results suggest a transferability of predicate histograms between different data sets of the same anatomy: (a) A visualization for carotid data set 1 was created using the predicate histogram (b). This was then applied as preset to carotid data set 2 yielding a very viable visualization (c).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>κ</head><label></label><figDesc>s),α i+1 = mα i (1 − α(s)) + α(s), α i+1 = α i (1 − α(s)) + α(s), i+1 = max(κ i , ln(α(s) + (1 − α(s)) exp(κ i − κ(s))) + κ(s)).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>•</head><label></label><figDesc>Christian Schulte zu Berge, Maximilian Baust, and Nassir Navab are with the Chair for Computer Aided Medical Procedures, Technische Universität München, Germany, E-mail: christian.szb@in.tum.de.</figDesc><table /><note>• Ankur Kapoor is with Imaging and Computer Vision, Siemens Corporation, Corporate Technology, Princeton, NJ, USA, E-mail: ankur.kapoor@siemens.com.</note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGEMENTS</head><p>This research was performed in the course of the CAMPVis project funded within the SoftwareCampus program of the German Federal Ministry of Education and Research (BMBF, Förderkennzeichen 01IS12057).</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Visual Analysis of Cardiac 4D MRI Blood Flow Using Line Predicates. Visualization and Computer Graphics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Born</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pfeifle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Markl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gutberlet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Scheuermann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="900" to="912" />
			<date type="published" when="2013-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Illustrative Context-Preserving Volume Rendering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bruckner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Grimm</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kanitsar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">E</forename><surname>Gröller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EuroVis</title>
		<editor>K. Brodlie, D. J. Duke, and K. I. Joy</editor>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="69" to="76" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Importance-Aware Composition for Illustrative Volume Rendering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>De Moura Pinto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Freitas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Graphics, Patterns and Images (SIB-GRAPI), 2010 23rd SIBGRAPI Conference on</title>
		<imprint>
			<date type="published" when="2010-08" />
			<biblScope unit="page" from="134" to="141" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Journal of Visual Communication and Image Representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">D</forename><surname>Angelini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">F</forename><surname>Laine</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="478" to="490" />
		</imprint>
	</monogr>
	<note>Surface function actives</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Variational classification for visualization of 3D ultrasound data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Fattal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lischinski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Visualization, 2001. VIS &apos;01. Proceedings</title>
		<imprint>
			<date type="published" when="2001-10" />
			<biblScope unit="page" from="403" to="410" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Multiscale vessel enhancement filtering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Frangi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Niessen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Vincken</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Viergever</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Medical Image Computing and Computer-Assisted Interventation -MIC-CAI</title>
		<editor>W. Wells, A. Colchester, and S. Delp</editor>
		<imprint>
			<biblScope unit="volume">1496</biblScope>
			<biblScope unit="page" from="130" to="137" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Statistical shape models for 3D medical image segmentation: A review</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Heimann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H.-P</forename><surname>Meinzer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Medical Image Analysis</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="543" to="563" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">A Quadratic Energy Minimization Framework for Signal Loss Estimation from Arbitrarily Sampled Ultrasound Data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Hennersperger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Mateus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Baust</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Navab</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Medical Image Computing and Computer-Assisted Intervention -MICCAI</title>
		<meeting><address><addrLine>Boston, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Ultrasound confidence maps using random walks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Karamalis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Navab</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Medical Image Analysis</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1101" to="1112" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Brushlet segmentation for automatic detection of lumen borders in ivus images: A comparison study</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Katouzian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Angelini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Sturm</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Laine</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">9th IEEE International Symposium on</title>
		<imprint>
			<date type="published" when="2012-05" />
			<biblScope unit="page" from="242" to="245" />
		</imprint>
	</monogr>
	<note>Biomedical Imaging (ISBI)</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Multidimensional transfer functions for interactive volume rendering. Visualization and Computer Graphics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kniss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Kindlmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Hansen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="270" to="285" />
			<date type="published" when="2002-07" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Semi-Automatic Vortex Extraction in 4D PC-MRI Cardiac Blood Flow Data using Line Predicates. Visualization and Computer Graphics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Kohler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Gasteiger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Preim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Theisel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gutberlet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Preim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2773" to="2782" />
			<date type="published" when="2013-12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">ClearView: An Interactive Context Preserving Hotspot Visualization Technique. Visualization and Computer Graphics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kruger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schneider</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Westermann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="941" to="948" />
			<date type="published" when="2006-09" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Multidimensional TF for effective visualization of streaming US and elasticity images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Mann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">J</forename><surname>Caban</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">J</forename><surname>Stolka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">M</forename><surname>Boctor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">S</forename><surname>Yoo</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="volume">7964</biblScope>
			<biblScope unit="page" from="796439" to="796439" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Shape-based transfer functions for volume visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-S</forename><surname>Prassni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Ropinski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Mensmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Hinrichs</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Pacific Visualization Symposium (PacificVis)</title>
		<imprint>
			<date type="published" when="2010-03" />
			<biblScope unit="page" from="9" to="16" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Visual Computing for Medicine: Theory, Algorithms, and Applications. The Morgan Kaufmann Series in Computer Graphics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Preim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Botha</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
			<publisher>Elsevier Science</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Interaction-dependent Semantics for Illustrative Volume Rendering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Rautek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bruckner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">E</forename><surname>Gröller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th Joint Eurographics / IEEE -VGTC Conference on Visualization, Euro-Vis&apos;08</title>
		<meeting>the 10th Joint Eurographics / IEEE -VGTC Conference on Visualization, Euro-Vis&apos;08<address><addrLine>Aire-la-Ville, Switzerland, Switzerland</addrLine></address></meeting>
		<imprint>
			<publisher>Eurographics Association</publisher>
			<date type="published" when="2008" />
			<biblScope unit="page" from="847" to="854" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Stroke-based Transfer Function Design</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Ropinski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Prassni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Steinicke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Hinrichs</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fifth Eurographics / IEEE VGTC Conference on Point-Based Graphics, SPBG&apos;08</title>
		<meeting>the Fifth Eurographics / IEEE VGTC Conference on Point-Based Graphics, SPBG&apos;08<address><addrLine>Aire-la-Ville, Switzerland, Switzerland</addrLine></address></meeting>
		<imprint>
			<publisher>Eurographics Association</publisher>
			<date type="published" when="2008" />
			<biblScope unit="page" from="41" to="48" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Preprocessing and volume rendering of 3D ultrasonic data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Sakas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L.-A</forename><surname>Schreyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Grimm</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics and Applications</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="47" to="54" />
			<date type="published" when="1995-07" />
			<publisher>IEEE</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">High-Level User Interfaces for Transfer Function Design with Semantics. Visualization and Computer Graphics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Salama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Keller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Kohlmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1021" to="1028" />
			<date type="published" when="2006-09" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Pathline predicates and unsteady flow structures. The Visual Computer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Salzbrunn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Garth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Scheuermann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Meyer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="1039" to="1051" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Orientation-Driven Ultrasound Compounding Using Uncertainty Information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Schulte Zu Berge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kapoor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Navab</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IPCAI</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="236" to="245" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Visualization of boundaries in volumetric data sets using LH histograms. Visualization and Computer Graphics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Sereda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bartroli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">W O</forename><surname>Serlie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Gerritsen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="208" to="218" />
			<date type="published" when="2006-03" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Computer Vision: Algorithms and Applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Szeliski</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010" />
			<publisher>Springer-Verlag New York, Inc</publisher>
			<pubPlace>New York, NY, USA</pubPlace>
		</imprint>
	</monogr>
	<note>1st edition</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">A Novel Interface for Higher-Dimensional Classification of Volume Data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F.-Y</forename><surname>Tzeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">B</forename><surname>Lum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K.-L</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 14th IEEE Visualization 2003 (VIS&apos;03), VIS &apos;03</title>
		<meeting>the 14th IEEE Visualization 2003 (VIS&apos;03), VIS &apos;03<address><addrLine>Washington, DC, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2003" />
			<biblScope unit="page">66</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Fast Volumetric Data Exploration with Importance-based Accumulated Transparency Modulation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Hansen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 8th IEEE/EG International Conference on Volume Graphics, VG&apos;10</title>
		<meeting>the 8th IEEE/EG International Conference on Volume Graphics, VG&apos;10<address><addrLine>Aire-la-Ville, Switzerland, Switzerland</addrLine></address></meeting>
		<imprint>
			<publisher>Eurographics Association</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="61" to="68" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Modified Dendrogram of Attribute Space for Multidimensional Transfer Function Design. Visualization and Computer Graphics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kaufman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="121" to="131" />
			<date type="published" when="2012-01" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
