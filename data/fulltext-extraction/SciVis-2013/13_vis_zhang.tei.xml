<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/pisenberg/grobid/grobid-0.6.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Lighting Design for Globally Illuminated Volume Rendering</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><roleName>Student Member, IEEE</roleName><forename type="first">Yubo</forename><surname>Zhang</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><roleName>Fellow, IEEE</roleName><forename type="first">Kwan-Liu</forename><surname>Ma</surname></persName>
						</author>
						<title level="a" type="main">Lighting Design for Globally Illuminated Volume Rendering</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2021-02-19T19:34+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Global illumination</term>
					<term>lighting design</term>
					<term>volume rendering</term>
					<term>tone mapping</term>
				</keywords>
			</textClass>
			<abstract>
				<p>With the evolution of graphics hardware, high quality global illumination becomes available for real-time volume rendering. Compared to local illumination, global illumination can produce realistic shading effects which are closer to real world scenes, and has proven useful for enhancing volume data visualization to enable better depth and shape perception. However, setting up optimal lighting could be a nontrivial task for average users. There were lighting design works for volume visualization but they did not consider global light transportation. In this paper, we present a lighting design method for volume visualization employing global illumination. The resulting system takes into account view and transfer-function dependent content of the volume data to automatically generate an optimized three-point lighting environment. Our method fully exploits the back light which is not used by previous volume visualization systems. By also including global shadow and multiple scattering, our lighting system can effectively enhance the depth and shape perception of volumetric features of interest. In addition, we propose an automatic tone mapping operator which recovers visual details from overexposed areas while maintaining sufficient contrast in the dark areas. We show that our method is effective for visualizing volume datasets with complex structures. The structural information is more clearly and correctly presented under the automatically generated light sources.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>In volume data visualization, lighting design is a process of setting up light sources for volume rendering. The goal is to enhance the visual perception of the volume data. In real world, human eyes can perceive objects better with the assistance of light. It is also true for volume rendering if light sources are placed appropriately. For example, local structures of isosurfaces can be perceived through local diffuse shading and ambient occlusion. Depth order and thickness can be perceived through global shadow casting and multiple scattering. Lighting design is as important as transfer-function design in volume visualization. Because a good lighting can improve the effectiveness of the visualization while a bad lighting may give a wrong impression of the volume dataset to the user.</p><p>In conventional volume visualization systems, setting up the light sources is often done manually by the user. However, this requires the user to have related knowledge in computer graphics including the shading models and light behaviors as well as the knowledge in arts. It takes time to setup a good lighting environment even for experienced users. The number of light sources, the position, direction and intensity of each light source are all unknown variables which need to be determined. Although a simple directional light can illuminate the volume data, it is not optimal and sometimes can give misleading results. On the other hand, a nicely designed lighting environment can present the volume structural information correctly and accurately, which greatly improves the effectiveness of the volume visualization.</p><p>Due to the limitation of graphics hardware in the early years, interactive volume visualization systems generally adopt simple local illumination models (e.g. local Phong shading) for rendering volume datasets. Therefore, previous studies on lighting design for volume data visualization are also based on local shadings. These proposed techniques mainly focus on enhancing the details of local surfaces and optimize the visual perception on the local structures. However, such methods do not fully exploit the benefit from global illumination and hence, may not produce optimized solutions for globally illuminated volume rendering. For example, the depth order of a cluttered volume dataset may not be well presented. Since global illumination has already been proven useful for volume data visualization <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b10">11]</ref> we have developed a practical automatic lighting design system for such cases which takes global shadow casting and multiple scattering into account.</p><p>In order to achieve interactive global illumination for volume rendering, we adopt a high quality real-time volume rendering technique which fully models light propagation, absorption and scattering under multiple light sources <ref type="bibr" target="#b31">[32]</ref>. Based on the renderer, we implemented a three-point lighting system where the key light and the fill light are used to shade the volume dataset with appropriate contrast and cast the shadows to enhance the depth perception. The back light is used to highlight the rim and relatively thin structures, and to illuminate certain overshadowed regions from the back. The role of back light is often ignored in previous work (e.g. <ref type="bibr" target="#b26">[27,</ref><ref type="bibr" target="#b29">30]</ref>) because it is impossible to fully exploit the back light without light absorption and multiple scattering effects. Our lighting design system can utilize the global light absorption, shadow casting, and multiple scattering to enhance the visual perception including depth and shape perception.</p><p>One issue of using back light in our lighting design system is that certain areas may be overexposed because the opacity can be unevenly distributed and certain thin structures can be penetrated by the back light and illuminated by all the light sources. Without sacrificing the shading quality, overexposure in certain regions of volume datasets is unavoidable with limited amount of light sources. However, increasing the number of light sources will not only increase the complexity of lighting design process, but also increase the cost of real-time volume rendering. Therefore, we further propose an automatic tone mapping operator to recover details from overexposed regions such as the rim and thin structures. Our tone mapping operator also produces better contrast in the dark areas compared to conventional tone mapping operators.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK</head><p>In recent years, involving advanced shading techniques into the interactive direct volume rendering (DVR) has been received much attention. We refer interested readers to the survey <ref type="bibr" target="#b6">[7]</ref>. The screenspace ambient occlusion (SSAO) technique <ref type="bibr" target="#b23">[24]</ref> which renders local shadows by sampling nearby depth values in the image-space, was extended to DVR in <ref type="bibr" target="#b2">[3]</ref>. The limitation of SSAO is that it can only produce local shadows. To avoid certain drawbacks in SSAO such as limited accuracy and overshadowing, Kronander et al. <ref type="bibr" target="#b10">[11]</ref> proposed an efficient visibility encoding technique for object-space occlusion calculation. They first estimate the local visibility at each voxel by sampling nearby voxels and then approximately estimate the global visibility by using the local visibility information and encode the visibility using spherical harmonics. However, as the opacity mapping changes, they need a second to update the visibility volume, which limits the ability of editing the transfer-function in real-time. In order to further reduce the occlusion estimation time, summed area table (SAT) based techniques <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b20">21]</ref> are developed to efficiently lookup the occlusion information approximately. In certain cases the SAT needs to be rebuilt if the opacity mapping is changed. In <ref type="bibr" target="#b19">[20]</ref> light propagation is simulated in the volume-space for shadow and single scattering. Kroes et al. <ref type="bibr" target="#b9">[10]</ref> applied Monte Carlo ray tracing to the DVR which can achieve various global illumination effects including shadow and single scattering. However, it still takes several seconds to converge which affects the interactivity and the rendering results are blurred due to the strong noise filtering. In <ref type="bibr" target="#b31">[32]</ref> a high quality DVR method is developed which fully simulates global shadow and multiple scattering effects in real-time.</p><p>Lighting design is a fundamental topic of computer animation in storytelling and expressing mood <ref type="bibr" target="#b0">[1]</ref> and has been studied for decades. In general, lighting design systems can be classified as three types including direct manipulation, indirect light generation and automatic light generation. Direct light manipulation allows the user to fully control the parameters of each light source. It is widely used in many rendering software applications such as Autodesk Maya <ref type="bibr" target="#b1">[2]</ref>. But it requires the user to have knowledge in computer graphics and digital arts in order to efficiently setup a good lighting environment. It is also not intuitive compared to the indirect light generation. Indirect light generation systems often let the user to specify certain intuitive parameters which are affected by light sources such as highlight and shadow areas in a scene. For example, in <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b16">17]</ref> users are allowed to place shadows or highlights directly and the system can indirectly modify the light sources accordingly to match the user input. In <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b24">25]</ref> users can also paint lights or shadows in the image-space. These systems can solve for the optimal lighting parameters based on the user's paint. Indirect lighting systems provide intuitive interfaces but the light sources cannot be controlled precisely.</p><p>Although intuitive, indirect light generation still requires the user possesses domain knowledge in computer graphics. In many cases such as medical visualization, the user can be an expert from other fields without the knowledge of shading models and light behaviors. Therefore, automatic light generation is desired in these situations. Shacked and Lischinski <ref type="bibr" target="#b22">[23]</ref> proposed a perceptual quality metric for automatic lighting design. The system searches for optimal lighting parameters based on the perceptual quality metric which can be evaluated from the rendered image. Similar strategies such as maximizing the perceptual entropy or visual information are presented in <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b29">30]</ref>. These methods try to optimize the lighting parameters based on an objective function. Lee et al. <ref type="bibr" target="#b11">[12]</ref> introduced a novel light source placement technique where the objects are segmented into local surface patches and assigned to different light sources. Zupko and El-Nasr <ref type="bibr" target="#b32">[33]</ref> developed a system which adapts lighting to the user interaction in real-time by involving perceptual theories and cinematic lighting techniques. Tao et al. <ref type="bibr" target="#b26">[27]</ref> developed an automatic lighting design system by measuring the structural differences between images. It takes the structural information into account during the lighting design process. For general evaluations, we refer readers to <ref type="bibr" target="#b8">[9]</ref> where the benefits of different types of lighting design interfaces are evaluated through a comprehensive user study.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">OVERVIEW</head><p>In general, our lighting system consists of three parts: the automatic light source generation, volume rendering, and exposure optimization. The light source generation module follows the classic three-point lighting setup and computes the light directions and intensities. Note that we only use directional light sources which are easy to manipulate. Our volume rendering module renders the volume dataset under the generated light sources and estimates the global light transportation. The exposure optimization step can recover more details from overexposed areas. <ref type="figure">Fig. 1</ref> shows the workflow of our volume visualization and how the lighting system fits into the whole process. The design of our automatic lighting system meets the following criteria:</p><p>• High Quality Shading The generated light sources should pro- duce high quality shading which leads to a good visual perception of depth and occlusion on the volume dataset.</p><p>• Real-time Response The light source generation should be fast enough in the real-time volume visualization context in order to provide a good user experience.</p><p>• Simple and Intuitive Light Settings The results should involve only a few light sources for better performance and easy adjustments. The light settings should also be intuitive to the user. The direction and the intensity of the light sources should be relatively stable as the camera view changes.</p><p>In the following sections, we first briefly introduce the rendering system and then discuss the light source generation and exposure optimization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">THE RENDERING SYSTEM</head><p>Our rendering system is based on the state of the art techniques <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b31">32]</ref>, where the global light transportation is calculated in the volume-space. For each light source, we compute the light propagation, absorption and multiple scattering on a volume grid. The transportation is modeled using a convection-diffusion partial differential equation and solved numerically. The general model equation has the form</p><formula xml:id="formula_0">∂ ∂t ρ(x) = −cu(x) • ∇ρ(x) − σ a (x)ρ(x) + σ s ∇ 2 ρ(x)<label>(1)</label></formula><p>where t is the time, ρ is the energy density, c is the speed of light, u is the local propagation direction of light, σ a and σ s are the absorption and scattering coefficients, respectively. For any directional light source, we assume the light direction is u D and the energy density of the directional light is ρ D . Assuming that directional lights are used, the following boundary condition is used for Eq. 1</p><formula xml:id="formula_1">ρ(x)| ∂ Ω = ρ D , if n(x) • u D &lt; 0, (2) ∂ ρ(x) ∂ n ∂ Ω = 0, otherwise.<label>(3)</label></formula><p>where x ∈ ∂ Ω is the boundary of the entire volume domain Ω and n(x) is the unit outward normal at x. The steady state solution of Eq. 1 represents the final energy distribution which is emitted from a single light source. Typically, light propagation in the data volume is computed using ray-tracing <ref type="bibr" target="#b7">[8]</ref> or volume photon mapping <ref type="bibr" target="#b4">[5]</ref>. However, these geometry-based or particle-based methods do not fit the volume data structure perfectly because frequent sampling and gathering operations are needed during the computation. Therefore, the first term on the right hand side of Eq. 1 is used for modeling the light propagation over time t from a single light source. The term is a convection term which ensures energy conservation and it is the basis of estimating the global illumination effects.</p><p>The light absorption is modeled using the second term of the right hand side of Eq. 1. This term simply reduces light energy according to the local absorption coefficients which are computed from the local opacity values. Due to the energy reduction, shadows can occur along the light paths. The global shadow effects can greatly enhance the visual perception of depth and occlusion which is important for accurate volume visualization.</p><p>We assume that the volume media is optically thick, so the multiple scattering can be modeled using diffusion <ref type="bibr" target="#b25">[26]</ref>. We use a simple isotropic diffusion term as the last term on the right hand side of Eq. 1 which is adequate for modeling realistic multiple scattering for volume visualization. It adds another layer of realism such that we can have a better sense of object thickness if the volume is illuminated from the back. In addition, the back light also highlights the rim of the volumetric object.</p><p>Eq. 1 together with the boundary conditions Eq. 2 and Eq. 3 are solved numerically on a volume grid, which is called light volume. The numerical computation can be highly parallelized with the assistance of the GPU. We refer readers to <ref type="bibr" target="#b31">[32]</ref> for details. The solution to the equation is then stored into the light volume. A typical volume ray casting algorithm can be performed for the final volume rendering where the global light energy distribution is combined with the local shading at each sampling point along the ray</p><formula xml:id="formula_2">L f inal (x) = L(x) (I a (x) + I d (x) + I s (x))<label>(4)</label></formula><p>where I a , I d and I s are the colors of ambient, diffuse and specular lights, respectively. L f inal (x) is then used as the final lighting color for material shading.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">LIGHTING DESIGN UNDER GLOBAL ILLUMINATION</head><p>The light source generation for volume visualization under global illumination has not been well studied. With global illumination effects, more structural information can be presented if the light sources are placed appropriately. We discuss the placement of each light source in our system, including the key light, the fill light and the back light. Instead of modeling a quality metric and iteratively refine the light parameters, we try to collect the statistical information from the volume dataset and setup the light sources using an empirical lighting design model. This leads to a lighting setup that is close to a manually designed lighting environment and it is unlikely to generate unexpected light configurations in any case. The details are discussed in the following subsections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Key Light</head><p>The key light in the lighting system controls the global shading. Intuitively, a good key light source can produce appropriate contrast on the volume dataset. Instead of iteratively searching the direction which maximizes the contrast measurement in the image-space, we propose a fast and intuitive method for placing the key light, which is stable and closer to human design process. This is done by observing the distribution of surface normals and placing the key light to generate balanced highlight, mid-tone and shadow areas. <ref type="figure" target="#fig_0">Fig. 2</ref> shows a good example of placing the key light source. To achieve this, we employ a statistical approach to guide the key light direction which is explained in the following subsections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.1">Normal Vector Distribution</head><p>To study the distribution of the visible surface normals, we have to compute the mean and spatial variation of these normal vectors. We analyze the distribution of the normal vectors in the image-space. This is faster than volume-space computation due to the space and time complexity. For semi-transparent volumes, there can be multiple visible samples that contribute to each pixel. The sample with highest contribution dominates the visual perception based on the adopted rendering model. Here, the contribution refers to the final alpha value that contributes to a pixel from a sample located at position x, which can be evaluated throughα</p><formula xml:id="formula_3">(x) = α(x)e − xc</formula><p>x α(t)dt whereα is the final alpha contribution, α is the local alpha value in the volume space, and x c is the camera position. So for each pixel, we pick the sample along the corresponding ray with the maximumα value. Assume the selected samples have local unit surface normals n k where k = 1, 2, . . . , m and m is the number of non-empty pixels. We first compute the mean of these normals n a = 1 m ∑ m 1 n k . Then the offset of each normal vector from the mean normal vector is computed through d k = n k − n a where θ k is the angle difference and d k is the rotation axis. Finally, the principal component analysis <ref type="bibr" target="#b5">[6]</ref> is performed on the set {d k |k = 1, 2, . . . , m} to get the principal vectors {v 1 , v 2 , v 3 } and its corresponding variance {λ 1 , λ 2 , λ 3 }. We use the resulting data as a guide for key light setup.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.2">Key Light Setup</head><p>Assume the diffuse shading C d [n • (−l)] is dominant where C d is the light color, n is the outward unit normal, and l is the light direction. It is obvious that we can produce higher shading contrast along the direction of the first principal vector v 1 because the normal vector distribution has the highest variance λ 1 along v 1 . An extreme case would be the curved surface of a cylinder. Following this intuition, we define two characteristic normal vectors n + = n a + λ 1 v 1 and n − = n a − λ 1 v 1 . If we set the key light direction to −n + , then the areas with normal vectors close to n + will be highlighted and the areas with normal vectors close n − will be shadowed unless the visible areas are relatively flat. Setting key light direction to either −n + or −n − can produce good shading contrast where the highlight, mid-tone and shadow areas are balanced. According to the study <ref type="bibr" target="#b14">[15]</ref>, we choose the one from top where the y-component of the direction vector of key light is negative. The other direction is then used for fill light which is discussed in the next section. We set the intensity of the key light I k = 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Fill Light</head><p>The fill light is used to illuminate the shadow areas in order to make the details in the shadow areas visible. Following the previous section, the direction of the fill light is already determined, which can be either −n − or −n + according to the selection of the key light. The y-component of the direction vector of fill light is non-negative. In addition to the direction, we also have to choose an appropriate intensity for the fill light. If the variance of the normal vector distribution is low, which means the visible areas are relatively flat, then there is no overshadowed areas and the fill light is even not necessary. On the other hand, we need the fill light if the variance λ 1 is high because there would be more overshadowed areas. Therefore, we set the fill light intensity based on the variance I f = c f λ 1 where c f &lt; I k is a scaling constant for the fill light intensity. In our system c f is a configurable parameter. <ref type="figure">Fig. 3</ref> shows two typical examples with different variance values of the normal vector distribution. It gives the intuition of how the intensity of the fill light is set based on the variance λ 1 .</p><p>(b) High Variance Case <ref type="figure">Fig. 3</ref>. (a) A typical case where the surface is relatively flat and the variance λ 1 is low. In this case, the intensity of the fill light should be low in order to maintain the contrast produced by the key light. (b) Another typical case where the variance λ 1 is close to 1/2 and half of the surface is completely shadowed. In this case the fill light can have a relatively high intensity value.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Back Light</head><p>The back light has an important role in the lighting design. Its capability can be fully exploited by global illumination including light absorption and multiple scattering. In photography, the back light is often used for highlighting the rim of the object or character. It can also be applied to the volume rendering and an example is shown in <ref type="figure" target="#fig_1">Fig. 4</ref>. We can see that the back light highlighted the backside of the object and improves the depth cue. In our system, the direction of the back light is simply set to the opposite direction of the camera view. The tricky part is to estimate an appropriate intensity value for the back light. While a lower intensity value can make the back light fully occluded by the object, a higher intensity value can also penetrate the object and make it over-illuminated. Therefore, we have to measure the opacity distribution of the volume dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.1">Accumulated Opacity Distribution</head><p>Similar to estimating the final alpha contribution in Eq. 5, we can also estimate the accumulated opacity A k along each camera ray direction d k in the image-space</p><formula xml:id="formula_4">A k = x c +s max d k x c α(t)dt (6)</formula><p>where x c is the camera position, s max is the maximum ray distance, α(t) is the opacity at position t, k = 1, 2, . . . , m, and m is the number of non-empty pixels. Then we can compute the mean A a and the variance A v from the set {A k |k = 1, 2, . . . , m}. With the opacity distribution, we can estimate the intensity of the back light at the reasonable scale.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.2">Back Light Setup</head><p>Assume that the back light can penetrate most part of the volume dataset, the following condition must hold</p><formula xml:id="formula_5">I b e −A a − √ A v &gt;= I ε<label>(7)</label></formula><p>where I b is the intensity of the back light, A a is the mean accumulated opacity, A v is the variance of accumulated opacity, and I ε is the lowest perceivable light intensity. The intuition behind Inequality 7 is that most areas have accumulated opacity values less than A a + √ A v by the definition of variance. Therefore, it is straightforward to find the lowest back light intensity that satisfies Inequality 7:</p><formula xml:id="formula_6">I b = I ε e A a + √ A v .<label>(8)</label></formula><p>I ε &lt;&lt; 1 is a configurable variable in our lighting system. Note that I ε is a data-independent value. Once set, the system can automatically compute the appropriate back light intensity for each case. This is much more convenient than adjusting the back light intensity manually.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.3">Color of the Back Light</head><p>In addition to the direction and intensity of the back light, the color of the back light can also be utilized. Using colors to illuminate shadow areas can improve the visual perception <ref type="bibr" target="#b28">[29]</ref>. In certain cases, if we set the back light source to a different color than the key light, we can have a better depth perception on the volume dataset since the rear part of the data will be illuminated in this color. It can also be used to evaluate the thickness of local structures because thin structures will be penetrated by the back light and the color will look different than thick structures. The use of the back light is evaluated in Section 8.</p><p>In certain extreme cases, The generated key and fill light directions can be quite different from the camera direction if the surface variance is big. Hence the light path between the camera focus point and the key light or even the fill light can be occluded. However, the structures around the focus point would not be overshadowed due to our strong back light penetration and scattering. They can be even highlighted by the back light color. We show a good example in <ref type="figure" target="#fig_0">Fig. 12</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">IMAGE-SPACE OPTIMIZATION</head><p>With the approach discussed in Section 5, we can already generate an appropriate three-point lighting environment for a volume dataset. However, certain areas in the image can be overexposed. This often happens when there are thin structures in the volume dataset which can be over-illuminated by the strong back light together with the key light.To avoid this, we automatically generate a special tone curve to optimize the exposure in highlight and shadow regions. Tone mapping is typically used in digital photo processing (e.g. <ref type="bibr" target="#b18">[19]</ref>) and is also applied to HDR rendering (e.g. <ref type="bibr" target="#b30">[31]</ref>). In our system, the goal is to generate a tone curve that can compress the highlight while maintain the contrast in the shadow area. In <ref type="bibr" target="#b18">[19]</ref>, a simple tone mapping operator was discussed which maps an average luminance value to 0.5 and compresses the highlight region:</p><formula xml:id="formula_7">L ′ = L L + M<label>(9)</label></formula><p>where L is the original luminance value, L ′ is the mapped luminance value, and M is the log-average luminance. It is obvious that Eq. 9 can map the value M to 0.5 and map the infinity to 1 which compresses the overexposed areas. However, Eq. 9 also reduces the contrast in the shadow area where L &lt; M. To remedy this, we introduce a modified tone mapping operator</p><formula xml:id="formula_8">L ′ = tL L + M + (1 − t)L 2 2M 2<label>(10)</label></formula><p>where t = min{L/M, 1}. Here the term L 2 2M 2 is used to control the contrast in the shadow areas and it is blended into the original tone mapping operator. The tone curves of Eq. 9 and Eq. 10 are plotted in <ref type="figure" target="#fig_2">Fig. 5</ref>. We can see that the contrast of the shadow area is enhanced in our modified tone curve. We discuss the implementation and results in the following sections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">IMPLEMENTATION</head><p>The implementation of our system is based on the OpenGL library and NVIDIA CUDA <ref type="bibr" target="#b13">[14]</ref>. We also use G3D <ref type="bibr" target="#b12">[13]</ref> as the application framework and user interface. The subsystems include lighting setup, volume rendering and exposure optimization and the detailed implementations are discussed in the following subsections. We summarize our method in Algorithm 1. In the automatic light source generation stage, we first use a standard volume ray casting to render the whole volume into a float-point frame buffer. Instead of writing colors into the frame buffer, we record the normal vectors and accumulated opacity values in the float-point RGBA channels. These values can be estimated during the volume ray casting. Then the frame buffer values are packed into an array for PCA and mean/variance computation where pixels with zero alpha values are discarded. Here the PCA computation is performed on a separate CPU thread. The results are then used for setting the direction and intensity of the light sources. The light source parameters are finally passed to the volume renderer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 1 Lighting Setup for Volume Visualization under Global</head><p>The volume renderer creates two 3D textures for storing the original dataset and the light volume. It also creates several GPU arrays for light simulation. In the lighting simulation step, Eq. 1 is firstly solved using CUDA acceleration for each light source. Then the result is written into the light volume. Finally, the light volume is combined with the standard volume ray casting and the image is rendered into an HDR frame buffer for tone mapping.</p><p>In the exposure optimization stage, we first compute the log-average luminance from the HDR frame buffer through parallel reduction. Then Eq. 10 is applied to all the pixels in the frame buffer and the final image is obtained. The tone mapping is implemented in a GLSL shader.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">RESULTS AND EVALUATION</head><p>In this section, we present various results produced to validate and evaluate our lighting system. The evaluation includes basic functional evaluation and real case studies. We first validated our modified tone mapping operator discussed in Section 6. A volume dataset with randomly distributed tubes is used. We set up a directional light with strong intensity and made the light source directly face to the volume. Then we rendered the volume dataset and applied tone mapping operators Eq. 9 and Eq. 10. We compared the rendering results with and without applying tone mapping operators in <ref type="figure" target="#fig_3">Fig. 6(a)</ref>-(c). We found that the simple operator in Eq. 9 is effective in compressing the highlights and our modified operator Eq. 10 can further improve the contrast in the dark areas. We also evaluated how our automatically generated light sources can improve the presentation of structural information. In this test, a dataset with cluttered tubes are used which has rich structural information. From this kind of data, we usually get poor depth perception under local illumination and we try to find out if our lighting system helps. In <ref type="figure" target="#fig_4">Fig. 7</ref>, we compare the rendering results with different light settings. It is shown that the distribution of the tubes looks flat in <ref type="figure" target="#fig_4">Fig.  7(a)</ref> where the volume is rendered using conventional volume renderer with local illumination. <ref type="figure" target="#fig_4">Fig. 7</ref>(b)-7(d) show the rendering results using our lighting system. To evaluate the contribution of each light source, we split the lighting into three settings. It is clearly shown that with only the key light which comes from the front-right side, the depth perception can already be improved greatly. The fill light from the front-left side then illuminates certain overshadowed areas. Finally, the blue colored back light further improves the shading such that we can realize the depth of the tubes from the shading color. The overshadowed deep areas are also illuminated in blue by the back light. From this experiment, we conclude that our lighting system is effective for visualizing volume datasets with cluttered spatial structures and can greatly improve the depth perception on the datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.1">Exposure Optimization</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.2">Depth Perception</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.3">Light Direction Evaluation</head><p>To evaluate the automatically generated key light and fill light directions, we show a set of examples in <ref type="figure">Fig. 8</ref> where two datasets are rendered with different camera positions and transfer functions. It is shown that the key light directions always deviate from the view directions, which leads to better shading and contrast. It is close to the use of key lights in photography which can produce images with better 3D-look than using headlights. The fill light effects are subtle and cannot be ignored in most cases. While in <ref type="figure">Fig. 8(g</ref>)-(i) the fill light effect is obvious, it can also illuminate most overshadowed small structures in certain cases. <ref type="figure">Fig. 9</ref> compared our automatically generated light settings to the headlight and randomly generated lights which deviate from the headlight direction. The flow dataset used has higher surface normal variance in the vertical direction. Our algorithm can capture this structural feature and generate an appropriate key light direction which produces good shading contrast and cast shadows vertically, as shown in 9(a). Using headlight, however, tends to produce a flat shading, as shown in 9(b), and the global illumination effect is weakened. We also generate a number of random light directions within 90 degrees from the camera direction. Here 9(c) and 9(d) are two representative cases. The specular lighting effects are missing in 9(c) due to a large deviation of the key and fill light directions. The depth perception in 9(d) is better than 9(b) and 9(c) but not as good as 9(a).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.4">Frame-to-frame Coherence</head><p>We also studied the frame-to-frame coherence of our automatically generated light directions by moving the camera around the volume dataset. We used a separate thread to calculate the PCA and continuously update the light directions. <ref type="figure" target="#fig_9">Fig. 10</ref> shows several frames captured from a camera moving test. These frames are chosen where the change of light directions are more obvious than other frames. The whole animation is provided in the supplementary video. In general, the directions of light sources change smoothly according to the continuous camera motion as the distribution of surface normals remains stable. The only exception is that the key light and the fill light can swap when they have similar y-component. This is caused by the strategy of choosing the key light described in Section 5.1.2. We also tested the frame-to-frame coherence when changing the transfer functions. <ref type="figure" target="#fig_5">Fig. 11</ref> shows several examples where the light sources are generated based on different transfer functions. It is shown that changing transfer functions may affect the light directions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.5">Case Studies</head><p>We applied our lighting system to several datasets including a scanned mechanical part, a vortex field from a combustion simulation, and a CT scan of a patient's hand who has orthopedic disease.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.5.1">Mechanical Part</head><p>Our first case is a scanned mechanical part dataset shown in <ref type="figure" target="#fig_0">Fig. 12</ref>. The mechanical part has some nested structure around the center. In <ref type="figure" target="#fig_0">Fig. 12(e)</ref>, the dataset is rendered using local shading under our automatically generated light sources. Although all the details can be clearly seen, we cannot determine the depth order of the structures   <ref type="figure" target="#fig_0">Fig. 12</ref>. Comparing the local shading and the global shading using the same light settings generated using our algorithm for a scanned mechanical part. Note the center area in (e), where local shading can give a wrong impression of the depth order. The blue back light together with light absorption and multiple scattering effects can enhance the depth perception. Note that our algorithm can compute an appropriate intensity which makes the back light penetrates the volume object while maintain a good contrast.</p><p>around the center since the back light effect is not visible in local illumination. It seems that the concave regions are closer to the camera and the surrounding vertical surfaces look flat. By using global shading under the same light setting, the concave regions are correctly shaded. In <ref type="figure" target="#fig_0">Fig. 12(d)</ref>, these regions are shadowed by the key light and are highlighted by the back light. The surrounding vertical surfaces also have a smooth transition from white to blue, which indicates the depth change. This case also shows the importance of the back light under global illumination. Without the back light, the concave regions  can be overshadowed, as shown in <ref type="figure" target="#fig_0">Fig. 12(b)</ref> and 12(c) where both the key light and the fill light cannot cover the overshadowed regions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.5.2">Vortex Field</head><p>Our second case is a turbulent vortex field which comes from a combustion simulation. The tangled vortex structures are difficult to visualize using local shading, as shown in <ref type="figure" target="#fig_10">Fig. 13(a)</ref>. It seems all the structures are in a flat plane and the fine scale details are not clearly presented. In <ref type="figure" target="#fig_10">Fig. 13(b)</ref>, we use global illumination to render the vortex field. As a result, the depths of all different vortex layers are clearly visualized. The key light is placed to illuminate the top-front of the dataset, which is similar to <ref type="figure">Fig. 9(a)</ref>. The shadows are cast from the upper vortex layers to the lower vortex layers which make the structural information well presented.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.5.3">Patient Hand</head><p>Our third case is a CT scan of a patient's left hand. The patient has orthopedic disease and there are several holes at the joints due to the erosion. The goal is to observe these holes and analyze the situation of the recovery process. In <ref type="figure" target="#fig_1">Fig. 14(e)</ref>, the dataset is visualized using local shading under our automatically generated light sources. We use red boxes to mark certain areas which were ambiguous to the experts. In    <ref type="figure" target="#fig_1">Fig. 14(e)</ref>, they could only identify rapid changes in surface topology, but were not able to tell if these corresponded to true erosions. The local shading does not always convey the appropriate depth information, which makes interpretation sub-optimal. In <ref type="figure" target="#fig_1">Fig. 14(d)</ref>, with the same light sources, the expert users concluded that they could better identify the true erosions and their extent. The more realistic portrayal of the erosions seems to provide adequate level of detail and allows the experts to focus on the relevant parts of the bone. The blue colored back light also highlights the deep holes and the rim of the bones which are overshadowed in <ref type="figure" target="#fig_1">Fig. 14(c)</ref>.Based on the evaluation from expert users, we conclude that our lighting design system is effective for certain cases in medical visualization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.5.4">Supernova</head><p>We also evaluated our lighting system for a supernova dataset with different camera views and transfer-functions, which is shown in <ref type="figure" target="#fig_2">Fig. 15</ref>.</p><p>For each camera and transfer-function setting, our system can generate optimized lighting that achieves good depth cue. <ref type="figure" target="#fig_2">Fig. 15(a)</ref> is a global view of the supernova. <ref type="figure" target="#fig_2">Fig. 15(b)</ref> is a close up view which visualizes the outer core. In 15(c) we removed the outer core to reveal the internal structures. In 15(d), we rendered the dataset from a different view. All four images have different transfer functions and the illuminations from our generated lights provide good visual perceptions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.5.5">Additional Results</head><p>Some additional results are shown in <ref type="figure" target="#fig_3">Fig. 16</ref> and <ref type="figure" target="#fig_4">Fig. 17</ref>. In <ref type="figure" target="#fig_3">Fig.  16</ref>, a scanned upper human body is visualized using different camera views. Our lighting system can generate appropriate view-dependent light sources based on each camera view. In <ref type="figure" target="#fig_4">Fig. 17</ref>, we show another vortex field rendered using our automatic lighting. We also reduced the opacity of outer layers. We can see that all the features are well shaded. The contrast makes these features distinguishable to the viewer.  <ref type="figure">Fig. 18</ref>. The performance of our light source generation mainly depends on the number of samples in the image-space that we used for estimating normal vector distribution and accumulated opacity distribution. Note that the x-axis is in log scale.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.6">Performance</head><p>We measured the time needed for light source generation on a laptop with Intel Quad-core 1.7GHz CPU and NVIDIA Geforce GTX460M GPU, which is plotted in <ref type="figure">Fig. 18</ref>. The computation time is related to the number of samples we used for analyzing normal vector distribution and accumulated opacity distribution. The number of samples highly depends on the rendering resolution. The main steps include the sample collection which needs a volume ray casting operation and the PCA computation. In our experiments, the average time taken for light source generation is less than 500ms. Since we use a separate CPU thread for the PCA computation, it is fast enough for interactive rendering systems. The lights are updated every 10-20 frames approximately while the rendering frame rate is above 30 fps. Currently the PCA computation is implemented on CPU which takes up 95 percent of the total computation time. We believe a full GPU implementation can further increase the performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9">CONCLUSION</head><p>In this paper, we present a novel automatic lighting design system for volume visualization under global illumination. It takes global light transportation into account during the lighting design process. Our system can automatically generate the key light, the fill light and the back light for a volume dataset by analyzing the structural information statistically and can fully utilize the back light for volume visualization. We verified our technique through various experiments and evaluated our lighting system through several case studies. We conclude that our lighting design method for globally illuminated volume visualization is effective for volume datasets with complex and fine structures. The performance of our method also makes it practical for interactive systems which should provide instant feedback to the user. Most importantly, we free the users of our system from worry-ing about setting up lighting parameters so they can focus on locating features of interest by picking good views and transfer functions for property mapping. However, our method also has limitations. First, it may not be applied to view-independent cases because the result is optimized for the camera view. Second, it is not applicable in cases where more than three light sources must be used. In addition, our method may not give optimal results for extremely complex datasets where point light sources are needed to illuminate internal structures that directional lights cannot reach. It does not take depth information into account.</p><p>In the future, we will extend our lighting design method to timevarying volume datasets, which are commonly found in scientific applications. We will also improve our system by supporting more than three light sources, including point light sources which can be used to highlight certain features in the volume.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 2 .</head><label>2</label><figDesc>An example of the key light source placement. The light direction is chosen such that the highlight, mid-tone, and shadow areas are balanced. The gray curve is the surface. The blue arrows are local surface normals. The yellow arrow is the light direction. The color of each circle dot indicates the illumination level.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 4 .</head><label>4</label><figDesc>Comparison of the back light effects under local and global illumination. In the global case (b), the backside of the object is highlighted in blue, which provides additional depth cue.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 5 .</head><label>5</label><figDesc>Comparison between the simple tone mapping operator and our modified operator. Here we set M = 0.5 as an example. The blue line is the simple operator and the red line is our modified operator. The red curve can enhance the contrast in the shadow area where L &lt; M while maintain some of the properties of the simple operator including the mid-point mapping and highlight compressing.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 6 .</head><label>6</label><figDesc>Evaluation of our tone mapping operator. (a) Rendering without tone mapping; (b) Rendering with simple tone mapping operator; (c) Rendering with our modified operator. Note that our operator produces better contrast in the darker area.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 7 .</head><label>7</label><figDesc>Comparison between local illumination (a) and global illumination (b)-(d) under the automatically generated light sources by our lighting system. Here we also split the contribution of these light sources into (b) key light, (c) key+fill lights and (d) key+fill+back lights. We can clearly see how these light sources can enhance the depth perception of the volume dataset under global illumination.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 11 .</head><label>11</label><figDesc>An example of frame-to-frame coherence test by changing the transfer function. Light sources are updated if the opacity mapping changes. Here we use the camera view for rendering.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 8 . 2 Fig. 9 .</head><label>829</label><figDesc>Evaluation of automatically generated key light and fill light positions based on our algorithm. Key lights are rendered in white and fill lights are rendered in gray. We also provide the results where fill lights are ignored. In certain cases there are overshadowed areas marked by red boxes.(g)-(i) shows an example where the fill light effects are strong. Comparison among automatically generated light directions (a), headlight (b) and randomly generated light directions (c)&amp;(d). The top row shows the light settings and the bottom row shows the corresponding rendering results.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig. 10 .</head><label>10</label><figDesc>An example of frame-to-frame coherence test by moving the camera around the volume dataset. Light sources are continuously updated using our system. Here the back light is shown in blue. These frames are chosen where the change of light directions are more obvious than other frames. Note the swap between key light and fill light after frame 130 which is caused by the strategy of choosing the key light described in Section 5.1.2.(a) Local Shading (b) Global Shading</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Fig. 13 .</head><label>13</label><figDesc>(a) Vortex field visualized using local shading; (b) Vortex field visualized using global shading. The automatically generated light sources are similar toFig. 9(a)with an additional back light source in white. Note that the shadows in (b) make the structural information better presented.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Fig. 14 .</head><label>14</label><figDesc>Comparing the local shading and the global shading using our lighting design system for a CT scan of a patient's hand. Note the red boxes in (e), where local shading can give a wrong impression of the depth order. These structures are correctly visualized in (d) with the assistance of light absorption, multiple scattering and an appropriate back light intensity.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Fig. 15 .Fig. 16 .Fig. 17 .</head><label>151617</label><figDesc>Visualization of a supernova dataset using different camera views and transfer-functions. Our system automatically generates optimized light sources for each camera and transfer-function combination where the global structures and the local features are well shaded.(a) Right View (b) Front View (c) Back View Visualization of a scanned human body using different camera views. Our lighting system can generate appropriate light sources for each view. Here a blue back light is used. (a) High Opacity (b) Medium Opacity (c) Low Opacity Another visualization of a vortex field from combustion simulation. The global opacity is adjusted to reveal the internal structures. Good contrast is achieved for both the large and the small scale features.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>,</head><label></label><figDesc>• YuboZhang  is with UC Davis. E-mail: ybzhang@ucdavis.edu. • Kwan-Liu Ma is with UC Davis. E-mail: ma@cs.ucdavis.edu. Manuscript received 31 March 2013; accepted 1 August 2013; posted online 13 October 2013; mailed on 4 October 2013. For information on obtaining reprints of this article, please send e-mail to: tvcg@computer.org.</figDesc><table /><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS</head><p>This research has been sponsored in part by the National Science Foundation through grants OCI-0905008, OCI-0850566, OCI-0749227, and CCF-0811422, and also the Department of Energy through grants DEFC02-06ER25777, DE-CS0005334, and DE-FC02-12ER26072.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Advanced RenderMan: Creating CGI for Motion Picture</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Apodaca</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Gritz</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999" />
			<publisher>Morgan Kaufmann Publishers Inc</publisher>
		</imprint>
	</monogr>
	<note>1st edition</note>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Autodesk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Maya</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Real-time ambient occlusion and halos with summed area tables</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Díaz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Vázquez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Navazo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Duguet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computers &amp; Graphics</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="337" to="350" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Maximum entropy light source placement</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gumhold</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of IEEE Visualization</title>
		<meeting>of IEEE Visualization</meeting>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="275" to="282" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Efficient simulation of light transport in scences with participating media using photon maps</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">W</forename><surname>Jensen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">H</forename><surname>Christensen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of SIGGRAPH</title>
		<meeting>of SIGGRAPH</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="1998" />
			<biblScope unit="page" from="311" to="320" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Principal Component Analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">T</forename><surname>Jolliffe</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1986" />
			<publisher>Springer-Verlag</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Interactive Volume Rendering with Volumetric Illumination</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Jönsson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Sundén</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ynnerman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Ropinski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Eurographics STAR program</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Ray tracing volume densities</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">T</forename><surname>Kajiya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">P</forename><surname>Von Herzen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIG-GRAPH Comput. Graph</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="165" to="174" />
			<date type="published" when="1984" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Toward evaluating lighting design interface paradigms for novice users</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">B</forename><surname>Kerr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Pellacini</surname></persName>
		</author>
		<idno>26:1-26:9</idno>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Graph</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="2009-07" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Exposure render: An interactive photo-realistic volume rendering framework</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kroes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">H</forename><surname>Post</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">P</forename><surname>Botha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS ONE</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page">38586</biblScope>
			<date type="published" when="2012-07" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Efficient visibility encoding for dynamic illumination in direct volume rendering. Visualization and Computer Graphics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kronander</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Jonsson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Low</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Ljung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ynnerman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Unger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="447" to="462" />
			<date type="published" when="2012-03" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Light collages: Lighting design for effective visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Hao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Varshney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE Visualization</title>
		<meeting>IEEE Visualization</meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="281" to="288" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mcguire</surname></persName>
		</author>
		<ptr target="http://g3d.sourceforge.net/" />
		<title level="m">G3D innovation engine</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Nvidia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Cuda C Programming Guide</surname></persName>
		</author>
		<ptr target="http://docs.nvidia.com/" />
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">The assumed light direction for perceiving shape from shading</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">P</forename><surname>Shea</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">S</forename><surname>Banks</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Agrawala</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 5th symposium on Applied perception in graphics and visualization, APGV &apos;08</title>
		<meeting>the 5th symposium on Applied perception in graphics and visualization, APGV &apos;08</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="135" to="142" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Lighting with paint</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Pellacini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Battaglia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">K</forename><surname>Morley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Finkelstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Graph</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2007-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">A user interface for interactive cinematic shadow design</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Pellacini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Tole</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Greenberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Graph</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="563" to="566" />
			<date type="published" when="2002-07" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Lights from highlights and shadows</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Poulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Fournier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of I3D</title>
		<meeting>of I3D</meeting>
		<imprint>
			<date type="published" when="1992" />
			<biblScope unit="page" from="31" to="38" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Photographic tone reproduction for digital images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Reinhard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Stark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Shirley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ferwerda</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Graph</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="267" to="276" />
			<date type="published" when="2002-07" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Interactive volumetric lighting simulating scattering and shadowing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Ropinski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Döring</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Rezk-Salama</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">PacificVis</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="169" to="176" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Extinction-based shading and illumination in gpu volume ray-casting. Visualization and Computer Graphics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Schlegel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Makhinya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Pajarola</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="1795" to="1802" />
			<date type="published" when="2011-12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Painting with light</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Schoeneman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dorsey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Smits</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Arvo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Greenberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 20th annual conference on Computer graphics and interactive techniques, SIGGRAPH &apos;93</title>
		<meeting>the 20th annual conference on Computer graphics and interactive techniques, SIGGRAPH &apos;93</meeting>
		<imprint>
			<date type="published" when="1993" />
			<biblScope unit="page" from="143" to="146" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Automatic lighting design using a perceptual quality metric</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Shacked</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lischinski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Graph. Forum</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="215" to="227" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Hardware accelerated ambient occlusion techniques on gpus</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Shanmugam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Arikan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of I3D</title>
		<meeting>of I3D</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="73" to="80" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Crayon lighting: sketch-guided illumination of models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Shesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 5th international conference on Computer graphics and interactive techniques in Australia and Southeast Asia, GRAPHITE &apos;07</title>
		<meeting>the 5th international conference on Computer graphics and interactive techniques in Australia and Southeast Asia, GRAPHITE &apos;07</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="95" to="102" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Multiple scattering as a diffusion process</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Stam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of EGWR</title>
		<meeting>of EGWR</meeting>
		<imprint>
			<date type="published" when="1995" />
			<biblScope unit="page" from="41" to="50" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Structureaware lighting design for volume visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Clapworthy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Bao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Vis. Comput. Graph</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2372" to="2381" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Automatic light source placement for maximum visual information recovery</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P.-P</forename><surname>Vázquez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Graph. Forum</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="143" to="156" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Chromatic shadows for improved perception</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Šoltészová</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Patel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Viola</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of NPAR</title>
		<meeting>of NPAR</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="105" to="116" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Lighting system for visual perception enhancement in volume rendering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">E</forename><surname>Kaufman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="67" to="80" />
			<date type="published" when="2013-01" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">High dynamic range volume visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">X</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">H</forename><surname>Porter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of IEEE Visualization</title>
		<meeting>of IEEE Visualization</meeting>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Fast global illumination for interactive volume visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K.-L</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of I3D</title>
		<meeting>of I3D</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">A tool for adaptive lighting design</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zupko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">S</forename><surname>El-Nasr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2008 ACM SIGGRAPH symposium on Video games, Sandbox &apos;08</title>
		<meeting>the 2008 ACM SIGGRAPH symposium on Video games, Sandbox &apos;08</meeting>
		<imprint>
			<biblScope unit="page" from="135" to="142" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
