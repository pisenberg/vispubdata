<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/pisenberg/grobid/grobid-0.6.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Registration Techniques for Using Imperfect and Partially Calibrated Devices in Planar Multi-Projector Displays</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ezekiel</forename><surname>Bhasker</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><roleName>Student, IEEE</roleName><forename type="first">Ray</forename><surname>Juang</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><roleName>Member, IEEE</roleName><forename type="first">Aditi</forename><surname>Majumder</surname></persName>
						</author>
						<title level="a" type="main">Registration Techniques for Using Imperfect and Partially Calibrated Devices in Planar Multi-Projector Displays</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2021-02-20T19:44+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Geometric calibration</term>
					<term>photometric calibration</term>
					<term>tiled displays</term>
				</keywords>
			</textClass>
			<abstract>
				<p>Multi-projector displays today are automatically registered, both geometrically and photometrically, using cameras. Existing registration techniques assume pre-calibrated projectors and cameras that are devoid of imperfections such as lens distortion. In practice, however, these devices are usually imperfect and uncalibrated. Registration of each of these devices is often more challenging than the multi-projector display registration itself. To make tiled projection-based displays accessible to a layman user we should allow the use of uncalibrated inexpensive devices that are prone to imperfections. In this paper, we make two important advances in this direction. First, we present a new geometric registration technique that can achieve geometric alignment in the presence of severe projector lens distortion using a relatively inexpensive low-resolution camera. This is achieved via a closed-form model that relates the projectors to cameras, in planar multi-projector displays, using rational Bezier patches. This enables us to geometrically calibrate a 3000 × 2500 resolution planar multi-projector display made of 3 × 3 array of nine severely distorted projectors using a low resolution (640 × 480) VGA camera. Second, we present a photometric self-calibration technique for a projector-camera pair. This allows us to photometrically calibrate the same display made of nine projectors using a photometrically uncalibrated camera. To the best of our knowledge, this is the first work that allows geometrically imperfect projectors and photometrically uncalibrated cameras in calibrating multi-projector displays.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Multi-projector displays are popular today for many applications such as visualization, entertainment, training, and simulation. Contemporary researchers envision future workspaces with ubiquitous pixels rendered by multi-projector displays of various scales and forms aiding users in collaboration, interface, and visualization <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b35">36]</ref>.</p><p>To enable such readily accessible multi-projector displays, automated camera-based registration techniques that register the imagery coming from multiple projectors, both geometrically and photometrically, have been proposed <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b37">38]</ref>. More recently, Bhasker, et al. <ref type="bibr" target="#b1">[2]</ref>, proposed a distributed network of compact projector-camera units that can self-register without any user input, relieving the user of installation and maintenance responsibilities. However, all these methods do not handle imperfections, such as lens distortions, that are common in inexpensive commodity devices. They assume pre-calibrated devices (i.e., devices whose geometric and photometric parameters are known) leaving the responsibility of device calibration to the user. Device calibration is often more challenging than multi-projector display registration and demands a very educated user. This difficulty in deployment has quarantined tiled projection-based displays to national laboratories and universities despite huge advances in automated camera-based registration techniques.</p><p>The work in this paper makes initial advances by developing geometric and photometric registration techniques that allow imperfect uncalibrated devices to be used for the most common cases of planar displays. The ultimate goal would be to allow the use of projectors with severe geometric and photometric distortion and still achieve acceptable geometric and photometric registration. We achieve this goal using cameras that are neither geometrically nor photometrically registered. The paper by Majumder and Stevens <ref type="bibr" target="#b20">[21]</ref> is the only work to date in this direction and presents initial methods to handle large spatial variation in intensity within and across projectors. In this paper, we make further advances to these unexplored domains. These are: (a) achieving geometric registration while using projectors that have considerable geometric imperfections (e.g., lens distortions); (b) achieving photometric registration with a photometrically uncalibrated camera.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1">Using Geometrically Imperfect Projectors</head><p>We present a new geometric registration technique that can correct for severe lens distortion using a relatively low-resolution camera for planar multi-projector displays. This method relies on a new parametric geometric model relating the projector to the camera used for registering the display. The relationship is modeled in a compact and efficient manner using a rational Bezier patch. Projection technology is advancing at a tremendous pace. Pocket projectors that can fit on one's palm are no longer a myth but a reality <ref type="bibr" target="#b0">[1]</ref>. Industry initiatives are finding ways to build short-throw, unbreakable projectors that use LEDs as light sources so that they can be embedded in cell phones. It is evident that lens distortion will be significant in such low-cost projectors. Our method will enable the use of such low-cost projectors to build commodity tiled displays.</p><p>Further, in designing a compact multi-projector display or changing an existing setup to increase space utility, a short-throw lens is required to decrease the throw distance of the projectors. These lenses currently require several optical elements to reverse the high lens distortion created by short focal lengths. Hence, they are cost-prohibitive (around $2000 -$6000) and at least 5-6 times the cost of regular projectors (around $800 -$1500). Our work handles severe lens distortions, thus paving the way for using inexpensive lenses on projectors, just as they are used on cameras today. This allows for even more compact multiprojector display designs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.2">Using Photometrically Uncalibrated Cameras</head><p>Existing methods for photometric calibration of a multi-projector display often use a camera that is first calibrated using high dynamic range images <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b25">26]</ref>. This involves taking images in an outdoor environment where one does not have control of motion, illumination, etc. This calibrated camera is then used to recover the photometric proper- ties of the projectors which are then modified appropriately to achieve a photometrically seamless multi-projector display <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b25">26]</ref>.</p><p>In this paper, we present a photometric self-calibration technique for a projector-camera pair that allows us to register a multi-projector display photometrically using an uncalibrated camera. To the best of our knowledge, this is the first work that estimates both the intensity transfer function and the spatial variation in intensity of projectors simultaneously using a photometrically uncalibrated camera.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK</head><p>In this section, we review existing geometric and photometric registration techniques and relate them to the techniques we present in this paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Geometric Registration</head><p>Geometric registration of planar multi-projector displays entails reconstructing two functions: (a) the function that relates the individual projector coordinates to the camera coordinates; and (b) the function that relates the camera coordinates to the global screen coordinates. Most geometric registration techniques devised for planar displays so far fall into the following categories.</p><p>Linear methods assume linear models for cameras and projectors. They relate the projector, camera, and the screen coordinates by linear matrices called homographies <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b33">34]</ref>. However, linear models do not account for geometric non-linearities, such as lens distortion, and cannot achieve accurate alignment in their presence. To achieve acceptable alignment in such cases, projectors are manually adjusted to the 'sweet-spot' in zoom level where the non-linear distortions become negligible.</p><p>Piecewise linear methods address these geometric non-linearities by using a piecewise linear function, essentially a triangulation, to relate the projector, camera and screen coordinates to each other. Though this achieves reasonable geometric accuracy, a dense triangulation is required to sample the parameter space adequately <ref type="bibr" target="#b36">[37]</ref>. Thus, a high-resolution (5-6 Megapixel) camera is required to register even relatively small displays made of 4-6 projectors.</p><p>Hereld, et. al. <ref type="bibr" target="#b12">[13]</ref>, use a non-linear model where a closed-form cubic function handles some of the geometric non-linearities. This method has two limitations. First, a simple cubic polynomial cannot capture the perspective projection between the projector and the camera adequately. As a result, this method assumes a close-to-rectangular array of projectors resulting from on-axis projection. Such an arrangement is relatively easy to achieve manually in a rear-projection system, but not in front-projection system where the projector is on the ceiling projecting on a screen placed on the ground. Second, this work is not motivated by accurate analysis of the kind of non-linearities seen in projectors and hence cannot handle higher order non-linearities.</p><p>Our method incorporates the non-linear distortions of the projector into the function that relates the projector to other entities, such as the camera and screen, using a single accurate closed-form function -the rational Bezier patch. This allows combination of distortions arising from completely different reasons (e.g., lens distortion and keystoning) into a single unified representation. Further, it results in an efficient camera-based geometric registration for planar, multi-projector displays, that can handle significant lens distortion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Photometric Registration</head><p>Photometric properties of a camera/projector involve its intensity transfer function, or ITF (more commonly called the gamma function), and the spatial intensity fall-off in its field-of-view (more commonly called the vignetting effect). Photometric registration of projectionbased displays requires estimation of the photometric properties of the projectors using a camera. To do this, the camera is first photometrically registered. The high dynamic range imaging technique <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b21">22]</ref> can be used to estimate the camera's ITF by taking images outdoors. Currently, there is no simple automated way of estimating the camera's vignetting effect. The registered camera is usually set to a narrow aperture when using it to estimate the photometric properties of the projectors in a tiled display. The techniques in the work by Raij, et al. <ref type="bibr" target="#b25">[26]</ref>, are then applied to estimate the projectors' ITF using the registered camera. Using the projectors with known ITF, the techniques described in the papers by Majumder and Stevens <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b20">21]</ref> are then used to estimate the spatial intensity fall-off of the projector, and to register the multiple projectors photometrically using the estimated photometric properties. No method currently exists that can use a photometrically uncalibrated camera and recover both the ITF and the spatial intensity fall-off of the projectors simultaneously. Our method in this paper estimates all the different photometric parameters of both devices in a photometrically uncalibrated projector-camera pair. It is accomplished in a controlled indoor setting without using any other physical props. Photometric registration techniques that use these parameters <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b37">38]</ref> can then be utilized to achieve photometric seamlessness in the multi-projector display.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">USING GEOMETRICALLY IMPERFECT PROJECTORS</head><p>In this section, we present our geometric registration technique that corrects for projector geometric imperfections, such as lens distortion. We use a camera that is corrected for lens distortion <ref type="bibr" target="#b2">[3]</ref>. First, we develop a new model that relates a single projector to the camera in a planar multi-projector display using a rational Bezier patch. The projector lens distortion is modeled by an affine-invariant non-rational Bezier patch. For a projector-camera setup with a planar display, this function is followed by a homography that relates the projector to the camera and to the screen linearly. We use a perspective-invariant rational Bezier patch to model the combination of these non-linear and linear functions. Thus, all the different distortions in a planar projectionbased display (e.g., key-stoning, radial, and tangential distortions) are combined into a single closed-form function. To the best of our knowledge, this is the first work that models both linear and non-linear distortions of a projector-camera system in a unified manner.</p><p>To geometrically register multiple distorted projectors, we sparsely sample the rational Bezier function relating the projector coordinates with the camera and screen coordinates, and estimate the function parameters. These parameters are then used to warp the input image to the projector appropriately resulting in a geometrically aligned image. The sparse sampling proves adequate for acceptable geometric registration since the rational Bezier offers a piecewise curve representation (which is more suited for lens distortions that transform lines to curves), rather than a piecewise linear representation. This sparse sampling allows us to use a low-resolution camera to achieve geometric registration for even medium sized displays made of 6-16 projectors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Model for Single Projector</head><p>We first consider the simple case of a single projector projecting onto a planar screen and being observed by a single camera corrected for lens distortion. Our goal is to design an accurate parametric function F that defines the relationship between the projector pixels (x, y) and the camera pixels (u, v), i.e., (u, v) = F (x, y). Ideally, the function F has two components. The first is the lens distortion function R that relates the undistorted projector coordinates (x, y) to the distorted coordinates on the display screen (</p><formula xml:id="formula_0">x d , y d ).</formula><p>The second component is the well-known homography H that relates the distorted coordinates to camera coordinates (u, v).</p><formula xml:id="formula_1">(u, v) = H (x d , y d ) = H (R(x, y)) = F (x, y)<label>(1)</label></formula><p>We would like to model F by a single compact parametric function that accurately captures the effect of the concatenation of these two functions, H and R, and is amenable to efficient data fitting computation.</p><p>Modeling R with Non-rational Bezier Patches: The classic lens distortion model <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b9">10]</ref> consists of two independent distortions: radial distortion (e.g., barrel or pin-cushion) and tangential distortion.</p><p>Radial distortion is usually modeled by</p><formula xml:id="formula_2">x d = x + (x − x p )(k 1 r 2 + k 2 r 4 + k 3 r 6 ) = x + ρ x ,<label>(2)</label></formula><formula xml:id="formula_3">y d = y + (y − y p )(k 1 r 2 + k 2 r 4 + k 3 r 6 ) = y + ρ y ,<label>(3)</label></formula><p>Case No.  <ref type="table">Table 1</ref>. This table shows the accuracy of our fit for lens distortion functions using non-rational Bezier patches of different degree. Due to the large number of lower degree terms, note that in case (e) distortion of higher degrees (e.g., degree 7) can be fitted to reasonable accuracy by a lower degree Bezier (e.g., degree 4). ε represents the convergence threshold used which is strictly less than 10 −11 .  <ref type="table">Table 1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Lens Distortion Parameters % Error For</head><formula xml:id="formula_4">Center Radial Tangential Bezier of degree (x c , y c ) (k 1 , k 2 , k 3 ) (p 1 , p 2 ) 2 3 4 5 6 7 (a) (0.5, 0.5) (−0.35, 0, 0) (0, 0) 5.78 ε (b) (0.5, 0.5) (0, 0, 0) (0.1, 0.1) ε (c) (0.5, 0.5) (−0.35, −0.35, 0) (0, 0) 9.00 0.91 0.56 ε (d) (0.6,</formula><p>where ( The principal center is a point in the image that is unchanged by radial distortion. In general, the principal center (x p , y p ) need not be at the center of the image but is usually close to the center. The tangential distortion is modeled by</p><formula xml:id="formula_5">x d = x + 2p 1 xy + p 2 r 2 + 2p 2 x 2 = x + τ x ,<label>(4)</label></formula><formula xml:id="formula_6">y d = y + 2p 2 xy + p 1 r 2 + 2p 1 y 2 = y + τ y<label>(5)</label></formula><p>where r = (x − x p ) 2 + (y − y p ) 2 and p 1 and p 2 are the tangential distortion parameters. Radial and tangential distortion are independent of each other and hence their effects can be combined into a comprehensive lens distortion equation, as</p><formula xml:id="formula_7">(x d , y d ) = (x + ρ x + τ x , y + ρ y + τ y ).<label>(6)</label></formula><p>Estimating the unknown radial and tangential distortion coefficients involves solving complex non-linear optimization problems. Hence, several simplifying assumptions are usually made which are often not true in a real system. The most common simplifications are to assume that the principal point coincides with the center of the image and to ignore the higher degree terms <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b38">39]</ref>.</p><p>We model this lens distortion by non-rational Bezier patches instead. A non-rational Bezier patch of degree k and dimension d is defined by (k + 1) d control points in a d-dimensional space. In our case, we consider a two-dimensional patch where d = 2. The Bezier patch is a tensor product patch where the control points, P i j , are weighted by blending functions that are products of independent one-dimensional Bernstein polynomials. There are k + 1 Bernstein polynomials of degree k given by</p><formula xml:id="formula_8">b nk (t) = k! n!(k − n)! t n (1 − t) k−n<label>(7)</label></formula><p>where 0 ≤ n ≤ k and 0 ≤ t ≤ 1. The non-rational Bezier patch can then be defined from these polynomials as</p><formula xml:id="formula_9">N B(x, y) = k ∑ i=0 k ∑ j=0 P i j b ik (x)b jk (y) (8) = k ∑ i=0 k ∑ j=0 P i j B i jk (x, y),<label>(9)</label></formula><p>where B i jk is the tensor product of the Bernstein polynomials b ik and b jk and 0 ≤ (x, y) ≤ 1. Hence, in the context of the single projectorcamera pair for planar displays, the projector lens distortion function R(x, y) is represented by</p><formula xml:id="formula_10">(x d , y d ) = R(x, y) = N B(x, y)<label>(10)</label></formula><p>Our choice of using a non-rational Bezier patch is guided by the following rationale.</p><p>1. The non-rational Bezier patch provides a unified framework to represent a large range of lens distortions. More severe lens distortions can be included by increasing the degree of the Bezier patch. For example, a bicubic Bezier patch may be sufficient for standard narrow FOV lenses, but a Bezier patch of degree 4 may be required for the more severe distortions of wide FOV lenses. All of these are handled by the non-rational Bezier patch without affecting the underlying computational framework.</p><p>2. When Equation 10 is expanded and compared with Equation 6, one finds that the non-rational Bezier patch has many more higher-order cross terms, making it a more flexible model. For example, it is possible for short-throw lens projectors to have a mix of both barrel and pin-cushion distortions. Such cases are better handled by a more flexible model such as the Bezier patch.</p><p>3. The principal center creates a particular nuisance in traditional lens distortion estimation techniques, and forces most practical systems to assume it to be at the center of the image. When using a non-rational Bezier patch, the principle center is encoded within the control points themselves, and need not be estimated seperately.</p><p>4. Like lens distortion, non-rational Bezier patches are also affineinvariant and hence provide an accurate model. <ref type="table">Table 1</ref> and <ref type="figure" target="#fig_1">Figure 1</ref> present results on the accuracy of our Bezier patch model. We consider a dense sampling of the (x, y) space, distort it using various traditional lens distortion parameters, and fit a nonrational Bezier patch to the distorted points. To evaluate the accuracy of the fitted Bezier, we find the average Euclidian distance error between fitted and the distorted data as a percentage of the distance from the principal center. Note that even when higher order distortions are present (e.g., x 7 ), lower degree Bezier patches (e.g., bicubic) can provide a good fit. This is due to the presence of a large number of lowerorder cross-terms, which are absent in the traditional lens distortion model. Modeling H R with Rational Bezier Patches: Non-rational Bezier patches are affine-invariant but not perspective-invariant. Relating the projector to the camera not only involves a lens distortion but also a perspective projection. In the case of planar displays, this is a homography H , a simpler 3 × 3 transformation induced by the planar display screen. So, to model the combined effects of H and R in Equation 1, we desire a function that retains all the properties of the Bezier and is also perspective-invariant. Retaining all the properties of Bezier patch assures retaining the accurate model of nonlinearities due to distortion. Invariance under perspective projection assures the additional modeling of the perspective projection between the projector and the camera. To our advantage, a generalized form of Bezier patches called rational Bezier patches offer us a function that has all the properties of a non-rational Bezier and is also perspectiveinvariant. In addition to the 2D control points of Bezier patches, rational Bezier patches have a scalar weight associated with each control point, and the patch is defined as a weighted sum of the blended control points:</p><formula xml:id="formula_11">B(x, y) = ∑ k i=0 ∑ k j=0 P i j w i j B i jk (x, y) ∑ k i=0 ∑ k j=0 w i j B i jk (x, y) .<label>(11)</label></formula><p>The weights provide this function with the capability to sample the parameter space in a non-uniform (but controlled) manner. This makes it perspective-invariant. Hence, we propose the use of a rational Bezier patch to estimate the function F = H R.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Geometric Registration of Multiple Projectors</head><p>Geometric registration of a multi-projector display requires estimating two functions. The first function maps the projector coordinates (x, y) to the camera coordinates (u, v). We use a rational Bezier patch B for this purpose. The second function maps the camera coordinates (u, v) to the normalized screen coordinates (p, q). The presence of a planar screen allows us to use a homography H S for this mapping. These functions are estimated as follows.</p><p>Parameter Estimation: To estimate H S , we require four correspondences between the camera and screen coordinates, (u, v) and (p, q). The four correspondences result in a system of linear equations that can be solved to recover the homography matrix. To find the correspondences, we identify four points in the camera image that correspond to the four corners of the screen. This can be done automatically by attaching fiducials to the display. Since our display is nearly rectangular, we set all the projectors to display white light and use simple image processing to detect the extreme corners of the lighted regions to find the camera coordinates that correspond to the four corners of the normalized screen space.</p><p>To estimate the parameters of the rational Bezier patch, B, we find correspondences between projector pixels (x, y) and camera pixels (u, v). Let us assume N correspondences, i.e., (x c , y c ) corresponding</p><formula xml:id="formula_12">to (u c , v c ), 0 ≤ c ≤ N − 1.</formula><p>The unknowns are the control points in the camera's space, P i j = (u i j , v i j ), and their scalar weights w i j . From the known correspondences, Equation 11 can be written for each correspondence as follows:</p><formula xml:id="formula_13">(u c , v c ) k ∑ i=0 k ∑ j=0 w i j B i jk (x c , y c ) − k ∑ i=0 k ∑ j=0 (u i j , v i j )w i j B i jk (x c , y c ) = 0. (12)</formula><p>Assuming U i j = u i j w i j and V i j = v i j w i j , Equation 12 yields two equations for each correspondence, as follows: It is evident that piecewise linear methods with sparse correspondences lead to severe mismatches. The results using rational Bezier are similar, even when the sampling is reduced by an order of magnitude. In fact, at places, the results from using rational Bezier patches with sparse sampling is better than the results from using a dense sampling for the piecewise linear method. This is evident as the grid lines are thicker in the overlap region in (b) due to slight errors.</p><formula xml:id="formula_14">u c k ∑ i=0 k ∑ j=0 w i j B i jk (x c , y c ) − k ∑ i=0 k ∑ j=0 U i j B i jk (x c , y c ) = 0.<label>(13)</label></formula><formula xml:id="formula_15">v c k ∑ i=0 k ∑ j=0 w i j B i jk (x c , y c ) − k ∑ i=0 k ∑ j=0 V i j B i jk (x c , y c ) = 0.<label>(14)</label></formula><p>The unknowns for estimating a two-dimensional rational Bezier patch of degree k are (k + 1) 2 control points and weights, which result in a total of 3(k + 1) 2 unknowns. The weights are variables that depend on the control points in a non-linear fashion. So, the above equations result in a non-linear least-squares fitting problem that can be solved efficiently using the Levenberg-Marquardt gradient descent optimization technique <ref type="bibr" target="#b30">[31]</ref>. As an initial guess to this optimization, we fit the control polygon tightly around the set of correspondences (u c , v c ) in the camera space and constrain the weights to be strictly greater than 0. To find the correspondences between projector and camera coordinates, (x, y) and (u, v), we display a rectangular grid of Gaussian blobs with known coordinates on each projector. These are captured by a calibrated camera in a series of non-overlapping images. We use a 2Dstepping procedure that depends on a user to identify the top-left blob and its immediate right and bottom neighbors in camera space. With this minimal three point user input, we can design a stepping procedure that (a) estimates the rough position of the next blob in scan-line order, and (b) searches for the correct blob position using the nearest windowed center-of-mass technique <ref type="bibr" target="#b10">[11]</ref>. If this is not possible for more extreme projector distortions, one can binary-encode the blobs and project them in a time sequential manner to recover the exact ids of the detected blobs and find the correspondences <ref type="bibr" target="#b27">[28,</ref><ref type="bibr" target="#b36">37]</ref>.</p><p>Image Correction: To create a geometrically seamless and undistorted display, we warp the image for each projector as follows: For each projector coordinate (x, y), we first compute the corresponding camera coordinate (u, v) using the rational Bezier patch B. Next, we compute the corresponding normalized screen coordinates (p, q) using the homography H S . The generated coordinates (p, q) are used as indices into the image being rendered on the tiled display. Bilinear interpolation is used to assign the final value of each projector pixel. Thus, the correction is achieved by the mapping</p><formula xml:id="formula_16">(p, q) = H S (u, v) = H S (B(x, y)).<label>(15)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Implementation and Results</head><p>We have applied our method on our 8 × 6-foot display made of 3 × 3 array of nine projectors. Our projectors have relatively large throw ra-tios and hence do not reveal major lens distortions. Instead of choosing the cost prohibitive option of buying nine short-throw lenses, we chose to simulate the distortion digitally by distorting the input images to the projectors. The registration is done offline and takes a couple of minutes. This generates the parameters of the rational Bezier for each projector, which are then stored to be used during image correction. We have implemented the image correction in real-time using modern GPUs through Chromium -an open-source distributed rendering engine for PC clusters <ref type="bibr" target="#b13">[14]</ref>. A module for Chromium is written that first precomputes the coordinate-mappings of all pixel coordinates using the stored parameters of the rational Bezier. This results in a per-pixel projector to screen lookup table. A fragment program for the pixel shader quickly maps pixels from the projector coordinate space to the screen coordinate space during rendering. <ref type="figure" target="#fig_3">Figure 2</ref> shows the results. The advantage of using an appropriate parametric function lies in an accurate alignment even with a sparse sampling of the function. We can achieve accurate alignment of our relatively high resolution display (3000 × 2100) by using a lowresolution VGA (640 × 480) camera. Notice that even with a lowresolution camera we get sub-pixel accuracy for fine grids (one pixel wide lines) and text. <ref type="figure" target="#fig_4">Figure 3</ref> shows that we can achieve accuracy comparable to existing methods (that use much higher resolution cameras) even when our sampling is sparser by an order of magnitude. To achieve perceptual photometric seamlessness, we used the work by Majumder, et al. <ref type="bibr" target="#b20">[21]</ref>. To make the quality of the geometric registration visible in the grid images, we did not register the display photometrically for <ref type="figure" target="#fig_3">Figure 2</ref>(c) and <ref type="figure" target="#fig_4">Figure 3</ref>. So, these images, though geometrically aligned, still show photometric seams. The real-time rendering is demonstrated in the submitted video. However the video, being in VGA resolution, cannot capture the high resolution details.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">USING PHOTOMETRICALLY UNCALIBRATED CAMERAS</head><p>In this section, we present a method for photometric registration of multi-projector displays using a photometrically uncalibrated camera. Projector photometric parameters that include its ITF and spatial intensity variation, need to be estimated to instrument existing photometric registration techniques <ref type="bibr" target="#b20">[21]</ref>. We use an uncalibrated camera (whose</p><formula xml:id="formula_17">i X f p (i) f p (i)L(x,y) f p (i)L(x,y)t j f c (f p (i)L(x,y)t j ) Projector Input Projector TF f p Spatial Variation (Projector + Screen) L (x , y ) Exposure t j Camera TF f c</formula><p>Camera Output Image Z <ref type="figure">Fig. 4</ref>. The transformation process of an image as it passes through a projector-camera system.</p><p>ITF is unknown) to extract these projector photometric parameters. In the process, we also recover the camera ITF and hence calibrate the camera photometrically. To suppress the spatial intensity variation, such as vignetting effect, of the camera, like most previous work in scene reconstruction <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b22">23]</ref>, we operate the camera at a narrow aperture setting where it approaches the ideal pinhole model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Model for a Single Projector</head><p>We assume a geometrically calibrated projector-camera system where a pixel (u, v) in the camera coordinate system is related to a pixel (x, y) in the projector coordinate system by a linear or non-linear warp G(x, y) = (u, v). G can be determined by any geometric calibration method, including the one presented in the previous section <ref type="bibr" target="#b37">[38]</ref>. Consider a spatially uniform grayscale input to the projector. Let the grayscale level be denoted by i. As per the model presented in the paper by Majumder and Gopi <ref type="bibr" target="#b17">[18]</ref>, the uniform image is first transformed by a spatially invariant input transfer function of the projector, f p , to create a spatially uniform output, f p (i). Next, the projector optics introduce a spatially-dependent but input-independent intensity variation. This is further modulated by the screen reflectance/transmittance function. We denote this combined spatially dependent attenuation factor due to projector lens and screen as L(x, y). Thus, the image produced after passing through the projector lens and screen is f p (i)L(x, y). The light from the screen then reaches the camera. The amount of light accepted by the camera is scaled by its exposure time t j , where j indexes different exposure times. The different exposures are instrumented by changing the shutter speed of the camera. This produces an image f p (i)L(x, y)t j that passes through the camera optics. Assuming negligible camera vignetting at narrow apertures, the image is transformed only by the input transfer function of the camera, f c , to generate the grayscale value recorded by the camera Z. Thus, Z is a function of the input i, the exposure time index j, and the spatial coordinates (x, y). This is illustrated in <ref type="figure">Figure 4</ref>. The final equation is</p><formula xml:id="formula_18">Z(i, j, x, y) = f c ( f p (i)L(x, y)t j ).<label>(16)</label></formula><p>For cameras, the intensity transfer function is monotonic <ref type="bibr" target="#b7">[8]</ref>, and hence invertible. Note that the same is not true for projectors <ref type="bibr" target="#b19">[20]</ref>. Assuming invertible f c , the above equation becomes</p><formula xml:id="formula_19">f −1 c (Z(i, j, x, y)) = f p (i)L(x, y)t j .<label>(17)</label></formula><p>Taking the natural logarithm of both sides we get,</p><formula xml:id="formula_20">ln f −1 c (Z(i, j, x, y)) = ln f p (i) + ln(L(x, y)) + ln(t j ).<label>(18)</label></formula><p>To simplify the notation, we define h c = ln f <ref type="bibr">−1 c</ref> and h p = ln f p , The above equation then becomes</p><formula xml:id="formula_21">h c (Z(i, j, x, y)) = h p (i) + ln(L(x, y)) + ln(t j )<label>(19)</label></formula><p>where i ranges over the grayscale inputs, j ranges over the exposure times, and (x, y) ranges over the spatial coordinates of the projector. In this equation, Z and t j are known while h p , h c and L are unknown.</p><p>Varying i and t j results in different values of Z for each pixel (x, y). We can use this to setup a system of linear equations. We recover h p , h c and L that best satisfy Equation 19 in a least-squares sense.</p><p>Note that recovering h p and h c involves solving the functions for a finite number of samples in the complete range of input values. The recovered parameters are illustrated in <ref type="figure" target="#fig_5">Figure 5</ref>. Improving Efficiency: The system of linear equations achieved by Equation 19 is very large. Let R i and R Z each be the cardinality of the set of input samples for h p and h c respectively, P be the total number of projector pixels, and T be the number of exposures. This results in PT R i equations and P + R i + R Z unknown variables for the system of equations defined by Equation 19. Typically R i = R Z = 256 and P = 1, 000, 000 (assuming common XVGA projector resolution). Since there are multiple exposures for each input in the range R i , the size of the linear system is on the order of at least a few million equations and cannot be solved efficiently.</p><p>To address this inefficiency we use a limited number of pixels in the projector space to solve for h p and h c . This is possible since h p and h c are both spatially constant. To ensure a sufficiently over-determined system, the criteria PT R i &gt; P + R i + R z should be satisfied. For R i = R Z = 256 and T = 6, a choice of 100 for P is more than adequate. So, we first subsample L to a resolution of 10 × 10 pixel and use this to setup a smaller linear system of equations to solve for h p and h c .</p><p>With the estimated h p and h c , we substitute these into Equation 19 and quickly solve for L(x, y) at the various projector coordinates, by rewriting Equation 19 as ln <ref type="figure">(L(x, y)</ref></p><formula xml:id="formula_22">) = h c (Z(i, j, x, y)) − h p (i) − ln(t j )<label>(20)</label></formula><p>Handling Noise: Our system does exhibit considerable random noise arising not only from the devices (camera and projector) but also from the screen. In particular, we use a rear projection screen with relatively high gain which has been shown to generate considerable random noise <ref type="bibr" target="#b19">[20]</ref>. This has an adverse effect on the signal to noise ratio, especially for low projector input i or low camera output Z. Thus, estimating h p and h c directly from Equation 19 and L from Equation 20 results in noisy parameter estimation. We take several measures to reduce the effect of this random noise.</p><p>To assure smooth h p and h c while solving the system of equations, we minimize the error function</p><formula xml:id="formula_23">E = ∑ j∈T ∑ (x,y)∈P ∑ i∈R i [(h c (Z) − h p (i) − ln(L(x, y)) − ln(t j )] 2 (21) +λ ∑ Z∈R Z h c (Z) 2 + ∑ i∈R i h p (i) 2 .<label>(22)</label></formula><p>The first term assures that the solution arises from the set of equations given by Equation 19 in a least-squares sense. The second term is a smoothing constraint on the curvature of h p and h c , given by their second derivatives. In the discrete domain, we use the Laplacian operator to find the curvature of h p and h c , i.e., h</p><formula xml:id="formula_24">p (i) = h p (i − 1) − 2h p (i) + h p (i + 1)</formula><p>. The scale factor λ weights the smoothness term relative to the data fitting term and should be chosen based on the amount of noise in Z. We choose λ = 10. However, note that the first term in Equation 22 gives equal weights to all recorded camera values Z, and the second term gives equal weights to all i and Z. For the first term, we want to emphasize images with higher signal to noise ratio i.e. images for higher i with higher recorded values Z. For the second term, we want to emphasize smoothing of h p and h c in the lower ranges of i and Z respectively where low signal to noise ratio would result in a noisier estimate. To achieve this, we weight the first and second term of the error function in Equation 22 as follows,</p><formula xml:id="formula_25">E = ∑ j∈T ∑ (x,y)∈P ∑ i∈R i [w c (Z)(h c (Z) − h p (i) − ln(L(x, y)) − ln(t j )] 2 (23) +λ ∑ Z∈R Z [(Z max − w c (Z))h c (Z)] 2 + ∑ i∈R i [(i max − w p (i))h p (i)] 2 . (24)</formula><p>where w p and w c are the weighting functions corresponding to the projector input and the recorded camera values, respectively, and Z max and i max are the maximum camera output and projector input respectively. To give the higher intensities greater confidence we use linear weighting functions, w c (Z) = Z and w p (i) = i. Similarly, noise can have adverse effects when estimating L using Equation 20 after h p and h c are recovered. Usually the image captured for input i at a particular exposure does not yield unsaturated outputs at all spatial pixel locations (x, y). So, we need to use different images for reconstruction of L at different spatial locations. This will yield an L with different signal to noise ratio at different spatial regions depending on the image that was used to reconstruct L in any spatial region. Even if a rare situation occurs when one finds a single image (at a particular input and exposure) where all the pixels are unsaturated, L will still be noisy due to the inherent random noise of the projector-screen-camera system.</p><p>Averaging multiple observations is the standard way to reduce random noise significantly <ref type="bibr" target="#b10">[11]</ref>. Using this fact, we reduce noise in L at any pixel (x, y) by solving it from multiple images and finding a weighted mean of the multiple solutions. The weighting function should emphasize higher i and Z to reduce the effect of random noise. We achieve this by a weighting function w L (Z, i) = w c (Z)w p (i). The solution can now be derived by modifying Equation 20 as ln <ref type="figure">(L(x, y)</ref></p><formula xml:id="formula_26">) = ∑ j∈T ∑ i∈R i w L (Z, i)[h c (Z) − h p (i) − ln(t j )] ∑ j∈T ∑ i∈R i w L (Z, i) ,<label>(25)</label></formula><p>resulting in clean estimated parameters as illustrated in <ref type="figure" target="#fig_5">Figure 5</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Photometric Registration of Multiple Projectors</head><p>For photometric registration of a multi-projector display, we estimate the f p and L(x, y) of each projector independently using the same camera. Note that in order to recover the relative intensity levels of the projectors, we use the unnormalized L(x, y) estimated independently from each projector. Using the extracted parameters from each projector, we use the photometric registration method proposed by Majumder and Stevens <ref type="bibr" target="#b20">[21]</ref> to generate a perceptually seamless display.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Implementation and Results</head><p>We used a Kodak DCS ProSLR/n camera and projected 32 flat grayscale fields with intensity levels uniformly sampled from 0 to 255. For each intensity level, 15 exposures were taken. The camera was set to a narrow aperture, f/32. The data collection took 25 minutes. To reduce the collection time, we tried reducing the number of exposures. Empirically, the minimum number of exposures needed before quantization effects became visible was eight. The exposures used, however, need to be well distributed amongst the range of available camera exposures. The program was written in C++ and utilizes Matlab and the OpenCV library. It takes about 11-15 minutes to register each projector on a Pentium 4, 2.8 GHz PC.</p><p>The photometric registration in <ref type="figure" target="#fig_3">Figure 2</ref> (d) and (e) are achieved by using a photometrically uncalibrated camera. Additional results with projectors that do not exhibit lens distortion are shown in <ref type="figure" target="#fig_6">Figure 6</ref>. Here a linear geometric registration method is used <ref type="bibr" target="#b4">[5]</ref>. These results show that a photometrically uncalibrated camera can be used irrespective of the kind of geometric registration method being used. When using the photometric registration technique of Majumder and Stevens <ref type="bibr" target="#b20">[21]</ref> we use a low photometric uniformity parameter to retain the high contrast of the display as much as possible. This results in some perceivable seams near the boundaries of the bottom left and right projectors, which are significantly dimmer than the other projectors in our display. However, these seams exist even when the photometric registration is carried out with a calibrated camera, showing that they are artifacts of the photometric registration method itself and are not due to imperfect projector parameter estimation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">CONCLUSION</head><p>This paper presents new registration techniques to handle imperfect and uncalibrated devices in planar multi-projector displays. The four relevant cases include allowing (a) photometrically imperfect projectors, (b) geometrically imperfect projectors, (c) a photometrically uncalibrated camera, and (d) a geometrically uncalibrated camera. Our work addresses (b) and (c) in particular, while (a) is addressed by existing literature <ref type="bibr" target="#b20">[21]</ref>. Our work allows severely distorted projectors to be used which opens up the possibility of mounting inexpensive lenses on projectors, just as with cameras, leading to very short-throw projectors. Using a photometrically uncalibrated camera allows the photometric registration to be conducted within a controlled indoor environment. Further, we have proposed the first method that estimates all projector/camera photometric parameters simultaneously. However, case (d) above of achieving geometric registration in multi-projector displays using a geometrically uncalibrated camera is still a challenging problem.</p><p>Further, our methods are within the realm of centralized architecture. Current distributed architectures <ref type="bibr" target="#b1">[2]</ref> are very amenable to easy deployment, simple maintenance and hence more affordable multiprojector displays. Our goal is to extend our developed methodologies in this paper to the distributed framework of a network of projectorcamera systems <ref type="bibr" target="#b1">[2]</ref>. This poses a significant challenge which, if resolved, can be instrumental in realizing commodity tiled projectionbased displays. All of these methodologies are stepping stones towards the vision of ubiquitous pixels in future workspaces. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Published 14</head><label>14</label><figDesc>September 2007.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 1 .</head><label>1</label><figDesc>Images showing the fives cases of distortion mentioned in</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>d , y d ) and (x, y) are the distorted and undistorted image coordinates respectively, r = (x − x p ) 2 + (y − y p ) 2 is the radial distance from the principal center (x p , y p ) in the undistorted image, and k i , 1 ≤ i ≤ 3 are the radial distortion coefficients. Negative values of k i result in barrel distortion while positive values result in pin-cushioning.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 2 .</head><label>2</label><figDesc>Results of geometric registration shown on our display which is a 3 × 3 array of nine projectors. The geometric registration is achieved using bicubic rational Bezier patches with sparse correspondences (8 × 6 for a 1024 × 768 projector). (a, b, c) Before registration; (d, e, f) After registration. The grid image in the last column is made of lines that are one pixel wide. To retain clarity of the grids in the overlap region, photometric registration is not applied to the grid image in (c) when generating the registered image (f).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 3 .</head><label>3</label><figDesc>Geometric registration of projectors with severe barrel distortion: using a linear piecewise method with sparse -48 samples (a) and dense -432 samples (b) correspondences; using rational bicubic Bezier patches with sparse -48 samples (c) and dense -432 samples (d) correspondences. (e,f,g,h) provides a zoomed in view of the projector overlap regions in (a,b,c,d) respectively.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 5 .</head><label>5</label><figDesc>(a) The estimated camera input transfer function f c . (b) The estimated projector input transfer function f p . (c) The estimated spatial intensity variation due to projector, screen, and camera L.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 6 .</head><label>6</label><figDesc>Images of our 3 × 3 array of nine projectors. (a,c) The geometrically registered display without any photometric registration. (b,d) Photometric registration achieved by using an uncalibrated camera.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>•</head><label></label><figDesc>Ezekiel Bhasker is with University of California, Irvine, E-mail: ebhasker@ics.uci.edu. • Ray Juang is with University of California, Irvine, E-mail: rjuang@ics.uci.edu. • Aditi Majumder is with University of California, Irvine, E-mail: majumder@ics.uci.edu.</figDesc><table /><note>Manuscript received 31 March 2007; accepted 1 August 2007; posted online 27 October 2007. For information on obtaining reprints of this article, please send e-mail to: tvcg@computer.org.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>, 0.55) (−0.35, −0.13, −0.016) (0.05, 0.05) 2.0 0.17 0.038 0.0012 0.00022 ε</figDesc><table><row><cell></cell><cell>0.55)</cell><cell>(−0.35, −0.13, 0)</cell><cell>(0.05, 0.05)</cell><cell>1.9</cell><cell>0.14</cell><cell>0.03</cell><cell>ε</cell></row><row><cell>(e)</cell><cell>(0.6</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Mitsubishi pocketprojector led dlp projector</title>
		<ptr target="http://www.mitsubishi-presentations.com/projpocket.asp" />
		<imprint/>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Asynchronous distributed calibration for scalable reconfigurable multi-projector displays</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">S</forename><surname>Bhasker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Sinha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Majumder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transections of Visualization and Computer Graphics (TVCG)</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1101" to="1108" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Camera calibration toolbox for matlab</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">Y</forename><surname>Bouguet</surname></persName>
		</author>
		<ptr target="http://www.vision.caltech.edu/bouguetj/calibdoc/index.html" />
		<imprint/>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Decentering distortion of lenses</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Brown</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Photometric Engineering</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="444" to="462" />
			<date type="published" when="1966" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Scalable alignment of large-format multi-projector displays using camera homography trees</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Sukthankar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Wallace</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE Visualization</title>
		<meeting>IEEE Visualization</meeting>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Automatic alignment of high-resolution multi-projector displays using an uncalibrated camera</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">W</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Finkelstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Housel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE Visualization</title>
		<meeting>IEEE Visualization</meeting>
		<imprint>
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Lens distortion recovery for accurate sequential structure and motion recovery</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Cornelis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pollefeys</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">V</forename><surname>Gool</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference in Computer Vision</title>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="186" to="200" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Recovering high dynamic range radiance maps from photographs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">E</forename><surname>Debevec</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACM Siggraph</title>
		<meeting>ACM Siggraph</meeting>
		<imprint>
			<date type="published" when="1997" />
			<biblScope unit="page" from="369" to="378" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Ubiworld: An environment integrating virtual reality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Disz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Papka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Stevens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Heterogeneous Computing Workshop</title>
		<imprint>
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Lens distortion for close-range photogrammetry</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Fryer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Brown</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Photogrammetric Engineering and Remote Sensing</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="51" to="58" />
			<date type="published" when="1986" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">C</forename><surname>Gonzalez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">E</forename><surname>Woods</surname></persName>
		</author>
		<title level="m">Digital Image Processing</title>
		<imprint>
			<publisher>Addison Wesley</publisher>
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Introduction to building projectionbased tiled display systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hereld</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Judson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Stevens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer Graphics and Applications</title>
		<imprint>
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Dottytoto: A measurement engine for aligning multi-projector display systems. Argonne National Laboratory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hereld</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">R</forename><surname>Judson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Stevens</surname></persName>
		</author>
		<idno>preprint ANL/MCS-P958-0502</idno>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Chromium : A stream processing framework for interactive rendering on clusters</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Humphreys</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Houston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Frank</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ahem</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Kirchner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Klosowski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions of Graphics</title>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Radial distortion refinement by inverse mapping-based extrapolation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">G</forename><surname>Jung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">J</forename><surname>Yoon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings to 18th International Conference on Pattern Recognition(ICPR)</title>
		<meeting>to 18th International Conference on Pattern Recognition(ICPR)</meeting>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Bluespace: Personalizing workspace through awareness and adaptability</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Levas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Chou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Pinhanez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Viveros</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Human Computer Studies</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="415" to="428" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Early experiences and challenges in building and using a scalable display wall system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">W</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Cook</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Damianakis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Essl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Finkelstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Funkhouser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Praun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Samanta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Shedd</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">P</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Tzanetakis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer Graphics and Applications</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="671" to="680" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Modeling color properties of tiled displays</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Majumder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gopi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics Forum</title>
		<imprint>
			<date type="published" when="2005-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Achieving color uniformity across multi-projector displays</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Majumder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Towles</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Welch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE Visualization</title>
		<meeting>IEEE Visualization</meeting>
		<imprint>
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Color nonuniformity in projection-based displays: Analysis and solutions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Majumder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Stevens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2003-04" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Perceptual photometric seamlessness in tiled projection-based displays</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Majumder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Stevens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Graphics</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2005-01" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Radiometric self calibration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Mitsunaga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Nayar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">A projection system with radiometric compensation for screen imperfections</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">K</forename><surname>Nayar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Peri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">D</forename><surname>Grossberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">N</forename><surname>Belhumeur</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE International Workshop on Projector-Camera Systems</title>
		<meeting>IEEE International Workshop on Projector-Camera Systems</meeting>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">The everywhere displays projector: A device to create ubiquitous graphical interfaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Pinhanez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Ubiquitous Computing</title>
		<meeting>Ubiquitous Computing<address><addrLine>Georgia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Ubiquitous interactive graphics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">S</forename><surname>Pinhanez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">C</forename><surname>Kjeldsen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Levas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">S</forename><surname>Pingali</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">E</forename><surname>Podlaseck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">B</forename><surname>Chou</surname></persName>
		</author>
		<idno>RC22495</idno>
	</analytic>
	<monogr>
		<title level="m">IBM Research</title>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="205" to="143" />
		</imprint>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">PixelFlex2: A Comprehensive, Automatic, Casually-Aligned Multi-Projector Display</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Raij</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Gill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Majumder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Towles</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Fuchs</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE International Workshop on Projector-Camera Systems</title>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Immersive planar displays using roughly aligned projectors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Raskar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE Virtual Reality</title>
		<meeting>IEEE Virtual Reality</meeting>
		<imprint>
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Multi projector displays using camera based registration. Proceedings of IEEE Visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Raskar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Towles</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Seales</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Fuchs</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Forlines. ilamps: Geometrically aware and self-configuring projectors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Raskar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Van Baar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Beardsley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Willwacher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Graphics</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">The office of the future: A unified approach to image based modeling and spatially immersive display</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Raskar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Welch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Cutts</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lake</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Stesin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Fuchs</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACM Siggraph</title>
		<meeting>ACM Siggraph</meeting>
		<imprint>
			<date type="published" when="1998" />
			<biblScope unit="page" from="168" to="176" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Artificial Intelligence: A Modern Approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Russell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Norvig</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1995" />
			<publisher>Prentice-Hall</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">A comparative review of camera calibrating methods with accuracy evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Salvi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Armangu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Batlle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="1617" to="1635" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">System design of smart table</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Steurer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">B</forename><surname>Srivastava</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the First IEEE International Conference on Pervasive Computing and Communications</title>
		<meeting>the First IEEE International Conference on Pervasive Computing and Communications</meeting>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Smarter presentations: Exploiting homography in cameraprojector systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Sukthankar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Stockton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mullin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of International Conference on Computer Vision (ICCV)</title>
		<meeting>International Conference on Computer Vision (ICCV)</meeting>
		<imprint>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Nonmetric calibration of wide-angle lenses and polycameras</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Swaminathan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">K</forename><surname>Nayar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1172" to="1178" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Emancipated pixels: Real-world graphics in the luminous room</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Underkoffler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Ullmer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ishii</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACM Siggraph</title>
		<meeting>ACM Siggraph</meeting>
		<imprint>
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Pixelflex: A reconfigurable multi-projector display system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Gotz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hensley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Towles</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">S</forename><surname>Brown</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE Visualization</title>
		<meeting>IEEE Visualization</meeting>
		<imprint>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Camera based calibration techniques for seamless multi-projector displays</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Majumder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Brown</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2005-04" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Flexible camera calibration by viewing a plane from unknown orientation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="1999" />
			<biblScope unit="page" from="666" to="673" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
