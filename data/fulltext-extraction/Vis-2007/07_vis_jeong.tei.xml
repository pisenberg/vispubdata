<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/pisenberg/grobid/grobid-0.6.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Interactive Visualization of Volumetric White Matter Connectivity in DT-MRI Using a Parallel-Hardware Hamilton-Jacobi Solver</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2007-10-27">27 October 2007</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><roleName>Student Member, IEEE</roleName><forename type="first">Ki</forename><surname>Jeong</surname></persName>
							<email>wkjeong@cs.utah.edu</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">with the Scientific Computing and Imaging Institute</orgName>
								<orgName type="department" key="dep2">School of Computing</orgName>
								<orgName type="institution">University of Utah</orgName>
								<address>
									<addrLine>72 S. Central Camput Dr</addrLine>
									<postCode>84112</postCode>
									<settlement>Salt Lake City</settlement>
									<region>UT</region>
								</address>
							</affiliation>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">with the Scientific Computing and Imaging Institute</orgName>
								<orgName type="department" key="dep2">School of Computing</orgName>
								<orgName type="institution">University of Utah</orgName>
								<address>
									<addrLine>72 S. Central Camput Dr</addrLine>
									<postCode>84112</postCode>
									<settlement>Salt Lake City</settlement>
									<region>UT</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">Thomas</forename><surname>Fletcher</surname></persName>
							<email>fletcher@sci.utah.edu</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">with the Scientific Computing and Imaging Institute</orgName>
								<orgName type="department" key="dep2">School of Computing</orgName>
								<orgName type="institution">University of Utah</orgName>
								<address>
									<addrLine>72 S. Central Camput Dr</addrLine>
									<postCode>84112</postCode>
									<settlement>Salt Lake City</settlement>
									<region>UT</region>
								</address>
							</affiliation>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">with the Scientific Computing and Imaging Institute</orgName>
								<orgName type="department" key="dep2">School of Computing</orgName>
								<orgName type="institution">University of Utah</orgName>
								<address>
									<addrLine>72 S. Central Camput Dr</addrLine>
									<postCode>84112</postCode>
									<settlement>Salt Lake City</settlement>
									<region>UT</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ran</forename><surname>Tao</surname></persName>
							<email>rantao@cs.utah.edu</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">with the Scientific Computing and Imaging Institute</orgName>
								<orgName type="department" key="dep2">School of Computing</orgName>
								<orgName type="institution">University of Utah</orgName>
								<address>
									<addrLine>72 S. Central Camput Dr</addrLine>
									<postCode>84112</postCode>
									<settlement>Salt Lake City</settlement>
									<region>UT</region>
								</address>
							</affiliation>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">with the Scientific Computing and Imaging Institute</orgName>
								<orgName type="department" key="dep2">School of Computing</orgName>
								<orgName type="institution">University of Utah</orgName>
								<address>
									<addrLine>72 S. Central Camput Dr</addrLine>
									<postCode>84112</postCode>
									<settlement>Salt Lake City</settlement>
									<region>UT</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><roleName>Member, IEEE</roleName><forename type="first">Ross</forename><forename type="middle">T</forename><surname>Whitaker</surname></persName>
							<email>whitaker@cs.utah.edu</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">with the Scientific Computing and Imaging Institute</orgName>
								<orgName type="department" key="dep2">School of Computing</orgName>
								<orgName type="institution">University of Utah</orgName>
								<address>
									<addrLine>72 S. Central Camput Dr</addrLine>
									<postCode>84112</postCode>
									<settlement>Salt Lake City</settlement>
									<region>UT</region>
								</address>
							</affiliation>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">with the Scientific Computing and Imaging Institute</orgName>
								<orgName type="department" key="dep2">School of Computing</orgName>
								<orgName type="institution">University of Utah</orgName>
								<address>
									<addrLine>72 S. Central Camput Dr</addrLine>
									<postCode>84112</postCode>
									<settlement>Salt Lake City</settlement>
									<region>UT</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Interactive Visualization of Volumetric White Matter Connectivity in DT-MRI Using a Parallel-Hardware Hamilton-Jacobi Solver</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2007-10-27">27 October 2007</date>
						</imprint>
					</monogr>
					<note type="submission">received 31 March 2007; accepted 1 August 2007; posted online</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2021-02-20T19:45+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Diffusion tensor visualization</term>
					<term>graphics hardware</term>
					<term>interactivity</term>
				</keywords>
			</textClass>
			<abstract>
				<p>In this paper we present a method to compute and visualize volumetric white matter connectivity in diffusion tensor magnetic resonance imaging (DT-MRI) using a Hamilton-Jacobi (H-J) solver on the GPU (Graphics Processing Unit). Paths through the volume are assigned costs that are lower if they are consistent with the preferred diffusion directions. The proposed method finds a set of voxels in the DTI volume that contain paths between two regions whose costs are within a threshold of the optimal path. The result is a volumetric optimal path analysis, which is driven by clinical and scientific questions relating to the connectivity between various known anatomical regions of the brain. To solve the minimal path problem quickly, we introduce a novel numerical algorithm for solving H-J equations, which we call the Fast Iterative Method (FIM). This algorithm is well-adapted to parallel architectures, and we present a GPU-based implementation, which runs roughly 50-100 times faster than traditional CPU-based solvers for anisotropic H-J equations. The proposed system allows users to freely change the endpoints of interesting pathways and to visualize the optimal volumetric path between them at an interactive rate. We demonstrate the proposed method on some synthetic and real DT-MRI datasets and compare the performance with existing methods.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Diffusion tensor magnetic resonance imaging (DT-MRI) is a powerful technique for imaging in vivo properties of white matter tissue in the human brain. Visualizations of the white matter pathways and of possible abnormalities along these pathways are an important tool for clinicians studying neuropsychiatric disorders. The physical principle behind diffusion imaging is that the motion of water is impeded in directions that are not parallel to the axons. In DT-MRI a diffusion tensor at each voxel gives an estimated model of the pattern of water diffusion aggregated over a point-spread function of the measurements. The neural fiber orientation is typically inferred from the principal eigenvector of the diffusion tensor, which is the direction of highest probability of water motion.</p><p>Several methods based on the Hamilton-Jacobi (H-J) equation have recently been introduced as a means for describing connectivity in white matter. A considerable amount of research has focused on developing numerically efficient algorithms to solve the H-J equation. Most solvers are based on either iterative schemes using pre-defined update orders or one-pass schemes using sorted data structures. However, solving the H-J equation on highly anisotropic speed volumes, such as those found in DT-MRI, usually requires at least a few minutes even on the fastest processor, making the application less interactive. Therefore, there remains a need for fast solutions to the H-J equation in a variety of visualization-related applications..</p><p>GPUs have evolved into a massively parallelized multiprocessor machine over the last few years. The current GPUs have up to 128 microprocessors running in a SIMD fashion, producing throughput of several hundreds GFLOPS (Giga Floating Point Operations Per Second). The GPU supports high precision computation up to 32bit floating point (64bit is on its way), has extremely wide memory bandwidth, and is fully programmable. In addition, the new generation GPUs based on DirectX 10 support much more flexible flow controls and memory management, and provide rich instruction sets and high level languages for GPGPU (General Purpose computation on the GPU) that help to reduce the overhead of executing graphics APIs and provide more flexible programming models. Due to their increasing computational power and programming flexibility, current GPUs are becoming a very powerful parallel computing platform for GPGPU problems <ref type="bibr" target="#b16">[17]</ref>.</p><p>In this paper we introduce an interactive system to compute and visualize volumetric white matter connectivity in DT-MRI volumes. Our method is based on the framework for volumetric quantification of DTI connectivity previously presented in <ref type="bibr" target="#b5">[6]</ref>. While that work focused on quantification of connectivity and the computations were done offline on the CPU, this paper extends the visualization aspect of the method and focuses on an efficient, interactive computational algorithm on the GPU. Existing CPU-based methods to extract DT-MRI white matter connectivity rely on the pre-computed distance volume because distance computation on the anisotropic speed volume is a highly timeconsuming process, and therefore, up to our knowledge, there are no existing systems that can extract the pathways in the DT-MRI volumes at an interactive rate. The proposed system uses the graphics processors to solve the H-J equation quickly, roughly 50-100 times faster than traditional CPU-based solvers, allowing users to freely change the endpoints of interesting pathways and to visualize the volumetric connectivity between them at an interactive rate. The main contribution of this paper is introducing a novel numerical algorithm to solve the H-J equation that can be well-adapted to various parallel architectures, an improved Godunov Hamiltonian computation, and a GPU implementation of the proposed H-J solver.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">DT-MRI connectivity</head><p>Much of the work in DT-MRI connectivity focuses on fiber tractography <ref type="bibr" target="#b2">[3]</ref>, in which streamlines are computed, by forward integration from a seed point, of the field of vectors defined by the principal eigenvector of the tensor at each point (interpolated between voxels), and where the twofold ambiguity of eigenvector directions is resolved by the continuity of paths. As a clinical tool for analyzing white matter pathways, tractography suffers from several drawbacks. First, imaging noise can cause fiber tracts to stray due to accumulating errors in the integration. The second issue is partial voluming. The finite size of a voxel measurement at fiber crossings (combined with sensor noise) can cause the direction of the major eigenvector to be ambiguous, further misleading the streamlines. This problem is aggravated by the fact that streamlines are often computed, displayed, and analyzed at subvoxel resolution-suggesting a level of precision that is not warranted  by the data. Finally, region-to-region analysis with conventional tractography is challenging, because there is no way to steer tracts from a seed point toward a particular target region. To address these problems, several researchers propose tractography algorithms that rely on a stochastic integration, in which flow vector are chosen from a distribution around the principal eigenvector. These stochastic techniques can be combined with Monte-Carlo simulations, which may include tens of thousands of paths from a single seed, of which only a small fraction will typically reach the target <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b13">14]</ref>.</p><p>Several H-J methods for white matter connectivity have been proposed to overcome some of the difficulties arising in tractography. These methods compute the cost of the shortest path from a seed region to every pixel in the volume (usually a white matter mask). This cost function consists of an integral that depends on path position and orientation, and typically penalizes paths that do not agree with the tensors. These H-J formulations result in first-order partial differential equations (PDEs) which model evolving fronts whose speeds are determined by information from the diffusion tensor. These methods are inherently more robust to noise in the diffusion weighted measurements than standard tractography. Parker et al. <ref type="bibr" target="#b17">[18]</ref> evolve a front with speed related to the inner product of the front normal with the principal eigenvector of the tensor. O'Donnell et al. <ref type="bibr" target="#b15">[16]</ref> propose using the diffusion tensor as a Riemannian metric in the image domain and compute a front representing arrival time of geodesics beginning at a single seed point. Connectivity to that point is defined as a ratio of Euclidean path length to Riemannian distance. Jackowski et al. <ref type="bibr" target="#b7">[8]</ref> use a speed derived as a function of the diffusivity magnitude in the front normal direction. They solve this Hamiltonian equation using a Lax-Friedrichs scheme, also beginning with an initial seed point. Pichon et al. <ref type="bibr" target="#b19">[20]</ref> define a directionally dependent local cost function that extends the H-J framework to high-angular diffusion data. In all of these works, the end result is either a dense field of connectivities to regions or a set of optimal paths emanating from a seed region, which are determined by integrating the characteristics of the PDEs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Hamilton-Jacobi equation solver</head><p>A number of different numerical strategies have been proposed to efficiently solve the H-J equation. These methods can be classified into two groups. One is a class of iterative methods based on a fixed-point update using Jacobi or Gauss-Seidel schemes. An early work by Rouy et al. <ref type="bibr" target="#b22">[23]</ref> solves the Eikonal equation, a special case of H-J equation, by updating the solutions of the grid using a pre-defined updating order and Godunov upwind Hamiltonian until they converge. Zhao <ref type="bibr" target="#b29">[30]</ref> proposed the Fast Sweeping method, which uses a Gauss-Seidel updating order for fast convergence. Tsai et al. <ref type="bibr" target="#b28">[29]</ref> employed the Fast Sweeping method and a Godunov upwind discretization of the class of convex Hamiltonians to solve anisotropic H-J equations. The proposed Godunov Hamiltonian uses only 1-neighborhood pixels, so it maps well on iterative schemes. However, there are many cases to check for the correct solution of the Hamiltonian. Kao et al. <ref type="bibr" target="#b10">[11]</ref> introduced a new interpretation of Hamiltonians based on the Legendre transformation, and in a subsequent paper <ref type="bibr" target="#b9">[10]</ref> they employed the Lax-Friedrichs Hamiltonian for arbitrary static H-J equations. The proposed method is simple to implement and can be used widely on both convex and non-convex H-J equations, but it requires many more iterations than the Godunov Hamiltonian and the solution shows excessive diffusion due to the nature of the scheme.</p><p>Another class of H-J solvers is based on adaptive updating schemes and sorting data structures. An earlier work by Qin et al. <ref type="bibr" target="#b21">[22]</ref> and later Sethian et al. <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b25">26]</ref> used a Dijkstra-type shortest path algorithm to solve H-J equations, which is generally referred to as the Fast Marching method. The main idea behind this method is that solutions for a convex Hamiltonian depend only on the upwind neighbors along the characteristics, so the causality relationship can be determined uniquely and the correct solutions can be computed by only a single pass update. The complexity of the Fast Marching method is O(NlogN), which is worst-case optimal, and the running time is not much affected by the complexity of the speed. However, for a class of general H-J equations <ref type="bibr" target="#b25">[26]</ref>, tracing the characteristics can cause expensive searching among a wider range of neighborhoods than solving equations using an iterative numerical method. In addition, the method uses a global sorting data structure, e.g., a heap, and therefore the parallelization is not straightforward.</p><p>Even though there has been much research effort on general purpose computing using the GPU, so far no one has developed a parallel algorithm for solving general H-J equations on the GPU. The closest work has focused on the distance or Voronoi diagrams computations on the GPU, which is equivalent to solving the Eikonal equation with a constant speed, a special case of the H-J equation. Hoff et al. <ref type="bibr" target="#b6">[7]</ref> first used OpenGL API and hardware rasterization in the fixed graphics pipeline to compute approximated Voronoi diagrams. Sigg et al. <ref type="bibr" target="#b26">[27]</ref> employed a scan conversion algorithm and used fragment programs to compute the distance to triangular meshes within narrow bands around the mesh. Sud et al. <ref type="bibr" target="#b27">[28]</ref> proposed a method to reduce unnecessary distance computations by using culling and clamping algorithms. The distance transform approaches shown above are all based on the assumption of isotropic constant speed over the domain, so they are not applicable to solving the H-J equation based on anisotropic tensor speed functions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">REGION-TO-REGION CONNECTIVITY</head><p>Our formulation of region-to-region connectivity is based on the principle of minimal cost paths. Using information from the entire diffusion tensor, we construct a local cost function based on the current position and directionality of a path. This leads to a first-order nonlinear PDE that computes the minimal cost from a starting region to each point in the image. Unlike previous front-propagation methods for DT-MRI, we then solve for minimal cost from a second target region. The two solutions are then combined, giving the minimal cost through each voxel of paths restricted to travel between the two target regions. The minimal cost function can then be used to threshold the data for visualization of only the pertinent white matter pathways. Also, the cost function serves as a measure of the strength, or integrity, of the connection. Visualizations of this cost function can be used to locate abnormalities, or weaknesses, in the white matter pathways in individuals with neuropsychiatric disorders.</p><p>An overview of our interactive region-to-region connectivity visualization system is shown in <ref type="figure" target="#fig_1">Figure 1</ref>. First, a volume rendering of the fractional anisotropy (FA), which is a measure of the anisotropy or elongation of the tensors, is displayed. Next, two starting seed points are chosen on 2D orthogonal slices of the FA map as the endpoints of the desired white matter pathway. Next, the cost function is computed using the GPU H-J solver as described in this paper. The cost function is volume rendered, displaying the areas of high connectivity between the two regions. Finally, the current pathway can be rendered by thresholding the cost function.</p><p>Given a path c :</p><formula xml:id="formula_0">[a, b] → Ω,</formula><p>where Ω is a compact image domain, we define the total cost of c as</p><formula xml:id="formula_1">E(c) = b a ψ(c(t), T (t))dt,<label>(1)</label></formula><p>where</p><formula xml:id="formula_2">T (t) = c (t)/ c (t)</formula><p>is the unit tangent vector of c. The total cost is defined as the integral of a local cost function, ψ :</p><formula xml:id="formula_3">Ω × S 1 → R, where ψ(x, v)</formula><p>gives the cost of moving in the unit direction v ∈ S 1 from the point x ∈ Ω. We require that the local cost be symmetric,</p><formula xml:id="formula_4">ψ(x, v) = ψ(x, −v)</formula><p>, which is generally consistent with the model of diffusion through passive media. This metric in (1) allows for a wide range of cost functions ψ that incorporate tangents. Pichon et al. <ref type="bibr" target="#b19">[20]</ref> describe the properties of this metric, the choices of ψ for high-angular diffusion data, and the relationship between this cost function and the corresponding speed that controls the motion of the wavefront in the H-J formulation. In this work we use a quadratic (bilinear) local cost function, with the understanding that all of the results in this paper generalize to highangular data using the methods described in <ref type="bibr" target="#b19">[20]</ref>. Thus we have</p><formula xml:id="formula_5">ψ(x, v) = v T M(x)v,<label>(2)</label></formula><p>where M(x) is a symmetric, positive-definite matrix defined at each point x ∈ Ω.</p><p>The relationship between the measured diffusion tensor field, D, and the metric for the path cost, M, must be considered carefully. We find that using the inverse of the original tensor field, M = D −1 , as proposed in most H-J DTI approaches <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b19">20]</ref>, does not sufficiently penalize paths in directions perpendicular to the major eigenvector. In fact, shortest paths using this method typically look almost identical to the paths defined by isotropic metrics constrained the white matter mask. Thus, we use a sharpened tensor field, which is the original tensor field raised to a power α. This must be combined with a normalization, and for this work we normalize by the tensor volume. If we consider the sharpened tensor to be speed (in the H-J formulation), which gives low cost along the principal eigen directions, the cost is the inverse, and we have</p><formula xml:id="formula_6">M(x) = |D(x)| − 1 3 D(x) |D(x)| 1 3 −α ,<label>(3)</label></formula><p>where α &gt; 1 is a constant and |D(x)| denotes the determinant of D(x). We used α = 3 for all of the experiments in this paper. We can consider all paths emanating from a region R 1 ⊂ Ω. Let u 1 (x) denote the minimal cost as defined by (1) over all paths beginning in the region R 1 and terminating at the point x. Then u 1 satisfies the convex H-J equation given as follows:</p><formula xml:id="formula_7">H(∇u 1 , x) = (∇u 1 ) T M(∇u 1 ) = 1, ∀x ∈ Ω,<label>(4)</label></formula><p>where Ω is a domain in R n , u 1 (x) is the travel time or distance from the source, R 1 , and M is the speed matrix defined on Ω by Equation 3. We use the Hamiltonian defined below for our 3D DT-MRI connectivity problem:</p><formula xml:id="formula_8">H(p, q, r) = ap 2 + dq 2 + f r 2 + 2(bpq + cpr + eqr) (5) M = ⎡ ⎣ a b c b d e c e f ⎤ ⎦ , p = ∂ u i ∂ x , q = ∂ u i ∂ y , r = ∂ u i ∂ z</formula><p>where p, q, and r are partial derivatives of u i at x along x, y, and z axis, and a, b, c, d, e, and f are triangular elements of the matrix M. Equation 4 becomes the Eikonal equation when M is an identity matrix. While u 1 gives us a measure of the connectivity from the region R 1 to any point in the image, we would like to assess the specific connectivity to a second target region. To do this, we define a second region R 2 ⊂ Ω and corresponding minimal cost function u 2 also satisfying <ref type="bibr" target="#b3">(4)</ref>. Consider all paths beginning in the region R 1 and terminating in R 2 . Now we define the total cost function for regions R 1 and R 2 to be u(x) = u 1 (x)+u 2 (x). The value of u(x) is the minimal cost of all paths between R 1 and R 2 that are constrained to pass through x. <ref type="figure" target="#fig_2">Figure 2</ref> shows the cost functions for paths along genu ((a) u 1 , (b) u 2 , and (c) the total cost We use the total cost function u to define which voxels in the image are contained in the pathway of interest. Let γ be the minimal total cost path, and fix a threshold ε ≥ 0, which is the tolerance of paths relative to the optimum. We define an ε-point as a point whose constrained minimum cost is less than (1 + ε)E(γ). The set of all such ε-points defines an volumetric pathway between R 1 and R 2 . This region is the set of voxels that belong to the fiber connection between R 1 and R 2 . By definition, a volumetric pathway must contain γ for any value of ε ≥ 0.</p><formula xml:id="formula_9">u = u 1 + u 2 ). (a) Cost u 1 (b) Cost u 2 (c) Total cost u</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">PARALLEL HAMILTON-JACOBI EQUATION SOLVER</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Fast Iterative Method</head><p>FIM is a numerical algorithm to solve PDEs, such as Equation 4, on parallel architectures. The main idea of FIM is to solve the H-J equation selectively on the grid nodes without maintaining expensive data structures. FIM maintains a narrow band, called the active list, for storing the index of grid nodes to be updated. Instead of using a special data structure to keep track of exact causal relationships, it maintains a looser relationship and update all nodes in the active list simultaneously (i.e., Jacobi update). During each iteration, we expand the list of active nodes, and the band thickens or expands to include all nodes that could be influenced by the current updates. A node can be removed from the active list when the solution is converged, and re-inserted when any changes of its adjacent neighbors affect the solution of the current node. Note that newly inserted nodes must be updated in the following update iteration to ensure a correct Jacobi update. To compute the solutions of the nodes in the active list, we use the Godunov upwind discretization of the Hamiltonian (section 4.2). The key ideas of the proposed algorithm are two fold: allowing multiple updates per node by reinserting nodes to the active list, and using a Jacobi update for parallel computation. It turns out that the proposed algorithm is an example of a class of label-correcting algorithms <ref type="bibr" target="#b20">[21]</ref>. Algorithm 4.1 is the pseudo code of FIM (U x is a discrete approximation of u(x), and g(U x ) is a new solution at x that satisfies Equation 4 computed using a Godunov Hamiltonian H G in Equation 6). </p><formula xml:id="formula_10">for each x ∈ X do ⎧ ⎨ ⎩ if x is source then U x ← 0 else U x ← ∞ for each x ∈ X do if any neighbor of x is source then add x to L comment: 2. Update nodes in L while L is not empty do ⎧ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎨ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎩ for each x ∈ L do ⎧ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎨ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎩ T old ← U x T new ← g(U x ) if T old &gt; T new then U x ← T new if |T old − T new | &lt; ε then ⎧ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎨ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎩ for each 1-neighbor x nb of x do ⎧ ⎪ ⎪ ⎪ ⎪ ⎪ ⎨ ⎪ ⎪ ⎪ ⎪ ⎪ ⎩ if x nb is not in L then ⎧ ⎪ ⎪ ⎪ ⎨ ⎪ ⎪ ⎪ ⎩ T old ← U x nb T new ← g(U x nb ) if T old &gt; T new then U x nb ← T new add x nb to L remove x from L</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Godunov Hamiltonian</head><p>To efficiently solve convex H-J equations, we employ a similar Godunov upwind Hamiltonian as introduced in <ref type="bibr" target="#b28">[29]</ref>. The Godunov Hamiltonian H G for the H-J equation on 3D grid can be defined as follows: </p><formula xml:id="formula_11">H G (p, q, r) = ext p∈I[p − ,p + ] ext q∈I[q − ,q + ] ext r∈I[r − ,r + ] H(p, q, r) (6) where ext x∈I[a,b] = min x∈[a,b] if a ≤ b ext x∈I[a,b] = max x∈[b,a] if a &gt; b p ± = D x ± u, q ± = D y ± u, r ± = D z ± u</formula><formula xml:id="formula_12">H(sgn max{(p − − p σ ) + , (p + − p σ ) − } + p σ , q, r) = 1 H(p, sgn max{(q − − q σ ) + , (q + − q σ ) − } + q σ , r) = 1 H(p, q, sgn max{(r − − r σ ) + , (r + − r σ ) − } + r σ ) = 1</formula><p>Even though the above test to check the validity of the solution looks mathematically clean and works well, practically it is not efficient due to two reasons. First, this test requires three evaluations of the Hamiltonian, which is an expensive operation. Second, we need to use a threshold to numerically check the floating point equality (|H − 1| &lt; ε), which may induce numerical errors. The new validity test we propose is based on the observation that if the solution is valid then p, q, or r used to compute the solution must be a correct value. For example, if we use p = p − , then sgn max{(p − − p σ ) + , (p + − p σ ) − } + p σ = p − must hold. Checking equality for this equation can be done efficiently because we can encode the left and the right side of the equation using integers, +1, 0, and -1, and compare equality of the integers. The right side index is determined by p, and the left side index is determined by p − , p + , and p σ based on the new solution.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Right side index</head><formula xml:id="formula_13">= ⎧ ⎨ ⎩ 0 if p = p σ +1 if p = p + −1 if p = p − Left side index = ⎧ ⎨ ⎩ 0 if p − &lt; p σ &lt; p + +1 else if (p − + p + )/2 &lt; p σ −1 else</formula><p>The proposed test does not entail an extra burden of Hamiltonian computations, and can be done using only simple integer equality and float inequality comparisons. Our experiments show that using the new validity test can increase the performance about 50% compared to the original method <ref type="bibr" target="#b28">[29]</ref>. The pseudo code for computing a new solution g(U x ) is given in <ref type="bibr" target="#b8">[9]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">GPU IMPLEMENTATION 5.1 GPU FIM for H-J Solver</head><p>We have chosen the GPU to implement FIM to solve the H-J equation. The major difference between the CPU and the GPU implementation of FIM is that the GPU employs a block-based updating scheme, as proposed by Lefohn et al. <ref type="bibr" target="#b14">[15]</ref> in the context of interactive level set computations, because the GPU architecture favors coherent memory access and control flows. The original node-based FIM (Algorithm 4.1) can be easily extended to a block-based FIM as shown in Algorithm 5.1. For a block-based update, the domain is decomposed into pre-defined size blocks (we use a 4 3 cube for 3D in the GPU implementation), and solutions of the pixels in the same block are updated simultaneously with a Jacobi update scheme. Therefore, the active list of the GPU maintains the list of active blocks instead of nodes. The GPU FIM algorithm consists of three steps. First, each active block is updated with a pre-defined number of iterations. During each iteration, a new solution of Equation 4 is computed, replace the old solution if the new solution is smaller, and its convergence is encoded as a boolean value. After the update step, we perform a reduction (Section 5.2.3) on each active block to check whether it is converged or not. If a block is converged, we mark it as to-be-removed. The second step is checking which neighbor blocks of to-be-removed blocks need to be re-activated. To do this, all the adjacent neighbor blocks of tobe-removed blocks are updated once, and another reduction operation is applied on each of the neighbor blocks. The final step is updating the active list by checking the convergence of each block. Only nonconverged blocks (i.e., C b is false) will remain in the active list. The following is a GPU FIM pseudo code for updating active blocks (C p and C b are introduced in Section 5.2).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Implementation Detail</head><p>Our GPU H-J solver is implemented on an NVIDIA GeForce 8800 GTX graphics card. NVIDIA CUDA <ref type="bibr" target="#b1">[2]</ref> is used for GPU programming, and we will explain the GPU implementation details based on the CUDA programming model (please refer to the CUDA programming guide <ref type="bibr" target="#b1">[2]</ref> for more details about the GPGPU programming using CUDA). Computation on the GPU entails running a kernel with a batch process of a large group of fixed size thread blocks, which fits well the block-based update method used in the FIM algorithm. We fix the block size to 4 <ref type="bibr" target="#b2">3</ref> , so 64 threads share the same shared memory and are executed in parallel on the same processor unit.</p><p>It is not necessary to use special data structures, e.g., list or vector, to implement the active list on the GPU. Therefore, we use a simple 1D integer array whose size is the total number of blocks to store active blocks. Only the array elements of index ranging between 0 to (number of total active blocks-1) are valid at any given time. For each CUDA kernel call, the grid size is adjusted to the current number of active blocks, and when a block is being processed, its block index is retrieved from the active list on the GPU. Updating solutions and reductions, which are computationally dominant in the overall process, are done entirely on the GPU.</p><p>In the GPU memory, we create two sets of boolean arrays, one C p with a size of the number of pixels (i.e., nodes), and the other C b with a size of the number of blocks, to store convergence of pixels and blocks, in addition to a float array with a size of the number of pixels to store solutions. To check the convergence of blocks, we run a reduction on C p to get C b . Managing the active list, e.g., inserting or deleting blocks from the list, is efficiently done on the CPU by reading back C b to the CPU and looping over it to insert only non-converged blocks to the active list. When the list is completely updated on the CPU, it is copied to the GPU, but only a small part of the active list is actually used at any given time (index 0 to (number of active blocks-1)), so only a small fraction of contiguous memory needs to be copied to the GPU.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.1">Data Packing for Coalesced Global Memory Access</head><p>To efficiently move data from global to shared memory on the GPU, we need to pack the data in the GPU memory space in a certain way to access global memory as a single contiguous, aligned memory access (coalesced memory access <ref type="bibr" target="#b1">[2]</ref>). Volumes are stored in memory as an 1D array with a certain traversing order. <ref type="figure" target="#fig_6">Figure 3</ref> shows an example of two different cases of storing a 4x4 image in the GPU global memory space as 1D array when a block is copied to shared memory. Host memory is the CPU side memory, and global / shared memory is the GPU side memory. Color represents the pixels in the same block. Usually pixels are stored from the fastest to the slowest axis order, as shown in <ref type="figure" target="#fig_6">Figure 3 (a)</ref>. In this case, a block is split into two regions in global memory space, which leads to split block accesses. However, if we re-order global memory as shown in <ref type="figure" target="#fig_6">Figure 3 (b)</ref>, accessing a block can be a single coalesced memory access, which is the most efficient way to access global memory on the GPU. Hence, whenever input volumes are copied from the CPU to the GPU memory, a proper re-ordering should be applied so that the block access can be done through a coalesced memory access.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.2">Efficient Neighbor Access using Shared Memory</head><p>Another factor that affects the GPU performance is accessing shared memory. The shared memory space in the NVIDIA G80 architec- ture is divided into 16 banks, and 16 shared memory accesses can be done simultaneously as long as all the memory requests refer to different memory banks or to the same memory bank. If any two memory requests, but not all, refer to the same memory bank, i.e., bank conflict, then this request must be serialized, and this impairs the performance. Because the block size is fixed to 4 3 , there is no bank conflict to access pixels inside blocks (block size is a multiple of warp size <ref type="bibr" target="#b1">[2]</ref>). However, we need adjacent neighbor pixels to solve the PDEs, so we should set up an additional shared memory space for left/right/up/down/top/bottom neighbors of the boundary pixels of each block.</p><p>To avoid bank conflicts, we assign the neighbor pixels to predefined banks, which requires a slightly larger extra shared memory space. <ref type="figure" target="#fig_8">Figure 4</ref> shows a 2D example of the bank assignment that avoids bank conflicts for neighbor pixel access. The block size for this example is 16 (4x4), which is drawn as a yellow box on the leftmost image in <ref type="figure" target="#fig_8">Figure 4</ref>. The extra four pixels on each left/right/up/down side of the block are neighbor pixels. The number on each pixel represents the bank number to be assigned. By assigning pixels to shared memory in this pattern, memory requests for left/right/up/down neighbors can be done simultaneously without a bank conflict <ref type="figure" target="#fig_8">(Figure 4</ref> red : left neighbors, cyan : right neighbors, green : up neighbors, blue : down neighbors). We need shared memory of size 3*blocksize to store a block and its neighbors because some bank numbers appear twice (1, 4, 13, and 16 in <ref type="figure" target="#fig_8">Figure 4</ref>). <ref type="figure" target="#fig_10">Figure 5</ref> shows an example of actual pixel assignment in shared memory. <ref type="figure" target="#fig_10">Figure 5 (a)</ref> shows a 2D block diagram with pixel indices (not bank numbers). <ref type="figure" target="#fig_10">Figure 5</ref> (b) shows which bank each pixel is actually assigned to. <ref type="figure" target="#fig_10">Figure 5 (c)</ref> shows a snapshot of a shared memory access pattern when left neighbors are accessed (same case as the second diagram from left in <ref type="figure" target="#fig_8">Figure 4</ref>). Pixels colored in red are accessed by 16 threads in parallel. Because there is no bank conflict, this memory request can be processed simultaneously. The 2D bank assignment technique can be easily extended to 3D by using slightly larger shared memory for storing top and bottom neighbors.      </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.3">Reduction</head><p>Reduction is one of the commonly used computational techniques in the streaming programming model to produce a smaller stream from a larger input stream. To check the convergence of a block, we need to check the convergence of every pixel in the block. Therefore, we need to reduce a block down to a single pixel that represents the convergence of the block. Lefohn et al. proposed a reduction on the GPU using a fragment shader to check the activity in blocks in <ref type="bibr" target="#b14">[15]</ref>. We implemented a parallel reduction in a single kernel execution using a block-level thread synchronization provided by CUDA. To reduce a block of size n, start with n 2 threads. For each iteration, every thread participating in reduction reads two convergence values from the current block and write a true or false to one of the original locations (both converge : true, else false). In the next iteration, the number of participating threads is halved and the same reduction is performed. This process is repeated until a block is reduced to a single pixel.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">RESULTS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Connectivity Visualization</head><p>To demonstrate our interactive DTI connectivity visualization for real clinical data, we applied our method to a single high-resolution (2 × 2 × 2.5mm 3 ) 3T image from a database of healthy controls. Using an interface in which points can be selected interactively on the tensor data set, we selected the terminal regions R 1 and R 2 at the white/grey matter interface for each tract we analyzed. <ref type="figure" target="#fig_11">Figure 6</ref> (a) shows the interactive path extraction using two selected points along the cortocospinal tract. A volume rendering of the total cost function u is displayed with blue representing lowest cost regions. The total cost function represents the strength, or integrity, of the connection, and this visualization could be used by clinicians to locate degradations in the white matter. The cortocospinal tract, which is a major pathway connecting the spinal cord to the motor cortex, has high connectivity and thus shows up as bright blue. Next, we selected five tracts for visualization: three bundles through the genu (GCC), splenium (SCC), and body (BCC) of the corpus callosum, and the left (LCG) and right (RCG) cingulum bundles. <ref type="figure" target="#fig_11">Figure 6</ref> (b) and (c) show isosurface renderings of the resulting volumetric pathways from the five selected tracts. These volumetric pathways can then be used to define a culling region for displaying the tensor data only in the pathways of interest, as shown in <ref type="figure">Figure 7</ref>. In <ref type="bibr" target="#b5">[6]</ref> the authors describe nonparametric methods for quantifying DTI and geometric information along tracts.  <ref type="figure">Figure 8</ref> show the running time of three H-J equation solvers (GPU, CPU Fast Sweeping with Godunov Hamiltonian, and CPU Fast Sweeping with Lax-Friedrichs Hamiltonian) and their solutions on three synthetic and real tensor volumes. We have tested H-J solvers on a PC equipped with a Intel Core 2 Duo 2.4GHz processor and an NVIDIA GeForce 8800 GTX graphics card.  <ref type="figure">Figure 8</ref> (a). The GPU solver took only 1 sec while the CPU solvers take about 1-2 minutes to compute the solution on this volume.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Running time comparison</head><p>Example 2 is a 64 3 volume with tensors aligned to a helix. We built a tensor whose dominant eigenvector is parallel to the tangent vector of the helix curve, and set the dominant eigenvalue as 1.0 and the other two eigenvalues as 0.0001. <ref type="figure">Figure 8 (b)</ref> is the solution and characteristic paths tracing from randomly distributed points to the seed point placed on the center of the bottom slice. The GPU solver took 1.5 second, while the CPU solvers took 1-3 minutes on this volume.</p><p>Example 3 is a DT-MRI brain volume of size 256x256x100, with the number of effective pixels is 196K (we only run the solver inside the white matter mask), and the solution is given in <ref type="figure">Figure 8</ref> (c). We put a seed at the center of the white matter region. The GPU solver runs less than 3 seconds while the CPU solver took 5 minutes on this volume. Overall, the proposed GPU H-J solver runs roughly 50-100 times faster than the commonly used CPU-based methods, allowing users for interactive volumetric paths extraction in DT-MRI volumes. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Discussion</head><p>The proposed GPU-FIM algorithm, in contrast to other labelcorrecting algorithms <ref type="bibr" target="#b20">[21]</ref>, scales well on massively parallel architectures by adopting a block-based parallel updating scheme. The proposed method uses the same discretization of Godunov Hamiltonian that is used in <ref type="bibr" target="#b28">[29]</ref>, so the solutions are exactly same as the fast sweeping methods. However, due to the hardware floating point implementation on different architectures (CPU and GPU), there is a small numerical difference between the solutions of those methods, but the difference is minimal and does not affect the quality of the extracted paths. Even though this paper focuses mainly on the computational aspect of the white matter pathway visualization, it is worth mentioning the pros and cons of the proposed method compared to the existing tractography methods. Global tractography gives interesting holistic visualizations of white matter architecture, which may be useful to the uninitiated. In contrast, the proposed method can provide a systematic method to query the quality of a particular path of interest, which is useful to experienced neuroscientists who already know the white matter architecture but wish to be able to easily and repeatably iden- <ref type="figure">Fig. 7</ref>. Tensor field visualization along the volumetric pathways using superquadric glyphs <ref type="bibr" target="#b11">[12]</ref> using the SCIRun software <ref type="bibr" target="#b0">[1]</ref>. From left to right: a) tensor visualization; b) zoom in view near BCC. tify white matter circuitry across populations of subjects or patients. In addition, tractography is sensitive to noise and oblique shapes in DT-MRI, while the proposed method is robust to them. A nice example is the arcuate fasciculus, which connects Wernicke's and Broca's areas (frontal and temporal cortex) shown in figure 9. This tract is not easy to find because it crosses through some ambiguous regions as it descends to the temporal lobe (temporoparietal junction). <ref type="figure">Figure 9</ref> right shows a close up picture of a typical result from tractography that shows the difficulty of locating tracts that connect these two relatively small regions, especially where the alignment of the tensors become ambiguous. The tractography result ends abruptly, and none of the many thousands of tracks we seeded successfully connected these two regions. In contrast, the proposed method robustly finds the optimal path between the end points that minimizes the total cost value, which are much less affected by noise and ambiguity (figure 9 left).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">CONCLUSION</head><p>A fast method to compute and visualize white matter connectivity in DT-MRI volume using graphics hardware is presented. The proposed method computes the connectivity as the minimum distance from a given source region, and define the total cost by summing the connectivity value from each source region. The proposed method finds a volumetric optimal path as a set of voxels in the DTI volume that contain paths between two regions whose costs are within a threshold of the optimal path. To quickly compute the cost function, we introduce a novel GPU H-J solver, which runs roughly 50-100 times faster than existing CPU-based solvers, allowing users to freely change the endpoints of interesting pathways and to visualize the optimal volumetric path between them at an interactive rate.</p><p>Introducing a fast volumetric connectivity extraction tool opens up numerous interesting future research directions. Because the GPU implementation of the FIM allows rapid computation of white matter connections, this makes computation of a full brain connectivity map feasible. This process could be automatically initialized with starting regions from a parcellation of the cortical surface, such as that produced by Freesurfer <ref type="bibr" target="#b4">[5]</ref>. The proposed GPU H-J solver can be also applied to wider range of applications other than DT-MRI image analysis. For example, seismic wave propagation simulation in an anisotropic speed volume will be a direct application of the GPU H-J solver for geoscience research. Extensive performance analysis and comparison of the GPU solver with existing solvers will be another interesting future work.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Published 14</head><label>14</label><figDesc>September 2007.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 1 .</head><label>1</label><figDesc>System Overview. From left to right: a) Input DT-MRI volume; b) Seed points (marked as red circles); c) Cost volume (blue to red : low to high); d) Volumetric path along genu (blue).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 2 .</head><label>2</label><figDesc>The cost functions for genu. Blue to red: low cost to high cost.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Algorithm 4 . 1 :</head><label>41</label><figDesc>FIM(X) comment: 1. Initialization (X : set of all grid nodes, L : active list)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>, and I[a, b] is the closed interval bounded by a and b. This definition of the Godunov Hamiltonian looks complicated, but the main idea is evaluating the Hamiltonian H(p, q, r) with all possible combination of p = {p − , p + , p σ }, q = {q − , q + , q σ }, and r = {r − , r + , r σ } where p σ , q σ , and r σ are critical points (because the extremum of a convex Hamiltonian occurs only on either the end of the interval or the critical point), and taking the valid minimum solution that satisfies Equation 4. To check the validity of the solution for H(p, q, r), Tsai et al. proposed the following conditions<ref type="bibr" target="#b28">[29]</ref>.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Algorithm 5 . 1 : 1 -</head><label>511</label><figDesc>GPU FIM(L,V ) comment: Update blocks b in active list L, V :list of all blockswhile L is not empty do ⎧ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎨ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎩ comment: Step 1 -Update Active Blocks for each b ∈ L do ⎧ ⎨ ⎩ for i = 0 to n do (b,C p (b)) ← g(b) C b (b) ← reduction(C p (b)) comment: Step 2 -Check Neighbors for each b ∈ L and do neighbor b nb of b do (b nb ,C p (b nb )) ← g(b nb ) C b (b nb ) ← reduction(C p (b nb )) comment: Step 3 -Update Active List clear(L) for each b ∈ V do if C b (b) = false then Insert b to L</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 3 .</head><label>3</label><figDesc>Example of coalesced/non-coalesced global memory access</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 4 .</head><label>4</label><figDesc>Neighbor pixel access without shared memory bank-conflict</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>1</head><label>1</label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Fig. 5 .</head><label>5</label><figDesc>Bank assignment example</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Fig. 6 .</head><label>6</label><figDesc>Volumetric pathways extractions using the proposed method. From left to right: a) cortocospinal tract; b) isosurface rendering of volumetric paths shown with FA slice; c) isosurface rendering of volumetric paths only. GCC(cyan), BCC(yellow), SCC(red), LCG(green), and RCG(blue). The SCIRun software<ref type="bibr" target="#b0">[1]</ref> is used to render final isosurfaces.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Example 1</head><label>1</label><figDesc>is a 64 3 volume with a constant tensor elongated along the diagonal direction (a = d = f = 1.0 and b = c = e = 0.9). The level sets of the solution on this volume is shown in</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Fig. 8 .Fig. 9 .</head><label>89</label><figDesc>Visualization of distance from a seed point. From left to right: a) Example 1 : tensor elongated toward diagonal direction; b) Example 2 : helix; c) Example 3: DT-MRI brain data. Comparison between the proposed method and tractography method to extract the arcuate fasciculus connecting frontal and temporal cortex. Left : Volumetric path from the proposed method. Right : Paths from the tractography method. Yellow dotted curve represents the arcuate fasciculus area.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 and</head><label>1</label><figDesc></figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 1 .</head><label>1</label><figDesc>Running time on 3D tensor volumes. L-F was not tested on example 3 due to its complex boundary.</figDesc><table><row><cell></cell><cell cols="3">Example 1 Example 2 Example 3</cell></row><row><cell>GPU FIM</cell><cell>1 sec</cell><cell>1.5 sec</cell><cell>2.8 sec</cell></row><row><cell>CPU FS Gdv</cell><cell>54 sec</cell><cell>76 sec</cell><cell>301 sec</cell></row><row><cell>CPU FS L-F</cell><cell>142 sec</cell><cell>220 sec</cell><cell>N/A</cell></row></table><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGEMENTS</head><p>This work is part of the National Alliance for Medical Image Computing (NAMIC), funded by the National Institutes of Health through the NIH Roadmap for Medical Research, Grant U54 EB005149. This work has been supported in part by ExxonMobil Upstream Research Company. The visualizations in <ref type="figure">Figure 6</ref> and 7 in this paper were produced with the BioPSE/SCIRun software package released by the Center for Integrative Biomedical Computing, NIH NCRR Project 2-P41-RR12553-07</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">SCIRun: A scientific computing problem solving environment, Scientific Computing and Imaging institute (SCI)</title>
		<ptr target="http://software.sci.utah.edu/scirun.html" />
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">NVIDIA CUDA programming guide</title>
		<ptr target="http://developer.nvidia.com/object/cuda.html" />
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">In-vivo fiber tractography using DT-MRI data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">J</forename><surname>Basser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Pajevic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Pierpaoli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Duda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Aldroubi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Magnetic Resonance in Medicine</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="page" from="625" to="632" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Characterization and propagation of uncertainty in diffusion-weighted MR imaging</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Behrens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Woolrich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Jenkinson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Johansen-Berg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Nunes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Clare</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Matthews</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Brady</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Magnetic Resonance in Medicine</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="page" from="1077" to="1088" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Automatically parcellating the human cerebral cortex</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Fischl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Van Der Kouwe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Destrieux</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Halgren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Sgonne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">H</forename><surname>Salat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Busa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">J</forename><surname>Seidman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Goldstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kennedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Caviness</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Makris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Rosen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">M</forename><surname>Dale</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cerebral Cortex</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="11" to="22" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A volumetric approach to quantifying region-to-region white matter connectivity in Difusion Tensor MRI</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">T</forename><surname>Fletcher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W.-K</forename><surname>Jeong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">T</forename><surname>Whitaker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Information Processing in Medical Imaging 2007 Conference Proceedings</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
	<note>to appear</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Fast computation of generalized Voronoi diagrams using graphics hardware</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">E</forename><surname>Hoff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iii</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Keyser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Manocha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Culver</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGGRAPH 1999 Conference Proceedings</title>
		<imprint>
			<date type="published" when="1999" />
			<biblScope unit="page" from="277" to="286" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Estimation of anatomical connectivity by anisotropic front propagation and diffusion tensor imaging</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Jackowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">Y</forename><surname>Kao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">T</forename><surname>Constable</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">H</forename><surname>Staib</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">MICCAI</title>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="663" to="667" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">A fast iterative method for a class of Hamilton-Jacobi equations on parallel systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W.-K</forename><surname>Jeong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">T</forename><surname>Whitaker</surname></persName>
		</author>
		<idno>UUCS-07-010</idno>
		<ptr target="http://www.cs.utah.edu/research/techreports.shtml" />
		<imprint>
			<date type="published" when="2007" />
		</imprint>
		<respStmt>
			<orgName>University of Utah</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Lax-friedrichs sweeping scheme for static Hamilton-Jacobi equations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Kao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Osher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Qian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Computational Physics</title>
		<imprint>
			<biblScope unit="volume">196</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="367" to="391" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Fast sweeping methods for static Hamilton-Jacobi equations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Kao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Osher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Tsai</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002" />
			<pubPlace>Los Angeles</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Department of Mathematics, University of California</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Superquadric tensor glyphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Kindlmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE TVCG/EG Symposium on Visualization</title>
		<meeting>IEEE TVCG/EG Symposium on Visualization</meeting>
		<imprint>
			<date type="published" when="2004-05" />
			<biblScope unit="page" from="147" to="154" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">An investigation of functional and anatomical connectivity using magnetic resonance imaging</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Koch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">G</forename><surname>Norris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H.-G</forename><forename type="middle">M</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neu-roImage</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="241" to="250" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Bootstrap white matter tractography (BOOT-TRAC)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lazar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">L</forename><surname>Alexander</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeuroImage</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="524" to="532" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Interactive deformation and visualization of level set surfaces using graphics hardware</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lefohn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kniss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Hansen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Whitaker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Visualization 2003 Conference Proceedings</title>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="75" to="82" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">New approaches to estimation of white matter connectivity in diffusion tensor MRI: elliptic PDEs and geodesics in a tensor-warped space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Donnell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Haker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-F</forename><surname>Westin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">MICCAI</title>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="459" to="466" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">A survey of general-purpose computation on graphics hardware</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">D</forename><surname>Owens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Luebke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Govindaraju</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Harris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Krüger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">E</forename><surname>Lefohn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">J</forename><surname>Purcell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics Forum</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="80" to="113" />
			<date type="published" when="2007-03" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Estimating distributed anatomical connectivity using fast marching methods and diffusion tensor imaging</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Parker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wheeler-Kingshott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Barker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions on Medical Imaging</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="505" to="512" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">A framework for a streamline-based probabilistic index of connectivity (PICo) using a structural interpretation of MRI diffusion measurements</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">J M</forename><surname>Parker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">A</forename><surname>Haroon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">A M</forename><surname>Wheeler-Kingshott</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Magnetic Resonance Imaging</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="242" to="254" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">A Hamilton-Jacobi-Bellman approach to high angular resolution diffusion tractography</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Pichon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-F</forename><surname>Westin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Tannenbaum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">MICCAI</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="180" to="187" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Implementation of efficient algorithms for globally optimal trajectories</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">C</forename><surname>Polymenakos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Bertsekas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">N</forename><surname>Tsitsiklis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Automatic Control</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="278" to="283" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Finite-difference solution of the eikonal equation along expanding wavefronts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Olsen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Schuster</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Geophysics</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="478" to="487" />
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">A viscosity solutions approach to shape-fromshading</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Rouy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Tourin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM Journal of Numerical Analysis</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="867" to="884" />
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">A fast marching level set method for monotonically advancing fronts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sethian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Natl. Acad. Sci</title>
		<meeting>Natl. Acad. Sci</meeting>
		<imprint>
			<date type="published" when="1996-02" />
			<biblScope unit="volume">93</biblScope>
			<biblScope unit="page" from="1591" to="1595" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Fast marching methods</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sethian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM Review</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="199" to="235" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Ordered upwind methods for static Hamilton-Jacobi equations: Theory and algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Sethian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vladimirsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM Journal of Numerical Analysis</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="325" to="363" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Signed distance transform using graphics hardware</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Sigg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Peikert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gross</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Visualization 2003 Conference Proceedings</title>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="83" to="90" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Difi: Fast 3d distance field computation using graphics hardware</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sud</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Otaduy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Manocha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics Forum</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="557" to="566" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Fast sweeping algorithms for a class of Hamilton-Jacobi equations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-H</forename><forename type="middle">R</forename><surname>Tsai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L.-T</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Osher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H.-K</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM Journal of Numerical Analysis</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="659" to="672" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">A fast sweeping method for eikonal equations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mathematics of Computation</title>
		<imprint>
			<biblScope unit="volume">74</biblScope>
			<biblScope unit="page" from="603" to="627" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
