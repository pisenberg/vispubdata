<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/pisenberg/grobid/grobid-0.6.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A Unified Paradigm for Scalable Multi-Projector Displays</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2007-10-27">27 October 2007</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><roleName>Member, IEEE</roleName><forename type="first">Niranjan</forename><surname>Damera-Venkata</surname></persName>
							<email>niranjan.damera-venkata@hp.com</email>
							<affiliation key="aff0">
								<orgName type="institution">Hewlett-Packard Laboratories</orgName>
								<address>
									<settlement>Palo Alto</settlement>
									<region>CA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><roleName>Member, IEEE</roleName><forename type="first">Nelson</forename><forename type="middle">L</forename><surname>Chang</surname></persName>
							<email>nelson.chang@hp.com</email>
							<affiliation key="aff0">
								<orgName type="institution">Hewlett-Packard Laboratories</orgName>
								<address>
									<settlement>Palo Alto</settlement>
									<region>CA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><roleName>Member, IEEE</roleName><forename type="first">Jeffrey</forename><forename type="middle">M</forename><surname>Dicarlo</surname></persName>
							<email>jeffrey.dicarlo@hp.com</email>
							<affiliation key="aff0">
								<orgName type="institution">Hewlett-Packard Laboratories</orgName>
								<address>
									<settlement>Palo Alto</settlement>
									<region>CA</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">A Unified Paradigm for Scalable Multi-Projector Displays</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2007-10-27">27 October 2007</date>
						</imprint>
					</monogr>
					<note type="submission">received 31 March 2007; accepted 1 August 2007; posted online</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2021-02-20T19:44+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Multi-projector displays</term>
					<term>tiled displays</term>
					<term>large format displays</term>
					<term>blending</term>
					<term>stitching</term>
					<term>automatic geometric alignment</term>
					<term>photometric correction</term>
					<term>super-resolution</term>
					<term>superimposed projection</term>
				</keywords>
			</textClass>
			<abstract>
				<p>We present a general framework for the modeling and optimization of scalable multi-projector displays. Based on this framework, we derive algorithms that can robustly optimize the visual quality of an arbitrary combination of projectors without manual adjustment. When the projectors are tiled, we show that our framework automatically produces blending maps that outperform stateof-the-art projector blending methods. When all the projectors are superimposed, the framework can produce high-resolution images beyond the Nyquist resolution limits of component projectors. When a combination of tiled and superimposed projectors are deployed, the same framework harnesses the best features of both tiled and superimposed multi-projector projection paradigms. The framework creates for the first time a new unified paradigm that is agnostic to a particular configuration of projectors yet robustly optimizes for the brightness, contrast, and resolution of that configuration. In addition, we demonstrate that our algorithms support high resolution video at real-time interactive frame rates achieved on commodity graphics platforms. This work allows for inexpensive, compelling, flexible, and robust large scale visualization systems to be built and deployed very efficiently.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Large format displays (e.g. greater than 100" diagonal) create a compelling environment for the visualization of life-size design, immersive simulation, and multi-modal interaction. However, today's display technologies are prohibitively expensive to scale for large visualization applications. An approach that has gained popularity is to combine multiple projectors into a scalable display for visualization.</p><p>Previous attempts at seamless "scalable" projector displays have been confined to edge-blended tiled projectors, where multiple projectors are configured to minimize the inter-projector overlap and maximize the overall size of the displayed image <ref type="bibr" target="#b20">[20,</ref><ref type="bibr" target="#b18">18,</ref><ref type="bibr" target="#b16">16,</ref><ref type="bibr" target="#b0">1,</ref><ref type="bibr" target="#b9">9]</ref>. These tiled approaches offer scalability of resolution and the ability to have arbitrary aspect ratios. However, tiled projection does not scale well along other image quality attributes. For instance, luminance discontinuities at the overlap regions prevent full brightness utilization. Here, the performance of a tiled array is limited by the quality of the worst projector in the array. If a single projector in a tiled array drifts from color or luminance calibration, or worse yet fails, the entire projector array needs to be changed to accommodate that projector or else the projector needs to be replaced. The dilemma that faces large scalable displays is how to enhance all image quality attributes and yet ensure a reliable system that is not limited by the performance or quality of the worst projector.</p><p>In contrast with tiled projection, superimposed projection is a paradigm where the goal is to maximize projector overlap instead of minimizing it. Superimposed projection has been used in event projection to maximize brightness while also offering robustness to projector failure via redundancy. Superimposed projection often results in a fundamentally more reliable system that can better compensate for common intra-and inter-projector variations (e.g. temporal variations such as color and luminance drift) that plague conventional tiled display walls. At first glance however, the benefits of superimposition seem severely mitigated by an apparent loss of resolution due to the superimposition <ref type="bibr" target="#b14">[14]</ref>. We previously showed both in theory <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b6">6]</ref> and in practice <ref type="bibr" target="#b7">[7]</ref> that superimposed projection can significantly enhance resolution beyond the Nyquist limit of any component projector. We showed that these resolution gains are achievable if we generate the component projector images intelligently. However unlike tiled projection, there are fundamental limits to the resolution gain using superimposed projection alone <ref type="bibr" target="#b6">[6]</ref>.</p><p>The preceding discussion motivates the need for a rigorous framework to support projector configurations that have the benefits of both tiled and superimposed projection. Likewise, there is a need for new algorithms that are capable of robustly optimizing the image quality of an arbitrary combination of projectors without any manual tweaking of blend maps or alignment. Furthermore, the rendering algorithms must also be suitable for video rates on today's high resolution (HD or better) content.</p><p>In this paper, we present a unified paradigm to automatically and efficiently deliver the best image quality for arbitrary multi-projector configurations. The paradigm leads to a multi-projector system that is</p><p>• Flexible: The paradigm can directly handle arbitrary projector configurations including tiled, superimposed, and even novel hybrid configurations; • Scalable: The paradigm scales not only in the number of projectors, but also along a variety of dimensions (e.g. brightness, resolution, aspect ratio, fault tolerance); • Automatic: The proposed camera-based calibration, estimation, and modeling techniques are fully automated; • Real-time: The algorithms can be efficiently implemented on commodity GPUs to create practical real-time display systems; • Vivid: The paradigm delivers seamless and superb image quality regardless of the multi-projector configuration, even delivering super-resolution where multiple projectors overlap.</p><p>Previous work in multi-projector displays has focused separately on only tiled configurations or only superimposed configurations. Techniques appropriate for one configuration will produce sub-optimal results when used for the other. In contrast, this paper proposes a unified paradigm that, for the first time, delivers high quality results from any multi-projector configuration. Examples of prototype multi-projector systems are shown in <ref type="figure" target="#fig_1">Figure 1</ref>. The rest of the paper is outlined as follows. Section 2 describes the model to accurately account for geometry, color, resolution, and spatial luminance characteristics of the entire multi-projector system. Section 3 maps the input image into a target space that is a subspace of the physically realizable outputs. Section 4 derives an efficient rendering algorithm that generates the projector images (a.k.a. subframes) in real-time, such that the overall system is capable of accurately and robustly creating a desired target image. Section 5 shows examples of the framework in action for different projector configurations and demonstrates its advantages over the prior state of the art. Finally,  Section 6 concludes the paper by summarizing the key contributions and motivating future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">MODELING MULTI-PROJECTOR SYSTEMS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Notation</head><p>In this paper, we choose to model images as stacked vectors instead of 2-D arrays. This allows linear operations on images to be represented compactly with matrix multiplications. Matrices and vectors are represented with boldface font, and matrices are capitalized. This approach is convenient in deriving and expressing computational algorithms. Consider a three-color (RGB) digital image</p><formula xml:id="formula_0">y(n 1 , n 2 ) of size N 1 × N 2 .</formula><p>We arrange the R, G, and B components of each pixel in row scan order into a vector to obtain the 3N 1 N 2 × 1 vector y. Linear operations on this image can then be represented by matrix multiplication</p><formula xml:id="formula_1">with 3N 1 N 2 × 3N 1 N 2 matrices.</formula><p>Let us consider a couple of image processing operations that will be important in this paper. First, a 3 × 3 color transformationC applied to each pixel in the image may be represented as</p><formula xml:id="formula_2">Cy = ⎛ ⎜ ⎜ ⎜ ⎝CC . . .C ⎞ ⎟ ⎟ ⎟ ⎠ y = I ⊗C y</formula><p>where ⊗ represents the Kronecker product operator <ref type="bibr" target="#b10">[10]</ref> and I is the</p><formula xml:id="formula_3">N 1 N 2 × N 1 N 2 identity matrix.</formula><p>Second, consider operations that are performed on a color-plane independent basis. For example, a spatial filtering operation using the same filter to process the red, green, and blue color planes of an image, respectively. In this case, the operation may be expressed in matrix form by the equation</p><formula xml:id="formula_4">Ay = ⎛ ⎜ ⎜ ⎜ ⎝Ã (0, 0)I •••Ã(0, N 1 − 1)Ĩ A(1, 0)I •••Ã(1, N 1 − 1)I . . . A(N 1 − 1, 0)I •••Ã(N 1 − 1, N 2 − 1)I ⎞ ⎟ ⎟ ⎟ ⎠ y = Ã ⊗ I y</formula><p>where here I is the 3 × 3 identity matrix. The</p><formula xml:id="formula_5">N 1 N 2 × N 1 N 2 matrixÃ</formula><p>represents the filtering operation on a single N 1 × N 2 color plane. In the above examples and in the paper,˜(tilde) is used to denote an elementary matrix transformation that generates a full matrix operator via the Kronecker product. We use theˆ(hat) accent to denote a predicted matrix or vector.</p><p>In the interest of brevity, the dimension of the matrices and vectors are not explicitly indicated since they should be clear from context. The notation does not distinguish between operators operating on images of different sizes. For example, a color transform applied to an N 1 × N 2 image y is denoted by Cy while the same color transform applied to an M 1 × M 2 image x is also denoted by Cx. Note that the dimensions of the matrix C is different in each case.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Mathematical model of multi-projector systems</head><p>With the above notation in mind, we can proceed to model the image formation process of a multi-projector system. Because light from multiple sources adds linearly, an estimate of the final projected image is given by the summation of the individual projector images. <ref type="bibr" target="#b0">1</ref> The key then is to model the imaging process from input image to the frame buffer of each component projector; let the resolution of the frame buffer of a component projector be</p><formula xml:id="formula_6">N 1 × N 2 .</formula><p>We next choose a target display "canvas" with respect to which each projector image is computed. The target display canvas is assumed to correspond to the largest rectangular region of specified aspect ratio where light from at least 1 ≤ κ ≤ K projectors hits the display surface. The resolution of the target display canvas is the desired resolution at which the final image is computed; we assume it to be M 1 × M 2 , typically larger than any one projector. Mathematically, the model for a K projector system may then be represented as:</p><formula xml:id="formula_7">x = K ∑ k=1 A k L k C k y k + b<label>(1)</label></formula><p>where y k represents the N 1 × N 2 input color image to projector k and x represents the M 1 × M 2 predicted final color image. The matrix C k = I ⊗C k represents the k th projector's color matrix that transforms the projector-dependent RGB color space into a common projector independent reference space (such as XYZ) or to the RGB space of a reference camera. As defined, the matrix C k allows color mixing to be modeled. Several previous approaches to projector tiling treated the red, green, and blue color planes independently <ref type="bibr" target="#b18">[18,</ref><ref type="bibr" target="#b16">16,</ref><ref type="bibr" target="#b9">9]</ref>, ignoring the fact that the same digital value of a primary color displayed by any individual projector potentially excites all of the R, G, and B camera sensors. Not accounting for this mixing results in color blotches and spatially varying color shifts when displaying uniform colors <ref type="bibr" target="#b19">[19,</ref><ref type="bibr" target="#b15">15,</ref><ref type="bibr" target="#b13">13]</ref>.</p><p>The diagonal matrix L k =L k ⊗ I represents the k th projector's spatial luminance rolloff due to lens vignetting in the projector-camera system. This models the fact that the camera image of a flat field of digital values projected by a projector exhibits spatially varying attenuation or vignetting. Each element along the diagonal scales the RGB pixel values at a given pixel location equally. However, the scaling across pixel locations is likely to be different.</p><p>The matrix A k =Ã k ⊗ I represents the resampling operation from the k th N 1 × N 2 low-resolution projector frame buffer to a high resolution display canvas of size M 1 × M 2 . It encapsulates the geometric warps, pixel reconstruction point spread function, and resample filtering operations. Additional details on its derivation may be found in <ref type="bibr" target="#b7">[7]</ref>.</p><p>Finally, the vector b in equation <ref type="formula" target="#formula_7">1</ref>represents the total black offset image of the system. It may be derived from the image the camera captures when all projectors are projecting images of all zeros due to light leakage from the projectors. This camera image, when warped and resampled to the reference display canvas coordinate system, gives the black offset b of the overall system.</p><p>It should be clear in this exposition that we have not assumed a particular configuration of projectors (e.g. tiled, superimposed) and have instead treated all configurations by the summation of the light contributions to a target display canvas by each component projector. Also, while the paper demonstrates results on planar surfaces, this general formulation handles arbitrary display surfaces as well.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Model parameter estimation</head><p>To accurately estimate the parameters of the above model, we introduce a camera into the setup to automatically solve for the above projector parameters in an offline calibration procedure. We leverage the techniques described in <ref type="bibr" target="#b7">[7,</ref><ref type="bibr" target="#b3">4]</ref>.</p><p>• A k : For each projector in sequence, an efficient structured-light coding technique computes the dense projector-camera mapping (a) (b) <ref type="figure" target="#fig_2">Fig. 2</ref>. Comparison between (a) the predicted output and (b) the corresponding actual output for a multi-projector system (six projectors arranged in a "two-wide, three-deep" configuration).</p><p>to cover every subframe location <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b2">3]</ref>. These projector-camera mappings are subsequently remapped to the target display canvas coordinate system to finally obtain the resampling filters A k from each projector to the target display canvas <ref type="bibr" target="#b7">[7]</ref>. • L k and C k : The system also measures the luminance profile and color transform for each projector. Because of cross talk, the camera RGB response to the maximum red, green, and blue of each projector is recorded and remapped to projector coordinates. These responses are then factorized using the technique described in <ref type="bibr" target="#b7">[7]</ref> to obtain L k and C k . • b: The system measures the overall black offset by first capturing an image when the inputs to all projector frame buffers are zero and then remapping it to the target display canvas. As seen from equation <ref type="formula" target="#formula_7">1</ref>, it is sufficient and easier to estimate the overall black offset rather than the individual projector black offsets. <ref type="figure" target="#fig_2">Figure 2</ref> helps to validate the previous modeling and measurement sections. Six projectors are arranged so that three overlapping projectors cover each of half of the screen, the so-called "two-wide, threedeep" configuration. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">THE TARGET SPACE</head><p>Our objective is to make the output of a system of projectors appear as the output of a single hypothetical projector, whose projected output coincides with the target display canvas defined in Section 2.2. The so-called target space describes the desired color and luminance properties of such a virtual projector. It is preferable to construct the target space to ensure a consistent color and smoothly varying luminance.</p><p>It is worth noting that the target space does not include certain colors or intensity values that can be physically projected by the projector system. In fact, the target space is a subspace of the so-called feasible space, the space of outputs achievable by the system of projectors for any valid frame buffer inputs in the range [0,1]. The color and luminance characteristics of feasible space itself may be highly nonuniform. To see this, consider the case when all projectors project full white. The intersection region where projectors overlap will have a much higher intensity than regions where there is no overlap or a smaller degree of overlap; an example can be seen in <ref type="figure" target="#fig_2">Figure 2</ref>.</p><p>From the preceding discussion, we may define the target space as being generated by a single hypothetical virtual "super projector" of resolution</p><formula xml:id="formula_8">M 1 × M 2 . An M 1 × M 2 image</formula><p>x may be represented in the target rendering space using the following mapping:</p><formula xml:id="formula_9">x =LCx +b<label>(2)</label></formula><p>The matrixC = I ⊗C represents a color transform that converts from the color space of the source image to be rendered into the target color space. The matrixL =L ⊗ I represents the spatial luminance characteristics of the virtual projector. The luminance surfaceL simply scales gray input pixel luminance along the white point of the system so that no color shift is introduced about the neutral axis. The vectorb represents the desired target black offset. Clearly, there are constraints in choosingC,L, andb imposed by the fact that the target space must be completely contained within the feasible space. Further, it may be desirable to maximize gamut, achieve a certain white point, or achieve a custom gamut. There is no one optimal value forC. It is highly dependent on user preferences, the application, and the viewing conditions, but it must be chosen to be contained in the feasible space. A simple way to choose aC that is in the feasible space when the projectors have similar color characteristics (typically satisfied by using projectors of the same model) is to define it based on the intersection of the individual gamuts of C k <ref type="bibr" target="#b19">[19]</ref>. This is represented by the equation:</p><formula xml:id="formula_10">C ⊆ ∩ k C k</formula><p>Once the color matrixC has been determined, we can designL to maximize brightness subject to feasibility constraints. It is also desirable to ensure that the variations of the target luminance surface are visually imperceptible. We solve a constrained optimization problem using linear programming to achieve this. It is convenient to illustrate this surface fitting process in one dimension on image rows. Let l(x; r) represent the desired luminance profile for row r. x is the distance along the profile in pixels. Using a basis of N basis functions, <ref type="bibr" target="#b1">2</ref> we may expand l(x; r) as</p><formula xml:id="formula_11">l(x; r) = N ∑ j=1 B j (x; r)θ j r</formula><p>where θ j r are the coefficients in the basis expansion for row r. If this signal is sampled uniformly at M grid locations, we may represent the resulting vector l r in discrete form by the equation</p><formula xml:id="formula_12">l r = B r θ r</formula><p>where the M × N matrix B r is defined by B(i, j; r) = B j (x i ; r). The brightness maximizing curve parameters θ * r may be obtained via linear programming. Specifically,</p><formula xml:id="formula_13">θ * r = argmax θ 1 T B r θ s.t. B r θ ≤ l max r B r θ ≤ +δ 1 B r θ ≥ −δ 1 whereB r (i, j) = ∂ 2 B j (x i ;r) ∂ 2 x , l max r</formula><p>is the maximum feasible luminance, and 1 is simply a column vector of all ones. The derivative constraint assures that the magnitude of the second derivative of any luminance curve is just small enough to be imperceptible by humans. The parameter δ may be set empirically or derived from psychovisual experiments. To get the luminance surface, the above linear program is solved for each row using the dual-simplex algorithm. The dual simplex method is preferred over the simplex method since there are relatively few basis functions in comparison with grid points, so the dual problem has far fewer constraints and can be solved efficiently. Once the curves for each row are obtained, a maximum luminance surface L max is obtained. The above algorithm is run for each column with l max c for the column problem equal to the columns of L max after the row problem has been solved. This separable fitting procedure is both memory efficient and quick. It may be iterated a few times to obtain L = L max .</p><p>A virtually identical procedure to the one outlined above is used to obtain the target black surfaceb by incorporating the constraint that the target black level should lie above the minimum feasible black level. While the luminance surfaceL maximizes brightness subject to smoothness and feasibility constraints, the black surfaceb darkens the black level of the system as much as possible also subject to smoothness and feasibility constraints. <ref type="figure" target="#fig_3">Figure 3</ref> is an example for the same "two-wide, three-deep" configuration as <ref type="figure" target="#fig_2">Figure 2</ref>. The top surface (drawn in blue) in <ref type="figure" target="#fig_3">Figure 3(a)</ref> is the feasible 3-D luminance surface of this configuration while the bottom surface (in red) is the automatically computed target luminance surface. Likewise, the bottom (blue) surface in <ref type="figure" target="#fig_3">Figure 3(b)</ref> is the feasible black offset whereas the top (red) surface is the target black offset. It should be clear that the automatically computed target surfaces in both cases are smooth and offer maximal contrast.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">OPTIMAL SUBFRAME GENERATION</head><p>Once model parameters are estimated and the target space is defined, the optimal rendering task reduces to finding subframe images y k such that the model predictionx in equation <ref type="formula" target="#formula_7">1</ref>is as close as possible in the MSE sense tox in equation <ref type="formula" target="#formula_9">2</ref>. The subframe images y k may be assumed to be generated from the following correction process.</p><formula xml:id="formula_14">y k = C −1 kC y + k + y 0 k<label>(3)</label></formula><p>This form is particularly convenient since it allows us to split the full optimization task of finding the optimal y k into the simpler tasks of finding an optimal correction y + k that encapsulates luminance correction and resolution enhancement (these may be implemented with color-plane independent filtering, as we shall see in the next subsection) and a black offset correction y 0 k (that is, a fixed correction for a given projector configuration, independent of the input image). To see how the optimization task is split, we may simply substitute (3) into (1). This yieldŝ</p><formula xml:id="formula_15">x = K ∑ k=1 A k L k C k C −1 kC y + k + y 0 k + b =C K ∑ k=1 A k L k y + k + K ∑ k=1 A k L k C k y 0 k + b<label>(4)</label></formula><p>CommutingC with L k and A k in (4) is allowed since applying the same color transform to all pixels in an image and then warping produces an identical result to warping an image and then applying the same color transform to all pixels. We may rewrite the target mapping by commutingC andL as</p><p>x =CLx +b</p><p>Comparing equations <ref type="bibr" target="#b3">(4)</ref> and <ref type="formula" target="#formula_16">5</ref>, we see that it suffices to choose y + k and y 0 k such that and</p><formula xml:id="formula_17">{y + k } = argmin {y + k } L x − K ∑ k=1 A k L k y + k 2 subject to: 0 ≤ y + k (i) ≤ 1, ∀i, k<label>(6)</label></formula><formula xml:id="formula_18">{y 0 k } = argmin {y 0 k } b − b r − K ∑ k=1 A k L k C k y 0 k 2 subject to: 0 ≤ y 0 k (i) ≤ 1, ∀i, k<label>(7)</label></formula><p>where r is called the black residual image. We can treat the above two optimization problems separately, where x appears only in equation (6).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Luminance and resolution optimization</head><p>Since the objective function in the optimization problem of equation <ref type="formula" target="#formula_17">6</ref>is convex on a convex constraint set, the optimal subframe images for a given x may be directly obtained by iterative gradient descent. However, the first termLx in the objective function of equation <ref type="formula" target="#formula_17">6</ref>is smooth by design, while the second term could have sharp jumps at the projector boundaries (for example, this is observed when the projectors are tiled) for some general initial guess for the subframes y k . Since iterative gradient descent uses local updates, it would require several hundred or even thousands of iterations to propagate error corrections from the discontinuities to all subframe regions. Hence, the algorithm's convergence speed is unacceptable. To greatly speed up convergence, we further split this optimization task by making the substitution</p><formula xml:id="formula_19">y + k = L + ky + k<label>(8)</label></formula><p>L + k are smooth luminance blend maps that are designed to eliminate discontinuities while accurately matching desired luminance. We first pre-process (offline) the luminance target surface to derive an optimal set of blend maps described in Section 4.1.1. This enables a huge reduction in the required per image optimization iterations required to determiney + k that optimizes resolution. Only a few localized iterations are needed to optimize resolution for each input image. Resolution optimization is discussed in Section 4.1.2. Splitting the optimization task for y + k does not compromise the optimality of the solution.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.1">Optimal blend maps</head><p>We define the desired blend maps L + k as diagonal matrices. For convenience in optimization, we represent them as vectors by choosing the diagonal elements only. This is accomplished by the transformation l + k = L + k 1. We then seek optimal vectors l + k as solutions to the following energy functional minimization problem:</p><formula xml:id="formula_20">{l + k } = argmin {l + k } ⎧ ⎨ ⎩ α L 1 − K ∑ k=1 A k L k l + k 2 +β ∇L1 − ∇ K ∑ k=1 A k L k l + k 2 + η K ∑ k=1 ∇l + k 2 subject to: 0 ≤ l + k (i) ≤ 1, ∀i, k<label>(9)</label></formula><p>The first term is simply obtained by a substitution of 1 instead of x in equation <ref type="bibr" target="#b6">(6)</ref>, which essentially selects the diagonal elements ofL that completely define the target luminance surface as the desired target image. The second term seeks to match at each pixel the gradients of the luminance surface with the gradients of the simulated luminance image from the multi-projector display. This is consistent with recent results in the area of image editing and seamless photo blending <ref type="bibr" target="#b8">[8,</ref><ref type="bibr" target="#b17">17,</ref><ref type="bibr" target="#b12">12,</ref><ref type="bibr" target="#b22">22]</ref> that showed that gradient domain fusion resulted in the high quality seamless images when illumination varied considerably in the images to be blended. The third term is a regularization term critical in guaranteeing robustness to calibration drift. It enforces a smoothness of the resulting blend maps l + k by minimizing gradient variation. The factors α, β , η trade off the various factors. We choose α β ∼ η ensuring that the solution ensures accurate reproduction of the target luminance surface that is also as smooth as possible. Taking derivatives and setting them to zero yields the first-order necessary and sufficient conditions for optima. Thus, the optimal blend maps are solutions to the following set of Euler-Lagrange partial differential equations.</p><formula xml:id="formula_21">αL T j A T j α e + β ∇ 2 e = η ∇ 2 l + j , j = 1 •••K<label>(10)</label></formula><p>where</p><formula xml:id="formula_22">e =L1 − K ∑ k=1 A k L k l + k</formula><p>and ∇ 2 is the discrete Laplacian operator. These equations may be solved very efficiently for l + j with fast convergence using coarse-to-fine multigrid methods <ref type="bibr" target="#b21">[21,</ref><ref type="bibr" target="#b8">8,</ref><ref type="bibr" target="#b17">17]</ref> with Neumann boundary conditions. These methods solve the above system of PDEs hierarchically by first transforming the problem to a coarse resolution. This is done by subsampling the luminance images. An iterative gradient descent algorithm can be used to find the optimal solution for the coarse level. Once the solution is obtained at the coarsest levels, it is mapped via interpolation to the next higher resolution level where it forms the initial guess at the solution for that level. The same iterative algorithm is applied at the new level to refine the initial guess into an optimal solution for that level. This process is repeated at successively finer resolutions until the finest resolution (which corresponds to the resolution of the original problem) is reached. The multi-resolution approach propagates error corrections very rapidly, allowing for fast convergence with only a few iterations needed at each level. The iterative gradient descent algorithm at each level may be expressed compactly as:</p><formula xml:id="formula_23">l +(n+1) j = ψ l +(n) j + αL T j A T j α e (n) + β ∇ 2 e (n) − η ∇ 2 l +(n) j</formula><p>where n indicates the iteration number and where ψ is the clipping function that clips all elements of its vector argument to the [0, 1] range. Thus, we can obtain the smooth luminance blend maps L + k in equation <ref type="bibr" target="#b8">(8)</ref>. <ref type="figure" target="#fig_4">Figure 4</ref> shows the luminance blend maps for an example of three tiled projectors. The blend maps have been automatically generated by the above process converging in only ten iterations performed at each of seven levels. Notice that they are smoothly varying.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.2">Resolution enhancement</head><p>Incorporating equation <ref type="bibr" target="#b8">(8)</ref>, the subframe generation problem of equation (6) becomes for a given x</p><formula xml:id="formula_24">{y + k } = argmin {y + k } L x − K ∑ k=1 A k L k L + ky + k 2 subject to: 0 ≤y + k (i) ≤ 1, ∀i, k<label>(11)</label></formula><p>For an arbitrary x, both terms in the objective function of equation <ref type="bibr" target="#b11">(11)</ref> are smooth and global luminance variations have been eliminated. This implies that in generating the optimal subframes, local corrections to subframe pixels suffice and only a few iterations will be needed to optimize image resolution by cancelling residual aliasing and eliminating blur. A straightforward gradient descent algorithm will yield the optimal estimates for the subframes in only a few iterations. This algorithm is presented below:</p><formula xml:id="formula_25">y +(0) k = L +T k L T k A T k x (initial guess) (12) f (n) = K ∑ k=1 A k L k L + ky +(n) k (modeling) (13) ∂ J ∂y +(n) k = −L +T k L T k A T k L x −f (n) (gradient)<label>(14)</label></formula><p>y</p><formula xml:id="formula_26">+(n+1) k = ψ y +(n) k − μ ∂ J ∂y +(n) k (correction)<label>(15)</label></formula><p>{y</p><formula xml:id="formula_27">+ k } = lim n→∞ {y +(n) k } (16)</formula><p>where μ is a parameter indicating the fraction of error to be incorporated at each iteration. The algorithm consists of two passes: In the modeling pass (13), we computef (n) from the current guesses of the subframesy</p><formula xml:id="formula_28">+(n) k</formula><p>. Then, a correction pass <ref type="bibr" target="#b15">(15)</ref> updates the subframes based on prediction errors. This algorithm may be intuitively understood as an iterative process of computing an error in the reference high resolution coordinate system and projecting a filtered version of it back onto the subframe data to form better estimates of the subframes. The operator A T k is simply another compactly supported resampling filter <ref type="bibr" target="#b7">[7]</ref>. Since the problem is convex with convex constraints, this process is guaranteed to converge to the optimal solutiony + k for the subframes, and hence one can obtain the optimal y + k given by equation (8).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Black offset optimization</head><p>Once L + k has been determined, we can solve the optimization problem of equation <ref type="formula" target="#formula_18">7</ref>by the following iteration:</p><formula xml:id="formula_29">y 0(0) k = L +T k L T k A T k r e 0(n) = r − K ∑ k=1 A k L k C k y 0(n) k y 0(n+1) k = ψ y 0(n) k + λ C T k L T k A T k e 0(n) {y 0 k } = lim n→∞ {y 0(n) k }</formula><p>where λ is a parameter indicating the fraction of error to be incorporated at each iteration. This optimization yields the optimal black corrections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Overall optimal solution</head><p>The results of the previous subsections may be combined to form the overall optimal subframe that optimizes for color, luminance, black levels, and resolution. Specifically, the solutions for y + k and y 0 k may be substituted into equation <ref type="formula" target="#formula_14">3</ref>to compute the overall optimal solution.</p><p>The iterative resolution enhancement algorithm of Section 4.1.2 produces optimal subframes. However, this algorithm precludes realtime rendering due to its computational complexity. To address this issue, we consider an efficient non-iterative algorithm for subframe generation that may be implemented as a bank of filters operating directly on the input image to be displayed. As proved in <ref type="bibr" target="#b4">[5]</ref>, we derive near-optimal filters by directly finding the impulse response (possibly space varying) of a linear approximation to the non-linear optimal iterative algorithm of Section 4.1.2.</p><p>Subframe generation is then accomplished by a bank of K spacevarying filters, each operating on the high resolution image to produce a component subframe <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b7">7]</ref>. Considering all color planes, this spatially varying filtering operation for subframe k may be represented as a matrix multiplication of x with a matrix H k . Thus, fast real-time subframe generation can be accomplished by the equation These operators may be efficiently implemented in the pixel shaders of commodity GPUs for real-time rendering <ref type="bibr" target="#b7">[7]</ref>.</p><formula xml:id="formula_30">y k = ψ C −1 kC H k x + y 0 k<label>(17)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">RESULTS</head><p>In this section, we consider examples to compare our method with prior work and to illustrate the benefits of the unified framework. We include results from prototype multi-projector display systems leveraging the unified framework. As shown in <ref type="figure" target="#fig_1">Figure 1</ref>, they consist of four-to-six XGA (1024 × 768) DLP projectors running on a single HP xw9300 workstation. The system uses a Point Grey Research 1600 × 1200 Scorpion Firewire camera to perform the automatic calibration in a one-time process. The entire calibration and modeling process discussed in Sections 2 through 4 takes less than ten minutes total for all six projectors. It runs a custom C++/OpenGL application on a single nVidia GeForce 8800 GTX graphics card to perform realtime filtering and rendering (equation <ref type="bibr" target="#b17">(17)</ref>) for all six projectors at 30 fps or higher. The same system may be reconfigured to address different display configurations and only a few representative examples are included due to space limitations. Additional results are available at our web site (http://hpl.hp.com/research/pluribus).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Tiled projection</head><p>Consider an example where two fairly similar projectors are tiled. First, we consider the traditional approach to tiled projection via edge blending. Representative state of the art geometric blending methods like <ref type="bibr" target="#b18">[18]</ref> are based on empirical blend functions. These blend func- tions taper off projector outputs in overlap regions, causing the sum of the luminances in the overlap region to vary smoothly. <ref type="figure" target="#fig_5">Figure 5(a)</ref> shows a one-dimensional horizontal cross-sectional view of the luminance surfaces used in the blending process. In this case, a significant amount of light in the overlap region is wasted due to the natural tapering of the blend functions. It is easy to see that as the overlap increases, even more light becomes wasted in the overlap region.</p><p>To overcome the brightness, contrast (if we make the similar arguments for black levels), and visual inefficiencies of classical geometric blending, Majumder and Stevens <ref type="bibr" target="#b16">[16]</ref> proposed a fast dynamic programming approach to fitting a target luminance surface to maximize brightness while minimizing visible brightness fluctuations. However, as shown in <ref type="figure" target="#fig_5">Figure 5</ref>(b), Majumder and Stevens' blended luminance target surface is not smooth and exhibits substantial gradient jumps. Even if this issue is ignored and a perfectly smooth target surface were specified, the generated blend functions still exhibit steep jumps in the blend maps for each projector. This means that this method of generating blend maps is very sensitive to calibration/model error or drift.</p><p>Harville et al. <ref type="bibr" target="#b9">[9]</ref> found that applying geometric blending (similar to Raskar et al. <ref type="bibr" target="#b18">[18]</ref>) prior to using Majumder and Stevens' algorithm produced smooth blend maps. However, this increased robustness is achieved at the cost of brightness/contrast maximization. Since the target surfaces are constrained to be below the geometrically blended surfaces, it is then impossible to increase brightness as projector over- lap increases.</p><p>No prior method exists that generates smooth blend maps, while at the same time maximizing brightness and contrast subject to luminance fluctuation visibility constraints. Our proposed optimal blend map generation process described in Section 4.1.1 achieves these objectives for the first time. <ref type="figure" target="#fig_5">Figure 5(c)</ref> shows that when the projector overlap is significant, our surface fitting procedure produces brightness levels in the overlap region that are significantly higher than those of any individual projector. Further, the generated blend maps that achieve the brightness maximization are smooth. In comparison with the surface fitting procedure of <ref type="bibr" target="#b16">[16]</ref>, our method based on the cubic B-spline bases is smooth with continuous second derivatives.</p><p>Consider now an example when the left projector is significantly brighter than the right projector and the overlap area is reduced. In this situation, conventional blending transitions rapidly from a high brightness projector to a low brightness projector over a narrow overlap region <ref type="figure" target="#fig_6">(Figure 6(a)</ref>). This causes the transition to appear as a visible seam in the display <ref type="figure" target="#fig_6">(Figure 6(b)</ref>). With the proposed technique, the bound δ (defined in Section 3) on the magnitude of the second derivative bounds the variation of the luminance surface, preventing steep jumps at the boundary of the overlap region. As shown in Figures 6(c) and (d), brightness is optimally reduced to preserve seamlessness in this case. If more brightness were desired, we can simply increase δ at any point to make the tradeoff with seam visibility. <ref type="figure" target="#fig_7">Figure 7</ref> is a screen capture of an actual four-projector tiled system in a two-wide, two-tall configuration (as diagrammed in the upper left corner). The system automatically solves for the optimal blend maps and produces a seamless final result for 1920 × 1080 video as shown in the figure. Note that the black offset is virtually invisible.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Superimposed projection</head><p>We next consider when all the projectors are superimposed. Brightness is typically increased with superimposed projection. Conventional algorithms, however, compromise the resolution of the display, especially when the resolution of the input to be displayed is higher than any individual projector resolution, resulting in either blurred or aliased images <ref type="bibr" target="#b4">[5]</ref>.</p><p>Using the rendering algorithms designed for tiled displays on a superimposed configuration also leads to sub-optimal results. As we saw earlier, these algorithms function poorly with respect to brightness and contrast when projector overlap is increased. In fact, if a conventional blending algorithm is used for superimposed projection, the brightness of the system is effectively that of a single projector. Note that the converse is also true: rendering algorithms designed for superimposed displays <ref type="bibr" target="#b11">[11,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b7">7]</ref> are focused on resolution enhancement and perform poorly for tiled configurations. They ignore target surface fitting and smoothing that is essential for handling luminance discontinuities in tiled displays. In contrast, our proposed paradigm automatically computes the maximal brightness and solves for the optimal resampling filters, even enhancing resolution when possible. <ref type="figure">Figure 8</ref> shows the performance of our system for superimposed projection with two projectors. Our target surface fitting algorithm automatically utilizes the full brightness capability of the combined system. Furthermore, the blend maps are not tapered in this case, allowing the target surface to be achieved without compromise.</p><p>Through the unified framework, one can observe the super-Nyquist resolution gain achieved over a single projector as shown in <ref type="figure">Figure 9</ref>. In this case, we compare the single aliased subframe versus four superimposed projectors for displaying higher resolution content (1600×1200). Because of its relative dimness, the single projector image has actually been contrast enhanced to improve visibility. There is clear improvement in text resolvability in the displayed Excel spreadsheet in the superimposed case.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Hybrid projection</head><p>In the previous sections, we showed how our framework can handle both tiled and superimposed projection seamlessly, with no configuration-specific modifications. We demonstrate in this section that it can also handle arbitrary configurations. <ref type="figure" target="#fig_1">Figure 10</ref> shows an actual screenshot of an example novel hybrid six-projector configuration (three projectors wide, two deep) displaying a high resolution 2700 × 800 video. In this case, the unified framework ensures color consistency, as well as maximizes brightness, contrast, and resolution for any configuration without any per configuration tweaking. Moreover, there is no visible seams or color shifts with this automatically produced result. This configuration has the added benefit of being fault tolerant to the loss of one projector. <ref type="figure" target="#fig_1">Figure 11</ref> shows a second hybrid example with the same six projectors arranged in another non-standard configuration (two tall, three deep), again resulting in a seamless and high quality final result. By design, this configuration is fault tolerant to the loss of two projectors. These configurations are representative examples of the freedom the paradigm offers in trading off brightness, resolution, aspect ratio, and <ref type="figure" target="#fig_1">Fig. 10</ref>. The proposed paradigm automatically corrects the inherent geometry, color, luminance, and black offset variations among six projectors in a three-wide, two-deep hybrid configuration (top) to create a seamless and high quality result on a 16' wide screen (bottom).</p><p>fault tolerance while producing high quality and seamless images.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">CONCLUSION</head><p>We have presented a unified paradigm that automatically optimizes image quality (i.e. color, brightness, contrast, resolution) of multiprojector systems regardless of how they are configured. We showed that our configuration-agnostic framework produces results that outperform the state-of-the-art even when we consider purely tiled or purely superimposed system configurations. Moreover, the prior algorithms for tiled projection and those for superimposed projection are shown to be significantly sub-optimal when applied to the other paradigm. In addition, we demonstrated robust modeling and measurement techniques that lead to seamless and high quality results in real-time using commodity GPUs. With current graphics technology, the same paradigm can handle up to twelve projectors on a single workstation, limited only by the bus bandwidth, size of texture memory, and number of physical display outputs. Further scalability can be achieved by linking multiple such workstations together.</p><p>The proposed paradigm allows for the first time explicit tradeoffs to be made and novel configurations to be supported. We believe this work opens new opportunities in the area of large display visualization through practical scalable multi-projector displays.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Published 14</head><label>14</label><figDesc>September 2007.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 1 .</head><label>1</label><figDesc>Prototype multi-projector displays featuring (a) four, (b) six, and (c) ten projectors.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 (</head><label>2</label><figDesc>a) is the predicted output according to equation<ref type="bibr" target="#b0">(1)</ref> for this multi-projector system where all projectors are projecting white.Figure 2(b) shows the actual camera-captured output of the physical system. It should be clear that the proposed paradigm accurately predicts the output. Since we do not model anything outside the target display canvas, the top of the projectors is visible at the bottom of the camera captured image(Figure 2(b)), and not in the model-predicted output(Figure 2(a)).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 3 .</head><label>3</label><figDesc>Comparison of 3-D plots between feasible and target quantities for the six-projector example in Figure 2: (a) Luminance; (b) Black offset.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 4 .</head><label>4</label><figDesc>Automatically computed blend maps for three tiled projectors. These smooth blend maps combine to form exactly the target surface.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 5 .</head><label>5</label><figDesc>Performance of various blending algorithms for two similar projectors with substantial overlap.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 6 .</head><label>6</label><figDesc>Conventional vs. optimal blending for two different projectors with small overlap. The seam in (b) is visible when projected, while the blended luminance in (d) has no visible seam.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 7 .</head><label>7</label><figDesc>Experimental results with four projector in a tiled configuration. Note the seamless nature of the final result. c 2007 Animusic. Image used with permission (www.animusic.com).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 8 .Fig. 9 .</head><label>89</label><figDesc>Unified framework applied to superimposed projection: luminance profiles. Experimental results with four superimposed projectors: (a) single aliased subframe (contrast enhanced for visibility) versus (b) superresolved output. Note the resolution enhancement as well as brightness gain of the superimposed result.</figDesc></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">Without loss of generality, the display surface is assumed to be uniformly Lambertian. Also, all image operations are performed in linear color space; nonlinear gamma effects are assumed to be undone with an inverse gamma function.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">In this work, we use a cubic B-spline basis.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGEMENTS</head><p>The authors wish to thank Arun Paruchuri, Tom Carrico, Si-Jie Yu, Suk-Hwan Lim, Qian Lin, Jerry Liu, and Bob Ulichney for their help with and support of this work.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Camera-based calibration techniques for seamless multiprojector displays</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Majumder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Visual. Comput. Graphics</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="193" to="206" />
			<date type="published" when="2005-03" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Efficient dense correspondences using temporally encoded light patterns</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">L</forename><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE International Workshop on Projector-Camera Systems (ProCams)</title>
		<meeting>IEEE International Workshop on Projector-Camera Systems (ProCams)<address><addrLine>Nice, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003-10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Creating interactive 3-D media with projector-camera system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">L</forename><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. SPIE Visual Communications and Image Processing Conference (VCIP)</title>
		<meeting>SPIE Visual Communications and Image essing Conference (VCIP)<address><addrLine>San Jose, CA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004-01" />
			<biblScope unit="volume">5308</biblScope>
			<biblScope unit="page" from="850" to="861" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Camerabased measurement for projector-camera systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">L</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Damera-Venkata</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Dicarlo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">H</forename><surname>Lim</surname></persName>
		</author>
		<imprint>
			<pubPlace>Hewlett-Packard Laboratories, Palo Alto, CA</pubPlace>
		</imprint>
	</monogr>
	<note type="report_type">Technical report</note>
	<note>In preparation</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Display supersampling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Damera-Venkata</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">L</forename><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Computer Graphics</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
	<note>Accepted with revisions</note>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Hybrid configuration where six projectors arranged in a twotall, three-deep configuration (left) to create a seamless and high quality result for a 9</title>
		<idno>Fig. 11</idno>
		<imprint/>
	</monogr>
	<note>tall screen (right</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">On the resolution limits of superimposed projection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Damera-Venkata</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">L</forename><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE International Conference on Image Processing (ICIP)</title>
		<meeting>IEEE International Conference on Image essing (ICIP)<address><addrLine>San Antonio, TX</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007-09" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Realizing super-resolution with superimposed projection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Damera-Venkata</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">L</forename><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE International Workshop on Projector-Camera Systems (ProCams)</title>
		<meeting>IEEE International Workshop on Projector-Camera Systems (ProCams)<address><addrLine>Minneapolis, MN</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Gradient domain high dynamic range image compression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Fattal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lischinski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Werman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ACM SIGGRAPH</title>
		<meeting>ACM SIGGRAPH<address><addrLine>San Antonio, TX</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002-07" />
			<biblScope unit="page" from="249" to="256" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Practical methods for geometric and photometric correction of tiled projector displays on curved surfaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Harville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Culbertson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sobel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Gelb</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Fitzhugh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Tanguay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE International Workshop on Projector-Camera Systems (ProCams)</title>
		<meeting>IEEE International Workshop on Projector-Camera Systems (ProCams)<address><addrLine>New York, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006-06" />
			<biblScope unit="page" from="52" to="59" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">K</forename><surname>Jain</surname></persName>
		</author>
		<title level="m">Fundamentals of Digital Image Processing</title>
		<meeting><address><addrLine>Englewood Cliffs, NJ</addrLine></address></meeting>
		<imprint>
			<publisher>Prentice Hall</publisher>
			<date type="published" when="1988" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Super-resolution composition in multiprojector displays</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Jaynes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ramakrishnan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE International Workshop on Projector-Camera Systems (ProCams)</title>
		<meeting>IEEE International Workshop on Projector-Camera Systems (ProCams)<address><addrLine>Nice, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003-10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Seamless image stitching in the gradient domain</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Levin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zomet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Peleg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Weiss</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. European Conference on Computer Vision (ECCV)</title>
		<meeting>European Conference on Computer Vision (ECCV)<address><addrLine>Prague, CZ</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004-05" />
			<biblScope unit="page" from="377" to="389" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Contrast enhancement of multi-displays using human contrast sensitivity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Majumder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)<address><addrLine>San Diego, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005-06" />
			<biblScope unit="page" from="377" to="382" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Is spatial super-resolution feasible using overlapping projectors?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Majumder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP)</title>
		<meeting>IEEE International Conference on Acoustics, Speech, and Signal essing (ICASSP)<address><addrLine>Philadelphia, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005-03" />
			<biblScope unit="page" from="209" to="212" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Color nonuniformity in projection-based displays: Analysis and solutions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Majumder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Stevens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Visual. Comput. Graphics</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="177" to="188" />
			<date type="published" when="2004-03" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Perceptual photometric seamlessness in tiled projection-based displays</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Majumder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Stevens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. on Graphics</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="111" to="134" />
			<date type="published" when="2005-01" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Poisson image editing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Perez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gagnet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Blake</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ACM SIGGRAPH</title>
		<meeting>ACM SIGGRAPH<address><addrLine>San Diego, CA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003-07" />
			<biblScope unit="page" from="313" to="318" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Multi-projector displays using camera-based registration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Raskar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Welch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Towles</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Seales</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Fuchs</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Visualization</title>
		<meeting>Visualization<address><addrLine>San Francisco, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1999-10" />
			<biblScope unit="page" from="161" to="522" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Color and brightness appearance issues in tiled displays</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Stone</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Comp. Graphics and Applications</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="58" to="66" />
			<date type="published" when="2001-09" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Scalable Self-Calibrating Display Technology for Seamless Large-Scale Displays</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Surati</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999-01" />
			<pubPlace>Cambridge, MA</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Massachusetts Institute of Technology</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">PhD thesis</note>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">An Introduction to Multigrid Methods</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Wesseling</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1992" />
			<publisher>John Wiley and Sons</publisher>
			<pubPlace>Chichester, UK</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Seamless image stitching by minimizing false edges</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zomet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Levin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Peleg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Weiss</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Processing</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="969" to="977" />
			<date type="published" when="2006-04" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
