<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/pisenberg/grobid/grobid-0.6.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Illustrative Deformation for Data Exploration</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><roleName>Student Member, IEEE</roleName><forename type="first">Carlos</forename><forename type="middle">D</forename><surname>Correa</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><roleName>Member, IEEE</roleName><forename type="first">Deborah</forename><surname>Silver</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><roleName>Member, IEEE</roleName><forename type="first">Min</forename><surname>Chen</surname></persName>
						</author>
						<title level="a" type="main">Illustrative Deformation for Data Exploration</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2021-02-20T19:44+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Volume deformation</term>
					<term>focus+context visualization</term>
					<term>interaction techniques</term>
				</keywords>
			</textClass>
			<abstract>
				<p>Much of the visualization research has focused on improving the rendering quality and speed, and enhancing the perceptibility of features in the data. Recently, significant emphasis has been placed on focus+context (F+C) techniques (e.g., fisheye views and magnification lens) for data exploration in addition to viewing transformation and hierarchical navigation. However, most of the existing data exploration techniques rely on the manipulation of viewing attributes of the rendering system or optical attributes of the data objects, with users being passive viewers. In this paper, we propose a more active approach to data exploration, which attempts to mimic how we would explore data if we were able to hold it and interact with it in our hands. This involves allowing the users to physically or actively manipulate the geometry of a data object. While this approach has been traditionally used in applications, such as surgical simulation, where the original geometry of the data objects is well understood by the users, there are several challenges when this approach is generalized for applications, such as flow and information visualization, where there is no common perception as to the normal or natural geometry of a data object. We introduce a taxonomy and a set of transformations especially for illustrative deformation of general data exploration. We present combined geometric or optical illustration operators for focus+context visualization, and examine the best means for preventing the deformed context from being misperceived. We demonstrated the feasibility of this generalization with examples of flow, information and video visualization.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>The purpose of visualization is to gain insight of complex structures through images and interactions. One primary objective of visualization is to aid us in building a spatio-temporal mental model of a phenomenon, process or physical quantity. The tools that we have in 3D data exploration to help build a mental model typically include realtime rendering, view transformation, transfer functions, segmentations and a collection of focus+context (F+C) techniques. However, most of these methods are active in "viewing" but passive in "handling", which is quite different from our everyday activities for exploring a complex or unfamiliar object. With the prevalence of 3D visualization far and wide, it is important to explore new methodologies, which can enhance our comprehension and understanding of data, and enable us to build a mental model efficiently and accurately with active "handling" as well as "viewing".</p><p>In science, engineering, medicine and education, hand-drawn illustrations often include two classes of elucidative methods. Firstly, multiple artistic painting styles are commonly employed to enhance, hide or emphasize different features of the object. This observation has led to a number of F+C techniques in visualization, such as cutaway views <ref type="bibr" target="#b10">[11]</ref>, ghosting <ref type="bibr" target="#b1">[2]</ref> and importance-driven rendering <ref type="bibr" target="#b27">[28]</ref>. Secondly, deformation is sometimes applied to parts of an object in order to depict the stages and the outcomes of a procedure, to uncover hidden features, or to reveal the spatial relationships between different components of the object. This observation has led to computer-generated surgical illustrations <ref type="bibr" target="#b7">[8]</ref>.</p><p>The aim of this work is to combine these two classes of elucidative methods into a single interactive framework, for the generation of effective F+C visualization, and to deploy the framework for data exploration in a wide range of applications. We call this framework illustrative deformation, in the sense that it is inspired by hand-drawn illustrations, and enables depiction of focus and context through a combination of rendering styles and geometric transformations.</p><p>• Carlos D. <ref type="bibr">Correa</ref>  There are several challenges in producing effective F+C visualization using illustrative deformation. These include:</p><p>Generalization -It is highly desirable to have a common technical framework for a variety of applications and data types such as discrete points, lines, surfaces and volumes. Following the taxonomy by Tory and Möller <ref type="bibr" target="#b24">[25]</ref>, a general framework should support both continuous data (such as a volume) and discrete data (such as points and lines).</p><p>Geometric Integrity -There has been a reluctance to employ deformation to scientific data for fear that it would prevent accurate interpretation of the data. We believe that, on the contrary, with careful marking-up of contextual structures, and maintaining the integrity of the geometric and optical properties of feature of interest, illustrative deformation can aid data interpretation without leading to incorrect interpretation.</p><p>Interactivity -It is highly desirable to allow users to explore data interactively. Because this exploration becomes an active manipulation of data, it is important to provide interaction feedback and cues of the manipulation to the user. These challenges are the focus of this paper. Our main contributions are: <ref type="bibr" target="#b0">(1)</ref> we introduce a novel approach to illustrative deformation, which enables focus preservation and context mark-up, based on a combination of multiple geometric and optical transformations. This is a new interactive F+C technique, allowing deformation-based data exploration to be deployed in scientific and information visualization, in addition to its traditional applications, such as surgical illustration <ref type="bibr" target="#b1">(2)</ref> We present a generalized technical framework that supports the illustrative deformation of discrete data using deformable implicit representations. This framework allows seamless integration of continuous and discrete representations, facilitates complex optical and geometric transformations on discrete data without requiring complex geometry intersection tests, and offers unprecedented scalability when compared to explicit representations. We also present a novel mechanism for ensuring the geometric integrity of discrete data when undergoing deformation. We show how these operations can be implemented in traditional rendering pipelines, and in contemporary GPUs. <ref type="bibr" target="#b2">(3)</ref> We demonstrate the effectiveness and feasibility through novel application of illustrative deformation in flow, video and information visualization. The initial feedback from potential users indicates that this new technique provides an intuitive means for actively exploring data and constitutes an important aid for scientific visualization</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK</head><p>An effective means for data exploration is the use of F+C techniques, which highlight focal objects in detail while depicting contextual ob- jects in brief to provide an overview. F+C techniques, such as fisheye views <ref type="bibr" target="#b20">[21]</ref>, perspective wall <ref type="bibr" target="#b16">[17]</ref>, hyperbolic space <ref type="bibr" target="#b18">[19]</ref> and rubber sheets <ref type="bibr" target="#b21">[22]</ref>, have been deployed extensively in information visualization.</p><p>F+C visualization is an intrinsic part of volume visualization. In a broader sense, without a F+C visualization, a volume dataset is just a solid volume cuboid containing a mixture of meaningful and insignificant information. Solutions that rely on the manipulation optical attributes and rendering styles include: Selective rendering allows the visualization of specifically selected parts of an object to enhance visibility of occluded parts. Fundamentally, the manipulation of transfer functions (e.g., <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b13">14]</ref>) is a means for re-balancing parts of volume data in the focus and those in the context by changing the optical attributes. Other techniques that involve more semantic selection include volume decomposition <ref type="bibr" target="#b23">[24]</ref>, and opacity peeling <ref type="bibr" target="#b19">[20]</ref>. Non-photorealistic techniques (e.g., <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b15">16]</ref>) enable difference emphases to be rendered in different illustrative rendering styles, especially when illustrative rendering styles are combined with photorealistic styles in the same visualization. Cutaway and ghosted views allow occluded objects to be rendered by fading <ref type="bibr" target="#b27">[28,</ref><ref type="bibr" target="#b26">27]</ref> or removing <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b2">3]</ref> occluding parts. Magic lenses allow the changing of the parameters of the viewing system to magnify the desired features, such as in <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b4">5]</ref>.</p><p>The above-mentioned F+C techniques rely on the manipulation of viewing attributes of the rendering engine and optical attributes of the data objects. Some solutions cannot effectively resolve the occlusion problem. Others can, but at the cost of decreasing the useful contextual information. Often the contextual information is completely suppressed. The use of deformation in volumetric objects has been proposed for animation, visualization and as a tool for computer graphics in general <ref type="bibr" target="#b5">[6]</ref>. Most of previous approaches enable continuous deformation of biomedical objects. Recent approaches allow cutting a dataset using 3D widgets <ref type="bibr" target="#b17">[18]</ref>, the generation of surgical cuts <ref type="bibr" target="#b7">[8]</ref> or exploded views <ref type="bibr" target="#b3">[4]</ref> by allowing breaks in the rendering of volume objects. In such approaches, deformation is considered strictly a geometric transformation problem. Optical properties of the deformed object are usually defined to preserve the original optical properties of the undeformed object.</p><p>Illustrative deformation, discussed in this paper, attempts to balance the visibility of important parts (or focus of attention), while maintaining contextual information, by using a combination of optical transformations and deformation interactively. Considering deformation and optical transformations as interdependent operations has several advantages: First, optical transformations can be used as a visual feedback of the deformation. Second, because deformation alone may not solve the occlusion problem, optical transformations can be used in combination with deformation so that contextual information is still present. Previous approaches to volume deformation usually apply the transformation with little regards to the features of interest. In our approach, deformations are applied in a feature-sensitive manner. It can preserve the visual integrity of focus features, while marking up contextual features. It can be applied to multiple features, and complex features (e.g., user-defined curves).</p><p>One inherent advantage of deploying F+C techniques in volume visualization is that most volume objects to be visualized are familiar to the viewers. It is relatively easy to establish a perceptive view of the contextual parts of an object, even when it is peeled open or exploded apart. Hence it remains an interesting conceptual conundrum and a technical challenge whether or not illustrative deformation can be effectively deployed as a F+C technique for data objects that are more abstract or unfamiliar to the viewers. Answering this conundrum and addressing this challenge is the main motivation of this paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">FOCUS AND CONTEXT IN ILLUSTRATIVE DEFORMATION</head><p>In illustrative deformation, a F+C visualization is the product of a series of transformations on graphical primitives. In Section 4, we will describe a generalized technical framework for accommodating a variety of such primitives for representing continuous as well as discrete data to be visualized. For F+C visualizations, one can consider the  following types of transformations. Geometric Transformation: It causes changes to the shape of an object by applying deformation to its geometry in object space. The deformation can be rigid or elastic. Optical Transformation: It causes changes to the appearance attributes (opacity, color, texture) of parts of an object. Making parts of an object disappearing is also considered as an optical (rather than geometric) transformation. Thus, cutting planes <ref type="bibr" target="#b29">[30]</ref>, ghosted views <ref type="bibr" target="#b1">[2]</ref> and importance-driven rendering <ref type="bibr" target="#b27">[28]</ref> are all optical transformations. Viewing Transformation. It causes changes to the viewing system and camera parameters, resulting in some visual distortion, for instance, fisheye views <ref type="bibr" target="#b20">[21]</ref> and magnification lenses <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b28">29]</ref>. In principle, viewing transformations can be seen as restricted geometric transformation in image space. Because its co-existence with object-space geometric deformation in the same visualization may lead to confusion, we do not consider such transformation in this paper. <ref type="figure">Fig. 1(a)</ref> shows an abstract representation of two types of transformation, geometric deformation and optical transformation. In this paper, we discuss the effects of combining the two types of transformations in order to obtain an effective and unambiguous F+C visualization involving deformation. The ambiguity typically arises from the difficulty in comprehending the original geometry of the key features in focus. Hence it is necessary to ensure focus preservation, such that no geometric or optical transformation is applied to the parts of the object in focus. As illustrated in <ref type="figure">Fig. 1(c)</ref>, without a preserving the geometry of the focus, the geometric integrity of visualization would be compromised. The ambiguity can also arise from the confusion between focus and context, and not knowing what has been transformed geometrically or optically. Hence it is necessary to mark up the context, or parts of the context close to the focus, to illustrate the transformed context. <ref type="figure">Fig. 1(b)</ref> shows two examples of marking-up the deformed context by using optical transformation for deemphasizing and highlighting respectively.</p><p>In the following subsections, we introduce the notion of focus of attention (FoA), which facilitates feature-sensitive transformation with both focus preservation and context mark-up.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Focus of Attention (FoA)</head><p>The most important goal of a F+C visualization based on deformation is to focus the viewer's attention on certain features of interest. Focus of Attention (FoA) defines a region of a data domain, or a feature of a data object, which is of particular interest in data exploration and will remain untransformed (geometrically or optically) during deformation. Similar to the color and opacity specification, an FoA can be defined via a transfer function, typically, H : R → R, or scalar field H : E 3 → R, where R denote the set of all real numbers and E 3 denote 3D Euclidean space. We call H the Levels of Desired Attention (LDA). The former implies the dependence of an FoA to the values of the dataset concerned, whilst the latter removes such a restriction, allowing an FoA be defined in many different ways (e.g., interactively by the viewers, or dynamically by a computational-steering monitor). In the following discussions, we assume that H is a scalar field, and refer the LDA value at p, p ∈ E 3 as H(p) directly. Without losing generality, we also assume that the values of H fall in the subdomain of</p><formula xml:id="formula_0">[0, 1].</formula><p>The values of H are typically divided into three ranges: <ref type="bibr" target="#b0">1]</ref> are said to be in the focus, and no geometric and optical transformation should be applied to these points. All the points with H(p) ∈ [0, f FoA ) are said to be in the context, and they can be transformed. The values in the second interval (c FoA , f FoA ) indicate those points in a transitional context region, which are typically needed to be marked up to alleviate the potential ambiguity or confusion. A weighting function can thus be defined based on H(p), for example, as:</p><formula xml:id="formula_1">H(p) ∈ [0, c FoA ] ∪ (c FoA , f FoA ) ∪ [ f FoA , 1], where 0 ≤ c FoA ≤ f FoA ≤ 1. All the points with H(p) ∈ [ f FoA ,</formula><formula xml:id="formula_2">η(p) = ⎧ ⎪ ⎨ ⎪ ⎩ 0 H(p) ∈ [0, c FoA ] H(p)−c FoA f FoA −c FoA H(p) ∈ (c FoA , f FoA ) 1 H(p) ∈ [ f FoA , 1]<label>(1)</label></formula><p>This example weighting function, η(p), specifies linearly the level of context marking-up in the transitional context region. Non-linear functions can also be defined in a similar manner.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Focus Preservation</head><p>There are a number of approaches to define deformations in 3D space. Most surface-based deformation approaches use explicit forward transformation of vertices. In forward deformation, preserving the focus is an easy task, and can be done by modulating the transformation with the weighting function η. However, volumetric objects are typically deformed using an inverse transformation. Here we show how focus preservation can be achieved when defining deformation as an inverse operation.</p><p>The 3D displacement mapping introduced in [7] offers a powerful and efficient technical framework for geometric transformation. It can facilitate rigid as well as elastic transformation. However, unlike <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b7">8]</ref>, this work has extended this framework significantly to accommodate a more general definition of multiple and dynamic FoA, discrete data and multi-space deformation (see Section 4 for details). An elastic deformation can be defined as an inverse transformation T :</p><formula xml:id="formula_3">E 3 → E 3 : T (p) = p + D(p)<label>(2)</label></formula><p>for each point p ∈ E 3 , where D :</p><formula xml:id="formula_4">E 3 → R 3 is a 3D displacement map.</formula><p>This definition can also be used to represent rigid transformations. However, for rigid transformations, a more compact representation (using a rotation matrix and a translation vector) is preferred. The preservation of the focus can be achieved geometrically by applying:</p><formula xml:id="formula_5">T (p) = p + (1 − η(p))D(p)<label>(3)</label></formula><p>This ensures that the transformation is injective for the points in focus, which is critical to the visualization. A given sampling point x in the focus will be mapped to a distinct x = T (x) because 1 − η(x) = 0. However, the transformation is not injective for the points in context, and it may happen that a sampling point in the context maps to a point in the focus, which is undesirable. This may occur when η(p) = 0, but η(T (p)) = 1. To alleviate this, one may carefully design the weighting function based on H, so that a point in the context is not mapped into the focus, for example, by using a distance field representation of the focus region.</p><p>We also define focus preservation as an optical transformation. We use two field representations as a generic form for an optical specification (e.g, color and opacity) of an object: F c : E 3 → [0, 1] 3 to denote the original color specification, and F α : E 3 → [0, 1] to denote the original opacity specification. Both can be captured, simulated or derived from the original data values using transfer functions. The conventional deformation, such as for surgical illustration <ref type="bibr" target="#b6">[7]</ref>, normally assures the preservation of optical specification for all points with: where c(p) and α(p) are the color ad opacity to be displayed at p. Let C con (p) and α con (p) be the transformed color and opacity for the points in the context. Their specification can be the original representations F c and F α , or mark-up functions as defined in Section 3.3. Then, the color and opacity to be displayed at a sample point p are:</p><formula xml:id="formula_6">c(p) = F c (T (p)), α(p) = F α (T (p)) (a) (b) (c) (d)</formula><formula xml:id="formula_7">c(p) = F c (p) η(p) = 1 η(p)F c (p) + 1 − η(T (p)) C con (T (p)) η(p) &lt; 1 (4) α(p) = F α (p) η(p) = 1 η(p)F α (p) + 1 − η(T (p)) α con (T (p)) η(p) &lt; 1<label>(5)</label></formula><p>Note that the color is preserved, as c(p) = F c (p), for points in the focus. Moreover, it ensures that points in full context are not mapped back to the focus. In such cases, η(p) = 0. When η(T (p)) = 0, c(p) = C con (T (p)), which is the context region, and when η(T (p)) = 1, α(p) = 0, which denotes empty space. On the other hand, points in the transitional region result in a blending of the deformed and undeformed positions. In this case, the focus and the context share a transition region, which is blended optically. Although some points in the transition region may be mapped to points in the focal region, the result is visually acceptable, as it depicts the FoA and the context as having a fuzzy boundary.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Context Marking-up</head><p>Simply preserving color and opacity of all parts of an object may be alright for applications such as surgical illustration, but it is certainly not adequate for illustrative deformation of objects (e.g., a flow field and a graph) that are not intuitively recognizable in real life. It is thereby necessary to distinguish untransformed focus region from the transformed context region. Since maintaining the visual integrity of the focus region cannot be compromised, it is best to mark up the context region. Mark-up effects can take many different forms, including both optical and geometric transforms. When alleviating the ambiguity due to deformation is the main concern, optical transformation can be used to highlight or deemphasize the deformed context region. Typical highlighting effects include introducing easily-recognizable colors (such as bright prime colors) and increasing opacity of points in the transitional context region. On the contrary, typical deemphasizing effects are transforming color hues towards bland colors (e.g. grey), or increasing transparency. Examples are shown in <ref type="figure" target="#fig_3">Fig. 4</ref> and <ref type="figure" target="#fig_8">Fig. 10</ref>, where the deformed glyphs are rendered more transparently.</p><p>Let M c and M α be general mark-up functions for color and opacity respectively. Let ω(p) ∈ [0, 1] be a weighting function that determines the desired degree of mark-up. Then, the color and opacity transformations for the context are:</p><formula xml:id="formula_8">C con (p) = (1 − ω(p))F c (p) + ω(p)M c (p) α con (p) = (1 − ω(p))F α (p) + ω(p)M α (p)</formula><p>An example weighting function is based on amount of deformation, e.g., ω(p) = ||T (p) − p|| , where || • || denotes vector magnitude.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">A GENERALIZED DEFORMATION FRAMEWORK</head><p>In visualization, data and models are usually represented by volumes, surfaces, lines, glyphs and points. Volumes differ from others in that no geometry is given explicitly. Instead each volume defines a continuous spatial subdomain, where every point is associated with one or more values, which may encode color, opacity, and implicit geometric information, or can be used to derive such information using transfer functions. Our previous work on deformation <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b7">8]</ref> was designed for such data representations in medical illustration. On the other hand, data representations composing discrete primitives such as lines, glyphs and points are much more common in scientific and information visualization. For such explicit representations, geometric and optical transformations are typically applied to the low-level primitives, such as vertices, and are interpolated along the high-level primitives such as faces. However, it is difficult to maintain geometric integrity and mark up contextual information without incurring costly intersection computation and neighborhood search. Our aim to extend the approach of illustrative deformation for data exploration in a broader range of applications led us to develop a generalized deformation framework that can work with discrete as well as continuous data. This framework is depicted in <ref type="figure">Fig. 3</ref>, as the composition of multiple geometric and optical transformations on sampling points p. These points are deformed via a displacement map or procedure, then sampled according to a volume representation (which can be an implicit representation of lines and points) and finally classified via an optical operator.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Composite LDA</head><p>Section 3 considers the use of a single FoA defined by a single LDA function. In many situations, users may wish to have multiple LDAs to influence the same visualization. Some may be feature-sensitive (e.g., defined using a transfer function), and others may be regionbased (e.g., specified by the user dynamically). <ref type="figure">Fig. 3</ref> shows the overall technical framework of our implementation. </p><formula xml:id="formula_9">n ∑ i=1 η i (p) + n ∑ i=1 ζ i (p) = 1, ∀p ∈ E 3</formula><p>Consider that each LDA H i is coupled with a geometric transformation T i , we can generalize Eqs. 4 and 5 as: <ref type="figure" target="#fig_2">Fig. 2</ref> shows a deformation of the tornado dataset using a LDA defined in terms of the vector field magnitude. This is mapped onto one focus weighting function, η a , for the central core of the data, and two context weighting functions, ζ a and ζ b , for the two halves of the volume.</p><formula xml:id="formula_10">c(p) = F c (p) ∃i, η i (p) = 1 ∑ n i=1 η i (p)F c (p) + ζ i (T i (p))C con (T i (p)) ∀i, η i (p) &lt; 1 α(p) = F α (p) ∃i, η i (p) = 1 ∑ n i=1 η i (p)F α (p) + ζ i (T i (p))α con (T i (p)) ∀i, η i (p) &lt; 1</formula><p>We can feed η a and ζ a into one pipeline in <ref type="figure">Fig. 3</ref>, and ζ b into another. By moving the contextual parts in opposite directions, we achieve a split. The bottom figure depicts the case where the contextual regions are defined as the two halves at either side of a user-drawn curve that matches the shape of the focus. The effect is a better view of the FoA. The advantage of defining the context with multiple ζ i is the ability to apply deformation to different parts of the context individually. For example, <ref type="figure" target="#fig_8">Fig. 10</ref> shows a F+C view of a 3D scatter plot, where the FoA is the region along the middle part of the plot. Two context regions deform in the opposite direction during a splitting operation. A more complex example of multiple LDAs is shown in <ref type="figure" target="#fig_8">Fig. 10(e)</ref>, where a global zooming operation is employed to explore the data, and a deformation is applied to the context to neutralize the zooming effects on the context.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Implicit Glyphs and Lines</head><p>In visualization, rendering the explicit representations of glyphs and lines is still the predominant approach. Because of the powerful capabilities of the current GPU technology, it has been possible to render discrete primitives in their implicit representations. In this work, we consider lines and glyphs as implicit functions defined in a volumetric domain, which can be deformed directly using space warping and rendered using a volume renderer. One such implicit function is a distance field, where voxels store the Euclidean distance to the closest primitives. In the case of a set of points, an implicit function encodes the geometry of the corresponding spheres surrounding the points; and in the case of a set of streamlines, an implicit function encodes the geometry of the corresponding streamtubes. This approach can also be extended to other data representations involving discrete primitives. For instance, interactive deformation of implicit meshes, useful for the rendering of isosurfaces, has been suggested <ref type="bibr" target="#b8">[9]</ref>. Nevertheless, the generation of implicit representations of lines and points is very fast, in comparison to arbitrary meshes. Timing results for generative and rendering of these implicit representations are given in Section 6.2. Let f (p) be the implicit representation of a set of lines or points. An example is the distance field, where voxels store the Euclidean distance to the closest line or point. Rendering of deformable streamtubes or spherical glyphs of a specific radius τ is done by using the conventional opacity transfer function:</p><formula xml:id="formula_11">O(p) = u τ − f (p) where u(x)</formula><p>is typically a unit step function. An example of applying illustrative deformation to a set of stream tubes is shown in <ref type="figure" target="#fig_3">Fig. 4</ref>, where we compare different deformation and optical mark-up methods.</p><p>Without a very fine sampling interval, the volume rendering integral typically gives rise to amorphous lines with fuzzy boundaries. While this effect can be useful for marking up contextual information, it is not desirable in situations where solid streamlines produce more effective visualization. For solid streamlines, we hence search for the intersections with specific isosurfaces of the distance volume, instead of doing compositing. This is achieved by sampling the volume until reaching the zero-set τ − f (T (p)) = 0, for each sample point p. Although discrete data is often represented and deformed explicitly, there are a number of advantages for performing it implicitly: (1) It is easier to incorporate volumetric data, such as registered MRI for the case of fiber tracts <ref type="figure" target="#fig_6">(Fig. 7)</ref>, or vector field magnitude for the case of flow visualization <ref type="figure" target="#fig_2">(Fig. 2)</ref>. <ref type="formula" target="#formula_3">2</ref>It is faster to incorporate soft shadows, necessary for better depth, motion and deformation cueing, as shown in <ref type="figure" target="#fig_4">Fig. 5</ref>. <ref type="formula" target="#formula_5">3</ref>Controlling the thickness of the glyph or streamtube is a simple operation, which does not require extra steps to control the smoothness of a mesh, and (4) It scales better to large numbers of glyphs (up to millions). This approach scales with the rendering area instead of the number of glyphs, which makes it feasible to render a large number of glyphs at interactive rates. This observation is exploited by the approach in <ref type="bibr" target="#b12">[13]</ref>, where a large number of particle data is rendered in real-time using raytracing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">LDA Specification for Discrete Data</head><p>The above specification of the weighting functions, η(p) and ζ (p), is not suitable for discrete data. The application of such an LDA may result in breaks in the discrete glyphs. Although cutting streamtubes for fiber tracking is reminiscent of the physical cutting of white matter tracts, it is not desirable for flow or graph visualization. To consider the discrete nature of data, we make use of a labeling scalar field, L, where each voxel has a unique identifier of the closest line or point. The specification of an LDA is thus based on L rather than the implicit function representing the discrete data. From L, we can create a look-up table, P, which maps each unique label to a 3D reference point associated with the corresponding glyph. For example, for the case of a sphere, we use its center as the reference point, while for a streamtube, we use its geodesic centroid.</p><p>This gives a new form of LDA as G(p) = P(L(p)), which is referred to as discrete LDA. From G(p), we can derive η(p) and ζ (p) in the same way as discussed in previous sections.</p><p>An example is shown in <ref type="figure" target="#fig_3">Fig. 4(d)</ref>, where a discrete LDA is defined for the blunt fin dataset. In comparison, without discrete LDA ( <ref type="figure" target="#fig_3">Fig.  4(e)</ref> for the case of composition. For direct rendering streamtubes by intersecting with the zero-set of an implicit representation f , a different approach must be taken. We hence split f into two implicit representations for the focus and context respectively:</p><formula xml:id="formula_12">f F (p) = τ − f (p) ξ (p) ≥ 1 − ε − f max ξ (p) &lt; 1 − ε , f C (p) = − f max ξ (T (p)) ≥ 1 − ε τ − f (T (p)) ξ (T (p)) &lt; 1 − ε</formula><p>where ξ (p) = η(G(p)) is a weighting function for a discrete LDA, f max is the maximum distance to the focus of attention, and ε (typically 0), is a threshold value to account for precision errors in the raycasting process. Then, we obtain a discrete F+C visualization by sampling the combined implicit representation</p><formula xml:id="formula_13">g(p) = min( f F (p), f C (p))<label>(6)</label></formula><p>An example can be seen in <ref type="figure" target="#fig_4">Fig. 5</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Multi-space Deformation</head><p>Conventionally, the geometric entities of illustrative deformation are defined using the same coordinate system. In the context of deformation, we can consider three different coordinate systems: Ξ v : the visual or renderable space, usually defined with a proxy geometry. Ξ d : deformation space, usually defined as a displacement map. Ξ o : original object space for continuous or discrete data, often defined as a rectilinear space for storage as a 3D texture. Therefore, we can define the following mappings between the different spaces:</p><formula xml:id="formula_14">W v,o : Ξ v → Ξ o , W d,o : Ξ d → Ξ o and W v,d : Ξ v → Ξ d</formula><p>, and a multi-space deformation is defined as: <ref type="figure" target="#fig_7">Fig. 8</ref> shows an example of video visualization, where the 3D video volume is rendered into a torus space to better use the screen space <ref type="bibr" target="#b9">[10]</ref>. Because the original data and the displacement are defined as a 3D texture, then</p><formula xml:id="formula_15">T (p) = W v,o (p) +W d,o D(W v,d (p))<label>(7)</label></formula><formula xml:id="formula_16">W v,o = W v,d</formula><p>are mappings from toroidal to rectilinear spaces, while W d,o is the identity transformation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">APPLICATIONS</head><p>We examine below the use of illustrative deformation in different application domains.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Flow Visualization</head><p>Flow visualization is essential for the understanding of the dynamics of fluids and gases by representing the movement of particles visually. Flow information is usually represented in a volume by sampling the velocity vectors in a regular grid at different moments in time. However, visualizing overall movement is complicated due to the large amount of information. For this reason, a number of mechanisms have been widely used, such as the explicit rendering of stream lines, ribbons or tubes to depict flow path, or the use of Linear Integral Convolution (LIC) <ref type="bibr" target="#b22">[23]</ref>. A challenge in both approaches is visualizing internal 3D flow. <ref type="figure" target="#fig_2">Fig. 2</ref> shows an example of flow visualization of the tornado dataset using LIC textures. We make two important considerations for ensuring that deforming a flow does not lead to misinterpretation of data. <ref type="bibr" target="#b0">(1)</ref> We avoid cutting through the flow. In the case of stream tubes, this is achieved with discrete FoAs, as depicted in <ref type="figure" target="#fig_3">Fig.  4</ref>. <ref type="formula" target="#formula_3">2</ref>We render deformed data with optical transformations, so that is understood as a means for context information.</p><p>In another experiment, we deformed data from a plasma turbulence simulation. Interestingly, the use of a continuous FoA defined radially along the centerline of the torus, provides a F+C view of flux surfaces, which are of interest to scientists. Examples can be shown in <ref type="figure" target="#fig_5">Fig.  6</ref>. By controlling the radius of the FoA, it is possible to interactively explore the different flux surfaces. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Fiber Tract Visualization</head><p>Another application of deformation of implicit lines is the visualization of white matter tracts in the human brain. These are usually obtained from diffusion tensor magnetic resonance images. Visualizing DTI datasets is useful for understanding the directional qualities of brain tissue, and most common approaches use glyphs or streamlines <ref type="bibr" target="#b30">[31]</ref>. <ref type="figure" target="#fig_6">Fig. 7</ref> shows cutting through the corpus callosum to visualize the internal fiber bundles on one brain hemisphere, which otherwise are occluded by the other hemisphere. We found deformation very intuitive in this case, as it is reminiscent of physical cuts that may be performed on specimens. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Video Visualization</head><p>Video visualization is a visual process for extracting meaningful information from a video sequence. It was introduced by Daniel and Chen as a mechanism for showing moving images in a static 3D volume <ref type="bibr" target="#b9">[10]</ref>. In general, a video can be understood as a 3D volume by using the time dimension as a spatial dimension. Using volume rendering techniques, it is possible to have a depiction of the entire video in a single image. One of the problems with these tools is the inability to show the original frames and still focus on an area of interest, due to occlusion. Proposed solutions make use of semi-transparent volumes derived via background substraction of each frame. This solution reduced the amount of contextual information that can be derived from the visualization. In our approach, we solve this problem using deformation, as depicted in <ref type="figure" target="#fig_7">Fig. 8</ref>. Here, a retracting deformation is used to manipulate the contextual information when visualizing the signature of a person walking. We also depict the use of multi-space deformation, in particular, the use of a toroidal shape, as proposed in <ref type="bibr" target="#b9">[10]</ref>). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Glyph and Graph Visualization</head><p>Another need for discrete data is in the visualization of glyphs. 3D glyphs, e.g., spheres, are often used to represent points in 3D space.</p><p>Here we consider two example applications: the visualization of a 3D scatter plot, where sample points are plotted in 3D using three continuous scalars as spatial coordinates and a a fourth scalar as color. <ref type="figure" target="#fig_8">Fig.  10</ref> shows a scatter plot of data from the cosmological simulation Enzo <ref type="bibr" target="#b0">[1]</ref>. The X,Y,Z coordinates correspond to gas energy, total energy and density of star particles, while color represents temperature. A discrete FoA is used to split the dataset and focus on a cluster of interest.</p><p>In graph visualization, vertices in a graph can be represented in <ref type="figure">Fig. 9</ref>. Deformation of a Hyperbolic graph and a multi-tier graph using a bending transformation. a similar fashion. Deformation of edges, however, cannot follow the same series of transformations, since it is undesired to cut an edge. Instead, we deform vertices and edges independently, and we use an algebraic operation to combine the result of both, as : <ref type="figure">(g(p)</ref>)) + C e (T e (p)) where C v and C e are optical transformations for vertices and edges, respectively, while T v and T e are deformations. T e differs from T v in that it must be continuous. In addition, vertices are transformed discretely, as defined in Section 4.3. <ref type="figure">Fig. 9</ref> shows two examples of deforming a hyperbolic graph, and a multi-layered graph.</p><formula xml:id="formula_17">c(p) = C v (T v</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">IMPLEMENTATION</head><p>Our approach can be incorporated in most traditional volume rendering systems. The algebraic operations depicted in <ref type="figure">Fig. 3</ref> can be implemented as a multi-pass process in most contemporary visualization processes, or, with the aid of the GPU, in a single-pass fragment shader. Each step in the process, identified as a box in <ref type="figure">Fig. 3</ref>, is a function that application developers can modify to suit their own needs. In our particular implementation, we use GPU-based raycasting. It proves to be a more flexible approach than slice-based volume rendering, as it enables us to use adaptive sampling of the volume, essential for the rendering of deformable stream tubes and glyphs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Interaction Issues</head><p>One of the goals of our work is to make our approach interactive. As the complexity of the illustrative deformation and the size of the dataset grow, it becomes important to use progressive sampling. We exploit dynamic branching capabilities of new GPUs to allow variable sampling rates of the volume. Low resolution is used when the user changes the view or the deformation parameters, and high resolution is activated once the user stops interacting. There are a number of technical challenges, including handling objects in 3D space and the interaction with complex transfer functions. Because there is a lot of research devoted to handling transfer functions, we focus in two new interaction challenges introduced by our framework: (1) manipulating the deformation space and (2) presenting interaction feedback to the user.</p><p>Interaction with the deformation parameters is done by applying rotations and translations to the deformation space. By moving the deformation space, the user can remove certain parts of an object, or define the FoA. However, this process is a complex task as the user only perceives the effects of deformation, rather than the deformation itself. For this reason, we provide a "widget" view of the deformation, which appears as a volumetric icon of the deformation. The icon is automatically generated from the displacement, by deforming a volumetric cube. A number of widgets, color coded according to the axis of rotation, allow the user to rotate the deformation along a specific axis. A wireframe box is also used to depict the object space. <ref type="figure" target="#fig_8">Fig.  10</ref> depict a series of deformations on a 3D scattered plot, obtained by translating and rotating the deformation space. Note the changes in the icon widget.</p><p>Another important aspect is the provision of interaction feedback. Because our approach does not incorporate additional modes of inter-action, such as haptic or auditive, we rely on visual cues to represent interaction. One such cue is the use of deformation arrows, which represent the principal direction of the deformation as the user moves the deformation space. We automatically obtain the direction of deformation from the displacement field D. To avoid clutter, we only show the arrows corresponding to a plane in the direction of the movement of the deformation plane. An example is shown in <ref type="figure" target="#fig_8">Fig. 10(b,c)</ref>, where the user translates the deformation in the z-direction, to control the amount of the splitting. The direction and magnitude of the arrows represent the direction and amount of deformation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Preprocessing</head><p>To handle discrete data (such as lines and points) in our framework, we can generate implicit representations of such datasets. As described in Section 4, there are a number of advantages, since the process for generating an implicit representation is very fast and can be performed seamlessly. By exploiting GPU programmability, it can be included in the rendering pipeline by intercepting the rendering primitives before they are sent to the rasterization process. For this reason, this preprocess of discrete data does not hinder the generality of our approach. In this paper, we developed an implicitization process on the CPU, which computes the distance field of an object only in the vicinity of the points and lines. In our experiments, we computed a 256 3 implicit representation of 10000 and 100000 points, which took 0.487 and 3.4 sec., respectively. For lines, 10000 and 100000 line segments took 2.887 and 31.287 sec., respectively. These values are obtained using a CPU-only implementation on a XEON 2.4 Ghz laptop. We believe that the process can be accelerated considerably with a GPUimplementation, so that it can be used in real-time. This is of particular interest for time-varying particle systems or flow simulations, where points and streamlines change dynamically. Another advantage of using implicit representations, is that rendering scales better for a large number of glyphs. In our experiments, 10000 are rendered using explicit representations in about 0.3 (low quality) to 1 sec. (high quality). 100000 glyphs are rendered at about 3 sec. per frame. In comparison, our implicit renderer takes from about 0.2 sec. (in the interactive mode using progressive sampling) up to 1.8 sec. (in high-quality mode), for a viewpoint of size 512 × 512, regardless of the number of points.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Evaluation</head><p>We experimented with a number of datasets, ranging in size from 64 3 to 256 3 . We obtained interactive results for all our datasets on a XEON processor with a Quadro FX 4400 GPU, using a 512 × 512 viewport and a sampling distance of d = 1 voxel. In our case, a comparative evaluation is more informative. <ref type="table" target="#tab_4">Table 1</ref> shows the comparison between our different methods vs. a basic rendering system. We compared for the case of volume rendering, e.g., <ref type="figure" target="#fig_3">Fig. 4</ref> and the case of implicit rendering via ray intersection, e.g., <ref type="figure" target="#fig_4">Fig. 5</ref>. Progressive sampling is used when the user is interacting, for d = 4, resulting in a four-fold improvement in performance (up to 20 fps). The overhead on introducing deformation and FoA will become smaller in future GPUs. Interactivity can be seen in the accompanying video and at :</p><p>http://www.caip.rutgers.edu/˜cdcorrea/deformation </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">VALIDATION AND CONCLUSIONS</head><p>The software tool developed in this work was demonstrated to a number of scientists, using the plasma turbulence data as an example. Although the scientists did not use the system directly, as it still requires the study of effective interaction widgets, they were enthusiastic. Contrary to our initial hypothesis that scientists may be reluctant to deform the data for fear of misinterpretation, they found it very intuitive and did not raised a concern with the concept of deformation of their data. In fact, they expressed interest in focus-preserving deformations that allow them to visualize the flux surfaces, as depicted in <ref type="figure" target="#fig_5">Fig. 6</ref>. They also suggested deformation operations where the torus surface is "flattened" interactively, in order to visualize the entire flux surface in a single view. In another informal validation, images from the deformation of DTI-based fiber tracking was presented to two brain scientists, who expressed interest in our framework. They commented on the deformation of individual fiber bundles as an interesting application, which validates the need for focus-preserving deformation, especially for discrete data such as streamtubes. Although this was an informal validation, we were very encouraged by the comments. A full evaluation is still an important aspect that needs to be addressed in the near future. This will be a time-consuming task, as our framework spans a variety of applications with very different groups of users, each of which must be analyzed independently. We presented a novel framework for data exploration through illustrative deformation, which combines active manipulation of the spatial data with opacity and color transformations. Our framework incorporates the definition of optical transformations, such as cutaways, ghosted views and clipping, with manipulation operators, such as cuts, exploded views and deformation, and can be applied to both continuous and discrete data. We showed the generality and flexibility of our approach through a number of examples, including flow visualization, video visualization, fiber tractography, scatter plots and 3D graphs. Initial comments from scientists and visualization experts are encouraging. We believe that illustrative deformation is an important aid in data exploration, where active "handling" of data is as important as active "viewing", which has been the predominant paradigm in visualization.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Published 14</head><label>14</label><figDesc>September 2007.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>context</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 2 .</head><label>2</label><figDesc>Illustrative Deformation of a Tornado Dataset. Top: Here, the context regions are simply defined by splitting the volume along a vertical line. Bottom: The contextual regions are defined by splitting along a user-drawn line that matches the shape of the focus.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 4 .</head><label>4</label><figDesc>Deformation to the stream tubes of the blunt fin dataset, with FoA defined to preserve the stream lines on the left (a) Original dataset (b) Optical transformation only (c) Optical transformation and rigid deformation (d) Optical transformation and elastic deformation (e) Without discrete FoA deformation, stream tubes are cut, making it difficult to understand.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 5 .</head><label>5</label><figDesc>), streamtubes are broken. The application of Eq. (5) works only Illustrative deformation of stream tubes with soft shadows.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 6 .</head><label>6</label><figDesc>Deformation of Plasma Turbulence Data. The use of FoA defined radially from the centerline of the torus provides a F+C view of flux surfaces.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 7 .</head><label>7</label><figDesc>Deformation of Fiber Tracts from Diffusion Tensor Imaging. Fiber Tracts are depicted as streamtubes, which can be cut and deformed interactively.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 8 .</head><label>8</label><figDesc>Deformation in Video Visualization using a retracting deformation, depicted in (a), using multi-space deformation. (b)-(c) Rectilinear coordinate system (d)-(e) Using Toroidal coordinate system. Wave deformation is used to mark up the contextual information.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 10 .</head><label>10</label><figDesc>Scatter Plot Visualization with Interaction Widget (inset). (a)-(c) Sequence for splitting while preserving FoA (defined along the center of the split). (d) Rotation can be used to select the region of interest along a different dimension. (e) Scaling of the FoA helps to get a better view.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 1 .</head><label>1</label><figDesc>Summary of rendering time for different methods.</figDesc><table><row><cell>F+C Method</cell><cell>Volume Rendering (s)</cell><cell>Implicit Rendering (s)</cell></row><row><cell>Basic Rendering</cell><cell>0.132</cell><cell>0.075</cell></row><row><cell>Deformation</cell><cell>0.217</cell><cell>0.131</cell></row><row><cell>Deformation with FoA</cell><cell>0.336</cell><cell>0.169</cell></row><row><cell>Deformation with Discrete FoA</cell><cell>0.399</cell><cell>0.279</cell></row></table><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGEMENTS</head><p>We would like to thank Dr. Han-Wei Shen, The Ohio State University, for the tornado and LIC texture datasets. Other datasets are from Nasa Advanced Supercomputing Division, University of North Carolina, Swansea University, San Diego Supercomputer Center and the SciDAC Center for Plasma Edge Simulation Project, to which we are grateful.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">ENZO -AMR cosmological simulation</title>
		<imprint>
			<pubPlace>UC San Diego</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Illustrative context-preserving volume rendering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bruckner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Grimm</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kanitsar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">E</forename><surname>Gröller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of EuroVis</title>
		<meeting>of EuroVis</meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="69" to="76" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Volumeshop: An interactive system for direct volume illustration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bruckner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">E</forename><surname>Gröller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of IEEE Visualization</title>
		<meeting>of IEEE Visualization</meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="671" to="678" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Exploded views for volume data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bruckner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">E</forename><surname>Groller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1077" to="1084" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Extending distortion viewing from 2D to 3D</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">S T</forename><surname>Carpendale</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">J</forename><surname>Cowperthwaite</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">D</forename><surname>Fracchia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer Graphics and Applications</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="42" to="51" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Ray casting free-form deformedvolume objects</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hesser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Manner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Visualization and Computer Animation</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="61" to="72" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Discontinuous displacement mapping for volume graphics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Correa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Silver</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Volume Graphics</title>
		<meeting>Volume Graphics</meeting>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Feature aligned volume manipulation for illustration and visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Correa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Silver</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1069" to="1076" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Programmable shaders for deformation rendering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">D</forename><surname>Correa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Silver</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Eurographics/SIGGRAPH Graphics Hardware</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Video visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Daniel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">VIS &apos;03: Proc. of the 14th IEEE Visualization 2003 (VIS&apos;03)</title>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="409" to="418" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Interactive cutaway illustrations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Diepstraten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Weiskopf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Ertl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics Forum</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="525" to="532" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Volume illustration: non-photorealistic rendering of volume models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ebert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Rheingans</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Visualization</title>
		<meeting>IEEE Visualization</meeting>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="page" from="195" to="202" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">A coherent grid traversal approach to visualizing particle-based simulation data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Ize</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kensler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Wald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">P</forename><surname>Gribble</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">G</forename><surname>Parker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="758" to="768" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Interactive volume rendering using multi-dimensional transfer functions and direct manipulation widgets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kniss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Kindlmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Hansen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Visualization</title>
		<meeting>IEEE Visualization</meeting>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="page" from="255" to="262" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">A magnification lens for interactive volume visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Lamar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Hamann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">I</forename><surname>Joy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Pacific Conference on Computer Graphics and Applications</title>
		<meeting>IEEE Pacific Conference on Computer Graphics and Applications</meeting>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="page" from="223" to="231" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Nonphotorealistic volume rendering using stippling techniques</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Morris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ebert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Rheingans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Hansen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Visualization</title>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="211" to="218" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">The perspective wall: detail and context smoothly integrated</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">D</forename><surname>Mackinlay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">G</forename><surname>Robertson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">K</forename><surname>Card</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ACM CHI</title>
		<meeting>ACM CHI</meeting>
		<imprint>
			<date type="published" when="1991" />
			<biblScope unit="page" from="172" to="180" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Using deformations for browsing volumetric data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Mcguffin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Tancau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Balakrishnan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Visualization</title>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="401" to="408" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Exploring large graphs in 3D hyperbolic space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Munzner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer Graphics and Applications</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="18" to="23" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Opacity peeling for direct volume rendering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Rezk-Salama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kolb</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics Forum</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="597" to="606" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Graphical FishEye views of graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sarkar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Brown</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ACM CHI</title>
		<meeting>ACM CHI</meeting>
		<imprint>
			<date type="published" when="1992" />
			<biblScope unit="page" from="83" to="91" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Stretching the rubber sheet</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sarkar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">S</forename><surname>Snibbe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">O</forename><surname>Tversk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">P</forename><surname>Reiss</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ACM Symp. User Interface Software and Technology</title>
		<meeting>ACM Symp. User Interface Software and Technology</meeting>
		<imprint>
			<date type="published" when="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">A new line integral convolution algorithm for visualizing time-varying flow fields</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H.-W</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">L</forename><surname>Kao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="98" to="108" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Interactive volume manipulation with selective rendering for improved visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Silver</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Symposium on Volume Visualization and Graphics &apos;04</title>
		<meeting>IEEE Symposium on Volume Visualization and Graphics &apos;04</meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="95" to="102" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Rethinking visualization: A high-level taxonomy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Tory</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Moller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the IEEE InfoVis</title>
		<meeting>of the IEEE InfoVis</meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="151" to="158" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Pen-and-ink rendering in volume visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M F</forename><surname>Treavett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Visualization</title>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="page" from="203" to="210" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Importance-driven focus of attention</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Viola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Feixas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sbert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">E</forename><surname>Gröller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="933" to="940" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Importance-driven volume rendering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Viola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kanitsar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">E</forename><surname>Groller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Visualization</title>
		<meeting>IEEE Visualization</meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="139" to="146" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">The magic volume lens: An interactive focus+context technique for volume rendering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Mueller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">E</forename><surname>Kaufman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Visualization</title>
		<meeting>IEEE Visualization</meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="367" to="374" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Interactive clipping techniques for texture-based volume visualization and volume shading</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Weiskopf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Engel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Ertl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Vis. Comput. Graph</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="298" to="312" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Diffusion tensor MRI visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Kindlmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">H</forename><surname>Laidlaw</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Visualization Handbook</title>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
