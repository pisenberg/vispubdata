<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/pisenberg/grobid/grobid-0.6.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Visualization of Neuronal Structures in Wide-Field Microscopy Brain Images</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saeed</forename><surname>Boorboor</surname></persName>
							<email>sboorboor@cs.stonybrook.edu</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shreeraj</forename><surname>Jadhav</surname></persName>
							<email>sdjadhav@cs.stonybrook.edu</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mala</forename><surname>Ananth</surname></persName>
							<email>mala.ananth@stonybrook.edu</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Talmage</surname></persName>
							<email>david.talmage@stonybrook.edu</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lorna</forename><surname>Role</surname></persName>
							<email>lorna.role@stonybrook.edu</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arie</forename><surname>Kaufman</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Stony Brook University</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">Department of Neurobiology &amp; Behavior, Stony Brook University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Visualization of Neuronal Structures in Wide-Field Microscopy Brain Images</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2021-02-19T19:41+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Wide-field microscopy</term>
					<term>volume visualization</term>
					<term>neuron visualization</term>
					<term>neuroscience</term>
				</keywords>
			</textClass>
			<abstract>
				<p>Fellow, IEEE Fig. 1. Visualization of neuronal structures in wide-field microscopy volumes. (a) Volume rendering of an unprocessed wide-field microscopy volume of a brain slice. (b) Our workflow provides different visualization modes for analysis of the region-of-interest shown in (a): bounded view (top), structural view (center), and classification view (bottom). (c) Visualization deployed on the Reality Deck, an immersive gigapixel resolution platform at Stony Brook University, for effective exploration of large datasets.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>The understanding of neural connections that underline brain function is central to neurobiology research. Advances in microscopy technology have been instrumental in furthering this research through the study of biological specimens. High-resolution images of brain samples obtained using optical microscopes (average resolution of 200 nm/pixel) and electron microscopes (average resolution of 3 nm/pixel) have made it possible to retrieve micro-and nano-scale three-dimensional (3D) anatomy of the nervous system. The field of connectomics <ref type="bibr" target="#b46">[47]</ref> and relevant studies in image processing have developed methods for the reconstruction, visualization, and analysis of complex neural connection maps. Insights gained from these reconstructed neuron morphologies, often represented as 3D structures and 2D graph layouts, can lead to a breakthrough understanding of human brain diseases.</p><p>A wide-field (WF) microscope <ref type="bibr" target="#b54">[55]</ref> is a type of fluorescence microscope that is often preferred by neurobiologists since it can image a biological sample orders of hours faster than a confocal microscope. Imaging a 40× slice of a sample using a confocal microscope would take 15 hours, whereas a WF microscope would take approximately 1.5 hours for the same sample. Moreover, WF microscopy (WFM) scanners are thousands of dollars cheaper and cause minimal photobleaching to the specimens, in comparison to a confocal or electron microscope. However, due to its optical arrangement, a WF microscope collects light emitted by fluorescent-tagged biological targets in the focal plane, plus all the light from illuminated layers of the sample above and below the focal plane <ref type="figure" target="#fig_0">(Fig. 2)</ref>. As a result, the acquired images suffer from a degraded contrast between foreground and background voxels due to out-of-focus light swamping the in-focus information, low signal-tonoise ratio, and poor axial resolution. Thus, analysis and visualization of WF data is a challenge for domain experts.</p><p>Most available techniques for 3D visualization of neuronal data are designed specifically for electron <ref type="bibr" target="#b13">[14]</ref> and confocal <ref type="bibr" target="#b51">[52]</ref> microscopy. Transfer function designs for the volume rendering of microscopy images <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b52">53]</ref> do not yield effective results when applied to WFM images. Furthermore, the accuracy of neuron tracing and morphology reconstruction algorithms depends on pre-processing image restoration steps <ref type="bibr" target="#b27">[28]</ref>. 3D deconvolution techniques <ref type="bibr" target="#b39">[40]</ref> attempt to reverse the outof-focus blur and restore the 3D WFM images with improved contrast and resolution. However, they are complex and time-consuming to compute, often requiring rounds of iterative approximations to produce the corrected image <ref type="bibr" target="#b44">[45]</ref>, and depend on detailed parameter inputs. These limitations compel neurobiologists to use rudimentary methods, such as manually traversing 2D slices of the volumetric image or using maximal intensity projections for better visibility of features at the cost of losing 3D information.</p><p>In collaboration with neurobiologists, we have designed a pipeline for the meaningful visualization of WFM brain images. Rather than employing computationally demanding and time-consuming image processing techniques, we propose a pipeline of simple and efficient visualization-driven techniques as a more practical solution in the daily workflow of neurobiologists. To achieve this goal, we propose a new kind of a distance transform algorithm, called the gradient-based distance transform function. Applying a curvilinear line filter <ref type="bibr" target="#b40">[41]</ref> and a Hessian-based enhancement filter to the computed distance field, we generate an opacity map for the extraction of neurites (axons and dendrites) and cell bodies, respectively, from raw WFM data. We enable the effective visualization and exploration of complex nano-scale neuronal structures in WFM images by generating three visualization datasets: the bounded, structural, and classification views. This eliminates the occlusion and clutter due to out-of-focus blur.</p><p>We demonstrate our visualization on two display paradigms. For a standard desktop computer display, we use FluoRender <ref type="bibr" target="#b52">[53]</ref> as the volume rendering engine since it is specially designed for visualization of microscopy data and can handle rendering large volumes without the requirement for high-end hardware. Additionally, we present a novel visualization paradigm that could be instrumental for future research in neurobiology. We utilize Stony Brook University Reality Deck (RD) <ref type="bibr" target="#b28">[30]</ref>, the world's largest immersive gigapixel facility, as a cluster for the processing and visualization of large, high-resolution, microscopy data. We provide neurobiologists with an interactive interface to naturally perform multiscale exploration of the visualization modes generated using our pipeline.</p><p>Our workflow allows researchers to visualize results without having to adjust image-correction parameters and transfer functions for the retrieval of useful information. In addition to being more efficient, we show that our method yields better visualization of neuronal structures compared to results from publicly available deconvolution software, as well as compare our results with confocal microscopy volumes of the same specimen. We summarize the contributions of our paper as follows:</p><p>• To the best of our knowledge, we are the first to present a framework for the meaningful visualization of neuronal structures in WFM images of brain samples.</p><p>• We introduce a novel algorithm to overcome out-of-focus blur in WFM, and extract and visualize neuronal structures efficiently.</p><p>• We develop our framework based on feedback and evaluation from neurobiologists and demonstrate its effectiveness on practical WFM brain data.</p><p>• We evaluate our method by comparing against confocal microscopy data and the output from a well-known deconvolution algorithm.</p><p>• We maximize the visual acuity of the domain scientists for the visualization of massive brain datasets by deploying our visualizations on the RD, the world's first immersive gigapixel-resolution facility.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK</head><p>The growing use of high-resolution microscopy technology by neurobiologists and the introduction of recent major initiatives, such as the BRAIN initiative [29], the BigNeuron project <ref type="bibr" target="#b29">[31]</ref>, and the DIADEM challenge <ref type="bibr" target="#b6">[7]</ref>, have considerably gained the attention of researchers to develop techniques for qualitative and quantitative analysis of 3D neuron morphology. Qualitative analysis Volume rendering systems have been developed for visualizing, segmenting, and stitching microscopy data. Mosaliganti et al. <ref type="bibr" target="#b25">[26]</ref> proposed a method for the 3D reconstruction of cellular structures in optical microscopy data sets and correcting axial undersampling artifacts. Wan et al. <ref type="bibr" target="#b52">[53]</ref> developed an interactive rendering tool for confocal microscopy data that combines the rendering of multi-channel volume data and polygon mesh data. Jeong et al. <ref type="bibr" target="#b13">[14]</ref> extended the domain of microscopy visualization tools by developing a system for the visualization, segmentation, and stitching analysis of large electron microscopy datasets. The techniques proposed in these works are designed specifically for confocal, two-photon, or electron microscopy data, where the acquired images contain only the light emitted by the points in the focal plane. However, due to out-of-focus light spreading through the WFM data and its poor axial resolution, the naïve application of these techniques on WFM data, does not produce effective visualizations.</p><p>Another group of techniques aims to segment or classify voxels based on neuronal structures. Janoos et al. <ref type="bibr" target="#b12">[13]</ref> presented a surface representation method for the reconstruction of neuron dendrites and spines from optical microscopy data. As a pre-processing step, their method requires the deconvolution of the microscopy images. Nakao et al. <ref type="bibr" target="#b26">[27]</ref> proposed a transfer function design for two-photon microscopy volumes based on feature spaces. The feature space they explored for the visualization of neural structures included local voxel average, standard deviation, and z-slice correlation. These features would be ineffective for WFM data, mainly because the intensity values due to the super-imposition of light emitted from the neurons can be greater than weak neurons and there is a low correlation for thin neuronal structures within z-slices. This makes transfer function adjustment an arduous task for neurobiologists. Close to neuron morphology, Läthén et al. <ref type="bibr" target="#b17">[18]</ref> presented an automatic technique to tune 1D transfer functions based on local intensity shift in vessel visualization. However, overlapping intensity ranges of the out-of-focus light and neuronal structures make this technique inapplicable to WFM datasets.</p><p>Quantitative analysis. Neuron tracing algorithms and the field of connectomics were introduced for the quantitative analysis of neuron morphology and functioning. Connectomics <ref type="bibr" target="#b46">[47]</ref> aims to develop methods to reconstruct a complete map of the nervous system <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b56">57]</ref> and the connections between neuronal structures <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b45">46]</ref>. Neuron tracing algorithms are designed to automatically or interactively extract the skeletal morphology of neurons. Available tools, such as NeuronJ <ref type="bibr" target="#b23">[24]</ref>, Reconstruct <ref type="bibr" target="#b8">[9]</ref>, NeuroLucida 360 <ref type="bibr" target="#b21">[22]</ref>, and Vaa3D <ref type="bibr" target="#b30">[32]</ref>   or local cues <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b57">58]</ref> to trace neuronal skeletal structures. We refer the reader to a detailed chapter by Pfister et al. <ref type="bibr" target="#b32">[34]</ref> on visualization in connectomics and a recent survey by Acciai et al. <ref type="bibr" target="#b0">[1]</ref> for a full review and comparison of recent neuron tracing methods.</p><p>Image processing of WFM data. The optical arrangement of a WF microscope lacks the capability to reject out-of-focus light emitted by fluorescent-tagged biological targets. The mathematical representation of this blurring is called a point spread function (PSF), which can be determined experimentally <ref type="bibr" target="#b42">[43]</ref> or modeled theoretically <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b35">36]</ref>. However, it depends on a detailed set of microscopy parameters and is subject to changes in the experimental procedure. Deconvolution is an image processing technique designed to reverse the attenuation caused by the PSF and to restore, as far as possible, the image signals to their true values. Often, deconvolution techniques are iterative since they follow an expectation-maximization framework <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b36">37]</ref>. Blind deconvolution techniques <ref type="bibr" target="#b18">[19]</ref> are used to bypass the need for PSF modeling or for cases where the parameters for PSF estimation are unknown. DeconvolutionLab2 <ref type="bibr" target="#b37">[38]</ref> is an open-source software that contains a number of standard deconvolution algorithms commonly used by neurobiologists. Even though deconvolution is an effective method for restoring microscopy images, the time and memory requirements to process large microscopy images make them less practical for regular use by domain experts.</p><p>Immersive Visualization. Immersive visualization systems tap into the human peripheral vision and allow a more effective exploration of three-and higher dimensional datasets. Prabhat et al. <ref type="bibr" target="#b34">[35]</ref> performed a user study on the exploration of confocal microscopy datasets on different visualization systems. Their findings reflected that, for qualitative analysis tasks, users perform better in immersive virtual reality environments. Laha et al. <ref type="bibr" target="#b16">[17]</ref> examined how immersive systems affect the performance of common visualization tasks. Their studies showed that immersive visualization environments improve the users' understanding of complex structures in volumes. Specifically in neurobiology, Usher et al. <ref type="bibr" target="#b50">[51]</ref> designed a system for interactive tracing of neurons, using consumer-grade virtual reality technology.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">DOMAIN GOALS</head><p>We design our pipeline for visualization and analysis of WFM brain images based on the guidance provided by our neurobiologist collaborators. We identify the following goals:</p><p>G1 -Improved quality of neuronal structure visualization. Thresholding is a common practice of domain scientists for the removal of the out-of-focus blur contamination in WFM brain images. This poses two problems: (a) in the process of removing noise, thresholding may also remove neurites and cell-bodies with lower intensities, and (b), since the biological targets do not emit light uniformly, thresholding may cause 'holes' or create discontinuity within the structure. Our collaborators want to be able to analyze the 3D structure of the neurites ( <ref type="figure" target="#fig_1">Fig. 3</ref>) and cell-bodies ( <ref type="figure" target="#fig_1">Fig. 3 (b)</ref>) without losing information due to thresholding.</p><p>G2 -Facilitate quantitative analysis. Due to limitations on preparation of specimens and the optical arrangement of a WF microscope, some neurites have considerably low intensities. Within the scope of the domain, lower intensity structures cannot be concluded as 'less significant', and the relationship between intensity and functioning strength of neuronal structures is open to research. For quantitative analysis, our neurobiologist collaborators consider all structures to be equally important. In practice, the microscopy data is binarized, following thresholding. Our collaborators want to study the axons and dendrites rendered at a uniform intensity value but with some visualization cues that could represent the intensity strength observed in the microscopy output.</p><p>G3 -An efficient pipeline to handle large datasets. The limitation of processing and visualization tools in handling large microscopy datasets can hinder the efficiency of neurobiologists' workflow to analyze experimental results. Our collaborators want our pipeline to be efficient with the ability to be deployed on commonly available desktop workstations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">OUR VISUALIZATION WORKFLOW</head><p>Based on the goals enumerated in Section 3, we present a workflow to overcome the out-of-focus blur in WFM brain images, making them more accessible to domain experts for visual and quantitative analysis. <ref type="figure" target="#fig_2">Fig. 4</ref> summarizes our feature extraction and visualization pipeline. Following the region-of-interest (ROI) selection by the users, we divide the ROI into smaller tiles for parallelization of the feature extraction steps. In the following sections, we describe our feature extraction pipeline, where we introduce our novel gradient-based distance transform function followed by the use of structural filters to extract neurites and cell-bodies. We use a desktop setup and an immersive gigapixel facility as two display paradigms for the visualization and exploration of the extracted neuronal information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Feature Extraction</head><p>Given the challenges of WFM data, fine structural details are swamped by out-of-focus light voxels and thus visualized with reduced contrast. We design a new gradient-based distance transform function based on the fast marching framework <ref type="bibr" target="#b43">[44]</ref> to capture of neuronal features in WFM brain data. Current distance transform functions are introduced for the skeletonization of neurites in confocal and multi-photon microscopy datasets. When applied to WFM data, the computed distance transform blends neurites that run close to each other, and fails to isolate structures that have low contrast with the background <ref type="figure" target="#fig_3">(Fig. 5 (b)</ref>). The goal of our novel gradient-based distance transform function is to suppress background voxels and grow regions of increasing intensity from the boundary of the neuronal structures to their center. The thresholded response from this distance function is used as a bounding mask to isolate in-focus features in the volume.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.1">Fast Marching and Gray-Weighted Distance Transform</head><p>Fast marching (FM) is a region growing algorithm that models a volume as a voxel-graph and recursively marches the graph from a set of seed points to all the remaining voxels, in a distance increasing order. The voxels are divided into three groups: alive, trial, and far. In the initialization step of the framework, voxels with intensity values corresponding to the 'background' are initialized as seed points and are labeled alive, the neighbors of the seed points are labeled trial, and the remaining voxels are labeled far. In each iteration, a trial voxel x, with the minimum distance to the set of alive voxels, is extracted and changed from trial to alive. For an iteration n + 1, the distance d of each non-alive neighbor y of x is updated to the following:</p><formula xml:id="formula_0">d(y) n+1 = min{d(y) n , d(x) n + e(x, y)}<label>(1)</label></formula><p>where d(y) n is the current distance value of voxel y, and e(x, y) is a distance function that determines the distance value between voxels x and y. Conventionally, distance functions were only applicable to . We present two display paradigms for the visualization of these modes, as shown in (b): FluoRender is used as the volume rendering engine for visualization on a personal desktop computer, and we developed a Unity 3D tool for the interactive exploration of these modes on the RD, an immersive gigapixel facility.</p><p>thresholded binary values. APP2 <ref type="bibr" target="#b55">[56]</ref>, a neuron tracing algorithm, defined a new distance function for grayscale intensities:</p><formula xml:id="formula_1">e(x, y) = ||x − y|| • I(y)<label>(2)</label></formula><p>where ||x − y|| is the Euclidean distance between two neighboring voxels x and y, and I(y) is the intensity of voxel y in the raw data. The scalar multiplication between the distance and its intensity in Eqn. 2 results in the FM algorithm outputting increasing distance values towards the center of neuronal structures.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.2">Gradient-based Distance Transform</head><p>In WFM images, the intensity of light emitted by biological targets decays with the square of the distance from the focal point in an airy pattern <ref type="bibr" target="#b15">[16]</ref>. We introduce a novel gradient-based distance transform function that is modeled on the emission of light in the sample, penalizes voxels contributing to the out-of-focus blur, and effectively recovers neurites with weak intensities. To automatically select an intensity value for initializing the set of background voxels as seed points, we determine a computed minimum intensity value that would work effectively with our proposed algorithm. The minimum intensity for each z-slice is calculated from the input volume and the distance transform value φ (x) for each voxel x in the slice, is initialized as,</p><formula xml:id="formula_2">φ (x) = 0, alive x ∈ background ∞, far x ∈ background<label>(3)</label></formula><p>Our choice of this minimum value is because in WFM data, z-slices away from the focal plane have decreasing intensities and reduced sharpness. Therefore, neurites away from the focal plane may have intensity values smaller than the intensity values of light-blur closer to the focal plane. Thus, to avoid weak intensity neurites being included as seed points, a minimum is calculated for each z-slice.</p><p>In the next step, the neighbors of all the background voxels are set as trial, their distance value (φ ) initialized as the intensity (I) of the voxel in the raw data, and pushed into a priority queue. The trial voxel x with the minimum φ value is extracted from the queue and its label is changed to alive. For each non-alive neighboring voxel y of x, φ (y) is updated as follows: where ∆G = ||G(x) − G(y)|| is the magnitude difference between the anisotropic diffusion values at x and y, and ||x z − y z || is the z distance of the voxels. If y is a far voxel, the label is changed to trial and pushed into the priority queue. The trial voxels are iteratively extracted until the priority queue is empty.</p><formula xml:id="formula_3">φ (y) n+1 =    min{φ (y) n , φ (x) • ||x − y|| + ∆G • I(y)} ||x z − y z || &gt; 0 min{φ (y) n , φ (x) • ||x − y|| + ∆G • I(y)} ||x z − y z || = 0 (4)</formula><p>The new distance-transform function we propose in Eqn. 4 aims to identify the 'neuriteness' of each voxel. Therefore, two new variations are introduced to the gray-weighted distance transform in Eqn. 2. First, the propagation of the distance transform value with respect to the z distance, attributing to the spreading of light from the targets in an airy pattern. Second, the addition of the term ∆G. We observed that regions of out-of-focus light have relatively uniform intensities, and the edge-enhancing property of anisotropic diffusion results in a gradient around the neuronal structures. Therefore, we include the difference in the anisotropic diffusion values between x and y as a weight in Eqn. 4. As a result, the out-of-focus blur regions have φ values close to 0. <ref type="figure" target="#fig_3">Fig. 5</ref> shows how the new variations introduced in Eqn. 4 improve the extraction of neurites.</p><p>The properties that differentiate the neuronal structures from the outof-focus light are similar to the three criteria motivating the anisotropic diffusion proposed by Perona and Malik <ref type="bibr" target="#b31">[33]</ref>: (1) any feature at a coarse level of resolution is required to possess a scale-space at a finer level of resolution and no spurious detail should be generated passing from finer to coarser scales; (2) the region boundaries should be sharp and coincide with the semantically meaningful boundaries at that resolution; and (3) at all scales, intra-region smoothing should occur preferentially over inter-region smoothing. In our workflow, we calculate the anisotropic diffusion G, of the raw volume, as a preprocessing step:</p><formula xml:id="formula_4">G = div(D(|∆u| 2 ) • ∆u)</formula><p>with the diffusiveness function,</p><formula xml:id="formula_5">D(|∆u| 2 ) = 1 1 + (|∆u|/λ ) 2</formula><p>Here, ∆u is the convolution of the 3D volume with a gradient kernel, and λ plays the role of a contrast parameter. λ enforces smoothing in regions of out-of-focus light that inherently have low contrast, and enhancement at the boundaries of neuronal structures that inherently have high contrast. We set ∆u to be a 3D convolution mask of 26 neighboring voxels that computes finite differences between the voxel intensity values. For λ , we studied the intensity histograms of the neurites and out-of-focus light voxels and determined its value, for our WFM datasets, to be 50 (for an intensity range of 0 − 255).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.3">Extraction of Neurites</head><p>From the generated 3D data of intensity values, we use the vesselness feature of the neurites to extract their geometric structure. We apply the 3D multi-scale filter for curvilinear structures, proposed by Sato et al. <ref type="bibr" target="#b40">[41]</ref>, to extract tubular structures from φ . The response from this filter is used to bound the voxels in the raw microscopy volume and thus used as an opacity map. This thresholding results in the removal of the background out-of-focus blur in the visualizations described in Section 4.2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.4">Extraction of Cell-bodies</head><p>The eigenvalues (λ 1 , λ 2 , λ 3 ) of the Hessian of a 3D image can indicate the local shape of an underlying object. A cell-body can be identified as an irregular-disk structure in a brain sample (the bright green 'spots' in <ref type="figure">Fig. 10 (a)</ref>). Substituting the geometric ratios introduced in Frangi's vesselness measure <ref type="bibr" target="#b9">[10]</ref>, an enhancement filter for a 2D plate-like structure can be defined as: . We apply a 2D plate enhancement filter on each z-slice of the image stack, instead of applying a 3D 'blob' filter on the volume, because the poor axial resolution of a WF microscope diminishes the ellipsoidal attribute of the cell-body. Simply applying a blob filter will only extract the centroid of the cell-body. To properly bound the cell-body, the response of the 2D filter from each z-slice is then diffused in the z direction using a Gaussian blur to form a 3D bounding structure. This bounding structure is then used to extract the cell-bodies from the raw data.  </p><formula xml:id="formula_6">O(λ ) =      e − R 2 B 2 β 2 • (1 − e − s 2 2 γ 2 ) λ j &lt;</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Feature Visualization</head><p>To satisfy G1, improved visualization of the neuronal structures, and G2, binary visualization of neurites, the next step of our workflow generates three visualization modes: (a) bounded view, (b) structural view, and (c) classification view. We use FluoRender as our volume rendering engine for the qualitative visualization of our outputs on a desktop computer. Our choice is attributed to FluoRender's ability to handle large microscopy data, multi-modal rendering of different volume groups, and its simple and interactive parameter settings.</p><p>Bounded view. We use an opacity map to separate features from out-of-focus blur and background noise, as shown in <ref type="figure" target="#fig_4">Fig. 6</ref>. The opacity map is computed from our feature extraction pipeline and forms a conservative bound around the neuronal structures. This enables the domain experts to investigate their data without having to threshold and adjust parameters to remove the out-of-focus blur. In contrast, transfer functions and visualization parameters can now be effectively used to adjust the rendering of neuronal structures in the data.</p><p>Structural view. 3D analysis of neurites is difficult in regions of dense neuronal network, since the structures in raw WFM are not continuous. To this end, we generate a volume from the responses of the curviliniear and cell-body extraction filters. For this visualization, we use two layers: the neurite layer and the extracted cell-bodies layer. <ref type="figure" target="#fig_5">Fig. 7</ref> shows an example of the structural view -the red structures in (a) are the cell-bodies and the green vessel-like structures are the neurites. Classification view. Neurites can have variable intensity in WFM images due to various reasons, such as the structure moving in and out of the sample and due to experimental limitations in the image acquisition process. However, weak intensity neurites are still relevant for domain analysis. Since the bounded and structural views are visualizations of the raw WFM data, our collaborators wanted an additional view that would allow them to analyze all the neuronal structures in the sample, at a uniform intensity, but with a cue that would represent the strength of the structures observed in the raw data. To this end, we make these structures distinguishable by classifying the extracted neurites based on average intensities from the raw images. Such a classification allows us to render the weak and strong structures with different colors rather than using variable opacity, which would make them less visible. <ref type="figure" target="#fig_6">Fig. 8</ref> shows an example of the classification view.</p><p>Essentially, we classify the neurites into weak and strong based on their signal strength in the original images. We achieve this classification in the following manner. First, we threshold and binarize the extracted structure of neurites from our pipeline to remove noisy fragments and artifacts. Second, we compute the Gaussian-weighted average intensity for every voxel in the original raw image using a standard deviation of 10× the voxel width. Finally, voxels of the binary mask computed in the first step are classified based on the weighted averages computed in the second step. We use an adjustable diverging (blue-to-red) transfer function <ref type="bibr" target="#b24">[25]</ref> with uniform opacity to visualize this classification as shown in <ref type="figure" target="#fig_6">Fig. 8</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">GigaPixel Visualization</head><p>We extend the exploration of WFM brain data to a novel visualization paradigm that could be instrumental for future research in neurobiology. We utilize Stony Brook University RD <ref type="bibr" target="#b28">[30]</ref>, the world's largest immersive gigapixel facility, as a cluster for the processing and visualization of massive, high-resolution, microscopy data. The facility offers more than 1.5 gigapixels of resolution with a 360 • horizontal field-of-view. Given the complex nano-scale structure of the neuronal network of a brain, we provide our collaborating neurobiologists with the ability to interactively analyze their data and improve their visual acuity on the display platform <ref type="figure">(Fig. 9)</ref>.</p><p>We have developed an application for the rendering of the three data views on the Reality Deck. Users mark their ROI using a desktop computer placed inside the facility. The data is then processed using our workflow and rendered on the display walls. Interaction is driven by two components: (a) using a game controller to globally rotate and translate the data; and (b) by physically approaching the display surfaces and naturally performing multiscale exploration. Additionally, by deploying our visulizations on the RD, we enable neurobiologists with the ability to collaboratively explore their large experimental data. Furthermore, this visualization cluster serves as a computational resource for our processing pipeline, thus achieving G3, an efficient pipeline to handle large datasets. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">IMPLEMENTATION</head><p>WF microscopes with a lateral resolution of 160 nanometers can image a brain slice with dimensions 4mm × 5mm × 0.00084mm that results in an image stack of approximately 10 gigabytes. Processing these large images on a regular basis poses an additional challenge to domain experts. We implement a workflow as shown in <ref type="figure" target="#fig_2">Fig. 4</ref> to accommodate G3 of the domain goals. The input format used in our workflow is TIFF, which is commonly used in neurobiology research and is a standard image format used by microscopy manufacturer softwares. First, we use MATLAB to load the microscopy volume, as input from the user, and display a lower resolution 2D maximum-intensity projection for the user to efficiently select an ROI. Since diffusion-based algorithms involve local and identical computations over the entire image lattice, the ROI is then divided into smaller tiles for better memory management during the feature extraction stage. For each tile, in parallel, the anisotropic diffusion volume is then generated. Next, the anisotropic diffusion volumes and raw tiles are set as input to our gradient-based distance function, implemented in C++. The priority queue was implemented as a Fibonacci heap to efficiently obtain the minimum trial voxel in each iteration. Finally, for extracting the 3D neuronal features from the output of the gradient-based distance function, we used ITK's <ref type="bibr" target="#b41">[42]</ref> Hessian computation functionality and the multi-scale vesselness filter. Based on the anatomical radii of the neurites and cell-bodies, provided by neurobiologists, we used a σ value of 1.0 to 2.0 for the Hessian matrix computation of the neurites, and a σ value of 5.0 for the cell-bodies. After generating the output data from the filter responses for the three visualization modes, the processed tiles are automatically stitched together to create the full ROI volumes as a final output for the user.</p><p>We use FluoRender's <ref type="bibr" target="#b52">[53]</ref> rendering engine for the visualization of our modes and introduced the tool to our collaborators for the qualitative analysis of their experimental studies for the desktop setup. The interactive tool for the visualization of the output views on the RD is implemented in Unity3D <ref type="bibr" target="#b49">[50]</ref>. We use UniCAVE <ref type="bibr" target="#b47">[48]</ref>, a Unity3D-based setup for virtual reality display systems. The tool is developed using C# and uses sparse textures to render the large microscopy volumes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">RESULTS AND EVALUATION</head><p>In this section, we provide a qualitative evaluation of the output volume and visualizations generated using our workflow as compared to Richardson-Lucy (RL) deconvolution results and confocal microscopy images of the same specimen. We also provide a computational performance evaluation by comparing with the RL deconvolution algorithm. This is followed by feedback and discussion on the features from our collaborators.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Data Preparation</head><p>We tested our workflow on WFM datasets of mouse brain slices, imaged by our collaborating neurobiologists. The WF microscope used was an Olympus VS-120, and the imaging parameters were set to a numerical aperture of 0.95 at 40× magnification, with xy resolution of 162.59 nm/pixel and z spacing of 0.84 µm. The results shown in this section are artificial chromosomes-transgenic mice, expressing a tau-green fluorescent protein (GFP) fusion protein under control of the ChAT promoter (ChAT tau-GFP) <ref type="bibr" target="#b11">[12]</ref>. Coronal brain sections of 30µm thickness were cut with a cryostat. Serial sections were collected onto slides. <ref type="table" target="#tab_2">Table 1</ref> provides details of the datasets used. <ref type="figure">Fig. 9</ref>. Exploration of the structural view of A-7 from our visualization pipeline on the RD. The inset tile shows the amount of detail that is visible by physically approaching the display walls. <ref type="figure">Fig. 10</ref>. A comparison between volume rendering of (a) raw WFM image (A-20wf), (b) confocal microscopy image (A-20c) of the same specimen, and (c) visualization of A-20wf generated by our workflow. All three sub-figures show the medial septum region of the same mouse brain specimen.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Evaluation</head><p>Qualitative comparison. The primary benchmark, for the qualitative evaluation of our results, is to compare the volume generated by our workflow with raw data obtained using a confocal microscope. In terms of microscopy, the principle advantage of using a confocal microscope over a WF microscope is its optical arrangement: a confocal microscope operates on the principle of a pinhole, which eliminates out-of-focus light, thus improving the fidelity of a 3D image and increasing the contrast of fine structural details. To evaluate our result, a mouse brain-slice was first imaged using WFM, and since a WF microscope does not completely bleach the biological sample, the slice was re-imaged using a confocal microscope. It took 10 minutes to image the slice using a WF microscope and approximately 2 hours for the same slice to be imaged using a confocal microscope. <ref type="figure">Fig. 10</ref> shows the volume rendering of (a) the raw WF data, (b) the raw confocal data, and (c) the volume generated using our method for the A-20wf dataset. The left column in <ref type="figure">Fig. 10</ref> is the zoomed out image of the ROI selected from the brain slice and the right column is 20× magnification into the dotted area of the region in the left column. The bright green irregular plate-like structures in <ref type="figure">Fig. 10 (a)</ref> and (b) are the cell-bodies in the brain, and the remaining vessel-like structures are the neurites. In comparison to confocal microscopy, the neuronal structures in WF data are blurred due to out-of-focus light, making it difficult to study the geometry of the dendrites in 3D. The rendering of our result in (c) shows that our workflow eliminates the out-of-focus blur noise from WFM data and successfully captures the neuronal structures in the slice. The red irregular structures in (c) are the cell-bodies and the green structures are the dendrites. On comparing our result with confocal data, the neurobiologists commented that the visualizations from our pipeline are qualitatively similar to confocal microscopy data.</p><p>An alternate method for the removal of out-of-focus blur from WFM data is using image restoration deconvolution algorithms. RL is a standard algorithm readily available in deconvolution tools, such as DeconvolutionLab2 or MATLAB's deconvolution functions and is widely-used by domain experts. Despite research efforts in image processing, deconvolution is a challenge because the PSF is unknown. Even though blind deconvolution algorithms are proposed to eliminate the need of an accurate PSF, the efficacy of these algorithms depends on an initial estimate. Since our pipeline is designed based on the strength of visualization techniques, our method does not require any input microscopy parameters.</p><p>A qualitative comparison between the RL algorithm and the results generated using our method is shown in <ref type="figure" target="#fig_7">Fig. 11</ref>. The first row shows an area of densely packed neuronal structures (in the striatum region of a mouse brain), the second row shows an area with axons, dendrites, and cell-bodies (in the medial septum region of a mouse brain), and the third row shows a 40× magnification into an area annotated in the medial septum. The volume renderings in each row are of the raw WFM data, the output from RL deconvolution, and the output from our method, from left to right. The parameters for the PSF estimation were obtained from the microscope settings (numerical aperture, objective magnification, CCD resolution, and z-spacing) and the slice preparation information (refractive index of the immersion medium, sample dimensions, and cover glass thickness). The PSF was calculated using Richards and Wolf <ref type="bibr" target="#b35">[36]</ref>, a shift invariant, vectorial-based diffraction PSF estimation model. We ran the RL algorithm several times, changing the number of iterations for each attempt and found that the algorithm visually converges after 150 iterations based on visual comparison by the domain experts. Therefore, the images shown in the deconvolution column of <ref type="figure" target="#fig_7">Fig. 11</ref> are the outputs from 150 iterations of the RL algorithm. It can be observed from the different projections of the zoomed-in dendrite, in the last row of <ref type="figure" target="#fig_7">Fig. 11</ref>, that even though deconvolution removes most of the surrounding out-of-focus blur, and improves the contrast between background and foreground structures, the area around the dendrite is still cluttered with noise. The result from our method allows the user to directly visualize the dendrite structures, without having to adjust for the out-of-focus light obstruction.</p><p>Quantitative comparison. Cell-body count and terminal field density are two commonly used measures for the quantification of experimental findings in neurobiology. The number of cell-bodies in a brain sample signifies the health of the brain and the network of axons neurites manifests the communication in the brain. In order to compute cell-body count and terminal density, the images are first maximum intensity projected along the z-axis. The images are converted to grayscale, and a threshold is set to determine what gray value <ref type="table">Table 2</ref>. Comparison of quantitative measurements performed on the A-20wf WF, A-20wf with the RL-deconvolution, A-20wf with our method, and A-20c confocal data. The output of our method produces measurements that are closer to the confocal benchmark image (A-20c).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Calculation</head><p>Raw For cell-body counts, a diameter criteria is set and counted using a cell counter plugin in ImageJ, which records a total count and tags each included cell-body to ensure no cell is counted twice. Terminal density is computed as a ratio of white (signal) pixels to black (background) pixels.</p><p>The results in <ref type="table">Table 2</ref> reflect that, compared to the quantitative measurements calculated using confocal imaging, much of the neuronal information in WFM is lost. This is primarily due to thresholding of the WFM data, in order to remove the out-of-focus blur pixels from the calculations. Even though the result from deconvolution improves the quantifications, some useful pixels are still thresholded in the process of removing residual noise. On the other hand, the quantitative measurements of the output generated from our workflow have similar values to that of confocal imaging and no thresholding was required to remove noise from our result. Thus, our method can aid neurobiologists to not only achieve qualitative renderings, but also quantitative results similar to that of confocal microscopy. Performance measure. Our pipeline was tested on two systems, a desktop workstation and the RD. The desktop workstation system was a Windows PC with Intel Xeon E5-2623 CPU, 64 GB RAM, and an NVIDIA GeForce GTX 1080 GPU. The RD is a visualization cluster with 18 nodes. Each node is equipped with dual hexacore Intel Xeon E5645 CPUs, 64 GB RAM, and four AMD FirePro V9800 GPUs. Dataset A-20wf was evaluated on the desktop system and A-7 was evaluated on the RD. Since deconvolution is an alternative method for the restoration of WFM images, for improved qualitative and quantitative analysis of brain samples, we compare the performance of our pipeline with the RL algorithm. Deconvolution was carried out using DeconvolutionLab2 <ref type="bibr" target="#b37">[38]</ref>, an ImageJ plug-in. <ref type="table" target="#tab_4">Table 3</ref> reports the performance measurements for the two methods.</p><p>The peak memory, in <ref type="table" target="#tab_4">Table 3</ref>, is the maximum amount of RAM required at any stage of the process, and total time is the time elapsed from the start of the processing pipeline until the final output results are generated. Dataset A-7 was divided into 16 tiles and each node of the RD processed two tiles. For both deconvolution and our method, 8 nodes of the RD were used for processing. The performance numbers show that our workflow is orders of hours faster, and more memory efficient than deconvolution. A domain expert would need a powerful, high performance computer to run the deconvolution process on their experimental data and it would make it even more challenging to process microscopy data in a large volume. Our pipeline can be executed on a standard desktop machine and generates results in a reasonable amount of time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Domain Expert Feedback</head><p>Bounded view. Our collaborating neurobiologists found that, through this view, they could adjust the gamma and the luminance settings, provided in FluoRender, for their qualitative analysis, which otherwise would have been impossible due the obstructions caused by the amplified noise voxels <ref type="figure" target="#fig_0">(Fig. 12</ref>).</p><p>Structural view. This output is particularly useful for our collaborators for their quantitative analysis. The cell-bodies layer gave them a direct cell-body count, without having to perform thresholding to remove all other structures, and the neurite layer can be projected directly in 2D for the terminal field density calculation. Additionally, they found it very useful to be able to shift between the structural and bounded visualization for a detailed analysis of their samples.</p><p>Classification view. In the ROI studied by our collaborators, the neurites often enter from and exit to the surrounding brain slices. The reason why some structures (or part thereof) have weaker intensities in the imaged data, is because the majority of structural mass could be in neighboring slices. Analyzing the result of the classification view, they could identify the region of the neurite entering/exiting the focal plane.</p><p>GigaPixel Visualization. The RD is actively being used by our collaborators in understanding the disposition of complex terminal field networks and the functional mapping of individual cholinergic neurons. Typically, when wanting to visualize a single region of the brain, scientists would have to zoom in to the ROI, and thus, lose the context of the entire brain slice. The panoramic projection of the data on the RD enable domain experts to notice details in the organization of structures from one brain region to another, which otherwise they would not have at such high resolution, side by side. This also allows for mapping of structures within the field of view as experts found they <ref type="figure" target="#fig_0">Fig. 12</ref>. Comparison of visualization parameter adjustment between the raw and bounded view. Column (a) shows a rendering of the raw volume (top) and a bounded view (bottom), at gamma value 1. Column (b) shows their corresponding renderings when the gamma value is changed to 2. Changing visualization parameters makes it difficult to study the features in the raw volume, due to the obstruction caused by noise, whereas for the bounded view, the parameters are only applied to the features bounded by the mask extracted using our algorithm.</p><p>were able to follow structures across large distances, which would have been difficult or impossible on standard desktop screens.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">CONCLUSION AND FUTURE WORK</head><p>We designed a visualization workflow, in collaboration with neurobiologists, for WFM volumes of brain specimens. We achieve this by building a visualization pipeline for a data modality where visualization tools, to the best of our knowledge, have been virtually non-existent. We overcome the inherent out-of-focus blur caused in the WFM images through a novel gradient-based distance transform computation followed by extraction of 3D neuronal structures using 3D curvlinear and 2D plate enhancement filters. Our exploration system provides three different visualization modes (bounded, structural, and classification view) that aim to meet the domain goals. A combination of these views and the ability to switch between them provide with the ability to explore local features through our visualization and compare with the raw images without losing context. Moreover, the ability of our workflow to separate cell-bodies from neurites provides a clutter-free and effective visualization. It also overcomes the unnecessary pre-processing procedures that are otherwise required of WF images for quantitative analyses, such as cell-body counting and estimating neurite density. We evaluated our workflow by providing a qualitative and quantitative comparison between our results, a standard deconvolution technique, and confocal microscopy imagery for the same specimen.</p><p>For future work, we plan to upgrade our framework to a complete exploration system by incorporating more sophisticated interaction techniques under immersive visualization platforms, such as gigapixel walls and head-mounted displays. Such immersive platforms can be leveraged for better exploration of large WFM images. Furthermore, we will investigate a GPU-based implementation of our feature extraction workflow to accelerate the computation of our distance function and the Hessian matrix calculation for the feature extraction filters. As a result, this would allow the users to interactively change the parameters of the neurite and cell-body extraction filters and observe their results reflected in the changing opacity maps.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 2 .</head><label>2</label><figDesc>WFM images are volumes obtained by focusing at different depths of a thinly sliced specimen. (a) Volume rendering of an unprocessed WFM brain image. (b) Top-left: a 2D cross-sectional view of the volume in the x-y plane. (b) Top-right: 2D cross-section in the y-z plane cut along the vertical dotted line. (b) Bottom: a 2D cross-section in the x-z plane cut along the horizontal dotted line. The cross-sections show how out-of-focus light occludes the low intensity features, making it difficult to analyze structures in 3D.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 3 .</head><label>3</label><figDesc>(a) Diagram of the anatomy of a neuron. (b) Neurons seen under a WF microscope. The bright green spots in (b) are the cell bodies and the remaining thread-like structures are neurites (axons and dendrites).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 4 .</head><label>4</label><figDesc>Our workflow for the visualization of neuronal structures in WFM brain data. The user first selects a ROI from the input volume which is then tiled for effective memory management during the feature extraction stage. Following the gradient-based distance transform algorithm, we process the output tiles to extract neurites and cell-bodies. The final output of our algorithm allows three visualization modes shown in (a): bounded view (top), structural view (center), and classification view (bottom)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 5 .</head><label>5</label><figDesc>Improvements in feature extraction due to our novel gradientbased distance transform function. (a) Raw WFM brain volume. (b) The application of the distance transform function in Eqn. 2. This distance function causes false branching between the neurites, because of the spreading of out-of-focus light, and is unable to recover neurites with lower intensities. (c) Improvements in neurite extraction due to the anisotropic diffusion term we introduce in Eqn. 4. The yellow arrows compare the incorrect branching of features in (b). (d) Improvements due to the introduction of the z distance condition in Eqn. 4. The red arrows compare how some neurites, incomplete or missing in (b), are recovered in (d).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 6 .</head><label>6</label><figDesc>Visualization using the bounded view. (a) Volume rendering of raw WFM data. (b) Bounded view visualization eliminating the out-of-focus light noise.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 7 .</head><label>7</label><figDesc>Visualization of the structural view. (a) The rendering of the extracted geometry of both the neurites (in green) and the cell bodies (in red). (b) The structural view of the neurites seen in Fig. 6 (b).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 8 .</head><label>8</label><figDesc>Classification view of neurites based on feature intensity. Blue color indicates weak intensity neurites while red indicates stronger intensity neurites. This classification helps in locating neurites that may be fragmented or moving across different specimen slices.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 11 .</head><label>11</label><figDesc>Qualitative comparison of volume renderings of raw WFM brain data, Richardson-Lucy (RL) deconvolution of the raw data, and the output result from our workflow for the A-7 dataset. The first row shows a region of the brain with dense neurites, the second row is a region with neurites and cell-bodies, and the last row is a µm-level zoom into the indicated region of the data.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 1 .</head><label>1</label><figDesc>Datasets used in the evaluation of our workflow. A-20wf and A-20c are WF and confocal images of the same specimen, respectively. A-7tile is a smaller region extracted from A-7.</figDesc><table><row><cell>Dataset</cell><cell>Dimensions</cell><cell cols="2">Microscopy Uncompressed</cell></row><row><cell></cell><cell></cell><cell></cell><cell>size (GB)</cell></row><row><cell>A-20wf</cell><cell>3000 × 6500 × 20</cell><cell>WF</cell><cell>0.85</cell></row><row><cell>A-20c</cell><cell>3000 × 6500 × 20</cell><cell>Confocal</cell><cell>1.05</cell></row><row><cell>A-7</cell><cell>11000 × 12400 × 20</cell><cell>WF</cell><cell>3.10</cell></row><row><cell>A-7tile</cell><cell>2750 × 3100 × 20</cell><cell>WF</cell><cell>0.22</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3 .</head><label>3</label><figDesc>Performance comparison for datasets A-20wf and A-7 between RL deconvolution algorithm and our method. A-20wf was evaluated on a desktop workstation and A-7 was evaluated on the RD.</figDesc><table><row><cell></cell><cell></cell><cell>Peak</cell><cell></cell><cell></cell></row><row><cell>Dataset</cell><cell>Method</cell><cell cols="3">Memory Total Time Process</cell></row><row><cell></cell><cell></cell><cell>(GB)</cell><cell>(hours)</cell><cell></cell></row><row><cell>A-20wf</cell><cell>Deconvolution Our Method</cell><cell>52.6 11.5</cell><cell>23.6 1.35</cell><cell>Serial Serial</cell></row><row><cell>A-7</cell><cell>Deconvolution Our Method</cell><cell>62 8.7</cell><cell>18.2 0.45</cell><cell>Parallel Parallel</cell></row></table><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS</head><p>We would like to thank Joseph Marino and Saad Nadeem for their guidance. This work has been partially supported by the NSF grants IIS1527200, NRT1633299, CNS1650499, the Marcus Foundation, the NIH BRAIN initiative award MH109104, and the National Heart, Lung, and </p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Automated neuron tracing methods: an updated account</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Acciai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Soda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Iannello</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuroinformatics</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="353" to="367" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Neurolines: a subway map metaphor for visualizing nanoscale neuronal connectivity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">K</forename><surname>Al-Awami</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Beyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Strobelt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Kasthuri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">W</forename><surname>Lichtman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Pfister</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hadwiger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2369" to="2378" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Rapid automated three-dimensional tracing of neurons from confocal image stacks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">A</forename><surname>Al-Kofahi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lasek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">H</forename><surname>Szarowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">J</forename><surname>Pace</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Nagy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">N</forename><surname>Turner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Roysam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Information Technology in Biomedicine</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="171" to="187" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">ConnectomeExplorer: Query-guided visual analysis of large volumetric neuroscience data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Beyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Al-Awami</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Kasthuri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">W</forename><surname>Lichtman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Pfister</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hadwiger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2868" to="2877" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Principles of optics: electromagnetic theory of propagation, interference and diffraction of light</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Born</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Wolf</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
			<publisher>Elsevier</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">An open-source VAA3D plugin for real-time 3D visualization of terabyte-sized volumetric images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bria</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Iannello</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Peng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Biomedical Imaging</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">The DIADEM data sets: representative light microscopy images of neuronal morphology to advance automation of digital reconstructions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">M</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Barrionuevo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">J</forename><surname>Canty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>De Paola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Hirsch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">S</forename><surname>Jefferis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Snippe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sugihara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">A</forename><surname>Ascoli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuroinformatics</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">2-3</biblScope>
			<biblScope unit="page" from="143" to="157" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Automated tracing of neurites from light microscopy stacks of images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Chothani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Mehta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Stepanyants</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuroinformatics</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">2-3</biblScope>
			<biblScope unit="page" from="263" to="278" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Reconstruct: a free editor for serial section microscopy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">C</forename><surname>Fiala</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Microscopy</title>
		<imprint>
			<biblScope unit="volume">218</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="52" to="61" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">F</forename><surname>Frangi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">J</forename><surname>Niessen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">L</forename><surname>Vincken</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Viergever</surname></persName>
		</author>
		<title level="m">Multiscale vessel enhancement filtering. International Conference on Medical Image Computing and Computer-Assisted Intervention</title>
		<imprint>
			<date type="published" when="1998" />
			<biblScope unit="page" from="130" to="137" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Experimental test of an analytical model of aberration in an oil-immersion objective lens used in three-dimensional light microscopy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">F</forename><surname>Gibson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Lanni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JOSA A</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="154" to="166" />
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">A transgenic mouse model reveals fast nicotinic transmission in hippocampal pyramidal neurons</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Grybko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Hahm</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Perrine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Parnes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">S</forename><surname>Chick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">E</forename><surname>Finger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Vijayaraghavan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">European Journal of Neuroscience</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1786" to="1798" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Classification and uncertainty visualization of dendritic spines from optical microscopy imaging</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Janoos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Nouansengsy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Machiraju</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">T</forename><surname>Wong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics Forum</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="879" to="886" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">SSECRETT and NeuroTrace: Interactive Visualization and Analysis Tools for Large-Scale Neuroscience Datasets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W.-K</forename><surname>Jeong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Beyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hadwiger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Blue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Law</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vazquez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Reid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lichtman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Pfister</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer Graphics and Applications</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page">5</biblScope>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Exploring brain connectivity with two-dimensional neural maps</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Jianu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Demiralp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">H</forename><surname>Laidlaw</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="978" to="987" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Blind Deconvolution of Widefield Fluorescence Microscopic Data by Regularization of the Optical Transfer Function (OTF)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Keuper</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Schmidt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Temerinac-Ott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Padeken</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Heun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Ronneberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Brox</surname></persName>
		</author>
		<idno type="DOI">10.1109/CVPR.2013.283</idno>
		<imprint>
			<date type="published" when="2013-06" />
			<biblScope unit="page" from="2179" to="2186" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Effects of immersion on visual analysis of volume data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Laha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Sensharma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">D</forename><surname>Schiffbauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename><surname>Bowman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="597" to="606" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Automatic tuning of spatially varying transfer functions for blood vessel visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Läthén</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lindholm</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Lenz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Persson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Borga</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2345" to="2354" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Understanding blind deconvolution algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Levin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Weiss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Durand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">T</forename><surname>Freeman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2354" to="2367" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Rivulet: 3d neuron morphology tracing with iterative back-tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Cai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuroinformatics</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="387" to="401" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">An iterative technique for the rectification of observed distributions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">B</forename><surname>Lucy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Astronomical Journal</title>
		<imprint>
			<biblScope unit="volume">79</biblScope>
			<biblScope unit="page">745</biblScope>
			<date type="published" when="1974" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mbf Bioscience</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Neurolucida360</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Graph-based visualization of neuronal connectivity using matrix block partitioning and edge bundling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Mcgraw</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="3" to="13" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Design and validation of a tool for neurite tracing and analysis in fluorescence microscopy images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Meijering</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Jacob</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-C</forename><surname>Sarria</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Steiner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Hirling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Unser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cytometry</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="167" to="176" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Diverging color maps for scientific visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Moreland</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Symposium on Visual Computing</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="92" to="103" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Reconstruction of cellular biological structures from optical microscopy data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Mosaliganti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Cooper</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Sharp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Machiraju</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Leone</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Saltz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="863" to="876" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Visualizing in vivo brain neural structures using volume rendered feature spaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Nakao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kurebayashi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Sugiura</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Sato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Sawada</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Kawakami</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Nemoto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Minato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Matsuda</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computers in biology and medicine</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="page" from="85" to="93" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">3-D image pre-processing algorithms for improved automated tracing of neuronal arbors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Narayanaswamy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Roysam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuroinformatics</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">2-3</biblScope>
			<biblScope unit="page" from="219" to="231" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">The Reality Deck-an Immersive Gigapixel Display</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Papadopoulos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Petkov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">E</forename><surname>Kaufman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Mueller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer Graphics and Applications</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="33" to="45" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">BigNeuron: Large-Scale 3D Neuron Reconstruction from Optical Microscopy Images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hawrylycz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Roskams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Spruston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Meijering</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">A</forename><surname>Ascoli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuron</title>
		<imprint>
			<biblScope unit="volume">87</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="252" to="256" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">V3D enables real-time 3D visualization and quantitative analysis of large-scale biological image data sets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Ruan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">H</forename><surname>Simpson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">W</forename><surname>Myers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature biotechnology</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">348</biblScope>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Scale-space and edge detection using anisotropic diffusion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Perona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="629" to="639" />
			<date type="published" when="1990" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Pfister</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Kaynig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">P</forename><surname>Botha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bruckner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">J</forename><surname>Dercksen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H.-C</forename></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Visualization in connectomics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">B</forename><surname>Hege</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Roerdink</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Scientific Visualization</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="221" to="245" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">A Comparative Study of Desktop, Fishtank, and Cave Systems for the Exploration of Volume Rendered Confocal Data Sets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Prabhat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Forsberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Katzourin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Wharton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Slater</surname></persName>
		</author>
		<idno>doi: 10. 1109/TVCG.2007.70433</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="551" to="563" />
			<date type="published" when="2008-05" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Electromagnetic diffraction in optical systems, ii. structure of the image field in an aplanatic system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Richards</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Wolf</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1274" />
			<publisher>The Royal Society</publisher>
			<biblScope unit="volume">253</biblScope>
			<biblScope unit="page" from="358" to="379" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Bayesian-based iterative method of image restoration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">H</forename><surname>Richardson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JOSA</title>
		<imprint>
			<biblScope unit="volume">62</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="55" to="59" />
			<date type="published" when="1972" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">DeconvolutionLab2: An open-source software for deconvolution microscopy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Sage</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Donati</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Soulez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Fortun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Schmit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Seitz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Guiet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Vonesch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Unser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Methods</title>
		<imprint>
			<biblScope unit="volume">115</biblScope>
			<biblScope unit="page" from="28" to="41" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Automatic morphological reconstruction of neurons from multiphoton and confocal microscopy images using 3D tubular models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Santamaría-Pang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Hernandez-Herrera</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Papadakis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Saggau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">A</forename><surname>Kakadiaris</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuroinformatics</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="297" to="320" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Deconvolution methods for 3-D fluorescence microscopy images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Sarder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Nehorai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Signal Processing Magazine</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="32" to="45" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">3D multi-scale line filter for segmentation and visualization of curvilinear structures in medical images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Sato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Nakajima</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Atsumi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Koller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Gerig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Yoshida</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Kikinis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVRMed-MRCAS&apos;97</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1997" />
			<biblScope unit="page" from="213" to="222" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">The ITK software guide. The Insight Consortium</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Schroeder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Cates</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Scientific Volume Imaging</title>
		<ptr target="https://svi.nl/RecordingBeads" />
		<imprint/>
	</monogr>
	<note>Recording beads to obtain an experimental PSF</note>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">A fast marching level set method for monotonically advancing fronts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Sethian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the National Academy of Sciences</title>
		<imprint>
			<biblScope unit="volume">93</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1591" to="1595" />
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Comparison of widefield/deconvolution and confocal microscopy for three-dimensional imaging</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">J</forename><surname>Shaw</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Handbook of biological confocal microscopy</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2006" />
			<biblScope unit="page" from="453" to="467" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title level="m" type="main">neuroMAP interactive graph-visualization of the fruit fly&apos;s neural circuit</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sorger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Bühler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Schulze</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Dickson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="73" to="80" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">The Human Connectome: A Structural Description of the Human Brain</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Sporns</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Tononi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Kötter</surname></persName>
		</author>
		<idno type="DOI">10.1371/journal.pcbi.0010042</idno>
	</analytic>
	<monogr>
		<title level="j">PLOS Computational Biology</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">2005</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Uni-CAVE: A Unity3D plugin for non-head mounted VR display systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Tredinnick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Boettcher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Solovy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Ponto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Virtual Reality</title>
		<imprint>
			<biblScope unit="page" from="393" to="394" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Automated reconstruction of dendritic and axonal trees by global optimization with geometric priors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Türetken</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>González</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Blum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Fua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuroinformatics</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">2-3</biblScope>
			<biblScope unit="page" from="279" to="302" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<title level="m" type="main">Unity Technologies</title>
		<ptr target="https://unity3d.com/unity" />
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">A virtual reality visualization tool for neuron tracing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Usher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Klacansky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Federer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P.-T</forename><surname>Bremer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Knoll</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yarch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Angelucci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Pascucci</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="994" to="1003" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">An Interactive Visualization Tool for Multi-channel Confocal Microscopy Data in Neurobiology Research</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Otsuna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">B</forename><surname>Chien</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Hansen</surname></persName>
		</author>
		<idno type="DOI">10.1109/TVCG.2009.118</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1489" to="1496" />
			<date type="published" when="2009-11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">FluoRender: an application of 2D image space methods for 3D and 4D confocal microscopy data visualization in neurobiology research</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Otsuna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-B</forename><surname>Chien</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Hansen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Visualization Symposium (PacificVis)</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">A broadly applicable 3-D neuron tracing method based on open-curve snake</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Narayanaswamy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-L</forename><surname>Tsai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Roysam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuroinformatics</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">2-3</biblScope>
			<biblScope unit="page" from="193" to="217" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<monogr>
		<title level="m" type="main">Introduction to Widefield Microscopy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Wilson</surname></persName>
		</author>
		<ptr target="https://www.leica-microsystems.com/science-lab/introduction-to-widefield-microscopy/" />
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">APP2: automatic tracing of 3D neuron morphology based on hierarchical pruning of a gray-weighted image distance-tree</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Peng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1448" to="1454" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Blockwise human brain network visual comparison using nodetrix representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Daianu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Tong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Thompson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="181" to="190" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Automated reconstruction of neuronal morphology based on local geometrical and global structural models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Amat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Clack</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Ahammad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Myers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuroinformatics</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">2-3</biblScope>
			<biblScope unit="page" from="247" to="261" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
