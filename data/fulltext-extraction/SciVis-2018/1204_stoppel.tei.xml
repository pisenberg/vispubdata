<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/pisenberg/grobid/grobid-0.6.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Firefly: Virtual Illumination Drones for Interactive Visualization</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergej</forename><surname>Stoppel</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Magnus</forename><surname>Paulson Erga</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Bruckner</surname></persName>
						</author>
						<title level="a" type="main">Firefly: Virtual Illumination Drones for Interactive Visualization</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2021-02-19T19:43+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>Dynamic lighting design, lighting drones</keywords>
			</textClass>
			<abstract>
				<p>Fig. 1. Lighting designs with static light sources aim to emphasize properties of the illuminated object such as the average surface variation or curvature. Sophisticated as those approaches can be, they can never account for all local properties of the illuminated object. We propose animated lights, or Fireflies, to solve this challenge by moving the light on a path that emphasizes the local properties over the time. In this image we show four consecutive positions of a Firefly designed to emphasize the brain.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Illumination has a crucial impact on the appearance of 3D objects and shape perception in computer-generated scenes. Once the geometry, textures, and material properties of the scene have been defined, its appearance is greatly affected by the illumination setup. Shape perception, for example, is highly dependent on light placement. Uncommon positioning of light sources can distort the perceived geometry as it is known from crater or dome illusions. The traditional approach for lighting specification is an iterative process of trial and error, where the user continuously adjusts the light parameters and evaluates the rendered image. This makes lighting design a challenging task even for static lights.</p><p>Moreover, in interactive scenarios static lights alone may not be sufficient. When asked to visually assess the geometry of objects, observers most commonly rotate them back and forth. Studies show that the motion of an object relative to the light source helps to evaluate its geometry and material properties <ref type="bibr" target="#b8">[10,</ref><ref type="bibr" target="#b38">40]</ref>. When the object of interest cannot be moved easily, observers tend to obtain geometry and material cues by moving the light source. It has been shown that participants have a clear intuition of how the light source distance and position affect the shading patterns for a variety of different surfaces <ref type="bibr" target="#b33">[35]</ref>. This indicates that animated lights could be used to enhance shape perception in 3D scenes. Modern animation approaches use moving light sources to emphasize temporal changes in the scene or to adapt the light conditions to a dynamic setup. While static lighting specification is already a challenging task with some existing solutions for automated support, the simultaneous control of the camera and moving light sources represents an even greater hurdle for most users. Furthermore, when considering the rapid advances in immersive virtual reality technology, which limit the available degrees of freedom for interacting with parameters like light source configurations, the requirement for "intelligent" light sources that automatically adjust to the movement of the camera becomes more and more pressing. To address this challenge, we propose a novel automated approach for scene illumination with dynamic light sources that offers additional perceptual cues compared to static lights. In addition to the static light sources in the scene, we generate a Firefly -a moving light drone that illuminates the scene while flying on an automatically generated path. Our system continuously optimizes the Firefly path based on a flexible energy function, tailored for various visualization tasks. We propose several energy function constructions for different visualization scenarios, that are designed to enhance different aspects of the rendered objects, while following established lighting design rules from photography and art.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK</head><p>Automation and optimization techniques have a long tradition in the field of visualization. A common problem is the choice of suitable parameters for a particular visualization technique and/or dataset. In volume rendering, for instance, the specification of transfer functions is a challenging task. While presets can provide some additional support to the user, the presence of additional variables such as differences in the data acquisition necessitates more advanced approaches. Examples include the work of Ruiz et al. <ref type="bibr" target="#b32">[34]</ref>, who presented a framework to define transfer functions based on a target distribution provided by the user. Similarly, Borga et al. <ref type="bibr" target="#b4">[6]</ref> proposed an optimization based algorithm that shifts preset transfer functions, to account for general deviations and local variations in the data. To deal with occlusion in flow visualization, GÃ¼nther et al. <ref type="bibr" target="#b14">[16]</ref> translate the occlusion problem into a view-dependent global optimization problem that is solved with the least squares method. Modern visualization solutions for 3D scenes often employ large and complex scene geometries. Early on it was found that the increased scene complexity hindered the orientation of the user and impaired the ability to navigate effectively. Freitag et al. <ref type="bibr" target="#b11">[13]</ref> automatically adjusted the camera speed based on viewpoint quality to reduce the cognitive effort for camera control in indoor scenes. Xie et al. <ref type="bibr" target="#b43">[45]</ref> proposed an automatic camera path planing method, that aims to improve the user's sense of direction in VR setups. The roles of static, animated, and interactive presentations of 3D scenes have been investigated by Froes et al. <ref type="bibr" target="#b12">[14]</ref>. Coffey et al. <ref type="bibr" target="#b5">[7]</ref> extended the study to virtual reality. Our approach can be seen as a natural development of expanding animations to light setups.</p><p>As our approach aims to generate virtual drones to automatically support the user in their task, we draw inspiration from physical autonomous vehicles. Already in 1969, Keiser and Peebles <ref type="bibr" target="#b19">[21]</ref> discussed a concept for automatic drone control. Nikolos et al. <ref type="bibr" target="#b27">[29]</ref> used an evolutionary approach to design a Bezier path for unmanned aerial vehicles. While their setup significantly differs from ours, Srikanth et al. <ref type="bibr" target="#b36">[38]</ref> used physical light drones for rim illumination of dynamic objects in indoor photography. Joubert et al. <ref type="bibr" target="#b17">[19]</ref> presented an interactive path planing tool for drone cinematography, particularly focusing on the importance of the trajectory smoothness and the spatial awareness of the user.</p><p>Illumination has a significant impact on the perception of a scene, but can necessitate a tedious trial and error process in order to arrive at a desired result. Cost et al. <ref type="bibr" target="#b6">[8]</ref> discussed an automated approach for lighting design that employed optimization strategies based on object geometry, material properties, and design goals. To support non-experts, Shacked et al. <ref type="bibr" target="#b34">[36]</ref> developed a method for fully automatic lighting design based on a perceptual quality metric. Gumhold <ref type="bibr" target="#b13">[15]</ref> used entropy to place a light source that maximizes the information added by illumination. Halle et al. <ref type="bibr" target="#b15">[17]</ref> presented LightKit, a lighting system for 3D scenes inspired by light designs of artists and photographers. Lee et al. <ref type="bibr" target="#b24">[26]</ref> introduced Light Collages, an illumination system that enhances local features using a globally inconsistent lighting setup. Wang et al. <ref type="bibr" target="#b41">[43]</ref> proposed a lighting system that enhances visual cues for local and global features. Zhang and Ma <ref type="bibr" target="#b45">[47]</ref> extended automatic three-point lighting setup to volume rendering employing global illumination. Recent work by Wambecke et al. <ref type="bibr" target="#b40">[42]</ref> introduced a lighting design approach based on photographic rules, taking into account the shapes and materials of the objects. A coherent lighting setup is especially important in augmented reality, as the rendered object must be integrated into an already illuminated scene. Haller et al. <ref type="bibr" target="#b16">[18]</ref> used real-time shadow maps to add realism to the augmented scene. Okumura et al. <ref type="bibr" target="#b28">[30]</ref> and Klein et al. <ref type="bibr" target="#b23">[25]</ref> incorporated blurring filters on the rendered image to match the depth of field of the captured video stream. Aittala <ref type="bibr" target="#b3">[5]</ref> used real-world observations from a diffuse sphere to adjust virtual lighting parameters for augmented reality setups.</p><p>To produce an effective lighting setup, it is important to account for various aspects of human perception. Studies by Ramachandran <ref type="bibr" target="#b29">[31]</ref>, Kleffner and Ramachandran <ref type="bibr" target="#b22">[24]</ref>, and Mamassian et al. <ref type="bibr" target="#b25">[27]</ref> investigated the assumptions made by the human visual system and how they are affected by the light position. Doerschner et al. <ref type="bibr" target="#b8">[10]</ref> identified three motion cues the visual system relies on to distinguish between matte and shiny surfaces. Kersten et al. <ref type="bibr" target="#b21">[23]</ref> performed a study on information provided by cast shadow motion. Their research suggests that the visual system assumes a stationary light source even if a moving light source is present. However, this may be due to the fact that no visual cues for the light position where presented to the participants. A recent study by SchÃ¼tt et al. <ref type="bibr" target="#b33">[35]</ref>, where the participants could control the light position to some degree, suggests that participants do have</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Firefly</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Init Path Energy</head><p>Function F e</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Optimizer</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>New points</head><p>Evaluation Pool Creates Testscenes <ref type="figure">Fig. 2</ref>. A conceptual overview of the Firefly system. The system operates in a parallel multi-threaded manner. The only input required by the user is a selection of the energy function from a provided library. The system iteratively updates the Firefly path by creating a set of new paths and evaluating them in the background (Evaluation Pool). The Firefly transitions to a better path when one is found.</p><p>a clear intuition of how light positions affect the appearance of the illuminated object. Guided by these findings, we inform the user of the Firefly position through visual cues and avoid sudden and unexpected trajectory changes by imposing constraints on the path shape.</p><p>In a cinematic context, lighting is often used to convey emotions, and the effects of lighting on the perceived scene atmosphere have been investigated in several studies. An overview of different lighting setups can be found in the book Advanced RenderMan by Apodaca and Gritz <ref type="bibr" target="#b2">[4]</ref>. De Melo et al. <ref type="bibr" target="#b7">[9]</ref> focused on the emotions induced by different lighting setups and proposes a model for the expression of emotions in virtual humans with a composition of lights, shadows, and chromatic filters. Wisessing et al. <ref type="bibr" target="#b42">[44]</ref> investigated how animated characters are perceived when viewed under different lighting conditions. Nasr et al. <ref type="bibr" target="#b9">[11]</ref> presented a lighting system that automatically adjusts to accommodate variations of the dramatic scene characteristics. We use the findings of these studies as guidelines in the construction of the Firefly paths.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">FIREFLY</head><p>The goal of our approach is to support users by providing an animated light source -a Firefly -that moves along an adaptive path continuously adjusting its trajectory if necessary. The Firefly complements additional static light sources and in particular aims to enhance dynamic aspects of the exploration process. As the control and planning of a moving light source is even more complex than the design of a static lighting environment, automatic generation and adaptation of the Firefly path is a key component of our system.</p><p>Whereas previous approaches for the placement of static lights could partially rely on precomputation, our aim is to provide a fully dynamic solution that adapts interactively to changes in the camera and scene setup, and does not impose any constraints on the content of the scene. A key aspect of our approach is that the FireFly acts in a view-dependent manner, i.e., it aims to adjust its trajectory according to what the user sees. As such, our approach is an online optimization process. We designed Firefly as an independent component that can be easily integrated into existing systems. To achieve a high degree of flexibility for versatile illumination tasks, we created the Firefly system as a plugin-based detached optimization process. We explain the general Firefly system in the remainder of this section, discussing the individual components in detail in the following subsections.</p><p>A general overview of our approach can be seen in <ref type="figure">Figure 2</ref>. The To reduce the complexity during the optimization process we compute the tangents at point P k automatically from the neighboring points P kâ1 and P k+1 . (b) Assuming that small changes of the camera position introduce only small changes to the scene, we transform the Firefly path with the camera around the object of interest to provide an initial path.</p><p>Firefly generation and optimization works as a parallel process to the rendering pipeline. The only input required from the user is the selection of an energy function from a catalog. When a Firefly is triggered during the interaction process, an initial Firefly path is constructed and placed in similar positions as lights in common photography setups. Next, the optimizer suggests a new set of light paths. The light paths are sent to an evaluation pool, which handles every test path in a separate thread. In each thread a new scene with the Firefly path is generated and the path is evaluated according to the energy function. After all paths have been processed, the evaluation pool returns a fitness value for each path to the optimizer. When the optimizer has found a better path than the one that is currently displayed, the Firefly transitions to the new best light path, without interrupting the optimization process. If the user moves the camera during the optimization, the existing Firefly path is transformed accordingly. To provide the user with visual ques on the position change of the Firefly, we display a tail behind the moving light source. The user is able to remove or adjust the tail through a simple slider. During the development of the Firefly, we found that users preferred a Firefly with a tail as reference.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Path Generation and Adaptation</head><p>Before discussing the optimization process of the Firefly path, we briefly describe the generation of the initial Firefly path and the adaptation to the camera movement. The Firefly path is defined by a set of control points as a smooth, closed, three dimensional curve. While our system is not limited to a specific path formulation, we implement the Firefly path as collection of cubic Bezier curves, with a C 1 transition at the endpoints. To reduce the complexity during the optimization, we automatically compute the tangent vectors for the Bezier curve and use the segment endpoints as optimization parameters. Because we designed the Firefly system with the goal of high flexibility, we generate the initial Firefly path as a simple shape that is able to adapt very fast, i.e., as a circular path between the camera and the object of interest. The simple circular shape has several advantages, as it has the lowest curvature of all possible shapes in the same space, thus avoiding sudden trajectory changes at the initialization. Furthermore, the circular shape naturally provides well distributed initial control points for the optimization process, as the control points are evenly spaced and cover a relatively large portion of the design space. Thus, the circular shape provides a fast convergence rate at the beginning of the optimization process. A common approximation for a circle with n Bezier curves is to construct the tangents at a point p k with the length l as:</p><formula xml:id="formula_0">l = 4 3 â¢ tan Ï 2n ,<label>(1)</label></formula><p>and the same direction as the circle tangent. To keep the Firefly path consistent, we keep the initial ratio of the tangent length and the distance between neighboring points fixed. Having saved the initial tangent length l and the initial distance d between two points p kâ1 and p k+1 , we can compute the new tangent t k at the point p k as:</p><formula xml:id="formula_1">t k = (p k+1 â p kâ1 ) â¢ l d<label>(2)</label></formula><p>We illustrate the automatic tangent computation in <ref type="figure">Figure 3</ref>(a). The initial placement of the path is inspired by photography rules discussed in Section 3.5 as an elevated key light.</p><p>As the control points are updated during the optimization, the Firefly transitions from the old to the updated path on a linearly interpolated trajectory. The intermediate position of the Firefly is then computed as:</p><formula xml:id="formula_2">P trans = P new â¢ t w + P old â¢ w â t w ,<label>(3)</label></formula><p>where w is a time window for the interpolation and t is the time that has passed since the interpolation start. In our implementation, we use a window size w of three seconds. As the sum of two smooth functions is smooth as well, the transition occurs without undesired jumps of the Firefly. When the user changes the camera position, the Firefly path needs to adapt to the changes in the visible scene. A reasonable assumption is that small changes to the camera transformation result in small changes to the visible scene and thus the path energy. Therefore, to create a well suited initial condition for the path, we rotate the Firefly path together with the camera position around the object of interest. We illustrate this transformation in <ref type="figure">Figure 3</ref>(b).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Energy Function</head><p>We aim for a flexible and easily-adjustable lighting system that automatically creates a well-suited light path for various application scenarios. To achieve this goal, we draw inspiration from approaches as active contour models <ref type="bibr" target="#b18">[20]</ref>, originally developed in the context of image segmentation, where the outline of an object is modeled as an energy-minimizing deformable curve using a combination of energy terms for the contour shape and image properties. This provides a high degree of flexibility in modeling specific application requirements using different variations of the individual energy terms. Inspired by this concept, we define the Firefly path through a plugin-based energy function. The optimization of the Firefly path can be formulated as a minimization problem of the used energy function. As such, the choice of the energy function directly determines the shape and the evolution of the Firefly path. In this section, we discuss the components of an energy function for light path optimization on a conceptual level, while we introduce detailed formulations of energy functions for specific application scenarios in Section 5. Previous approaches for lighting design are guided by rules taken from photography or image properties such as entropy. In addition, our approach needs to take the path shape into consideration as well. For instance, drastic and unexpected changes of the light trajectory can be confusing for the user <ref type="bibr" target="#b21">[23]</ref>, as they might be misinterpreted as object movement in the scene. Hence, a general energy function consists of two components, one component for the rendered scene and one component for the path properties. A general energy function for light path optimization can be constructed as follows:</p><formula xml:id="formula_3">E = Î± â¢ E I + (1 â Î±) â¢ E P (4)</formula><p>where E I is the image energy, E P the path energy, and Î± is a weight to control the influence of the energy components. The weight Î± essentially controls the degree of directional change of the Firefly path. A value of Î± = 1 discards the path shape completely and can produce very sharp trajectory changes. On the other hand a value of Î± = 0 results in a closed curve with the least trajectory change, i.e., a large circle. Because we ensure C 1 continuity of the path, we can choose a relatively high Î± without causing excessively sharp trajectory changes. While this weight can differ for various application scenarios, we used Î± = 0.95 for all examples in this paper. In <ref type="figure" target="#fig_1">Figure 4</ref>, we illustrate the light trajectories resulting from different values for the weight Î±. In the remainder of this section, we discuss the image and path energy in detail.</p><p>Image Energy: The image energy is the most versatile and important component of the energy function. With image energy, we denote any energy formulation that can be derived directly from the rendered scene. The formulation of this component indirectly determines how the light path will illuminate the scene. As there are countless possibilities to define a meaningful image energy, we illustrate only a handful formulations and their effects on the resulting light path.</p><p>As we are interested in how the light path affects the scene as seen from the current camera position, we only consider illumination contributions that are visible from the current camera's point of view. As mentioned before, we formulate the path computation as a minimization problem of the energy function, and therefore the light path must be aggregated into a single energy value. To achieve this, the illumination evaluation must be aggregated over the rendered image as well as over the path. Therefore, we define the image energy as two nested functions. Using the notation I for image and P for the path domain, we define the energy function of the scene sc as:</p><formula xml:id="formula_4">E I = F P (F I (sc)) or: (5) E I = F I (F P (sc))<label>(6)</label></formula><p>As the respective functions are not necessarily commutative, the order of the evaluation can have critical impact on the resulting energy function and should be chosen according to the application scenario. The purpose of a light is the illumination of the scene. Therefore the image energy must account for the scene illumination explicitly or implicitly. A straight forward measure of the scene illumination is the measurement of the brightness of the rendered object. A useful target for a Firefly would be the illumination of the scene with a desired intensity. We can formulate such behavior with the following energy function:</p><formula xml:id="formula_5">E I = max P (avg I (br(sc) â Î³))<label>(7)</label></formula><p>where Î³ is the target brightness and br(sc) the measured brightness in the rendered scene. Such a formulation forces all light positions on the path to be close to the desired brightness on average. However, the energy does not penalize an image with too dark and too bright regions, as long it does not change the average brightness of the scene. Changing the order of the functions yields the following energy function:</p><formula xml:id="formula_6">E I = avg I max P (br x,y â Î³)<label>(8)</label></formula><p>where br x,y is the brightness measured for a pixel at the position x, y. This energy function first creates a new image with the maximal difference along the path for each pixel and then computes the average of the image. This means that we first aggregate over time and evaluate the influence of the light path locally. Therefore, this formulation penalizes paths that produce surface illuminations differing strongly from the desired brightness anywhere on the illuminated object, hence enforcing a uniformly illuminated object for the whole Firefly path. In <ref type="figure">Figure 5</ref>, we illustrate the effects of these two energy functions on the Firefly path shape and the illuminated scene. For this example we have chosen Î³ as 0.3. The first row of <ref type="figure">Figure 5</ref> shows the paths of the Firefly. In <ref type="figure">Figure 5</ref> appearance in <ref type="figure">Figure 5(d)</ref>. Using the max P (avg I ) energy function enforces a greater distance between the object and the light, but it can create strong shadows, as shown in <ref type="figure">Figure 5</ref>(e). Using avg I (max P ) results in a scene as in <ref type="figure">Figure 5(f)</ref>. Clearly, the surface is much more evenly illuminated compared to the one in <ref type="figure">Figure 5</ref>(e). We want to point out that we have chosen these energy functions to demonstrate the importance of the function order and not necessarily as best suited for certain illumination scenarios. We introduce energy functions tailored to specific application scenarios in Section 5.</p><p>Lighting setups are commonly centered around an object of interest. However, the user may be interested in multiple objects in the scene or might want to change the object of interest. To address this, we allow the user to select objects of interest in the scene though a simple click on the object. When an object is selected, the system generates an object mask M ob j to evaluate only the pixels covered by the mask. We illustrate such a mask in <ref type="figure">Figure 6(b)</ref>, where the ink container in <ref type="figure">Figure  6</ref>(a) is selected as the object of interest resulting in a mask as shown in <ref type="figure">Figure 6</ref>(b), which discards the background completely. If the user is only interested in parts of the image, they can add an additional input mask M in to emphasize these regions. The input mask is defined as a smooth function between 1 and 0, that decreases with the distance to the mouse position. A combination of the object mask and input mask can be seen in <ref type="figure">Figure 6</ref>(c).</p><p>Path Energy: The visual system is very sensitive to changes in the lighting conditions. Sudden and unexpected changes of the light trajectory can lead to misinterpretation of the scene dynamics. As indicated by Kersten et al. <ref type="bibr" target="#b21">[23]</ref>, users can misinterpret unexpected changes of light conditions as movements in the scene. The likelihood of such misinterpretations can be reduced using two strategies: by employing a smooth light trajectory without sharp turns and by giving the user explicit feedback on the light positions. The path energy a b <ref type="figure">Fig. 7</ref>. The brightness values of the rendered image in (a) are partitioned into 64 Ã 64 segments resulting in a down-sampling shown in (b). This partitioning provides a good trade-off between the preserved level of detail and data reduction.</p><p>ensures the former. The degree of how drastically a path is changing can be measured through the curvature of the path. To avoid sharp turns, the path energy is defined as the maximal curvature Îº(s) over the path P:</p><formula xml:id="formula_7">E P = max(Îº(s)), s â P.<label>(9)</label></formula><p>This simple restriction in addition to the C 1 continuous path formulation ensures a smooth trajectory of the Firefly without excessively sharp turns.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Optimization</head><p>Having specified the desired energy function, a well-suited path for the Firefly is one that minimizes the total energy. Choosing a suitable optimization approach is crucial for the quality of the Firefly path.</p><p>As mentioned in Section 3.1, the Firefly path is defined by a set of control points. Thus, the dimensionality of the parameter space is equivalent to the number of control points. Hence, there is a tradeoff between the problem complexity and the granularity of the direct path shape specification. Because the Firefly is created as a supportive tool during user interaction, the optimization must provide adequate results on the fly. In our examples, we construct the Firefly path with eight control points, which provides enough control for the Firefly path definition, while constraining the optimization to a reasonable degree of complexity that allows us to maintain interactivity. As the energy functions are dependent on the scene composition, they can be highly non-convex, resulting in many local minima. This imposes a challenge for many gradient descent algorithms. Even modern methods such as Adagrad, AdaDelta, RMSprop, and NADAM <ref type="bibr" target="#b31">[33]</ref> can get stuck in local minima. To overcome local minima, we implemented an adapted version of the Simulated Annealing (SA) algorithm <ref type="bibr" target="#b39">[41]</ref>. Traditional SA considers one neighboring stateS of the current state S, and decides whether to update the system state toS, based on a temperature-dependent probability function. In each iteration, the system temperature is decreased, stabilizing the energy state, until the computational budget has been used up. In our approach, we always evaluate an ensemble of neighbors at once, thus increasing the convergence speed of the algorithm.</p><p>A straight-forward adoption of SA to ensemble sampling is a Monte Carlo sampling of the ensemble over the parameter subspace. However, several publications <ref type="bibr" target="#b20">[22,</ref><ref type="bibr" target="#b35">37,</ref><ref type="bibr" target="#b44">46]</ref> show an improved convergence rate of Latin hypercube sampling over Monte Carlo, due to its improved space filling properties. Therefore, in each iteration, we perform a Latin hypercube sampling, computed using the method of Stein <ref type="bibr" target="#b37">[39]</ref>. We assume a normal parameter distribution and no parameter correlation for the sampling process. In each iteration, we use the best state of the ensemble for the update decision.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Sample Evaluation</head><p>As mentioned previously, computation speed is crucial for interactive scenarios. A common bottleneck for light design approaches is the evaluation of the scene. This is even more true for our approach, as the scene needs to be evaluated not just for different light positions but for different light paths. To approach this challenge, we can essentially employ two strategies: increase the computational performance of our approach and reduce the computational complexity of the problem.</p><p>To increase the performance of our approach, sampling and evaluation of the scene are performed in a detached parallel rendering pipeline. We employ a worker thread pool to generate the scenes and collect their information for each a test path. Optimization techniques require an aggregation of the fitness to a numeric value. For the Firefly path, the fitness is computed through the energy function. As mentioned in Section 3.2, the order of the energy function components affects the order of the aggregation over the image domain and the path domain. If the aggregation is performed over the image domain first, then the worker can return a single numerical value for each scene. However, if the aggregation is performed over the path domain first, then the worker would need to store the scene information for every light sample on the path before performing the aggregation.</p><p>Clearly, this creates a substantial overhead for the worker performance. To address this challenge, we need to find a suitable trade-off between computational efficiency and the preservation of features of the energy function. Usually, light affects the scene over neighborhoods instead of isolated points. Therefore it is reasonable to assume that neighboring pixels will have similar energy characteristics. We use this fact to abstract the localized energy states in the scene through partitions that store the average energy of their pixels. We illustrate the partition of the illumination energy in <ref type="figure">Figure 7</ref>. In our current implementation, we divide the scene image into 64 by 64 partitions, which still captures enough details. For each path, the workers evaluate the partitions first over the path domain and then over the image domain according to the energy function, and then report the resulting image energy as a single value.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Lighting Design</head><p>The three-point lighting setup is a common lighting method used in photography, cinematography, and computer-generated imagery. It is a relatively simple but versatile approach which forms the basis for most lighting setups. In the following, we briefly discuss the integration of Firefly into a basic version of three-point lighting as described in several photography text books <ref type="bibr" target="#b10">[12,</ref><ref type="bibr" target="#b30">32]</ref>. As the name suggests, threepoint lighting uses three light sources, a key light, a fill light, and a back light, as shown in <ref type="figure" target="#fig_3">Figure 8</ref>.</p><p>The key light is the main and usually the strongest light of the setup. The goal of the key light is to produce tonal variations in the image. Therefore, it is usually placed to one side of the illuminated object in order to produce shadows visible to the camera, as illustrated in <ref type="figure" target="#fig_3">Figure  8</ref>. A strong key light can create very strong shadows and thus hide geometric details. To overcome this problem, a secondary light is used to "fill" out the shadows with a soft light. The fill light is often placed at 90 â¢ to the key light (see <ref type="figure" target="#fig_3">Figure 8)</ref>. The fill light is usually less bright and softer than the key light, playing only a secondary role for the illumination. The back light is placed behind the illuminated object. Instead of providing direct illumination of the object, the back light emphasizes and provides subtle highlights of the object's silhouette. This helps to separate the object from the background and provides additional depth cues. We integrate our Firefly into a three-point light setup by considering it as the key light. A common placement of the key light is at an angle Î± of 30 â¢ to 45 â¢ at the side of the camera and the illuminated object, as shown in <ref type="figure" target="#fig_3">Figure 8</ref>. Furthermore, the key light is commonly placed slightly above the camera. We initialize the Firefly path position at an Î± value of 30 â¢ and a relative elevation above the camera equal to half of the path radius. The fill light moves with the key light and is placed at an angle of 90 â¢ to the key light rotated on a plane defined by the right and front camera vectors. The back light is placed behind the object in the view space. However, this setup should be considered as guideline rather than a rule, as the Firefly path converges quickly even when poorly initialized.</p><p>In <ref type="figure">Figure 9</ref>, we illustrate the effect of the number of lights on a model from the animated short film Adam <ref type="bibr" target="#b0">[1]</ref>. In <ref type="figure">Figure 9</ref>(a), only the key light is used and in (b) a fill light was added to the scene creating a more even illumination. In <ref type="figure">Figure 9</ref>(c), the addition of a back light provides additional subtle highlights of the geometry.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">IMPLEMENTATION</head><p>We implemented the Firefly system as a camera component in <ref type="figure">Unity [3]</ref>. Unity is a popular multi-purpose engine that supports 2D and 3D graphics. The drag-and-drop functionality of Unity and the C# scripting interface provide fast prototyping possibilities. Furthermore, the efficient plugin system allows for easy sharing of the results across multiple platforms. To use the system, the user simply adds Firefly as a camera component to the scene setup. For selecting the object of interest, Firefly only requires that the 3D objects have a collision geometry and a unique name.</p><p>Firefly is implemented as a background process, running in parallel to the main rendering thread, as illustrated in <ref type="figure">Figure 10</ref>. When an object of interest is selected, a new Firefly path is initialized and the optimizer creates a list with control point offsets that is sent to the path manager. The path manager creates the light paths that are evaluated in a worker thread pool. The workers create a sampling queue of scenes that are rendered and evaluated in a process that is fully transparent to the user. The primary benefit of a worker thread pool over creating a new thread for each path evaluation is that the thread creation and destruction overhead is restricted to the pool creation. The size of the worker thread pool depends on the used hardware. We found that on an Intel Core i7 3.00 GHz CPU, a worker thread pool of size five delivered the best performance.</p><p>Each worker evaluates one path at a time by computing its image and path energy. The image energy is computed on the GPU by rendering the scene for uniformly-sampled Firefly positions along the path. Thus, the number of scene evaluations directly corresponds to the evaluation time for the image energy. During the development of the Firefly system, we found that evaluating 14 samples for each path provides a robust estimate of the path quality while still allowing for a fast computation. When a worker has finished the evaluation of a path, the information of this path is stored in the worker pool. When all paths have been processed, the worker pool sends the results of all paths to the optimizer.</p><p>In the optimizer, the collected information is used to compute the final energy function. Next, the optimizer evaluates the fitness of the paths and possibly updates the Firefly path to a better one. The last step of the iteration is the computation of a set of new sampling parameters that are sent to the path manager. On an Nvidia GeForce GTX 780 GPU and an Intel Core i7 3.00 GHz CPU and a screen resolution of 1920 Ã 1200, one such iteration requires on average 973 ms for the evaluation of 40 paths with 14 rendered images for each path. The main thread is virtually unaffected by this computation and we did not detect a noticeable drop of the frame rate for the rendered scene.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">RESULTS</head><p>In the following, we demonstrate the use of Firefly for four different scenarios. To show the versatility of our approach, we selected examples covering scientific visualization applications as well as scenarios inspired by applications in the entertainment industry. All Firefly paths described in this paper are initialized according to the basic three-point lighting setup. In each iteration, the sampling is performed with 40 test paths and 14 samples for each path. As it is difficult to fully capture the dynamic behavior of our approach in text and still images, we encourage the reader to also refer to our supplemental video.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Molecular Structures</head><p>The exploration and analysis of molecular data is a prominent topic in scientific visualization. The purpose of molecular visualization is to provide an understanding of the rich and highly complex world of atomic structures, by mapping molecular structures, their functionality, properties, and interactions to visual characteristics. Molecular data is commonly very crowded, and the visualization of molecules features high visual complexity. The illumination of such complex geometry is a challenging task. In this example we use a 3D model of a tRNA structure 1GAX, consisting of 17210 atoms. This molecule has several deep cavities and tunnels, that pose a challenge to an illumination setup. A static setup will often result in deeply shadowed cavities and tunnels, hindering the geometry assessment. We can address this challenge by guiding the Firefly to the regions we want to illuminate using an input mask. We define a simple energy function that illuminates the surface with a desired brightness value of Î³ = 0.3. As strong shadows can be beneficial for shape perception, we use the energy function given in Equation 7. In <ref type="figure">Figure 11</ref>, we show two images of the same scene illuminated with two different Firefly paths. In <ref type="figure">Figure 11(a)</ref> ,the mask was set to cover the left side of the molecule, while in (b) the right part was the focus. The Firefly path automatically deforms to create a better energy for the masked part only. One can clearly see that tunnels on the left side of the molecule are much better illuminated in the top image.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Human Anatomy</head><p>Advances in computer technology have profoundly affected the domain of medical education. It has been shown that using 3D computer models as a teaching medium of human anatomy significantly improves the recollection of anatomical structures <ref type="bibr" target="#b26">[28]</ref>. Often such models are slightly exaggerated to emphasize structures and textures of the anatomical objects. The visualization of such structures highly benefits from a lighting setup that highlights the variations of the model surfaces. However, as the models tend do be highly complex, it is difficult to find a static light source that provides a good illumination of all relevant structures. We illustrate such a scenario on a model of the human head <ref type="bibr" target="#b1">[2]</ref>. We show the model illuminated with the preset static lights in <ref type="figure">Figure 12</ref>(a). The complex spatial relationships between the individual structures can significantly benefit from a moving light source. Intuitively, a well-suited light path should not illuminate the object near to the camera position as this would decrease perceived shape variation <ref type="bibr" target="#b25">[27]</ref>. Instead, the light should illuminate the object from several sides to account for all aspects of the model surface. The shape of the brain gyri and sulci is most prominent with a high contrast between the valleys and ridges of the surface. We can indirectly measure the local contrast of the model through a local variance measure. However, using the variance alone does not account for the brightness of the image. Therefore, the image brightness must be included in the energy as well. Because the image brightness value is much higher than the variance, we multiply the variance with an importance factor Î¾ . To allow for stronger shadows, we measure the average instead of the maximum brightness for this example. Incorporating the difference in brightness and variance results in the following energy function:</p><formula xml:id="formula_8">E I = â x,y Î¾ â¢ min P |(var(sc, s) â Î¸ |) + avg P (|br x,y â Î³|)<label>(10)</label></formula><p>where Î¸ is the desired variance. Here, we used Î¸ = 0.02 and Î¾ = 5. Using this energy function favors paths that emphasize high variance in the scene while maintaining uniform illumination. In <ref type="figure">Figure 12(b)</ref>, we show the resulting Firefly path after 34 iterations. One can see that the Firefly path resembles two loops with a relatively uniform distance to the model. We show four consecutive snapshots for this Firefly path in <ref type="figure" target="#fig_6">Figure 13</ref>. One can see that the Firefly indeed travels on a path that illuminates the scene from different directions (up, down, left, right). Interestingly, the Firefly path forms a loop, as this light trajectory is better suited to emphasize the features at the edge of the brain as well as the ones in the center of the model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Animation</head><p>Lighting setup is a crucial part of cinematic animations. In addition to static lights, many animation techniques employ dynamic lights as they can be used to convey the passing of time, emphasize a dramatic change of a character, or change the focus of attention. When an illuminated character moves in the scene, the dynamic light needs to adjust to this motion, which poses a challenge on the animator to carefully construct a lighting path that still creates the desired result while in motion. With our approach this challenge can be addressed through the automatic adjustment of the Firefly path. As the Firefly path is defined relative to the object of interest, it moves with the object automatically adapting to the changing conditions. In this example, we use a character from the animated short film Adam <ref type="bibr" target="#b0">[1]</ref>. We illuminate the same scene with three different illumination setups that create different effects for the user.</p><p>The first setup creates a dramatic atmosphere, the second a threatening one, and the third setup aims to produce a calm atmosphere.</p><p>To create a dramatic effect, cinematography often employs rim lights. Rim lights are used to create dramatic scenes with a Chiaroscuro lighting. This artistic technique, developed in the Renaissance, uses strong lighting on one side of the object to create distinct one-sided shadows. We can formulate this by maximizing the variance and requiring a certain brightness in the image. To restrict the effect to one side of the object, we compute the dot product between the normalized vector from the Firefly to the object l o and the right vector r in camera space. Minimizing the dot product favors light positions on the right side of the object.</p><p>To create a threatening scene effect, we follow the guidelines of digital cinematography <ref type="bibr" target="#b2">[4]</ref>. Disregarding the light color, a threatening effect can be generated by using a low key light, that has a light intensity ratio of 8:1 between the key and fill light, and a strong back light. Furthermore, the light should illuminate the object from underneath creating a high variance in the scene.</p><p>In contrast, a calming atmosphere can be achieved with a high key light, i.e., a similar intensity of key and fill light. This setup is reduces the overall variance in the image. In addition, the light elevation should be close to the elevation of the camera. Following these guidelines we can define the three energy functions as:</p><p>dramatic:</p><formula xml:id="formula_9">E I = â P âvar I (s) + |br s â Î³| + (l 0 â¢ r)<label>(11)</label></formula><p>threatening:</p><formula xml:id="formula_10">E I = â P âvar I (s) + |br s â Î³| + |el + Ï 3 | ds<label>(12)</label></formula><p>calm:</p><formula xml:id="formula_11">E I = â P var I (s) + |br s â Î³| + |el| ds.<label>(13)</label></formula><p>Where el is the elevation angle in radians. In <ref type="figure" target="#fig_1">Figure 14</ref>, we show a representative result for the energy functions and the corresponding paths. One can clearly see the different moods present in the images. <ref type="figure" target="#fig_1">Figure 14</ref>(a) shows a dramatic scene, (c) a threatening scene, and (e) shows a rather calm atmosphere. The corresponding paths are shown in (b),(d), and (f).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Still Life</head><p>The assumption of light position is stronger for scenes with a familiar setup. Illuminating such a scene with a Firefly constructed with the previously described energy functions might create an odd scene not matching the user's expectations. Therefore, when designing an animated light for a realistic scene, for example a still life, we need to closely follow photographic lighting setup rules.</p><p>In this example, we illuminate a still life and formulate the energy function guided by the approach of Wambecke et al. <ref type="bibr" target="#b40">[42]</ref>. This method, based on photographic rules, optimizes the azimuth and elevation of the light to emphasize the surface variation of the object while constraining the light position to the upper front hemisphere. Illuminating the scene with this method results in a rendering as shown in <ref type="figure" target="#fig_8">Figure 15(a)</ref>.</p><p>A Firefly constructed in accordance with this method should be arranged above the camera and the object, with an azimuth range that accounts for the majority of the surface variation. Following the approach of Wambecke et al., we break down the light position into the light azimuth and elevation. The azimuth is computed using the structure tensor of the geometry measuring the direction of surface variance, and the elevation is used to produce a grazing light. For more details, we refer to the paper of Wambecke et al. <ref type="bibr" target="#b40">[42]</ref>. For the azimuth, we first obtain the gradient of the surface depth âd for each pixel, and compute the local structure tensor S x,y for each image partition P x,y :</p><formula xml:id="formula_12">âd = ân x n z , ân y n z (14) S x,y = â pâP x,y âd âd T .<label>(15)</label></formula><p>The eigenvector e 1 of S associated to the largest eigenvalue Î» 1 represents the direction in which most surface variations appear for each partition. If e 1 is pointing downwards, then the vector is simply flipped. Wambecke et al. define the light azimuth at an angle of e 1 in view space. In our approach, we measure the fitness of the Firefly azimuth by computing the dot product between e 1 and the normalized vector from the Firefly to the center of gravity of the illuminated object l o . To favor light positions close to e 1 for the whole path, we define the azimuth energy as:</p><formula xml:id="formula_13">E az = max s (1 â (e 1 â¢ l o )) .<label>(16)</label></formula><p>The elevation of the light is chosen such that l o is orthogonal to hidden surface normals n 0 defined as:</p><formula xml:id="formula_14">n 0 = n if l e 0 ,o â¢ n &gt; 0 0 if l e 0 ,o â¢ n â¤ 0<label>(17)</label></formula><p>where l e 0 ,o is the vector between the light position projected on an elevation of 0 and the object of interest. Therefore, the elevation energy is defined as:</p><formula xml:id="formula_15">E el = max s (l e 0 ,o â¢ n 0 ).<label>(18)</label></formula><p>Incorporating the information of the optimal light direction can lead to light positions too far away or too near to the object, resulting in too weak or to strong illumination. A straightforward solution would be to define a minimum distance between the object and the Firefly, but such a condition could produce rather unnatural illumination. Using the energy function, we can instead easily control the distance between the a b <ref type="figure">Fig. 16</ref>. The Firefly path for the still life scene seen from the front (a) and from the side (b). In (b), the Firefly moves away from the object briefly to generate illumination from the front that does not produce shadows on the object.</p><p>object and the Firefly indirectly by minimizing the maximal brightness difference for each image partition. Putting all parts of the energy function together, the image energy is evaluated as a sum of the individual energy states over the image:</p><formula xml:id="formula_16">E I = â x,y E az + E el + max P (|br x,y â Î³|) .<label>(19)</label></formula><p>Where x and y are the partition indices. The desired brightness Î³ was set to 0.3. Using this energy function results in a scene illumination shown in <ref type="figure" target="#fig_8">Figure 15(b)</ref>, (c), and (d). We show the static lighting setup computed with the method of Wambecke in <ref type="figure" target="#fig_8">Figure 15(a)</ref>. Naturally, the Firelfy produces very similar results as the static state-of-the-art method -in fact the light positions in images (a) and (b) are almost identical. However, for the static setup we had to adjust the distance between the light source and the object to achieve the desired brightness. Our method adjusted the distance automatically based on the desired brightness value. Furthermore, our method emphasizes all of the geometry throughout the path. In <ref type="figure" target="#fig_8">Figure 15</ref>(c), the Firefly creates shadows that emphasize the shape of the cake and in <ref type="figure" target="#fig_8">Figure 15</ref>(d) the shape of the coffee bag is much more prominent. We show the corresponding Firefly path in <ref type="figure">Figure 16</ref>. As expected, the path is organized above and in front of the object, forming an arc on the azimuth plane. In <ref type="figure">Figure  16</ref>(b), one can see that the path moves away from the object over a short path section in front of the object. This movement of the light away from the object generates a light position that produces almost no shadows on the object, thus creating an overall stronger illumination of the scene. To account for this, the light moves farther away in order to achieve an illumination close to the desired values.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">DISCUSSION</head><p>In our experiments we found that the animated light of the Firefly provides a powerful and versatile addition to a static lighting setup. We deliberately chose relatively simple energy functions for most of our examples, but nonetheless showed that our approach is capable of incorporating state-of-the-art solutions for static lighting design in a dynamic setup. The Firefly approach can be easily integrated into other renderers, but we believe that our implementation as a Unity plugin makes it already accessible to a large number of applications. Our method is independent of the scene content and rendering method, and hence can be used with a wide variety of different types of data. While the evaluation of the test paths requires around 500 milliseconds on average, the fact that this process is executed in the background makes it transparent to the user. After the initialization, the optimization requires 35 to 40 iterations to reach a stable state. We show a representative convergence rate in <ref type="figure">Figure 17</ref>. The whole optimization process takes around 34 seconds for full convergence, but since the Firefly continuously updates to the best available solution, a good result is typically already achieved after about 9 seconds. When the user changes the view, the optimization needs 3 to 6 iterations to update the Firefly path to a new stable state, requiring 2.5 to 5 seconds. Because these background computations do not affect the performance of the main rendering thread and the Firefly transitions smoothly into a new path, we did not experience any negative effects on the overall usability. The initialization of the worker pool requires around 9 seconds during the program start, since all the workers need to be initialized with the corresponding Unity scene and settings. When the user employs a selection mask, regions outside the selection are not accounted for in the illumination optimization. This can cause unwanted effects outside the selection mask, such as strong shadows or change of light intensity. However, we believe that these results are tolerable as the user deliberately shifts the attention to selected substructures. While dynamic light can emphasize and enhance certain aspects of the scene, it can also be misleading in some situations. Dynamic lights might be unsuitable for scenarios with highly dynamic scenes or dynamic textures as the change of light position might be interpreted as a change in the scene. Furthermore, dynamic lights might deflect the user's attention and thus may not be not suitable for applications where high concentration is needed to carefully study the data.</p><p>In this paper, we define a limited number of energy functions. To allow for an easy energy function formulation, we construct the energy function as an assembly of building blocks, measuring different properties in the scene and the rendered image. New energy functions can be constructed by using different combinations of these building blocks. However, the current version of the Firefly requires the user to define the energy function by writing a short code segment combining the building blocks. We are working on a visual editor that will allow the user to easily construct custom energy functions by combining the building blocks in a drag-and-drop manner. Finally, the effects of animated lights on the perception need to be formally evaluated, and we plan to conduct a user study investigating their perceptual consequences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">CONCLUSION AND FUTURE CHALLANGES</head><p>We presented a novel approach for the automated generation of dynamic illumination paths in interactive scenes. Our approach shows that animated light provides a powerful and versatile addition to static lighting setups. We designed the Firefly tool as a flexible plugin that can be easily added to various visualization scenarios. The applicability of Firefly was demonstrated on various examples ranging from scientific visualization to applications for the entertainment industry. At present, the Firefly travels with a constant speed over the curve. In the future, we would like to investigate how the speed of the Firefly can be adapted for a better illumination without appearing unnatural to the user. While in this paper we only used point lights, Firefly is not restricted to a specific light type. In the future, we will investigate how Firefly can be integrated into complex lighting setups with box lights, strip lights, ring lights, and reflector probes. Moreover, we will investigate how a Firefly with dynamic chromatic light could emphasize changing moods in the scene.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>Fig. 3. (a) To reduce the complexity during the optimization process we compute the tangents at point P k automatically from the neighboring points P kâ1 and P k+1 . (b) Assuming that small changes of the camera position introduce only small changes to the scene, we transform the Firefly path with the camera around the object of interest to provide an initial path.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 4 .</head><label>4</label><figDesc>The influence of Î± on the light trajectory shape. The weight is set to 0, 0.95 and 0.999 in (a), (b), and (c), respectively. Using Î± = 0 results in a circular trajectory (a), whereas neglecting the path shape too much can result in sharp trajectory turns (c). An Î± of 0.95 (b) results in a light path that is able to accommodate the image energy without excessively sharp turns.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 5 .Fig. 6 .</head><label>56</label><figDesc>(a) we show the initial Firefly path, in (b) and (c) we depict a Firefly path after 30 iterations with the image energy defined in Equation 7 and Equation 8, respectively. The second row shows a captured scene that illustrates the differences in the energy functions. The initial path comes close to the object, creating an overly bright An illustration of path shapes with varying energy functions. The first row shows the paths seen from above while the second row presents a scene state typical for the energy function. (a) and (d) show the path and a scene for the initial path. The object is too bright for some positions of the Firefly. (b) and (e) show the resulting path for the energy function described in Equation 7. On this path the Firefly can take positions that create strong shadows in the scene. In (c) and (f) the path was changed according to the energy function in Equation 8. The scene is much more evenly illuminated compared to (e). We allow the user to select objects of interest. Here, the user selected the paint jar in (a) with a object mask shown in (b). If the user wants to further specify a local region of interest, they can use an input mask. The combined object and input mask are shown in (c).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 8 .</head><label>8</label><figDesc>Firefly can be easily integrated into existing lighting setups. In thisFigure,a Firefly is integrated into a three-point lighting setup as the key light at an angle Î± of 30 â¢ . A fill light is positioned at 90 â¢ to the key light. The back light is placed behind the illuminated object with respect to the camera position.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 9 .Fig. 10 .</head><label>910</label><figDesc>A comparison between (a) a single key light, (b) a combination of key and fill light, and (c) a three-point lighting setup. The Firefly system is implemented as a background process running parallel to the main thread. To achieve on-the-fly adaptation of the Firefly path, we evaluate 40 paths at once in a worker pool. When the paths are evaluated, the information is sent to the optimizer that computes the path energy and requests further samples.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 11 .Fig. 12 .</head><label>1112</label><figDesc>Input mask guided illumination. In (a) the mask was held over the left side of the molecule. In (b) the right molecule side was masked. The Firefly path adapts automatically to the input mask. This way the user is able to adjust the illumination indirectly by moving the input mask. a b (a) A model of the human head with a static light setup. (b) A firefly path after 34 iterations.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 13 .</head><label>13</label><figDesc>Four consecutive positions of the Firefly. The Firefly travels on a loop illuminating the head from (a) below, (b) right, (c) above and (d) left.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 14 .</head><label>14</label><figDesc>Difference between scenes with different moods encoded through the energy function. (a) shows a dramatic scene, (b) a threatening scene and (e) a calm scene. Images (b),(d) and (f) show the corresponding paths, respectively.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 15 .</head><label>15</label><figDesc>Still life rendered with the method of Wambecke et al. (a). The same model illuminated with the Firefly method (b,c,d). The lighting in (a) and (b) is almost identical, but (c) and (d) reveal the surface variation of the remaining model parts.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>â¢ Sergej Stoppel is with the University of Bergen, Norway, E-mail: sergejsto@gmail.com â¢ Magnus Paulson Erga is with the University of Bergen, Norway, E-mail: magnus.p.erga@gmail.com â¢ Stefan Bruckner is with the University of Bergen, Norway, E-mail: stefan.bruckner@uib.</figDesc><table /><note>no Manuscript received xx xxx. 201x; accepted xx xxx. 201x. Date of Publication xx xxx. 201x; date of current version xx xxx. 201x. For information on obtaining reprints of this article, please send e-mail to: reprints@ieee.org. Digital Object Identifier: xx.xxxx/TVCG.201x.xxxxxxx</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>Fig. 17. A representative convergence curve for an energy function described in Equation 8. The Firefly path significantly improves already after a single iteration. After 10 iterations (approximately 9 seconds) the energy was more than halved. After 30 iterations, the energy state was almost optimal. The stable state was reached after 36 iterations requiring just under 33 seconds.</figDesc><table><row><cell></cell><cell>1.17</cell><cell></cell></row><row><cell></cell><cell>0.91</cell><cell></cell></row><row><cell>Energy</cell><cell>0.39 0.65</cell><cell cols="2">State Stable</cell></row><row><cell></cell><cell>0.13 0</cell><cell>10 Iterations 20 30</cell><cell>40</cell></row></table><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLDEGMENTS</head><p>The research presented in this paper was supported by the MetaVis project (#250133) funded by the Research Council of Norway.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename></persName>
		</author>
		<ptr target="https://unity3d.com/pages/adam.Accessed" />
		<imprint>
			<biblScope unit="page" from="2018" to="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">U-anatomy; ufulio anatomy realistic</title>
		<ptr target="https://ufulio.wixsite.com/ufulioanatomy.Accessed" />
		<imprint>
			<biblScope unit="page" from="2018" to="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Advanced RenderMan: Creating CGI for Motion Pictures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Apodaca</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Gritz</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999" />
			<publisher>Morgan Kaufmann</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Inverse lighting and photorealistic rendering for augmented reality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Aittala</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Visual Computer</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="669" to="678" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Automatic tuning of spatially varying transfer functions for blood vessel visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Borga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Persson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Lenz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lindholm</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Lathen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2345" to="2354" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Visualizing motion data in virtual reality: Understanding the roles of animation, interaction, and static presentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Coffey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Korsakov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Hagh-Shenas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Thorson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ellingson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Nuckley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">F</forename><surname>Keefe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics Forum</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">3pt3</biblScope>
			<biblScope unit="page" from="1215" to="1224" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Lighting design: A goal based approach using optimisation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">C</forename><surname>Costa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Sousa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">N</forename><surname>Ferreira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Eurographics Workshop on Rendering</title>
		<meeting>Eurographics Workshop on Rendering</meeting>
		<imprint>
			<date type="published" when="1999" />
			<biblScope unit="page" from="317" to="328" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Expression of emotions in virtual humans using lights, shadows, composition and filters</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>De Melo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Paiva</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Affective Computing and Intelligent Interaction</title>
		<meeting>Affective Computing and Intelligent Interaction</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="546" to="557" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Visual motion and the perception of surface material</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Doerschner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">W</forename><surname>Fleming</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Yilmaz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">R</forename><surname>Schrater</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Hartung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kersten</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Current Biology</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">23</biblScope>
			<biblScope unit="page" from="2010" to="2016" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Real-time lighting design for interactive narrative</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">S</forename><surname>El-Nasr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Horswill</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Virtual Storytelling. Using Virtual RealityTechnologies for Storytelling</title>
		<meeting>Virtual Storytelling. Using Virtual RealityTechnologies for Storytelling</meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="12" to="20" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Light Science &amp; Magic: An Introduction to Photographic Lighting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Hunter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Biver</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Fuqua</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<publisher>Focal Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Automatic speed adjustment for travel through immersive virtual environments based on viewpoint quality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Freitag</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Weyers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">W</forename><surname>Kuhlen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 3DUI</title>
		<meeting>3DUI</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="67" to="70" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Evaluation of static and dynamic visualization training approaches for users with different spatial abilities</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">E</forename><surname>Froese</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Tory</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">W</forename><surname>Evans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Shrikhande</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2810" to="2817" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Maximum entropy light source placement</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gumhold</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Visualization</title>
		<meeting>IEEE Visualization</meeting>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="275" to="282" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Decoupled opacity optimization for points, lines and surfaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>GÃ¼nther</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Theisel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gross</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics Forum</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="153" to="162" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Lightkit: A lighting system for effective visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Halle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Meng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Visualization</title>
		<meeting>IEEE Visualization</meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="48" to="57" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">A real-time shadow approach for an augmented reality application using shadow volumes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Haller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Drab</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Hartmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ACM Symposium on Virtual Reality Software and Technology</title>
		<meeting>ACM Symposium on Virtual Reality Software and Technology</meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="56" to="65" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">An interactive tool for designing quadrotor camera shots</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Joubert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Truong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Berthouzoz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Hanrahan</surname></persName>
		</author>
		<idno>238:1-238:11</idno>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Graphics</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">6</biblScope>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Snakes: Active contour models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kass</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Witkin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Terzopoulos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="321" to="331" />
			<date type="published" when="1988" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">An automatic system for the control of multiple drone aircraft</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">E</forename><surname>Keiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">Z</forename><surname>Peebles</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Aerospace and Electronic Systems, AES</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="515" to="524" />
			<date type="published" when="1969" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Latin hypercube sampling monte carlo estimation of average quality index for integrated circuits</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Keramat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Kielbasa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Analog Integrated Circuits and Signal Processing</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="131" to="142" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Moving cast shadows induce apparent motion in depth</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kersten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Mamassian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">C</forename><surname>Knill</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Perception</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="171" to="192" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">On the perception of shape from shading</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename><surname>Kleffner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">S</forename><surname>Ramachandran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Perception &amp; Psychophysics</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="18" to="36" />
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Compositing for small cameras</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Murray</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE/ACM International Symposium on Mixed and Augmented Reality</title>
		<meeting>IEEE/ACM International Symposium on Mixed and Augmented Reality</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="57" to="60" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Light collages: lighting design for effective visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Hao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Varshney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Visualization</title>
		<meeting>IEEE Visualization</meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="281" to="288" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Prior knowledge on the illumination position</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Mamassian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Goutcher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognition</title>
		<imprint>
			<biblScope unit="volume">81</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="9" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Can virtual reality improve anatomy education? a randomised controlled study of a computer-generated three-dimensional anatomical ear model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">T</forename><surname>Nicholson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Chalk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">R J</forename><surname>Funnell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Daniel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Medical Education</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1081" to="1087" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Evolutionary algorithm based offline/online path planner for UAV navigation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">K</forename><surname>Nikolos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">P</forename><surname>Valavanis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">C</forename><surname>Tsourveloudis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">N</forename><surname>Kostaras</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Systems, Man, and Cybernetics</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="898" to="912" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Augmented reality based on estimation of defocusing and motion blurring from captured images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Okumura</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kanbara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Yokoya</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE/ACM International Symposium on Mixed and Augmented Reality</title>
		<meeting>IEEE/ACM International Symposium on Mixed and Augmented Reality</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="219" to="225" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Perception of shape from shading</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">S</forename><surname>Ramachandran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">331</biblScope>
			<biblScope unit="issue">6152</biblScope>
			<biblScope unit="page" from="163" to="166" />
			<date type="published" when="1988" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">How to Set Up Photography Lighting for a Home Studio</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Richards</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
			<publisher>CreateSpace</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">An overview of gradient descent optimization algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ruder</surname></persName>
		</author>
		<idno>abs/1609.04747</idno>
		<imprint>
			<date type="published" when="2016" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Automatic transfer functions based on informational divergence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ruiz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bardera</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Boada</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Viola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Feixas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sbert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="1932" to="1941" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Perception of light source distance from shading patterns</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">H</forename><surname>SchÃ¼tt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Baier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">W</forename><surname>Fleming</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Vision</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">9</biblScope>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Automatic Lighting Design using a Perceptual Quality Metric</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Shacked</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lischinski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics Forum</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="215" to="227" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">The generalization of latin hypercube sampling. Reliability Engineering and System Safety</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">D</forename><surname>Shields</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">148</biblScope>
			<biblScope unit="page" from="96" to="108" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Computational rim illumination with aerial robots</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Srikanth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Bala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Durand</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Computational Aesthetics</title>
		<meeting>Computational Aesthetics</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="57" to="66" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Large sample properties of simulations using latin hypercube sampling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Stein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Technometrics</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="143" to="151" />
			<date type="published" when="1987" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Enhancement of glossiness perception by retinal-image motion: Additional effect of head-yoked motion parallax</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Tani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Araki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Nagai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Koida</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Nakauchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kitazaki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLOS ONE</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="8" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">Simulated annealing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">J M</forename><surname>Van Laarhoven</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">H L</forename><surname>Aarts</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1987" />
			<publisher>Springer</publisher>
			<pubPlace>Netherlands</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Automatic lighting design from photographic rules</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wambecke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Vergne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G.-P</forename><surname>Bonneau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Thollot</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Eurographics Workshop on Intelligent Cinematography and Editing</title>
		<meeting>Eurographics Workshop on Intelligent Cinematography and Editing</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Lighting system for visual perception enhancement in volume rendering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">E</forename><surname>Kaufman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">19</biblScope>
			<biblScope unit="page" from="67" to="80" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Perception of lighting and shading for animated virtual characters</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Wisessing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dingliana</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Mcdonnell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ACM Symposium on Applied Perception</title>
		<meeting>ACM Symposium on Applied Perception</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="25" to="29" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Automatic path planning for augmented virtual environment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. International Conference on Virtual Reality and Visualization</title>
		<meeting>International Conference on Virtual Reality and Visualization</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="372" to="379" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">A fast general extension algorithm of latin hypercube sampling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Statistical Computation and Simulation</title>
		<imprint>
			<biblScope unit="volume">87</biblScope>
			<biblScope unit="issue">17</biblScope>
			<biblScope unit="page" from="3398" to="3411" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Lighting design for globally illuminated volume rendering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K.-L</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2946" to="2955" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
