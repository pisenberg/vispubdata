<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/pisenberg/grobid/grobid-0.6.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Evaluating the Impact of Task Demands and Block Resolution on the Effectiveness of Pixel-based Visualization</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2010-10-24">24 October 2010</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><roleName>Member, IEEE</roleName><forename type="first">Rita</forename><surname>Borgo</surname></persName>
							<email>r.borgo@swansea.ac.uk</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karl</forename><surname>Proctor</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><roleName>Member, IEEE</roleName><forename type="first">Min</forename><surname>Chen</surname></persName>
							<email>m.chen@swansea.ac.uk</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><roleName>Member, IEEE</roleName><forename type="first">Heike</forename><surname>Jänicke</surname></persName>
							<email>heike.jaenicke@iwr.uni-heidelberg.de</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tavi</forename><surname>Murray</surname></persName>
							<email>t.murray@swansea.ac.uk</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><forename type="middle">M</forename><surname>Thornton</surname></persName>
							<email>i.m.thornton@swansea.ac.uk</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">•</forename><forename type="middle">R</forename><surname>Borgo</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">• K M</forename><surname>Proctor</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Thornton</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">•</forename><forename type="middle">H</forename><surname>Jänicke</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">•</forename><forename type="middle">T</forename><surname>Murray</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">are with Computer Science</orgName>
								<orgName type="institution">Swansea University</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">Department of Psychology</orgName>
								<orgName type="institution">Swansea University</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="department">Interdisciplinary Center for Scientific Computing</orgName>
								<orgName type="institution">Heidelberg University</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="department">Department of Geography</orgName>
								<orgName type="institution">Swansea University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Evaluating the Impact of Task Demands and Block Resolution on the Effectiveness of Pixel-based Visualization</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2010-10-24">24 October 2010</date>
						</imprint>
					</monogr>
					<note type="submission">received 31 March 2010; accepted 1 August 2010; posted online</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2021-02-19T18:58+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Pixel-based visualization</term>
					<term>evaluation</term>
					<term>user study</term>
					<term>visual search</term>
					<term>change detection</term>
				</keywords>
			</textClass>
			<abstract>
				<p>Pixel-based visualization is a popular method of conveying large amounts of numerical data graphically. Application scenarios include business and finance, bioinformatics and remote sensing. In this work, we examined how the usability of such visual representations varied across different tasks and block resolutions. The main stimuli consisted of temporal pixel-based visualization with a white-red color map, simulating monthly temperature variation over a six-year period. In the first study, we included 5 separate tasks to exert different perceptual loads. We found that performance varied considerably as a function of task, ranging from 75% correct in low-load tasks to below 40% in high-load tasks. There was a small but consistent effect of resolution, with the uniform patch improving performance by around 6% relative to higher block resolution. In the second user study, we focused on a high-load task for evaluating month-to-month changes across different regions of the temperature range. We tested both CIE L*u*v* and RGB color spaces. We found that the nature of the change-evaluation errors related directly to the distance between the compared regions in the mapped color space. We were able to reduce such errors by using multiple color bands for the same data range. In a final study, we examined more fully the influence of block resolution on performance, and found block resolution had a limited impact on the effectiveness of pixel-based visualization.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Pixel-based visualization is a collection of techniques that use colored position in 2D space to encode data <ref type="bibr" target="#b14">[15]</ref>. These techniques can display a large amount of encoded data, and have been found useful in a range of applications, including business and finance <ref type="bibr" target="#b37">[38]</ref>, bioinformatics <ref type="bibr" target="#b13">[14]</ref> and remote sensing <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b27">28]</ref>.</p><p>In a typical pixel-based visualization, colored pixels are grouped into blocks (also termed as sub-windows in the literature), and blocks are normally organized in matrix form with two primary attribute dimensions (e.g., month and year). The typical objective of the visualization task is to establish the correlations, causality or other relations between blocks of pixels, and to identify unusual patterns in the data. Block resolution (i.e., the number of pixels in each block) can vary substantially. A block may contain one data value (e.g., temperature), or over a million pixels (e.g., in a satellite image). Visualizing a series of high resolution pixel blocks can benefit from a large power-wall display.</p><p>A challenging scientific question naturally arises from such variation: what are the factors that mainly determine user performance with such displays? Will it depend only on the number of pixels in each block? Or will other variables have a greater impact? The answer to such a question will clearly depend on a number of factors, such as the nature of the task, the skill level of the user and, more fundamentally, the limits of human vision, attention and cognition. However, so far, there has been little quantitative analysis of pixel-based visualization, especially in terms of task variations and block variations. It is this gap that we try to fill in the current work.</p><p>In three user studies, we examined performance in a common sce-nario in which month-to-month variations in temperature were visualized over a six-year period. Block resolution was varied within a small range (from uniform patches up to 8 × 8 arrays), allowing the whole visual design to be easily reproducible on a ordinary computer displays. In the first study, we examined block resolution and task difficulty, by presenting different comparative visual search and change detection tasks. This initial study allowed us to identify upper and lower limits of performance and to make an initial assessment of the impact of resolution. In the two subsequent studies, we selected tasks at the two extremes of performance, and examined more closely the role of block resolutions and color maps in determining patterns of behavior. Across all three studies, we found that:</p><p>• block resolution had a limited impact on the effectiveness of pixel-based visualization;</p><p>• task demands and related perceptual constraints accounted for most of the observed variation;</p><p>• careful selection of color palettes is essential for reducing taskrelated errors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK</head><p>Pioneered by Keim <ref type="bibr" target="#b14">[15]</ref>, pixel-based visualizations are known for the capability of making the best possible use of screen space <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b9">10]</ref>. Such display can visually present more data than many other techniques, such as iconic and projection-based techniques <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b5">6]</ref>. The controls of its design space normally include the choice of color space, subwindow shapes, pixel arrangement, dimension ordering and query specification <ref type="bibr" target="#b26">[27,</ref><ref type="bibr" target="#b18">19]</ref>. With the advent of giga-pixel displays <ref type="bibr" target="#b36">[37]</ref>, it is desirable to learn how well pixel-based visualization will scale according to the increasing block resolution. Natural images contain detail at a wide range of spatial scales <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b30">31]</ref>. The human visual system has evolved mechanisms to parse information according to spatial frequency content <ref type="bibr" target="#b34">[35,</ref><ref type="bibr" target="#b7">8]</ref>. In image perception, it is thought that coarse-scale information, captured by low spatial frequency filters, conveys information about general shape and structure, while fine-scale information, captured by high spatial frequency filters, carries information about edges and surface texture. Human perception of images at different resolutions has been extensively studied (e.g., <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b30">31]</ref>). Much work in this area focused on object and face recognition from degraded images. The practical objective, in pixel based visualization, is to achieve cost-effectiveness by using relatively low resolution images or videos while maintaining reasonable accuracy and speed in recognition.</p><p>In pixel-based visualization, much of the high spatial frequency content originates in the block contours themselves. Indeed, such "block quantization" effects are often used to mask inherent fine-scale information <ref type="bibr" target="#b10">[11]</ref>). It remains to be seen whether such local, high frequency "noise" affects the ability of users to extract global, low frequency content. For example, when comparing the average temperatures between two months, will additional details of the daily temperatures help or hinder the decision? However, the practical objective in pixel based visualization is normally the opposite of that for recognition from degraded images. As high-resolution pixel blocks depict more information, it is desirable to use such blocks as long as visualsearch and change detection speed and accuracy rates are reasonable.</p><p>In addition to block resolution, human performance with pixelbased visualization may also be influenced by a number of other factors. These may include the effect of surrounding context, working memory and attention demands of a given task. Oliva and Torralba <ref type="bibr" target="#b22">[23]</ref> provide and excellent review of the impact of context on human performance. There are many examples in the literature showing that context can influence visual performance (e.g., <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b12">13]</ref>). Objects appearing in familiar or consistent context (e.g., a plate on top of a kitchen table) will be more efficiently processed than when appearing in an inconsistent context (e.g. on top of a bathtub). This is particularly true when using degraded or low-resolution images (e.g., <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b30">31]</ref>). However, most pixel-based visualizations do not benefit from such context, which may affect cognitive load.</p><p>Tasks can vary greatly in the demands they place on a user, particularly with respect to memory and attention. Cognitive loads for different types of tasks have been studied in the paradigms of visual search <ref type="bibr" target="#b35">[36]</ref>, change detection <ref type="bibr" target="#b24">[25]</ref>, and working memory <ref type="bibr" target="#b23">[24]</ref>. For pixel-based visualization, there are no previous studies that relate directly to the cognitive load of different tasks. A primary goal of this paper will thus be to provide an initial assessment of the impact of resolution impact within tasks and their demands in pixel-based displays.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">APPLICATION SCENARIO</head><p>Pixel-based visualization can be applied to spatial and non-spatial data. In this work, we consider three application scenarios. The first scenario concerns the use of tabular form of pixel-based visualization to aid the analysis of numeric data captured at regular temporal intervals, such as stock market data. The second scenario concerns the common practice of color coding gene sequences for analyzing individual gene expressions within clusters from a single array. The third scenario concerns the common practice of juxtaposing an image sequence in analyzing remote sensing data.  <ref type="figure">Fig. 1a</ref> where the average changes are depicted, the 43 × 6 pixel blocks in 1c and 1b contain more information useful for localized reasoning while incurring additional perceptual burden in global reasoning. While acknowledging the necessity for the kind of visualization in <ref type="figure">Fig. 1</ref>, it would be helpful to know the effects upon the viewers in their global reasoning. For instance, when reasoning a global trend, would the users mentally determine the average color of each block first? If so, would the errors in determining the average colors result in less accurate reasoning? <ref type="figure" target="#fig_3">Fig. 2a</ref> shows a pixel-based visualization of part of a microarray archive derived from a leukemia study <ref type="bibr" target="#b3">[4]</ref>. <ref type="figure" target="#fig_3">Fig. 2b</ref> shows a sequence of Landsat images at two different resolutions with their locations marked on the left. Glaciologists need to compare imagery features at different scales, while trying to establish the overall patterns of the geo-environmental changes. They usually know well the regions that they are interested in. Even when they are given images with a large coverage, their attention immediately focuses on the regions of interests. During a period of collaboration with glaciologists, we observed the typical visual tasks in their scientific discovery work. For instance, they visually estimate the temperature variation over a period, compare the cyclic patterns between different years, and discuss the spatial and temporal relationships between identified phenomena. The varying degrees of uncertainty expressed by the glaciologists when they visualize and analyze such image sequences led us to examine the dependency of the visual analytical accuracy upon the resolution of the pixel blocks and task variations.</p><p>There have been numerous prior works on the impact of image resolution upon a viewer's ability to recognize an object or a scene captured by an image (e.g. <ref type="bibr" target="#b30">[31,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b0">1]</ref>). These works confirmed that as the resolution increases, viewers perform their recognition tasks better. However, the results of such studies cannot be applied to pixel-based visualization. As the viewers in the above mentioned scenarios perform analytical tasks that are very different from object recognition, the increase of the block resolution could very well have a negative impact. This provides this work with a motivation.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">EXPERIMENTS OVERVIEW</head><p>The three application scenarios mentioned in the previous section indicate several different tasks when using pixel-based visualization. These may include, but not limited to, (i) block-based pattern, change and trend detection (e.g., Figs. 1a and 2a), and (ii) pixel-in-block and pixel-across-blocks analysis (e.g., <ref type="figure">Fig. 1b-1c</ref> and <ref type="figure" target="#fig_3">Fig. 2b</ref>). The block size can vary from individual primitive blocks (e.g., monthly blocks in <ref type="figure">Fig. 1b-1c</ref>) and composite blocks (e.g., yearly blocks in <ref type="figure">Fig.1a</ref>). In some cases, such as <ref type="figure" target="#fig_3">Fig. 2a</ref>, the block size varies according to the levels of the two indexing trees. It is thus necessary to make some abstraction from the details of application-specific tasks.</p><p>In order to provide our study with an intuitive scenario that all the participants can easily understand, we decided to focus on temporal pixel-based visualization, and chose the common experience of temperature time series as the source of stimuli. A temporal pixel-based visualization is essentially a visualization of multiple time series. In our experiments, we group the values of multiple time series at each time step in a block of pixels.</p><p>In designing our experiments, we considered the following factors:</p><p>• Data Focuses -Time series data consists of sequences of measurements that follow a specific order. Many time series are expected to exhibit some cyclical behaviors. Such a time series normally features several properties. Amplitude measures the magnitude of the peak of a cycle against the mean of a cycle (or sometimes a predefined base value). Frequency measures the number of cycles in a pre-defined period. Phase shift measures the extent of displacement of one cycle in relation to the preceding cycle, or a predefined reference cycle. • Task Goals -The goals of time series analysis and pixel-based visualization typically include the measurement of difference and distribution, cycle length at different scales and the identification of peak, trend, seasonality, and irregular fluctuations. • Types of Changes -There are many types of changes, including existence change (e.g., adding or deleting an object), attribute change (e.g., color, size, etc.), layout change (e.g., relative spatial relationship between objects), and semantic identity change (e.g., a square to a triangle) <ref type="bibr" target="#b25">[26]</ref>. • Block Resolution -The number of pixels in each block can vary from application to application. In this work, we explore a relative small range of variation, due to scalability of both stimulus design and test length. This limit is compensated by the varying of block hierarchy. • Block Hierarchy -Blocks can be the primitive blocks, such as the monthly blocks in <ref type="figure">Fig. 1b-c</ref> and composite blocks such as yearly row in <ref type="figure">Fig. 1a</ref>. More complex hierarchy is exhibited in  <ref type="figure" target="#fig_3">Fig. 2a</ref>, while the hierarchy in <ref type="figure" target="#fig_3">Fig. 2b</ref> is feature-dependent. In this study, we focus on the basic primitive blocks and composite blocks at one hierarchy upper.</p><p>• Colormap -There are many properties of colormaps, including the number of principle colors, and colorimetric transformation.</p><p>In this work, we had a fixed colormap in the first user study, and examined a small number of foundational variations in the second and third user studies.</p><p>All of these factors could influence the perceptual load of a task. We thus designed our first user study, to capture the variation of different tasks. As it is not feasible to explore all combinations of different factors, we designed five tasks to reflect typical tasks in pixel-based visualization for supporting time-series analysis. We found noticeable performance variations between tasks, which likely reflect the different levels of perceptual loads. We then chose two tasks with the best and worst performance for detailed investigation in subsequent studies (studies 2 and 3). Performance was assessed by analyzing both accuracy and reaction time (RT). However, in Studies 1 and 3, RT results were collected as a secondary factor because participants were encouraged to focus on accuracy and were allowed to take as long as they wished to perform the tasks. These RT results are thus prone to a larger variance, and their evidential contribution should be treated with caution. The three studies are described in the following sections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">COLOR MAPS</head><p>In the choice of our color scales we followed the taxonomy provided in <ref type="bibr" target="#b1">[2]</ref> and the ColorBrewer guidelines <ref type="bibr" target="#b11">[12]</ref> (in particular for colorblind friendliness). To guarantee a consistent representation of the structure in the data we choose isomorphic colormaps. By design the generated stimuli mimic the output from a weather model computing the variation in relative temperature over a geographic region. The structure of this low spatial-frequency temperature variations over a region, and tasks, which required mental integration of the color-mapped values especially for resolution levels ≥ 1, made us choose low frequency colormaps therefore guaranteeing a uniform luminance and a monotonically increasing saturation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">USER STUDY 1</head><p>The purpose of this study was to assess accuracy in temperature related judgments as a function of block resolution and specific task demands.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Participants</head><p>Twenty four participants (9 female, 15 male) took part in this experiment in return for partial course credit or a £5 book voucher. Students were recruited from the Swansea University community, from a variety of disciplines including Psychology, Humanities, Engineering and Economics. Ages ranged from 18 to 46 (Mean=27.39, SD=5.97). All participants had normal or corrected to normal vision and were not informed about the purpose of the study at the beginning of the session. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Apparatus</head><p>Visual stimuli were created using custom software that was written in C++ in conjunction with Qt. Stimuli were saved as static images and presented to participants using a custom made interface. Experiments were run using Intel dual core PCs running at 2.13 GHz, with 2 GB of RAM and Windows XP Professional. The display was 19" LCD at 1280x1024 resolution with a 32bit sRGB color mode. Each monitor was adjusted to have same brightness and same level of contrasts. Participants interacted with the software using a standard mouse at a desk in a dimmed experimental room.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Stimuli</head><p>A total of 120 stimuli were used in this study, and they were organized as 5 groups for different tasks. The 24 stimuli were further divided into four levels, each with 6 stimuli. Each stimulus is a 6 × 12 image grid as shown in <ref type="figure">Fig. 4</ref>, and it corresponds to a unique temperature dataset. The datasets were designed to represent the temporal distribution of 12 monthly temperature samples from a fictional territorial area spread over a period of 6 years. Temperature datasets were created artificially, and mimicked, as far as possible, real temperature distributions taken from <ref type="bibr" target="#b21">[22]</ref>. Our artificial temperature range varied from -40 to +40 degrees. For each temperature value, a 400 × 400 PNG uniform pixel block was created (L0 block, see <ref type="figure" target="#fig_5">Fig. 5a</ref>). Colors were determined based on a white-to-red gradient mapping as shown in <ref type="figure" target="#fig_4">Fig. 3a</ref>. This mapping has proven to be colorblind friendly in accordance to the guidelines provided in <ref type="bibr" target="#b11">[12]</ref>. Color mapping was performed using a two step conversion process: first from a temperature value to a CIE L*u*v* value, and then from an L*u*v* value, via the CIE XYZ color space, to gamma-corrected sRGB value for display on sRGB calibrated screen. For this white-to-red CIE L*u*v* color space transformation we used standard correction formula as in <ref type="bibr" target="#b19">[20]</ref>. The value of the reference <ref type="figure">Fig. 4</ref>. User Study 1. User Interface Description.</p><p>white chosen for the present study was the maximum monitor white as in <ref type="bibr" target="#b33">[34]</ref>. From each L0 block, three higher resolution blocks at levels 1, 2, and 3 (L1, L2 and L3 blocks, see <ref type="figure" target="#fig_5">Fig. 5b</ref>-c-d) were created iteratively. These L1, L2 and L3 blocks were generated by using a quadtree, with the L0 block as the root. The nodes of each quadtree at level L &gt; 0 contained the pixel values for the block at resolution L, and these values were computed from values at level L − 1 using a midpoint displacement algorithm with roughness factor equal to 0.5. The background color was chosen to convey neutrality in relation to the color information within the grid quadrants.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.4">Tasks</head><p>Participants performed five main tasks each probing a specific aspect of the exploratory process typically conducted by scientists. <ref type="table" target="#tab_0">Table 1</ref> summarizes the main design attributes of the five tasks as outlined in Section 4. For each task, it lists the question asked, the unit of response (month/year), the nature of the task demands, the nature of the time series phenomena, the nature of the evaluation performed, the nature of the target response and the overall probability of a correct answer via random guess.</p><p>Task 1 involved visual search for a unique target, the hottest month, within the grid. Target months were designed to have at least a 15% magnitude difference from the next nearest distractor.</p><p>Task 2 involved estimating temperature changes between consecutive months, in order to locate the largest such increase across the whole display. Temperature increases always occurred from left to right. Target pairs were designed to have at least a 20% magnitude difference between each other, compared to 10% for the nearest distractor pair. In Tasks 1 and 2, users were asked to indicate their response by clicking with the mouse over the target month. The comparison in Task 2 is based on the evaluation of changes between two neighboring blocks. Such changes are not explicitly given, and we hence call such an attribute an implicit attribute. The participants have to carry out two levels of change evaluation, first between two neighbors in each pair, and then between changes taking place in different months and years.</p><p>Task 3 required participants to evaluate which year was the "hottest" on average. For this and the remaining 2 tasks, the selection of any month within a row resulted in the selection of the entire row/year. Both Tasks 4 and 5 required the participants to search for the year with a pattern of behavior not synchronized with the others. Task 4 involved detecting a difference in phase between the signal characterizing the target and all other years. Non-target years were created using sine or cosine functions with a uniform phase shift as their only differentiating feature. Target stimuli were created using functions with non-uniform or opposite phase shifts to the distractors.</p><p>Task 5 required users to detect and count temperature transitions within each year. Target years included at least 20% more transitions than the nearest distractor year. Transition periodicity was inserted into the data in the form of functions with different frequency. Target stimuli were designed to be high frequency sine or cosine functions while distractors followed a normal distribution. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.5">Procedure</head><p>The experiment began with a brief overview read by the experimenter using a predefined script. Detailed instructions were then given through a self-paced slide presentation. Brief descriptions of the requirements of each task were also provided (at each terminal). Each participant completed a total of 120 trials, separated into 5 blocks of 24 trials. The 5 tasks were always completed in sequential order, as we wanted to block month and year trials and to avoid confounding task difficulty with initial familiarization with the scenario. For a similar reason, we also controlled the presentation order of block resolution. Within a given task, all trials at level 0 were completed before moving on to level 1, then level 2 and finally level 3. Randomness was introduced at "year" level, rows were randomly swapped between each display to reduce the learning effect.</p><p>Specific instructions were given onscreen before each task and 12 practice trials were also completed. At the end of each task, participants took a short break. When all tasks had been completed each participant completed a short debriefing questionnaire and were provided with information about our experimental goals.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.6">Results</head><p>Performance in this experiment, as a function of task and block resolution level, is summarized in <ref type="figure" target="#fig_6">Fig. 6</ref>. There is clearly noticeable variation in performance across tasks, and the magnitude of this variation is more striking than we expected. As shown in <ref type="figure" target="#fig_6">Fig. 6a</ref>, peak accuracy performance is in Task 1, with 76% on average across all 4 levels, followed by 72% for Task 3, 65% for Task 5, 52% for Task 4, and conspicuously 39% for Task 4. Reaction time patterns <ref type="figure" target="#fig_6">(Fig: 6b)</ref> show a similar trend show a similar trend where Task 3 leads to fastest average responses, at 4.8 sec., followed by Task 1 at 6.2 sec., Task 5 at 6.5 sec., Task 4 at 11.2 sec. and Task 2 at 15.0 sec. The impact of block resolution appears to be less clear-cut, with the largest change in performance occurring in Task 1, where uniform patterns gave rise to an accuracy advantage of around 10% and a speed decrease of several seconds. Overall, the pattern of accuracy and reaction time data show no hint of a speed/accuracy tradeoff.</p><p>To explore these patterns in more detail a 5 (Task) × 4 (Level) repeated measures analysis of variance (ANOVA) was used to examine the accuracy and the reaction time data.</p><p>For accuracy data, there were main effects of both Task, F(4,92)=21.5, p &lt; 0.001, and Level, F(3,69)=5.2, p &lt; 0.001, and no interaction. To further examine the impact of Task, we computed pairwise comparisons of all means, using Bonferroni correction to adjust for multiple testing. This indicated that performance in both Task 2 and Task 4 were significantly lower than in the other three tasks (all ps &lt; .05) but were not statistically different from each other. No other comparisons were significant. To examine the effect of levels upon each task, we ran separate one-way repeated measures ANOVAs. In Task 1, there was a main effect of level, F(3,69)=9.5, p &lt; 0.001. Accuracy at level 0 is consistently better than those at levels 2 and 3, but the difference against Level 1 is not statistically significant. Level 1 stimuli also led to better accuracy than those at level 2, but not compared with Level 3. For the accuracy of other four tasks, there were no other reliable differences.</p><p>For reaction time data there were main effects of both Task, F(4,92)=29.6, p &lt; 0.001 and Level, F(3,69)=14.1, p &lt; 0.001, and no interaction. One-way ANOVAs showed a consistent main effect of level for Task 1, F(3,69)=10.6, p &lt; 0.001, with comparison of means indicating that responses to level 1 were slower than all other levels. Task 2 also showed a main effect of level, F(3,69)=3.3, p &lt; 0.05, which appears to be driven by rapid responses to level 3 stimuli (p=.05). The Task 4 main effect, F(3,69)=6.9, p &lt; 0.001, is driven by slow responses to level 0 stimuli, although this was only reliably different from level 2 responses. Finally, Task 5 responses were affected by level, F(3,69)=18.9, p &lt; 0.001, with levels 1 and 2 being slower than levels 3 and 4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.7">Discussion</head><p>The main purpose of Study 1 was to provide an initial assessment as to how the task performance is affected by the nature of tasks and the different levels of block resolution. From <ref type="figure" target="#fig_6">Fig. 6</ref>, we can observe the difference between different tasks, suggesting different perceptual load because of the task characteristics shown in <ref type="table" target="#tab_0">Table 1</ref>. Meanwhile, the cost associated with higher resolutions in all tasks was modest, never exceeding a 6% increase in errors. In general our users were able to extract monthly or yearly averages of (the increased) resolution.</p><p>Results showed a clear per task variation in performances, tasks that required searching for specific trends, either at the month or year level (Tasks 1, 3 and 5) were performed well, those that required processing of change or detection of seasonal variations across the display gave rise to high error rates.</p><p>The surprising finding in Study 1 was that the performance of Task 2, in both accuracy and reaction time, was very poor. We had not expected performance to drop below 40% correct, though this is still much higher than the chance of a random guess (1.5%). Note we cannot compare the perceptual load with tasks 3, 4 and 5 directly based on the results in <ref type="figure" target="#fig_6">Fig. 6</ref>, as they have a much higher chance of a correct answer via random guess (17%).</p><p>In addition to the empirical results, post-hoc discussions with the users also indicated that this task was particularly difficult. Although we had designed the target change to be at least 20% larger than the next nearest change in temperature, many users reported that locating the target change was extremely difficult, while others reported identifying multiple possible targets with no way to distinguish between them. Such large variation in performance highlights the relationship between task load and visual characteristics of a display. Therefore we chose Task 1 and Task 2 for further inspection as the two tasks with highest and lowest performance results. In the following studies, we tried to establish whether other aspects of the displays, such as the context or the color spaces, in addition to the change task itself, might be contributing to this pattern of results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">USER STUDY 2</head><p>In order to explore the source of the errors in Task 2 of the previous study, we made a number of design modifications aimed at increasing the diagnostic power of the experimental procedure. Specifically, we removed the search component of the task, focusing more directly on assessment of change, reduced the number of block resolutions levels from four to three, and sampled the color space in a more comprehensive manner. More details in these modifications are provided below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1">Participants</head><p>There were 21 participants recruited for this study (4 male and 17 female), each took part in this experiment in return for partial course credit or a £5 book voucher. Students were recruited from the Swansea University community, again from a variety of disciplines. Ages ranged from 18 to 39 (Mean=21.76, SD=4.18). Participants were randomly assigned to one of three experimental conditions, with 7 participants in each group. All participants had normal or corrected to normal vision and were not informed about the purpose of the study at the beginning of the session.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2">Apparatus and Stimuli</head><p>Visual stimuli were created using the custom software written in C++, with Qt as graphics library used in Study 1, which mapped a -40 to +40 temperature range into the appropriate color space (see details of each condition below). Stimuli were saved as static images and presented to participants via custom written MATLAB routines using Psychophysics Toolbox Version 3 (PTB-3) <ref type="bibr" target="#b4">[5]</ref>. Presentation was controlled using a Macintosh G5 computer running at 2.1 GHz, with 4 GB of RAM and OSX 10.4.2. The monitor was a color-calibrated 21" cinema display (visible area 41cm by 30cm) with a resolution of 1024 × 768 pixels and an effective refresh rate of 75 Hz. Participant responses were recorded via a standard keyboard at a desk in a dimmed experimental room.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.3">Task Design and Procedure</head><p>On each trial, users were presented with two pairs of images (one pair in the upper part and one pair in the lower part of the screen, see <ref type="figure" target="#fig_7">Fig. 7</ref>) representing the change in temperature between consecutive months. Users had to indicate which pair contained the greatest increase in temperature by pressing either "T" or "B" for top and bottom respectively.</p><p>The size of the target change was randomly selected to be either 12 or 16 degrees. The distractor change was randomly selected to be 4 or 8 degrees. Target pairs had an equal probability of occurring in the upper or lower part of the screen. Trials were organized into four categories, depending on the section of the temperature range that each pair originated from. These categories were labeled hot-hot (HH), cold-cold (CC), hot-cold (HC) and cold-hot (CH). The first member of each Hot pair was randomly selected to be within the range +2 and +12 degrees, and the first member of each Cold pair between -32 and -28 degrees. These constraints were designed to sample the mid regions of each temperature range while avoiding the end points. As before, the block resolution was varied. This time only 3 levels were used and were randomly intermixed rather than blocked. The order of trial presentation was randomly generated on a user-by-user basis.</p><p>Participants were assigned to one of three groups; Red-White RGB, Red-White CIE L*u*v* or Blue-White-Red sRGB. Each participant was presented with a total of 480 trials, presented in blocks of 60, following which the participants were given the option of a short break. In a change to the previous study, the resolution of the images was randomized, as was each of the four conditions (hot-hot, cold-cold, hot-cold, cold-hot), leading to a 3 (conditions) × 3 (block resolution level) × 4 (categories) repeated measures design. All other aspects of the procedure were the same as described in Section 6.5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.4">Condition 1: White-Red in CIE L*u*v*</head><p>The users in Condition 1 were shown stimuli that were generated using the same color mapping as in Study 1. Our purpose was to see whether the high error rates measure in Task 2 of Study 1 would be replicated, and whether our experimental modifications allowed us to more precisely locate the source of those errors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.4.1">Results</head><p>Performance in this experiment, as a function of color category and block resolution level, is summarized in <ref type="figure" target="#fig_8">Fig. 8a and Fig. 8b</ref>. When changes had to be evaluated in pairs from the same category, performance was consistently good, exceeding 75% correct and remaining below RTs of 2 seconds across all resolutions. In both the HH and CC categories, there appears to be a clear performance advantage, in both speed and accuracy, for level 0 representations. When changes across categories had to be evaluated, however, the story is very different. Users appear to have a strong bias to select the pair from the colder category, leading to much slower, chance-level performance in the HC category. Although performance appears to be excellent in the CH condition, it seems highly likely that this is an outcome of the general bias to favour the cold pair.</p><p>A 4 (pair color category) × 3 (block resolution level) repeated measures ANOVA was used to explore these patterns for both speed and accuracy.</p><p>For the accuracy data there were main effects of both Category, F(3,15)=40.6, p &lt; 0.001, and Level, F(2,10)=4.6, p &lt; 0.05, and no interaction. Comparison of means indicated that the HC category was significantly lower than all other categories (all ps &lt; 0.05, accuracy). No other comparisons were significant. Separate one-way ANOVAs were computed for each category to more fully explore the effect of level. This revealed that only the CC category has a reliable main effect of level, F(2,10)=15.6, p &lt; 0.001. This resulted from performance in level 0 being significantly greater than levels 1 and 2. The reaction time data showed main effects of both Category, F(3,15)=7.8 , p &lt; 0.01 and Level, F(2,10)=8.0, p &lt; 0.01 and no interaction. Comparison of means showed a significant decrease in performance only between HC and CC categories (p &lt; 0.02). No other comparisons were significant. Separate one-way ANOVAs revealed main effects of Level for both the HH, F(2,10)=8.0, p &lt; 0.01, and CC, F(2,10)=10.1, p &lt; 0.01 reflecting the rapid responses to level 0 stimuli.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.4.2">Discussion</head><p>Our goal was to try and localize the cause of the poor performance in evaluating changes during Task 2 of Study 1. The current results indicate errors arise when users need to explicitly compare the magnitude of changes in pairs from different sides of the temperature range. More specifically, there is a bias to judge changes in lower temperature pairs as being greater when compared to a higher temperature pair. If a similar bias were present in our previous study, this may have led users to miss-assign the target change, and even to identify multiple potential targets.</p><p>How can we explain this bias? It has been well established that physically equal steps in color space are not perceived as such <ref type="bibr" target="#b29">[30,</ref><ref type="bibr" target="#b33">34]</ref>. The visual systems response to certain color and luminance changes is not linear, but varies according to overall intensity <ref type="bibr" target="#b20">[21]</ref>. Psychophysical "laws" such as Weber's Law and Stephen's Law describe neatly how detection varies inversely with the overall intensity of a display.</p><p>The standard color mapping and correction we used to create our stimuli attempts to account for these perceptual effects, essentially by amplifying changes when intensity levels are high. That is, steps for each degree of temperature at the lower end of our range are physically larger than steps at the upper end. Theoretically, this should give rise to perceptually equalized steps in color space. Clearly, however, our users place more weight on the overall intensity differences than on the intended "perceptually uniform" color changes.</p><p>The effect of block resolution observed in this condition was again similar to that observed in Study 1. Block resolution did not appear to be the source of errors, a significant decrement in performance could be measured only between level 0 and other levels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.5">Condition 2: White-Red in sRGB</head><p>If the errors we have observed in the previous studies originate in our attempts to use a perceptually uniform color space, or at least in our users assigning more weight to intensity differences rather than perceived color changes, can we improve performance by using a physically linear color space? To test this idea, we generated a new set of stimuli using uncorrected sRGB values. In these stimuli, the physical difference in intensity from degree-to-degree is uniform across the whole temperature/color range. All other aspects of the experiment were identical to Condition 1, except data was collected from 7 new users.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.5.1">Results</head><p>Performance in this experiment, as a function of color category and block resolution level, is summarized in <ref type="figure" target="#fig_8">Fig. 8c and Fig. 8d</ref>. It is clear from the figure, that overall performance has not been improved by removing the CIE L*u*v* mapping, rather the location of the bias has shifted. Again, when pairs came from the same temperature range (HH and CC), performance was rapid and near to ceiling. Now though, the slow, error-prone responses have shifted to the CH category. This indicates that users in this condition have a strong bias to see changes in the warmer part of the range as larger.</p><p>The same 4 (pair category) × 3 (block resolution level) repeated measures ANOVA was again used to explore both accuracy and reaction time.</p><p>For accuracy, there were main effects of both Category, F(3,15)=62.4, p &lt; 0.001, and Level, F(2,10)=46.7, p &lt; 0.001. There was also a significant interaction between these factors, F(6,30)=7.6, p &lt; 0.001. This interaction would appear to arise due to the large increase in errors between levels in the CH category. To further explore the main effect of category, a comparison of all means was conducted. This indicated that performance in the CH category was significantly worse than in all other categories and that performance in the HC category was significantly better than both the CC and the CH conditions (all ps &lt; 0.05). A similar comparison for the main effect of level indicated that performance with level 0 stimuli was significantly better than with level 1 or 2 stimuli (ps &lt; 0.05). To further examine the interaction between Category and Level, separate one-way ANOVAs were conducted for each color category. This confirmed the presence of a level 0 advantage in accuracy, in all categories except HC (all Fs &gt; 6.0, ps &lt; 0.05).</p><p>For reaction time, there was only a main effect of Category, F(3,15)=24.4, p &lt; 0.001. Means comparison indicated that performance in the CH category was significantly slower than in any other category. There was a trend for level 0 responses to be faster, although this did not reach significance, p=0.09.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.5.2">Discussion</head><p>Rather than reducing the overall rate of errors, the physically uniform color space simply shifted them in a rather predictable manner. That is, the tendency of users to over-estimate the changes occurring at the hot end of our temperature range (i.e. when overall stimulus intensity is lower) is precisely the pattern of results that would be predicted based on the non-linear properties of the visual system. Simply ignoring these limitations, would not seem to be an option, at least given the current task. As in the previous condition, a small, but reliable cost of increasing block resolution was again present in this task between level 0 and other levels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.6">Condition 3: Blue-White-Red in sRGB</head><p>In the final condition of this study, we wanted to explore one simple option for reducing the errors seen in conditions 1 and 2. Our idea was to effectively compress the overall range of intensity values by using two color hues instead of one. We re-mapped temperatures lower than zero using a White-Blue scale and temperature above zero using a White-Red scale (see <ref type="figure" target="#fig_4">Fig. 3c</ref>). This re-mapping, together with the target selection method employed in the previous two studies, ensured that pairs across all four of our color categories were now much more closely matched in terms of overall intensity. Would this modification improve overall performance?</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.6.1">Results</head><p>The results from this manipulation are shown in <ref type="figure" target="#fig_8">Fig. 8e</ref> and <ref type="figure" target="#fig_8">Fig. 8f</ref>. It is immediately obvious that systematic errors have been reduced. Performance in all Categories and across the three levels remained close to ceiling levels. The same 4 (pair category) × 3 (block resolution level) repeated measures ANOVA used in the previous two experiments was applied to both speed and accuracy data. For accuracy there were no main effects, nor interactions. For the reaction time data, there were main effects of both Category, F(3,15)=3.4, p &lt; 0.05, and Level, F(2,10)=5.9, p &lt; 0.05, but no interaction. The Category effect would appear to reflect slightly faster responses for the within category decisions of HH and CC, although further analysis revealed no significant differences. The effect of Level was also limited to the HH, F(2,10)=4.5, p &lt; 0.05, and CC, F(2,10)=5.4, p &lt; 0.05 conditions. Although this pattern would seem to favor faster responses for level 0 stimuli, further analysis could not confirm this pattern.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.6.2">Discussion</head><p>Conditions 1 and 2 of this study demonstrated that user responses can sometimes be biased by properties of a color space other than those intended by a given task. It seems likely that performance in Task 2 of Study 1, were also caused by such factors. Although our tasks were aimed at detecting changes in color saturation, observers were highly sensitive to changes in intensity. The results of condition 3 suggest that one possible solution, at least in this specific task, would be to try and compress the range of intensity values, in our case, by introducing a second hue. No block resolution effect in this condition was reported even with near ceiling levels of performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">USER STUDY 3</head><p>In our final study, we examined more fully the influence of block resolution on the participants' performance. In Studies 1 and 2, there have been small but reliable advantages for the uniform patterns of level 0 versus other levels. In Study 1, this advantage was most apparent for the simple task of identifying the hottest month (i.e., Task 1). Here, we return to this particular task with a slightly modified procedure, to explore whether this advantage is truly robust. The same design framework described in Section 6 was adopted and interface, interaction and apparatus remained unchanged.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.1">Participants</head><p>Eleven participants (7 female, 4 male) took part in this experiment in return for partial course credit or a £5 book voucher. Students were recruited from the Swansea University community as in the previous studies. Ages ranged from 18 to 43 (Mean=27.9, SD=6.36). All participants had normal or corrected to normal vision and were not informed about the purpose of the study at the beginning of the session.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.2">Stimuli</head><p>Stimuli used in Test 1 were modified for this study. The changes are:</p><p>• We kept the three lower levels of resolution but removed the highest level (level 3), since it was found in Study 1 that there is no sufficiently noticeable difference between resolution levels 2 and 3. • We randomized the positions of pixel blocks at each level, rather than following a seasonal pattern, as in User Study 1, where the positions of pixels blocks were governed approximately by a cold-to-warm-to-cold annual cycle. • Stimuli were divided into 4 basic bands of the temperature range, labeled as Very Hot (VH, target chosen from the hot region extreme between 70% and 90% of gradient), Hot (HO, target chosen half way of hot region between 50% and 70% of gradient), Warm (WA, target chosen close to mid region between 30% and 50% of gradient), and Cold (CO, target chosen half way of cold region between 10% and 25% of gradient). We avoided to chose target/distractor from the extremes of the gradient to compensate the difficulty of detecting changes in these areas.</p><p>Same as for Study 1 the CIE L*U*V color space was used. Target months were still required to have at least a 15% magnitude difference from the distractors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.3">Procedure</head><p>The experiment followed the same overall procedure detailed in Section 6.5. For the purpose of this study though each participant was presented with a total of 288 trials, presented in blocks of 72, following which the participants were given the option of a short break. The order in which the four temperature bands were shown was also randomized. <ref type="figure" target="#fig_9">Fig. 9</ref> shows the performance summarized as a function of block resolution and temperature band. It is clear that the performance was extremely good, remaining above 90% in all conditions. There is not much noticeable difference in terms of mean accuracy, though a 4 (temperature band) × 3 (block resolution) repeated measures ANOVA revealed main effects of Level, F(2,20)=4.5, p &lt; 0.05, Band, F(3,30)=9.0, p &lt; 0.001, and their interaction, F(6,60)=4.8, p &lt; 0.001. Further analysis of the main effects revealed that the performance at level 0 (M=97%) was only marginally better than at either level 1 (M=97%; p=0.08) or level 2 (M=96%; p=0.08). The effect of temperature band related to the fact that the performance in the middle two bands were slightly better than at either the Very Hot or Cold extremes (ps &lt; 0.05). To explore the interaction, we ran separate oneway ANOVAs to examine the pattern of block resolution at each temperature band. This revealed that the only reliable difference occurred in the Cold temperature band, F(2, 20)=8.0, p &lt; 0.001, where level 0 performance was approximately 6% better than at levels 1 and 2. A similar trend was seen for the Hot temperature band, although this did not reach significance, F(2, 20)=2.9, p = 0.08. Reaction time analysis via 4 (temperature band) × 3 (block resolution) repeated measures ANOVA revealed main effects of Level, F(2,20)=3.7, p &lt; 0.001 (RT), Band, F(3,30)=46.4, p &lt; 0.001 no interaction was significant. Separate one-way ANOVAs to examine the pattern of block resolution at each temperature band revealed main effect of Level for all bands but a significant interaction only between level 0 and the other levels (p &lt; 0.001), with an increase of approximately 30%.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.4">Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.5">Discussion</head><p>The goal of this study was to explore in more detail the impact of resolution observed during Task 1 of Study 1. As part of this study, we also examine the impact of resolution in different color bands. The current results confirm that there may be a small cost when the resolution of pixel blocks increases. However, this effect is a marginal one in terms of mean accuracy. The presence of a level × temperature band interaction indicates that this impact is influenced by other factors. Specifically, our post-hoc analysis suggests that the effect of level is more observable in the lowest temperature band (CO) that maps to a white-to-pale red color band. The Reaction Time results also support this observation. This indicates that the effect of resolution may depend on the color band, or at least it may be more apparent in some color bands than others.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9">DISCUSSION SUMMARY</head><p>In this section, we consider the results of three user studies together, and provide our overall observations, each is accompanied by a summary of evidence and the suggested practical impact on the use of pixel-based visualization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9.1">The Effect of Resolution of Pixel Blocks</head><p>Observation. Block resolution has a limited impact on the effectiveness of pixel-based visualization, when visualization tasks focus primarily on block-level reasoning.</p><p>Evidence. In all three studies the effect of block resolution on accuracy was both numerically small (less than 10%) and restricted to sub-sets of the data. In Task 1 of Study 1, for example, the results show that it is generally statistically insignificant to differentiate the effect of different levels. Similar results can be found for the same category conditions of Study 2 and the cold temperature band of Study 3. There thus appears to be no general or consistent accuracy-cost for increasing block resolution. In Study 3 that focuses on Task 1, the observed effect of resolution is marginal in terms of mean accuracy. Reaction time slowing for increasing resolution was observed in some conditions, but again, this was relatively modest and not universal.</p><p>Practical Impact. This confirms that pixel-based visualization is a cost-effective, and to a large extent scalable, technique. Although the user studies involved only three or four levels of resolution, the studies have clearly indicated that the impact of levels upon accuracy is expected to be small. There is a noticeable impact on reaction time when changing from level 0 to other levels, but there is no suggestion that the trend of decreasing performance will continue along with the increasing resolution.</p><p>Limitation. We focused only on block level reasoning in our user studies, and did not experiment with the spatial reasoning within blocks (e.g., determine how two hottest pixels in different blocks are spatially related). Our finding about the lack of effect of levels should not be generalized to spatial reasoning. Further study is necessary to determine the effect of resolutions for such a task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9.2">The Effect of Difference in Tasks Demand</head><p>Observation. There are noticeable effects, depending on the task complexity and cognitive load to perform the task. The order of task difficulty can be expressed as (i) Task 1 &lt; Task 2 and (ii) Task 1 &lt; (Task 3, Task 5) &lt; Task 4.</p><p>Evidence. User study 1 confirms that the performance of Task 2 and Task 4 are significantly worse than other tasks in terms of both accuracy and reaction time.</p><p>The results in Section 6.6 confirm both (i) and (ii). It is not conclusive when comparing Task 2 with Tasks 3, 4 and 5 due to the significant difference in the chance of a correct answer by random guess. Meanwhile, taking the chance into account, Task 1 is much easier than Tasks 3, 4, and 5.</p><p>Practical Impact. Pixel-based visualization is effective for some tasks but not always effective for others. Some tasks can be performed poorly, with a below average accuracy. The poor performance is likely related to the difficulties in quantifying, comparing, and reasoning with changes of pixel blocks. As a guideline, it is recommended that users should be made aware of the possibility of poor accuracy when performing some tasks using pixel-based visualization. As a discipline, we need to develop new visualization techniques to address such difficulties.</p><p>Limitation. We have not precisely established the reasons for the poor performance in some tasks. Further study is necessary, especially with a focus on the cognitive load of different tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9.3">The Effect of Color Mapping</head><p>Observation. In pixel-based visualization, the choice of color space affects the task performance. The CIE L*u*v* color space is not as perceptually uniform as stated in the literature. The White-Red colormap in CIE L*u*v* has no clear advantage over that in RGB color space. In pixel-based visualization, using two or more color gradient bands does improve the performance in accuracy, but there is no evidence to suggest any improvement in reaction time.</p><p>Evidence. User study 2 confirms these findings. Similar findings on using two color gradient bands were reported previously <ref type="bibr" target="#b33">[34]</ref>.</p><p>Practical Impact. Qualifying changes in any color space is an error-prone task, and should be exercised with caution. For a large data value range coupled with a need for evaluating relatively small changes, multiple color gradient bands can improve the detection of just noticeable difference (jnd) as well as the comparison between changes taking place at different data ranges, provided that in each band the color distance increases significantly between every two neighboring data values.</p><p>Limitation. User study 2 only examined Blue-White-Red color map. It is not appropriate to generalize this finding to many bands. In this study, we considered that the white color was the middle point of zero degree, which is the middle point of the data value range as well. Further study is necessary to understand of the effectiveness of multi-color gradient bands for a data value range without semantically meaningful breaking points or with irregularly-spaced breaking points.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="10">CONCLUSIONS AND FUTURE WORK</head><p>In this work we conducted three user studies on aspects of pixel-based visualization, resulting in a quantitative analysis of task and block variations in using such a technique. Our results are most relevant to the users and developers of pixel-based visualization systems, particularly those working with time series analysis (see Section 3).</p><p>Based on the four levels examined, we can conclude that pixelbased visualizations do not suffer from noticeable impact due to resolution variation. The perceptual load associated with different tasks can impact upon the performance of the users in a more noticeable manner. For example, Task 2, which reflects a simple day-to-day visualization task in many applications, exhibited a high perceptual load, resulting in poor performance. Study 2 also showed that common judgements, such as estimating change, sometimes interact in unexpected ways with particular display characteristic.</p><p>This suggests that users should be provided with careful guidance as to the nature of the errors that could potential be encountered in a specific tasks. Based on the results obtained in this work, we have been discussing our findings with remote sensing researchers. We also hope to further explore our findings as to how the appropriate selection of colormaps can alleviate task problems in more complex practical situations. We also believe that the current empirical work makes a useful first step towards understanding some of the factors that affect the usability of hierarchical pixel-based visualizations.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>(a) 2006 to date month-year calendar heatmap (b) September 2009 heatmap (c) October 2009 heatmapFig. 1. (a) A heatmap of Microsoft's stock price adjust close from 2006 to date (data source: Yahoo), generated with R [9] and plotted using Paul Bleicher's calendarHeat function. (b-c) Comparative visualization of two financial heatmaps depicting the secondary market statistics of the London Stock Exchange (courtesy of [7]).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>Fig. 1b-c show a pixel-based visualization depicting the monthly percentages of changes of the 8 indices of the London Stock Exchange between September 2009 and November 2009, for 43 different sectors. The 8 indices are normally grouped into a block, and blocks are organized into year-month matrices. In comparison with</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 2 .</head><label>2</label><figDesc>(a) A pixel-based bioinformatic visualization, with its spatial layout controlled by two trees; (b) Landsat image of Greenland glacier outlet Geiki.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 3 .</head><label>3</label><figDesc>The three color sequences used in experiments 1, 2 and 3.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 5 .</head><label>5</label><figDesc>Stimuli samples at 4 different levels of resolution.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 6 .</head><label>6</label><figDesc>User Study 1. Overall accuracy and reaction time for the four levels per task. Error bars show standard error.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 7 .</head><label>7</label><figDesc>User Study 2. Examples of stimuli pairs seen on each trial for the four categories in both white-red (a-d) and blue-white-red (e-h) conditions.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 8 .</head><label>8</label><figDesc>(a) WR, CIE L*u*v*, accuracy (b) WR, CIE L*u*v*, reaction time (c) WR, sRGB, accuracy (d) BR, sRGB, reaction time (e) BWR, sRGB, accuracy (f) BWR, sRGB, reaction time User Study 2. Overall accuracy and reaction time for the 3 levels × 4 conditions of each color space. Three color spaces are White-Red in CIE L*u*v*, White-Red in sRGB, and Blue-White-Red in sRGB. Error bars show standard error.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig. 9 .</head><label>9</label><figDesc>User Study 3. Overall accuracy and reaction time for the 3 levels of resolutions × 4 temperature bands (COld, WArm, HOt, Very Hot). Error bars show standard error.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>User Study 1. Tasks description and relative complexity.</figDesc><table><row><cell cols="2">Task Question</cell><cell>Unit</cell><cell>Task Goals</cell><cell>Data Focuses</cell><cell>Type of Change</cell><cell cols="2">Block Hierarchy Chance</cell></row><row><cell>1</cell><cell>Which month is the hottest?</cell><cell>Month</cell><cell>difference, peak</cell><cell>amplitude</cell><cell>attribute</cell><cell>primitive</cell><cell>1/72</cell></row><row><cell>2</cell><cell>Which month is followed by a sudden change in temperature?</cell><cell>Month</cell><cell>difference, trend</cell><cell>amplitude</cell><cell>implicit attribute</cell><cell>primitive</cell><cell>1/66</cell></row><row><cell>3</cell><cell>Which year is the hottest on average?</cell><cell>Year</cell><cell>difference, peak</cell><cell>amplitude</cell><cell>attribute</cell><cell>composite</cell><cell>1/6</cell></row><row><cell>4</cell><cell>Which year has an irregular pattern?</cell><cell>Year</cell><cell>irregular fluctuations</cell><cell>phase shift</cell><cell>existence, layout</cell><cell>composite</cell><cell>1/6</cell></row><row><cell>5</cell><cell>Which year has most frequent changes between hot and cold months?</cell><cell>Year</cell><cell>distribution, seasonality</cell><cell>frequency</cell><cell>existence, layout</cell><cell>composite</cell><cell>1/6</cell></row></table><note></note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Identification of spatially quantized tachistoscopic images of faces: How many pixels does it take to carry identity?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Bachmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">European Journal of Cognitive Psychology</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="85" to="103" />
			<date type="published" when="1991" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A rule-based tool for assisting colormap selection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">D</forename><surname>Bergman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">E</forename><surname>Rogowitz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">A</forename><surname>Treinish</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">VIS &apos;95: Proceedings of the 6th conference on Visualization &apos;95</title>
		<meeting><address><addrLine>Washington, DC, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="1995" />
			<biblScope unit="page">118</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Searching for objects in real-world scenes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Biederman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">L</forename><surname>Glass</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">W J</forename><surname>Stacy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology</title>
		<imprint>
			<biblScope unit="volume">97</biblScope>
			<biblScope unit="page" from="22" to="27" />
			<date type="published" when="1973" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Gene expression profile of adult t-cell acute lymphocytic leukemia identifies distinct subsets of patients with different response to therapy and survival</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chiaretti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Gentleman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vitale</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Vignetti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Mandelli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ritz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">R</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Blood</title>
		<imprint>
			<biblScope unit="issue">103</biblScope>
			<biblScope unit="page" from="2771" to="2778" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Top-down attentional guidance based on implicit learning of visual covariation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Chun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Jiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychologicl Science</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="360" to="365" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">From visual data exploration to visual data mining: A survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">C F</forename><surname>De Oliveira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Levkowitz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="378" to="394" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">S</forename><surname>Exchange</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Relations between the statistics of natural images and the response profiles of cortical cells</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Field</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Optical Society of America</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="2379" to="2394" />
			<date type="published" when="1987" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">The r project for statistical computing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Gentleman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ihaka</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Multi-resolution techniques for visual exploration of large time-series data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">C</forename><surname>Hao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Dayal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename><surname>Keim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Schreck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EuroVis</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="27" to="34" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Masking in visual recognition: Effects of two-dimensional filtered noise</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">D</forename><surname>Harmon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Julesz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">science</title>
		<imprint>
			<biblScope unit="volume">180</biblScope>
			<biblScope unit="page">1194</biblScope>
			<date type="published" when="1973" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Colorbrewer.org: An online tool for selecting colour schemes for maps</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Harrower</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">A</forename><surname>Brewer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cartographic Journal</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="27" to="37" />
			<date type="published" when="2003-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Putting objects in perspective</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">E</forename><surname>Hoiem</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Comp. Vis. Pattern Recog</title>
		<meeting>IEEE Comp. Vis. Pattern Recog</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="2137" to="2144" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Interactive visual analysis of time-series microarray data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">H</forename><surname>Jeong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Darvish</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Najarian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Ribarsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Vis. Comput</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="1053" to="1066" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Designing pixel-oriented visualization techniques: Theory and applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename><surname>Keim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="59" to="78" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Visualization techniques for mining large databases: A comparison</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename><surname>Keim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H.-P</forename><surname>Kriegel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Knowl. and Data Eng</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="923" to="938" />
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Pixelmaps: A new visual data mining approach for analyzing large spatial data sets. Data Mining</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename><surname>Keim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Panse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sips</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">C</forename><surname>North</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE</title>
		<imprint>
			<biblScope unit="page">565</biblScope>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Pixel based visual mining of geo-spatial data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename><surname>Keim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Panse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sips</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">C</forename><surname>North</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computers and Graphics</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="327" to="344" />
			<date type="published" when="2004-09" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Hierarchical temporal patterns and interactive aggregated views for pixel-based visualizations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Lammarsch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Aigner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bertone</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gartner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Mayr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Miksch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Smuc</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IV &apos;09: Proceedings of the 2009 13th International Conference Information Visualisation</title>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="44" to="50" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Cie standard color equations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Lindbloom</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Frequency of seeing functions for intensity discrimination at various levels of adapting intensity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">G</forename><surname>Mueller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of General Physiology</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="463" to="474" />
			<date type="published" when="1951" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><forename type="middle">D</forename><surname>Energy</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010" />
			<publisher>DOE)</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">The role of context in object recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Oliva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Torralba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Trends in Cognitive Sciences</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="520" to="527" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Cognitive load theory: Instructional implications of the interaction between information structures and cognitive architecture</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Paas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Renkl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sweller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Instructional Science</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="1" to="8" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Visual search for change: A probe into the nature of attentional processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">A</forename><surname>Rensink</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Visual Cognition</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="345" to="376" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Change detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">A</forename><surname>Rensink</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Annual Review of Psychology</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="page" from="245" to="277" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">An automated approach for the optimization of pixel-based visualizations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schneidewind</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sips</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename><surname>Keim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Visualization</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="75" to="88" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Coordinated views to assist exploration of spatio-temporal data: A case study</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">H</forename><surname>Shimabukuro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">F</forename><surname>Flores</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">C F</forename><surname>De Oliveira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Levkowitz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CMV &apos;04: Proceedings of the Second International Conference on Coordinated &amp; Multiple Views in Exploratory Visualization</title>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2004" />
			<biblScope unit="page" from="107" to="117" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Channel surfing in the visual brain</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">T</forename><surname>Sowden</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Schyns</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Trends in Cognitive Sciences</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="538" to="545" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Psychophysics of sensory function. Sensory Communication</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">S</forename><surname>Stevens</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1961" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">How many pixels make an image?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Torralba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE</title>
		<meeting>the IEEE</meeting>
		<imprint>
			<date type="published" when="1948" />
			<biblScope unit="volume">94</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Statistics of natural images categories</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Torralba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Oliva</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Network Comput. Neural Syst</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="391" to="412" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Detecting faces in impoverished images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Torralba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Sinha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CBCL Memo</title>
		<imprint>
			<biblScope unit="volume">208</biblScope>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
	<note type="report_type">Technical report</note>
	<note>In AI Memo 2001-028</note>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Color sequences for univariate maps: Theory, experiments and principles</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Ware</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer Graphics and Applications</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="41" to="49" />
			<date type="published" when="1988" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Spatial-frequency tuning of orientation selective units estimated by oblique masking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">R</forename><surname>Wilson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">K</forename><surname>Mcfarlane</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">C</forename><surname>Phillips</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Vision Research</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="873" to="882" />
			<date type="published" when="1983" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">What attributes guide the deployment of visual attention and how do they do it?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wolfe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Horowitz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature Reviews Neuroscience</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="1" to="7" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Beyond visual acuity: the perceptual scalability of information visualizations for large displays</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Yost</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Haciahmetoglu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>North</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CHI &apos;07: Proceedings of the SIGCHI conference on Human factors in computing systems</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2007" />
			<biblScope unit="page" from="101" to="110" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Visual analytics on the financial market: Pixel-based analysis and comparison of long-term investments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ziegler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Nietzschmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename><surname>Keim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Information Visualisation, International Conference on</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="volume">0</biblScope>
			<biblScope unit="page" from="287" to="295" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
