<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/pisenberg/grobid/grobid-0.6.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">SignalLens: Focus+Context Applied to Electronic Time Series</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Kincaid</surname></persName>
						</author>
						<title level="a" type="main">SignalLens: Focus+Context Applied to Electronic Time Series</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2021-02-19T18:59+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Focus+Context</term>
					<term>Lens</term>
					<term>Test and Measurement</term>
					<term>Electronic Signal</term>
					<term>Signal Processing</term>
				</keywords>
			</textClass>
			<abstract>
				<p>Figure 1. SignalLens view of an amplitude modulated electronic signal. The lens area exposes an anomalous glitch in the otherwise uniform oscillations. The tracks below the signal depict the location of filtered measurements and indicate a periodicity to the occurrences of similar glitches. See Section 5.1 for more details.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Modern electronic devices increasingly depend on complex systems of high-speed interconnected components. These systems require sophisticated test and measurement platforms (oscilloscopes, logic analyzers, spectrum analyzers, etc.) to aid in the design as well as debugging of such systems. Modern electronic designs often leverage features such as increased clock rates, high speed serial data interconnects and multi-core CPUs and GPUs. These trends push the limits of current measurement technology. One response is to provide increasingly larger storage capacity for test and measurement devices. This increased capacity enables longer signal traces to be captured and subsequently analyzed for behaviour over longer time periods. High-end devices now typically record up to a billion or more data points per trace. However, due partly to the necessity of convenient portability for such devices and partly for historical and traditional reasons, screen sizes have remained relatively small. For example a typical large oscilloscope display is on the order of only 1024x768 pixels, which includes both the signal trace and the UI elements for control of the device. Based on these observations, we realized there was a critical need to better manage the visual display of very large signal traces that would enable a compact representation of the entire context of the trace as well as inspection of low-level details of interest.</p><p>To explore these issues we developed SignalLens, a research prototype for the visual analysis of large electronic time series. We use a Focus+Context approach to display the entire time series with simultaneous inspection of low-level signal details via a lens distortion in the region of interest. Unlike typical two-dimensional Focus+Context lens implementations, we are only interested in distorting the very long and visually problematic time axis.</p><p>Any attempt to display large data sets with a small set of pixels requires data overlay or pixel merging, which leads to loss of potentially important visual details. Recognizing this fact we also introduced a flexible ad hoc scheme for computing time-aligned properties of the signal and presenting the results as an aligned track below the original signal. These computed tracks can be further combined and/or filtered to reveal specific low-level features of the signal that might otherwise be hard to visualize on the small screen. These computed and filtered properties can be viewed in the context of the entire signal trace and used for navigating the lens to regions of potential interest. We will demonstrate that combining these tracks with the full trace and Focus+Context approach yields an effective means to quickly isolate and visually analyze subtle signal features within the constraints of typical instrument displays. This paper describes the following contributions:</p><p>A high-magnification lens-based visualization for viewing large electronic time series.</p><p>Extension of the signal context via computed measurement tracks to aid feature finding and navigation.</p><p>Demonstration of the design by analyzing real electronic signals.</p><p>Observations on benefits and limitations of a lens-based approach for viewing such time series.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">PROBLEM DESCRIPTION</head><p>The specific problem we are trying to address is to design a compact visualization that provides both global context and local details for long duration signal traces. In addition to the specific analysis tasks we wish to support, we must also consider aspects of the underlying data characteristics as well as the target users of the prototype solution.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Target Users</head><p>During the early information gathering phase of this project we noted an interesting characteristic of our target users. Most of the visual interaction between user and instrument is based on ad hoc real-time visualizations of live electronic signals. The typical strategy is to manipulate the visualization (e.g. an oscilloscope trace) to reveal salient features in the signal. As such, electronic test and measurement can be viewed as a largely dynamic ad hoc information visualization task with the same requirements for a high degree of interactivity and the same dependency on leveraging pre-attentive human visual perception to detect relevant patterns, trends and outliers in the data. These users are also highly visually oriented in their analysis tasks and therefore (in our opinion) likely to accept information visualization approaches. We note that this target audience is largely untapped by the information visualization community and represents a valuable domain for further information visualization research. Paradoxically, at the same time most test equipment as well as users are extremely tied to legacy designs and paradigms, even when they are no longer physically required. For example, modern digital oscilloscopes still maintain displays that mimic the fixed etched reticules found on cathode-ray displays used in early oscilloscopes as well as their physical knob-based controls. This observation leads to the added requirement that whatever solution we provide must try to be minimally disruptive to the pervasive culture and expectation of our users. So while we believe users of test and measurement equipment would be receptive to information visualization approaches, designs must be sensitive to the domain and its historical prejudices.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Data</head><p>Modern test and measurement systems generally sample voltages at extremely precise fixed intervals. For example, high-end oscilloscopes have sample rates as high as 40GHz or more, but this sample interval can be adjusted lower depending on the source being analyzed. At high sample rates, even a Gigapoint trace (10 9 points) may only involve a small fraction of a second. Such traces can be thought of as simply time series data. The form in which such data is usually represented on the measurement device can be thought of as viewing a small portion of a much larger smoothed or interpolated line graph of the voltage over time. Navigation is typically accomplished with zoom-and-pan techniques. Aigner et al. <ref type="bibr" target="#b0">[1]</ref> explored taxonomies for time series data and visualizations. Using their terminology the temporal primitive consists of equally spaced time points and the time structure is linear. The data measured is abstract and univariate (usually voltage).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Target Analysis Tasks</head><p>There are a multitude of analysis tasks performed by electrical engineers testing and debugging electronic circuits. It is beyond the scope of this paper to discuss all of these in detail. However, the goal of SignalLens is to address the specific issue of analyzing very large signal traces. Thus, we focused our attention primarily on finding specific signal features or anomalies buried within the complexity of a large sample. This task is generally a hard problem to solve with existing instrument software, and not easily subject to standard ad hoc techniques. We can break this down into two main tasks: Anomaly Detection: which may consist of simple, obvious outliers or more subtle cases of "a pattern surprising if the frequency of its occurrence differs substantially from that expected by chance" (Keogh et al. <ref type="bibr" target="#b12">[13]</ref>). In many cases, extreme outliers may be detectable visually. More subtle cases often require computational and/or statistical approaches.</p><p>Motif Discovery: which involves searching a time series for a specific time-dependent pattern (Lin et al. <ref type="bibr" target="#b19">[20]</ref>). Typically, the search will begin with a specific pattern of interest. In the case of electronic signals this pattern or waveform may have been initially found during a preceding anomaly detection task.</p><p>These signal processing tasks are generally based on computing appropriate signal measurements and filtering by ad hoc criteria. Existing instruments typically require the tedious use of pan-andzoom interfaces to navigate to these measurements of interest. Instrument analysis software does not typically support visualizing multiple measurements and the signal in a global context while at the same time viewing low level signal details.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">RELATED WORK</head><p>In designing SignalLens we leveraged several key topics from information visualization research:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Context-based Visualization Systems</head><p>There exists a well known body of research in context-based visualization frameworks. Two common approaches are Overview+Detail (O+D) <ref type="bibr" target="#b24">[25]</ref> and Focus+Context (F+C) <ref type="bibr" target="#b6">[7]</ref>. Each approach attempts to provide a contextual overview simultaneously with a detailed view for inspecting details of interest. Several user studies have provided evidence that providing an overall context along with details of interest provides a more effective analytical framework. Whether O+D is more effective than F+C (or vice versa) is an area of some ambiguity in the current literature and may be somewhat task specific <ref type="bibr" target="#b4">[5]</ref>. For example, Gutwin and Skopik <ref type="bibr" target="#b10">[11]</ref> found distortion lenses best for steering tasks while Pietriga et al. <ref type="bibr" target="#b23">[24]</ref> found zoomable O+D interfaces more efficient for multi-scale search tasks. Evidence generally seems to indicate that for many tasks both are similarly effective with slightly different tradeoffs. Cockburn et al. <ref type="bibr" target="#b4">[5]</ref> provide a recent review of this topic including a discussion of relevant user studies. However, the high magnifications we will typically require for electronic signals make Overview+Detail somewhat problematic. For useful navigation beyond 100X, one or more intermediate views are likely to be required <ref type="bibr" target="#b24">[25]</ref>. For example, assuming the user could accurately select a single pixel on an overview trace of 10 6 points on a display 10 3 pixels wide, the selection of a single pixel would correspond to a range on the order of 10 3 points. Scaling to larger time series the problem becomes even more problematic. This inability to select precise ranges in the overview makes navigation with high magnification difficult in a scenario consisting of an overview and a single detail view. Further, any selection indicators in the overview will be of such a tiny size (~1 pixel wide) that they become difficult to select and manipulate easily. In contrast, while the initial context selection is still problematic in our Focus+Context design, we will demonstrate examples where the lens actually facilitates rapid navigation to the region of interest.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Lens Frameworks</head><p>A distortion lens is a frequent design pattern in Focus+Context implementations and traces its origins to Furnas' Fisheye Views <ref type="bibr" target="#b5">[6]</ref>. Several approaches to lens construction have been described <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b18">19]</ref>. In this work we follow the mathematical formalism for lens distortions provided by Carpendale and Montagnese's Elastic Presentation Space <ref type="bibr" target="#b2">[3]</ref>. This framework provides for a variety of lens shapes. A further discussion of how this framework is used within SignalLens is described in more detail in section 4.1. Carpendale et al. have also studied the issues associated with high magnification <ref type="bibr" target="#b3">[4]</ref> and those findings are also leveraged in this work.</p><p>Recently Pietriga and Appert have published work on Sigma Lenses <ref type="bibr" target="#b22">[23]</ref> based in part on earlier work by Gutwin <ref type="bibr" target="#b9">[10]</ref>. Sigma Lenses replace standard optical distortions with dynamic translucence to transition between focus and context areas. While for some use cases Sigma Lenses have been shown to be more effective than traditional lens implementations, they have not been tested under conditions of extreme magnification. Further, Sigma Lenses go beyond the simple mental metaphor of an optical magnification lens. Since we desired to keep our implementation intuitive and as close to a standard instrument display as possible (for the reasons described in Section 2.1) we chose a more traditional distortionbased implementation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Time Series Visualizations and Analytics</head><p>A large body of work exists for visual analysis of time series. Aigner et al. <ref type="bibr" target="#b0">[1]</ref> take a systematic view of the field and provide a framework for categorizing various approaches. LiveRAC <ref type="bibr" target="#b21">[22]</ref> provides semantic zooming of a reorderable matrix of system management time series. Time-series bitmaps <ref type="bibr" target="#b16">[17]</ref> uses a bitmap encoding to efficiently represent a large collection of time series. Line Graph Explorer <ref type="bibr" target="#b15">[16]</ref> supported visual analysis of large collections of time series, but was not designed to support very large time series.</p><p>TimeSearcher <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b11">12]</ref> uses an Overview+Detail approach for querying and visualizing features in time series data. TimeSearcher is perhaps most relevant, since it works directly with line graphs of time series data and provides facilities for pattern matching similarly shaped motifs. However, it is primarily designed toward motif searching versus a general purpose signal analysis tool. Also as mentioned previously, our screen and magnification requirements make Overview+Detail a poor choice for our design.</p><p>Lopez-Hernandez et al. <ref type="bibr" target="#b20">[21]</ref> recently extended oscilloscope eye diagrams using an interactive 2.5D layer-based technique.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">DESIGN</head><p>The dominant feature of SignalLens is obviously the signal trace, which consists of a relatively straightforward two-dimensional line chart of the signal. No lens distortion is apparent until the user clicks the mouse at a region of interest. Our choice to take a Focus+Context approach is driven primarily by issues of limited screen real estate combined with the requirement for high magnification. For prototyping purposes SignalLens was developed as a standalone application. However, our intent was to design an effective visualization that could function embedded within the constrained dimensions of an instrument display.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Lens</head><p>Our lens design follows the distance-based model described in Carpendale and Montagnese's framework for Elastic Presentation Space (EPS) <ref type="bibr" target="#b2">[3]</ref>. Due to the high magnification typically required, we also leverage further work by Carpendale et al. that is specifically related to high magnification <ref type="bibr" target="#b3">[4]</ref>. Readers should refer to these references and related EPS work for complete details on computing lens distortions. We review briefly the features of this framework that are relevant to our discussion of SignalLens. </p><p>To enable continuously variable magnification between the region of interest and the unmagnified context area, we allow h to be a variable function dependent on the distance away from the region of interest. This height function is also sometimes called a "drop off" function. Further, we define our height functions based on a standard lens radius of 1. This simplifies the computations and the resulting displacements can simply be multiplied by the lens radius to get the final displacement.</p><p>SignalLens implements a variety of lens functions for comparison (linear, cubic, quadratic, hyperbolic, spherical and Gaussian). As was found previously <ref type="bibr" target="#b3">[4]</ref>, high magnification generally requires "concave" drop-off functions to avoid occlusion. For the signal traces we have analyzed we have found the quadratic height function (for a unit radius): <ref type="bibr" target="#b1">(2)</ref> to be the most practical since it gives a useful distortion field and the transition to the context area seems relatively natural. It is this lens shape that we use for all figures presented in this paper.</p><p>A focus area of fixed magnification is provided in the center of the lens corresponding to the region of interest. We found this design advantageous for accurately interpreting signal details as any lens distortion also distorts the signal shape, making accurate analytical comparisons or interpretation difficult. As a further aid we allow an optional grid or reticule to be displayed, so that the user can clearly see the boundary where the non-linear distortion begins. Another optional bounding box is provided to indicate the full extent of the lens. This feature is often useful in training or initial usage, but once users become familiar with the lens concept they generally turn this feature off. We also restrict the focus area to a fixed percentage of the plot size as this restriction was previously found to effectively avoid visual occlusion at the transition between the focus and dropoff areas when using high magnification <ref type="bibr" target="#b3">[4]</ref>.</p><p>Settings are also provided for the magnification level, the size of the lens (as a percentage of the full signal trace) and the lens shape (by selecting the corresponding drop-off function). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>4.2</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Measurement Tracks</head><p>For large data sets the visual density of the display can obscure fine details and make it difficult to find interesting visual features. To address this problem we chose to use computational assistance in finding features of interest. The user can choose from an extensible list of time-aligned computations based on the original signal. Following the terminology used with test and measurement instruments we refer to these computations as "measurements" and thus we are creating "measurement tracks". In effect we are making post-acquisition measurements of the already acquired signal. Such measurements are common features of devices such as oscilloscopes and logic analyzers, so our measurement tracks also provide a mechanism for incorporating these computations into the Focus+Context design.</p><p>Tracks can be filtered with the dynamic query sliders shown in <ref type="figure" target="#fig_3">Figure 3D</ref>. The two black "carets" can be dragged independently with the mouse to set minimum and maximum values. This setting specifies the range of data being included by the filter and is indicated by the green coloring between the carets. The red regions are values excluded by the filter. Additionally, the user can type the values directly into the flanking text boxes. Text entry facilitates entering exact values that would be tedious to select via mouse drag. Alternatively the user can click the histogram button ( <ref type="figure" target="#fig_3">Figure 3F</ref>) to invoke a separate histogram window as shown in <ref type="figure" target="#fig_6">Figure 5E</ref>. As the user zooms or pans the histogram, the visible region of the time axis is used to filter the display and only those time points with measurement values passing the user-set filter are displayed.</p><p>Color is used to distinguish between tracks enabling the user to visually connect the track with the similarly colored query slider. We originally tried to encode the measurement value in a manner similar to Line Graph Explorer <ref type="bibr" target="#b15">[16]</ref> by mapping a color gradient to represent the measurement value. However, the density of the resulting data was such that this method was seldom of any analytic value. The brightness and frequency of large values tended to overwhelm and dominate the unmagnified display while smaller values, even when filtered suffered from visibility issues. We chose instead to not encode the measurement value and merely use the tracks as binary markers indicating where there are filter-passing values. In practice this implementation seems a simpler and more tractable approach, since the task is generally one of trying to isolate a relatively small number of outlier features via filtering, and navigate to those, versus an attempt to view the entire population of measurement values.</p><p>This paper is primarily concerned with the visualization and interaction design of SignalLens and a full description of all measurement algorithms is beyond the scope of this paper. Briefly summarized, the currently supported measurements include:</p><p>Savitsky-Golay filtering <ref type="bibr" target="#b25">[26]</ref> to produce smoothed 1 st or 2 nd derivatives of the signal.</p><p>A simple signal motif finder based on computing a Pearson correlation between a target waveform and each matching window of the signal <ref type="bibr" target="#b14">[15]</ref>.</p><p>Rise time and fall time (duration of leading and trailing edges of pulsed signals).</p><p>Measurements based on other measurements are also supported such as:</p><p>Logical and/or between tracks. This operation takes two tracks and generates a third based on the union (or) or intersection (and) of measurements with corresponding time intervals.</p><p>Distance between measurements in a single track. For example, we can compute the distance between the occurrences of motif matches.</p><p>Distance between measurements in two tracks. For example one can compute rise time in one track, fall time in a second and pulse width in a third track by computing the distance between rise time and fall time of the previous two tracks.</p><p>The intent is to provide a limited set of basic operations (e.g. rise time/fall time) and produce more complex measurements (e.g. pulse width) as combinations of these basic primitives.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Additional Features</head><p>The "goto" button allows quick navigation to a specific time point and the "clr" button merely clears the display to the state when the data was first opened, thus closing the lens. The user can also select to "animate" navigation. In this case any operation that navigates to a new time point will be animated from the old time point to the new one. We observed that for dense signal plots with very repetitive signal pulses there were minimal visual cues that navigation was taking place. However, by animating intermediate steps through the time dimension, one can see the cursor actually moving in time and the movement forward or backward is much more apparent and natural to the user. A scratchpad area ( <ref type="figure" target="#fig_3">Figure 3G</ref>) allows the user to save and/or overlay the contents of the focus area for later reference or comparison.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Evaluation by Experts</head><p>While no formal user studies have yet been performed, there have been a number of informal as well as formal reviews of the working prototype by experts in test and measurement devices. These reviews included instrument hardware as well as instrument software designers and also field engineers directly supporting users of test and measurement instruments. Experts were also provided access to the software for their own trials. The response from these interactions was generally positive. Review of the first prototype raised several issues which led to further refinement of the prototype. These subsequent design modifications were subject to further expert review. Two key issues raised were: There was generally an initial aversion to distorting the time axis due to a cultural bias that viewed the visual time increment as inviolate. This finding led us to implement the fixed magnification focus area which makes the focus area seem more consistent with previous user expectation, even though the drop-off areas still maintain distortion. The lens grid also reinforces the correspondence to a traditional reticule found on real instruments.</p><p>Initial reviews also revealed the gaps in the current methods of measurement visualization, which led to the design of the current track and filtering mechanisms in order to support a more efficient and visual means for manipulating and navigating to salient measurement features in the context of the full signal.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">EXAMPLE RESULTS</head><p>In this section we present several example analyses to illustrate how SignalLens is effective in visually analyzing large signal traces. <ref type="figure" target="#fig_3">Figure 3</ref> displays an amplitude modulated (AM) signal from an oscilloscope demonstration board used for training and sales purposes. This signal consists of a relatively modest 65,534 data points. The carrier frequency of this signal is 2 MHz with a modulating frequency of approximately 440 kHz. However, the amplitude of every 2 nd envelope has slightly different amplitude when compared to the previous envelope due to an intentional discontinuity in the carrier at approximate repetitive rate of 220 kHz. This discontinuity is synchronous with the overall modulating frequency, not the carrier signal, and hence each occurrence of the discontinuity will appear differently depending upon the phase relationship of the modulating and the carrier signals. Therefore, this signal represents a useful test case where we know there is a repetitive "glitch" within the signal and we can attempt to find these anomalies using SignalLens. We begin by observing that the overall signal appears to be quite uniform except for a few instances where a slight "whisker" appears to protrude from the otherwise uniform shape. <ref type="figure" target="#fig_4">Figure 4</ref> shows an example of such a whisker and the sequence of navigation events that narrow into the corresponding signal glitch. <ref type="figure" target="#fig_3">Figure 3A</ref> shows the lens positioned over this feature. We can use the signal motif finder to look for a similar wave shape as this glitch in <ref type="figure" target="#fig_3">Figure 3A</ref>. After filtering for only statistically significant matches we plot the top track show in <ref type="figure" target="#fig_3">Figure 3C</ref>. At this stage we notice that the repetition of the glitch generally appears every other carrier oscillation except for a few instances which seem to skip this pattern. We can investigate further by examining 1 st and 2 nd derivatives. Filtering for just the most extreme slopes and curvatures yields the additional two tracks shown in <ref type="figure" target="#fig_3">Figure 3C</ref>. In this case we notice that the pattern is uniform and inspection of the indicated locations show that even when the motif finder missed a glitch, the filtered derivatives indicate its location.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Amplitude Modulated Signal</head><p>If this exercise had been on a completely unknown signal, it would be reasonable to follow this work flow by first noticing the obvious anomalies and then try to pattern match against an example waveform as we have done here. Noticing that there is an apparent pattern, we can perform further calculations to dig deeper into the signal and find the remaining glitches. From a task perspective we can describe this process as (1) a classic outlier detection followed by (2) motif searching and finally (3) detection of a more subtle anomaly consisting of a surprising frequency of occurrence of the motif (cf. Keogh et al. <ref type="bibr" target="#b12">[13]</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">PCI Express</head><p>Peripheral Component Interconnect Express (PCI Express or PCI-E) is a widely used standard for computer expansion card interfaces as well as motherboard-level interconnects. It is a high-speed point-topoint protocol with speeds up to 1GB per second per lane. Motherboard designers frequently need to measure these high speed signals to establish compliance with PCI-E specifications as well as debug transient signal issues. <ref type="figure" target="#fig_6">Figure 5</ref> shows a sample of PCI-E data generated from PCI-E demo board. In this case the overview context is relatively featureless and provides no real clues as to where any anomalies  . An example navigation sequence using the AM signal. (A) We initially find an anomalous "whisker" protruding from the standard waveform (inset shows magnified view for clarity). (B) After clicking the mouse on the "whisker" we are nearer the anomaly, which can now be seen more clearly in the drop-off area of the lens. Clicking on this larger target navigates precisely to (C) the point of interest. The arrow indicates the same target of interest in all views. might lie. We could manually scroll through the entire data set visually looking for anything suspicious, but this procedure would be quite time consuming and tedious. Instead, we can use the measurement tracks to aid us in discovering any hidden features. We begin by calculating rise and fall times of the signal pulses. These calculations provide us the location of the leading and trailing edges of the PCI-E pulses. We calculate a third track from the first by calculating the distance from the rise to fall time, essentially giving us the pulse width. If we then view the histogram of pulse widths ( <ref type="figure" target="#fig_6">Figure 5E</ref>) we notice they mostly follow the expected equally spaced distribution of PCI-E widths corresponding to the different width multiples in the specification. However, we notice that there is a very narrow outlier peak. Using the histogram, we can filter for just this peak. Navigating to the single outlier, we find an extremely sharp spike at 2.1426 ms as shown in <ref type="figure" target="#fig_6">Figure 5A</ref>.</p><p>Users of this demo board had never seen this anomaly before due to the single instance of a very narrow spike. However, SignalLens found the spike quite easily with just a few simple operations. In this case the outlying pattern is actually discovered in the histogram of pulse widths and the visualization is used to navigate to and view this anomaly in context.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">ECG</head><p>Not all electronic time series are measured from semiconductor based systems. Physiological measurements such as electrocardiograms (ECG) are particularly well suited for analysis by SignalLens. <ref type="figure" target="#fig_7">Figure 6</ref> shows one channel of an ECG spanning four continuous hours of heart monitoring. This data of a 53 year old male is taken from dataset chf01 from the BIDMC Congestive Heart Failure Database obtained from PhysioBank <ref type="bibr" target="#b7">[8]</ref>. As in the previous AM signal, we navigate to a suspiciously protruding feature to find that it looks different from the typical repetitive waveform. Referring to the literature we find that the wave shape corresponds to a premature ventricular contraction <ref type="bibr" target="#b8">[9]</ref>. Using the motif finder we can locate a number of similar features in the data set, and can quickly navigate to each one using the next/previous buttons ( <ref type="figure" target="#fig_3">Figure 3E</ref>).</p><p>Another aspect we can quickly recover from the ECG is a rough approximation of the heart rate. If we calculate the rise time, we capture the leading edge of most heart beats. If we then calculate the distance between these edges and inspect the corresponding histogram (not shown) we find that the distribution of time between heartbeats centers around 0.9 seconds corresponding to a heart rate of 67 beats per second which seems plausible. Similar distance measures could be used to characterize the distribution of time spans between PVC's or any other anomalies of interest.</p><p>While considerable work would be required for SignalLens to be an FDA-approved tool for ECG analysis, the results with this data set are encouraging that the general approach has broader potential application to other time series domains. This example also demonstrates that the methods are relatively robust against signals which are less uniform and well behaved than those generated by well designed electronics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">DISCUSSION</head><p>During the development of SignalLens several important issues arose. We discuss these here with the hope that these insights may be of value to others interested in implementing similar designs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Magnification, Context and Levels of Detail</head><p>One might think that extreme magnifications of 500x or more would be impractical or at least problematic. However, in this paper we have demonstrated real (not hypothetical) examples where such magnifications are clearly tractable and useful. The AM signal example in Section 5.1 shows how even the drop-off regions of the lens can be very useful for iteratively navigating to an otherwise difficult-to-find feature (see <ref type="figure" target="#fig_4">Figure 4</ref>).  We have also seen that some signals (e.g. the PCI-E signal in Section 5.2) can have a relatively featureless uniform context area. However, even for those instances where the context area is relatively uninformative, we can still rely on the measurement tracks to provide assistance in detecting and navigating to interesting features or outliers in the data. The temporal position and spacing of detected features is shown in relation to the global context and impart useful contextual information even when the signal itself is relatively featureless. Put another way, since the measurement tracks are subject to the same Focus+Context techniques, they provide supplemental contextual information at the overview level, which aids in navigation and feature finding in the same way that visible signal features would.</p><p>Finally, we wish to show one final striking example of how rich signal details can be found in large signal traces, even when viewed in their entirety. <ref type="figure" target="#fig_8">Figure 7</ref> shows slightly more than a full frame of an NTSC video signal <ref type="bibr" target="#b13">[14]</ref>. What is striking about this figure is that one can see rich signal detail at all levels. One can clearly see two flanking vertical sync regions ( <ref type="figure" target="#fig_8">Figure 7A</ref>) in the context area. As expected, one can see clear details in the focus region of the lens (here the color burst signal, <ref type="figure" target="#fig_8">Figure 7C</ref>). What is perhaps not expected is that the drop off areas (because of their intermediate magnification ranges) still enable significant interpretation of the signals flanking the focus region. Here we can clearly see the horizontal sync area ( <ref type="figure" target="#fig_8">Figure 7B</ref>) as well as the beginning of the scan line signal ( <ref type="figure" target="#fig_8">Figure 7D)</ref>. While some signals such as the PCI-E data in Section 5.2 are so uniform that little useful detail is available in the context area, there are examples such as the NTSC signal where significant detail at multiple levels of magnification is discernable. In these cases the focus, drop-off and context regions work together to provide useful landmarks for navigation and feature selection.</p><p>We speculate that many modern analog electronic signals will be similarly amenable to Focus+Context techniques, since they typically require multiple levels of modulation and/or multiplexing leading to a similar degree of multi-level detail. In contrast, purely digital signals such as the PCI-E signal have relatively uniform wave shapes leading to featureless overviews. Focus+Context applied to such signals will have limited value unless supplemented with filterable measurement tracks for navigation and feature finding.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Scalability and Performance</head><p>Signal data is read as simple two column tab-delimited text in order to support a variety of data sources. Each line of text corresponds to a time/signal value pair. No specific pre-processing is required and all pre-computations and caching are performed as they are needed. The current implementation of SignalLens is capable of reasonable performance on datasets up to 2-3 Megapoints <ref type="bibr">(10 6</ref> ). To achieve this performance with standard hardware we implemented several strategies: Lens calculations are pre-computed at runtime for the unit radius and fetched as needed from a lookup table. We use a lookup table containing 10 6 entries which provides more than sufficient accuracy for our needs. For the hardware described in <ref type="table" target="#tab_0">Table 1 the lookup table  can</ref> be computed in approximately 160 ms for the quadratic lens. The resulting runtime performance is very fast and consistent across lens shapes regardless of the complexity of the lens shape (e.g. Gaussian vs. polynomial vs. linear).</p><p>We aggregate those line segments in the signal plot which will map within the same horizontal pixel and cache these as a single vertical line segment. Additionally we cache the first and last time points for each line segment to allow drawing the appropriate connection between adjacent line segments. This aggregation enables the undistorted areas to be plotted as a relatively small number of line segments (~10 3 ) rather than several million segments, while still accurately representing the signal's appearance. From the time span of each cached line segment we can determine if a segment will still fall within a single horizontal pixel after lens distortion. In such cases we also plot the cached line segments rather than the lines connecting the individual points. <ref type="table" target="#tab_0">Table 1</ref> presents typical performance data for three of the datasets discussed in this paper using a nominal off-the-shelf consumer grade computer. For smaller data sets such as the amplitude modulated signal (AM) the frame rate during navigation animation is quite high. For the larger more complex data sets the frame rate declines but is still well within a usable range for visual navigation cues. Frame rates depend on a variety of factors including the size of the dataset as well as the magnification level. Even though the ECG data is larger than the PCI-E data set, the higher magnification results in more use of the cached aggregated line segments and fewer draws of individual time points. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Lens Navigation</head><p>As discussed previously, high magnification creates some difficulties in selecting targets since a pixel of context corresponds to a potentially large number of underlying time points, and the user intent becomes somewhat ambiguous. As with direct target selection, positioning the lens by dragging has the similar difficulties since a single pixel movement corresponds to potentially large time increments which may pass over many time points. Hence, simply dragging the lens is incapable of positioning to a specific target. For most navigation, direct selection via mouse clicks (e.g. the sequence shown in <ref type="figure" target="#fig_4">Figure 4</ref>) is more effective than dragging the lens into position. In our design, keyboard actions (arrow keys) can be used to micro-position the lens to the precise time point required. Navigation is further supplemented by the ability to navigate to a specific time or individual features in the filtered measurement tracks. The combination of these navigation aids largely overcomes the issues related to lens movement.</p><p>Despite these limitations we maintain the capability to drag the lens in order to maintain consistency with the metaphor of a movable lens, and to allow for coarse positioning. We designed SignalLens to explore the possibility of using Focus+Context techniques to address the issues of long electronic signal traces within the constraints of the limited screen real estate typical of current instruments. Our preliminary results using the tool as well as reviews by experts indicate that it is a promising direction for further study. However, a formal user study is required before any definitive claims can be made. In lieu of such studies, we believe the included examples illustrate that the SignalLens design is tractable and useful for conditions constrained by small screens. The inclusion of computed measurement tracks to aid in the analysis of an acquired signal significantly improves the usability of the system. These tracks can be viewed as extending the overall context of the data. Filtered tracks improve the visibility of salient features and aid in the navigation of the original data set. As we have seen with the PCI-E data, with appropriate domain knowledge, even minute features can be found visually after computing and filtering characteristics of the signal. Measurement tracks enable rapid analysis and navigation even if the context/overview of the full data set is so dense as to be featureless to the user. While this implementation has proven to be valuable for SignalLen's Focus+Context implementation, the same concept could be applied to an Overview+Detail approach. In this case the tracks should be plotted in parallel with both the overview and the detail view. This would enable viewing features at both levels of detail, and offer the same affordances.</p><p>While SignalLens has made progress towards handling very large time series, further work and optimization still needs to be made to handle Gigapoint traces with reasonable interactivity. Our current implementation has reasonable performance for dataset as large a 2-3 Megapoints simply using an aggregation and caching strategy. Scaling to larger datasets will likely require graphics hardware acceleration and/or leveraging the GPU as a computational engine.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Robert</head><label></label><figDesc>Kincaid  is with Agilent Laboratories, E-Mail: robert_kincaid@agilent.com. Manuscript received 31 March 2010; accepted 1 August 2010; posted online 24 October 2010; mailed on 16 October 2010. For information on obtaining reprints of this article, please send email to: tvcg@computer.org .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2</head><label>2</label><figDesc>defines the relevant variables used in the distance-based (vs. optical) magnification scheme. From the viewpoint looking downward at the presentation surface we define d s as the distance to the surface and d b as the distance to the base. For the region of interest we, in effect, stretch the viewing surface toward the viewpoint where d s is much smaller than d b resulting in a magnification of d b /d s . In the surrounding context area, d s is identical to d b and no magnification is achieved. Between the region of interest and the unmagnified context area we provide a smooth height function h corresponding to d b -d s . Equation 1 summarizes the relationship between these distances and the magnification m.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 .</head><label>2</label><figDesc>Schematic of lens parameters. The heavy line denotes the hypothetical viewing surface.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 .</head><label>3</label><figDesc>SignalLens User Interface. This is a view of an AM test signal with a lens magnification of 500X. (A) Fixed magnification focus area bounded by lens grid, showing a signal "glitch". (B) Undistorted context area showing global scope oscillations. (C) Filtered measurement tracks (see text for details). (D) Measurement panel where measurements can be selected and filtered using the dynamic query sliders. (E) Forward/Backward buttons for directly navigating to the next or previous measurement which passes the filter criteria. (F) Histogram button for invoking histogram used for filtering. (G) Scratch Pad for storing/overlaying waveforms of interest.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4</head><label>4</label><figDesc>Figure 4. An example navigation sequence using the AM signal. (A) We initially find an anomalous "whisker" protruding from the standard waveform (inset shows magnified view for clarity). (B) After clicking the mouse on the "whisker" we are nearer the anomaly, which can now be seen more clearly in the drop-off area of the lens. Clicking on this larger target navigates precisely to (C) the point of interest. The arrow indicates the same target of interest in all views.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 5 .</head><label>5</label><figDesc>PCI-E Signal with spurious signal spike. (A) The non-compliant signal spike shown at magnification 250X. (B) Rise time track. (C) Fall time track. (D) The anomalous pulse width which was computed as the difference between rise time and fall time, and then filtered for any anomalous values. (E) Histogram view of the anomalous pulse width used for filtering the visualization.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 6 .</head><label>6</label><figDesc>A four hour ECG Signal with a lens magnification of 1000X. (A) An instance of a premature ventricular contraction (PVC). (B) Other PVC's detected by the motif finder and shown in the track display. (C) Inset illustrating how the scratch pad can overlay two or more waveforms, here showing a comparison between two PVC signals.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 7 .</head><label>7</label><figDesc>NTSC Video Signal with a lens magnification of 500X. Multiple levels of signal detail are visible: (A) vertical sync (B) horizontal sync (C) color burst (D) single line of video. The motif finder has been used to find the rising edge of each video scan line.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>Typical Rendering Performance (2.70 GHz AMD Athlon II X2 235e, 4GB RAM)</figDesc><table><row><cell>Data</cell><cell>Time Points</cell><cell>Magnification</cell><cell>Frames Per Second</cell></row><row><cell>AM</cell><cell>65534</cell><cell>500</cell><cell>49</cell></row><row><cell>PCI-E</cell><cell>1023983</cell><cell>250</cell><cell>17</cell></row><row><cell>ECG</cell><cell>1799998</cell><cell>1000</cell><cell>20</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">KINCAID: SIGNALLENS: FOCUS+CONTEXT APPLIED TO ELECTRONIC TIME SERIES</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS, VOL. 16, NO. 6, NOVEMBER/DECEMBER 2010</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Visualizing time-oriented data-A systematic view</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Aigner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Miksch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Muller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computers &amp; Graphics</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="401" to="409" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Interactive pattern search in time series</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Buono</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Aris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Plaisant</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. SPIE</title>
		<meeting>SPIE</meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="175" to="186" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A framework for unifying presentation space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Carpendale</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Montagnese</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM Symposium on User interface Software and Technology</title>
		<meeting>the ACM Symposium on User interface Software and Technology</meeting>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="page">70</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Achieving higher magnification in context</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Carpendale</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ligh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Pattison</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM Symposium on User interface Software and Technology</title>
		<meeting>the ACM Symposium on User interface Software and Technology</meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="71" to="80" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">A Review of Overview plus Detail, Zooming, and Focus plus Context Interfaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Cockburn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Karlson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">B</forename><surname>Bederson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Computing Surveys</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="page" from="1" to="31" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Generalized fisheye views</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Furnas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM SIGCHI Bulletin</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page">23</biblScope>
			<date type="published" when="1986" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A fisheye follow-up: further reflections on focus+ context</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Furnas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the SIGCHI Conference on Human Factors in Computing Systems</title>
		<meeting>the SIGCHI Conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page">1008</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">PhysioBank, PhysioToolkit, and PhysioNet -Components of a new research resource for complex physiologic signals</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">L</forename><surname>Goldberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">A N</forename><surname>Amaral</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Glass</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Circulation</title>
		<imprint>
			<biblScope unit="volume">101</biblScope>
			<biblScope unit="page" from="215" to="220" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Gomella</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Haist</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Clinician&apos;s Pocket Reference: McGraw-Hill Medical</title>
		<imprint>
			<biblScope unit="page">390</biblScope>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Improving focus targeting in interactive fisheye views</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Gutwin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the SIGCHI Conference on Human factors in Computing Systems</title>
		<meeting>the SIGCHI Conference on Human factors in Computing Systems</meeting>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="267" to="274" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Fisheyes are good for large steering tasks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Gutwin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Skopik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the SIGCHI Conference on Human Factors in Computing Systems</title>
		<meeting>the SIGCHI Conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page">208</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Interactive exploration of time series data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Hochheiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Shneiderman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Lecture Notes in Computer Science</title>
		<imprint>
			<biblScope unit="page" from="441" to="446" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Finding surprising patterns in a time series database in linear time and space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Keogh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lonardi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Chiu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data mining</title>
		<meeting>the ACM SIGKDD International Conference on Knowledge Discovery and Data mining</meeting>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="550" to="556" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Data Conversion Handbook: Newnes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Kester</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Devices</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page">608</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">MassVis: Visual analysis of protein complexes using mass spectrometry</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Kincaid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Dejgaard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Symposium on Visual Analytics Science and Technology</title>
		<meeting>the IEEE Symposium on Visual Analytics Science and Technology</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="163" to="170" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Line graph explorer: scalable display of line graphs using Focus+ Context</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Kincaid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Working Conference on Advanced Visual Interfaces</title>
		<meeting>the Working Conference on Advanced Visual Interfaces</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="404" to="411" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Time-series bitmaps: A practical visualization tool for working with large time series databases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Lolla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Keogh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIAM 2005 Data Mining Conference</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="531" to="535" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">A focus+ context technique based on hyperbolic geometry for visualizing large hierarchies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lamping</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Pirolli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the SIGCHI Conference on Human Factors in Computing Systems</title>
		<meeting>the SIGCHI Conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<date type="published" when="1995" />
			<biblScope unit="page">408</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">A review and taxonomy of distortionoriented presentation techniques</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Leung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Apperley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Computer-Human Interaction (TOCHI)</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="126" to="160" />
			<date type="published" when="1994" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Finding motifs in time series</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Keogh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lonardi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Workshop on Temporal Data Mining</title>
		<meeting>of the Workshop on Temporal Data Mining</meeting>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="53" to="68" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">A layeroriented interface for visualizing time-series data from oscilloscopes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Lopez-Hernandez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Guilmaine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Mcguffin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Pacific Visualization Symposium (PacificVis)</title>
		<meeting>the IEEE Pacific Visualization Symposium (PacificVis)</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="41" to="48" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">LiveRAC: Interactive visual exploration of system management time-series data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Mclachlan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Munzner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Koutsofios</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the SIGCHI Conference on Human Factors in Computing Systems</title>
		<meeting>the SIGCHI Conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="1483" to="1492" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Sigma lenses: focus-context transitions combining space, time and translucence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Pietriga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Appert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceeding of the SIGCHI Conference on Human Factors in Computing Systems</title>
		<meeting>eeding of the SIGCHI Conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="1343" to="1352" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Pointing and beyond: an operationalization and preliminary evaluation of multi-scale searching</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Pietriga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Appert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Beaudouin-Lafon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the SIGCHI Conference on Human Factors in Computing Aystems</title>
		<meeting>the SIGCHI Conference on Human Factors in Computing Aystems</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page">1224</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Image-browser taxonomy and guidelines for designers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Plaisant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Carr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Shneiderman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Software</title>
		<imprint>
			<biblScope unit="page" from="21" to="32" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">H</forename><surname>Press</surname></persName>
		</author>
		<title level="m">Numerical recipes in C++</title>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Cambridge University Press</publisher>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
	<note>2nd ed. Cambridge</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
