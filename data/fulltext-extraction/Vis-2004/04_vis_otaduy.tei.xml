<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/pisenberg/grobid/grobid-0.6.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Haptic Display of Interaction between Textured Models</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Miguel</forename><forename type="middle">A</forename><surname>Otaduy</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Department of Computer Science</orgName>
								<orgName type="department" key="dep2">Carolina at Chapel Hill http://gamma.cs.unc.edu/HTextures</orgName>
								<orgName type="institution">University of North</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nitin</forename><surname>Jain</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Department of Computer Science</orgName>
								<orgName type="department" key="dep2">Carolina at Chapel Hill http://gamma.cs.unc.edu/HTextures</orgName>
								<orgName type="institution">University of North</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Avneesh</forename><surname>Sud</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Department of Computer Science</orgName>
								<orgName type="department" key="dep2">Carolina at Chapel Hill http://gamma.cs.unc.edu/HTextures</orgName>
								<orgName type="institution">University of North</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><forename type="middle">C</forename><surname>Lin</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Department of Computer Science</orgName>
								<orgName type="department" key="dep2">Carolina at Chapel Hill http://gamma.cs.unc.edu/HTextures</orgName>
								<orgName type="institution">University of North</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Haptic Display of Interaction between Textured Models</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2021-02-20T19:33+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>haptics</term>
					<term>textures</term>
					<term>graphics hardware</term>
				</keywords>
			</textClass>
			<abstract>
				<p>Figure 1: Haptic Display of Interaction between Textured Models. From left to right: (a) high-resolution textured hammer (433K polygons) and CAD part (658K polygons), (b) low-resolution models (518 &amp; 720 polygons), (c) hammer texture with fine geometric detail.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Haptic rendering provides a unique, two-way communication between humans and interactive systems, enabling bi-directional interaction via tactile sensory cues. By harnessing the sense of touch, haptic display can further enhance a user's experience in a multimodal synthetic environment, providing a more natural and intuitive interface with the virtual world. A key area in haptics that has received increasing attention is the rendering of surface texture, i.e. fine geometric features on an object's surface. The intrinsic surface property of texture is among the most salient haptic characteristics of objects. It can be a compelling cue to object identity, and it can strongly influence forces during manipulation <ref type="bibr" target="#b15">[16]</ref>. In medical applications with limited visual feedback, such as minimally-invasive or endoscopic surgery <ref type="bibr" target="#b23">[24]</ref>, and virtual prototyping applications of mechanical assembly and maintainability assessment <ref type="bibr" target="#b26">[27]</ref>, accurate haptic feedback of surface detail is a key factor for successful meticulous operations.</p><p>Most of the existing haptic rendering algorithms have focused primarily on force rendering of rigid or deformable flat polygonal models. This paper addresses the simulation of forces and torques due to interaction between two textured objects. Effective physically-based force models have been proposed to render the interaction between the tip (a point) of a haptic probe and a textured object <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b9">10]</ref>. However, no technique is known to display both interaction forces and torques between two textured models. In fact, computation of texture-induced forces using full-resolution geometric representations of the objects and handling contacts at micro-geometric scale is computationally prohibitive.</p><p>Similar to graphical texture rendering <ref type="bibr" target="#b1">[2]</ref>, objects with high combinatorial complexity (i.e. with a high polygon count) can be described by coarse representations with their fine geometric detail stored in texture images, which we will refer to as haptic textures in this paper. Given this representation and a new force model that captures the effect of geometric surface details, we are able to haptically display intricate interaction between highly complex models using haptic textures instead of actual surface geometry.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Main Contributions:</head><p>In this paper, we introduce a physicallybased algorithm for incorporating texture effects to haptic display of interaction between two polygonal models. This algorithm enables, for the first time, interactive haptic display of forces and torques due to fine surface details. The main results of our paper are:</p><p>• A novel force model for haptic texture rendering, based on the gradient of directional penetration depth, that accounts for important factors identified by psychophysics studies;</p><p>• A fast algorithm for approximating directional penetration depth between textured objects;</p><p>• An efficient implementation on programmable graphics hardware that enables interactive haptic display of forces and torques between complex textured models;</p><p>October 10-15, Austin, Texas, USA IEEE Visualization 2004 0-7803-8788-0/04/$20.00 ©2004 IEEE</p><p>• A new approach to haptically render complex interaction due to fine surface details using simplified representations of the original models and the corresponding haptic textures.</p><p>Our algorithm can be integrated in state-of-the-art haptic rendering algorithms to enhance the range of displayed stimuli. We have successfully tested and demonstrated our algorithm and implementation on several complex textured models. Some examples are shown in <ref type="figure">Fig. 1</ref>. Subjects were able to perceive roughness of various surface textures.</p><p>Organization: The rest of the paper is organized as follows. In Sec. 2 we discuss related work. Sec. 3 defines key terminology and describes several important concepts central to our force model. Sec. 4 presents the force computation model. Sec. 5 introduces a simple yet effective algorithm for approximating directional penetration depth and its parallel implementation on graphics processors. We then describe our results in Sec. 6. Finally, we discuss and analyze our approach in Sec. 7 and conclude with possible future research directions in Sec. 8.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">PREVIOUS WORK</head><p>In this section we briefly discuss related work on haptic rendering and penetration depth computations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Six Degree-of-Freedom Haptics</head><p>Haptic display of forces and torques between two interacting objects is commonly known as 6 degree-of-freedom (DoF) haptics. In all approaches to 6-DoF haptics, collision detection is a dominant computational cost. The performance of collision detection algorithms depends on the size of the input models, which in turn depends on the sampling density of the models, both for polygonal representations <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b10">11]</ref> and for voxel-based representations <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b26">27]</ref>.</p><p>To be correctly represented, surfaces with high-frequency geometric texture detail require higher sampling densities, thereby increasing the cost of collision detection. As a result, haptic rendering of forces between textured objects becomes computationally infeasible to achieve, and new representations must be considered.</p><p>Otaduy and Lin <ref type="bibr" target="#b19">[20]</ref> recently suggested multiresolution representations to minimize the computational impact of collision detection and to adaptively select the appropriate resolution at each contact location. However, their approach filters out high resolution geometric features, thus ignoring all texture effects.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Haptic Texture Rendering</head><p>Rendering and perception of textures has been one of the most active areas in haptics research. Please refer to <ref type="bibr" target="#b15">[16]</ref> for a survey on psychophysics of tactile texture perception. Klatzky and Lederman made important distinctions between perception of textures with bare skin vs. perception through a rigid object. When perceived through a rigid probe, roughness of a textured surface is encoded as vibration.</p><p>Several researchers have successfully developed haptic texture rendering techniques for interaction between a probe point and an object, using coarse geometric approximations and geometric texture images. These techniques use the idea of computing geometrydependent high frequency forces, which transmit vibratory information to the user, and are perceived as virtual roughness. Minsky <ref type="bibr" target="#b17">[18]</ref> showed that texture information can be conveyed by displaying forces on the tangent plane defined by the contact normal. Minsky computed a texture-induced force proportional to the gradient of a 2D height field stored in a texture map. Ho et al. <ref type="bibr" target="#b9">[10]</ref> have proposed techniques that alter the magnitude and direction of 3D normal force based on height field gradient. Siira and Pai <ref type="bibr" target="#b25">[26]</ref> followed a stochastic approach, where texture forces are computed according to a Gaussian distribution.</p><p>All these techniques exploit the fact that, for point-object contact, a pair of texture coordinates can be well defined, and this is used to query height fields stored in texture maps. Note that only geometric effects of one object are captured. We are interested in rendering forces occurring during the interaction of two surfaces. In this case, the geometric interaction is not limited to and cannot be described by a pair of contact points. Moreover, the local kinematics of the contact between two surfaces include rotational degrees of freedom, not captured by point-based haptic rendering methods.</p><p>Choi and Tan <ref type="bibr" target="#b2">[3]</ref> have studied the influence of collision detection and penetration depth computation on point-based haptic rendering, and their findings appear to be applicable to 6-DoF haptics as well.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Penetration Depth Computation</head><p>Several algorithms <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b12">13]</ref> have been proposed for computing a measure of penetration depth using various definitions. However, each of them assumes that at least one of the input models is a convex polytope. It is commonly known that if two polytopes intersect, then the difference of their reference vectors with respect to the origin of the world coordinate system lies in their convolution or Minkowski sum <ref type="bibr" target="#b7">[8]</ref>. The problem of penetration depth computation reduces to calculating the minimum distance from the origin to the boundary of the Minkowski sum of two polyhedra. The worst case complexity for two general, non-convex polyhedra can be as high as O(m 3 n 3 ), where m, n are the number of polygons in each model. Kim et al. <ref type="bibr" target="#b13">[14]</ref> presented an algorithm for estimating penetration depth between two polyhedral models using rasterization hardware and hierarchical refinement. Although it offers better performance than previous techniques, this approach may take up to minutes to compute the penetration depth, making it inadequate for haptic simulation.</p><p>In this paper we present a new algorithm to estimate directional penetration depth between models described by low-resolution representations and haptic textures. Unlike the algorithm by Kim et al. <ref type="bibr" target="#b13">[14]</ref>, it does not compute the global penetration depth between two models, but its performance makes it suitable for haptic display.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">PRELIMINARIES</head><p>In this section we first introduce notation used in the paper. Then, we present definitions related to penetration depth, which is an essential element of our force model. Finally, we describe the computational pipeline for haptic rendering of interaction between textured models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Notations</head><p>A height field H is defined as a set</p><formula xml:id="formula_0">H = {(x, y, z) | z = h(x, y), (x, y, z) ∈ R 3 }. We call h : R 2 → R a height function. Let q denote a point in R 3 , let q xyz = (q x q y q z )</formula><p>T denote the coordinates of q in a global reference system, and q uvn = (q u q v q n ) T its coordinates in a rotated reference system {u, v, n}. A surface patch S ⊂ R 3 can be represented as a height field along a direction n if q n = h(q u , q v ), ∀q ∈ S. Then, we can define a mapping g :</p><formula xml:id="formula_1">D → S, D ⊂ R 2 , as g(q u , q v ) = q xyz , where: h(q u , q v ) = q n = n • q xyz = n • g(q u , q v )<label>(1)</label></formula><p>The inverse of the mapping g is the orthographic projection of S onto the plane (u, v) along the direction n.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Definitions of Penetration Depth</head><p>Penetration depth δ between two intersecting polytopes is typically defined as the minimum translational distance required to separate them (see <ref type="figure" target="#fig_0">Fig. 2-b</ref>). As mentioned in Sec. 2.3, this distance is equivalent to the distance from the origin to the Minkowski sum of the polyhedra. Directional penetration depth δ n along the direction n is defined as the minimum translation along n to separate the polyhedra (see <ref type="figure" target="#fig_0">Fig. 2-c)</ref>. The penetration depth between two intersecting surface patches will be referred to as local penetration depth. Let us assume that two intersecting surface patches S A and S B can be represented as height fields along a direction n. Consequently, S A and S B can be parameterized by orthographic projection along n, as expressed in Sec. 3.1. As a result of the parameterization, we obtain mappings g A :</p><formula xml:id="formula_2">D A → S A and g B : D B → S B , as well as height functions h A : D A → R and h B : D B → R.</formula><p>The directional penetration depth δ n of the surface patches S A and S B is the maximum height difference along the direction n, as illustrated in <ref type="figure" target="#fig_1">Fig. 3</ref> by a 2D example. Therefore, we can define the directional penetration depth δ n as: </p><formula xml:id="formula_3">δ n = max (u,v)∈(D A ∩D B ) h A (u, v) − h B (u, v)<label>(2)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Haptic Display Pipeline</head><p>We assume that the interacting objects can be described as parameterized low-resolution triangle meshes with texture maps that store fine geometric detail. In a haptic simulation of object-object interaction, the object whose motion is controlled by the user is called the probe object. Contacts between the probe object and the rest of the objects in the environment generate forces that are displayed to the user. Following a common approach in 6-DoF haptics, we simulate the dynamics of the probe object as a result of contact forces and a virtual coupling force that ensures stable interaction with the user <ref type="bibr" target="#b0">[1]</ref>. We propose a novel algorithm for computing contact forces, taking into account texture effects. We follow the steps below to compute contact forces:</p><p>1. Each haptic simulation frame starts by performing collision detection between the low-resolution meshes. We then identify intersecting surface patches as contacts. We characterize each contact by a pair of contact points on the patches and a penetration direction n.</p><p>2. For each contact, we compute force and torque using our novel force model for texture rendering, based on the penetration depth and its gradient. The penetration depth is approximated taking into account fine geometric detail stored in haptic textures.</p><p>3. The forces and torques of all contacts are combined to compute the net force and torque on the probe object.</p><p>Other effects, such as friction <ref type="bibr" target="#b8">[9]</ref>, can easily be incorporated into this display pipeline using the contact information computed between the low-resolution meshes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">A FORCE MODEL FOR TEXTURE RENDERING</head><p>In this section we describe our force model for haptic display of interaction between textured surfaces. We first show how factors highlighted by psychophysics studies are taken into account. Then, we introduce a penalty-based force model for texture rendering. Finally, we present the formulation of the gradient of penetration depth used in our force model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Foundation of the Proposed Force Model</head><p>Roughness of surface textures perceived through a rigid probe is mainly encoded as vibration and strongly influences the forces that must be applied to manipulate the objects <ref type="bibr" target="#b15">[16]</ref>. In point-based haptic texture rendering, vibrating forces are commonly computed using a height field gradient <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b9">10]</ref>. Our force model generalizes the point-based approach by computing forces based on the gradient of penetration depth between two objects.</p><p>Based on psychophysics studies, Klatzky and Lederman <ref type="bibr" target="#b15">[16]</ref> highlight factors influencing perception of roughness through a rigid spherical probe. These factors are:</p><p>Probe Radius: For spherical probes, the texture frequency at which perception of roughness is maximum depends on probe radius. At low frequencies, roughness increases with texture frequency, but after reaching a peak, roughness decreases as texture frequency increases. Our conjecture is that roughness perception is tightly coupled to the trajectory traced by the probe, which can be regarded as an offset surface of the perceived geometry. Okamura and Cutkosky <ref type="bibr" target="#b18">[19]</ref> also modeled interaction between robotic fingers and textured surfaces by tracing offset surfaces. They defined an offset surface as the boundary of the Minkowski sum of a given surface and a sphere. Therefore, the height of the offset surface at a particular point is the distance to the boundary of the Minkowski sum for a particular position of the probe, also known to be the penetration depth <ref type="bibr" target="#b0">1</ref> . In other words, the height of the offset surface reflects the distance that the probe must move in order to avoid interpenetration with the surface. Since, for spherical probes, perception of roughness seems to be tightly coupled with the oscillation of offset surfaces, in our force model for general surfaces we have taken into account the variation of penetration depth, i.e. its gradient.</p><p>Normal Force: Perception of roughness grows monotonically with normal force. This relation is also captured by our force model in a qualitative way, in making tangential forces and torques proportional to the normal force.</p><p>Exploratory Speed: The exploratory speed, or velocity of the probe in the plane of contact with the surface, affects the perception of roughness. Our force model is intrinsically geometry-based, but in a haptic simulation dynamic effects are introduced by the haptic device and the user. We have analyzed the dynamic behavior of our force model, and we have observed that vibratory motion produced by simulated forces behaves in a way similar to physical roughness perception. The results of our experiments are described in detail in <ref type="bibr" target="#b20">[21]</ref>.</p><p>The influence of probe geometry, normal force and exploratory speed is taken into consideration in the design of our force model, which will be presented next.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Penalty-Based Texture Force</head><p>For two objects A and B in contact, we define a penalty-based force proportional to the penetration depth δ between them. Penaltybased forces are conservative, and they define an elastic potential field. In our force model we have extended this principle to compute texture-induced forces between two objects.</p><p>We define an elastic penetration energy U with stiffness k as:</p><formula xml:id="formula_4">U = 1 2 kδ 2<label>(3)</label></formula><p>Based on this energy, we define force F and torque T as:</p><formula xml:id="formula_5">F T = −∇U = −kδ (∇δ )<label>(4)</label></formula><p>where</p><formula xml:id="formula_6">∇ = ∂ ∂ x , ∂ ∂ y , ∂ ∂ z , ∂ ∂ θ x , ∂ ∂ θ y , ∂ ∂ θ z</formula><p>is the gradient in 6-DoF configuration space.</p><p>As described in Sec. 3.3, each contact between objects A and B can be described by a pair of contact points p A and p B , and by a penetration direction n. We assume that, locally, the penetration depth between objects A and B can be approximated by the directional penetration depth δ n along n. We rewrite Eq. 4 for δ n in a reference system {u, v, n} <ref type="bibr" target="#b1">2</ref> . In this case, Eq. 4 reduces to:</p><formula xml:id="formula_7">F u F v F n T u T v T n T = −kδ n ∂ δ n ∂ u ∂ δ n ∂ v 1 ∂ δ n ∂ θ u ∂ δ n ∂ θ v ∂ δ n ∂ θ n T<label>(5)</label></formula><p>where θ u , θ v and θ n are the rotation angles around the axes u, v and n respectively.</p><p>The force and torque on object A (and similarly on object B) for each contact can be expressed in the global reference system as:</p><formula xml:id="formula_8">F A = (u v n) (F u F v F n ) T T A = (u v n) (T u T v T n ) T<label>(6)</label></formula><p>As explained in Sec. 3.3, forces and torques of all contacts are summed up to compute the net force and torque. Generalizing Minsky's approach <ref type="bibr" target="#b17">[18]</ref>, we define tangential forces F u and F v proportional to the gradient of penetration depth. However, we also define a penalty-based normal force and gradientdependent torque that describe full 3D object-object interaction. In addition, in our model the tangential force and the torque are proportional to the normal force, which is consistent with psychophysics studies showing that perceived roughness increases with the magnitude of the normal force <ref type="bibr" target="#b15">[16]</ref>.</p><p>2 u and v may be selected arbitrarily as long as they form an orthonormal basis with n.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Penetration Depth and Gradient</head><p>In our formulation, δ and δ n are functions defined on a 6-DoF configuration space. We have opted for central differencing over onesided differencing to approximate ∇δ n , because it offers better interpolation properties and higher order approximation. The partial derivatives are computed as:</p><formula xml:id="formula_9">∂ δ n ∂ u = δ n (u + ∆u, v, n, θ u , θ v , θ n ) − δ n (u − ∆u, v, n, θ u , θ v , θ n ) 2∆u<label>(7)</label></formula><p>and similarly for</p><formula xml:id="formula_10">∂ δ n ∂ v , ∂ δ n ∂ θ u , ∂ δ n ∂ θ v</formula><p>and ∂ δ n ∂ θ n . δ n (u + ∆u, ...) can be obtained by translating object A a distance ∆u along the u axis and computing the directional penetration depth. A similar procedure is followed for other penetration depth values.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">DIRECTIONAL PENETRATION DEPTH</head><p>In this section we present an algorithm for approximating local directional penetration depth for textured models and describe a parallel implementation on graphics hardware.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Approximate Directional Penetration Depth between Textured Models</head><p>A contact between objects A and B is defined by two intersecting surface patches S A and S B . The surface patch S A is approximated by a low-resolution surface patchŜ A (and similarly for S B ). We define f A :Ŝ A → S A , a mapping function from the low-resolution surface patchŜ A to the surface patch S A . Collision detection between two low-resolution surfaces patcheŝ S A andŜ B returns a penetration direction n. Let us assume that both S A andŜ A (and similarly for S B andŜ B ) can be represented as height fields along n, following the definition in Sec. 3.1. Given a rotated reference system {u, v, n}, we can project S A andŜ A orthographically along n onto the plane (u, v). As the result of this projection, we obtain mappings g A :</p><formula xml:id="formula_11">D A → S A andĝ A :D A →Ŝ A . We definē D A = D A ∩D A .</formula><p>The mapping function g A can be approximated by a composite mapping function f A •ĝ A :D A → S A (See <ref type="figure" target="#fig_2">Fig. 4</ref>). From Eq. 1, we define an approximate height functionĥ :D A → R as: Given approximate height functionsĥ A andĥ B , a domain D = D A ∩D B , and Eq. 2, we can approximate the directional penetration depth δ n of S A and S B by:</p><formula xml:id="formula_12">h(u, v) = n • ( f A •ĝ A (u, v))<label>(8)</label></formula><formula xml:id="formula_13">δ n = max (u,v)∈D ĥ A (u, v) −ĥ B (u, v)<label>(9)</label></formula><p>Although this algorithm can be realized on CPUs, it is best suited for implementation on graphics processors (GPUs), as we will present next.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Computation on Graphics Hardware</head><p>As shown in Eq. 5, computation of 3D texture-induced force and torque according to our model requires the computation of directional penetration depth δ n and its gradient at every contact. From Eq. 7, this reduces to computing δ n all together at 11 configurations of object A 3 . As pointed out in section 2.3, computation of penetration depth using exact object-space or configuration-space algorithms is too expensive for haptic rendering applications. Instead, the approximationδ n according to Eqs. 8 and 9 leads to a natural and efficient image-based implementation on programmable graphics hardware. The mappingsĝ and f correspond, respectively, to orthographic projection and texture mapping operations, which are best suited for the parallel and grid-based nature of GPUs.</p><p>For every contact, we first computeĥ B , and then perform two operations for each of the 11 object configurations: computeĥ A for the transformed object A, and then find the penetration deptĥ δ n = max(∆ĥ) = max ĥ A −ĥ B 4 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Height Computation</head><p>In our GPU-based implementation, the mapping f :Ŝ → S is implemented as a texture map that stores geometric detail of the highresolution surface patch S. We refer to f as a "haptic texture". The mappingĝ is implemented by renderingŜ using an orthographic projection along n. We compute the height functionĥ in a fragment program. We obtain a point in S by looking up the haptic texture f and then we project it onto n. The result is stored in a floating point texture t.</p><p>We choose geometric texture mapping over other methods for approximating h (e.g. rendering S directly or performing displacement mapping) in order to maximize performance. We store the input haptic texture f as a floating point texture, thus alleviating precision problems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Max Search</head><p>The max function in Eq. 9 can be implemented as a combination of frame buffer read-back and CPU-based search. However, we avoid expensive read-backs by posing the max function as a binary search on the GPU <ref type="bibr" target="#b6">[7]</ref>. Given two height functionsĥ A andĥ B stored in textures t 1 and t 2 , we compute their difference and store it in the depth buffer. We scale and offset the height difference to fit in the depth range. Height subtraction and copy to depth buffer are performed in a fragment program, by rendering a quad that covers the entire buffer. For a depth buffer with N bits of precision, the search domain is the integer interval [0, 2 N ). The binary search starts by querying if there is any value larger than 2 N−1 . We render a quad at depth 2 N−1 and perform an occlusion query 5 , which will report if any pixel passed the depth test, i.e. the stored depth was larger than 2 N−1 . Based on the result, we set the depth of a new quad and continue the binary search.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Gradient Computation</head><p>The height functionsĥ A (±∆u),ĥ A (±∆v) andĥ A (±∆θ n ) may be obtained by simply translating or rotatingĥ A (0). As a result, only 6 height functionsĥ A (0),ĥ B (0),ĥ A (±∆θ u ) andĥ A (±∆θ v ) need to be computed for each pair of contact patches. These 6 height functions are tiled in one single texture t to minimize context switches and increase performance (See <ref type="figure" target="#fig_3">Fig. 5</ref>). Moreover, the domain of each height function is split into 4 quarters, each of which is mapped to one of the RGBA channels. This optimization allows us to exploit vector computation capabilities of fragment processors. As shown in <ref type="figure" target="#fig_3">Fig. 5</ref>, we also tile 11 height differences per contact in the depth buffer. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Multiple Simultaneous Contacts:</head><p>The computational cost of haptic texture rendering increases linearly with the number of contact patches between the interacting objects. However, performance can be further optimized. In order to limit context switches, we tile the height functions associated with multiple pairs of contact patches in one single texture t, and we tile the height differences in the depth buffer, as shown in <ref type="figure" target="#fig_3">Fig. 5</ref>. We also minimize the cost of "max search" operations by performing occlusion queries on all contacts in parallel.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">RESULTS</head><p>We now describe the implementation details and results obtained with our haptic texture rendering algorithm, both in terms of force and motion characteristics, as well as performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Implementation Details</head><p>Our haptic texture rendering algorithm requires a preprocessing step. Input models are assumed to be 2-manifold triangle meshes with fine geometric details. We parameterize the meshes and create texture atlas storing surface positions. We also simplify the meshes to produce coarse resolution approximations which are used by the collision detection module. The parameterization must be preserved during the simplification process, and distortion must be minimized. Our implementation of parameterization-preserving simplification is based on existing approaches <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b3">4]</ref>.</p><p>As described in Sec. 3.3, before computing forces we perform collision detection between coarse-resolution models. We adapt the approach of Kim et al. <ref type="bibr" target="#b14">[15]</ref> and decompose the models in convex pieces. Object interpenetration is considered to occur when objects are closer than a distance tolerance. In practice, by using this technique, penetration depth between the coarse resolution models is computed less frequently, thus accelerating collision detection.</p><p>For texture force computation, we compute each value of penetration depth between contact patches on a 50 × 50, 16-bit depth buffer. This resolution proved to be sufficient based on the results.</p><p>In our experiments we have used a 6-DoF Phantom T M haptic device, a dual Pentium-4 2.4GHz processor PC with 2.0 GB of memory and an NVidia GeForce FX5950 graphics card, and Windows2000 OS. The penetration depth computation on graphics hardware is implemented using OpenGL plus OpenGL's ARB fragment program and GL NV occlusion query extensions. Our haptic texture rendering cannot be stalled by the visual display of the scene; hence, it requires a dedicated graphics card. We display the full resolution scene on a separate commodity PC. The force update of the haptic device takes place at a frequency of 1kHz, but the haptic simulation is executed in a separate thread that updates the force input to a stabilizing virtual coupling <ref type="bibr" target="#b0">[1]</ref> asynchronously. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Benchmarks</head><p>In our experiments we have used the models shown in <ref type="figure" target="#fig_4">Fig. 6</ref>. The complexity of full resolution textured models and their coarse resolution approximations is listed in <ref type="table" target="#tab_1">Table 1</ref>  Notice the drastic simplification of the low resolution models. At this level all texture information is eliminated from the geometry, but it is stored in 1024 × 1024-size floating point textures. The number of convex pieces at coarse resolution reflects the geometric complexity for the collision detection module. Also notice that the block and gear models are fully convex at coarse resolution. The interaction between these models is described by one single contact, so they are better suited for analyzing force and motion characteristics in the simulations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Conveyance of Roughness</head><p>We have performed experiments to test the conveyance of roughness with our haptic texture rendering algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Roughness under Translation:</head><p>The gear and block models present ridges that interlock with each other. One of our experiments consisted of translating the block in the 3 Cartesian axes, while being in contact with the fixed gear, as depicted in <ref type="figure" target="#fig_4">Fig. 6-b. Fig. 7</ref> shows the position of the block and the force exerted on it during 1500 frames of interactive simulation (approx. 3 seconds).</p><p>Notice that the force in the x direction, which is parallel to the ridges, is almost 0. Our model successfully yields this expected result, because the derivative of the penetration depth is 0 along the x direction. Notice also the staircase shape of the motion in the z direction, which reflects how the block rests for short periods of time on the ridges of the gear. The motion in the y direction resembles a staircase as well, but with small overshoots. These reflect the state between two successive interlocking situations, when the ridges are opposing each other. The wide frequency spectrum of staircase motion is possible due to the fine spatial resolution of penetration depth and gradient computation. Last, the forces in y and z are correlated with the motion profiles.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Roughness under Rotation:</head><p>We placed two identical striped blocks interlocking each other, as shown in <ref type="figure" target="#fig_4">Fig. 6</ref>-a. We then performed small rotations of the upper block around the direction n, and observed the induced translation along that same direction. <ref type="figure" target="#fig_7">Fig. 8</ref> shows the rotation and translation captured during 6000  frames of interactive haptic simulation (approx. 12 seconds). Notice how the top block rises along n as soon as we rotate it slightly, thus producing a motion very similar to the one that occurs in reality. Point-based haptic rendering methods are unable to capture this type of effect. Our force model successfully produces the desired effect by taking into account the local penetration depth between the blocks. Also, the derivative of the penetration depth produces a physically-based torque in the direction n that opposes the rotation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Summary of Experiments:</head><p>From the experiments described above, we conclude that our force model successfully captures roughness properties of objects with fine geometric detail. We have also conducted informal experiments where subjects were asked to explore a textured plate with a virtual probe, while only the untextured coarse-resolution models were displayed graphically on the screen. Hence, the subjects could only recognize the texture patterns through haptic cues. The reported experiences were promising, as subjects were able to successfully describe regular patterns such as stripes, but had more difficulty with irregular patterns. This result is what we expect when real, physical textured models are explored.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.4">Performance Tests</head><p>One of the key issues to achieve realistic haptic rendering is very high force update rate. High update rates enhance the stability of the system, as well as the range of stimuli that can be displayed.</p><p>We have tested the performance of our haptic texture rendering algorithm and its implementation in scenarios where the coarse resolution models present complex contact configurations. These scenarios consist of a file scraping a rough CAD part, and a textured hammer touching a wrinkled torus. In particular, we show timings for 500 frames of the simulation of the file interacting with the CAD part in <ref type="figure" target="#fig_9">Fig. 9</ref>. The graph reflects the time spent on collision detection between the coarse-resolution models (an average of 2ms), the time spent on haptic texture rendering, and the total time per frame, which is approximately equal to the sum of the previous two. In this experiment we computed each value of penetration depth on a 50 × 50 16-bit depth buffer (See Sec. 5.2). As shown in Sec. 6.3, this proved to be sufficient to display convincing roughness stimuli.  In this particularly challenging experiment we were able to obtain haptic update rates between 100Hz and 200Hz. The dominant cost appears to be the haptic texture rendering, which depends nearly linearly on the number of contacts. The achieved force update rate may not be high enough to render textures with very high spatial frequency. However, as shown in Sec. 6.3, our proposed force model enables perception of roughness stimuli that were not captured previously by earlier methods. Moreover, in <ref type="figure" target="#fig_9">Fig. 9</ref> we show performance results for a contact configuration in which large areas of the file at many different locations are in close proxim-ity with the CAD part. In fact, collision detection using coarseresolution models reports an average of 104 pairs of convex pieces in close proximity, which are later clustered into as many as 7 contacts. Using the full-resolution models, the number of contact pairs in close proximity would increase by several orders of magnitude, and simply handling collision detection would become challenging at the desired haptic rendering frame rates. Furthermore, as the support for programming on GPUs and capabilities of GPUs continue to grow at a rate faster than Moore's Law, we expect the performance of our algorithm to reach KHz update rates in the near future.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">DISCUSSION AND ANALYSIS</head><p>In Sec. 6.3 we have analyzed forces and motion generated by our algorithm during actual haptic simulations. We have further analyzed the properties of the force model presented in Sec. 4 by simulating its behavior in experiments similar to the ones conducted in psychophysics studies <ref type="bibr" target="#b15">[16]</ref>. Our main conclusion is that the acceleration produced by our force model matches qualitatively the behavior of roughness perception as a function of texture frequency. A detailed description of the experiments we have conducted can be found in <ref type="bibr" target="#b20">[21]</ref>.</p><p>Our force model and implementation present a few limitations, some of which are common to existing haptic rendering methods. Next we discuss these limitations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1">Force Model</head><p>In some contact scenarios with large contact areas, the definition of a local and directional penetration depth is not applicable. An example is the problem of screw insertion. Situations also exist in which local geometry cannot be represented as height fields, and the gradient of directional penetration depth may not capture the effect of interlocking features.</p><p>As shown in Sec. 6, in practice our force model generates forces that create a realistic perception of roughness for object-object interaction; however, one essential limitation of penalty-based methods and impedance-type haptic devices is the inability to enforce motion constraints. Our force model attempts to do so by increasing tangential contact stiffness when the gradient of penetration depth is high. Implicit integration of the motion of the probe object allows for high stiffness and, therefore, small interpenetrations, but the perceived stiffness of rigid contact is limited through virtual coupling for stability reasons. New constraint-based haptic rendering techniques and perhaps other haptic devices <ref type="bibr" target="#b21">[22]</ref> will be required to properly enforce constraints.</p><p>A very important issue in every force model for haptic rendering is its stability. Choi and Tan <ref type="bibr" target="#b2">[3]</ref> have shown that even passive force models may suffer from a problem called aliveness. In our algorithm, discontinuities in the collision detection between lowresolution models are possible sources of aliveness.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2">Frequency and Sampling Issues</head><p>As with other sample-based techniques, our haptic texture rendering algorithm is susceptible to aliasing problems. Here we discuss different aliasing sources and suggest some solutions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Input textures:</head><p>The resolution of input textures must be high enough to capture the highest spatial frequency of input models, although input textures can be filtered as a preprocessing step to downsample and reduce their size.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Image-based computation:</head><p>In the height function computation step, buffer resolution must be selected so as to capture the spatial frequency of input models. Buffer size, however, has a significant impact in the performance of force computation.</p><p>Discrete derivatives: Penetration depth may not be a smooth function. This property results in an infinitely wide frequency spectrum, which introduces aliasing when sampled. Differentiation aggravates the problem, because it amplifies higher frequencies. The immediate consequence in our texture rendering approach is that the input texture frequencies have to be low enough so as to represent faithfully their derivatives. This limitation is common to existing point-based haptic rendering methods <ref type="bibr" target="#b17">[18]</ref> as well.</p><p>Temporal sampling. Force computation undergoes temporal sampling too. The Nyquist rate depends on object speed and spatial texture frequency. Image-based filtering prior to computation of penetration depth may remove undesirable high frequencies, but it may also remove low frequencies that would otherwise appear due to the nonlinearity of the max search operation. In other words, filtering a texture with very high frequency may incorrectly remove all torque and tangential forces. Temporal supersampling appears to be a solution to the problem, but is often infeasible due to the high update rates required by haptic simulation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">CONCLUSION</head><p>We have introduced a new haptic rendering algorithm for displaying interaction between two textured models, based on localized directional penetration depth and its gradient. We have also presented an image-based implementation on programmable graphics hardware that enables interactive haptic display between complex textured models for the first time. We have further shown that, using a coarse geometric representation with haptic textures that encode fine surface details, it is possible to render contact forces and torques between two interacting textured models at haptic rates.</p><p>Several possible directions for future research remain, including but not limited to:</p><p>• Interactive haptic texture synthesis;</p><p>• Addition of constraint forces for fine motion and dexterous manipulation;</p><p>• Further analysis of human factors. Finally, we would like to integrate our haptic rendering system with different applications, such as assisted technology, surgical training, and virtual prototyping.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :</head><label>2</label><figDesc>Definitions of Penetration Depth. (a) Intersecting objects A and B, (b) global penetration depth δ , and (c) directional penetration depth δ n along n.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 :</head><label>3</label><figDesc>Penetration Depth of Height Fields. Directional penetration depth of surface patches expressed as height difference.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4 :</head><label>4</label><figDesc>Approximate Height Function. Height function of a surface patch approximated by a composite mapping function.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 5 :</head><label>5</label><figDesc>Tiling in the GPU. Tiling of multiple height functions and contacts to minimize context switches between target buffers.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 6 :</head><label>6</label><figDesc>Benchmark Models. From left to right: (a) textured blocks, (b) block and gear, (c) hammer and torus, (d) file and CAD part.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 7 :</head><label>7</label><figDesc>Roughness under Translation. Position and force profiles generated while translating the model of a textured block in contact with a gear model, as shown inFig. 6-b. Notice the staircase like motion in z, and the correlation between force and position changes.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 8 :</head><label>8</label><figDesc>Roughness under Rotation. Motion profile obtained by rotating one textured block on top of another one, as depicted in Fig. 6-a. Notice the translation induced by the interaction of ridges during the rotational motion.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 9 :</head><label>9</label><figDesc>Timings. Performance analysis and number of clustered contact patches during 500 simulation frames of a file model scraping a CAD part, as shown inFig. 6-d. In this complex contact scenario we are able to maintain a haptic frame rate between 100Hz and 200Hz.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc></figDesc><table /><note>Complexity of Benchmark Models. Number of triangles at full resolution (Full Res. Tris) and low resolution (Low Res. Tris), and number of convex pieces at low resolution (Low Res. Pcs).</note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">Actually, the height of the offset surface is the distance to the surface along a particular direction, so the distance to the boundary of the Minkowski sum must also be measured along a particular direction. This is known to be the directional penetration depth.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">Note that, since we use central differencing to compute partial derivatives of δ n , we need to transform object A to two different configurations and recompute δ n . All together we compute δ n itself and 5 partial derivatives, hence 11 configurations<ref type="bibr" target="#b3">4</ref> We denote the height difference at the actual object configuration by ∆ĥ(0), and the height differences at the transformed configurations by ∆ĥ(±∆u), ∆ĥ(±∆v), ∆ĥ(±∆θ u ), ∆ĥ(±∆θ v ) and ∆ĥ(±∆θ n ).<ref type="bibr" target="#b4">5</ref> http://www.nvidia.com/dev content/nvopenglspecs/GL NV occlusion query.txt</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS</head><p>This research is supported in part by a fellowship of the Government of the Basque Country, National Science Foundation, Office of Naval Research, U.S. Army Research Office, and Intel Corporation. We would like to thank Roberta Klatzky, Susan Lederman, Dinesh Manocha, Russ Taylor, Fred Brooks, Mark Foskey, Bill Baxter, the UNC Gamma group and the anonymous reviewers for their feedback on the earlier drafts of this paper.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A two-port framework for the design of unconditionally stable haptic interfaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">J</forename><surname>Adams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Hannaford</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of IEEE/RSJ International Conference on Intelligent Robots and Systems</title>
		<meeting>of IEEE/RSJ International Conference on Intelligent Robots and Systems</meeting>
		<imprint>
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">A Subdivision Algorithm for Computer Display of Curved Surfaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edwin</forename><forename type="middle">E</forename><surname>Catmull</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1974-12" />
		</imprint>
		<respStmt>
			<orgName>Dept. of CS, U. of Utah</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">PhD thesis</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Aliveness: Perceived instability from a passive haptic texture rendering system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">Z</forename><surname>Tan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of IEEE/RSJ International Conference on Intelligent Robots and Systems</title>
		<meeting>of IEEE/RSJ International Conference on Intelligent Robots and Systems</meeting>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Appearance preserving simplification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Olano</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Manocha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACM SIGGRAPH</title>
		<meeting>of ACM SIGGRAPH</meeting>
		<imprint>
			<date type="published" when="1998" />
			<biblScope unit="page" from="115" to="122" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Computing the intersection-depth of polyhedra</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Dobkin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hershberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kirkpatrick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Suri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Algorithmica</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="518" to="533" />
			<date type="published" when="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">New distances for the separation and penetration of objects</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">G</forename><surname>Gilbert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">J</forename><surname>Ong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of International Conference on Robotics and Automation</title>
		<meeting>International Conference on Robotics and Automation</meeting>
		<imprint>
			<date type="published" when="1994" />
			<biblScope unit="page" from="579" to="586" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Fast computation of database operations using graphics processors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">K</forename><surname>Govindaraju</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Lloyd</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">C</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Manocha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACM SIGMOD</title>
		<meeting>of ACM SIGMOD</meeting>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Ruler, compass and computer: the design and analysis of geometric algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">J</forename><surname>Guibas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Stolfi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NATO ASI Series F</title>
		<editor>R. A. Earnshaw</editor>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="page" from="111" to="165" />
			<date type="published" when="1988" />
			<publisher>Springer-Verlag</publisher>
		</imprint>
	</monogr>
	<note>Theoretical Foundations of Computer Graphics and CAD</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A new computational model of friction applied to haptic rendering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Hayward</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Armstrong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Experimental Robotics VI</title>
		<imprint>
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Efficient point-based rendering techniques for haptic display of virtual objects</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-H</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Basdogan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Srinivasan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Presence</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="477" to="491" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Six degree of freedom haptic rendering of complex polygonal models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Willemsen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of Haptics Symposium</title>
		<meeting>of Haptics Symposium</meeting>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Efficient algorithms for computing two measures of depth of collision between convex polygons</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">S</forename><surname>Keerthi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Sridharan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1989" />
		</imprint>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">DEEP: an incremental algorithm for penetration depth computation between convex polytopes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Manocha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of IEEE Conference on Robotics and Automation</title>
		<meeting>of IEEE Conference on Robotics and Automation</meeting>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="921" to="926" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Fast penetration depth computation for physically-based animation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Otaduy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Manocha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACM Symposium on Computer Animation</title>
		<meeting>of ACM Symposium on Computer Animation</meeting>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Six-degreeof-freedom haptic rendering using incremental and localized computations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">J</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Otaduy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">C</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Manocha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Presence</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="277" to="295" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Perceiving texture through a probe</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">L</forename><surname>Klatzky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Lederman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Touch in Virtual Environments, chapter 10</title>
		<editor>M. L. McLaughlin, J. P. Hespanha, and G. S. Sukhatme</editor>
		<meeting><address><addrLine>Upper Saddle River, NJ</addrLine></address></meeting>
		<imprint>
			<publisher>Prentice Hall PTR</publisher>
			<date type="published" when="2002" />
			<biblScope unit="page" from="180" to="193" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Six degree-of-freedom haptic rendering using voxel sampling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Mcneely</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Puterbaugh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Troy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACM SIGGRAPH</title>
		<meeting>of ACM SIGGRAPH</meeting>
		<imprint>
			<date type="published" when="1999" />
			<biblScope unit="page" from="401" to="408" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Computational Haptics: The Sandpaper System for Synthesizing Texture for a Force-Feedback Display</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Minsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Thesis work done at UNC-CH Computer Science</title>
		<imprint>
			<publisher>MIT</publisher>
			<date type="published" when="1995" />
		</imprint>
	</monogr>
	<note type="report_type">PhD thesis</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Feature detection for haptic exploration with robotic fingers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">M</forename><surname>Okamura</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">R</forename><surname>Cutkosky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Robotics Research</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="925" to="938" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Sensation preserving simplification for haptic rendering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Otaduy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">C</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACM SIG-GRAPH)</title>
		<meeting>of ACM SIG-GRAPH)</meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="543" to="553" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">A perceptually-inspired force model for haptic texture rendering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Otaduy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">C</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of Symposium APGV</title>
		<meeting>of Symposium APGV</meeting>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Peshkin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">E</forename><surname>Colgate</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cobots. Industrial Robot</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="335" to="341" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">A framework for multi-contact multi-body dynamic simulation and haptic display</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ruspini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Khatib</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of IEEE/RSJ International Conference on Intelligent Robots and Systems</title>
		<meeting>of IEEE/RSJ International Conference on Intelligent Robots and Systems</meeting>
		<imprint>
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Making graphics physically tangible</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">K</forename><surname>Salisbury</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">8</biblScope>
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Texture mapping progressive meshes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">V</forename><surname>Sander</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Snyder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Gortler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Hoppe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACM SIGGRAPH</title>
		<meeting>of ACM SIGGRAPH</meeting>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="page" from="409" to="416" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Haptic textures -a stochastic approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Siira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">K</forename><surname>Pai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of IEEE International Conference on Robotics and Automation</title>
		<meeting>of IEEE International Conference on Robotics and Automation</meeting>
		<imprint>
			<date type="published" when="1996" />
			<biblScope unit="page" from="557" to="562" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Quasi-static approximation for 6 degrees-of-freedom haptic rendering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">A</forename><surname>Mcneely</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of IEEE Visualization</title>
		<meeting>of IEEE Visualization</meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="257" to="262" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
