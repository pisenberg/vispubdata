<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/pisenberg/grobid/grobid-0.6.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Integrated Volume Compression and Visualization</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tzi-Cker</forename><surname>Chiueh</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Experimental Computer System laboratory Taosong He Bell Laboratories of Lucent Technologies Hanspeter Pfister Mitsubishi Electric Research Laboratory</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chuan-Kai</forename><surname>Yang</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Experimental Computer System laboratory Taosong He Bell Laboratories of Lucent Technologies Hanspeter Pfister Mitsubishi Electric Research Laboratory</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arie</forename><surname>Kaufman</surname></persName>
							<affiliation key="aff1">
								<orgName type="department" key="dep1">Center for Visual Computing</orgName>
								<orgName type="department" key="dep2">Deparment of Computer Science State University of New York at Stony Brook Stony Brook</orgName>
								<address>
									<postCode>11794-4400</postCode>
									<region>NY</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Integrated Volume Compression and Visualization</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2021-02-19T20:35+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>I.3.8 [Computer Graphics]: Applications; I.4.5 [Image Processing]: Reconstruction Volume Compression</term>
					<term>Fourier Projection Theorem</term>
					<term>Discrete Hartley Transform</term>
					<term>Image Compositing</term>
				</keywords>
			</textClass>
			<abstract>
				<p>Volumetric data sets require enormous storage capacity even at moderate resolution levels. The excessive storage demands not only stress the capacity of the underlying storage and communications systems, but also seriously limit the speed of volume rendering due to data movement and manipulation. A novel volumetric data visualization scheme is proposed and implemented in this work that renders 2D images directly from compressed 3D data sets. The novelty of this algorithm is that rendering is performed on the compressed representation of the volumetric data without pre-decompression. As a result, the overheads associated with both data movement and rendering processing are significantly reduced. The proposed algorithm generalizes previously proposed whole-volume frequencydomain rendering schemes by first dividing the 3D data set into subcubes, transforming each subcube to a frequency-domain representation, and applying the Fourier Projection Theorem to produce the projected 2D images according to given viewing angles. Compared to the whole-volume approach, the subcube-based scheme not only achieves higher compression efficiency by exploiting local coherency, but also improves the quality of resultant rendering images because it approximates the occlusion effect on a subcube by subcube basis.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>With the advent of 3D medical imaging devices such as Computer Tomography (CT), Nuclear Magnetic Resonance (NMR), and 3D ultrasound systems, more and more medical diagnostic data are now represented in a volumetric format. Meanwhile, scientists and researchers develop a large variety of computational models to study and understand various physical phenomenon. Results from these numerical simulations typically reflect certain aspects of the underlying physical world and therefore inherently exhibit a 3D structure. An important characteristic of volumetric data sets is their very large storage requirements. As an example, a 1024x1024x1024 volume with each voxel represented by 24 bits will require 3 Gbytes of storage space. Excessive storage demands exact the underlying I/O and communications subsystems, as well as lengthen the end-to-end rendering delay. Compression is one possible solution toward this problem.</p><p>Although faster CPUs help mitigate the overhead associated with compression/decompression, the compressed data set, when explicitly decompressed, still incurs significant data movement overhead on the memory bus (not I/O bus), which is proportional to the size of the uncompressed data set. Because the performance of modern RISC processors is critically dependent upon the reduction of main memory traffic, it is essential to maintain the data in the compressed form as long as possible. This paper proposes an algorithm that performs volume rendering directly on compressed data sets, thus avoiding the decompression step at run time and its associated performance overhead.</p><p>This algorithm is a generalization of whole-volume frequencydomain 3D rendering algorithm independently developed by Dunne, Napel, and Rutt <ref type="bibr" target="#b0">[DNR90]</ref>, and Malzbender and Kitson <ref type="bibr" target="#b5">[MK93,</ref><ref type="bibr" target="#b4">Mal93]</ref>, both of which in turn are based on the Fourier Projection Theorem. We take a cube-based approach by first subdividing the data volume into subcubes, then applying a Fourierlike transform to each of these subcubes, and finally quantizing the resulting coefficients according to the dynamic range of the coefficient values in the subcubes. To implement spatial-domain ray casting <ref type="bibr" target="#b11">[Sab88]</ref>, we apply the Fourier Projection Theorem on the quantized frequency-domain representation of each subcube, and perform spatial-domain compositing by treating each subcube as an indivisible macro-voxel with its aggregate opacity and intensity values.</p><p>None of the previous works <ref type="bibr" target="#b7">[NH92,</ref><ref type="bibr" target="#b8">NH93,</ref><ref type="bibr" target="#b15">YL95,</ref><ref type="bibr" target="#b1">FY94]</ref> in this area allows direct rendering from compressed data without decompression. Compared to these efforts, the proposed integrated volume compression and visualization algorithm exhibits the following two advantages:</p><p>High compression efficiency: Transform coding compacts the energy of the spatial-domain signal to few transform-domain coefficients. Consequently, higher compression efficiency is expected compared to other compression approaches. In addition, the proposed subcube-based approach can exploit the coherency in local regions more effectively than the wholevolume approach [DNR90] <ref type="bibr" target="#b4">[Mal93]</ref> and therefore attain better compression ratio.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Better rendering quality:</head><p>The image quality of whole-volume frequency-domain volume rendering is usually poor because it simulates the interaction between light and voxels by a simple line integral along the view direction across the volume. The result is essentially a X-ray-like image without any occlusion effects. Totsuka and Levoy <ref type="bibr" target="#b12">[TL93]</ref> proposed a linear approximation to the exponential attenuation <ref type="bibr" target="#b11">[Sab88]</ref> and an alternative shading model to fit the computation within the frequency-domain rendering framework. Although their images show improved visual depth cues, the effect of the linear attenuation model and the lack of occlusion is still noticeable.</p><p>We address these problems by first applying the Fourier Projection Theorem on a subcube-by-subcube basis to derive the aggregate intensity and opacity values for each subcube; then we use spatial compositing (e.g., <ref type="bibr" target="#b2">[Lev88,</ref><ref type="bibr" target="#b14">Wes90]</ref>) to combine these intensity and opacity values according to an exponential attenuation model <ref type="bibr" target="#b11">[Sab88]</ref>. The resulting images thus show improved occlusion and attenuation effects.</p><p>The rest of this paper is organized as follows. In Section 2, the basic algorithm for volume data compression is presented. In Section 3, the concept of Fourier volume rendering is introduced and the proposed compression-domain volume rendering algorithm is described in detail. That section also presents different possibilities of generating occlusion effects and non-linear attenuation in subcube-based frequency domain rendering. The results are presented in Section 4. Section 5 concludes this paper by summarizing the main results and outlining plans for future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">VOLUME DATA COMPRESSION</head><p>The proposed volume data compression algorithm is based on transform coding and is actually a generalization of the JPEG still image compression algorithm <ref type="bibr" target="#b13">[Wal91]</ref> to the 3D case, with one important exception: the transform is a discrete Fourier transform rather than a discrete cosine transform (DCT). </p><formula xml:id="formula_0">Fu; v; w = 1 M 3 M , 1 X x =0 M,1 X y=0 M,1 X z=0 fx;y; ze ,2i xu+yv+zw M</formula><p>(1) For simplicity and without loss of generality we assume that N is an integral multiple of M. Each of the 3D Fourier coefficients in each subcube is then quantized using the equation</p><formula xml:id="formula_1">F Q u; v; w = R ound Fu; v; w Qu; v; w (2)</formula><p>where Qu; v; w is the quantization table entry corresponding to Fu; v; w and represents the quantization step. The resulting 3D quantized frequency coefficients within a cube are organized as a linear sequence through a 3D zig-zag order. A 3D zig-zag order through a cube is the traversal order in which u1; v 1 ; w 1 precedes u2; v 2 ; w 2 if u1 + v1+w1 u 2 + v 2 + w 2 , and the u; v; w tuples on the plane u + v + w = K follow a 2D zig-zag order. The resulting linear sequence of Fourier transform coefficients is fed into an entropy encoder that in turn consists of run-length coding and Huffman coding. Decompression is done by reversing the above process.</p><p>Because the above compression algorithm is based on transform coding, it is inherently lossy. Most of the compression gain is realized by the quantization step, with subsequent steps corresponding to a lossless compression scheme. In fact, manipulating the contents of the quantization table is the most effective way of making the tradeoff between compression ratios and reconstruction errors. As for the compression/decompression overhead, the entropy encoding step involves only table look-up and bit compaction/expansion and therefore accounts for a small portion of the overall delay. Because the entropy encoding step plays a rather minor role in the space and time performance of the proposed volume compression scheme, we will use the term compressed volume data to refer to the sets of quantized 3D Fourier coefficients from the subcubes of a volume data set.</p><p>In the case of JPEG, a recommended set of quantization tables have been developed through extensive testing and measurements of a large number of images. Because there isn't much previous research on volume data compression, a theoretical understanding of a good choice of Qu; v; w 0 s in Equation 2, i.e., the entries in the quantization table, is still lacking. Ideally it is preferable to take advantage of the varying perceptive significance of different frequency coefficients by allocating to each of them a different number of bits. For example, <ref type="table">Table 1</ref> shows the variance distribution of the 3D Fourier coefficients using 4x4x4 cubes as basic units. The fact that few coefficients have a much larger magnitude than the others demonstrate the energy concentration capability of transform coding. Presumably one could base each coefficient's number of representation bits on the size of its corresponding variance. However, the fact that our experience in the interaction between volume rendering and volume data compression is rather limited forces us to adopt a simpler approach.</p><p>In our implementation we use the same quantization step Qu; v; w for all coefficients in a subcube. We calculate the dynamic range Ri of coefficients in each subcube i as</p><formula xml:id="formula_2">Ri = jmax valuei , min valueij (3)</formula><p>where max valuei and min valuei are the maximum and minimum AC coefficient values of the i-th subcube, respectively. The quantization step for the i-th subcube is then chosen to be Qu;</p><formula xml:id="formula_3">v; w = R i 2 c ; u,v,w = 0, 1,..., M -1<label>(4)</label></formula><p>with c being a fixed constant. We found that the total Mean Square Error, defined as  was acceptable for c 10, where E is the expectation operator. <ref type="table" target="#tab_2">Table 2</ref> shows the compression ratios for different subcube sizes using the above quantization strategy.</p><formula xml:id="formula_4">MSQE = E Fu; v; w , F Q u; v; w 2<label>(5)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">RENDERING FROM COMPRESSED VOLUME</head><p>Given the compressed volume data, i.e., the Fourier coefficients of the volume's subcubes, one can apply the Fourier Projection Theorem to compute the projection image of each subcube, and performs a spatial-domain compositing by treating each subcube as a macro-voxel with its own color and opacity values derived from the projection image. <ref type="figure">Figure 2</ref> shows the basic rendering process.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Generation of Subcube Projection Image</head><p>To derive a subcube's projection image from its compressed representation, we use a new class of volume rendering algorithms <ref type="bibr" target="#b0">[DNR90,</ref><ref type="bibr" target="#b5">MK93,</ref><ref type="bibr" target="#b4">Mal93,</ref><ref type="bibr" target="#b3">Lev92,</ref><ref type="bibr" target="#b12">TL93]</ref> that are based on the Fourier Projection Theorem, which was originally developed for Computer Tomography (CT) 3D reconstruction.</p><p>To facilitate the exposition of the theorem <ref type="bibr" target="#b6">[MO74]</ref>, we start with the 2D case and then generalize the theorem to the 3D case. Given a 2D spatial distribution fx;y, the 1D projection of fx;y along a line specified as x cos + y sin = R is a line integral and is </p><formula xml:id="formula_5">F ; = F 1D g ;R<label>(10)</label></formula><p>where F1D represents a 1D Fourier transform operator. In other words, the 1D Fourier transform of a 1D projection of fx;y along the direction specified by the angle , is a 1D line across the center of the 2D Fourier transform of fx;y whose normal vector is along the direction specified by the angle . The generalization of this theorem to the 3D case is straightforward: The 2D Fourier transform of a 2D projection of a 3D distribution fx; y; z along the direction specified by the angle , is a 2D plane across the center of the 3D Fourier transform of fx;y; z whose normal vector is along the direction specified by the angle .</p><p>Discrete cosine transform (DCT) exhibits better energy compaction properties and is used in the JPEG still picture compression standard <ref type="bibr" target="#b10">[RY90,</ref><ref type="bibr" target="#b13">Wal91]</ref>. However, the fact that the DCT does not possess the separability property, i.e., cosx cosy cosz 6 = cosx + y + z (11) prevents a DCT-based projection theorem. In the above derivation we make use of this property to go from Equation 7 to Equation 8, but it no longer holds if the transform used is a DCT.</p><p>The Fourier Projection Theorem also applies to discrete Hartley transform (DHT). The 3D DHT is defined as where S is 1 N 3 for the forward and 1 for the inverse transform.</p><formula xml:id="formula_6">Hu; v; w = S P N , 1 x =0 P N,1 y=0 P N,1 z=0 fx;y; z cos2 ux+vy+wz N + sin2 ux+vy+wz N<label>(12)</label></formula><p>Because the DHT requires only real and no imaginary number manipulation and assumes the same format for forward and reverse transformations, it is used in our algorithm implementation.</p><p>To apply the Fourier Projection Theorem in the context of the proposed algorithm, we need to address the following two issues. First, the original formulation is in the continuous domain whereas our algorithm is supposed to work in the discrete domain. Second, because our algorithm applies the Fourier Projection Theorem on a subcube by subcube basis, it is critical to eliminate the aliasing effect around the boundary region of the subcube's projection image. <ref type="figure">Figure 3</ref> shows how a subcube in the original data volume evolves before its projection image is generated. Before being transformed into the frequency-domain representation, an nnn subcube is first expanded into n + 2 n + 2 n + 2 subcube by including voxels from its neighboring subcubes. In the case of boundary subcubes, zero padding is assumed. This expansion provides overlap between the projection images from neighboring subcubes so that during spatial-domain compositing those rays that traverse through the boundaries of subcubes always have the same number of projection values for interpolation as the other rays. Then each subcube is zero-padded and grows to n + 2 + Z n + 2 + Z n + 2 + Z . This zero padding provides a protection zone for the original data against aliasing, which tends to degrade the boundary region. In the course of applying the Fourier Projection Theorem, a slice of the dimension 2n + 2 + Z 2n + 2 + Z is extracted from the n + 2 + Z n+2+Z n+2+Z frequency subcube, with zero filled in those pixels that are not defined in the subcube. The reason that the extracted slice is twice the size along each dimension is to accommodate the fact that the projection image along a non-orthonormal direction is larger than those along the orthonormal directions, which are of the same dimension as the subcube.</p><p>For example, the support of a 1D projection across a X X 2D block is X if the projection angle is orthonormal, i.e., multiples of 1 2 . However, if the projection angle is non-orthonormal, say 1 4 ,</p><p>then the support of the 1D projection is p 2X. It can be shown that doubling the dimension of the extracted slice is sufficient to accommodate all possible projection angles.</p><p>Because zero padding in the frequency domain corresponds to super-sampling in the spatial domain, the subcube's projection image is computed by taking a 2D inverse transform of the extracted slide every other sampling point along each dimension, and the resultant dimension is n+ 2 + Zn+2+Z. Next a post-filtering step is applied to this projection image to eliminate the aliasing effect and arrive at a n + 2 n + 2 image, of which only the n n portion is contributed by the subcube itself.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Summation of Subimages</head><p>The proposed compression scheme applies the Fourier Projection Theorem not on the whole volume but on individual subcubes. In this section we show that the summation of the resulting subimages is equivalent to whole-volume frequency domain rendering, and the next section describes how spatial compositing between subimages can include the occlusion effect through opacity transfer functions.</p><p>To simplify the explanation, we again describe the algorithm in the context of 2D images. From 2D to 3D, it is just a straightforward generalization. In <ref type="figure" target="#fig_3">Figure 4 (a)</ref>, a rectangular 2D image I is projected along the direction represented by the arrows. According to the Fourier Projection Theorem, the projection of I along the projection angle is a 1D signal, which is the inverse Fourier transform of the line that crosses the center of the 2D Fourier transform of I also at the angle . Mathematically,</p><formula xml:id="formula_7">PI = F , 1 X F I (13)</formula><p>where the X operator means extracting the line that crosses the </p><p>where PL a; f represents a point in the 1D signal PI. Similarly, one can view PL a; b as a point in the projection of the subimage SI01, i.e., in PSI01, and the same interpretation applies to the other segments of L. Because both Fourier transform and the projection operation are linear operators, PI can thus be rewritten as</p><formula xml:id="formula_9">PI = N X i=0 M X j=0 PSIij = N X i=0 M X j=0 F ,1 XF SIij<label>(15)</label></formula><p>where N and M equal three in our example, but in general they depend on how the image is decomposed into blocks. What Equation 15 says is that one can apply the Fourier Projection Theorem to each of the subimages and sum the projections up, to compute the projection of a 2D image.</p><p>In the 3D case we cast a 2D array of rays into the data volume along the view angle to get the projected image. <ref type="figure" target="#fig_3">Figure 4 (b)</ref> shows a viewing ray Rt perpendicular to the view plane intersecting the image planes of the subcubes at points P1 through P4. Each image plane is generated using the Fourier Projection Theorem on the subcube, and the sum of all projected intensities P 4 i=1 Pi is equivalent to the projection of the whole data volume along the ray Rt.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Compositing of Subimages</head><p>Most contemporary volume rendering algorithms use more sophisticated modulation schemes that take into account the physical affects of light absorption, scattering, and shading <ref type="bibr" target="#b11">[Sab88]</ref>. Let us assume that each voxel of the data volume is characterized by a density x; y; z and a color value x; y; z such that the voxel can emit light with an energy of per unit length and can absorb light with an opacity of per unit length, where is the attenuation constant. Consider a viewing ray Rt that shoots through the data volume and is parameterized by t with Ra and Rb as the start and end points. If one ignores the scattering effect, the total energy arriving at Rb due to emission and absorption along the ray from Ra to Rb is given by</p><formula xml:id="formula_10">I Rb = b Z a Rt Rte , R t a R u du dt (16)</formula><p>If one simplifies the illumination model further by ignoring the absorption effect, then the equation is reduced to</p><formula xml:id="formula_11">I Rb = b Z a Rt Rtdt (17)</formula><p>This can be computed by directly applying the Fourier Projection Theorem because each projection image pixel is the result of a line integration along the viewing ray. However, the Fourier Projection Theorem cannot be applied to Equation 16 because of the exponential attenuation term in the integral. Levoy <ref type="bibr" target="#b3">[Lev92]</ref> proposed to approximate the exponential attenuation mechanism with the firstorder term of its Taylor expansion by changing Equation 16 to</p><formula xml:id="formula_12">I Rb = b Z a Rt Rt 1 , Rat , a dt (18)</formula><p>Based on Equation 18, the absorption effect is simulated using three additional volumes each voxel of which is pre-multiplied with its X, Y, and Z coordinates respectively before applying the 3D forward Fourier transform <ref type="bibr" target="#b3">[Lev92]</ref>. Unfortunately this approach requires four times as much storage overhead compared to spatial-domain rendering schemes, aggravating the already serious storage problem of volume datasets.</p><p>A subsequent paper by Totsuka and Levoy <ref type="bibr" target="#b12">[TL93]</ref> described frequency-domain rendering methods with depth cueing and directional shading using a linear approximation to the Lambertian reflection model that require only one copy of the dataset. The quality of the resultant images is not particularly good compared to volume rendering of the spatial domain representation. The reason is that the first-order approximation to the exponential absorption function, although greatly simplifying computation, significantly distorts the attenuation effects of the original illumination model. In addition, this technique cannot be applied to arbitrary opacity transfer functions.</p><p>The proposed approach applies block-by-block compositing based on the projection subimages that are derived through the Fourier Projection Theorem from each subcube. That is, given the line integrals along the viewing rays for each subcube, how should the aggregate color and opacity values contributed by each subcube be calculated so that each subcube can be treated as a macro-voxel for spatial-domain compositing? The attenuation among consecutive voxels along a ray is modeled using a spatial compositing approximation to Equation 16 <ref type="bibr" target="#b9">[PD84]</ref>. The discrete front-to-back compositing formula is defined as:</p><p>Cacc;out = 1 , Oacc;inCvOv + Cacc;in <ref type="bibr">(19)</ref> Oacc;out = 1 , Oacc;inOv + Oacc;in <ref type="bibr">(20)</ref> where Ov and Cv represent the absorption and emission parameters for the voxel v, and Cacc;in (Oacc;in ) and Cacc;out (Oacc;out ) represent the accumulative color (opacity) values into and out of the voxel, respectively. Ov and Cv are usually derived from the voxel's raw data value through a color and a opacity transfer function.</p><p>To treat each subcube as a macro-voxel, one needs to compute the aggregate color and opacity values contributed by each subcube. From Equations 19 and 20, the aggregate color contributed by a subcube that intersects with a projection ray is</p><formula xml:id="formula_13">Csubcube = n X i=1 Ci Oi i,1 Y j=1 1 , Oj (21)</formula><p>where we assume there are n voxels on the projection ray that fall within the given subcube. Similarly the aggregate opacity contributed by such a subcube is</p><formula xml:id="formula_14">Osubcube = 1 , n Y i =1 1 , Oi (22)</formula><p>However, the only information about each subcube after the application of the Fourier Projection Theorem is the line integrals through the subcube along the projection angle, that is,</p><formula xml:id="formula_15">P n i=1 Di,</formula><p>where Di is the raw data value associated with the i-th voxel. When the opacity transfer function assumes a negative exponential form:</p><formula xml:id="formula_16">Oi = 1 , e , K D i (23)</formula><p>then it can be shown that Osubcube can be computed exactly from P n i=1 Di as follows:</p><formula xml:id="formula_17">Osubcube = 1 , e , K P n i =1 D i (24)</formula><p>For arbitrary opacity transfer functions, the only way to reconstruct</p><p>Osubcube exactly is to prepare a second volume from the original data volume by applying the following transformation to each voxel:</p><formula xml:id="formula_18">Dnew; i = log1 , ODi (25)</formula><p>where O is any chosen opacity transfer function. Unfortunately, this approach is only applicable if the opacity transfer function is fixed, i.e., no interactive classification.</p><p>To allow the flexibility of changing the opacity transfer function interactively at run time, we choose the following method to approximate Osubcube given P n i=1 Di. The basic idea is to assume that the voxel values within a subcube are reasonably close to each other so that one can use the average values for each of the voxels along the ray.</p><formula xml:id="formula_19">Let Davg = P n i=1 D i n .</formula><p>By substituting Davg for every voxel in Equation 22, we get</p><formula xml:id="formula_20">Osubcube = 1 , 1 , ODavg n (26)</formula><p>where O is the chosen opacity transfer function The smaller the subcube is, the more accurate this approximation of Osubcube is.</p><p>The aggregate color contributed by a subcube, Csubcube, can be derived through two possible approaches. If the color transfer function is linear with respect to the raw voxel value, i.e., Ci = K Di, which is the case most of the time, the aggregate color can be approximated by ignoring the attenuation due to voxels within the subcube:</p><formula xml:id="formula_21">Csubcube = K n X i=1 Di<label>(27)</label></formula><p>When opacity is discounted, e.g., X-ray-like projections, this approximation method is preferable. Alternatively, one can apply the same idea of using the average value for every voxel on the ray and plugging it into Equation 21:</p><formula xml:id="formula_22">Csubcube = CDavg ODavg 1 , 1 , ODavg n ODavg (28)</formula><p>In this case, the color transfer function C doesn't have to be linear with respect to the raw data. Again the smaller the subcube is, the more accurate this approximation of Csubcube is.</p><p>Given the aggregate color and opacity approximations for each subcube from its projection sums, we then apply subcube-bysubcube spatial domain compositing using the following equations:</p><p>Cacc;out = 1 , Oacc;inCsubcube + Cacc;in (29) Oacc;out = 1 , Oacc;inOsubcube + Oacc;in <ref type="bibr">(30)</ref> where Cacc;in, Cacc;out, Oacc;in and Oacc;out are with respect to a subcube, not a voxel. Note that Equation 29 is different from Equation 19 because the occlusion effect due to each voxel has been captured in the aggregate color calculation, and should not be repeated in subcube-level compositing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">RESULT</head><p>Compared to conventional voxel-by-voxel ray casting algorithms, the proposed compression domain rendering algorithm may introduce two sources of errors. First, the projection sums computed from the Fourier Projection Theorem may not be exact due to aliasing. This error may be significant since the aliasing effect tends to be more serious at the subcube boundaries, which in turn could be in the middle of the data volume. Secondly, the calculations of the subcube's aggregate color and opacity values from the projection sums are just approximations, which may lead to further deviation from the result of the ray casting algorithm.</p><p>All the reported measurements below are 2D mean square errors (MSE) from the head data set. <ref type="table" target="#tab_5">Table 3</ref> shows the average mean square errors between the projection sums derived from the Fourier Projection Theorem and those from spatial domain summing, for subcubes of different sizes from different viewing angles. The projection angles are specified in the second row in terms of multiples of . Mean square errors for orthonormal viewing angles are usually smaller than those for non-orthonormal ones, because nonorthonormal projections require interpolation for sample values on the rays, and thus tend to suffer more from aliasing. For a given non-orthonormal viewing angle, the mean square error increases as the subcube size decreases. This is because the MSE calculation tends to amplify the aliasing error, which in itself is independent of the subcube size, when the subcubes are smaller. For orthonormal viewing angles, such trends are less obvious, because most of the MSE in this case is mainly due to floating-point rounding. <ref type="table">Table 4</ref> shows the mean square errors between the rendered images computed from voxel-by-voxel ray casting and those from subcube-by-subcube compositing using the aggregate color and opacity values approximated from spatial-domain projection sums, for different opacity transfer functions and different viewing angles. The reason we choose spatial-domain rather than the projection sums calculated from the Fourier Projection Theorem is to isolate the errors due only to the aggregate color and opacity approxi-    <ref type="table">Table 4</ref>: The mean square errors between the rendered images using voxel-by-voxel ray casting and those from subcube-by-subcube compositing based on aggregate color and opacity approximation values, for different opacity transfer functions and viewing angles. The color values are normalized to the range between 0 and 255. value for K. As expected, the smaller the subcube, the smaller the MSE. MSEs for orthonormal projections are smaller than those for non-orthonormal, because the aliasing effect is less serious. Because the aggregate opacity approximation is exact when the opacity transfer function is exponential, the MSEs for the exponential opacity case are smaller than the MSEs for the linear opacity case.</p><p>To compare the rendered images from voxel-by-voxel ray casting and from the compression domain rendering algorithm, we render the head data set using the two algorithms under different opacity transfer functions. <ref type="figure">Figure 6</ref> and 9 show the rendered images using ray casting and compression domain rendering, assuming that there is no opacity, i.e., only X-ray effect. In this case, both the color and opacity approximation equations are exact, and therefore they look almost identical. <ref type="figure">Figure 7</ref> and 10 show the rendered images using ray casting and compression domain rendering, assuming an exponential opacity transfer function. In this case, the aggregate opacity approximation equation is exact, but the color opacity approximation equation is not. At the subcube size of 4 3 , the image from the proposed method is quite comparable to that from ray casting. <ref type="figure">Figure 8</ref> and 11 show the rendered images using ray casting and compression domain rendering, assuming a linear opacity transfer function, i.e., the opacity is linearly proportional to the data density. In this case, neither the color nor the opacity approximation equation is exact. At the subcube size of 4 3 , the two rendered images still look comparable, although the difference is more significant compared to the exponential opacity case.</p><p>To understand how the difference arises between the rendered images from the proposed scheme and ray casting, we trace the set of voxels encountered by the rays that are responsible for the portion of the image that shows the most serious discrepancy. <ref type="figure" target="#fig_5">Figure  5</ref> shows a partial sequence of voxel values encountered by such a ray, and the average approximation for each subcube used by our approach. Because the voxel value sequence fluctuates noticeabaly within each subcube, the average approximations fail to capture the true ray casting computation. As a result, there is a significant difference in the final results produced by two methods for these rays.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">CONCLUSION</head><p>By applying the Fourier Projection Theorem on a subcube by subcube basis, and performing spatial-domain compositing by treating each subcube as an indivisible macro voxel, we have integrated volume data compression and volume rendering in a unified framework. The preliminary experiment results show both high compres-sion ratios and improved image quality over previous frequency domain rendering approaches.</p><p>There are several directions from this research that we are currently exploring. First, we are developing a strategy to choose the quantization table for a given data volume that produces the best compression ratio while maintaining the same reconstructed data quality. Secondly, we are examining the interaction between volume rendering and compression. In particular, we are interested in identifying the compression algorithm parameters to which the rendering algorithm is most sensitive. Thirdly, we are investigating the feasibility of using variable subcube size in the compression domain rendering algorithm, so as to exploit data-dependent optimization and achieve higher compression efficiency and better rendering quality. <ref type="figure">Figure 6</ref>: A ray-cast image of the head data set, using the X-ray-like opacity model. <ref type="figure">Figure 7</ref>: A ray-cast image of the head data set, using an exponential opacity transfer function. <ref type="figure">Figure 8</ref>: A ray-cast image of the head data set, using a linear opacity transfer function. <ref type="figure">Figure 9</ref>: A compression-domain rendered image of the head data set, using the X-ray-like opacity model. The subcube size is 4x4x4. <ref type="figure" target="#fig_0">Figure 10</ref>: A compression-domain rendered image of the head data set, using an exponential opacity transfer function. The subcube size is 4x4x4. <ref type="figure" target="#fig_0">Figure 11</ref>: A compression-domain rendered image of the head data set, using a linear opacity transfer function. The subcube size is 4x4x4.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>The data flows of the proposed volume (a) compression and (b) decompression algorithms.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1</head><label>1</label><figDesc>shows the data flow of the proposed compression/decompression algorithm. An N N N volume is decomposed into M M M subcubes, each of which first goes through a 3D discrete Fourier transform as follows:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :Figure 3 :</head><label>23</label><figDesc>) = (1 -O(in) )C + C(in) O(out) = (1 -O(in) )O + O(in) Integrated volume data compression and rendering. Each subcube is first independently Fourier-transformed. Then the projection image of each subcube is computed through the Fourier Projection Theorem. The final rendered image results from compositing the subcubes' projection images according to the view angle and opacity/color transfer functions. The evolution of a subcube as its projection image is generated through the Fourier Projection Theorem.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Summation of projection sums from (a) each block in the 2D case and (b) from each subcure in the 3D case along the viewing ray. center at angle . Now let us decompose the image into 16 subimages, SIij, where i; j = 0 ; 1 ; 2 ; 3 , and apply the Fourier Projection Theorem to each of them. Consider a particular projection ray, say L in the figure, and let us denote the line integral of I between a segment of L as PL m; n , where m and n represent points on L. By definition, PL a; f = PL a; b + PL b; c + PL c; d + PL d; e + PL e; f</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>mation scheme. The linear opacity transfer function, Oi = K Di, chooses K to be the inverse of the difference between the largest and smallest density values in the volume, whereas the exponential opacity transfer function, as defined in Equation 23, uses the same</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 5 :</head><label>5</label><figDesc>The sequence of voxel values encountered by a sample projection ray, as shown as the solid line, and the average approximation voxel value used for each subcube, as shown as the dashed line.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>Achievable compression efficiency for different datasets using different subcube size.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head></head><label></label><figDesc>Rwith a fixed stands for the projection of fx; y along the direction that is at an angle , 2 with respect to the X axis. To see how this is related to the 2D Fourier transform Fu; v of fx; y, we start with the definition</figDesc><table><row><cell cols="2">given by g;R =</cell><cell cols="3">Z Z</cell><cell>f x; y x cos + y sin , Rdxdy</cell></row><row><cell></cell><cell>=</cell><cell cols="2">2 Z</cell><cell>1 Z</cell><cell>fr; rcos , , R rd dr (6)</cell></row><row><cell></cell><cell></cell><cell>0</cell><cell></cell><cell>0</cell></row><row><cell cols="3">The term g;Fu; v =</cell><cell cols="2">Z Z</cell><cell>f x;ye ,i2ux e ,2vy dxdy</cell><cell>(7)</cell></row><row><cell cols="5">Expressing Fu; v in polar coordinates with u = cos ;v =</cell></row><row><cell cols="2">sin gives F ; =</cell><cell cols="3">Z Z</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>trans-</cell></row><row><cell>formed to</cell><cell></cell><cell></cell><cell></cell></row><row><cell>F ; =</cell><cell cols="4">Z Z Z</cell><cell>f x; y</cell></row><row><cell>=</cell><cell cols="4">x cos + y sin , Re ,i2 R dxdydR Z g ;Re ,i2 R dR</cell><cell>(9)</cell></row><row><cell>Therefore,</cell><cell></cell><cell></cell><cell></cell></row></table><note>f x;ye ,i2 xcos +y sin dxdy (8) By exploiting the property of a : function, this can be</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 3 :</head><label>3</label><figDesc>The average mean square errors between the projections derived from the Fourier Projection Theorem and those from spatial domain summing, for various viewing angles. The color values are normalized to the range between 0 and 255.</figDesc><table><row><cell>Subcube Size</cell><cell>0:5 0 1</cell><cell>Exponential 0 : 48 0:1 0 : 95</cell><cell>0:5 0 1</cell><cell>Linear 0 : 48 0:1 0 : 95</cell></row><row><cell>2 x 2 x 2</cell><cell>3.115</cell><cell>5.339</cell><cell>4.935</cell><cell>8.377</cell></row><row><cell>4 x 4 x 4</cell><cell>7.0699</cell><cell>8.001</cell><cell>9.129</cell><cell>10.560</cell></row><row><cell>8 x 8 x 8</cell><cell>10.870</cell><cell>12.698</cell><cell>12.699</cell><cell>14.958</cell></row><row><cell>16 x 16 x 16</cell><cell>16.775</cell><cell>17.314</cell><cell>18.397</cell><cell>19.402</cell></row><row><cell>32 x 32 x 32</cell><cell>25.781</cell><cell>26.089</cell><cell>27.778</cell><cell>28.321</cell></row><row><cell>64 x 64 x 64</cell><cell>32.750</cell><cell>37.336</cell><cell>34.579</cell><cell>39.601</cell></row></table><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgement</head><p>This research is supported by an NSF Career Award MIP9502067 and a contract 95F138600000 from Community Management Staff's Massive Digital Data System Program.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Fast reprojection of volume data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Dunne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Napel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Rutt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1st Conference on Visualization in Biomedical Computing</title>
		<meeting>the 1st Conference on Visualization in Biomedical Computing</meeting>
		<imprint>
			<date type="published" when="1990" />
			<biblScope unit="page" from="11" to="18" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Lossless compression of volume data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Fowler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Yagel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Visualization &apos;94</title>
		<meeting>Visualization &apos;94</meeting>
		<imprint>
			<date type="published" when="1994-10" />
			<biblScope unit="page" from="43" to="50" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Display of surfaces from volume data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Levoy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer Graphics &amp; Applications</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="29" to="37" />
			<date type="published" when="1988-05" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Volume rendering using the fourier projection-slice theorem</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Levoy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Graphics Interface &apos;92</title>
		<meeting>Graphics Interface &apos;92</meeting>
		<imprint>
			<publisher>Canadian Information Processing Society</publisher>
			<date type="published" when="1992" />
			<biblScope unit="page" from="61" to="69" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Fourier volume rendering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Malzbender</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Graphics</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="233" to="250" />
			<date type="published" when="1993-07" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A fourier technique for volume rendering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Malzbender</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Kitson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Focus on Scientific Visualization</title>
		<editor>H. Hagen, H. Müller, and G. M. Nielson</editor>
		<imprint>
			<publisher>Springer Verlag</publisher>
			<date type="published" when="1993" />
			<biblScope unit="page" from="305" to="316" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Digital reconstruction of multidimensional signals from their projections. Proceedings of the IEEE</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Mersereau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Oppenheim</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1974-10" />
			<biblScope unit="volume">62</biblScope>
			<biblScope unit="page" from="1319" to="1338" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Vector quantization for volume rendering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Ning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Hesselink</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1992 Workshop on Volume Visualization</title>
		<meeting>the 1992 Workshop on Volume Visualization</meeting>
		<imprint>
			<date type="published" when="1992-10" />
			<biblScope unit="page" from="69" to="74" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Fast volume renderign of compressed data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Ning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Hesselink</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Visualization &apos;93</title>
		<meeting>Visualization &apos;93</meeting>
		<imprint>
			<date type="published" when="1993-10" />
			<biblScope unit="page" from="11" to="18" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Porter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Duff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Compositing digital images. Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="1984-07" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Discrete Cosine Transform, Algorithms, Advantages</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">R</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Yip</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1990" />
			<publisher>Applications. Academic Press Inc</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">A rendering algorithm for visualizing 3D scalar data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Sabella</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">4</biblScope>
			<date type="published" when="1988-08" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Frequency domain volume rendering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Totsuka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Levoy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Graphics Proceedings, Annual Conference Series</title>
		<imprint>
			<date type="published" when="1993" />
			<biblScope unit="page" from="271" to="278" />
		</imprint>
	</monogr>
	<note>Proceedings of SIG-GRAPH 93</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">The JPEG still picture compression standard</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">K</forename><surname>Wallace</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="30" to="44" />
			<date type="published" when="1991-04" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Footprint evaluation for volume rendering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Westover</surname></persName>
		</author>
		<idno>Au- gust 1990</idno>
	</analytic>
	<monogr>
		<title level="m">Proc. SIGGRAPH &apos;90</title>
		<meeting>SIGGRAPH &apos;90</meeting>
		<imprint>
			<biblScope unit="volume">24</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Volume rendering of dct-based compressed 3d scalar data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B.-L</forename><surname>Yeo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="29" to="43" />
			<date type="published" when="1995-03" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
