<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/pisenberg/grobid/grobid-0.6.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A Comparison Of Normal Estimation Schemes</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Torsten</forename><surname>Möller</surname></persName>
							<email>mueller@cis.ohio-state.edu</email>
							<affiliation key="aff0">
								<orgName type="department">395 Dreese Lab</orgName>
								<address>
									<postCode>43210</postCode>
									<settlement>Columbus</settlement>
									<region>OH</region>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Department of Computer and Information Science</orgName>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="department">The Advanced Computing Center for the Arts and Design</orgName>
								<orgName type="institution">The Ohio State University</orgName>
								<address>
									<settlement>Columbus</settlement>
									<region>Ohio</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raghu</forename><surname>Machiraju</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">NSF Engineering Research Center for Computational Field Simulation</orgName>
								<address>
									<addrLine>Mississippi State</addrLine>
									<postBox>P.O. Box 9627</postBox>
									<postCode>39762</postCode>
									<region>MS</region>
								</address>
							</affiliation>
							<affiliation key="aff4">
								<orgName type="department">NSF Engineering Research Center for Computational</orgName>
							</affiliation>
							<affiliation key="aff5">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Mississippi State University</orgName>
								<address>
									<settlement>Mississippi</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Klaus</forename><surname>Mueller</surname></persName>
							<email>moeller@cis.ohio-state.edu</email>
							<affiliation key="aff2">
								<orgName type="department">Department of Computer and Information Science</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roni</forename><surname>Yagel</surname></persName>
							<email>yagel@cis.ohio-state.edu</email>
							<affiliation key="aff0">
								<orgName type="department">395 Dreese Lab</orgName>
								<address>
									<postCode>43210</postCode>
									<settlement>Columbus</settlement>
									<region>OH</region>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Department of Computer and Information Science</orgName>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="department">The Advanced Computing Center for the Arts and Design</orgName>
								<orgName type="institution">The Ohio State University</orgName>
								<address>
									<settlement>Columbus</settlement>
									<region>Ohio</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Field</forename><surname>Simulation</surname></persName>
						</author>
						<title level="a" type="main">A Comparison Of Normal Estimation Schemes</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2021-02-19T20:36+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>interpolation filters</term>
					<term>derivative filters</term>
					<term>filter design</term>
					<term>normal estimation</term>
					<term>Taylor series expansion</term>
					<term>efficient volume rendering</term>
				</keywords>
			</textClass>
			<abstract>
				<p>The task of reconstructing the derivative of a discrete function is essential for its shading and rendering as well as being widely used in image processing and analysis. We survey the possible methods for normal estimation in volume rendering and divide them into two classes based on the delivered numerical accuracy. The three members of the first class determine the normal in two steps by employing both interpolation and derivative filters. Among these is a new method which has never been realized. The members of the first class are all equally accurate. The second class has only one member and employs a continuous derivative filter obtained through the analytic derivation of an interpolation filter. We use the new method to analytically compare the accuracy of the first class with that of the second. As a result of our analysis we show that even inexpensive schemes can in fact be more accurate than high order methods. We describe the theoretical computational cost of applying the schemes in a volume rendering application and provide guidelines for helping one choose a scheme for estimating derivatives. In particular we find that the new method can be very inexpensive and can compete with the normal estimations which pre-shade and pre-classify the volume [8].</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Reconstruction of a continuous function and its derivatives from a set of samples is one of the fundamental operations in visualization algorithms. In volume rendering, for instance, we must be able to interpolate the function at arbitrary locations to obtain the volume densities. The gradient (the first derivative of the function) is employed in both volume classification and shading <ref type="bibr" target="#b2">[3]</ref> <ref type="bibr" target="#b7">[8]</ref>. If the gradient estimation is done carelessly, shading and classification will yield wrong colors and opacities. Since the derivative of a function indicates the velocity of change of the function values, the presence of noise especially will lead to incorrect images <ref type="bibr" target="#b3">[4]</ref>.</p><p>There have been various studies and comparisons of accurate interpolation filters, a summary of which is given in <ref type="bibr" target="#b9">[10]</ref> <ref type="bibr" target="#b11">[12]</ref>. However, as is also shown in <ref type="bibr" target="#b11">[12]</ref>, the derivative approximation has a larger impact on the quality of the image and therefore deserves a thorough analysis, which is the goal of this paper.</p><p>The ideal derivative filter is the Cosc filter, which is the derivative of the ideal interpolation filter (Sinc) <ref type="bibr" target="#b0">[1]</ref> <ref type="bibr" target="#b3">[4]</ref>. For a practical use of the Sinc filter, windowing is suggested <ref type="bibr" target="#b6">[7]</ref>. Goss <ref type="bibr" target="#b5">[6]</ref> extends the idea of windowing from interpolation filters to derivative filters. He uses a Kaiser window to mitigate the adverse effects of the truncated ideal derivative filter. Bentum et al. <ref type="bibr" target="#b0">[1]</ref> use the Cardinal cubic splines to develop derivative filters. A good survey of exist-ing digital derivative filters can be found in the paper by Dutta Roy and Kumar <ref type="bibr" target="#b3">[4]</ref>.</p><p>While all of the previous work focuses on the design of derivative filters, no work is known to us, that tries to conduct a comparative study of gradient filters. Especially, in the case of volume rendering, most algorithms are driven by efficiency considerations and may decompose the gradient estimation in one or two steps. One step is typically the interpolation of the normals or of the data values with a continuous interpolation filter. The other step is the application of a digital derivative filter (e.g. central differences) in order to compute the normal at the sampling location. However, there have been schemes proposed, that estimate the normal at an arbitrary point in the volume in one step <ref type="bibr" target="#b0">[1]</ref>. The goal of this paper is to enumerate and classify the different schemes of gradient estimation and to analyze them in terms of accuracy and efficiency.</p><p>In this paper, we denote by f(t) a continuous function (the signal) which is sampled into the discrete function f[k] = f(kT), where T is the sampling distance and k is an integer. In computer imaging, f(t) is not available; we only have f <ref type="bibr">[k]</ref>. We denote by h(t) the continuous function kernel used for interpolation and by d[k] the digital (i.e. only defined for integer arguments) derivative filter.</p><p>We employ a Taylor series expansion of the convolution sum for our numerical analysis, as introduced in <ref type="bibr" target="#b11">[12]</ref>. Our Taylor series expansion provides both qualitative and quantitative means of analyzing filters. In Section 3, this analysis is expanded to the convolution of two filters. The methods of <ref type="bibr" target="#b11">[12]</ref> are briefly summarized.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1">Taylor Expansion of the Convolution Sum</head><p>To reconstruct a continuous function f(t) or its derivative from a set of sample points f[k], we convolve f[k] with a filter kernel, i.e. we compute a weighted average of these samples. By convolving the sampled signal f[k] with a continuous interpolation filter h, we reconstruct an approximation of the original function f(t). Similarly, if we convolve the samples with a continuous derivative filter d, we reconstruct an approximation of the derivative of the original function. We denote the result of this operation by , where w is the filter used. Formally, this can be written as:</p><p>Now we can expand into a Taylor series about t. The Taylor series expansion at that point would be:</p><p>where is the n-th derivative of f and Substituting the Taylor series expansion into the convolution sum of Equation 1, leads to an alternative representation for the reconstructed value at a point t:</p><formula xml:id="formula_1">f′ t ( ) f r w t ( ) f r w t ( ) f k [ ] w t T ---k - ( ) ⋅ k ∞ - = ∞ ∑ = f k [ ] f kT ( ) = f k [ ] f n ( ) t ( ) n! ---------------kT t - ( ) n n 0 = N ∑ f N 1 + ( ) ξ k ( ) N 1 + ( )! ---------------------------kT t - ( ) N 1 + ( ) + = f n ( ) t ( ) ξ k t kT , [ ] ∈ (2)</formula><p>where is chosen such that , with , and i is an integer. It is noteworthy that the derived Taylor coefficients a and the remainder term r only depend on the offset to the nearest sampling point, i.e., they are periodic in the sampling distance T. For further details, please refer to <ref type="bibr" target="#b11">[12]</ref>.</p><p>The characterization of the filtering process in Equation 2 imposes 4 different criteria for a good normal estimation scheme. First of all, we require to be zero. Secondly we have to normalize by in order to reconstruct the actual derivative as opposed to a multiple of it. Further by determining the largest N, such that is zero, we can determine the asymptotic error behavior of a filter for a decreasing sampling distance T. Finally, the remainder term r gives us an indication of the absolute error of that filter.</p><p>This expansion of the convolution sum assumes that at least the first N derivatives of the function f exist, where N depends on our error analysis. This condition is generally met in practice since image and volume acquisition devices such as scanners and cameras inherently perform a low-pass filtering operation that bandlimits the functions <ref type="bibr" target="#b1">[2]</ref>. Numerical simulations of physical phenomena, as performed in the field of computational fluid dynamics, usually generate bandlimited images as well since typically robust numerical solutions can be obtained only if the algorithm incorporates a smoothing step <ref type="bibr" target="#b14">[15]</ref>. Finally, all rendering and scan-conversion algorithms, in order to provide antialiased images, usually also employ a filtering step that bandlimits the image. Bandlimited functions do not contain frequencies higher then a certain limiting frequency in their spectra. One can conclude, that bandlimited functions are analytic functions and all N derivatives exist.</p><p>The remainder of the paper is organized as follows. In Section 2, we summarize the different schemes for normal estimation. In Section 3, we modify the Taylor series expansion of the convolution operation for the specific use of cascading two filters, and compare the schemes of Section 2 numerically. In Section 4, we examine possible implementations of the normal estimation schemes and compare their efficiency. Experimental results are also presented in Section 5. Finally, in Section 6, we summarize the results of this paper and discuss some open questions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">GRADIENT RECONSTRUCTION FROM THE VOLUME SAMPLES</head><p>We will use the symbol F to represent the discrete function f <ref type="bibr">[k]</ref>. Further, we let D and H denote the derivative and interpolation operators, respectively. In the process of volume rendering there are two additional operators applied to the data. The first is the transfer function, which maps the raw data values into material attributes such as color, opacity, and reflectivity. We denote this operator, also called classification function, by C. The second operator applied to the data is shading, which illuminates the data. The shading operator, which we denote by S, takes as input material attributes, light attributes, and the surface normal, and produces a displayable value (e.g., RGBα).</p><p>Since S needs the output of C, shading will always be performed after classification. Since S needs the function's derivative, it will always be after D. We now present four different ways of computing the function derivatives. Except for the first approach, (FD)H, in all others the operators CS will be performed after the interpolated derivative has been computed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Method (FD)H -Derivative First</head><p>One way of computing the derivative at a point t of a discrete function f[k] is to first compute the normal at the grid points kT and then interpolate these normals, producing the derivative at the desired location t. This is the method most commonly used in volume graphics <ref type="bibr" target="#b5">[6]</ref> <ref type="bibr" target="#b8">[9]</ref>. The first step, the computation of the derivative at the grid points, can be expressed in the following convolution: Now the derivative at an arbitrary point can be interpolated as:</p><p>Square brackets are used to emphasize the discrete nature of the operator. Since a convolution in spatial domain is the same as a multiplication in frequency domain, we conclude the following frequency characterization of the above operation:</p><formula xml:id="formula_2">(3)</formula><p>Here D D (ω) denotes the Fourier transform of the discrete derivative filter and F D (ω) denotes the Fourier transform of the sampled function f <ref type="bibr">[k]</ref>. The Fourier transform of a discrete function contains replicated frequency spectra at k2π (where k is an arbitrary integer). Therefore D D (ω) and F D (ω) are periodic functions with period 2π. Following the Fourier transform in Equation 3, we will refer to this method as (FD)H. Unlike all other methods described in this paper, some algorithms <ref type="bibr">([8]</ref>[3] <ref type="bibr" target="#b15">[16]</ref>) perform interpolation after classification and shading. Normal values are computed at the grid points and classification is also applied to the original data values. Then, these data points are shaded. The final RGBα volume is then interpolated at the appropriate sampling points. Using our notation, this method can be summarized by (((FD)C)S)H. This is indeed an efficient method, since CS does not have to be computed for every sample point (which is the case for all other methods described in this paper where interpolation is done before CS) but rather it is computed only for the original data points. However, this method will produce correct results only if both C and S are linear operators. The result of employing a non-linear transfer function or illumination model may, for example, cause the appearance of errors or pseudo-features that are non-existent in the original data. In the case of S, one must therefore allow illumination models consisting of only ambient lighting. In the case of C, the linearity restriction may not be acceptable for many applications. For example, if we want to find the opacity in-between two data values a and b (using linear interpolation), we would find (C(a)+C(b))/2 by performing classification first. However we would find C((a+b)/2) by performing interpolation first. Obviously, if C is a non-linear operator, the two results will be different. We therefore concentrate our analysis and discussion in the more general and accurate methods that per-</p><formula xml:id="formula_3">f r w t ( ) a n w τ ( ) f n ( ) t ( ) n 0 = N ∑ r N i , w τ ( ) + = a n w τ ( ) T n n! ------ k τ - ( ) n w τ k - ( ) k ∞ - = ∞ ∑ = r N i , w τ ( ) max ξ i M - ( )T i M + ( )T , [ ] ∈ f N1 + ( ) ξ ( ) ( )     a N 1 + w τ ( ) ≤ or r N w τ ( ) a N 1 + w τ ( ) f N 1 + ( ) t ( ) ≈ τ t i τ + ( )T = 0 τ ≤ 1 &lt; a 0 w a 1 w a N w f d k [ ] f l [ ] d k l - [ ] ⋅ l ∞ - = ∞ ∑ = f r dh t ( ) f d k [ ] h t T ---k - ( ) ⋅ k ∞ - = ∞ ∑ = f l [ ] d k l - [ ] ⋅ l ∞ - = ∞ ∑       h t T ---k - ( ) ⋅ k ∞ - = ∞ ∑ = F r dh ω T ---- ( ) F D ω ( )D D ω ( ) ( ) Hω ( ) =</formula><p>form CS only after gradient estimation and interpolation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Method (FH)D -Interpolation First</head><p>In this approach, we first reconstruct the continuous function f(t) from the sampled values f k and then apply the discrete derivative filter d <ref type="bibr" target="#b9">[10]</ref> <ref type="bibr" target="#b13">[14]</ref>. Since the derivative filter is discrete, we only need to evaluate the convolution sum of the interpolated function at discrete points. The interpolated function can be expressed as a convolution of the samples f k using the interpolation filter h:</p><p>The reconstructed derivative can be computed by:</p><p>Using similar arguments as above, we find the Fourier Transform to be:</p><formula xml:id="formula_4">(4)</formula><p>Using our previous notation scheme, we refer to this method as method (FH)D.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Method F(DH) -Continuous Derivative</head><p>Looking at all possible combinations of applying the interpolation filter and the derivative filter to the discrete signal, we are led to a theoretical result. Namely, that we can first convolve the digital derivative filter with the continuous interpolation filter. The result will be a new continuous derivative filter which we can apply to the data samples, enabling us to reconstruct the derivative at any arbitrary point t directly. This can be written as:</p><p>where the continuous derivative filter dh(t) is obtained as the convolution of the digital filter d <ref type="bibr">[k]</ref> with the interpolation filter h:</p><p>We can show that the frequency representation of this process is: <ref type="bibr" target="#b4">(5)</ref> therefore referring to this method as F(DH). The benefit of this scheme is more conceptual at this moment. In Section 3 we show how it can be used for a convenient analysis of the normal estimation process. Further we will show in Section 4, that this method can also be the most efficient to use for volume rendering algorithms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Method -Analytic Derivative</head><p>A fourth method to compute the gradient of a discrete function is to convolve the samples f[k] with the analytical derivative of the interpolation filter h:</p><p>In this case, represents a continuous derivative filter, allowing us to reconstruct the continuous derivative directly from the samples f <ref type="bibr">[k]</ref> in just one convolution. This is very similar to the previous method F(DH). It differs only in the way we construct the derivative filter: In method F(DH) we compute a convolution sum for the continuous derivative filter, while in this method we compute the continuous derivative filter analytically. Bentum et al. <ref type="bibr" target="#b0">[1]</ref> apply this idea to cardinal splines, and Marschner and Lobb <ref type="bibr" target="#b10">[11]</ref> use this for the BC-splines. The Fourier transform of the derivative of a function is simply the scaled Fourier transform of that function multiplied by iω (i 2 = -1) <ref type="bibr" target="#b1">[2]</ref>. Therefore, we find that the Fourier transform of is:</p><p>and we refer to this method as .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">NUMERICAL ACCURACY</head><p>Comparing Equations 3, 4, and 5 we easily find that these three methods are numerically equivalent and thus produce the exact same reconstructed derivative of f. Therefore, we will concentrate on comparing the methods (FD)H, (FH)D, F(DH) with the method . In order to compare the numerical accuracy of the methods, we use the tools developed in <ref type="bibr" target="#b11">[12]</ref> and summarized in Section 1.1.</p><p>For method , w in Equation 1 is simply the derivative of the interpolation filter h. For other methods, we choose the derivative filter described in Section 2.3. To clarify the notation, we will replace w by dh. To better compute the coefficients of Equation 2 for the derivative filter dh, we will substitute the convolution sum of the derivative and interpolation filters into the expression for in Equation 2:</p><p>which simplifies to:</p><p>Substituting m for k+l in the inner sum, we get:</p><formula xml:id="formula_5">which resolves to</formula><p>This means that the error coefficient of a convolution filter is simply the convolution of the error coefficients of both filters. In <ref type="table">Table 1</ref>, we have computed the coefficients for some commonly used filter combinations. The first column shows the error coefficients for the probably most common used filter combination of linear interpolation and central differences, abbreviated by DL. Another common choice is the combination of a cubic interpolation filter (we have chosen the class of cubic cardinal splines) with central differences. We let DC denote this filter class. For the class of analytic derivative filters we have chosen the derivative of the cubic interpolation filter, as introduced in <ref type="bibr" target="#b0">[1]</ref>. We use C to represent this filter class.</p><p>In the case that α=-0.5, is zero for all three methods and</p><formula xml:id="formula_6">f r h t ( ) f r h t ( ) f k [ ] h t T ---k - ( ) ⋅ k ∞ - = ∞ ∑ = f r dh t ( ) d k [ ] f r h t kT - ( ) ⋅ k ∞ - = ∞ ∑ = F r ω T ---- ( ) F D ω ( )H ω ( ) ( ) D D ω ( ) = f r dh t ( ) f k [ ] dh t T ---k - ( ) ⋅ k ∞ - = ∞ ∑ = dh t ( ) d k [ ] h t T ---k - ( ) ⋅ k ∞ - = ∞ ∑ = F r dh ω T ---- ( ) F D ω ( ) D D ω ( )H ω ( ) ( ) = FH′ f r h′ t ( ) f k T -----h′ t T ---k - ( ) ⋅ k ∞ - = ∞ ∑ = h′ f′ t ( ) f r h′ t ( ) F r h′ ω T ---- ( ) F D ω ( ) iω T ------H ω ( )     = FH′ FH′ FH′ a n dh τ ( ) a n dh τ ( ) a n dh τ ( ) T n n! ------ k τ - ( ) n d l [ ] h τ k - l - ( ) ⋅ l ∞ - = ∞ ∑       k ∞ - = ∞ ∑ = a n dh τ ( ) T n n! ------ d l [ ] k τ - ( ) n h τ k - l - ( ) k ∞ - = ∞ ∑       ⋅ l ∞ - = ∞ ∑ = a n dh τ ( ) T n n! ------ d l [ ] m τ - l - ( ) n hτ m - ( ) m ∞ - = ∞ ∑       ⋅ l ∞ - = ∞ ∑ = T n n ! ------ d l [ ] n i     m τ - ( ) i l - ( ) n i - i 0 = n ∑       h τm - ( ) m ∞ - = ∞ ∑       l ∞ - = ∞ ∑ = a n dh τ ( ) T n n! ------ n i     l - ( ) n i -d l [ ] l ∞ - = ∞ ∑       m τ - ( ) i hτ m - ( ) m ∞ - = ∞ ∑       i0 = n ∑ = a n i - d 0 ( )a i h τ ( ) i 0 = n ∑ = a 2 d</formula><p>we must compare</p><p>. One can easily prove that this coefficient for DL is always greater than T 2 /6 (the coefficient for DC), which in turn is greater than the coefficient for C. This implies that, the worst behavior is observed for DL, and C is more accurate than DC.</p><p>Therefore we conclude, that the optimal filter to use is C for α = -0.5. However, one might be interested to use different α in different situations. For instance Park and Schowengerdt <ref type="bibr" target="#b12">[13]</ref> conclude from a frequency study of the cardinal cubic splines, that some α (different than -0.5) might yield better images. They find that α depends strongly on the underlying function to be reconstructed. Therefore it is of interest to analyze the spatial error for different α as well.</p><p>In the case that α ≠ -0.5, the coefficient for is zero only for the method DL. In order to compare the error coefficient among the methods DC and C, we compare for both filters. As we have pointed out in <ref type="bibr" target="#b11">[12]</ref>, these coefficients need to be normalized. <ref type="figure" target="#fig_1">Fig. 1</ref> shows a plot of after its normalization. Note that T simply scales both plots equally. Therefore, it can be set to one. In <ref type="figure" target="#fig_1">Fig. 1</ref>, one can clearly see that the error coefficient for DC is smaller than the error coefficient for C. Therefore, we conclude that DC is superior to C when α ≠ -0.5. This is a rather unexpected result, since one would naturally expect the analytic derivative of a filter to be more exact and therefore to perform better. As we have just seen, this is not necessarily the case.</p><p>For the special cases that τ = 0 and τ = 0.5 (where ) we found by comparing , that C is more accurate than DC foroe α ∈ [-3,-0.6]. Another value to consider is the second derivative of the underlying function. When it goes to zero, we also have to use the error coefficient for an error comparison.</p><p>We are left to compare the error behavior of the most common method DL with the other two methods. Again, for the special cases, where the second coefficient or the second derivative of the function go to zero, we must compare in order to find the most accurate filter. For the other cases however, we can follow the following analysis. If we have influence on the original sampling distance T for our applications, we can always find a T, such that the combination of central difference and linear interpolation is superior to the other two methods. In other words, DL is asymptotically better than DC and C. However in most practical applications we are given a data set with fixed sampling distance T. In these cases we need to weight the actual error of the filters and conclude from this comparison which filter is more accurate. If we are comparing DL and DC, we want to find out for which α DC performs better than DL. Mathematically:</p><p>Using the second error approximation of Equation 2, we find the following criteria:</p><p>We can conclude that the choice of α very much depends on the resampling offset τ and the actual data. After some algebraic manipulations, we can conclude: <ref type="bibr" target="#b5">(6)</ref> For α in this range the method DC is more accurate than DL. As expected, the choice of the most accurate filter strongly depends on the underlying data. For a similar comparison of the methods DL and C we find:  <ref type="table">Table 1</ref>.Coefficients for some commonly used filter combinations </p><formula xml:id="formula_7">a 3 d a 2 d a 2 d a 2 d a 3 d 0 = a 3 d a 3 d a 3 d ε DL ε DC ≥ a 3 DL τ ( ) f 3 ( ) t ( ) a 2 DC τ ( ) f 2 ( ) t ( ) ≥ T 5 4 ---f 3 ( ) t ( ) f 2 ( ) t ( ) ---------------α 0.5 + T 5 4 ---f 3 ( ) t ( ) f 2 ( ) t ( ) --------------- - ≥ ≥ central</formula><formula xml:id="formula_8">a 0 d a 1 d T 1 2α 1 + ( ) 6τ 2 - 6τ 1 - + ( ) + ( ) a 2 d T - 2 2 α1 + ( )τ 1 τ - ( ) 1 2τ - ( ) 3T 2 2α 1 + ( )τ 1 τ - ( ) 1 2τ - ( ) a 3 d T 2 6 ------1 3τ 3τ 2 - + ( ) α 0.5 - = T 2 6 ------ τ 0 = T 2 6 ------ τ 0.5 = T 2 6 ------ 6 4 ---α 14 8 ------ +     α 0.5 - = T 2 6 ------6τ 2 6τ - 1 + ( ) τ 0 = T 2 6 ------ τ 0.5 = T 2 6 ------<label>14α</label></formula><p>An important observation that we draw from Equation 6 and Equation 7 is the dependency of the comparative accuracy on the sampling distance. The higher the sampling rate the smaller the range in which C or DC performs better than DL. This means that for densely sampled data sets a combination of linear interpolation and central difference is not only efficient, but also recovers the derivative accurately. That can also be explained in the frequency domain. The higher the sampling rate, the further apart the frequency spectra are placed. In other words, the signal's aliases are more separated. Thus, the deficiencies of the central difference operator at higher frequencies do not impose a problem since no signal aliases exist in this frequency range. This is an important and new result, since it tells us, that for some data sets DL is just as accurate, as the other two (more expensive) methods DC and C.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">EFFICIENCY CONSIDERATIONS</head><p>In this section, we compare the four methods (FH)D, (FD)H, F(HD), and from an efficiency perspective. While the first three methods are equivalent from an accuracy standpoint, they are not so from an efficiency point of view. This section also contrasts the overall computational effort of these four shading-deferring methods with the demands of the popular, but less accurate, preshading scheme <ref type="bibr" target="#b7">[8]</ref>. We denote this approach as ((FD)CS)H, where C and S stand for classification and shading that occur after gradient computation but before color interpolation. Our comparisons will be valid for the 3D case only (a typical application will be volume rendering algorithms). If we compare normal estimation schemes in other dimensions, our analysis will be similar.</p><p>In the following discussion, we distinguish between implementations that compute all results on-the-fly, and implementations that utilize some form of caching to reuse previously computed results. The latter approaches obviously requires an extra amount of memory and cache management overhead. We now introduce some terminology: For digital filters is obviously the length of the filter, but for continuous filters (e.g. cardinal splines)</p><p>is usually the filter support, i.e. the number of sample values, that are influenced by the filter. Since the filter operation is the weighted sum of elements, we usually have for a straight forward implementation of multiplications and additions. However, for some special filters, there will be a more efficient implementation. For instance, the central difference filter (in one dimension), can be implemented in 2 operations (one subtraction and one division by 2) as opposed to 3 operations (two multiplications by 0.5 and one subtraction). Therefore, we find it important to separate between and . In the following discussion we will discuss the cost of reconstructing the function and its derivative at all the sample points. We will also comment on the cost of applying the classification and shading operators.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">(FD)H -Derivative First</head><p>In this method, we first compute the gradient at all grid voxels within the extent of the interpolation filter h, and then interpolate these gradients using H. An on-the-fly approach would have to compute gradients for a total cost of , followed by three interpolations to compute the three gradient components and one interpolation to compute the data value itself. The total cost is thus:</p><p>By storing computed gradients in a gradient volume, one could reduce the cost to:</p><p>The process of classification and shading will require additional m⋅E CS cost and the total cost will then be:</p><p>However, in the ((FD)CS)H method, classification and shading are applied to the data values, and the interpolation filter is applied to the resulting RGBα values. Therefore, the total cost for this method, assuming caching, is:</p><p>Since in most cases, to assure proper sampling, , the computational advantage of this method is clear. Moreover, when classification and illumination does not change for multiple rendering, the cost of the first component in the last two equations is amortized and can therefore be ignored. If we ignore the shading component then the cost of reconstructing the function and its derivative assuming caching is given by:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">(FH)D -Interpolation First</head><p>The (FH)D method computes the derivative at a ray sample location from a set of additionally interpolated samples in the neighborhood of the sample location. In parallel (orthographic) rendering of volumes the data is resampled into a new grid. If this grid is cached somewhere, one can perform the derivative calculations using the data values at that grid.</p><p>Without caching, in order to compute the derivative at a sample location, (FH)D interpolates additional samples, each at a cost of E H , and uses them to obtain three axis derivatives at the cost E D . Another interpolation at the sample location, each at a cost of E H , yields the function value. The total cost for reconstructing the function and its derivative is:</p><p>Later, these samples are classified and shaded, with an additional cost (for the whole volume) of . However, if caching is employed, only one interpolation is needed per sample, and the D operator uses only existing samples. Therefore the total cost for reconstructing the function and its derivative:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">F(DH) -Continuous Derivative</head><p>Here the derivative filter is pre-convolved with the interpolation filter which increases its size. The gradients are then computed by convolving the volume by this combined DH-filter. The total cost for computing the function and its derivative is then given by: This is the most direct method of the three methods presented so far and there is no caching mechanism available to gain some speedup.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Method -Analytic Derivative</head><p>This method is not equivalent to the previous three in terms of</p><formula xml:id="formula_10">1 1 T --- 4 5 ---f 2 ( ) t ( ) f 3 ( ) t ( ) ---------------2 + -------------------------------------α 0.5 + 1 1 T --- 4 5 ---f 2 ( ) t ( ) f 3 ( ) t ( ) ---------------2 + ------------------------------------- - ≥ ≥ FH′ H′ λ λ λ λ E λ 2 λ 1 - = λ λ 1 - E λ λ H H E D m H E D ⋅ 3E H E H + + ( ) n E D ⋅ m 3E H E H + ( ) + n E D ⋅ m 4E H E CS + ( ) + n E D E CS + ( ) ⋅ m4 E H ( ) + n m ≤ n E D ⋅ m 4E H ( ) + D m D E H ⋅ E D E H + + ( ) m E CS ⋅ m E D E H + ( ) m E DH E H + ( ) FH′</formula><p>accuracy, as other sections of this paper demonstrate.</p><p>uses a special gradient filter derived from the interpolation filter to estimate the gradients. Since this derivative filter has the same size as H the corresponding cost for computing the function and its derivative is: .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Summary and Numerical Examples</head><p>We are now ready to compare the theoretical cost functions presented in the previous subsections and provide some numerical examples to highlight the differences. Since the derivative filters are directional filters, and E DH denotes the cost of computing all three derivative components, we find that E DH is three times the cost of one derivative component operation. In order to find the directional derivative, we convolve the interpolation filter of size with a 1D derivative filter of length k (in our case -central differences -k = 2). That results in a filter of size . Therefore we find the cost of E DH for H being cubic is 477 and for H being trilinear is 69.</p><p>As expected the analytical derivative method ( ) is the most efficient one. However, as we showed in Section 3, it is not necessarily the most accurate. Among the other three schemes (which are numerically identical), we find our new method (F(DH)) most efficient if there is no caching. However, if caching is available, (FH)D is certainly the most efficient way to compute the normal and the data value at this point. Therefore, we conclude that in terms of efficiency and in terms of accuracy, there is no need for the most commonly used method (FD)H (in the case of deferred shading). As was pointed out already in Section 4.1, if we do shading at the grid locations, we might find a more efficient algorithm, yet trading speed for accuracy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">EXPERIMENTS</head><p>The images were rendered employing a simple raycaster to find isosurfaces.The volumes were resampled at an interval of 0.05 voxel lengths. At each sampling point, the raycaster first applied the interpolation kernel to reconstruct the function at that point. If the reconstructed value was above a pre-set isovalue, the derivative filter was used to compute the 3D gradient. Shading was then performed using the traditional Phong lighting model <ref type="bibr" target="#b4">[5]</ref> with diffuse and specular reflections. The obtained color and opacity were composited with the previous ray values, and the ray was terminated after the opacity reached a value close to one. Since for all our filters both the interpolation and the derivative kernel were separable, the filter operations could be efficiently performed using a scheme similar to the one given by Bentum et al <ref type="bibr" target="#b0">[1]</ref>.</p><p>For our experiments we used an analytic data set, derived from the same function as the one used by Marschner and Lobb <ref type="bibr" target="#b10">[11]</ref>. Specifically, we used:</p><p>Since we study different derivative filters, we have fixed the interpolation filter to be the Catmull-Rom interpolation filter -a cubic filter with small error as was also shown in <ref type="bibr" target="#b11">[12]</ref>. From Equations 6 and 7 we learn that the range of α where C and/or DC performs better than DL is dependent on the data set. To address this issue, we have computed the ratio analytically for the data points for the three axis directions x, y, and z, where we reconstruct and collected them in a histogram, plotted in <ref type="figure" target="#fig_4">Fig. 2</ref>. In order to guarantee that all data points are reconstructed more accurately using DC (or C) than DL, we would have to choose the minimal ratio. This ratio is zero and therefore we can conclude that only for α = -0.5 we can guarantee, that the derivative reconstruction at any single point will be better for the methods DC and C as opposed to DL. In order to get practical results, we could choose a higher ratio of , giving up on the accuracy assurance for some reconstructed values. If we for instance choose the ratio 7, we still guarantee all z directional derivatives to be estimated more accurately. Approximatly 8% of the directional derivatives in y will be more accurate by DL, and only 3.8% of the directional derivatives in x will be better by DL.</p><p>When we plug in the ratio of 7 into Equations 6 and 7, we find the theoretical result that for α ∈ [-0.78,-0.22], DC performs better than DL and for α ∈ [-0.65,-0.34], C performs better than DL. These theoretical ranges have steered our experiments and in <ref type="figure">Fig. 3</ref> (see color plates) we have rendered the Marschner-Lobb data set for several different α. For a better (analytical) understanding of these rendered images, we have also drawn the angular error images in <ref type="figure">Fig. 4</ref>. For each reconstructed normal we computed the actual normal and recorded their angular difference. The grey value of 255 was displayed for an angular error of 5 degrees.</p><p>For the first row of images we have used α = -0.5. Following our analysis in Section 3, we expect that ε(C) &lt; ε(DC) &lt; ε(DL), where ε(A) denotes the error measure of image A. The first row of <ref type="figure">Fig. 3</ref> shows the different images for α = -0.5. Although the differences are small, one can find DC to be better, than DL. Although the image for DC is overall smoother, it's error image in <ref type="figure">Fig. 4</ref> reveals a much higher error than for C.</p><p>The images for α = -1.0 show the opposite behavior. From our analysis we deduce the following error behavior: ε(DL) &lt; ε(DC) &lt; ε(C). From <ref type="figure">Fig. 3</ref> we conclude, that C clearly is the worst image. Also a visual comparison of DC and DL leads to the conclusion, that DL is better than DC. The error images in <ref type="figure">Fig. 4</ref> support this analysis.</p><p>The rows for α = -0.6 and α = -0.7 show rather a transitional phase. Since the change of the filter weights happens continuously, we cannot necessarily expect a sudden sharp change in the image  </p><formula xml:id="formula_11">15 = s s s ⋅ ⋅ s 3 = s k 1 - + ( ) s s ⋅ ⋅ FH′ f x y z , ,<label>( ) 1 2</label></formula><formula xml:id="formula_12">--- 2 5 --- π 2 ---z     sin - 1 10 ------ 12π π 2 ---x 2 y 2 +     cos     cos + = f 3 ( ) t ( ) f 2 ( ) t ( ) ⁄ f 3 ( ) t ( ) f 2 ( ) t ( ) ⁄</formula><formula xml:id="formula_13">f 3 ( ) t ( ) f 2 ( ) t ( ) ⁄</formula><p>quality. The differences in the image quality can be better studied using the error images in <ref type="figure">Fig. 4</ref>. We can conclude, that for α = -0.6 our results follow our theoretical analysis: ε(DC) &lt; ε(C) &lt; ε(DL). However, for α = -0.7 it is debatable, which method is preferable in terms of image quality. Analytically we show ε(DC) &lt; ε(DL) &lt; ε(C). It is clear, that the image for C is the least appealing to the viewer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">CONCLUSIONS AND FUTURE GOALS</head><p>We have classified the different techniques of normal estimation into four groups, and we have developed a new scheme F(DH). We showed that the schemes (FD)H, (FH)D and F(DH) are numerically equivalent, and then extended the idea of classifying filters using Taylor series expansion to the convolution of two filters. We found that computing the analytic derivative of a filter kernel (method ) is not always more accurate than using a combination of that filter with the central difference kernel (any of the methods FDH). Therefore, a careful analysis of existing filters and filter combinations is suggested.</p><p>The new scheme F(DH) opens up new ways to design continuous derivative filters. Furthermore, this method of normal estimation is also the second most cost-efficient one, if no caching is performed (with being the most cost effective one). However, if caching is enabled, then the method (FH)D is clearly preferable over any other method in terms of efficiency. In fact, what is believed as one of the most commonly used methods, (FD)H, is one of the slowest normal estimation method. The only advantage one could gain is the pre-calculation of the shading operation at the grid voxels, as Levoy <ref type="bibr" target="#b7">[8]</ref> has proposed it. However, as was pointed out in Section 2, this method is certainly not preferable if accurately rendered images are required.</p><p>One of our immediate goals is to compare various combinations of known derivative and interpolation filters in order to find new derivative filters. We also would like to extend the error analysis to frequency space so that we can examine any aliasing and smoothing errors. Finally, it would contribute to the accuracy of our analysis to include a noise model. We also believe that it is very important to further investigate the shading and classification steps in terms of numerical accuracy.   </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>FIGURE 1 .</head><label>1</label><figDesc>In both plots we set T to 1.0. takes the values 0, -0.2, -0.4, -0.6, -0.8, -1. (a) The coefficient of the central difference and cubic interpolation filter for varying . (b) The normalized coefficient of the cubic derivative filter for varying α.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>E λ : The computational effort to apply the operator λ where λ can be H, D, DH, , or CS. :Number of filter weights used for applying the operator λ. n: Number of data elements (voxels). m: Number of samples.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>FH′</head><label></label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>FIGURE 2 .</head><label>2</label><figDesc>The ratio of for the directional derivatives in x, y, and z direction respectively for the Marschner Lobb data set.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>FIGURE 3 .FIGURE 4 .</head><label>34</label><figDesc>Marschner Lobb data set. Error images of the Marschner Lobb images inFig. 3 (see color plates)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 2</head><label>2</label><figDesc></figDesc><table><row><cell></cell><cell></cell><cell cols="2">lists all costs derived</cell></row><row><cell cols="3">above and gives two numerical examples: In case 1, H and</cell><cell>are</cell></row><row><cell cols="2">cubic filters (</cell><cell cols="2">), D is a central difference filter</cell></row><row><cell>(</cell><cell cols="2">), and in case 2, H is a trilinear filter (</cell><cell>) and D</cell></row><row><cell cols="4">is again the central difference filter. For the following discussion</cell></row><row><cell cols="4">we count the number of floating point operations associated with</cell></row><row><cell cols="4">each operator, but we do not distinguish between additions, multi-</cell></row><row><cell cols="4">plications or divisions. In this case, the cost of E H for H being</cell></row><row><cell>cubic is</cell><cell></cell><cell cols="2">, of E H for H being trilinear is</cell></row><row><cell></cell><cell></cell><cell cols="2">, of E D for D being central difference the cost is 6.</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 .</head><label>2</label><figDesc>Comparison of efficiency of the normal estimation schemes</figDesc><table><row><cell></cell><cell>m H E D ⋅ (</cell><cell cols="2">+</cell><cell cols="5">3E H E H +</cell><cell>)</cell><cell>n E D ⋅</cell><cell>+</cell><cell>m 4E H (</cell><cell>)</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>n E D ⋅</cell><cell>+</cell><cell>m 4E H (</cell><cell>)</cell></row><row><cell></cell><cell cols="2">m D E H ⋅ (</cell><cell cols="2">+</cell><cell cols="3">E D E H +</cell><cell>)</cell><cell>m E D E H + (</cell><cell>)</cell></row><row><cell></cell><cell cols="6">m E HD E H + (</cell><cell>)</cell></row><row><cell>FH′</cell><cell cols="5">m 2E H (</cell><cell>)</cell><cell></cell></row></table><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We thank Prof. Wayne Carlson and the Advanced Computing Center for the Arts and Design for the use of their computing facilities and Prof. Robert Moorhead of the NSF Engineering Research Center, Mississippi State University as well as Tom Malzbender of Hewlett-Packard Labs for providing encouragement and support. This project was partially supported by the Department of Defense USAMRDC 94228001, by the Advanced Research Projects Agency Contract DABT63-C-0056 and the NSF Research Center for Computational Field Simulations.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Frequency Analysis of Gradient Estimators in Volume Rendering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Bentum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">B A</forename><surname>Lichtenbelt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Malzbender</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="242" to="254" />
			<date type="published" when="1996-09" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Two Dimensional Imaging</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">N</forename><surname>Bracewell</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1995" />
			<publisher>Prentice Hall Inc</publisher>
			<pubPlace>Englewoods Cliffs, NJ</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Volume Rendering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">A</forename><surname>Drebin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Carpenter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Hanrahan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="51" to="58" />
			<date type="published" when="1988-08" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Digital Differentiators</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dutta</forename><surname>Roy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">C</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename></persName>
		</author>
		<editor>Statistics, N. K. Bise and C. R.</editor>
		<imprint>
			<date type="published" when="1993" />
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="159" to="205" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Computer Graphics, Principles and Practice</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">D</forename><surname>Foley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Van Dam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">K</forename><surname>Feiner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">F</forename><surname>Hughes</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1990" />
			<publisher>Addison-Wesley</publisher>
			<pubPlace>Reading, Massachusetts</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">An Adjustable Gradient Filter for Volume Visualization Image Enhancement</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">E</forename><surname>Goss</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Graphics Interface&apos;94</title>
		<meeting>Graphics Interface&apos;94<address><addrLine>Toronto, Ontario</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1994" />
			<biblScope unit="page" from="67" to="74" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Digital Filters</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">W</forename><surname>Hamming</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1983" />
			<publisher>Prentice Hall Inc</publisher>
			<pubPlace>Englewoods Cliffs, NJ</pubPlace>
		</imprint>
	</monogr>
	<note>Second Edition</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Display of Surfaces from Volume Data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Levoy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer Graphics and Applications</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="29" to="37" />
			<date type="published" when="1988-05" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Marching Cubes: a High Resolution 3D Surface Reconstruction Algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">E</forename><surname>Lorensen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Cline</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="163" to="169" />
			<date type="published" when="1987-07" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Reconstruction Error Characterization and Control: A Sampling Theory Approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">K</forename><surname>Machiraju</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Yagel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics, ITVCG</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="364" to="376" />
			<date type="published" when="1996-12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">An Evaluation of Reconstruction Filters for Volume Rendering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">R</forename><surname>Marschner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">J</forename><surname>Lobb</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Visualization &apos;94</title>
		<meeting>Visualization &apos;94</meeting>
		<imprint>
			<publisher>IEEE CS Press</publisher>
			<date type="published" when="1994-10" />
			<biblScope unit="page" from="100" to="107" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Evaluation and Design of Filters Using a Taylor Series Expansion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Möller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">K</forename><surname>Machiraju</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Mueller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Yagel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="184" to="199" />
			<date type="published" when="1997-06" />
		</imprint>
	</monogr>
	<note>ITVCG</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Image Reconstruction by Parametric Cubic Convolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">K</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">A</forename><surname>Schowengerdt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision, Graphics, and Image Processing</title>
		<imprint>
			<date type="published" when="1983" />
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="258" to="272" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Cube-4 -A Scalable Architecture for Real-Time Volume Rendering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Pfister</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">E</forename><surname>Kaufman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1996 Symposium on Volume Visualization</title>
		<meeting>the 1996 Symposium on Volume Visualization</meeting>
		<imprint>
			<date type="published" when="1996-10" />
			<biblScope unit="page" from="47" to="54" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><forename type="middle">U</forename><surname>Warsi</surname></persName>
		</author>
		<title level="m">Fluid Dynamics: Theoretical and Computational Approaches</title>
		<meeting><address><addrLine>Boca Raton, FL</addrLine></address></meeting>
		<imprint>
			<publisher>CRC Press</publisher>
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Footprint Evaluation for Volume Rendering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Westover</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Graphics (SIGGRAPH &apos;90 Proceedings)</title>
		<imprint>
			<date type="published" when="1990-08" />
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="367" to="376" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
