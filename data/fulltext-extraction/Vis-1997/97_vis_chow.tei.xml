<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/pisenberg/grobid/grobid-0.6.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Optimized Geometry Compression for Real-time Rendering</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><forename type="middle">M</forename><surname>Chow</surname></persName>
							<email>mike.m.chow@eng.sun.com</email>
							<affiliation key="aff0">
								<orgName type="institution">Massachusetts Institute of Technology</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Optimized Geometry Compression for Real-time Rendering</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2021-02-19T20:35+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
				<p>Most of existing visualization applications use 3D geometry as their basic rendering primitive. As users demand more complex datasets, the memory requirements for retrieving and storing large 3D models are becoming excessive. In addition, the current 3D rendering hardware is facing a large memory bus bandwidth bottleneck at the processor to graphics pipeline interface. Rendering 1 million triangles with 24 bytes per triangle at 30Hz requires as much as 720 MB/sec memory bus bandwidth. This transfer rate is well beyond the current low-cost graphics systems. A solution is to compress the static 3D geometry as an off-line pre-process. Then, only the compressed geometry needs to be stored in main memory and sent down to the graphics pipeline for real-time decompression and rendering. We present several new techniques for compression of 3D geometry that produce 2 to 3 times better compression ratios than existing methods. We first introduce several algorithms for the efficient encoding of the original geometry as generalized triangle meshes. This encoding allows most of the mesh vertices to be reused when forming new triangles. Our second contribution allows various parts of a geometric model to be compressed with different precision depending on the level of details present. Together, our meshifying algorithms and the variable compression method achieve compression ratios of 30 and 37 to one over ASCII encoded formats and 10 and 15 to one over binary encoded triangle strips. Our experimental results show a dramatically lowered memory bandwidth required for real-time visualization of complex datasets.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Large geometric models are widely used in visualization applications such as visualizing complex aerospace models, large automotive CAD datasets, large medical datasets of isosurfaces, architectural walkthroughs, and virtual environments. As a result, much of the current research has been focused on managing these large datasets. Two well known techniques are polygon simplification and visibility culling. The former allows an object to be viewed at different details depending on viewing distance from the object <ref type="bibr" target="#b3">[4]</ref> <ref type="bibr" target="#b4">[5]</ref>. Visibility culling allows the invisible portions of a model to be culled away and removed from the drawing loop <ref type="bibr" target="#b8">[9]</ref>. However, these techniques do not work well when most of the object is visible and its full resolution is desired (during close-up viewing). In this case, the full detailed geometry must still be sent down to the graphics hardware for rendering.</p><p>As visualization users demand ever larger and more detailed geometric datasets, real-time graphics hardware is increasingly facing a memory bus bandwidth bottleneck in which the large amount of geometry data cannot be sent fast enough to the graphics pipeline for rendering due to the slow memory subsystems <ref type="bibr" target="#b6">[7]</ref>. For example, to render a large geometric dataset with 1 million triangles at 30Hz (30M triangles/sec) would require 720MB/sec bus throughput between the processor and graphics pipeline (assuming 24 bytes per triangle). Such high memory bandwidth requirement may be reachable by high-performance, high-cost graphics workstations, but it is not reasonable for mid-range and low-end machines <ref type="bibr" target="#b0">[1]</ref>. Current low to mid-range machines have a memory bus bandwidth of only 250 to 320MB/sec <ref type="bibr" target="#b5">[6]</ref> <ref type="bibr" target="#b6">[7]</ref>.</p><p>One proposed solution is to compress the static geometry as an offline pre-process <ref type="bibr" target="#b1">[2]</ref>. Then, the geometry data can be stored in main memory in compressed format. Upon rendering, the compressed geometry is sent to the rendering hardware for real-time decompression using an efficient hardware decompressor <ref type="bibr" target="#b1">[2]</ref> and the decompressed geometry is then rendered.</p><p>Geometry compression is an attractive solution since many of the geometric datasets used by visualization applications are static and do not change from frame to frame. A medical dataset of the human body, architectures and buildings, the engines and chassis of a Boeing 777 are some examples. Using compressed geometry, we can make high-performance graphics much more accessible for low-cost graphics hardware implementations. Based on experimental results of this paper, with an optimized compression ratio of 10:1, for the same 1 million triangles, we need only store roughly 3.8 MB of compressed geometry in main memory and require less than 120 MB/sec memory bus bandwidth at 30Hz. Thus, given a sufficiently fast graphics pipeline, rendering 30 million triangles per second in real-time on a mid-range machine would not be unreasonable in terms of the memory bandwidth requirements. The geometry compression techniques described here improves 2 to 3 times over existing techniques <ref type="bibr" target="#b1">[2]</ref>. Using the optimized compression results from this paper, we can reduce the total runtime geometry 10 to 15 times smaller than uncompressed geometry (stored as triangle strips) with little loss in image quality. The first optimization efficiently converts the original geometry into generalized triangle mesh format which allows most vertices to be reused when forming new triangles. We present local and global algorithms for building generalized triangle meshes.</p><p>The second optimization allows different regions of a geometric model to be compressed with different precision depending on the level of detail present at each region. This lowers the average bits per triangle for a given object. We also present a method for automating the selection of quantization levels given a user error threshold. This enables unsupervised compression of large geometric databases.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">PREVIOUS WORK</head><p>The concept of 3D geometry compression was first introduced by Deering <ref type="bibr" target="#b1">[2]</ref>. His compression method is lossy and allows for compression ratio vs. quality trade-offs. First, 3D geometry is represented as a generalized triangle mesh, a data structure that efficiently encodes both position and connectivity of the geometry and allows many of the mesh vertices to be reused.</p><p>Next, the positions, normals, and colors are quantized to less than 16 bits. This is a lossy step and the final desired image quality determines the quantization level used. These quantized positions and colors are then delta encoded while normals are mapped onto a unit sphere for a lookup-table based compression. These final deltas are Huffman encoded to output the final compression stream.</p><p>This compression method reduces the storage per triangle to between 35.8 to 58.7 bits rather than 192 bits for 3 floating point positions and normals. However, since no efficient methods for decomposing a model into generalized triangle meshes existed at that time, the final compression ratio was limited to between 5 and 7 to one (without much degradation in image quality). Also, the compression method requires users to manually experiment with quantization levels given a desired image quality. This trial and error process can be very time consuming for compressing large geometric databases. Following Deering's work, Taubin and Rossignac <ref type="bibr" target="#b9">[10]</ref> gave an efficient method for compressing geometry connectivity. Their method decomposes a mesh into spanning trees of triangles and vertices. These trees are encoded separately so that both connectivity and position data are compressed well. They were able to reduce connectivity information to 2 bits per triangle.</p><p>However, one disadvantage of this method is that the decompression stage is complicated by large memory requirements and is not amenable to cost-effective hardware implementations. Since decompression requires random access to an array of vertices for a given mesh, a large on-chip cache memory is required to store the referenced vertices. Also, two passes must be made to retrieve the final triangles. One pass must be made for decompression of positions and normals for the vertices. Then, another pass is needed to extract the final triangles which reference those vertices.</p><p>Taking these factors together, it is unclear how a fast and costeffective decompression hardware can be built using this compression method. A software decompressor will not meet the stringent real-time requirements of a fast graphics pipeline. In contrast, since Deering's method outputs a linear stream of compressed positions and normals, a high speed and cost-effective decompression unit has been proposed <ref type="bibr" target="#b1">[2]</ref> which incrementally extracts triangles from the compression stream for output to the rendering pipeline. Because of the real-time decompression constraints, we chose to focus primarily upon Deering's compression method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">EFFICIENT MESHIFYING ALGORITHMS</head><p>In this section, we present our first optimized compression technique: decomposing a given triangulated mesh into generalized triangle meshes which efficiently encode the original geometry.</p><p>Generalized triangle mesh A generalized triangle mesh is a compact representation of 3D geometry first introduced by Deering <ref type="bibr" target="#b1">[2]</ref>. It consists of a generalized triangle strip <ref type="bibr" target="#b0">[1]</ref> with a kentry fifo to store old vertices (called the mesh buffer). Old vertices are pushed onto the fifo and referenced in the future when they are needed again. Thus, instead of storing an entire x, y, z position along with the Nx, Ny, Nz normal components, we only store the fifo index bits representing the old vertex in the fifo. A minimum vertex header is also needed to specify a vertex reference.</p><p>An example of a generalized triangle mesh is shown in <ref type="figure">Figure 1</ref>. Although the geometry can be specified using one generalized triangle strip, most of the interior vertices will be specified twice in the strip. With the help of a mesh buffer to store the old vertices, a generalized triangle mesh efficiently reuses many old vertices by specifying mesh buffer references instead of repeating those vertices. There is a small cost for each mesh buffer reference due the bits used to index the buffer entries. However, this paper assumes a maximum of 4-bit index for a maximum of 16 entries mesh buffer (due to hardware limitations). Studies by Evans et al. <ref type="bibr" target="#b2">[3]</ref> had also shown that there is little improvement in vertex reuse from very large buffer sizes.</p><p>To our knowledge, no general meshifying algorithms have yet been proposed for decomposing an arbitrary triangulated meshes into generalized triangle meshes. One of the main contributions of this paper is to show how to design very effective local and global meshifying algorithms for triangular and polygonal meshes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Local algorithm</head><p>In this section we present a simple, greedy algorithm which constructs generalized triangle meshes by linking together generalized triangle strips.</p><p>Given a triangulated polygonal mesh, the local algorithm begins by finding a set of connected, boundary edges on a mesh boundary (see Step 1 in <ref type="figure" target="#fig_1">Figure 2A</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Generalized triangle strip from boundary edges</head><p>The first generalized triangle strip is found from the boundary edges as follows. Each of the successive edges in the boundary edge list is traversed such that a vertex is shared between one edge and the next. To chain together triangles for the first strip, a shortest path of triangles is found from the adjacent triangle of the first edge (marked as 'a' in <ref type="figure" target="#fig_1">Figure 2B</ref>) to the adjacent triangle of the second edge (marked as 'b'). This path (shown by the arrows in </p><formula xml:id="formula_0">R7, O1,O8p, O2, O3, M9p, O4, O5, M10p, O6, O11p, O12, O17p, O16p, M-4, O15p, O-6, O14p, O-8, O7, M13p, M18, M19, M-3, O20, O-4, O21, O-5, O22</formula><p>Legend: R=Restart, O=Replace Oldest, M=Replace Middle p=push into mesh buffer Om reads "Replace Oldest on the mth vertex" O-m reads "Replace Oldest and use the mth entry in the mesh buffer" <ref type="figure">Figure 1</ref>. Example of a generalized triangle mesh. <ref type="figure" target="#fig_1">Figure 2B</ref>) joins together a set of adjacent triangles; we add these triangle, in order, to the triangle list of the current strip. After all of the boundary edges are traversed, we have found a list of triangles that forms a generalized triangle strip. From an in-order traversal of the triangles in this list, we assign the vertex replacement codes that defines a generalized triangle strip (this will be discussed shortly).</p><p>Finding the next strip So far, we have only found the first strip of triangles. The next strip should be adjacent to the previous one in order to reuse as many vertices as possible from the previous strip. Once a strip is determined, its triangles are marked as discovered and a new set of boundary edges is created and separates the strip's triangles from the undiscovered triangles adjacent to the strip. To reuse the previous strip's vertices, we chain together the new set of boundary edges of the previous strip (Step 3 in <ref type="figure" target="#fig_1">Figure 2C</ref>). In Step 4 of <ref type="figure" target="#fig_1">Figure 2D</ref>, the next strip's triangles are found from these edges by chaining together the set of adjacent, undiscovered triangles starting from one adjacent triangle of a boundary edge to the adjacent triangle of the next edge (this is the same as in Step 2).</p><p>The pseudocode for the algorithm is shown in <ref type="figure" target="#fig_3">Figure 4</ref>. After the second strip is found, we mark the reused vertices of the first strip as mesh buffer pushes (see Step 6 in <ref type="figure" target="#fig_3">Figure 4</ref>). Likewise, for the corresponding vertices in the second strip, we assign their mesh buffer references based on their positions in the current mesh buffer. After the mesh buffer assignments, the first strip is added to the current generalized triangle mesh data-structure.</p><p>The algorithm continues to add subsequent generalized triangle strips to a general triangle mesh until the generalized triangle mesh ends at a mesh boundary or when all triangles in the subsequent strip have been discovered already. <ref type="figure" target="#fig_3">Figure 14a</ref>-c show several iterations of this algorithm (with some improvements described in the following section). Next, a new generalized triangle mesh is created and a new set of boundary edges is found for starting a new generalized triangle strip (the else statement in <ref type="figure" target="#fig_3">Figure 4</ref>). <ref type="figure">Figure 3a</ref> and 3b show this abstractly.</p><p>The algorithm terminates when there are no more undiscovered triangles left in the mesh region.</p><p>Assigning replacement codes Generalized triangle strips improves over OpenGL triangle strips by allowing triangle fans and "zig-zag" strips to coexist in the same generalized strip <ref type="bibr" target="#b0">[1]</ref>. A generalized strip consists of vertex header codes which specify how the incoming vertex should be combined with two previous vertices when forming the new triangle. A buffer of last three vertices is used to form the next triangle.</p><p>To form a generalized triangle strip from the ordered set of   triangles from Step 2 and 4, we traverse the triangles, in the order as they were chained together. We do a restart code at the start of a fan or "zig-zag" strip. Then, each new, non-restart vertex added to the generalized strip represents a new triangle, and the replacement code (either replace-oldest or replace-middle) assigned is based on which of the three vertices currently in the buffer is to be replaced when forming the new triangle. An old vertex is evicted from the buffer and is replaced by the new one.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Performance of meshifying algorithms</head><p>The performance of a meshifying algorithm can be measured by the final vertex to triangle ratio:</p><p>For example, independent triangles have a 3 to 1 vertex to triangle ratio (r = 3). Generalized triangle strips have a theoretical minimum of 1 vertex per triangle (r = 1). In both cases, the number of mesh buffer reference vertices is zero. With the help of the mesh buffer, however, generalized triangle meshes have a theoretical minimum of r = 0.5 for an infinite, regular mesh grid.</p><p>Based on our test results, the local algorithm, using several improvements given in the next section, shows an average of 0.67 vertex to triangle ratio with an average of 43% vertex reuse.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Adaptive local algorithm</head><p>In this section we improve on the previous local algorithm by applying several heuristics based on observations from common triangulated meshes. These heuristics allow the local algorithm to adapt to different sections of a given mesh.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Adaptive boundary edges</head><p>The efficiency of a meshifying algorithm depends largely on how well it reuses old vertices. With a mesh buffer size of k entries, finding consecutive generalized strips with k-1 boundary edges each would lead to an optimal use of the mesh buffer via pushing of the edge vertices.</p><p>However, the number of boundary edges per strip can decrease for different sections of a mesh. This causes many entries of the mesh buffer to be left unused since fewer vertices are pushed. Consider the situation in <ref type="figure" target="#fig_5">Figure 5A</ref>. Because the current strip folds on itself, its number of boundary edges decreased from that of the previous strip. In the next strip, only a fraction of the mesh buffer entries will actually used. This lowers the total vertex reuse (increasing the final vertex to triangle ratio).</p><p>One solution is to extend the current strip if its boundary edge count falls below k-1 edges. We extend the strip along the boundary edges of the adjacent triangles that were already discovered (see <ref type="figure">Figure 5B</ref>). This allows strips to maintain k-1 boundary edges as far as possible and maximizes the use of the mesh buffer.</p><p>Avoiding fan-outs An opposite problem of having small number of boundary edges is having very long strips whose pushed vertices overflow the mesh buffer. If more than k entries are pushed into the mesh buffer, some of the unused vertices will be evicted before they are reused by the next strip. A strip with more than k-1 boundary edges can overflow the mesh buffer if all of its boundary vertices are pushed into the mesh buffer ( <ref type="figure">Figure 6A</ref> shows one such situation). A solution is to chain up only enough triangles for the current strip so that its boundary edge count is no more than k-1. This is shown in <ref type="figure">Figure 6B</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Avoiding isolated triangles</head><p>The local algorithm can be thought of as a greedy mesh covering procedure which incrementally adds triangles to the generalized triangle meshes. It is efficient if it avoids leaving behind isolated triangles which lowers the final vertex reuse count. To avoid leaving gaps or isolated triangles, the generalized triangle mesh should be formed in a spiral pattern as shown in <ref type="figure" target="#fig_3">Figure 14a</ref>-c.</p><p>The first edge of a strip often determines the direction of the current generalized triangle mesh. Often, if the first edge of a strip is part of a star or fan of triangles, a spiral pattern can arise as in <ref type="figure">Figure 7</ref>. This pattern of generalized triangle mesh avoids leaving behind isolated triangles.   <ref type="figure">Figure 6A</ref>. Triangle fan-out problem. The number of vertices pushed onto mesh buffer exceeds its max size (7 in this example). 6B. A solution is to chain up only enough triangles to avoid mesh buffer overflow.</p><p>Current generalized triangle mesh first strip <ref type="figure">Figure 7</ref>. The spiral pattern arises from the first edge of a strip. This pattern of generalized triangle mesh avoids leaving behind isolated triangles.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Global algorithm</head><p>While the local algorithm greedily selects the next triangle strip that maximizes mesh buffer usage, we could also find generalized triangle meshes using a global analysis. We have experimented with a global method based on triangle strips work of Evans et al. <ref type="bibr" target="#b2">[3]</ref>. Evans' global algorithm found long triangle strips by first locating large patches of quadrilateral faces in the model. Instead of finding triangle strips, we can find generalized triangle meshes from the quad patches by breaking a patch into k by N generalized triangle meshes where k is the mesh buffer size and N is the "height" of the general triangle mesh. However, because of this method's dependence on quad polygons, it is not general enough for arbitrary meshes. More research is needed to find global methods for arbitrary triangular meshes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">VARIABLE COMPRESSION</head><p>In this section, we present our second optimization for compressing 3D geometry: variable compression. We first discuss a method for automatically selecting the quantization threshold for a given model. Then, we present a method for separating a model into variable regions of detail. These regions are later assigned different quantization levels for compression.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Selecting the right quantization</head><p>One of the main steps of geometry compression is the lossy quantization of positions where they are truncated to less than 32bits precision. For many models, quantizations to less than 16 bits results in little loss in quality (the reason will be discussed shortly).</p><p>The quantization step involves first normalizing the object's geometry to a unit cube where all x, y, z positions are in the range of [-0.5, 0.5]. There, the positions are quantized to q bits (q &lt;= 16) by truncating the least significant m bits of the position components, where m = 16 -q. This lossy step can be thought of as overlaying a 3D quantization grid onto the object to be compressed ( <ref type="figure" target="#fig_6">Figure 8a</ref> shows this grid in 2D). The 3D quantization grid is divided into units of 1/2 q each. Each quantization level corresponds to one quantization grid.</p><p>For a given object, if we choose quantization, q, to be too small, the corresponding quantization grid would be too coarse for the given object. Many vertices of the object will be moved drastically and quantization artifacts will start to appear. This "under-precision" case is shown in <ref type="figure" target="#fig_6">Figure 8b</ref>.</p><p>If we pick quantization, q, to be too large, we are in effect overlaying a much denser quantization grid than the object geometry's precision requires. Most of the vertices would remain unchanged after quantization. This "over-precision" case is shown in <ref type="figure" target="#fig_6">Figure 8c</ref>.</p><p>Current geometry compression techniques rely solely on the user to pinpoint the exact value of q to quantize a given object for a desired quality. This is by far a trial and error process and can be quite time consuming when compressing large databases of models. We would like to automate this process by having the program choose the right level of quantization given a user defined error tolerance.</p><p>We have explored a quantization assignment method that first separates the object's geometry into regions of similar detail based on triangle sizes and curvature. This step separates the higher detailed geometry from the lower detailed portions (this step will be discussed shortly). Based on the average edge-length of triangles in each region, we test all possible quantization levels, from q=3 to q=16, to find the best value of q so that its corresponding quantization grid best suits the triangle size.</p><p>For each 3D quantization grid of q, we test to see if the triangle size (normalized to unit cube) is within K times a grid unit (length of 1/2 q ). If it is, we use q as our quantization level. The value, K, corresponds to a user-controlled error threshold, e = 1/K. It roughly means the range in which the triangle vertices are moved when they are quantized. The smaller the value of e (a larger K), the less vertices shift when they are quantized (K typically varies from 5 to 20). The values of K for two different grid units are shown in <ref type="figure" target="#fig_7">Figure 9</ref>.</p><p>Using the error threshold, e, we free the user of manually searching for the right level to quantize an object. Our algorithm analytically finds the right quantization level given the error threshold.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Variable precision geometry</head><p>Another related goal we would like to achieve is choosing different q = 3 q = 2 q = 4 If e = 0.1 (K = 10), then q must be 4. quantization levels for different parts of an object. The geometry for a given object is rarely described with the same detail everywhere. Often, the high frequency regions of an object are given more detail in terms of smaller triangles. For example, in a 3D model of a person, the geometry describing a person's face may be given more detail than other low frequency regions. For a MCAD model of a car, the two side mirrors with curved surfaces are described with a high density of triangles while the doors with lower density.</p><p>Currently, if the user wishes to preserve the highest details in the model, he or she will have to quantize the entire model using the highest quantization even though the highly detailed regions may only account for a small percent of the total geometry. The lower detailed portions of the geometry model are quantized to the same highest quantization level. We call this static quantization to distinguish the variable quantization method we are proposing.</p><p>For optimal geometry compression, we would like to separate the regions of higher detail from the lower ones. This way, we can preserve the highly detailed regions of a model by quantizing less.</p><p>In turn, we can quantize more on the less detailed regions. As a result, we can achieve a higher compression since the average quantization level for the whole object is lowered (as compared to choosing a static, highest bit quantization).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Regions based on triangle size</head><p>We have explored two methods for separating a mesh into regions for different levels of quantization. The first method separates a mesh into different regions based on triangle sizes. Beginning with a triangulated model, each triangle is successively merged with neighboring triangles to form regions of similar triangle sizes (see <ref type="figure" target="#fig_8">Figure 10)</ref>. Two triangles have similar areas if their areas differ within a certain percentage of the sum of their areas. Next, the small adjacent regions are merged together to reduce the total region count (to be discussed shortly). We then assign quantization levels to each region using the assignment method described earlier.</p><p>These regions are then meshified and compressed.</p><p>Regions based on curvature Even if the triangles are similar in sizes (as in scanned meshes), portions of a mesh may still be separated based on curvature. The resulting regions with high curvature is assigned more bits than the ones with lower curvature. This method preserves the high frequency changes during compression. For example, in <ref type="figure" target="#fig_9">Figure 11</ref>, the bump on the surface is separated into one region and assigned more bits than the flat, planar region (even though the triangle sizes are similar).</p><p>Triangles of the mesh are merged into regions as in the previous method except, now, the merging criterion is based on curvature. The curvature of a region can be found in different ways. This work estimates curvature using the method described by Turk in <ref type="bibr" target="#b10">[11]</ref> where curvature is derived at each vertex from the angles formed by the incident edges. This curvature estimate is fast to compute and produces good results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Trade-offs of mesh regions</head><p>Although it is desirable to describe an object using several quantization levels, we cannot have arbitrarily small regions. Currently, to prevent cracks at the boundary of two region with different quantizations, we must stitch together the two regions with a set of boundary triangles with vertices that span the two quantization levels. Thus, too many regions will incur more cost in terms of more isolated boundary triangles (which decrease the final vertex reuse).</p><p>Our goal then is to divide a mesh into regions of different quantizations and to keep the number of regions low. This motivates merging the small regions together. A "small" region is one where the region's triangle count is less than a certain fraction of the total triangles. Also, any two remaining adjacent regions can be merged if they have the same quantization levels and their combined region has that same quantization level.</p><p>To summarize, our variable compression method is divided into these steps:</p><p>1. Find regions of similar details by grouping triangles into regions based on triangle size and on curvature. 2. Merge adjacent regions using the merge criteria described above and assign quantization. 3. Meshify and quantize the remaining regions using their calculated quantization. 4. Delta encode the vertices and the normals, and then Huffman encode the deltas to output the final compression stream.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">RESULTS</head><p>We have implemented all the algorithms described here as a part of an OpenGL geometry compression extension. We have tried our optimized geometry compressor on over 120 models from several datasets: large medical isosurfaces produced from the Marching Cubes algorithm, laser range scanned 3D meshes, mechanical CAD models, and a database of Viewpoint DataLabs 3D models. A sample of these models is presented in <ref type="figure" target="#fig_3">Figure 14</ref> and <ref type="table">Table 1</ref>.    <ref type="table">Table 1</ref>: Optimized geometry compression statistics. <ref type="figure" target="#fig_3">Figure 14e</ref> and h show two models compressed using the variable region quantization method. In <ref type="figure" target="#fig_3">Figure 14f</ref> and i, each detailed region is assigned a quantization level (one color per level). In contrast to the static quantization method as shown in <ref type="figure" target="#fig_3">Figure 14d</ref> and g, which assigns one quantization to the whole object, our variable quantization preserved the high frequency details (such as the maiden's face in <ref type="figure" target="#fig_3">Figure 14h</ref>) while still retaining a low average quantization for the entire model. The large models shown in <ref type="figure" target="#fig_3">Figure 14k</ref> and m were compressed without any manual intervention using our automated quantization assignments. By setting the initial error tolerance, to be small (e = 0.1), the compressed models were virtually indistinguishable from the originals <ref type="figure" target="#fig_3">(Figure  14j and l)</ref>. <ref type="table">Table 1</ref> shows our optimized compression statistics. The last two columns show the ratio of uncompressed geometry (in both ASCII and binary encoding formats) to their compressed counterparts. We calculated the "original size" of the ASCII format using independent triangles and the binary format using OpenGL triangle strips with positions and normals represented with full-floating point precision. In the "compressed strip bytes" column, we compressed the models using triangle strips without using either the meshifying algorithm or variable quantization. This is comparable to results using existing compression techniques <ref type="bibr" target="#b1">[2]</ref>.</p><p>Because of the meshifying algorithms and the variable compression method, our results show a two to three-fold improvement over existing geometry compression techniques and an overall 30 to 37 to one compression ratios over ASCII format and 10 to 15 to one over binary triangle strips format. Our variable compression results are shown in "ave quant" column. As compared to a static quantization ("pos quant" column), a variable quantization method lowered the average quantization level for the whole object while still preserving the high frequency details. The values in the "pos quant" column were manually chosen so to preserve the highest details in the models. To match and preserve the same details, we picked a low error threshold e = 0.1 for our quantization assignment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Meshifying algorithm performance</head><p>We measured the performance of the adaptive local algorithm using a subset of the tested objects (using a mesh buffer size of 16 entries). This is shown in <ref type="figure" target="#fig_1">Figure 12</ref>. With the help from the observations made in section 3.2, the adaptive local algorithm reduced the final vertex to triangle ratio closer to the theoretical minimum of 0.5. This is much lower than the ratios produced by the triangle strips algorithm. The same adaptive local algorithm was used to produce the "vert/tri" column in <ref type="table">Table 1</ref>. We found the meshifying process to dominate the compression time ("time" column), which is in the range of a few seconds to minutes for objects of different complexity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Memory bus bandwidth</head><p>We also plotted a graph of the realtime memory bus bandwidth requirements for a sample of the tested objects. The graph shown in <ref type="figure" target="#fig_10">Figure 13</ref> compares the memory cost of rendering uncompressed vs. compressed geometry in real-time (30Hz). The vertical axis shows the memory bus bandwidth (MB/sec) required to send a given amount of geometry memory to the rendering pipeline. The results from our tests clearly show the advantage of using compressed geometry with respect to memory bandwidth costs. Based on our results, as the scene complexity reaches 1 million triangles, the equivalent memory bus bandwidth required for real-time rendering at 30Hz <ref type="figure" target="#fig_1">Figure 12</ref>. Performance of the adaptive meshifying algorithm. The graph plots the vertex to triangle ratio as a function of the input model size. The adaptive algorithm reduced the vertex to triangle ratio closer to the theoretical minimum of 0.5. surpasses 1GB/sec when using uncompressed geometry (average strip size decreased for larger models). Using our optimized geometry compression, this is reduced to less than 105MB/sec, which is manageable even on existing low-end machines.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">SUMMARY AND FUTURE WORK</head><p>Two new techniques for better compressing 3D geometry were presented. First, efficient meshifying algorithms were described for decomposing a given geometry model into the compact generalized triangle mesh format. This representation significantly reduced the number of vertices used to specify a given number of triangles, thus reducing the total geometry size. The local adaptive meshify algorithm was to used to compress over 120 models of various complexity with good results.</p><p>The second contribution allows different regions of a geometric model to be compressed with variable precision depending on the level of detail present at each region. High detailed regions are preserved by quantized less while low detailed ones are quantized more. We have also introduced a method for automating the quantization selection process for geometry compression. This enables unsupervised compression of large geometric databases to be feasible.</p><p>Together, the two optimizations improved 2 to 3 times over the existing compression method based on Deering's work. Our experimental results demonstrated a significant reduction (10 to 15 times less) in the required memory bus bandwidth for real-time visualization of complex geometric datasets. This reduction in memory bandwidth requirements allows high-performance graphics to be accessible for low-cost hardware implementations.</p><p>There are several areas for future work, including:</p><p>1. Combine geometry compression with a multi-resolution, progressive mesh representation <ref type="bibr" target="#b3">[4]</ref> for fast, real-time rendering. 2. Experimentation with global meshifying algorithms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Applications of geometry compression to interactive authoring</head><p>and modeling tools and to 3D rendering API's such as OpenGL and Java 3D <ref type="bibr" target="#b7">[8]</ref>. i.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 .</head><label>2</label><figDesc>triangles for the next strip (Step 4) E. Find boundary edges of the previous strip (repeat Step 3) F. Chain triangles for the next strip (repeat Step 4) C. Find boundary edges of the previous strip (Step 3) B. Chain triangles for the first strip (Step 2) A. Find mesh boundary edges (Step 1) Main steps in the local algorithm.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure</head><label></label><figDesc>3a. A new generalized triangle mesh is created from boundary edges after the previous one has stopped. 3b. After several iterations of the algorithm. a. b. Local_meshify_algorithm(MeshRegion *region) { currGtmesh = gtmeshCreate(); meshInfoAddMesh(region, currGtmesh); /* Step 1: Find mesh boundary edges. */ findMeshBoundaryEdges(&amp;boundaryEdges, MAX_MBUFF_SIZE); /* Step 2: Chain together triangles of the first strip. */ boundaryEdgesGetStripFacets(boundaryEdges, &amp;currStripFacets); while (more triangles in the mesh region){ /* Step 3: Find boundary edges of the previous strip. */ findNextBoundaryEdges(currStripFacets, &amp;boundaryEdges); /* Step 4: Chain together triangles of the next strip. */ change = boundaryEdgesGetStripFacets(boundaryEdges, &amp;nextStripFacets); if (change){ /* Mark the new boundaries of the current strip facets. */ stripFacetsMarkBoundary(currStripFacets); markFacetsAsDiscovered(currStripFacets); /* Step 5: Assign vertex replacement codes to form a gtristrip.*/ gtriStrip = findGeneralTriangleStrip(currStripFacets); /* Step 6: Assign mesh buffer pushes and references. */ assignBufferRefs(gtriStrip, nextStripFacets); gtmeshAddNextStrip(currGtmesh, gtriStrip); currStripFacets = nextStripFacets; } /* No change means no more strips. */ else { /* Start a new general triangle mesh. */ currGtmesh = gtmeshCreate(); meshInfoAddMesh(region, currGtmesh); /* Step 7: Start a new general triangle mesh from a boundary.*/ restartFromBoundaryEdges(&amp;currStripFacets); } } }</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 .</head><label>4</label><figDesc>Pseudocode for the local algorithm.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>totalVerticesVisited:</head><label></label><figDesc>Total vertices in the final generalized triangle meshes. meshBufferReferences: Number of vertices in the generalized triangle meshes which are references to mesh buffer entries. totalTriangles: Number of triangles in the mesh.r totalVerticesVisited meshBufferReferences -totalTriangles ---------------------------------------------------------------------------------------------------------------------</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 5A .</head><label>5A</label><figDesc>Decreasing the number of boundary edges lowers vertex reuse. 5B. Extending the current strip increases the boundary edges to 10 and the number of vertex pushes.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 8 .</head><label>8</label><figDesc>Quantization Grids in 2D. e = 0.25 (K = 4), then q must be 2.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 9 .</head><label>9</label><figDesc>Various values of K chosen for a given triangle size. Top: Setting e = 0.25 (K = 4) leads to a larger error in the final quantization (q=2). Bottom: With e = 0.1 (K = 10), the error is small for the assigned quantization level (q=4).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 10 .</head><label>10</label><figDesc>Separating a mesh into regions by triangle size. To enable variable compression, triangles of region A is separated from those of region B based on the triangle sizes.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 11 .</head><label>11</label><figDesc>Separating a mesh into regions based on curvature. To allow variable compression, the curved bump is separated into a different region from the flat, planar region.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 13 .</head><label>13</label><figDesc>Real-time memory bandwidth requirements. j. Original Marching Cubes Skull. k. Quantized to 11.7 bits. m. 10.2 bits quantization.Figure 14. Optimized Compression Results. a-c show several iterations of the adaptive local meshify algorithm. The pink highlighted triangles show the strip being added to the current generalized triangle mesh. Gray represents the discovered triangles. The spiral pattern avoids leaving behind isolated triangles and increases vertex reuse. d, g and e, h compare static vs. variable quantization. Small details are preserved in e and h but not in d and g which were quantized statically. f and i show the quantization assigned to each region; each color shows one quantization level. j-m compare the original surfaces with the compressed versions using our quantization assignment method (error = 0.1). l. Original Buddha. a. b. h. Schooner, variable quantized to 11.8 bits. f. Quantization assignments. c. g. Schooner, static quantized to 12 bits. d. Acura, static quantized to 10 bits. e. Acura, variable quantized to 10.4 bits.</figDesc></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS</head><p>The author would like to thank many people at Sun Microsystems: Dan Petersen for writing the underlying OpenGL geometry compression extension and for help on this paper, Michael Deering and Aaron Wynn for clarifying many compression details, and Scott Nelson for answering memory bandwidth questions and for comments on the paper. At MIT, thanks go to Marek Techimann and Seth Teller for the discussions of the algorithms and help on this paper. The word "meshify" was coined by Michael Deering in <ref type="bibr" target="#b1">[2]</ref>. The scanned models were from Stanford Graphics Lab, Marching Cubes data from Vtk, and others from Viewpoint DataLabs.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Deering</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Nelson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Leo</surname></persName>
		</author>
		<title level="m">A System for Cost Effective Shaded 3D Graphics. Computer Graphics (Proc. SIGGRAPH)</title>
		<imprint>
			<date type="published" when="1993-08" />
			<biblScope unit="page" from="101" to="108" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Geometry Compression. Computer Graphics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Deering</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. SIGGRAPH)</title>
		<meeting>SIGGRAPH)</meeting>
		<imprint>
			<date type="published" when="1995-08" />
			<biblScope unit="page" from="13" to="20" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Optimizing Triangle Strips for Fast Rendering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Evans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Skiena</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Varshney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Visualization &apos;96</title>
		<meeting>Visualization &apos;96</meeting>
		<imprint>
			<biblScope unit="page" from="321" to="326" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Hoppe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. SIG-GRAPH)</title>
		<meeting>SIG-GRAPH)</meeting>
		<imprint>
			<date type="published" when="1995-08" />
			<biblScope unit="page" from="99" to="108" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Decimation of Triangle Meshes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">J</forename><surname>Schroeder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Zarge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">E</forename><surname>Lorensen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics</title>
		<imprint>
			<date type="published" when="1986" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Silicon Graphics, Inc. Indigo2 IMPACT System Architecture</title>
		<ptr target="http://www.sgi.com/Products/hardware/Indigo2/products/arch.html" />
		<imprint>
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<ptr target="http://www.sun.com/desktop/products/Ultra1" />
		<title level="m">Inc. The UPA Bus Interconnect. Ultra1-Creator3D Architecture Technical Whitepaper</title>
		<imprint>
			<date type="published" when="1996" />
		</imprint>
		<respStmt>
			<orgName>Sun Microsystems</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sun Microsystems</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Inc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Java</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Guide</surname></persName>
		</author>
		<ptr target="http://java.sun.com:80/products/java-media/3D" />
		<title level="m">The Java 3D API</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Teller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">H</forename><surname>Sequin</surname></persName>
		</author>
		<title level="m">Visibility Preprocessing for Interactive Walkthroughs. Computer Graphics (Proc. SIGGRAPH)</title>
		<imprint>
			<date type="published" when="1991" />
			<biblScope unit="page" from="61" to="69" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Taubin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Rossignac</surname></persName>
		</author>
		<ptr target="http://www.research.ibm.com/vrml/binary" />
		<title level="m">Geometry Compression Through Topological Surgery. IBM RC-20340</title>
		<imprint>
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Re-Tiling Polygonal Surfaces. Computer Graphics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Turk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. SIGGRAPH)</title>
		<meeting>SIGGRAPH)</meeting>
		<imprint>
			<date type="published" when="1992" />
			<biblScope unit="page" from="55" to="64" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
