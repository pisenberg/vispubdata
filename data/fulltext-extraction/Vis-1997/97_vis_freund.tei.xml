<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/pisenberg/grobid/grobid-0.6.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Accelerated Volume Rendering Using Homogeneous Region Encoding</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Freund</surname></persName>
							<email>jfreund@sgi.com</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenneth</forename><surname>Sloan</surname></persName>
							<email>sloan@cis.uab.edu</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="laboratory">Silicon Graphics</orgName>
								<address>
									<region>Inc</region>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">University of Alabama at Birmingham</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Accelerated Volume Rendering Using Homogeneous Region Encoding</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2021-02-19T20:35+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>Volume Rendering, Ray-casting</keywords>
			</textClass>
			<abstract>
				<p>Previous accelerated volume rendering techniques have used auxiliary hierarchic al datastructures to skip empty and homogeneous regions. Although some recent research has taken advantage of more efficient direct encoding techniques to skip empty regions, no work has been done to directly encode homogeneous but not empty regions. 3-D distance transforms previously used to encode empty space can be extended to pre-process homogeneous regions as well, and these regions can be efficiently encoded and incorporated into volume ray-casting and back projection algorithms with a high degree of flexibility.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>One of the challenges of volume rendering is speed. It would be useful to have real-time control to help focus quickly on a desired aspect. While surface representations allow nearly instantaneous positioning of a model at a desired viewpoint, the next level of expectation is to be able to maintain this speed, but produce volume renderings of the entire dataset. Unfortunately, volume data is immense compared to geometric data. A typical geometric representation might require a few hundred objects; a similar volume database may contain millions of voxels. Although volume data is immense, there are many special coherency factors inherent to volume data which make these elevated rendering goals tempting.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">PREVIOUS WORK</head><p>Much work has been done to accelerate volume rendering in the image-order (ray-casting) and object-order (backprojection) domains.</p><p>Early accelerated volume rendering techniques used hierarchical data struct ures such as K-d trees <ref type="bibr" target="#b11">[12]</ref> and octrees <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b10">11]</ref> to quickly traverse empty regions of the volume data, thus reducing the number of samples needed to construct an image.</p><p>Later, several papers used hierarchical datastructures to accelerate rendering of homogeneous as well as empty regions <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b14">15]</ref>. Homogeneity-accelerated ray-casting techniques accelerate a ray through portions of the volume data in exchange for error. The use of a hierarchical datastructure, has several drawbacks. Each method must choos e a single, global parameter for their octrees to determine where the error should be distributed. They differ in the choice of this parameter. Arvo <ref type="bibr" target="#b0">[1]</ref> uses density, meaning that regions of low density are automatically assumed to be unimportant. Van Gelder, et al <ref type="bibr" target="#b14">[15]</ref> use the average deviation from the average intensity value in a node. Laur and Hanrahan <ref type="bibr" target="#b8">[9]</ref> store average intensity values in octnodes to control the sampling rate. Danskin and Hanrahan <ref type="bibr" target="#b4">[5]</ref> use density ranges to gain a speedup from regio ns which are relatively uniform. None of the techniques give the user the ability to change an importance classification independently of the global parameter.</p><p>Although these assumptions work intuitively well when the user does not want to accurately focus on a particular part of the data, it is restrictive if the user wishes to determine, for each anatomy, how much error can be tolerated independent of that anatomy's intensity value. The use of octrees also leads to speed penalties during rendering. In addition to requiring extra storage, octrees must be indexed differently from the volume data. Complicating the innermost loop of rendering with octree traversal code reduces the effect of any savings gained by accelerating rays through octnodes. Finally, the use of octrees dices regions at octnodes. Rather than having each voxel encode it's own region, an octree can dice a region at many levels at the boundary of an octnode.</p><p>To circumvent the problems of hierarchical datastructures, later techniques ex plored other forms of encoding such as a look-aside buffer, flat pyramid or proximity cloud to encode empty space <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b15">16]</ref>, amorphous "shell" encodings to allow interactive thresholding <ref type="bibr" target="#b12">[13]</ref>, or run-length encodings to precisely skip empty regions <ref type="bibr" target="#b7">[8]</ref>. The success of these techniques over hierarchical methods stems from their encoding scheme where encodings or "skips" are indexed with the same indices used for the volume data. Most recently, the greatest time savings have been made with Lacroute's <ref type="bibr" target="#b7">[8]</ref> shear-warp back-projection algorithm which precisely skips empty regions of space.</p><p>This paper extends the successful idea of directly encoding empty regions to include homogeneous regions. In Section 3, we show a method for constructing homogeneous regions and a datatype for efficiently encoding them. In Section 4, we show how the direct encoding of homogeneous regions can be used to accelerate volume ray-casting beyond speeds realized by hierarchical schemes or schemes which directly encode only empty regions. In Section 5 we present a new algorithm which extends Lacroute's fast shear-warp back-projection algorithm <ref type="bibr" target="#b7">[8]</ref> to use our encoded homogeneous regions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">HOMOGENEOUS REGIONS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Empty Region Distance Transforms</head><p>Proximity clouds <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b15">16]</ref> use a 3-D distance transform <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b16">17]</ref> to accelerate rays through empty space. A "proximity'' or "skip" field is calculated by a distance transform algorithm which computes the distance from each empty voxel, to the nearest opaque voxel, making each voxel the center of its own empty region. This "skip" field is the distance that may be safely skipped along any ray which samples that voxel. Based on a user-defined transparency threshold, the distance transform calculation is an inexpensive linear time operation, calculated once for the entire volume dataset.</p><p>There are several ways to compute an empty space distance transform, and all of them require a two-step initialization phase to compute a distance map. The distance map generated empty space distance transforms record, for each voxel, the distance to the nearest opaque voxel. First, voxels are classified as being transparent or non-transparent. Those which are transparent are called background, and are initialized to the maximum distance in a distance map. The rest are called foreground and are initialized to zero (or the minimum distance).</p><p>Next, interior voxels are removed by overlaying a simple six-connected neighbor mask at each voxel. If the center voxel and all six neighbors are foreground, the center voxel is changed to background. The result of this initialization phase is a distance map where voxels on the surface of non-transparent regions are initialized to the minimum distance.</p><p>After the distance map has been initialized, there are several ways to compute the distance transform. Our implementation uses a fast distance transform calculation presented in <ref type="bibr" target="#b2">[3]</ref> which propagates a wavefront of Euclidean distances represented by x and y components, through the volume. A wavefront (represented as a queue) of distances is grown from each foreground voxel until voxels in the distance queue reach the maximum distance or a border. After the queue is exhausted, the Pythagorean theorem is used to compute integer approximations to the true Euclidean distance from the x and y components.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Homogeneous Region Distance Transform</head><p>With a slight modification to the initialization phase, any distance transform algorithm can be made to generate distances for homogeneous as well as empty regions. Instead of using an isovalue determination to label a voxel as transparent or non-transparent, each voxel is tagged or colored according to what kind of region it lies in. There are many possible ways of identifying regions. Regions could be identified by thresholding, by using a contouring scheme, using local information such as a gradient operator, or by using any number of graph, split-and-merge, or region growing techniques. Because the choice of homogeneous region identification algorithms is so varied and application-dependent, this choice is left open.</p><p>We separate the question of region boundary definition from the volume data. Instead of using a parameter of the volume such as density, opacity, or homogeneity to control error bracketing and sample spacing, our direct encoding scheme allows complete control over how regions are identified. This allows the user to have flexibility in changing parameters. The disadvantage is that the user is responsible for choosing a suitable technique to identify region boun daries.</p><p>After voxels are identified according to their region, interior voxels must be removed using a similar kind of neighborchecking filter to that used by empty space encoding distance transforms. If a voxel has been identified as belonging to the same region as its six neighbors, it is set to background in the corresponding distance map. At the end of this initialization phase, only voxels corresponding to the surfaces of identified regions will be set to the foreground (see Plate 1a).</p><p>After the ho mogeneous region initialization phase is complete, any of the empty space distance transform computation algorithms mentioned in the beginning of Section 3.1 can finish the job. The resulting distance map will record the distance from each voxel to the nearest boundary voxel whether that voxel happens to be inside an empty or homogeneous region (see Plate 1b).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Data Encoding</head><p>Once the volume is pre-processed to find homogeneous regions, skip fields must be stored in an efficient manner. We tested several skip encoding methods for speed and storage efficiency which are all similar in their purpose, but differ in implementation details which lead to different optimizations in the volume traversal portion of rendering algorithms. The most straightforward way to encode skip information is to create a look-aside volume <ref type="bibr" target="#b16">[17]</ref> of skip fields which correspond to each voxel. Although this encoding scheme requires a secondary volume of byte-sized skip fields, it does not require extra overhead for indexing because the same indices into the voxel database will index the look-aside volume.</p><p>Proximity clouds <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b15">16]</ref> do not require auxiliary storage for encoding skip fields. Proximity clouds store skip fields in place of voxel intensities wherever a voxel contains air. Nonair voxels simply store the original voxel intensity. This duality leads to a minor dilemma. It is not possible for a voxel to contain an intensity less than the maximum possible skip size. Fortunately, this should not cause concern because low voxel densities are usually classified as transparent.</p><p>Medical imaging scanners typically produce twelve bit (or less) intensity values for each voxel. On most computers, this data is stored in sixteen bit words. This leaves four bits available for other uses. Like the proximity cloud datatype, our "hybrid" datatype stores skip sizes in empty voxels. For nontransparent voxels, we take advantage of the upper four unused bits to encode skip information. The dilemma in representing skip sizes instead of low intensity values is avoided because it is possible to encode a voxel with an intensity less than the maximum skip size in our hybrid datatype as long as that voxel has an encoded skip (of any size). <ref type="figure">Figure 1</ref> shows how our hybrid datatype would encode skip fields in a typical 16 bit word.</p><p>Unlike previous hierarchical encoding schemes mentioned in Section 2, this hybrid datatype requires no auxiliary skip storage, no additional indexing, and no additional memory accesses to fetch skip fields. Datasets consisting of 8 bit samples incur a two fold memory penalty because an extra byte for each voxel must be used to store the skip field. The maximum skip size of 15 provided by these upper four bits is more than adequate for recording skip fields because our experiments show the tradeoff in speed for skip size falls logarithmically as the speed bottleneck shifts from traversing and sampling the volume to other parts of the rendering algorithm. Using a ray-caster, the diff erent encoding techniques were compared for their inherent efficiency on three volume datasets. The 3dhead and 3dknee <ref type="bibr" target="#b13">[14]</ref> are 256x256x109 MRI datasets of 8 bit intensity values. The hipip <ref type="bibr" target="#b13">[14]</ref> dataset is a 64x64x64 electron density map of a high-energy protein molecule. <ref type="table">Table 1</ref> shows a comparison of the inherent efficiency of the skip encoding datatypes when tested with our three datasets.</p><p>Because proximity cloud and look-aside datatypes can only encode empty regions, <ref type="table">Table 1</ref>  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">RAY-CASTING</head><p>Skip fields can easily be used to accelerate ray-casting. Skip fields indicate how large a jump any ray sampling that voxel may take in any direction. The skip is also used as a weight for sampling that voxel so the sample will represent the linear span of voxels the ray traverses. The upper four skip size bits of a hybrid voxel conveniently double as an index into precomputed higher-weighted portions of the anatomy classification table, giving us sampling weight multiplications for the price of the anatomy classification lookup.</p><p>Our homogeneous region ray-caster was tested by rendering a clean image of each of the datasets mentioned in Section 3.3. For each dataset, we classified anatomy by assigning colors, opacities, and a transparency threshold. The wavefront <ref type="bibr" target="#b2">[3]</ref> algorithm was used to generate Euclidean skip fields which were then encoded using our "hybrid" datatype. When zero error is required, our method can render a perfect image using the same amount of pre-processing time as other ray-casting algorithms which directly encode empty regions. The time used by our algorithm to render an error-free image is comparable to <ref type="bibr" target="#b15">[16]</ref> (refer back to <ref type="table">Table 1</ref>).</p><p>If some image error can be tolerated, then image quality can be traded for a rendering speedup. We tested the amount of time which could be saved during ray-casting against the amount of image error generated by encoding various sized homogeneous regions. Our experiment re-processed each of the three volume datasets 15 times for a range of uniformly relaxed to incrementally more stringent gradient threshold values. A simple gradient threshold was used to identify region boundaries, and skip fields were created using our homogeneous region distance transform, and stored using our hybrid datatype. Danskin and Hanrahan <ref type="bibr" target="#b4">[5]</ref>, from whom our error metric was taken, noted that a 20% error in image quality was usually the maximum useful limit. The graph in <ref type="figure" target="#fig_2">Figure 2</ref> shows the tradeoff between speed and accuracy for our homogeneous region accelerated ray-caster on each of the datasets. All experiments generate 256 2 pixel images. . This is not a precise problem description because we do not need to compute an optimal solution, nor can we do so in a reasonable amount of time (the perfect solution is probably NP-hard). Our imperfect solution favors extracting larger regions rather than smaller ones because fewer large regions can fit inside a volume. It is easy, however, to think of a counterexample where it would not be preferable to extract the largest regions first. A brute force approach to extracting non-overlapping homogeneous regions makes a sweep through the volume once for each possible skip size (in order from largest to smallest), pulling out regions of that skip size which do not overlap any other region. Certain information associated with extracted regions is appended to a list of regions datastructure. Each voxel which is part of an extracted homogeneous region must be tagged so that other regions will be able to check against that voxel for possible overlap.</p><p>The brute force algorithm is effective at finding sets of large, non-overlapping homogeneous regions. Unfortunately, it is very slow because it traverses the entire volume once for each possible skip size, and it must visit every voxel within the shell's neighborhood to determine if one region overlaps with another. On a 256 x 256 x 100 MRI volume dataset, the brute force homogeneous region extraction algorithm typically runs from 15 seconds to several minutes on a Pentium Pro 200 computer. Time varies a great deal, depending on both the number and the size of non-overlapping homogeneous regions found <ref type="bibr" target="#b5">[6]</ref>.</p><p>A faster version of the greedy algorithm can be developed based on the observation that the next largest non-overlapping region can be found in logarithmic time <ref type="bibr" target="#b5">[6]</ref>. The fast homogeneous region extraction algorithm uses an octree to direct queries to the next largest homogeneous region. After creating the initial octree, this algorithm runs approximately six to eight times faster than the brute force method. <ref type="table">Table 1</ref>: Render times (in seconds) for each encoding method to produce a 0% error image, taking advantage of empty region encoding only. Our hybrid datatype was usually as efficient as the proximity cloud encodings. The list of regions datastructure simply stores certain attributes of extracted regions that will later be required for rendering. The color of the region is pre-computed as the average color of all voxels contained in the region. Because it is possible for a region to contain different shades of anatomy, we only need to keep track of the average col or (not intensity) value over the entire region, computed as:</p><formula xml:id="formula_0">Region color = c n i i n = ∑ 0</formula><p>where n is the number of samples enclosed in the region and c i is the pre-multiplied color and opacity of a sample in the region. The only other information about the extracted region that is required is the location of its center and its skip size.</p><p>The last phase of pre-processing compresses remaining voxels into a run-length encoded (RLE) datastructure as described in <ref type="bibr" target="#b7">[8]</ref>. The RLE datastructure consists of two arrays: an array of alternating transparent and non-transparent scanline run lengths and an array of non-transparent voxel values. The memory saved by compressing non-transparent, nonhomogeneous voxels into run length arrays allows for the creation of a different RLE datastructure for each major viewing axis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Rendering</head><p>Our accelerated homogeneous region back-projection algorithm operates in two phases.</p><p>The first phase is identical to Lacroute's fas t shear-warp back-projection algorithm <ref type="bibr" target="#b7">[8]</ref>. Runlength encoded voxels are projected onto an intermediate image which is then 2-D warped to become the final image. In the second phase, footprints of the extracted homogeneous regions are blended into the final image.</p><p>The image produced by warping the intermediate image will be a perfect rendering of the non-transparent, non-occluded voxels, minus extracted homogeneous regions. The last step of the rendering process adds extracted homogeneous regions back into the final image. Our algorithm saves time by drawing 2-D images of the 3-D extracted homogeneous regions. Extracted regions are blended into the final image from the list of regions structure generated during pre-processing. This is done by first projecting each region on to the image plane in order to find out its image space coordinates. Then the average region color is blended into the image according to weights for each position in a re-sampling mask. This weight indicates how deep the region is at a particular point in the mask.</p><p>The Euclidean distance metric generated by Bouts ' algorithm <ref type="bibr" target="#b2">[3]</ref> was chosen during pre-processing in our implementation because it constructs roughly spherical regions--and homogeneous spheres look roughly the same from any angle.</p><p>Our implementation uses an approximating 2-D resampling filter with pre-computed weights for each possible region size. Masks are constructed by first computing the number of pixels used by each row and column in the mask. Then the weight of each position in the mask is computed as the minimum of its row and column sizes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Results and Discussion</head><p>We tested the amount of time which could be saved by our object-order renderer against the amount of image error generated by encoding various sized homogeneous regions.</p><p>Again, a simple gradient threshold was used to identify region boundaries, and skip fields were created using our homogeneous region distance transform. Our experiment reprocessed each of the three volume datasets 15 times for a range of uniformly relaxed to incrementally more stringent gradient threshold values.</p><p>Our homogeneous region accelerated object-order renderer is capable of pre-processing volume data and rendering perfect images in the same amount of time as Lacroute's algorithm <ref type="bibr" target="#b7">[8]</ref>.</p><p>If, however, image error is acceptable, we were able to cut rendering time nearly in half with less than 4% image error <ref type="figure">(Figure 4</ref> and Plate 2d). Speed and image quality might be further improved by using more sophisticated region boundary identification schemes, or by focusing on detail in specific regions rather than using a global, uniform gradient threshold as in our experiments. The group of dots in the upper-left corner of the hipip graph in <ref type="figure">Figure 4</ref> represents attempts to relax region thresholds in order to reduce rendering time. Because voxel intensities from this dataset represent smooth transitions from high to low potential, the dataset demonstrates the worstcase behavior of homogeneous region accelerated renderers.</p><p>Shading is a slight problem in the object-order rendering algorithm. Tissue highlights generated by a shading function can get "averaged out " in extracted homogeneous regions. A partial solution to this is to simply use the average pre-shaded and pre-multiplied color and opacity value when extracting homogeneous regions. Fortunately, shading should not pose much of a problem because most shading algorithms affect only tissue surfaces whose true shaded color values can stay intact with the RLE volume.</p><p>Error is introduced at three stages during pre-processing and rendering:</p><p>• During the two re-sampling steps as the volume is transformed into sheared-object space,</p><p>• By approximating the color of a region from it's average color, • By approximating the thickness of a region from any angle using a single pre-computed mask. The first error source is inherent to any object-order rendering technique which uses the shear-warp factorization. Lacroute reported that error due to resampling is negligible <ref type="bibr" target="#b7">[8]</ref>. The second source of error depends on the user's region definitions. If homogeneity definitions are strict, then relatively small amounts of error will be incurred. The last source of error is dependent on several factors such as the viewing angle, the distance metric chosen to encode homogeneous regions during <ref type="figure">Figure 4</ref>: Total render time used by homogeneous region accelerated back-projection algorithm. Rendering time is cut almost in half with less than 4% image error. 3dknee 3dhead hipip pre-processing, and the weights used to compute the depth of each point in the re-sampling mask. We chose the Euclidean distance metric so that regions would look roughly symmetrical from any angle, however any distance metric should work as long as weights are computed properly. If error generated at this stage is of concern, then new region re-sampling masks could be re-computed each time the viewing angle changes.</p><p>The homogeneous region accelerated back-projection algorithm only works for parallel projections right now. This is not a limitation of sheared-object space.</p><p>Lacroute <ref type="bibr" target="#b7">[8]</ref> developed a transformation to sheared-object space which allows for perspective projections. In order to allow for perspective projections in our algorithm, it would be necessary to compensate for the scaling effect on our omnidirectional homogeneous regions. Another limitation of our object-order renderer is that it currently does not support the use of the "over" operator. Instead, samples must be collected by blending rgba values because homogeneous regions are composited after scanning.</p><p>The over operator might be incorporated into our back-projection algorithm if extracted homogeneous regions were to be sorted by depth for each principal viewing axis.</p><p>This way, scanning could be interrupted each time a region is encountered so the region could be drawn into the image at the correct time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">CONCLUSIONS</head><p>If no image error can be tolerated, our homogeneous region rendering algorithms can easily be made to fall back on a conventional empty space distance transform to produce a perfect rendering in the same amount of time as previous algorithms. If a small amount of image error is tolerable, and homogeneous regions exist in the volume, a significant additional speedup can be gained with little or no extra cost in pre-processing time.</p><p>In Section 3.2, standard distance transforms which had previously been used to encode empty space distances, were used to compute distance transforms for homogeneous regions. Direct encoding of homogeneous regions provides flexibility over hierarchical based encoding techniques, giving the user control over importance for each anatomy. In Section 3.3, we showed that during ray-casting, our hybrid datatype is just as efficient as other direct encoding datatypes, while allowing for both empty and homogeneous regions to be directly encoded.</p><p>In Section 4, it was demonstrated that our homogeneous region accelerated raycaster can cut rendering time of other empty-space skipping ray-casters in half with little image error. Finally, in Section 5, we showed that our homogeneous region accelerated objectorder renderer cut rendering time of Lacroute's <ref type="bibr" target="#b7">[8]</ref> algorithm in half with less than 4% image error. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 3 :</head><label>3</label><figDesc>Hybrid datatype stores just a skip in the range of[1..15]  for transparent voxels, and a combination o skip and intensity values for non-transparent voxels.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>The first phase of pre-processing for our homogeneous region scanning algorithm computes and stores skip fields for homogeneous regions, as in Section 3.2 (see Plates 1a,b). Next, the fewest number non-overlapping homogeneous regions, covering the most amount of space, are extracted from the volume data, (see Plate 1c)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Homogeneous regions encoded with our hybrid datatype generally doubl ed ray-casting speed with 2% -6% overall loss in image quality. 3dknee 3dhead hipip</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Plate 1 :Plate 2 :</head><label>12</label><figDesc>Pre-processing phase of object-order homogeneous region accelerated volume rendering algorithm. (a) Identify region boundaries. (we used a simple gradient thresholding technique) (b) Compute distance transform and encode skip fields directly into volume (c) Extract largest nonoverlapping homogeneous regions. Rendering phase of object-order homogeneous region accelerated volume rendering algorithm. (a) Rendering of RLE encoded volume (b) Rendering of extracted homogeneous regions (c) Composite of Plates 2a and 2b. (d) Clean rendering. The average error (of colored pixels) between Plates 2c and 2d is 3.2%; however, Plate 2c was rendered in about half the time as Plate 2d.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>compares our hybrid encodin g scheme when only transparent (and not homogeneous) regions have been encoded in the datasets.</figDesc><table><row><cell></cell><cell>3dhead</cell><cell>3dknee</cell><cell>hipip</cell></row><row><cell>Hybrid</cell><cell>4.50</cell><cell>5.96</cell><cell>5.71</cell></row><row><cell>Proximity</cell><cell>4.69</cell><cell>4.66</cell><cell>5.75</cell></row><row><cell>Look-aside</cell><cell>7.45</cell><cell>9.48</cell><cell>7.70</cell></row><row><cell>No Skips</cell><cell>8.35</cell><cell>10.36</cell><cell>5.87</cell></row></table><note></note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Adaptive error bracketing for controlled-precision volume rendering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Arvo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Salesin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Novins</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1992-04" />
			<biblScope unit="page" from="92" to="1312" />
			<pubPlace>New York</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Cornell University</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Distance transforms in digital images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Borgefors</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Graphics, &amp; Image Processing</title>
		<imprint>
			<date type="published" when="1986" />
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="344" to="71" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A fast, error free, Euclidean distance transform</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Bouts</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of VIP &apos;93 (International Conference on Volume Image Processing</title>
		<meeting>VIP &apos;93 (International Conference on Volume Image Processing<address><addrLine>Utrecht, the Netherlands</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1993" />
			<biblScope unit="page" from="47" to="49" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Proximity clouds -an acceleration technique for 3D grid traversal</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Shefer</surname></persName>
		</author>
		<idno>TR FC93-01</idno>
		<imprint>
			<date type="published" when="1993-02" />
			<pubPlace>Israel</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Ben Gurion University</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Fast algorithms for volume ray tracing. TR-1991</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Danskin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Hanrahan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1991-11" />
			<pubPlace>Princeton University</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Volume processing assisted volume rendering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Freund</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1997-06" />
		</imprint>
		<respStmt>
			<orgName>University of Alabama at Birmingham</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Ph.D. dissertation</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Shape-based interpolation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">T</forename><surname>Herman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Jinsheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">A</forename><surname>Bucholtz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer Graphics and Applications</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="69" to="79" />
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Fast volume rendering using a shear-warp factorization of the viewing transformation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Lacroute</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Levoy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of SIGGRAPH &apos;94</title>
		<meeting>of SIGGRAPH &apos;94</meeting>
		<imprint>
			<date type="published" when="1994-08" />
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="451" to="457" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Hierarchical splatting: a progressive refinement algorithm for volume rendering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Laur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Hanrahan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of SIGGRAPH &apos;91</title>
		<meeting>SIGGRAPH &apos;91</meeting>
		<imprint>
			<date type="published" when="1991-08" />
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="285" to="288" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">University of North Carolina at Chapel Hill</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Levoy</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1988" />
		</imprint>
	</monogr>
	<note type="report_type">Ph.D. dissertation</note>
	<note>Display of surfaces from volume data</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Efficient ray tracing of volume data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Levoy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans on Graphics</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="245" to="271" />
			<date type="published" when="1990-07" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Applying space subdivision techniques to volume rendering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Subramanian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Fussell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">S</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of Visualization &apos;90</title>
		<meeting>of Visualization &apos;90</meeting>
		<imprint>
			<date type="published" when="1990" />
			<biblScope unit="page" from="150" to="158" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Shell rendering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Udupa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Odhner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Comput. Graph. &amp; Applications</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="58" to="67" />
			<date type="published" when="1993-12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">UNC) The 3dhead, 3dknee, and hipip datasets are available for public FTP from the University of North Carolina at Chapel Hill at ftp</title>
		<imprint/>
	</monogr>
	<note>unc.edu</note>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Hierarchically accelerated ray casting for volume rendering with controlled error</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Van Gelder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wilhelms</surname></persName>
		</author>
		<idno>CRL-95-31</idno>
		<imprint>
			<date type="published" when="1995-03" />
		</imprint>
		<respStmt>
			<orgName>University of California at Santa Cruz</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Tech Report</note>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Shell accelerated volume rendering of transparent regions. The Visual Computer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Yagel</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1994-11" />
			<biblScope unit="page" from="53" to="61" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Acceleration of ray-casting using 3D distance transforms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Zuiderveld</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Koning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Viergever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Visualization in Biomedical Computing</title>
		<imprint>
			<date type="published" when="1992" />
			<biblScope unit="page" from="324" to="335" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
