<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/pisenberg/grobid/grobid-0.6.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Volume Rendering of Abdominal Aortic Aneurysms</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roger</forename><forename type="middle">C</forename><surname>Tam</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of British Columbia</orgName>
								<address>
									<addrLine>2366 Main Mall, Vancouver, British Columbia, V6T 1Z2</addrLine>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">G</forename><surname>Healey</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">EECS Department, CS Division</orgName>
								<orgName type="institution">University of California at Berkeley</orgName>
								<address>
									<addrLine>549 Soda Hall #1776, Berkeley</addrLine>
									<postCode>94720, 1776</postCode>
									<region>California</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Borys</forename><surname>Flak</surname></persName>
							<affiliation key="aff3">
								<orgName type="department">Department of Radiology</orgName>
								<orgName type="institution">University of British Columbia</orgName>
								<address>
									<postCode>V6T 1Z3</postCode>
									<settlement>Vancouver</settlement>
									<region>British Columbia</region>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Cahoon</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of British Columbia</orgName>
								<address>
									<addrLine>2366 Main Mall, Vancouver, British Columbia, V6T 1Z2</addrLine>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Departments of Computer Science and Radiology</orgName>
								<orgName type="department" key="dep2">CS Division</orgName>
								<orgName type="institution" key="instit1">University of British Columbia EECS Department</orgName>
								<orgName type="institution" key="instit2">University of California at Berkeley</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Volume Rendering of Abdominal Aortic Aneurysms</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2021-02-19T20:37+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>aneurysm</term>
					<term>colourization</term>
					<term>computed tomography</term>
					<term>CT</term>
					<term>image processing</term>
					<term>medical imaging</term>
					<term>scientific visualization</term>
					<term>segmentation</term>
					<term>volume rendering</term>
				</keywords>
			</textClass>
			<abstract>
				<p>Volume rendering is a valuable and important technique for scientific visualization. One well known application area is the reconstruction and visualization of output from medical scanners like computed tomography (CT). 2D greyscale slices produced by these scanners can be reconstructed and displayed onscreen as a 3D model. Volume visualization of medical images must address two important issues. First, it is difficult to segment medical scans into individual materials based only on intensity values. This can result in volumes that contain large amounts of unimportant or unnecessary material. Second, although greyscale images are the normal method for displaying medical volumes, these types of images are not necessarily appropriate for highlighting regions of interest within the volume. Studies of the human visual system have shown that individual intensity values are difficult to detect in a greyscale image. In these situations colour is a more effective visual feature, since the lowlevel visual system can rapidly and accurately detect the presence or absence of a particular target colour in a multicoloured image. We addressed both problems during the visualization of CT scans of abdominal aortic aneurysms. We have developed a classification method that empirically segments regions of interest in each of the 2D slices. We use a perceptual colour selection technique to identify each region of interest in both the 2D slices and the 3D reconstructed volumes. The result is a colourized volume that the radiologists are using to rapidly and accurately identify the locations and spatial interactions of different materials from their scans. Our technique is being used in an experimental post-operative environment to help to evaluate the results of surgery designed to prevent the rupture of the aneurysm. In the future, we hope to use the technique during the planning of placement of support grafts prior to the actual operation.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Volume visualization displays data representing volumetric objects as 3D models on a computer screen. Volume rendering focuses on one part of the volume visualization problem: the reconstruction and display of the 3D model. This allows users to view their data sets in an appropriate three-dimensional context. Various techniques, such as the use of transparency and cutting planes, can be used to simultaneously display both the surface and the interior of the volume. One important application of volume visualization is the display of 3D medical volumes. Medical techniques like computed tomography (CT) and magnetic resonance imaging (MRI) use equipment that scans the body in a user-chosen direction. The result is a set of 2D intensity maps representing cross-sectional slices through the body. Different intensities in a slice correspond to different materials (e.g., bone, muscle, and fat) detected during the scan. The intensity values returned by the scanner are often adjusted to try to highlight areas of interest within the volume. Stacking the slices together and resampling the data allows for the reconstruction of a volume representation of the scanned region ( <ref type="figure" target="#fig_0">Figure 1</ref>). Finally, the results are displayed onscreen, allowing radiologists to visually explore and analyze the output of the medical scanner.</p><p>Although 3D reconstructed volumes are often a dramatic improvement over the original 2D slices, the techniques used to build the volumes must address a number of important problems. Different materials detected during the scan will have overlapping greyscale ranges. This makes it difficult to isolate a particular type of material based only on the intensity values in the 2D slices. The 3D reconstructed volumes are often displayed in greyscale, using pixel intensities that are directly proportional to tissue density. In many cases this is appropriate, since difference in intensity most effectively captures the high spatial-frequency differences that occur in these types of images. However, greyscale images may not be as useful when a user is searching for the location of a particular material within the volume. Partial occlusion of the interior of the volume, the inability of the low-level visual system to rapidly and accurately find specific intensity values, and the possibility of overlapping greyscale ranges can combine to result in a time consuming search through the image. In the worst case, the material in question may be accidentally overlooked, reducing the value of the effort spent to build and display the volume.</p><p>In this paper we address both problems in the context of a specific set of medical images: CT scans of abdominal aortic aneurysms. First, we have developed a new classification method to empirically determine the correct boundaries for regions of interest in our scans; material that does not correspond to one of these regions is eliminated from each of the 2D slices. Second, we use a colourization technique to distinguish each of our regions of interest in both the 2D slices and the 3D reconstructed volume. A perceptual colour se- lection algorithm is used to guarantee that the colours we choose are all equally differentiable from one another. The result is a colourized volume that the radiologists can use to rapidly and accurately identify the exact locations of individual materials of interest. Our techniques are being used in an experimental post-operative environment to assess the effectiveness of grafts placed within aortic aneurysms. In the future, we hope to use our visualizations to help to plan placement of the grafts prior to an operation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1">Abdominal Aortic Aneurysms</head><p>An abdominal aortic aneurysm (AAA) is a focal dilation of the abdominal aorta (which has a normal diameter 2cm) usually below the level of the renal arteries ( <ref type="figure" target="#fig_1">Figure 2</ref>). Patients that develop AAAs likely have a basic genetic predisposition as this disease unequivocally runs in families. Other contributing factors probably include smoking and high blood pressure. By the age of 80, over 5% of white males will develop an AAA. AAAs are among the top ten causes of death in white males over 55, due to their propensity to silently enlarge and subsequently rupture resulting in shock and ultimate death in more than 80% of cases. For unknown reasons the prevalence in elderly males is five times that of females.</p><p>Size of the AAA is the best predictor of risk of rupture. Over a period of only a few years an AAA measuring 5 to 6cm in diameter has a rupture rate of about 50%. Therefore, most surgeons agree that a repair should be undertaken unless there are other underlying medical conditions making the procedure too risky. Other worrisome features heightening the risk of imminent rupture include rapid expansion of the AAA (greater than 0.5cm/yr) or the development of abdominal pain unexplained by other causes.</p><p>Traditional repair of an AAA entails a major operation with an incision into the aneurysm, evacuation of the clot contained within, placement of a synthetic graft, and wrapping of the graft with the remnants of the wall of the AAA. Mortality rates from the surgery are in the range of 1 to 2%. The associated hospital stay is typically 7 to 10 days, several of which are spent in the intensive care unit. The patient generally requires 6 to 8 weeks of recovery at home prior to commencing normal activity. Many elderly patients are simply in too poor a medical condition to survive the surgery. Because of these factors a new treatment option, endovascular stenting, has been proposed and is currently undergoing clinical trials. This pro-Tynes <ref type="figure">Figure 3</ref>: Stent grafts, showing a bifurcation graft placed in the iliac arteries (upper image), and a close-up of a graft and the tynes used to support it and hold it in place in the artery (lower image) cedure does not require general anaesthesia and can be done less invasively by simply placing a self-expanding stent ( <ref type="figure">Figure 3</ref>) via a catheter into the AAA to stabilize it. Less fit patients are able to withstand the procedure, hospital stay is cut to 1 to 2 days, and postoperative recovery is shortened considerably.</p><p>Several key pieces of information are necessary prior to undertaking any repair (either operative or endovascular), including: accurate measurement of AAA diameter and length, determination of distance between the renal arteries and the proximal end of the AAA, and measurement of the distance between the distal end of the AAA and the aortic bifurcation ( <ref type="figure" target="#fig_1">Figure 2</ref>). There are a number of imaging modalities available including angiography, ultrasound, computed tomography (CT) and magnetic resonance imaging (MRI) which are capable of providing the answers to varying degrees, but all suffer from a number of shortcomings. Therefore, we have turned to 3D reconstruction of axial spiral CT images (MRI images could be used interchangeably) in an attempt to solve the shortcomings.</p><p>Spiral CT enables extremely fast scanning through the range of the AAA. This allows a volumetric data set to be obtained free of misregistration artifacts. Optimum opacification of the aorta, which brightens the vessel in greyscale images, can be done using an intravenous contrast material. This improves the ease of segmentation. The volumetric data also allows for overlapping reconstructions of thinly collimated scans, which further enhances resolution in the Zaxis, thereby reducing staircase artifacts.</p><p>We hypothesize that 3D reconstructions that can be rotated and viewed from any angle will be the most accurate representation of the relationship between the neck of the aneurysm and the renal arteries and thus will provide the best measurements. This can often be difficult to appreciate in 2D due to the tortuosity (that is, the amount of twisting and bending) of the aorta in this region. Measuring distances accurately is paramount to both types of repair. In the case of operative repair one must determine if there is adequate space to clamp the aorta, and in the case of endovascular repair if adequate space is available to anchor the stent below the renal arteries. Positioning the stent inappropriately across the renal arteries would result in their occlusion, most likely leading to permanent renal failure. Measuring the distance between the distal end of the AAA and the aortic bifurcation will determine whether a tube stent can be used, or whether a more complicated bifurcation stent or graft will be necessary. Accurate diameter measurement of the AAA is required to properly size the stent. This is optimally done at right angles to the long axis of the AAA, a view that is difficult to provide using only 2D slices. Improper sizing may result in leakage of blood around the graft, which defeats the purpose of the procedure (i.e., the prevention of further AAA expansion). An incorrectly sized stent might also dislodge and drift downstream. The length of the AAA, ideally along the bloodflow centerline, needs to be known to determine proper stent length. Again, this representation is only available in a 3D image. A stent that is too short may result in subsequent AAA development in the unprotected segment of the aorta, while a stent that is too long may result in the stent kinking. Finally, a post-operative rendering can be useful for judging final stent position.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.2">Volume Visualization</head><p>There are many three-dimensional rendering methods available for visualizing medical data. We believe that volume rendering <ref type="bibr" target="#b3">[4]</ref> is the most appropriate for our application. This technique produces high quality images without any intermediate geometric representation, which may be time-consuming to generate. In our case, the metal tynes that support the stent graft form a pattern ( <ref type="figure">Figure 3</ref>) that would be extremely difficult to reconstruct using a surface-based method. The resulting images have also been shown to be very effective in the portrayal of the relationships among anatomical structures <ref type="bibr" target="#b8">[9]</ref>, especially through the use of colour and transparency. This is important, since the aneurysm surrounds the aorta and the stent graft. Volume rendering is the most effective way to see the entire stent graft and aorta without losing detail contained in the aneurysm. Also, since volume rendering preserves information about each object's interior as well as its surface, clipping the volume at various angles can be used as an effective method for measuring parts of the volume. This technique can provide the radiologists with the accurate AAA measurements they require during their surgical procedures.</p><p>This paper presents the results to date of our research into using volume rendering for the analysis of AAAs. This work is similar in principle to <ref type="bibr" target="#b0">[1]</ref>, but has a less clinical emphasis. Rather, we focused on reconstruction methodologies and the use of perceptual rules during volume rendering. The next three sections describe in detail our techniques for segmenting and classifying the 2D slices, colouring the resulting regions of interest, and displaying and manipulating the reconstructed volume.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">METHODOLOGY</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Segmentation and Classification</head><p>Segmentation involves processing the raw greyscale images to enable or enhance the visualization of structures that are useful for analysis, while suppressing or eliminating the structures that would otherwise obstruct our view of the areas of interest. In our case, the objects that we need to view as clearly as possible are the aorta and branch vessels, the aneurysm, and the metal tynes that support the stent graft. The Dacron fabric of the stent graft does not appear appreciably in the 2D images, so the tynes are the only way of determining the position of the graft. Objects such as the spine, kidneys, and fatty tissue should not appear to any significant extent in the volume rendering.</p><p>There are many segmentation methods available, ranging in complexity from manual editing to knowledge-based domain-specific techniques. The decision of which methods to use depends on characteristics of the greyscale images and properties of the volume renderer. For example, probabilistic classifiers, which assign the percentage of individual tissues within each voxel from greyscale intensities or CT values <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b4">5]</ref>, have trouble separating structures that have similar greyscale ranges in the 2D images. Using a combination of techniques, such as those described in <ref type="bibr" target="#b5">[6]</ref> for visualizing livers with tumors, is often the most effective approach.</p><p>In our case, we find that a combination of simple cropping and percentage classification can separate out most of the structures of interest. Percentage classification is a generalized form of thresholding that allows a voxel to contain a mixture of tissue types. This minimizes aliasing effects such as staircasing or jagged edges at tissue-density transitions <ref type="bibr" target="#b7">[8]</ref>.</p><p>We use percentage classification to create smooth and accurate boundaries between the tynes and the aorta and between the aneurysm and air. Unfortunately, using percentage classification to separate the aorta and air introduces two visual artifacts into our volume. The first occurs when we pass from air into a blood vessel. In the greyscale slices air is black (an intensity value 0), the aneurysm is grey (intensity values ranging from approximately 0.4 to 0.5), and blood vessels are bright white (an intensity value near 1.0). If we use percentage classification, voxels at the boundary of a blood vessel will be classified as some part air and some part vessel. This will result in an intermediate intensity for the voxel. If that intermediate intensity happens to lie in the greyscale range for the aneurysm, the voxel will be incorrectly classified as part of the aneurysm.</p><p>The second type of visual artifact also occurs at the wall of a blood vessel. Percentage classification will identify voxels on the boundary of the vessel as some part vessel wall and some part surrounding material. In order to provide effective antialiasing, we need to assign a reasonably large opacity to the vessel walls. However, the stent grafts lie inside the vessel walls. Increasing the opacity of the walls hides the grafts and their corresponding tynes. Since clarity of the tynes is vital to analyzing which parts of the vessel wall are supported, we decided that most of the vessel wall should be thresholded out. In cases where there is no stent graft, visibility of the tynes is not an issue, and aliasing by default is significantly reduced. Because of the visual artifacts described above, we chose to use simple thresholding to segment the blood vessels.</p><p>Using our intensity-based techniques, the most problematic object to segment is the aneurysm itself, because of its similarity in intensity to other soft tissue that often surrounds it. In most cases the aneurysm spans only 30 to 40 slices, and is fairly well-defined in shape in the 2D images. Because of this, it is easy for the radiologists to identify slices that contain some part of the aneurysm. For slices that do not contain aneurysm tissue, pixel values with similar intensity ranges can simply be classified as air. For slices that do contain the aneurysm, a number of manual and semi-automatic techniques were investigated to try to segment the aneurysm (e.g., interactive clipping planes and region growing), however, none of these methods gave completely satisfactory results. Moreover, in order to reconstruct the volume quickly, we would like to avoid as much human-interaction as possible when the slices are segmented.</p><p>Accurate boundary values are required for percentage classification and thresholding. We have developed an effective method for empirically determining these values. Since CT images are typically 16-bit, and most display systems do not support greyscale images greater than 8 bits deep, scaling is usually required to visualize the 2D slices. This can cause loss of information in cases in which we are interested in objects at both the high and low ends of the intensity range. In our case, the blood vessels and tynes have the highest intensity values, whereas the aneurysm has much lower intensities. Scaling the entire range down to 256 values causes the boundaries between the blood vessels and the tynes to become indistinct. <ref type="figure" target="#fig_2">Figure 4a</ref> shows this lack of definition when we try to view all the regions of interest simultaneously. Our solution is to analyze the high and low-order bytes of the image separately, thereby minimizing unnecessary scaling. Two images of the slice are formed, one using only the high-order bytes <ref type="figure" target="#fig_2">(Figure 4b</ref>), the other using only the low-order ones <ref type="figure" target="#fig_2">(Figure 4c</ref>). The high-order image shows the high- est pixel intensities, quantized into ranges of width 256. For example, a pixel with intensity value 1 is actually a pixel with an intensity value between 2 8 and 2 9 , 1 in the original image. This gives a rough classification of the high pixel values. We then adjust this image with information gained from looking at the low-order image, which contains information about the variations within these ranges, as well as the lower intensity pixel values, until we get an image that is representative of the classification that we want <ref type="figure" target="#fig_2">(Figure 4d</ref>). In our case, the low-order image contains all of the aneurysm intensities, as well as those of the blood vessel walls. <ref type="figure" target="#fig_2">Figure 4b</ref> shows the tynes and the aorta very clearly, with some "bleeding" from the tynes, an effect that is typical when metal objects are scanned with CT. <ref type="figure" target="#fig_2">Figure 4c</ref> shows the boundary of the aneurysm very clearly. We start with (b) and bring in parts that we want from (c). In essence, (b) is used as a mask, and the strength of the mask at each pixel depends on properties derived from (c). We obtain important characteristics from both images (i.e., the boundaries between the aorta and the tynes from <ref type="figure" target="#fig_2">Figure 4b</ref>, and the boundary of the aneurysm itself from <ref type="figure" target="#fig_2">Figure 4c</ref>). These characteristics are necessary to produce <ref type="figure" target="#fig_2">Figure 4d</ref>, which shows the tynes (with no bleeding), the aorta and the aneurysm all very clearly. Note that noise within the aorta in (c), an artifact created by splitting the original image, exactly cancels that from (b).</p><p>Although the adjustment stage requires some human intervention, once a classification for a certain scanning protocol has been determined, it never needs to be changed. The classification can automatically segment any scan derived from the given CT protocol. Protocols for a given patient condition change infrequently in a clinical environment, so the need to perform this adjustment procedure is rare.</p><p>The advantages of analyzing the two bytes separately include having to look at far fewer pixel values in general, being able to view all of the data simultaneously without scaling, and the inherent simplicity of the method. In all of the cases to date, our classification and rendering techniques give the aneurysm enough clarity so that other segmentation methods are unnecessary. We believe this method has potential application in analyzing other types of highcontrast scans.</p><p>Once the classifications have been determined, a colour and an opacity is assigned to each tissue type. The tynes are given the highest opacity, followed closely by the blood vessels. The aneurysm is given approximately half the opacity value of the blood vessels. The result is an image where the tynes and aorta show through the aneurysm very well, giving a complete 3D view of structural relationships between the three objects of interest.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Colourization</head><p>We use colour to highlight each of the three objects of interest (the arteries, the aneurysm, and the tynes) in our reconstructed 3D volumes. Normally, greyscale images are used to visualize 3D medical volumes <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b9">10]</ref>, because the high spatial-frequency components in a typical medical volume are most easily detected by the visual system through differences in luminance.</p><p>The radiologists are interested in rapidly identifying the general location of each object of interest, in particular they want to see where the tynes lie within the arteries and the aneurysm. We felt representation using colour would be most effective for this type of visual region detection. Studies of the human visual system have shown that only the two end values of a greyscale range can be rapidly and accurately detected in a greyscale image <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b11">12]</ref>; values from the interior of the range are much more difficult to identify. Previous work in our laboratory found that up to seven different colours can be displayed simultaneously, while still allowing a viewer to rapidly and accurately determine whether any one of the colours is present or absent in an image <ref type="bibr" target="#b6">[7]</ref>. Finally, our segmen-tation procedure allows us to identify uniquely the three objects of interest. Material that does not correspond to one of these objects is removed from the CT slices before they are visualized.</p><p>We use our colour selection algorithm to choose three colours to represent the three objects in our reconstructed volumes. The colours are chosen to maximize perceived difference to one another using a multi-criteria selection technique <ref type="bibr" target="#b6">[7]</ref>. This is in contrast to the traditional methods of colour selection for medical volumes, which are largely based on aesthetics <ref type="bibr" target="#b7">[8]</ref>. In our case, selection is performed in a perceptually balanced colour model, where the Euclidean distance between pairs of colours can be used to approximate their perceived colour difference. We use the CIE LUV colour model, although any perceptually balanced model can be chosen. Colours are selected such that:</p><p>The distance between them is constant and above a minimum threshold.</p><p>Each colour can be separated from all of the other colours by a straight line.</p><p>Each colour occupies a unique named colour region, that is, no two colours occupy the same named colour region.</p><p>Results from the original colour selection experiments showed that all three effects need to be considered to guarantee equally distinguishable colours.</p><p>The algorithm begins by defining a colour region from which to choose colours. Individual colours are selected from the boundary of this region. Each colour is chosen such that it has minimum distance and linear separation from all the other colours. Normally, colour distance (to the nearest neighbour) and linear separation are held constant for each colour. For example, in <ref type="figure" target="#fig_3">Figure 5</ref> we are choosing five colours that lie along the circumference of a circle. The circle sits in a 2D isoluminant slice through the CIE LUV colour model. By selecting colours that are equidistant around the circle, we guarantee that each colour has a constant distance d to its two nearest neighbours, and a constant linear separation l from all the other colours. Finally, we must ensure that no two colours occupy the same named colour region. Notice that the circle in <ref type="figure" target="#fig_3">Figure 5</ref> has been subdivided into eight named regions. We use a simple technique to quickly divide any part of a colour model (in this case, the circumference of a circle embedded in CIE LUV) into named regions. Our technique uses an automatic step to initially divide the model into ten named regions. This is followed by a short experimental step, where individual users name representative colours from each of the ten regions. This allows us to compress regions that have a high perceptual overlap with one another. In our example two regions were compressed, resulting in the final eight regions shown in <ref type="figure" target="#fig_3">Figure 5</ref>. Notice that the five example colours we have chosen are all located in their own named region.</p><p>Although the original experiments were restricted to isoluminant colours (i.e., colours with the same perceived brightness), for the CT images we choose colours with different intensities. There is evidence which shows that a random intensity pattern masks the identification of colour boundaries <ref type="bibr" target="#b2">[3]</ref>. However, in our images individual colour regions are spatially connected, resulting in spatially coherent intensity regions (as opposed to a random pattern of different intensities). Using colours with different intensities allows us access to a larger number of named colour regions (e.g., colours that we name "yellow" must be bright, otherwise they are named "brown"). Using colours with different intensities also helps to highlight the boundaries between different objects of interest.</p><p>The radiologists ask us to avoid using greens during visualization, since green and green-yellow are conceptually identified as bile in these types of medical images. We used our selection technique to choose colours from the non-green regions of our monitor's colour gamut. The result was three colours: a purple-blue (monitor RGB=142, 141, 163) that is used to represent the aneurysm, a yellow (monitor RGB=194, 149, 8) that is used to represent the blood vessels, and a red (monitor RGB=255, 0, 6) that is used to represent the tynes. The three objects of interest are visualized in colour in both the 2D CT slices and the 3D reconstructed volume. There was some concern that the alpha-blending used to visualize the 3D volume might skew our colours. However, the final images do not exhibit this problem. The colours we chose allow the radiologists to rapidly and accurately identify the exact locations of the tynes, the arteries, and the aneurysm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Volume Rendering</head><p>The volume renderer that we are using is a modified version of Volren, a product of Silicon Graphics, Inc. (SGI) that is based on the OpenGL graphics language. The basic principle behind this renderer is to define the volumetric data as a three-dimensional texture and render it by mapping it onto a stack of "display slices" that are orthogonal to the viewing direction <ref type="bibr" target="#b1">[2]</ref>. After the texture data is built, lookup tables are used to colourize it. The slices are then blended as they are rendered back to front <ref type="figure">(Figure 6</ref>). This technique can take advantage of the hardware-accelerated texture mapping capabilities of certain workstations, such as the SGI Indigo II High Impact that we are currently using. Our modifications to Volren include adding several resampling filters (variants of a Gaussian filter) for noise removal. Another enhancement is an increase in the number of display slices on which the texture is mapped (this includes a corresponding decrease in the distance between display slices, to ensure the size of the object does not change). This improves considerably the quality of the images, especially in areas where the user is looking through a semi-transparent object.</p><p>Volren includes a number of features that are especially important to our application. It allows the user to interactively rotate and clip the volume, which is very useful for determining the geometry of an object. Not only can this provide the clinicians with the exact static view that they want, but the motion gives them important depth information as well <ref type="bibr" target="#b7">[8]</ref>. Volren also allows the user to interactively modulate the overall opacity of the volume. We have carefully chosen the opacities of the aorta, tynes and aneurysm so that decreas-  <ref type="figure">Figure 6</ref>: Volren Algorithm ing the overall opacity mostly affects the visibility of the aneurysm.</p><p>In this manner, we can have the aneurysm ranging from completely opaque to entirely invisible, depending on where we want to focus our analysis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">RESULTS</head><p>An actual clinical data set is used to demonstrate our techniques. The patient is an elderly male with a large abdominal aortic aneurysm and a bifurcation stent graft installed. The original data consists of 128 slices from a Toshiba Xpress SX helical CT scanner. The slices were reconstructed at 3mm intervals to produce the greyscale images. Other than removal of the spine behind the aorta, no manual segmentation was done in preparation for rendering. The data sets contain 128 slices of size 128128 pixels. Volren requires, on average, about five seconds to read a data set, and about 17 seconds to display an initial rendering. After the initial rendering is produced, the data set can be manipulated interactively by the user (our machines can display approximately 10 frames per second). In order to demonstrate the effectives of both the mask segmentation technique and proper colour selection, consider a reconstructed AAA volume using four different representations. The simplest visualization <ref type="figure">(Figure 7a</ref>) displays the volume without segmentation or colour selection. <ref type="figure">Figure 7b</ref> shows the result of masking unimportant material, but continues to use greyscale intensities to visualize the resulting volume. Colour Plate 1a displays the segmented volume with a set of colours previously selected by the radiologists. Finally, Colour Plates 1b-1d display the segmented volume with a set of colours chosen using our colour selection algorithm.</p><p>Greyscale images produced with no masking and no colour selection provide little or no information of interest to the viewer. Most of the important objects are occluded or hidden by materials near the outer edge of the volume. Volren allows us to change the opacities of different materials, and to apply cutting planes to try to cull out unimportant areas of the volume <ref type="figure">(Figure 7a</ref>). None of these techniques, however, will allow us to obtain a clear view of only the aneurysm, the arteries, and the tynes.</p><p>The greyscale image in <ref type="figure">Figure 7b</ref> is much more effective than an unmasked rendering. Our masking technique has been used to remove material in the volume that does not correspond to the aneurysm, the artery walls, or the tynes. Whereas images with no masking are essentially unusable, the representation in <ref type="figure">Figure 7b</ref> provides a variety of information about the scanned region. Because of the initial masking step, the structure of arteries and the aneurysm is clearly displayed. Viewers can also distinguish between the aneurysm and the artery walls.</p><p>The voxel intensities used in <ref type="figure">Figure 7</ref> are directly proportional to the original pixel intensities in the unprocessed 2D images <ref type="figure" target="#fig_2">(Figure 4)</ref>. As with those images, certain areas in the volume suffer from the same lack of definition in the tyne boundaries. The tyne positions are only visible outside of the aneurysm. When the aneurysm  <ref type="figure">Figure 7</ref>: Volume rendering in greyscale: (a) a volume displayed without segmentation, cutting planes and transparency were used to show a cross-section of the aneurysm and the aorta; (b) the same volume after applying our initial segmentation step, the structure of the aneurysm and aorta are now clearly visible and the arteries overlap, the locations of the tynes are hidden. Decreasing the opacity of the aneurysm will eventually show the tynes, but at that point the aneurysm itself becomes so transparent that its boundaries and depth can no longer be identified. We feel <ref type="figure">Figure 7b</ref> represents a good tradeoff between the ability to see the tynes in the artery walls and the opacity of the aneurysm. Although it is possible to identify the general location of the tynes within the artery, the specific patterns they form, and the locations where different grafts mesh with one another are not readily apparent. Moreover, it is difficult to see whether there is adequate reinforcement of the blood vessels.</p><p>Colour Plate 1a shows the same reconstructed CT volume as Figure 7. Our masking technique was used to ensure that only the arteries, aneurysm, and tynes were included in the 2D slices used during the reconstruction. A colourmap chosen by radiologists was applied to the resulting volume. The colourmap was obtained in a trial and error fashion to try to best represent data from individual data sets; perceptual issues were not considered when the colourmap was designed. Colouring the volume provides a dramatic improvement over the greyscale image. The structure of the scanned region is very clear, due in large part to our initial masking step. The colourmap used by the radiologists does a good job of highlighting the artery walls and the tyne locations (represented by yellow and red, respectively). However, the aneurysm itself (shown as a red cloud around the artery) is not as well defined. In particular, when the aneurysm overlaps with the artery, it disappears from view. This makes it very difficult for the radiologists to determine depth from the image, in particular, it is almost impossible to tell how far certain parts of the aneurysm extend from the wall of the artery. To obtain this measurement, the radiologists needed to rotate the volume repeatedly, in an effort to avoid looking "straight-on" at the aneurysm and the underlying arteries and tynes. Increasing the opacity of the aneurysm makes it stand out more strongly. However, this begins to obscure the location of the tynes. Colour Plate 1a was the best tradeoff we could obtain between showing clearly the artery wall and tyne locations, and increasing the opacity of the aneurysm to show fully its 3D structure.</p><p>The problems encountered in Colour Plate 1a occur because the colours used for the arteries, aneurysm, and tynes are not equally distinguishable from one another. We used our colour selection technique to choose three new colours; our algorithm tries to ensure that any of the colours can be rapidly and accurately detected in the image. The radiologists asked us to avoid choosing green or greenyellow colours, since these are associated with bile in the context of coloured medical volumes. This requirement significantly reduced which parts of the colour model were available to us. In spite of this, we were able to pick three colours that had a very strong perceived difference from one another. These colours were used to produce the volume in Colour Plate 1b. The location of the tynes within the artery walls is as clear as in Colour Plate 1a. Moreover, the entire 3D structure of the aneurysm can be clearly identified. Depth information is not lost when the aneurysm and the artery wall overlap with respect to the viewing direction. Our colours make it easy for the radiologists to estimate how far the aneurysm extends from the artery wall. Using perceptual rules to select our colours provides a more effective visualization, even when compared to the colourmap previously being used by the radiologists.</p><p>Colour Plate 1c uses Volren's interactive cutting planes to slice diagonally through the volume. The slice allows us to measure the cross-sectional area of the aneurysm and the two iliac arteries. It also shows how the tynes are positioned just inside the wall of the artery. This image also helps to demonstrate the advantages of volume rendering when compared to other techniques like 2D slices or surface representations. 2D slices are taken at a fixed orientation through the volume. This makes it impossible to look at cuts through the volume from a different viewing direction. Sur-face models support arbitrary viewing directions, but they lose information about the density of material within the volume. Information about the thickness and density of the aneurysm would not be available in a surface rendering. This is especially important in cases where leakage from the stent into the aneurysm occurs, because changes in the density of the aneurysm would be symptomatic of this condition.</p><p>Colour Plate 1d uses a viewing direction that is orthogonal (or "straight-on") to one of the iliac arteries. This viewing direction shows the zigzag pattern the tynes make when they are embedded within the artery. Our masking technique is capable of extracting this level of detail in each 2D slice, even in these smaller blood vessels. Applying an effective colourmap allows effortless detection of the locations, patterns, and interactions between different materials in the volume. Note that we can view the pattern of the tynes much more clearly on the artery that is perpendicular to the viewing direction, in contrast to the artery that is heading away from the viewer. This shows how the ability to change viewing angles can be important in volume visualization. The interactive rotation feature in Volren is extremely useful in such cases. Colour Plate 1d also shows increased opacity in the aneurysm, also interactively adjustable, as compared to the other images in Colour Plates 1a-1c.</p><p>The radiologists have now started to use our results to view their CT scans. The figures in Colour Plate 1 represent a post-operative scan of a patient who underwent the endovascular stenting procedure. Our visualizations allow the radiologists to identify important details in the volume. For example, when the radiologists looked at the volume in Colour Plate 1b, they immediately noticed an area in the artery that was not supported by the grafts (the two large yellow areas inside the aneurysm in Colour Plate 1b that have no red, and hence no tynes supporting them). This occurred because one of the grafts in the iliac artery was not pushed up far enough to mesh with its upstream partner. Although this poses little risk to the patient, it is very useful for the radiologists to be able to examine the results of their surgical procedures in this manner. Other visualization techniques (e.g., surface meshes or 2D slices) would have made it more difficult for the radiologists to identify and estimate the size of this region of low support. In the future, we hope to use our volume rendering technique to allow the radiologists to help in planning the surgical procedure.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">CONCLUSIONS</head><p>In this paper we have presented ongoing work in the use of volume rendering in the pre and post-operative analysis of abdominal aortic aneurysms. Each CT data set passes through two stages during visualization: a segmentation stage to isolate the regions of interest (the aneurysm, the arteries, and the tynes), and a colourization stage to highlight each region.</p><p>We investigated a number of common segmentation techniques (e.g., interactive clipping planes and region growing) when we tried to identify the aneurysm, the arteries, and the tynes in each 2D slice. Unfortunately, none of these gave completely satisfactory results. To overcome this, we developed a new segmentation technique that empirically combines low and high-order intensity images to classify accurately objects of interest in a set of 2D CT slices. Our technique effectively identifies the locations of and boundaries between the three regions of interest. This is crucial to reconstructing an accurate 3D volume.</p><p>We also discussed a perceptual method for selecting groups of highly distinguishable colours. Our technique uses three separate criteria to build groups of colours which can be rapidly and accurately identified from one another. Colours obtained using this technique improved the effectiveness of our visualizations when compared to both greyscale images and colourmaps chosen in a more aesthetic fashion. Finally, we showed how our rendering techniques can be used to display and analyze real clinical data in a number of important and useful ways.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">FUTURE WORK</head><p>There are a number of areas that we hope to improve upon in order to produce even more accurate images in a shorter period of time. Anti-aliasing measures to reduce staircasing at blood vessel and air boundaries is topmost on the list, because most radiologists consider this to be an important issue. Experiments aimed at smoothing the boundaries by interpolation methods have had some initial success.</p><p>Another area we plan to address is the segmentation procedure. Since the shape of aneurysm tissue is well-defined in the 2D slices, some form of automatic segmentation seems to be a realistic shortterm goal. As mentioned previously, region-growing methods have strong potential here.</p><p>All of our classifications are currently determined by empirically selecting tissue boundary values, because fairly simple automatic techniques such as histogram-based classification <ref type="bibr" target="#b5">[6]</ref> do not work well for our data. Even though we can generate transfer functions fairly quickly with our current methods, it would be desirable to have a way of automatically modifying these functions to account for changes in the scanning parameters (e.g., the intravenous contrast material being used).</p><p>The use of stereoscopic displays is another area for further exploration. Preliminary tests have suggested that clinicians would find stereo useful for establishing depth cues without rotating the volume and thereby altering the viewpoint. Combining stereo displays with a built-in measurement tool would be helpful for volumetric analysis.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Scanning and 3D reconstruction, a medical scanner generates 2D slices, which are segmented, coloured, and reconstructed into a 3D volume</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>An image of the abdominal anatomy, showing the major arteries and organs of interest</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4 :</head><label>4</label><figDesc>Segmentation and classification of a 2D CT slice; (a) the original slice with greyscale intensities reduced to 8 bits; (b) the high intensity pixel values, quantized into ranges of width 256; (c) the low intensity pixel values; (d) the segmented result</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 5 :</head><label>5</label><figDesc>Five colours selected along the circumference of a circle embedded in a slice through the CIE LUV colour model; each colour is equidistant along the circle, to guarantee a constant distance d to its two nearest neighbours, and a constant linear separation l from all the other colours</figDesc></figure>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0" />			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Volumetric analysis of abdominal aortic aneurysms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><forename type="middle">M</forename><surname>Baskin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Catherine</forename><forename type="middle">A</forename><surname>Kusnick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sussane</forename><surname>Shamsolkottabi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elvira</forename><forename type="middle">V</forename><surname>Lang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><forename type="middle">D</forename><surname>Corson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><surname>Stanford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brad</forename><forename type="middle">H</forename><surname>Thompson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><forename type="middle">A</forename><surname>Hoffman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedingsof the SPIE Conference on Medical Imaging 1996: Physiology and Function from Multidimensional Images</title>
		<meeting>of the SPIE Conference on Medical Imaging 1996: Physiology and Function from Multidimensional Images</meeting>
		<imprint>
			<date type="published" when="1996" />
			<biblScope unit="page" from="323" to="337" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Accelerated volume rendering and tomographic reconstruction using texture mapping hardware</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brian</forename><surname>Cabral</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nancy</forename><surname>Cam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jim</forename><surname>Foran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings 1994 ACM/IEEE Symposium on Volume Visualization</title>
		<meeting>1994 ACM/IEEE Symposium on Volume Visualization</meeting>
		<imprint>
			<publisher>IEEE CS Press Order No. PR07067</publisher>
			<date type="published" when="1994" />
			<biblScope unit="page" from="91" to="97" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Dimensional interaction of hue and brightness in preattentive field segregation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">C</forename><surname>Callaghan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Perception &amp; Psychophysics</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="25" to="34" />
			<date type="published" when="1984" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Volume rendering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">A</forename><surname>Drebin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Carpenter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Hanrahan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="65" to="74" />
			<date type="published" when="1988" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Three-dimensional reconstruction of the human body</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elliot</forename><forename type="middle">K</forename><surname>Fishman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><forename type="middle">A</forename><surname>Drebin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ralph</forename><forename type="middle">H</forename><surname>Hruban</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Derek</forename><forename type="middle">R</forename><surname>Ney</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Donna</forename><surname>Magid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">American Journal of Radiology</title>
		<imprint>
			<biblScope unit="volume">150</biblScope>
			<biblScope unit="page" from="1419" to="1420" />
			<date type="published" when="1988" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Surgical planning for liver reconstruction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elliot</forename><forename type="middle">K</forename><surname>Fishman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brian</forename><forename type="middle">S</forename><surname>Kuszyk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><forename type="middle">G</forename><surname>Heath</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luomin</forename><surname>Gao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="64" to="72" />
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Choosing effective colours for data visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">G</forename><surname>Healey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Visualization &apos;96</title>
		<meeting><address><addrLine>San Francisco, California</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1996" />
			<biblScope unit="page" from="263" to="270" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Volume rendering of computed tomography data: Principles and techniques</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Derek</forename><forename type="middle">R</forename><surname>Ney</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elliot</forename><forename type="middle">K</forename><surname>Fishman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Donna</forename><surname>Magid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer Graphics &amp; Applications</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="24" to="32" />
			<date type="published" when="1990" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Volume rendering for display of multiple organs, treatment objects, and image intensities</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Stephen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Pizer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Henry</forename><surname>Levoy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julian</forename><forename type="middle">G</forename><surname>Fuchs</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Rosenman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the SPIE Conference on Science and Engineering of Medical Images</title>
		<meeting>the SPIE Conference on Science and Engineering of Medical Images</meeting>
		<imprint>
			<date type="published" when="1989" />
			<biblScope unit="volume">1137</biblScope>
			<biblScope unit="page" from="92" to="97" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">An architecture for rule-based visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernice</forename><forename type="middle">E</forename><surname>Rogowitz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lloyd</forename><forename type="middle">A</forename><surname>Treinish</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings Visualization &apos;93</title>
		<meeting>Visualization &apos;93<address><addrLine>San Jose, California</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1993" />
			<biblScope unit="page" from="236" to="243" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Color sequences for univariate maps: Theory, experiments, and principles</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Ware</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer Graphics &amp; Applications</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="41" to="49" />
			<date type="published" when="1988" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">The role of categorization in visual search for orientation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeremy</forename><forename type="middle">M</forename><surname>Wolfe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stacia</forename><forename type="middle">R</forename><surname>Friedman-Hill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marion</forename><forename type="middle">I</forename><surname>Stewart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kathleen</forename><forename type="middle">M</forename><surname>O'connell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: Human Perception &amp; Performance</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="34" to="49" />
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Limitations on the parallel guidance of visual search: Color color and orientation orientation conjunctions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeremy</forename><forename type="middle">M</forename><surname>Wolfe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><forename type="middle">P</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marian</forename><forename type="middle">I</forename><surname>Stewart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amy</forename><forename type="middle">D</forename><surname>Shorter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stacia</forename><forename type="middle">R</forename><surname>Friedman-Hill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyle</forename><forename type="middle">R</forename><surname>Cave</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: Human Perception &amp; Performance</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="879" to="892" />
			<date type="published" when="1990" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
