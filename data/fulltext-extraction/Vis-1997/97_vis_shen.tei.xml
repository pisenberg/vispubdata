<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/pisenberg/grobid/grobid-0.6.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">UFLIC: A Line Integral Convolution Algorithm For Visualizing Unsteady Flows</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han-Wei</forename><surname>Shen</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">MRJ Technology Solutions NASA Ames Research Center NASA Ames Research Center</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><forename type="middle">L</forename><surname>Kao</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">MRJ Technology Solutions NASA Ames Research Center NASA Ames Research Center</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">UFLIC: A Line Integral Convolution Algorithm For Visualizing Unsteady Flows</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2021-02-19T20:36+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>I.3.3 [Computer Graphics]: Picture/Image Generation</term>
					<term>I.3.6 [Computer Graphics]: Methodology and Techniques</term>
					<term>I.4.3 [Image Processing]: Enhancement flow visualization, vector field visualization, image convolution, line integral convolution, flow animation, unsteady flows, surface flows, texture synthesis</term>
				</keywords>
			</textClass>
			<abstract>
				<p>This paper presents an algorithm, UFLIC (Unsteady Flow LIC), to visualize vector data in unsteady flow fields. Using the Line Integral Convolution (LIC) as the underlying method, a new convolution algorithm is proposed that can effectively trace the flow&apos;s global features over time. The new algorithm consists of a time-accurate value depositing scheme and a successive feed-forward method. The value depositing scheme accurately models the flow advection, and the successive feed-forward method maintains the coherence between animation frames. Our new algorithm can produce time-accurate, highly coherent flow animations to highlight global features in unsteady flow fields. CFD scientists, for the first time, are able to visualize unsteady surface flows using our algorithm.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Vector field data arise from computer simulations in a variety of disciplines such as computational fluid dynamics (CFD), global climate modeling, and electromagnetism. Visualizing these vector data effectively is a challenging problem due to the difficulties in finding suitable graphical icons to represent and display vectors on two-dimensional computer displays. Presently, new challenges emerge as time-dependent simulations become ubiquitous. These simulations produce large-scale solutions of multiple time steps, which carry complex dynamic information about the underlying simulation model. To visualize these time-varying data, two types of methods are generally used. One may be referred to as the instantaneous method where calculations are based on an instance of the data field in time. Examples are streamlines and vector plots. The other method is the time-dependent method which can better characterize the evolution of the flow field by continuously tracking the visualization results over time. Examples are streaklines and pathlines computed from unsteady flow data <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b4">5]</ref>.</p><p>This paper presents a time-dependent method for visualizing vector data in unsteady flow fields. Using the Line Integral Convolution (LIC) <ref type="bibr" target="#b0">[1]</ref> as the underlying method, we propose a new convolution algorithm, called UFLIC (Unsteady Flow LIC), to accurately model the unsteady flow advection. The Line Integral Convolution method, originally proposed by <ref type="bibr">Cabral</ref>  tor data input to characterize the flow field's global features. While this method is effective, it is primarily for steady flow data. Forssell and Cohen <ref type="bibr" target="#b1">[2]</ref> propose an extension using a streakline convolution 1 for the time-varying vector field. However, several problems associated with the algorithm, such as obscure coherence within and among the output image frames and less accurate temporal manipulation, greatly limit its effectiveness in practice. A detailed analysis of their algorithm is provided in the next section. In our algorithm, we propose a time-accurate value depositing scheme and a successive feed-forward method to perform the line integral convolution. By progressively updating the visualization results in time, UFLIC can produce highly coherent animation frames and accurately trace the dynamic flow movement. The main contribution of this work is to provide a time-accurate global visualization technique to analyze unsteady flow data.</p><p>We begin this paper by giving an overview of the LIC method. Next, we describe and analyze Forssell and Cohen's algorithm for unsteady flows. We then present our UFLIC algorithm. We conclude this paper by presenting results of applying our method to several unsteady flow data sets from CFD simulations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Background and Related Work</head><p>In this section, we briefly review the LIC method proposed by Cabral and Leedom <ref type="bibr" target="#b0">[1]</ref>. We then describe and analyze the method proposed by Forssell and Cohen <ref type="bibr" target="#b1">[2]</ref> for unsteady flow field data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Line Integral Convolution</head><p>The Line Integral Convolution method is a texture synthesis technique that can be used to visualize vector field data. Taking a vector field and a white noise image as the input, the algorithm uses a low pass filter to perform one-dimensional convolution on the noise image. The convolution kernel follows the paths of streamlines originating from each pixel in both positive and negative directions. As a result, the output intensity values of the LIC pixels along each streamline are strongly correlated so the global features of the flow field can be easily visualized. To perform the convolution, different periodic filter kernels can be used. Examples are the Hanning filter <ref type="bibr" target="#b0">[1]</ref> and the box filter <ref type="bibr" target="#b7">[8]</ref> <ref type="bibr" target="#b6">[7]</ref>.</p><p>Recently, several extensions to the original LIC algorithm have been proposed. Forssell and Cohen <ref type="bibr" target="#b1">[2]</ref> adapt the LIC method for curvilinear grid data. Stalling and Hege <ref type="bibr" target="#b7">[8]</ref> propose an efficient convolution method to speed up the LIC computation. Shen, Johnson, and Ma <ref type="bibr" target="#b6">[7]</ref> combine dye advection with three dimensional LIC to visualize global and local flow features at the same time. Okada and Kao <ref type="bibr" target="#b5">[6]</ref> use post-filtering techniques to sharpen the LIC output and highlight flow features such as flow separations and reattachments. Recently, Kiu and Banks <ref type="bibr" target="#b2">[3]</ref> propose using multi-frequency noise The texture outputs from the Line Integral Convolution method provide an excellent visual representation of the flow field. This effectiveness generally comes from two types of coherence. The first is spatial coherence, which is used to highlight the flow lines of the field in the output image. The LIC method establishes this coherence by correlating the pixel values along a streamline as the result of the line integral convolution. The second type of coherence is temporal coherence. This coherence is required for animating the flow motion. The LIC method achieves this temporal coherence by shifting the filter phase used in the convolution so that the convolved noise texture can periodically move along the streamlines in time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Line Integral Convolution for Unsteady Flows</head><p>The LIC technique proposed originally is primarily for visualizing data in steady flow fields. To visualize unsteady flow data, Forssell and Cohen propose an extension <ref type="bibr" target="#b1">[2]</ref>. In contrast with convolving streamlines in the steady flow field, the algorithm convolves forward and backward pathlines originated from each pixel at every time step. A pathline is the path that a particle travels through the unsteady flow field in time. To animate the flow motion, the algorithm shifts the filter's phase at every time step to generate the animation sequence.</p><p>Forssell and Cohen's algorithm for visualizing unsteady flows has several problems. First, their algorithm does not establish clear spatial coherence. To explain this, in <ref type="figure" target="#fig_0">Figure 1</ref> a pathline P1 that starts from pixel A at time T1 and passes through pixel B at time T2 is the convolution path for pixel A. Similarly, pathline P2 starting from B at time T1 is the convolution path for pixel B. Since pathlines P1 and P2 pass through B at different times (T2 and T1, respectively), they have different traces. As a result, convolution values of A and B are uncorrelated because two different sets of pixel values are used. Hence, no spatial coherence is established in either pathline P1 or P2. In Forssell and Cohen's paper, it is mentioned that flow lines in the output images become ambiguous when the convolution window is set too wide. The problem mentioned here can explain this phenomenon.</p><p>The second problem of the algorithm is that the convolution value of each pixel at any given time is derived from a mixture of past and future flow information. For instance, in <ref type="figure" target="#fig_0">Figure 1</ref>, pathline P1 starting from A does not reach B until T2. However, in the algorithm, B's pixel value is included in the convolution of pixel A at time T1.</p><p>This mixture implies that the convolution result at any given time can be influenced by what will happen in the future, which is unphysical.</p><p>The third problem of the algorithm is that the temporal coherence in the unsteady flow field is difficult to establish by using the phaseshift method. This is because the pathlines from the same seed point vary over time unless the flow is relatively steady. Therefore, in the algorithm the same filter with shifted phases is applied to different convolution paths. However, the effectiveness of using the phaseshift method to create artificial motion effects mainly relies on the fact that the convolution is applied to the same path over time. As a result, the temporal coherence between consecutive frames to represent the flow motion using this phase-shift method becomes rather obscure for unsteady flow data.</p><p>Another problem is the lack of accurate time stepping in Forssell and Cohen's method. In the algorithm, the time variable in the pathline integration advances only when the particle crosses cell boundaries. This approximation greatly sacrifices the time accuracy because it is the step size in the numeric integration and the physical velocity, instead of the grid geometry, which determine the advancement of time. This assumption poses a major drawback of the algorithm because time accuracy is crucial in analyzing time-dependent flow data.</p><p>Due to the above problems, the effectiveness of Forssell and Cohen's algorithm is greatly limited. In the following section, we propose a new algorithm for visualizing unsteady flow fields. The new algorithm consists of a time-accurate value depositing scheme and a successive feed-forward method. Our algorithm provides a time accurate, highly coherent solution to highlight dynamic global features in unsteady flow fields.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Algorithm</head><p>In this section, we present a new convolution algorithm, UFLIC, for visualizing unsteady flows. First, we present a time-accurate value depositing scheme. Next, we discuss a successive feed-forward method. The combination of these two techniques can provide effective spatial and temporal coherence for tracking dynamic flow features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Time-Accurate Value Depositing</head><p>The convolution method proposed originally by Cabral and Leedom <ref type="bibr" target="#b0">[1]</ref> uses a value gathering scheme. In this algorithm, each pixel in the field travels in both positive and negative streamline directions to gather pixel values and compute the convolution. Stalling and Hege <ref type="bibr" target="#b7">[8]</ref> propose a different approach for speeding up the computation. Rather than gathering, each pixel deposits its value along the streamlines. To compute the convolution, values deposited at each pixel are collected to perform the integration. This method can be referred to as a value depositing scheme. For steady state vector fields, value gathering and value depositing are equivalent. For time-varying vector fields, value gathering and value depositing can produce different results when the convolution of a streamline is extended to the pathline. To illustrate this, again in <ref type="figure" target="#fig_0">Figure 1</ref>, the pathline starting from pixel A to pixel B enables B to receive a contribution from A if the depositing scheme is used. However, when using the gathering scheme, B does not gather A's value because the pathline P2 starting from B at T1 does not pass A. To accurately reflect the physical phenomena in unsteady flow fields, value depositing is superior to value gathering. This is because value depositing by nature corresponds to flow advection. On the other hand, the value gathering scheme, as the one used in Forssell and Cohen's algorithm, possesses several difficulties as we discussed in the previous section.</p><p>We propose a new algorithm to compute the line integral convolution for unsteady flows. In the algorithm, we use a time-accurate value depositing scheme, which incorporates time into the convolution, to simulate the flow advection in unsteady fields. Our deposit scheme works as follows. As in the original LIC algorithm, initially a white noise image is used as the input texture. To "smear" this input texture, each pixel in the field serves as a seed point to advect forwards following the pathline direction. The pathline can be defined as:</p><formula xml:id="formula_0">pt + t = p t + Z t +t t vpt; t dt</formula><p>where pt is the position of the particle at time t, pt + t is the new position after time t, and vpt; t is the velocity of the particle at pt at time t. The Runge-Kutta second or fourth order numeric integration scheme can be used to evaluate the above equation and generate particle traces. At each integration step, the seed point deposits a triplet ;!; at the pixel where the particle is currently located. is the input texture value of the seed pixel, ! is the arc length used to normalize , and is the physical time at the current integration step. Assuming that the seed pixel's value is V , the pathline starts from the seed pixel at physical time T0, the i th integration step size is ti, then at step n, the physical time is:</p><formula xml:id="formula_1">Tn = T0 + i=n X i=1 ti</formula><p>The deposited weight ! is the distance between the particle locations in the current and previous integration steps:</p><formula xml:id="formula_2">!n = kpTn,1pTnk</formula><p>The deposited pixel value is:</p><formula xml:id="formula_3">n = V</formula><p>And the deposited time is:</p><formula xml:id="formula_4">n = Tn</formula><p>For each seed pixel, the distance that its pathline can travel is defined as the convolution length. We determine this convolution length indirectly by specifying a period of physical time as the pathline's life span. This life span is a global property that we use for all the pathlines in the convolution. The advantage of using this global life span to control the convolution length is that the lengths of different pathlines can be automatically scaled to be proportional to the velocity magnitudes, which is a desirable effect as described in <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b1">2]</ref>. It is worth mentioning that in our method, each pixel deposits its value along only the forward pathline direction but not the backward direction. This is because the backward depositing does not correspond to actual physical phenomena in practice (flows do not advect backwards). In addition, the symmetry issue mentioned in <ref type="bibr" target="#b0">[1]</ref> does not appear as a problem in our unsteady flow animations.</p><p>To receive the deposits, each pixel keeps a "bucket" which stores deposits from different seeds at different time. In <ref type="figure" target="#fig_2">Figure 2(a)</ref>, pixels A, B, and C have pathlines stepping through C. As a result, C has a deposit from each source as shown in <ref type="figure" target="#fig_2">Figure 2(b)</ref>.</p><p>To compute the convolution frame at time T, we integrate only the deposits that are made at or before T. These correspond to deposit triplets 0 ; ! 0 ; 0 that have time-stamp 0 smaller than T.</p><p>For each pixel x;y, the convolution result Cx; y can be computed using the formula:</p><formula xml:id="formula_5">Cx; y = X 0 T 0 ! 0 = X 0 T ! 0</formula><p>where triplets 0 ; ! 0 ; 0 were deposited to pixel x;y's bucket,  Once the convolution is completed, the used deposits are discarded from the bucket. In our algorithm, the above convolution process is repeated at each time step. However, values of time-stamps in the deposit triplets, determined by the step sizes of pathline integration, can be real numbers anywhere in the time interval of the simulation's entire course. Therefore, when computing the convolution, we need to integrate any deposit that has a time-stamp between the physical time in the current and the previous step. This explains why the deposits with time-stamp values smaller than the current physical time should be selected.</p><p>Our value depositing scheme provides a time-accurate model simulating the flow advection to create spatial coherence in the output texture. In the next section, we describe the process that successively transports the convolution results over time to maintain the temporal coherence for visualizing unsteady flows.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Successive Feed-Forward</head><p>As mentioned previously, we define a time-dependent method as one that progressively tracks the visualization results over time. In this section, we propose a time-dependent process, called Successive Feed-Forward, which is combined with the value depositing scheme to create temporal coherence. Our algorithm works as follows. Initially, the input to our convolution algorithm is a regular white noise texture. Our value depositing scheme advects and convolves the noise texture to obtain the convolution result at the first time step. For the subsequent convolutions, instead of using the noise texture again, we use the output from the previous convolution as the input texture. This input texture, showing patterns that have been formed by previous steps of the flow field, is then further advected. As a result, the output frames in consecutive time steps are An important issue for the successive feed-forward method that must be addressed stems from the fact that the line integral convolution method in general, or our value depositing scheme in particular, is a process of low-pass filtering. This low-pass filtering can gradually reduce contrasts among flow lines when repeatedly being applied to the input texture over time. This would cause problems if one tries to visualize a long sequence of unsteady flow data. To correct this problem, we apply a high-pass filter (HPF) to the input texture, which is the result from the previous convolution, before it is used by the value depositing scheme at the next step. This highpass filter can enhance the flow lines and maintain the contrast in the input texture so the value depositing scheme can produce images with restored contrast and clearer flow traces. <ref type="figure" target="#fig_3">Figure 3</ref> gives an overview of our entire algorithm.</p><p>The high-pass filter used in our method is a Laplacian operator.</p><p>A two-dimensional Laplacian can be written as a 3 3 mask:</p><formula xml:id="formula_6">1 1 1 1 ,8 1 1 1 1</formula><p>The result computed from the mask does not have exclusively positive value. In order to display the result, a common technique used in digital image processing applications is to subtract the Laplacian results from the original image. The filter mask of overall operations of Laplacian and subtraction can be derived as:</p><formula xml:id="formula_7">HPF= ,1 ,1 ,1 ,1 9 ,1 ,1 ,1 ,1 = 0 0 0 0 1 0 0 0 0 , 1 1 1 1 ,8 1 1 1 1</formula><p>For flow data in three dimensional space, this filter needs to be extended to three dimensions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Results and Discussions</head><p>We have used UFLIC to visualize surface flow data from several CFD simulations. CFD scientists, for the first time, are able to visualize unsteady surface flows using our method. In this section, we show snapshots from animations of the surface flows, which are shown in the accompanying video.</p><p>The first example is a two-dimensional flow simulation with dynamic vortices. There are three vortices in the flow. <ref type="figure">Figure 4</ref> shows a snapshotin a sequence of the surface flow evolving over time. The simulation has two vortices orbiting clockwise around the central vortex, which spirals counterclockwise. These three vortices generate well-defined flow lines. In the video, the spiraling of the vortices is very dramatic. <ref type="figure">Figure 5</ref> shows the same time step as shown in <ref type="figure">Figure 4</ref>, except the flow pattern is now color-mapped by the velocity magnitude. Near the center of each vortex, the velocity is high, as illustrated in the figure. A disadvantage of combining color contours with surface flow patterns is that the color contours tend to appear more visually dominant than the flow patterns, and one needs to pay closer attention to see the surface flow patterns. <ref type="figure">Figure 6</ref> shows a time series of unsteady two-dimensional flow over an oscillating airfoil. The airfoil, which is colored in black, pitches down and then up eleven degrees. Images from left to right show the formation of the primary vortex spiraling clockwise above the airfoil, and a counterclockwise secondary vortex forming behind the trailing edge of the airfoil. As the airfoil pitches up and the secondary vortex gains strength, the primary vortex is separated from the airfoil. <ref type="figure">Figure 7</ref> shows the same time series as in <ref type="figure">Figure 6</ref>, except the flow is now colored by velocity magnitude contours. Again, the color contours seem to dominate more visually. However, the color contours also add additional insight to the physical phenomena of the flow. For example, the velocity was high near the leading edge of the airfoil at first. Then, as the airfoil pitches down first and then up, the velocity decreases along the leading edge and increases near the trailing edge. This gives strength to the secondary vortex near the trailing edge.</p><p>Unsteady surface flows are very useful in detecting flow separations and reattachments. <ref type="figure" target="#fig_4">Figure 8</ref> shows surface flow over a delta wing at 30 degree angle of attack. <ref type="figure" target="#fig_5">Figure 9</ref> is a close-up view of the delta wing. The image reveals the flow separation and reattachment lines along the leading edge of the delta wing. These flow features are even clearer in the video.</p><p>Finally, <ref type="figure" target="#fig_0">Figure 10</ref> shows surface flow over a vertical tail of a twin-tailed F18 fighter aircraft at high-angle-of-attack. The aerodynamic load on the fighter aircraft was simulated. During highangle-of-attack, the flow surrounding the vertical tail of the aircraft becomes highly unsteady, and bursting of vortices near the leading edge of the tail becomes very frequent. The image shows a snapshot of the surface flow that results from the highly unsteady flow.</p><p>Some observations can be made regarding visualizing surface flows using our algorithm. Blurriness may occur in regions where the direction of the flow is changing rapidly. It may also occur at flow separation and reattachment locations. Unlike the surface flow patterns generated from regular LIC, the flow lines generated using our unsteady LIC may have different linewidths. This can be attributed to changes in the velocity magnitude and the flow direction. Regions where the flows are relatively steady or diverging tend to exhibit thicker flow lines. Since the surface flow pattern is displayed using texture mapping, aliasing effects are visible at different viewing resolutions. In our algorithm, we have not applied any anti-aliasing techniques to the result images.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusions and Future Work</head><p>We have presented UFLIC, an Unsteady Flow Line Integral Convolution algorithm, for visualizing vector data in unsteady flow fields. Using the time-accurate value deposit scheme and the successive feed-forward method, our new convolution algorithm can accurately model the flow advection and create highly coherent flow animations. The results from several case studies using our algorithm have shown that the new technique is very effective in capturing dynamic features in unsteady flow fields. Future work includes adapting the acceleration technique proposed in <ref type="bibr" target="#b7">[8]</ref> into our unsteady flow algorithm and applying our method to 3D data sets. In addition, we would like to compare our unsteady LIC method with the Spot Noise technique introduced by van Wijk <ref type="bibr" target="#b8">[9]</ref>. Spot Noise is an effective method for creating flow texture patterns. The final texture image quality is based on the distribution and the shape of spots. Recently, de Leeuw and van Wijk <ref type="bibr" target="#b9">[10]</ref> enhanced the spot noise technique by bending spots based on local stream surfaces. The objective is to produce more accurate flow texture patterns near flow regions with high curvature. To extend the spot noise technique for unsteady flows, there are a few key issues to be resolved. For instance, as spots are advected over time the distribution of the spots can change rapidly. A challenge is to maintain the coherence of the spots over time. Another consideration is that spot bending assumes the flow is steady over the local stream surfaces; however, for unsteady flows this assumption may not be true. We plan to look into these issues. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>1Figure 1 :</head><label>1</label><figDesc>As described in their paper. However, in a strict sense, their convolution follows pathlines of advected particles. Uncorrelated values of A and B input for LIC to enhance the contrasts among regions with different velocity magnitudes.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>and the deposited pixel values 0 are normalized by weights ! 0 .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Time-Accurate Value Deposit Scheme</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 :</head><label>3</label><figDesc>Algorithm Flowchart highly coherent because the flow texture is continuously convolved and advected throughout space and time.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 8 :</head><label>8</label><figDesc>A snapshot of the surface flow on a delta wing at 30 degree angle of attack. The flow is relatively steady along the center of the wing body.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 9 :</head><label>9</label><figDesc>A close-up of the delta wing reveals flow separations and reattachments along the leading edge of the wing.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 10 :</head><label>10</label><figDesc>Surface flow over a vertical tail of a twin-tailed F18 fighter aircraft at high-angle-of-attack. The flow is highly unsteady and vortex bursting is frequent near the leading edge of the tail.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>and Leedom, is a visualization technique that synthesizes textures based on the vec-NASA Ames Research Center, Mail Stop T27A-2, Moffett Field, CA 94035 (hwshen@nas.nasa.gov) y NASA Ames Research Center, Mail Stop T27A-2, Moffett Field, CA 94035 (davidkao@nas.nasa.gov)</figDesc><table /><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>This work was supported in part by NASA contract NAS2-14303. We would like to thank Neal Chaderjian, Ken Gee, Shigeru Obayashi, and Ravi Samtaney for providing their data sets. We also thank Tim Sandstrom, Gail Felchle, Chris Henze, and other members in the Data Analysis Group at NASA Ames Research Center for their helpful comments, suggestions, and technical support.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Imaging vector fields using line integral convolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Cabral</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Leedom</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of SIGGRAPH 93</title>
		<meeting>SIGGRAPH 93</meeting>
		<imprint>
			<publisher>ACM SIGGRAPH</publisher>
			<date type="published" when="1993" />
			<biblScope unit="page" from="263" to="270" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Using line integral convolution for flow visualization: Curvilinear grids, variable-speed animation, and unsteady flows</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">K</forename><surname>Forssell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">D</forename><surname>Cohen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="133" to="141" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Multi-Frequency noise for LIC</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-H</forename><surname>Kiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Banks</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Visualization &apos;96</title>
		<meeting>Visualization &apos;96<address><addrLine>Los Alamitos, CA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society Press</publisher>
			<date type="published" when="1996" />
			<biblScope unit="page" from="121" to="126" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Visualization of time-dependent flow fields</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename><surname>Lane</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Visualization &apos;93</title>
		<meeting>Visualization &apos;93<address><addrLine>Los Alamitos, CA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society Press</publisher>
			<date type="published" when="1993" />
			<biblScope unit="page" from="32" to="38" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Visualizing time-varying phenomena in numerical simulations of unsteady flows</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename><surname>Lane</surname></persName>
		</author>
		<idno>AIAA-96-0048</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 34th Aerospace Science Meeting and Exhibit</title>
		<meeting>34th Aerospace Science Meeting and Exhibit</meeting>
		<imprint>
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Enhanced line integral convolution with flow feature detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Okada</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">L</forename><surname>Kao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IS&amp;T/SPIE Electronic Imaging &apos;97</title>
		<meeting>IS&amp;T/SPIE Electronic Imaging &apos;97</meeting>
		<imprint>
			<date type="published" when="1997" />
			<biblScope unit="page" from="206" to="217" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Visualizing vector fields using line integral convolution and dye advection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H.-W</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">R</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K.-L</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 1996 Symposium on Volume Visualization</title>
		<meeting>1996 Symposium on Volume Visualization<address><addrLine>Los Alamitos, CA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society Press</publisher>
			<date type="published" when="1996" />
			<biblScope unit="page" from="63" to="70" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Fast and resolution independent line integral convolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Stalling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H.-C</forename><surname>Hege</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of SIGGRAPH 95</title>
		<meeting>SIGGRAPH 95</meeting>
		<imprint>
			<publisher>ACM SIGGRAPH</publisher>
			<date type="published" when="1995" />
			<biblScope unit="page" from="249" to="256" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Spot noise: Texture synthesis for data visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">J</forename><surname>Van Wijk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="309" to="318" />
			<date type="published" when="1991" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Enhanced spot noise for vector field visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>De Leeuw</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">J</forename><surname>Van Wijk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Visualization &apos;95</title>
		<meeting>Visualization &apos;95<address><addrLine>Los Alamitos, CA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society Press</publisher>
			<date type="published" when="1995" />
			<biblScope unit="page" from="233" to="239" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
