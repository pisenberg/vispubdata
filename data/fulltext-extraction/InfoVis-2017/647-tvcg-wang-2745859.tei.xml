<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/pisenberg/grobid/grobid-0.6.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">EdWordle: Consistency-preserving Word Cloud Editing</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunhai</forename><surname>Wang</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaowei</forename><surname>Chu</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Bao</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lifeng</forename><surname>Zhu</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oliver</forename><surname>Deussen</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Baoquan</forename><surname>Chen</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Sedlmair</surname></persName>
						</author>
						<title level="a" type="main">EdWordle: Consistency-preserving Word Cloud Editing</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="DOI">10.1109/TVCG.2017.2745859</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2021-02-19T19:17+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Wordle</term>
					<term>consistency</term>
					<term>text visualization</term>
				</keywords>
			</textClass>
			<abstract>
				<p>Fig. 1. Result of a case study with a professional writer who sought to visualize a BBC news feed: the left image shows the input Wordle layout; the right image shows the layout that was created using EdWordle. The writer ordered related words into semantically meaningful groups, one group per story. Each group was organized spatially together and color-coded, creating a layout that the user referred to as a &quot;storytelling cloud&quot;.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Wordle <ref type="bibr" target="#b16">[17]</ref> is a popular visualization tool that converts a piece of text into a word cloud, in which each word is sized according to its number of occurrences. Despite several concerns that have been raised by the visualization community <ref type="bibr" target="#b0">[1]</ref>, Wordle has gained great popularity and has been adopted by many non-expert users since its introduction in 2008. One of the major reasons for this success is the aesthetic and participatory output that Wordle creates. In other words, Wordle is mainly used as an authoring tool to produce visually pleasing word clouds, which can be customized for appearance and shared with others. It is very rarely used as a data analysis tool with the need of accurately representing the underlying data <ref type="bibr" target="#b36">[37]</ref>.</p><p>To fine-tune the output so that it meets their aesthetic goals, users often wish to further manipulate Wordles by adding, deleting, or modifying words <ref type="bibr" target="#b16">[17]</ref>. The original method, however, only allows users to change the attributes of the whole word cloud. To fill this gap, Koh et al. <ref type="bibr" target="#b25">[26]</ref> introduced ManiWordle, a technique that enables users to directly manipulate individual words with different operations such as selection, movement or rotation. Jo et al. <ref type="bibr" target="#b23">[24]</ref> extended this work by developing WordlePlus for pen-and touch-enabled tablets. This version of the method provides full control over a wordle that includes resizing, adding, and deleting elements.</p><p>The manipulation of size, orientation, or position of words inevitably involves a re-organization of the whole layout. For example, when a user deletes a word, there will be empty space that needs to be filled. If a word is moved to a new position, others need to be moved away. Current state-of-the-art re-organization strategies <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b25">26]</ref> relocate words that no longer fit anymore by simply moving them to empty spaces. While this approach warrants a compact overall layout, it also results in substantial global reordering with words being moved to completely different positions. This approach hence contradicts the idea of consistency, a core principle in many design-related areas <ref type="bibr" target="#b32">[33]</ref>. A proper, consistency-preserving editing approach will be even more important in semantically-ordered word clouds <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b40">41]</ref>. Here, the neighborhood of words is meaningful, so that words like "BBC" and "News", or "presidential" and "candidate" appear spatially close together, as shown in <ref type="figure">Figure 1</ref>. In such a case, inconsistent and unpredictable layout changes during editing would likely result in poor user experience.</p><p>To fill this gap, we designed EdWordle, a context-aware interaction technique that seeks to preserve the local and global order of words in a word cloud. Our technique is based on the coherent combination of two components: a customized rigid body dynamics simulation and a neighborhood-aware re-layout algorithm. Similar to morphable word clouds <ref type="bibr" target="#b7">[8]</ref>, each word is viewed as a rigid body with a mass and the dynamics simulation arranges words by applying forces. Representing each body solely as a box might be too loose for producing compact word clouds. Hence, we use a two-level box representation for each word, where each letter is viewed as an individual box and the common part of all letters as the other box. Based on this representation, we construct two kinds of forces: neighboring forces between words pull them to stay as close as possible, and a central force pulls each word towards the center of the word cloud. Such a dynamic system is able to generate compact and non-overlapping word clouds, but it cannot guarantee that all empty spaces will be filled, especially at the boundary. To alleviate this problem, we additionally propose a neighborhoodaware local Wordle algorithm, which moves words that are far from the center to fill nearby empty spaces.</p><p>Although EdWordle's primary function is to edit word clouds, the method can also be used to improve any existing word cloud. Thus, we compare it to state-of-the-art word cloud creation algorithms <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b40">41]</ref> by taking their outputs as our inputs and then investigating how much our approach improves these layouts under experimental settings as proposed by <ref type="bibr">Barth et al. [4]</ref>. A quantitative analysis shows that our approach is i) consistently better in preserving word neighborhoods, ii) successfully avoids global changes to the layout, and iii) has similar or even better results in avoiding empty spaces. In addition, we compare EdWordle to ManiWordle to investigate its usability for Wordle editing by conducting a laboratory study. The results show that people were not only faster and more accurate with EdWordle, but also felt they achieved better results. Finally, we invited some designers and writers to investigate the value of EdWordle as an authoring tool. The results demonstrate the advantages of our approach over Wordle and ManiWordle in creating storytelling visualizations, for example laying out headlines in a semantically meaningful way as shown in <ref type="figure">Figure 1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK</head><p>We review previous work related to word cloud visualization and work related to authoring tools for visual representations more generally.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Word Cloud Visualization</head><p>A word cloud, also known as a tag cloud, is a visual representation of text data that has been used on the web since 1997 <ref type="bibr" target="#b35">[36]</ref>. A word cloud encodes the frequency of words of a given text into font size and color <ref type="bibr" target="#b30">[31]</ref>, and spatially arranges the words on the canvas. Over the years, a number of different spatial arrangements have been proposed. Standard word cloud visualizations use a rectangular line-by-line layout, where the words may be sorted alphabetically or by their importance. To produce more compact and aesthetic visualizations, a large family of alternative layout methods have been proposed <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b36">37]</ref>. Among them, the most well-known algorithm is Wordle <ref type="bibr" target="#b36">[37]</ref>, which is the focus of the present study. Wordle uses a greedy approach to produce compact layouts, where words are placed in different orientations, not just in a single direction. To improve the orthogonal ordering of Wordle, Strobelt et al. <ref type="bibr" target="#b34">[35]</ref> suggest to combine scan-line based techniques <ref type="bibr" target="#b28">[29]</ref> with the greedy layout strategy of Wordle. To enable the user to easily create visually appealing word clouds, Tagxedo <ref type="bibr" target="#b27">[28]</ref> and WordArt <ref type="bibr" target="#b39">[40]</ref> both allow the user to put word clouds into specific shapes. However, such improvements still do not capture the relationship between words, let alone the temporal coherence of time-varying text data. Therefore, a variety of semantic and temporal word cloud generation methods and editing tools have been proposed in recent years.</p><p>Semantic Word Clouds While Wordle and its variants produce aesthetic visualizations, their layout algorithms do not incorporate the neighborhood relationships between words and thus they do not place semantically related words close to each other. This was mentioned by Hearst <ref type="bibr" target="#b21">[22]</ref> as one of the critical limitations of traditional word cloud visualizations. To overcome this limitation, Wu et al. <ref type="bibr" target="#b40">[41]</ref> proposed an approach that places similar words close to each other. To do so, they first compute a distance matrix between words and then use multidimensional scaling to place words onto a 2D canvas, while removing blank spaces through a carving scheme. Paulovich et al. <ref type="bibr" target="#b29">[30]</ref> extended this idea to document collections by using multidimensional projec-tion techniques to compute neighborhood relationship and arrange the words accordingly.</p><p>For pre-specified neighborhood relationships, Barth et al. <ref type="bibr" target="#b2">[3]</ref> show that creating a semantic word cloud that strictly respects the relationship between words is a NP-hard problem. They consequently present approximation algorithms and conduct a comparison <ref type="bibr" target="#b3">[4]</ref> between Wordle and the carving method <ref type="bibr" target="#b40">[41]</ref>. Their findings show that semantic word clouds were not as compact as Wordle. Recently, Buchin et al. <ref type="bibr" target="#b5">[6]</ref> pushed this line further, proposing geo word clouds that respect not only the neighborhood relationships but also the relative (geo-spatial) position associated with each word. All these algorithms, however, do not allow the user to re-position words, which means that semantics cannot be adjusted once the layout is generated. Our neighborhoodpreserving editing approach is specifically important for semantic word clouds, and plays a crucial role for keeping the neighborhood between words. Globally re-positing words upon edits, as pursued by current state-of-the-art editing approaches (see below), would naturally interfere with the goal of keeping a semantic order. With our approach users are able to order words in a way that even tells a story within the word cloud, a feature that has not yet been possible.</p><p>Temporal Word Clouds Given a time-varying set of words, temporal word clouds attempt to visualize temporal trends while preserving temporal coherence. Collins et al. <ref type="bibr" target="#b9">[10]</ref> introduce Parallel TagClouds that combine parallel coordinates and traditional word clouds, where the words of each document are distributed along each coordinate axis. Lee et al. <ref type="bibr" target="#b26">[27]</ref> present Sparkclouds that visualize trends between multiple word clouds by integrating sparklines into a word cloud. Both methods perform well in the visualization of trends, with Sparkclouds being the better one in terms of scalability. Cui et al. <ref type="bibr" target="#b10">[11]</ref> combine a trend chart and multiple word clouds together to illustrate temporal changes of the underlying data. By combining multidimensional scaling and force-directed layout, this method can create semantic and stable word clouds over time. Recently, Chi et al. <ref type="bibr" target="#b7">[8]</ref> propose morphable word clouds where a sequence of spatial shapes is specified as a boundary for a set of time-varying word clouds. By using rigid body dynamics, they arrange words within the given shape sequence so that temporal changes are encoded by both the shapes and the content of the word clouds. In this paper, we also use rigid body dynamics to rearrange words after editing. Representing each word as a rigid body, however, might result in large empty spaces between words. To address this issue, we propose a two-level rigid body representation for each word and combine rigid body dynamics with a local version of the Wordle placement algorithm.</p><p>Word Cloud Editing Almost none of the existing word cloud visualizations allows users to edit typographical properties of individual words. While this might be plausible for pure data analysis settings, Viegas et al. found that Wordles are mainly used as an authoring tool for participatory visualizations <ref type="bibr" target="#b36">[37]</ref>. In this scenario, users often want to manually customize and edit the visual output. To address this need, Koh et al. proposed Maniwordle <ref type="bibr" target="#b25">[26]</ref>, which allows the user to move, rotate and remove a word with a mouse. Wordleplus <ref type="bibr" target="#b23">[24]</ref> by Jo et al., extended Maniwordle to multi-touch settings and enriched it with natural interactions. Since user interaction might result in empty space between words, ManiWordle re-runs the Wordle layout algorithm for the un-edited words and Wordleplus repeatedly uses the words at the boundary of Wordle to fill empty space within the cloud. Both approaches result in global and unpredictable layout changes, as can be seen in <ref type="figure" target="#fig_6">Figure 7</ref> on page 6. Our approach, EdWordle, overcomes these limitations by striving to preserve a consistent neighbor-relationship before and after editing. It can also be used for other applications such as semantic word cloud generation and temporal cloud generation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Visualization Construction and Authoring Tools</head><p>For the last few decades, there has been considerable effort to create easy-to-use visualization construction tools. Grammel et al. <ref type="bibr" target="#b20">[21]</ref> provide a survey of various types of such visualization construction tools. Among them, visual builders provide large flexibility by allowing the user to move and resize visual elements in order to create custom visu- alizations. Two typical examples are Dust &amp; Magnet <ref type="bibr" target="#b33">[34]</ref> and flexible linked axes <ref type="bibr" target="#b8">[9]</ref>. EdWordle also belongs to this type of interfaces that allows the user to freely control elements.</p><p>Today, designers can create visualizations with a large variety of tools <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b37">38]</ref>, and further edit visualization with drawing tools like Adobe Illustrator, if needed. Very recently, Bigelow et al. <ref type="bibr" target="#b4">[5]</ref> pointed out that current tools leave a gap between producing and later editing of visualizations, which can considerably hinder designers in their creative process. Towards bridging this gap, they proposed a model which allows for a much easier iteration between visualization creation and editing. Along similar lines, Fulda et al. <ref type="bibr" target="#b18">[19]</ref> proposed an authoring tool that allows designers and journalists to create and edit timeline visualizations for temporal story telling. Our work was inspired by this recent trend towards authoring tools in visualization, and eases the transition from an automatically generated word cloud to a manually adapted visual output. <ref type="figure" target="#fig_0">Figure 2</ref> illustrates the overall approach behind EdWordle. The process starts by simply loading some text that can be copied and pasted into the tool. Alternatively, we also can start from an existing word cloud as input. For illustrative purposes we assume the case that an initial word cloud has already been created, as illustrated in <ref type="figure" target="#fig_0">Figure 2</ref>(a). After the wordle is loaded, we first apply a customized rigid body dynamics approach, which helps us to make the layout more compact while preserving the neighborhood relationships. This process results in a compact representation of the input.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">EDWORDLE</head><p>The user can then freely edit the cloud until the desired result is obtained. In our example, the user would like to move the word "dedicate" closer to the word "nation". For each interaction, EdWordle's main goal is to allow for predictable changes, as well as to produce a compact and aesthetic result after each editing step. More specifically, we seek to preserve neighborhoods of words to allow for consistency when changing the layout (instead of words that might jump around unpredictably). To do so, after each step the rigid body dynamics step is automatically invoked again <ref type="figure" target="#fig_0">(Figure 2</ref>(b)-(c)). At any time, the result can be further improved by performing a Re-Wordle, a local Wordle layout process, in which empty spaces at the boundary are filled by nearby words. All steps are based on our two-level box representation for the words, which allows us to create compact representations without words squeezing in between characters of other larger words.</p><p>Using this approach, EdWordle gives the user full creative control including the ability to drag, rotate, add, delete, or resize a word or multiple words at the same time. Moreover, it allows previewing of the intermediate outcome actions by continuously updating the layout while words are moved around by the user <ref type="bibr" target="#b32">[33]</ref>. In the following, we describe each of the core components of EdWordle in more detail. We first briefly introduce the general rigid body dynamics, then explain our two-level box representation, as well as our customized external forces approach ( <ref type="figure" target="#fig_0">Fig. 2(a)</ref>-(c)), and finally explain the local Wordle layout algorithm that we designed ( <ref type="figure" target="#fig_0">Fig. 2(d)</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Rigid Body Dynamics Based Layout</head><p>By representing each word as a rigid object, rigid body dynamics allow us to avoid word overlapping by enforcing non-penetration constraints.</p><p>We provide a brief review of rigid body dynamics, for more details please refer to Witkin <ref type="bibr" target="#b38">[39]</ref>. Rigid body dynamics systems deal with the motion of bodies that are subject to external forces. Rigid bodies cannot penetrate each other, so their motion is simulated using two major components: unconstrained and constrained dynamics. The former updates position and velocity in response to (outer) forces, while the latter detects collisions between bodies and creates corresponding responses, please refer to Appendix A for unconstrained rigid body dynamics. In general, however, the state of a rigid body is described by the vector Y(t) = (x(t), R(t), P(t), L(t)), which includes its position x, orientation R, linear momentum P and angular momentum L.</p><p>A constraint is a restriction to the position or motion of a rigid body <ref type="bibr" target="#b15">[16]</ref>. To satisfy a non-penetration constraint for instance, an appropriate collision detection and response between the rigid bodies is required. By representing each body as a convex hull with corresponding bounding box hierarchy, collisions can be detected by any efficient algorithm, such as the separating axis method <ref type="bibr" target="#b14">[15]</ref>. After a collision is detected, the non-penetration constraint is enforced by impulse-based dynamics, which solve the imposed constraints using linear equations <ref type="bibr" target="#b6">[7]</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.1">Adaptive Two-level Word Representation</head><p>Previous approaches <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b40">41]</ref> typically represent words with a single bounding box, which is simple but results in non-compact layouts (see <ref type="figure" target="#fig_1">Figure 3</ref>(a)). An alternative way is to represent each word as a combination of multiple letter-level bounding boxes, which allows compact layouts to be generated but might result in word overlaps. <ref type="figure" target="#fig_1">Figure 3</ref>(b) illustrates this issue: the collision response from the letter 'i' and 'o' of the word "dedicate" cancel out each other so that "dedicate" and "nation" are getting stuck due to their letter-level boxes. Since the collision detection is done for all boxes attached to the body, the letter-level box representation also incurs a substantial computational overhead.</p><p>Thus, we propose to combine the two representations in an adaptive way. Directly using the bounding box of the entire word will make the letter-level boxes useless. As a consequence, we compute the bounding box of the common part of all letters to form our word-level box, shown as a red dashed box in <ref type="figure" target="#fig_1">Figure 3</ref>(c). The width of our word-level box is the width of the bounding box of the whole word and the height is the minimal height of all letters. To reduce the computational cost, we use this two-level box representation only for words whose relative sizes compared to the largest word are larger than a fixed threshold. In this way we do not introduce large empty spaces between words, since gaps between letters in small words are typically too small for placing other words. In our experiments, the threshold was set to 0.5. This means all words with at minimum half the font size of the largest word will be subject to our two-level box representation. For all other words we use normal word-level boxes. Our collision detection is based on this two-level box representation. In this study we primarily work on compact wordle layouts, but users are allowed to offset the proposed two-level bounding box for creating more whitespace if they want to make words more outstanding.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.2">Customized External Forces</head><p>To produce a compact layout while preserving the neighborhood, we apply two external forces to the objects: neighboring forces and central forces. While the former pushes neighboring words close to each other, the latter drags all words to the canvas center. For computing neighboring forces, we first determine the neighborhood relation among the words in the given word cloud and then apply the external forces accordingly to move them (see <ref type="figure" target="#fig_2">Figure 4</ref>(a)). If two words collide, they will bounce off each other, see <ref type="figure" target="#fig_2">Figure 4</ref>(b). Note that forces are enforced to the center of the mass of each rigid body represented by our adaptive two-level boxes.</p><p>Neighborhood Search: The body center of each word is connected to the centers of all other words. If the line segment connecting two words does not intersect a third word, these two words are considered to be neighbors. As shown in <ref type="figure" target="#fig_2">Figure 4</ref>(a), the word with the red border is thus not taken as a neighbor of the selected word.</p><p>Neighboring Forces: Suppose the selected word has n f neighbor words, then the exerted neighboring force is:</p><formula xml:id="formula_0">F neigh i = n f ∑ j=1 m i × m j /r 2 i, j<label>(1)</label></formula><p>where r i, j is the Euclidean distance between the body centers of the selected word i and the n neighbor words j. The mass m is a given weighting factor for each word. Since this force is inverse proportional to the distance (we divide by r 2 i, j ), it will pull neighboring words more closely together. <ref type="figure" target="#fig_4">Figure 5</ref>(a,b) shows an example where the neighboring force pulls "struggled" and "testing" as well as "resolve" and "liberty" together after deleting the word "conceived".</p><p>Central Forces: Since the magnitude of neighboring forces decreases with their distance, neighboring words with large distances cannot be pulled together. This could result in considerable gaps. For example, there is a large gap between the words "struggled" and "score" in <ref type="figure" target="#fig_4">Figure 5</ref>(b). To address this issue, we introduce a central attraction source. That is, we place a virtual body with a large mass M at the center of the canvas to attract all words toward it using the following formula:</p><formula xml:id="formula_1">F cent i = m i × M × r 2 i,c (2)</formula><p>where M is a unit mass, and r i,c the distance between word i and the canvas center. Central forces are proportional to the distance between the words and the virtual object in the center (we multiply by r 2 i,c ). Thus, they will especially attract those words that are farthest from the center. <ref type="figure" target="#fig_4">Figure 5</ref>(c) shows an example where the central force pulls the words "resolve" and "fought" more closely to the center.</p><p>Joining the Forces We now can simply join the forces by computing a weighted sum for each word body i, at each iteration step t:</p><formula xml:id="formula_2">F i (t) = F neigh i (t) + αF cent i (t)<label>(3)</label></formula><p>where α is the weight. Large central forces might destroy the neighborhood relationship, for example, during movement from <ref type="figure" target="#fig_4">Figure 5</ref>(a) to (c), the neighboring words "vain" and "resolve" are not neighbors anymore. We heuristically found α = 0.1 to be a good compromise between the forces.</p><p>Damping Strategy: Directly applying this force F i to the words will, however, cause the system to halt in a non-equilibrium state since (i) the forces move words so that collisions occur and (ii) the collision forces pull them back into the opposite direction. This results in an unstable, oscillating system. The words would jitter and shake around at each iteration step. To address this issue, we apply an attenuation function g(t) to the force. In combination with the the force F i for each word body, we receive the following final equation at each iteration t:</p><formula xml:id="formula_3">F damp i (t) = F i (t) × g(t)<label>(4)</label></formula><p>Since neighboring forces become much larger when words are close and the system is getting compact, the attenuation function should become smaller as the number of iteration increases. Thus, we set g(t) = β /(t + 1) with β an attenuation constant.</p><p>Nonetheless, only applying an attenuation function to the forces is not enough to avoid jittering. Words keep moving as long as their velocity is not zero. Thus, we also decay the velocity with a damping coefficient λ : v i (t) = v i (t) × λ , where we set λ to 0.8. This damping strategy reduces the movement of the rigid bodies until they reach their resting positions.</p><p>Driven by these two strategies, any change to the position of a word has an effect on the forces being exerted on it. Such effect in turn changes the moving velocity of the word and subsequently its updated position, leading to an iteratively updating framework. Since different words have different velocities, we specify a maximum number of iterations to stop the simulation. In our experiment, we found that 80 iterations are enough for achieving convergence for all of our word clouds, where the running time is typically around 0.6s with our not yet optimized implementation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 1 Local Wordle Layout</head><p>1: identify the boundary word list 2: for each word w in the sorted boundary word list do pick the position that best preserves the neighborhood 6: end for</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Local Wordle Layout</head><p>When the rigid body simulation stops, most word body motions are blocked by neighboring words so that words are packed compactly. Since the spatial distribution according to the neighbourhood relation might not be uniform, the arrangement of words might be biased towards some direction, which results in gaps among the words in the obtained layout. As shown in <ref type="figure" target="#fig_0">Figure 2(c)</ref>, such gaps often appear at the boundary of a cloud. To fill them, we propose to re-arrange the related words using the original Wordle layout algorithm. However, this layout algorithm will, according to its greedy strategy, potentially destroy the neighborhood relationship among words. This would produce inconsistencies with the rigid body system. In other words, the re-layout has to take the neighborhood relationship into account. Thus, we propose a local version of the Wordle layout algorithm as outlined in Algorithm 1. It has two key components: i) identification of boundary words; and ii) searching a new position. Note that this algorithm might destroy the original neighborhood relation a little to improve the compactness and thus we leave it as an option for the user.</p><p>Identification of boundary words (line 1). We compute the width and height of an axis-aligned bounding box b of the current word cloud and then construct a circle centered at the center of the layout and with a radius β * min(width b , height b ). All words that lie outside of this circle need to be re-placed, indicated as red boxes in <ref type="figure" target="#fig_5">Figure 6</ref>(a). After identifying such words, we sort them in terms of their font sizes.</p><p>Picking the best position (line 3-5). Before searching for a new position using the spiral scheme of Worlde (cf. <ref type="bibr" target="#b16">[17]</ref>), we define its initial position as the midpoint of the line segment that connects the mass centers of the current word and the center of the entire word cloud. Then we find k candidate positions along the spiral and select the one that preserves the largest number of neighborhood relations on its new position. If more than one position preserves the same number of neighborhoods, we pick the one that is found first, because it is closer to the word cloud center. <ref type="figure" target="#fig_5">Figure 6(b)</ref> illustrates the procedure for the orange box highlighted in <ref type="figure" target="#fig_5">Figure 6(a)</ref>.</p><p>In our experiment, β and k are set to 0.8 and 20, which works well for most of our data. In this way, our local Wordle layout algorithm not only fills gaps but also preserves the original neighboring relationship as much as possible. <ref type="figure" target="#fig_0">Figures 2(c,d)</ref> show a comparison of the word clouds without and with adaptation by the local Wordle layout.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Interactions</head><p>The above approach allows us to provide a set of new or refined types of interactions that enables users to create visually pleasing word clouds:</p><p>Neighborhood-preserving editing. After importing a word cloud, Ed-Wordle allows the user to move, rotate, resize, add and delete words while preserving the neighborhood relationship. Although ManiWordle <ref type="bibr" target="#b25">[26]</ref> and WordlePlus <ref type="bibr" target="#b23">[24]</ref> both also support most of these operations, neither of them respects the original neighborhood relationships of words. <ref type="figure" target="#fig_6">Figure 7</ref> compares the re-layouted results generated by Mani-Wordle and EdWordle after moving and rotating the word "dedicate". In ManiWordle (b), this editing step evokes global repositioning of the words marked in orange, and results in a non-compact layout. Our approach overcomes these limitations, retaining the word neighborhoods and compactness of the layout.</p><p>Note that resizing words does interfere with the validity of word clouds, but only if used as a pure data/text analysis tool. As ManiWordle <ref type="bibr" target="#b25">[26]</ref> and WordlePlus <ref type="bibr" target="#b23">[24]</ref> , we take Wordle more as a communication and artistic tool, where users start with an initial layout and then want to adjust it to their needs. In this case, a precise representation of word counts through word size is not of primary concern, and users even request the ability to resize words as shown in the FAQ and discussion forums of Wordle <ref type="bibr" target="#b16">[17]</ref>.</p><p>Multi-word editing. To simultaneously manipulate multiple words, EdWordle allows the user to select multiple words by pressing the Ctrl button or with the help of rectangle selection. Once multiple words are selected, the user can move, rotate, delete, re-color, re-font and re-wordle them. With traditional editing approaches, such multi-word interactions would be impracticable as manipulations would result in substantial global changes and would introduce large gaps between words.</p><p>Re-Wordle. As mentioned in Section 3.2, our local Wordle layout algorithm can re-arrange the words so that gaps at the borders can be closed. We refer to this operation as Re-Wordle. While the standard Re-Wordle process has the default parameters (β and k), we also allow the user to play around with the parameters, or only use it on specific subsets of words. To select specific words, EdWordle allows the user to interactively adjust the circle center, circle radius and de-select some boundary words if they want to keep their positions.</p><p>Other interactions. To make EdWordle a full and usable creative editing environment, we also provide other common interactions, such as undo, redo, save and load, or edit data. We furthermore provide an additional multi-touch version of EdWordle, allowing users to select, drag, rotate, and resize words with multi-touch interactions similar to WordlePlus <ref type="bibr" target="#b23">[24]</ref>. Such an approach is interesting specifically for collaborative Wordle creation where concurrent interaction of multiple users is now possible because the user does not get interrupted by words jumping around from another user editing the word cloud simultaneously.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Implementation and Tool</head><p>EdWordle is written in JavaScript and runs in the web-based environment, which is is available as an online tool 1 . The Hammer.js library (http://hammerjs.github.io/) is used for touch interaction. The accompanying video shows examples of the above described interactions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">EVALUATION</head><p>We evaluate our approach in three different ways. First, we illustrate how EdWordle allows us to refine and improve existing word clouds. Second, we present a small-scale quantitative lab study with 16 participants. And third, we discuss the results of a qualitative case study with 10 designers and writers. The purpose of these studies is to compare our approach to current state-of-the-art approaches for generating and  editing word clouds. Further details on experimental designs and results can be found in the supplemental materials.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Quantitative Comparison</head><p>In this section, we validate that EdWordle can improve the quality of existing word clouds by enhancing their compactness, while preserving most of the neighborhood relations. To do so, we use Barth et al.'s semantic word clouds layout <ref type="bibr" target="#b3">[4]</ref> as input for Edwordle for further processing. The resulting layouts produced by Edwordle are expected to be more compact, while at the same time we expect them to largely retain word neighborhoods. Such a quality refinement is specifically interesting for semantic word clouds, because under this condition the semantic neighborhood of words does not get destroyed by the quality optimization process. We illustrate the quality improvement by comparing the initial layout with the processed layout. For most word clouds with 50 words, the improvement procedure can be done in less than 0.5s.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.1">Study Design</head><p>Metrics. According to <ref type="bibr">Barth et al. [4]</ref>, there are six common metrics for evaluating word cloud layouts: realized adjacencies, distortion, compactness, uniform area utilization, aspect ratio, and running time. Here, we focus on the realized adjacencies, and compactness, which are especially relevant for our goals. The metric of realized adjacencies is defined as the sum of edge weights of all pairs of boxes that share a common boundary. This metric mainly reflects how well the semantic relatedness between pairs of words is "realized" in the word cloud layout. Compactness indicates how much area is used to render the actual words in relation to the entire area the cloud covers, that is, used area/all area. Compactness therefore indicates how efficiently the drawing area is used. To define all area, we simply use the bounding box of the whole word cloud, while we set the used area as the sum of bounding box areas for all words.</p><p>Existing Algorithms. We use two different word cloud layout algo-rithms: Star Forest, and Cycle Cover, which have been found to outperform the other methods in realized adjacencies, and are competitive with respect to the other metrics <ref type="bibr" target="#b3">[4]</ref>.</p><p>Data. We use two datasets taken from Brath et al. <ref type="bibr" target="#b3">[4]</ref>. For each algorithm, we tested both datasets.</p><p>1. WIKI, consisting of 112 plain-text articles from the English Wikipedia, each has 200 distinct words or more; and 2. PAPERS, consisting of 56 scientific papers from two experimental algorithms conferences (SEA and ALENEX, 2011-2012). <ref type="figure" target="#fig_7">Fig. 8</ref> shows the results of our experiments. <ref type="figure" target="#fig_7">Fig. 8(a)</ref> demonstrates that the neighborhood relations in all word clouds created by EdWordle are well-preserved. The metrics of realized adjacencies for the output layouts created by EdWordle (dotted lines) are almost equal to the input lines by the original layouts (continuous lines). Only for the PAPERS, Cycle Cover case, we see that the EdWordle output is slightly worse than the original input. The loss, however, is very minor, and we deem it acceptable. <ref type="figure" target="#fig_7">Fig. 8(b)</ref> shows the results for compactness. After applying EdWordle to the initial layout, the compactness of these word clouds improved substantially. This suggests that EdWordle indeed is able to further improve given semantic word clouds, by making them more compact while at the same time preserving their word neighborhoods. <ref type="figure" target="#fig_7">Fig. 8(c)</ref> illustrates this effect with an example.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.2">Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Lab study</head><p>In this study, our goal was to evaluate how well different editing approaches perform in tasks related to keeping word neighborhoods. For instance, a user might like to move a word next to another word or to create a semantic layout where the position of words is meaningful [3,4,30,41]. He might even like to create a storytelling cloud, which shows complete headlines as a sequence of words inside the cloud.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1">Experimental factors</head><p>We had two experimental factors (independent variables): editing approach and tasks.</p><p>Editing tools. We compare our EdWordle approach with ManiWordle, the current state-of-the-art approach for editing Wordles. To ensure a fair comparison, we only test the basic functionality of both approaches, that is, moving and rotating objects. For EdWordle, we initially considered three variants to be tested: (1) without preview, (2) with preview, and (3) a version that "pushes" words away. We thought that a version with preview will be easier to use as it allows users to see how the overall-layout will change, even though necessarily adds response time to the system. The variant without preview is fast but not as user-friendly since users cannot foresee the impact of their actions. The third version was inspired by how moving physical objects would push away other objects while moving, such as stones that lie on a table. To determine which of the three versions to use in our study, we first conducted a pilot study with 6 participants. We found that users consistently preferred version (2) with preview, deeming the slight increase of response time as acceptable. We also considered including WordlePlus into the study, but refrained from it as WordlePlus uses very similar basic functions as implemented in ManiWordle.</p><p>Tasks. We carefully explored different test tasks and evaluated them based on how they can be measured, and how realistic they are. This process led us to the following two tasks for our study:</p><p>Task 1-Pairwise placement: This task is meant to test simple and common pairwise interactions of word placements. It encompasses three subtasks: put word x on top of word y; put x on left of y; put x on top of y and rotate them to a certain angle. For different users, x and y were randomly sampled. We visually illustrated the task in an abstract spatial way as shown in <ref type="figure" target="#fig_8">Fig. 9(a)</ref>. Our goal with this approach was to allow participants to easily infer spatial target positions, while keeping it abstract enough to avoid a focus on superficial details.</p><p>Task 2-Semantic misplacement: The second task relates to the ability to form groups of related words, for instance, as common in Semantic Wordles <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b40">41]</ref>. Instead of testing the entire ordering process, we opted for simply correcting four randomly sampled misplaced words into their correct groupings, as shown in <ref type="figure" target="#fig_8">Fig. 9(b)</ref>. We also opted to let users group words by color, instead of the actual semantic meaning of words. On the one hand, color can be perceived much quicker than semantic meaning, which avoids potential learning effects between the two conditions. On the other hand, semantic interpretation would leave too much room for subjective interpretation, making it hard to measure. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2">Hypotheses</head><p>Based on EdWordle's ability to preserve local and global neighborhoods, we had the following hypotheses before conducting the study:</p><p>• H1: For both tasks, users will be more efficient with EdWordle than with ManiWordle. • H2: For Task 1 (pairwise placement), EdWordle will result in more accurate results, that is, with fewer errors. • H3: The layouts created with EdWordle will be more compact.</p><p>• H4: Subjective ratings will be slightly better for EdWordle than for ManiWordle, as ManiWordle can lead to unpredictable word changes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.3">Experiment Design</head><p>We used a within-subjects design: each participant conducted both tasks with both editing tools (independent variables). The following dependent variables were tested:</p><p>• Efficiency: We used three efficiency measures: the time (seconds) a user takes to perform a task, the number of clicks needed, and the distance of the mouse movement. • Accuracy: We counted the number of misplacements in each resulting Wordle layout, that is, words that were not correctly placed according to the subtask/task description. • Compactness: As in the experiment above, we also computed the compactness c of the resulting layouts by c = used area/all area, using the bounding box approach to specify all area. Since we do not have word box information of ManiWordle, we counted the number of pixels with non-background color to define used area. • Subjective ratings: We used the ManiWordle questionnaire <ref type="bibr" target="#b25">[26]</ref> to gather subjective ratings of users on six questions, ranging from strong disagreement to strong agreement (7-point Likert scale). We attempted to avoid biasing effects by the interviewer in our study.</p><p>Data. We used two different datasets in our study:</p><p>• D1: the paper "Participatory Visualization with Wordle" by Viegas et al. <ref type="bibr" target="#b36">[37]</ref> • D2: the Wikipedia entry about the famous South Korean skater Yu-Na Kim. To limit the complexity of the study design, D1 was used only in task 1, and D2 in task 2.</p><p>Participants. We recruited 16 participants (8 male, 8 female), most of whom are Computer Science students from the local university. The age ranged from 20 to 29 years (median age 22). All participants reported normal or corrected-to-normal vision, and had no color vision deficiencies. None of them had prior experience with word cloud generating tools.</p><p>Procedure. We defined the following procedure for the study:</p><p>1. introduction video, familiarization with both tools (2 min. each), and explanation of tasks by the interviewer; 2. Task 1, with both editing tools; 3. Task 2, with both editing tools; and 4. questionnaire and short interview. The orders within (2)-(4) were counterbalanced to avoid systematic bias through potential learning effects. During (4), the participants were allowed to play around with the respective editing tools again, and were shown the wordles they created with this tool before. The study was run on a quad-core PC with a 23" LCD widescreen, using a mouse as input and a 1920 × 1080 px display as output. The system was equipped with a AMD FirePro W2100 GPU with 2048 MB of memory.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.4">Results</head><p>We followed recent recommendations of statistical analysis practices and used an estimation-based approach with effect sizes and confidence intervals <ref type="bibr" target="#b1">[2]</ref>. This approach overcomes several biases and limitations of classical null hypothesis testing with p-values (NHST) <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b13">14]</ref>. Cumming and Finch offer guidance on how to interpret statistical tests using confidence intervals (CI) <ref type="bibr" target="#b12">[13]</ref>. Specifically, if there is no overlap between CI error bars we can assume a statically significant result with a p-level of p ≈ .01 (if the bars touch each other) or smaller (if there is a gap between them) <ref type="bibr" target="#b12">[13]</ref>.</p><p>The results of our quantitative measures are summarized in <ref type="figure" target="#fig_9">Figure 10</ref>. For time, clicks, and distance, lower values are better. For compactness, higher values are better. The results are consistent with the trends we initially predicted with our hypotheses. All three efficiency measures, (a) time, (b) clicks, and (c) distance show a clear and strong effect of EdWordle being more efficient than ManiWordle.</p><p>In terms of accuracy, we counted the errors that were made under each condition. For Task 1, an error is defined as an incorrect neighborhood between an indicated pair of words (e.g., because a word had jumped unpredictably around). For ManiWordle we counted 10 errors The results of the compactness scores, which we computed for each resulting word cloud layout, are shown in <ref type="figure" target="#fig_9">Figure 10(d)</ref>. For Task 1, EdWordle is only slightly better than ManiWordle. For Task 2, the effect is much more pronounced and EdWordle created more compact results. When inspecting the resulting clouds of the participants, we noticed some EdWordle layouts in which words would purposely "stick out" from the bulk of other words, such as the word "culture" in <ref type="figure" target="#fig_8">Fig. 9(a)</ref>. While this behavior is not negative per se, the bounding box-based compactness measure is very sensitive to it and explains the small effect on compactness values of EdWordle in Task 1. As a more sensitive alternative, Barth et al. <ref type="bibr" target="#b3">[4]</ref> proposed basing the compactness measure on the convex hull of a word cloud. This hull-based approach would indeed avoid this issue, but was impractical in our case because we only have images available for ManiWordle layouts, and not the word-box information.</p><p>Finally, we looked at the subjective ratings of the ManiWordle questionnaire. The results are shown in <ref type="table" target="#tab_1">Table 1</ref>, and they indicate that EdWordle was consistently better rated than ManiWordle by our participants. In particular, questions related to usability (Q2 &amp; Q3) and to the generated results (Q6) show clear evidence that EdWordle subjectively outperformed ManiWordle. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Case Studies with Designers</head><p>In our last evaluation we wanted to determine the value of EdWordle in a more qualitative way. We thus conducted a set of case studies with designers and writers, two of our primary target audiences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.1">Study Design</head><p>Overall, we invited 10 participants to our study. All participants worked in some sort of creative profession, such as graphic design or journalism, and had different interests, such as international political affairs or technology. We asked them to use EdWordle to create a layout according to their own taste, desire, and needs. To do that, they were allowed to pick an article of their choice. The only prerequisite was that they had to be familiar with the selected article, in order to resemble a data presentation rather than a data exploration scenario. In contrast to the quantitative lab study, we offered the participants the full spectrum of EdWordle's functionality. The design process of each participant was closely observed and recorded. After each session, we collected their results and comments on EdWordle, as well as information about their background. Overall, every case study took 1-2 hours.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.2">Results</head><p>We were happy to observe that all 10 participants engaged in a very creative design process, and came up with interesting and inspiring layouts. <ref type="figure">Fig. 11</ref> as well as <ref type="figure">Fig. 1</ref> show 6 of the resulting Wordle layouts. All of the created word clouds involved some sort of semantic layout, which is inherently fostered by our approach as it allows designers to manly organize words according to their semantics. <ref type="figure">Fig. 1</ref> shows an example done by a writer who is strongly interested in international affairs. Her EdWordle is based on a news feed from BBC, which included different threads of daily news. Deciding to reveal these different threads in her layout, she ordered the words that belong to a specific story spatially together, and also color-coded them with the same colors. With this layout it becomes very clear that the article is made up of five news pieces: (1) America supporting the Israeli-Palestinian solution; (2) President Trump's administration did fine-tune and publish the travel ban; (3) Marine Le Pen, a presidential candidate in France, was under investigation; (4) 70 people were killed in Pakistan because of a suicide attack, and (5) 50 people in Baghdad died of a car bomb by the IS. <ref type="figure">Fig. 11(a)</ref> shows the result of another participant with a background in journalism, who sought to visualize an article about "deleting some of your apps will make you happier". As the article was heavily referring to iPhones and Apple's App Store, the journalist decided to design the overall shape of the Wordle as an Apple logo. While creating such a shape-oriented Wordle would also have been possible with previous approaches <ref type="bibr" target="#b7">[8]</ref>, the user went beyond that in that he carefully designed the leaf of the apple as a catchy headline "delete and you will thank me later". There are also other semantic groups in the layout, such as "2 million apps", and the two numbers that refer to a central message in the article: deleting "54%" of the apps freed up "24%" of the disk space. <ref type="figure">Fig. 11</ref>(b)-(e) show the results of another four case studies. We see that the designers of these layouts also engaged in producing creative and semantically-inspired layouts, often with some sort of "story" behind it. Participants (b)-(d) made strong usage of different orientations, and sought to order words into meaningful groups. In (b), for instance, the participant visualized a speech of Obama by semantically ordering its four parts into separate corners, while having recurring themes in the center. Result (e) was the closest to a classical Wordle layout, with the difference that the participant sough to put the central message into the center: "All men are created equal". More details about the case studies, as well as the other studies can be found in the supplemental materials.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">CONCLUSIONS AND FUTURE WORK</head><p>In this work, we presented EdWordle, a novel approach for editing word clouds. EdWordle's main benefit is that it allows a neighborhoodpreserving editing process, which keeps words at predictable and close locations during and after the editing process. In a set of quantitive experiments with and without users, we found that this approach outperformed other state-of-the-art editing approaches. In our qualitative case study with 10 designers and writers, we furthermore found that, with its neighborhood-preserving character, EdWordle fosters new ways of creating and editing Wordles. Designers and writers would, for instance, automatically engage in creating some sort of semantically meaningful Wordles, which represented some aspects of the underlying stories, or simply storytelling clouds. This finding is in line with the increasing amount of recent research on semantic word clouds. So far, however, it has been very hard to edit such clouds without destroying their semantic layout. EdWordle fills this gap. We also believe that our neighborhood-preserving approach opens various doors for new forms of interactions. For instance, we experimented with pushing bars that allow users to interactively customize desired shapes by pushing the entire layout around. <ref type="figure" target="#fig_0">Figure 12</ref> as well as the video illustrate this idea. We believe that there are many other ideas that could be realized based on our consistency-preserving approach. Extending the pushing bar metaphor to multi-touch, one could, for instance, think about a solution that allows users to literally "shape" a word cloud with the hands. Another idea is to allow the user to draw a lasso or a shape, and pull at the ends of this "rope" to "tighten" the word cloud -an idea that is similar to shape word clouds <ref type="bibr" target="#b27">[28,</ref><ref type="bibr" target="#b39">40]</ref>. Or one could simply combine their shape constraints <ref type="bibr" target="#b7">[8]</ref> with our approach of neighborhood-preserving editing. Such an approach would even better support editable shape Wordles as the one described in our "apple" case study ( <ref type="figure">Fig. 11(a)</ref>).</p><p>A more general avenue for future work is to develop more sophisticated authoring tools for the generation of storytelling word clouds. Eight of our 10 designers/writers mentioned that they would have liked creative support through a more direct link to the underlying text. Our system still requires a considerable amount of user interaction to generate the final storytelling clouds as shown in <ref type="figure">Fig. 1</ref>. In the future, we thus plan to combine our consistency-preserving editing approach with advanced text analysis algorithms <ref type="bibr" target="#b17">[18]</ref> to inform better initial layouts so that user interaction can be further reduced. Furthermore, our system is designed to preserve local word neighborhoods while reducing whitespace. The resulting word clouds might be too compact in some cases so that some distinct words might be hard to identify (e.g., when all words are horizontally aligned). For a word cloud consisting of multiple topics, separating topics by whitespace might also make storytelling clouds more understandable. It would be interesting to learn more about how compactness and whitespace affect the usability and readability of word clouds. These ideas indicate the potential of more sophisticated authoring tools that connect word cloud generation, editing, and text analysis tools.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 2 .</head><label>2</label><figDesc>Overview of our method: (a) given a Wordle, (b) we use our customized rigid body dynamics to move words close to each other; (c) if a word is moved, the forces update the words accordingly; (d) empty spaces are removed by using a local version of the Wordle algorithm.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 3 .</head><label>3</label><figDesc>Comparison of three different body representations for a word with collision responses shown by black arrows (upper row) and resulting layouts (lower row). (a) the word-level box representation introduces large empty spaces between words; (b) the letter-level boxes result in a compact layout but introduces overlapping words; (c) The two-level box representation combines the advantages of the representations in (a,b).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 4 .</head><label>4</label><figDesc>Illustration of our rigid body dynamics: (a) Neighboring forces (black solid lines) and central forces (black dashed lines) act on the central box (neighbours are shown with blue outline); (b) Motion before and after collision between two words.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 5 .</head><label>5</label><figDesc>The resulting word clouds after (a) deleting the word "conceived" in the input word cloud. (b) The results generated by applying the neighboring forces; (c) central forces in combination with neighboring forces, and (d) central forces with a weight α = 0.1.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 6 .</head><label>6</label><figDesc>Illustration of the local Wordle layout method, the point shown with the cross is the center of the entire word cloud. (a) The words outside of the circle are taken as boundary words and are shown with red borders; (b) k candidates (shown as triangles) are found for the word highlighted in orange, where the green circle indicates the starting position and the yellow triangle is the position finally selected.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 7 .</head><label>7</label><figDesc>Comparison between Maniwordle<ref type="bibr" target="#b25">[26]</ref> and our method for movement and rotation. (a) Input word cloud where the word "dedicate" is moved down and rotated about a small angle; (b,c) Results generated by Maniwordle and our method, respectively.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 8 .</head><label>8</label><figDesc>(a) Realized adjacencies for various word clouds; higher is better. The dashed and continuous lines match up well, indicating that EdWordle is able to preserve neighborhoods well. (b) Mean and standard deviation of compactness for various word clouds; higher is better. EdWordle (dotted) produces substantially more compact results. (c) An example for refining a semantic word cloud (top) with EdWordle (bottom).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 9 .</head><label>9</label><figDesc>(a) Example picture for Task 1. (b) Example picture for Task 2.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig. 10 .</head><label>10</label><figDesc>Mean values and errors as 95% CIs of (a) time, (b) clicks, (c) distance, and (d) compactness. For (a)-(c), lower values are better; for (d) higher values are better across all users, for EdWordle only 2. Screenshots of all errors are shown in the supplemental material. For Task 2, there were no errors under either condition. We expected this result, as Task 2 is based on pre-attentive color sorting that allows users to easily spot and correct for errors.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Fig. 11 .Fig. 12 .</head><label>1112</label><figDesc>Results of our case studies, visualizing (a) an article about how much time apps eat up, (b) a speech by Obama, (c) a transcript of an interview on a psychological topic, (d) an article about solar eclipse, and (e) a speech by Martin Luther King. Pushing bars can push words into specific directions. Once some words collide with the pushing bar, they will be moved along the pushing direction: (a) cloud before moving pushing bar; (b) intermediate result; (c) after using the pushing bar from two sides to customize the word cloud shape.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>• Y. Wang, B. Chen, X. Chu, and C. Bao are with Shandong University. Email: {wang.yh, baoquan}@sdu.edu.cn, {cuxiaoxie, baochen95 }@gmail.com. • L. Zhu is with Southeast University. E-mail: lfzhulf@gmail.com. • O. Deussen is with Konstanz University and VCC SIAT, China. E-mail: oliver.deussen@uni-konstanz.de. • M. Sedlmair is with University of Vienna, Austria. E-mail: michael.sedlmair@univie.ac.at. • Y. Wang and X. Chu are joint first authors.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 .</head><label>1</label><figDesc>Subjective Responses to Six Questions(Average Ratings)</figDesc><table><row><cell>Questions</cell><cell>ManiWordle</cell><cell>EdWordle</cell></row><row><cell>Q1: It was easy to learn this visualization.</cell><cell>6</cell><cell>6.41</cell></row><row><cell>Q2: It was easy to use this visualization.</cell><cell>4.94</cell><cell>6.18</cell></row><row><cell>Q3: I liked to use this visualization.</cell><cell>4.56</cell><cell>6.09</cell></row><row><cell>Q4: It was fun to use this visualization.</cell><cell>5.12</cell><cell>5.74</cell></row><row><cell>Q5: I felt creative while using this visualization.</cell><cell>5.12</cell><cell>5.53</cell></row><row><cell>Q6: Overall, I am satisfied with the result layout.</cell><cell>4.69</cell><cell>6.08</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">http://www.edwordle.net/</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS</head><p>The authors would like to thank Haifeng Zhang for making the evaluation. This work is supported by the grants of NSFC </p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>APPENDIX A: UNCONSTRAINT DYNAMICS</head><p>Given the center of mass x(t) as the origin of the body space and its orientation represented by rotation matrix R(t) in world space at a time t, a position r b in body space can be mapped to a position r(t) in world space by:</p><p>To describe how position and orientation change over time, we define a linear velocity υ(t) and an angular velocity ω(t). The quantity</p><p>gives the velocity of translation, while ω(t) specifies the rotation speed and the axis about which the body is rotating. By using the relationṘ(t) = ω(t) × R(t), the velocity of the body at the position</p><p>When external forces act on the body with the mass m, the position and velocity of the body will be changed. Suppose, an external force F(t) is given, then the torque τ(t) acting on the body is:</p><p>where τ(t) depends on the location r(t) of the body relative to its center of mass x(t).</p><p>Since momentums are conserved in nature, it is recommend to describe the state of a moving body with a linear momentum P(t) and an angular momentum L(t). They are computed from the linear and angular velocity, respectively:</p><p>where I(t) is an inertia tensor describing how the mass in a body is distributed relative to the center of mass. The change in linear momentum can be described aṡ</p><p>where the acceleration is α = F(t)/m. By analogy, the derivative of the angular momentum is formulated asL(t) = τ(t).</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">The biasing effect of word length in font size encodings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Alexander</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-C</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Shimabukuro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Franconeri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Collins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gleicher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Poster Compendium of the IEEE Conference on Information Visualization</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Publication manual of the American psychological association</title>
		<imprint>
			<date type="published" when="2010" />
			<publisher>American Psychological Association Washington</publisher>
		</imprint>
	</monogr>
	<note>6th edition</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Semantic word cloud representations: Hardness and approximation algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Barth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">I</forename><surname>Fabrikant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">G</forename><surname>Kobourov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lubiw</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Nöllenburg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Okamoto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Pupyrev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Squarcella</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Ueckerdt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Wolff</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-642-54423-145</idno>
	</analytic>
	<monogr>
		<title level="m">Latin American Symposium on Theoretical Informatics</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="514" to="525" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Experimental comparison of semantic word clouds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Barth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">G</forename><surname>Kobourov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Pupyrev</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-319-07959-221</idno>
	</analytic>
	<monogr>
		<title level="m">International Symposium on Experimental Algorithms</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="247" to="258" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Iterating between tools to create and edit visualizations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bigelow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Drucker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Fisher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Meyer</surname></persName>
		</author>
		<idno type="DOI">10.1109/TVCG.2016.2598609</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Vis. &amp; Comp. Graphics</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="481" to="490" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Geo word clouds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Buchin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Creemers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lazzarotto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Speckmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wulms</surname></persName>
		</author>
		<idno type="DOI">10.1109/PACIFICVIS.2016.7465262</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Pacific Visualization Symposium</title>
		<meeting>the IEEE Pacific Visualization Symposium</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="144" to="151" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Iterative dynamics with temporal coherence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Catto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Game Developer Conference</title>
		<meeting>Game Developer Conference</meeting>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Morphable word clouds for time-varying text data visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-T</forename><surname>Chi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S.-S</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S.-Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-H</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T.-Y.</forename><surname>Lee</surname></persName>
		</author>
		<idno type="DOI">10.1109/TVCG.2015.2440241</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Vis. &amp; Comp. Graphics</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="1415" to="1426" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Flexible linked axes for multivariate data visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">H</forename><surname>Claessen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">J</forename><surname>Van Wijk</surname></persName>
		</author>
		<idno type="DOI">10.1109/TVCG.2011.201</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Vis. &amp; Comp. Graphics</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2310" to="2316" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Parallel tag clouds to explore and analyze faceted text corpora</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Collins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">B</forename><surname>Viegas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Wattenberg</surname></persName>
		</author>
		<idno>doi: 10. 1109/VAST.2009.5333443</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Symposium on Visual Analytics Science and Technology</title>
		<meeting>the IEEE Symposium on Visual Analytics Science and Technology</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="91" to="98" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Context preserving dynamic word cloud visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">X</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Qu</surname></persName>
		</author>
		<idno type="DOI">10.1109/PACIFICVIS.2010.5429600</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Pacific Visualization Symposium</title>
		<meeting>the IEEE Pacific Visualization Symposium</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="121" to="128" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Understanding the new statistics: Effect sizes, confidence intervals, and meta-analysis. Routledge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Cumming</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Inference by eye: confidence intervals and how to read pictures of data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Cumming</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Finch</surname></persName>
		</author>
		<idno type="DOI">10.1111/j.1467-9639.2007.00267.x</idno>
	</analytic>
	<monogr>
		<title level="j">American Psychologist</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">170</biblScope>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Fair statistical communication in hci</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dragicevic</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-319-26633-613</idno>
	</analytic>
	<monogr>
		<title level="m">Modern Statistical Methods for HCI</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="291" to="330" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Real-time collision detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Ericson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004" />
			<publisher>CRC Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Rigid body dynamics algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Featherstone</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Wordle-beautiful word clouds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Feinberg</surname></persName>
		</author>
		<ptr target="http://www.wordle.net/" />
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">The text mining handbook: advanced approaches in analyzing unstructured data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Feldman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sanger</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
			<publisher>Cambridge university press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Timelinecurator: Interactive authoring of visual timelines from unstructured text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Fulda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Brehmer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Munzner</surname></persName>
		</author>
		<idno type="DOI">10.1109/TVCG.2015.2467531</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Vis. &amp; Comp. Graphics</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="300" to="309" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Visualising a text with a tree cloud</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Gambette</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Véronis</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-642-10745-061</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Federation of Classification Societies Conference</title>
		<meeting>the International Federation of Classification Societies Conference</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="561" to="569" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">A survey of visualization construction user interfaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Grammel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Bennett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Tory</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-A</forename><surname>Storey</surname></persName>
		</author>
		<idno type="DOI">10.2312/PE.EuroVisShort.EuroVisShort2013.019-023</idno>
	</analytic>
	<monogr>
		<title level="m">EuroVis-Short Papers</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="19" to="23" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">What&apos;s up with tag clouds? Visual Business Intelligence Newsletter</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Hearst</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Constructing visual representations: Investigating the use of tangible tokens</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Huron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Jansen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Carpendale</surname></persName>
		</author>
		<idno type="DOI">10.1109/TVCG.2014.2346292</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Vis. &amp; Comp. Graphics</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2102" to="2111" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Wordleplus: Expanding wordle&apos;s use through natural interaction and animation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Jo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Seo</surname></persName>
		</author>
		<idno type="DOI">10.1109/MCG.2015.113</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer Graphics and Applications</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="20" to="28" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Tag-cloud drawing: Algorithms for cloud visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Kaser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lemire</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Workshop onTagging and Metadata for Social Information Organization</title>
		<meeting>the Workshop onTagging and Metadata for Social Information Organization</meeting>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Maniwordle: Providing flexible control over wordle</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Koh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Seo</surname></persName>
		</author>
		<idno type="DOI">10.1109/TVCG.2010.175</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Vis. &amp; Comp. Graphics</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1190" to="1197" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Sparkclouds: Visualizing trends in tag clouds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">H</forename><surname>Riche</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">K</forename><surname>Karlson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Carpendale</surname></persName>
		</author>
		<idno type="DOI">10.1109/TVCG.2010.194</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Vis. &amp; Comp. Graphics</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1182" to="1189" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Leung</surname></persName>
		</author>
		<ptr target="http://www.tagxedo.com/.lastvisited06/2017" />
		<title level="m">Tagxedo website</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Layout adjustment and the mental map</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Misue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Eades</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Sugiyama</surname></persName>
		</author>
		<idno type="DOI">10.1006/jvlc.1995.1010</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of Visual Languages &amp; Computing</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="183" to="210" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Semantic wordification of document collections</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">V</forename><surname>Paulovich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Toledo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">P</forename><surname>Telles</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Minghim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">G</forename><surname>Nonato</surname></persName>
		</author>
		<idno type="DOI">10.1111/j.1467-8659.2012.03107.x</idno>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics Forum</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">3pt3</biblScope>
			<biblScope unit="page" from="1145" to="1153" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Getting our head in the clouds: toward evaluation studies of tagclouds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">W</forename><surname>Rivadeneira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">M</forename><surname>Gruen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Muller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">R</forename><surname>Millen</surname></persName>
		</author>
		<idno type="DOI">10.1145/1240624.1240775</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the SIGCHI conference on Human Factors in Computing Systems</title>
		<meeting>the SIGCHI conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="995" to="998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">On the beauty and usability of tag clouds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Seifert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Kump</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Kienreich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Granitzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Granitzer</surname></persName>
		</author>
		<idno type="DOI">10.1109/IV.2008.89</idno>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Conf. on Information Visualisation</title>
		<meeting>Int. Conf. on Information Visualisation</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="17" to="25" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Designing the user interface: strategies for effective human-computer interaction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Shneiderman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010" />
			<publisher>Pearson Education India</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Dust &amp; magnet: multivariate information visualization using a magnet metaphor</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">Soo</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Melton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Stasko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Jacko</surname></persName>
		</author>
		<idno type="DOI">10.1057/palgrave.ivs.9500099</idno>
	</analytic>
	<monogr>
		<title level="j">Information Visualization</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="239" to="256" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Rolled-out wordles: A heuristic method for overlap removal of 2d data representatives</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Strobelt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Spicker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Stoffel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Keim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Deussen</surname></persName>
		</author>
		<idno type="DOI">10.1111/j.1467-8659.2012.03106.x</idno>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics Forum</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="1135" to="1144" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Timelines tag clouds and the case for vernacular visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">B</forename><surname>Viégas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Wattenberg</surname></persName>
		</author>
		<idno>doi: 10.1145/ 1374489.1374501</idno>
	</analytic>
	<monogr>
		<title level="j">Interactions</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="49" to="52" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Participatory visualization with wordle</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">B</forename><surname>Viegas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Wattenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Feinberg</surname></persName>
		</author>
		<idno>doi: 10. 1109/TVCG.2009.171</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Vis. &amp; Comp. Graphics</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">6</biblScope>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">An exploratory study of data sketching for visual representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Walny</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Huron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Carpendale</surname></persName>
		</author>
		<idno type="DOI">10.1111/cgf.12635</idno>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics Forum</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="231" to="240" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Physically based modeling: principles and practice constrained dynamics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Witkin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics</title>
		<imprint>
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Wordart</surname></persName>
		</author>
		<ptr target="http://www.wordart.com/.lastvisited06/2017" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Semantic-preserving word clouds by seam carving</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Provan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K.-L</forename><surname>Ma</surname></persName>
		</author>
		<idno type="DOI">10.1111/j.1467-8659.2011.01923.x</idno>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics Forum</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="741" to="750" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
