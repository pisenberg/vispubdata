<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/pisenberg/grobid/grobid-0.6.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Taking Word Clouds Apart: An Empirical Investigation of the Design Space for Keyword Summaries</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cristian</forename><surname>Felix</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><roleName>Member, IEEE</roleName><forename type="first">Steven</forename><surname>Franconeri</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><roleName>Member, IEEE</roleName><forename type="first">Enrico</forename><surname>Bertini</surname></persName>
						</author>
						<title level="a" type="main">Taking Word Clouds Apart: An Empirical Investigation of the Design Space for Keyword Summaries</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="DOI">10.1109/TVCG.2017.2746018</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2021-02-19T19:17+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Word Clouds</term>
					<term>Tag Clouds</term>
					<term>Text Visualization</term>
					<term>Keyword Summaries</term>
				</keywords>
			</textClass>
			<abstract>
				<p>In this paper we present a set of four user studies aimed at exploring the visual design space of what we call keyword summaries: lists of words with associated quantitative values used to help people derive an intuition of what information a given document collection (or part of it) may contain. We seek to systematically study how different visual representations may affect people&apos;s performance in extracting information out of keyword summaries. To this purpose, we first create a design space of possible visual representations and compare the possible solutions in this design space through a variety of representative tasks and performance metrics. Other researchers have, in the past, studied some aspects of effectiveness with word clouds, however, the existing literature is somewhat scattered and do not seem to address the problem in a sufficiently systematic and holistic manner. The results of our studies showed a strong dependency on the tasks users are performing. In this paper we present details of our methodology, the results, as well as, guidelines on how to design effective keyword summaries based in our discoveries.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>In this paper we present a set of four user studies aimed at exploring the visual design space of what we call keyword summaries: lists of words with associated quantitative values used to help people derive an intuition of what information a given document collection (or part of it) may contain.</p><p>Such summaries are often generated through a set of natural language processing steps aimed at extracting the most relevant words and are very often represented as word clouds, that is, collections of words organized in space-optimized compact layouts in which font size encodes the frequency (or other relevance) value.</p><p>In this work, we seek to systematically study how different visual representations may affect people's performance in extracting information out of keyword summaries. To this purpose, we first create a design space of possible visual representations and then compare the possible solutions in this design space through a variety of representative tasks and performance metrics.</p><p>Even though word clouds are often used more as an emotional experience than an analytical tool <ref type="bibr" target="#b26">[26]</ref>, our focus in studying keyword summaries is on their use in exploratory data analysis, that is, when visual representations of a set of keywords and their frequency (or other value) is used to help an analyst generate questions, hypotheses and insights on the underlying data set.</p><p>This set of studies is motivated by our recent work on developing applications to analyze large sets of opinion data collected as sets of comments <ref type="bibr" target="#b8">[9]</ref>. In this context, users generate keyword summaries of comments retrieved using a specific query and use the summary to get a sense of people's opinions. For instance, in summarizing reviews of restaurants that receive negative (1 star) reviews, one can identify trends and major issues that consumers mention in their reviews.</p><p>Similar problems are faced by a multitude of communicators, data analysts and developers when deciding what is the most appropriate form to utilize when visualizing sets of keywords that summarize a given set of documents (e.g., in social media, humanities, journalism, marketing).</p><p>• Cristian <ref type="bibr">Felix</ref>  This study is also motivated by the indiscriminate use of word clouds as the default solution to visualize keyword summaries. On the one hand, word clouds are extremely popular and do not seem to have generated major concerns in their users. On the other hand, several researchers and practitioners have voiced their dissatisfaction with them due to numerous shortcomings they seem to have <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b20">21]</ref>, namely: (1) the lack of natural reading order in how words are laid out;</p><p>(2) the use of font size to communicate quantitative information, which is believed to be sub-optimal compared to other visual channels; and (3) the variation in word size due to word length rather than value.</p><p>Other researchers have in the past studied some aspects of effectiveness with word clouds. As we will describe in the next section, however, the existing literature is somewhat scattered and does not seem to address the problem in a sufficiently systematic and holistic manner. More specifically, the existing works, while useful, seem to focus on particular solutions or situations with a limited effort to place them in a framework of possible design choices.</p><p>In this work, we propose to study the visual design space of keywords summaries more systematically. More precisely, our systematic approach derives from two factors. First, we define a design space based on spatial layout and value encoding, two key visual parameters linked to performance, and include all meaningful combinations in the study. Second, we study these combinations across a set of representative tasks aimed at spanning a wide spectrum of task granularity: low-level tasks, to address low-level perceptual issues, and high-level tasks, to deal with tasks in which cognition plays a more prominent role.</p><p>To the best of our knowledge this approach is novel and will be a significant contribution to both theory and practice. We conjecture that organizing the work around a well-defined design space of possible solutions and a variety of tasks can not only lead to useful practical and theoretical insights, but also help researchers with a foundation to use for future studies in this area.</p><p>In the following section we describe existing studies and place them in a descriptive framework. Such framework is going to help us understand how the existing studies relate to one to another and where major gaps exist in the literature. We then move on to describing our study rationale, which includes the design space we devised for keyword summaries and the tasks we included in our studies. In Section 4 we describe the four studies in detail, providing details on their design, execution and results. Finally, in Section 6 we discuss the implications of the studies and in Section 7 we describe potential future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">BACKGROUND AND RELATED RESEARCH</head><p>In this section we provide background information about how word clouds are used, visualization techniques employed and empirical re-search performed to better understand how humans extract information out of them.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Word Clouds Origin and Use</head><p>At least two names have been commonly used to denote a collection of words that depict the content of a collection, tag clouds and word clouds. Historically, the term tag cloud derives from how blogs and web sites have used lists of textual tags with associated frequencies to provide a visual index to their content. The term word clouds, on the other hand, seems to originate from the idea of generating a document summary by extracting its most frequent words. The two terms however have been used interchangeably over the years referring to different goals, data extraction methods and different ways to depict information visually. In this study we will only use the term word clouds, referring to all possible uses found in the literature, and we will focus on their use as a method to automatically extract and visualize keywords from a document collection with the purpose of summarizing its content.</p><p>In this context, a word cloud visualization method receives as an input a list of words, each with an associated frequency value, and creates a visual depiction of this information. Several visual representations have been devised for word clouds throughout the years. By far the most common representation used is the one in which words are positioned in an unordered layout, to optimize the use of space, and frequency values are mapped to font size. Several variants however exist.</p><p>One common variant is to assign different colors to the words to create more aesthetically pleasing clouds or to encode an additional data attribute. Another very popular variant is Wordle, a word cloud in which words can be positioned horizontally or vertically (or even other orientations) and smaller keywords can also be nested inside the empty spaces of large letters in order to maximize space usage. This kind of representation has been used with the intent to maximize aesthetic impact and social interactions <ref type="bibr" target="#b13">[14]</ref>.</p><p>Sometimes, word clouds are also organized in more structured layouts. For instance the words can be organized row-wise or column-wise to increase their legibility and ease their scanning. Word cloud variants have also been devised to convey additional information available in the data. As an example, parallel tag clouds uses parallel lists of words connected by lines to allow comparison between subsets of documents (e.g., how they change over time) <ref type="bibr" target="#b6">[7]</ref>. SparkClouds adds small line charts below each word to convey information on how the relevance of each word changes over time <ref type="bibr" target="#b16">[17]</ref>. BirdVis uses geo-located word clouds to summarize comments generated by groups of bird watchers positioned in different geographical locations <ref type="bibr" target="#b9">[10]</ref>. The keyphrases method proposed by Chuang et al., extends the techniques to n-grams to show more of the context of each word <ref type="bibr" target="#b3">[4]</ref>. Semantic-Preserving Word Clouds position the words so that semantically related words are positioned together <ref type="bibr" target="#b27">[27]</ref>. And Phrase Nets organizes the extracted words in a network in which words are connected by user-defined relationships <ref type="bibr" target="#b24">[24]</ref>.</p><p>In this paper, we focus on the case in which the information to be conveyed consists of a list of words with an associated numerical value.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Summary of Empirical Research</head><p>In preparation for this research we performed a literature review and found a total of 8 research papers reporting on studies aimed at studying word clouds empirically.</p><p>Rivadeneira et al. <ref type="bibr" target="#b19">[20]</ref> produced one of the first works evaluating tag clouds. In their work they propose a set of 4 groups of tasks that can be used for evaluation: search, browsing, impression formation (gist) and matching. Search consists of finding a specific term or concept in the set of words displayed in the cloud. Browsing consists of inspecting the clouds to see if any term catches the user's interest. Impression formation (gist) consists of extracting the overall set of topics or concepts present in the cloud (as opposed to single terms). Matching consist of specifying which, among a list of predefined topics, is most related to the cloud presented to the participant.</p><p>In this study, using words extracted from psychology datasets and news reports, they conducted two experiments. In the first one, they used classic word clouds, with an unordered layout and font size encoding frequency, and asked the participants to report which words they could recall after a 20 seconds exposure. The results showed that participants recalled the words with larger font size (value) more often.</p><p>In the second experiment, they compared four different word cloud designs in which one was a simple list of terms and the rest used font size to encode frequency and the following positioning strategies: row layout ordered by frequency, row layout ordered alphabetically, spatial/unordered. The main tasks tested were impression formation (gist) and matching. For the gist task, the participants saw a word cloud for 30 seconds and were then asked to specify concepts/topics they contained. For the matching task, the participants had to match the word cloud's content to a set of predefined target concepts. The list design was found to be the most effective for the gist task and an effect of font size was found in the matching task, that is, the participants performed better when the target was presented with larger fonts.</p><p>Alexander &amp; Gleicher [2] also studied the gist task in a recent new study. The study is based on topics generated from an automated topic extraction procedure (LDA) applied to news articles. It asked the participants to provide a topic name for the word cloud and to identify words not present in the word cloud as belonging or not to the topic expressed by the cloud. The study compared two main designs: spatial/unordered word clouds with font size encoding frequency and simple lists sorted in descending order of frequency and all fonts set to the same size. The results showed no effect of visual design on the results.</p><p>Halvey &amp; Keane <ref type="bibr" target="#b11">[12]</ref> asked people to find a country name in a list of countries using 3 different layouts, vertical list, horizontal list and tag cloud, each presented in two versions, ordered alphabetically and random. The results showed that ordering and font size play a major role in the search task, with alphabetical order outperforming unordered designs and words with a bigger font being easier to detect.</p><p>Lohmann et al. <ref type="bibr" target="#b17">[18]</ref> asked participants to perform three type of tasks: find a tag by name, find tag by size and find tags belonging to a topic. They compared 4 different designs, sequential (row-wise), circular (with words organized in concentric circles and most important words in the center) and clustered (with semantically close words placed close together) using font size to encode frequency, and a sequential version without font encoding. The results showed that: alphabetically ordered tag clouds do not show frequency visually, perform better for word search tasks; the circular layout ordered by frequency performs better for the value search tasks; and thematically clustered layouts performed better for the search by topic task.</p><p>Schrammel et al <ref type="bibr" target="#b22">[22]</ref> conducted a study to investigate the effects of different ordering of words, all using a row-wise sequential layout strategy and frequency mapped to font size. For all experiments they used a set of tags extracted from Flickr and 4 ordering strategy: alphabetic, random, folksonomy-based, and linguistic-based. In the folksonomybased solution, words were placed according to their relatedness computed using Flickr's related tags feature. In the linguistic-based solution, words were placed according to their semantic relatedness computed using WordNet.</p><p>In the first experiment researchers asked participants to find a specific tag on the tag cloud and found that the alphabetic ordering was faster, followed by the folksonomy-based ordering. In the second experiment, participants were asked to find to find a tag belonging to an assigned topic and found no effect of ordering or font size. In the third experiment, they asked the participants to scan a tag cloud for 30 seconds and report on which keywords they could recall. The results showed an effect of font size, that is, words with bigger fonts were more likely to be recalled, and no effect of ordering.</p><p>Word clouds have also been tested using an eye-tracking methodology, mostly confirming the results reported in previous experiments. Lohmann et al. <ref type="bibr" target="#b17">[18]</ref> confirmed the stronger eye fixation on the top-left quadrant of the cloud but also that eye fixation areas are affected by the layout used. Schrammel et al. <ref type="bibr" target="#b20">[21]</ref> confirmed that people mostly scan rather than read the words one by one jumping from one location of the visual space to another. They also confirmed that bigger fonts take most of the user's attention and that the top-left quadrant is the one that receives most attention.</p><p>Another interesting study is the one performed by Bateman et al. <ref type="bibr" target="#b2">[3]</ref> in which they tested 8 different font features (size, weight, color, intensity, number of pixels, tag width, number of characters, tag area) to verify which one is more appropriate to represent importance. The study showed that font size, font weight, color hue and intensity are the best features for this purpose.</p><p>Focusing on font characteristics, the work of Alexander et al. <ref type="bibr" target="#b0">[1]</ref> also provides interesting insights. In their work, they study whether word length affects magnitude perception. The results showed that there is a very small effect and that it can only be noticed when the difference in size between the words is of one single pixel.</p><p>Finally, the work of Hoeber et al. <ref type="bibr" target="#b15">[16]</ref> is the only one we found in which the frequency value is encoded with an additional mark (a horizontal bar) rather than font size. They presented a search interface in which the results are summarized as a keyword summary in which frequency is presented as a horizontal bar chart. In the study participants were asked to search for documents related to a topic (e.g., "new hydroelectric projects") and rate the quality of the result with and without the help of the summary. The study however also showed that bar charts ordered by frequency demanded less time for the user to make decisions and it was also ranked as the favorite.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.1">Main Findings</head><p>Reviewing the works presented above we can summarize some of the main findings that recur across multiple studies. Regarding position of words, using simple ordered lists, helps people find words more quickly than using solutions where the keywords are arranged randomly and unordered, and it also shows good performance for "gisting" tasks. Ordering keyword summaries lexicographically improves search by word tasks, since the user can go straight to the region where the target word is located. Ordering by value also improves performance on task based on value as the user can quickly read the top words. People scan keyword summaries, starting from top-left and going to bottom-right, this has an effect on how quickly people find target words, with words on the bottom-right corner taking longer to be found.</p><p>Visual encoding has an effect on drawing the attention of the user. Font size has a strong attractive power, with bigger fonts being remembered more easily, also people intuitively assume that bigger fonts refer to more important words. This attractive effect of font presents some trade-offs, for example, searching for smaller words in situations where no encoding is applied is sometimes faster, as when using font size, the bigger words distracts the user from the target word that is small.</p><p>In <ref type="figure" target="#fig_0">Figure 1</ref> we present a summary of the tasks and treatments that have been studied in previous work. There are questions that are unanswered in previous work, leaving gaps in the existing literature base. For example, "How would using an additional mark instead of font feature improve performance in different tasks" or "How well people can decode values from font size".</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.2">Gaps and Main Focus of Our Study</head><p>From the related work we can also identify some relevant gaps. One problem we identify is a lack of systematic breakdown of the design space into relevant components. Most of the studies focus on a few conditions that vary across multiple parameters. Consequently, it is not always easy to understand what is the root cause of an observed effect. For instance, in studies that compare spatial/unordered word clouds to sorted lists it is not possible to understand if the observed effect is due to the ordering property of lists or the way words are arranged in the visual space. Similarly, some potentially interesting designs are never included in the studies we reviewed. In particular we identified two major design space gaps: parallel lists and additional marks. One interesting positioning strategy is to arrange the words in a set of parallel lists, rather than one single list extending exclusively in the vertical direction. This design solution is particularly interesting because it allows designers to use an even aspect ratio rather than one that grows only vertically. Also, as we have seen above, lists tend to perform well when tested with some tasks. Therefore, it seems natural to evaluate how designs that leverage the list arrangement perform.</p><p>The use of additional marks is a way to convey magnitude information through marks and visual channels that are, at least theoretically, better than font size. It is surprising to notice how few studies include this specific kind of solution in their comparisons. Related to this last point, we also notice only one single study including a task based on extracting the magnitude value out of the visual representation. Yet, if magnitude is used in visual encoding, it seems natural to verify how accurately people can extract information out of it.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">STUDY RATIONALE</head><p>The main goal of our study is to break down the design space of word clouds in meaningful components and then test their performance against a variety of relevant tasks. In the following section, we describe the design space we have devised and the sets of tasks we used to run our studies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Proposed Design Space</head><p>We will assume the only information available to build such summaries is the list of keywords returned by an automated keyword extraction method (we provide details on which methods we use in our studies below) and the frequency of each keyword in the collection. In this respect, the study is orthogonal to studies that address the problem of improving the keyword extraction process and the use of additional metrics in place of, or in addition to, frequency. In our study we focus exclusively on how to visually encode this information and how different solutions may lead to different performance outcomes.</p><p>The main visual encoding problem therefore consists in deciding how to visually represent a list of words/labels with an associated quantitative value. We identify two main visual parameters that can be freely varied and combined: layout and magnitude encoding. The layout strategy consists in deciding how to position the words in the spatial substrate available for the visualization. The magnitude encoding strategy consists in deciding how to visually encode the quantitative value associated to each word.</p><p>We expect these two factors to have major effects on performance with different tasks and also to have, to some degree, some interaction effects. We expect the position of the words to affect the order in which an observer decides to scan the list of words. Similarly, we expect different magnitude encoding strategies to affect the precision with which values can be compared and extracted. Furthermore, we expect different magnitude encoding strategies to have an effect on guiding the viewer's attention and, as such, to also play a role, together with layout, in determining the order in which the viewer scans and reads the words. <ref type="figure" target="#fig_0">Figure 1</ref> provides a summary of the elements we include in our design space. <ref type="bibr" target="#b0">1</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.1">Layouts: Word Positioning</head><p>There are multiple ways keywords can be positioned in the visual space. In our design space we include three main options: horizontal, vertical, spatial. We choose these three main layouts because they are representative of the three main reading directions they promote: horizontal, vertical and spatial.</p><p>Horizontal: In this layout keywords are placed one after the other in a row until there is no more space available, then a new line is created. It starts from the top-left corner following the reading order from left to right, the standard used in Western countries <ref type="bibr" target="#b1">2</ref> . This layout is one of the most popular: it was popularized by tools like TagCrowd <ref type="bibr" target="#b23">[23]</ref> and it is also used in sites like Google Books <ref type="bibr" target="#b10">[11]</ref>. This layout has also been included several of the studies we mentioned above <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b20">21]</ref>.</p><p>Vertical: In this layout keywords are positioned one after the other in a vertical direction. When no additional vertical space is available a new column is created, thus leading to a multi-column design. One special case of this layout are single-column lists. In this case the list grows only vertically leading to the use of either an uneven aspect ratio of the visual space or the use of a scroll bar. Since we do not want these two aspects to work as confounding factors in our studies, they  are not included in our experiments. As mentioned above, this type of solution is surprisingly rare and underutilized. One example of its use can be found in our previous work on TextTile, an interactive text data analysis system we built <ref type="bibr" target="#b8">[9]</ref>.</p><p>Spatial: In this layout there is no specific order used to position the keywords in the visual space. Many different algorithms have been devised to position the words. The large majority of them however have been designed with the major intent of optimizing space use rather than reading performance. One interesting exception is the use of "semantic layouts": methods that aim at placing words that are semantically related in adjacent positions <ref type="bibr" target="#b22">[22,</ref><ref type="bibr" target="#b27">27]</ref>. While interesting, we do not include this option in our studies because they rely heavily on the quality of methods that compute the "semantic relatedness" of the words and are also not easy to implement uniformly across the spatial layouts we want to test. The spatial layout strategy is by far the most popular and the one that includes many variants. In our studies we use the spiral placement layout proposed in Wordle <ref type="bibr" target="#b26">[26]</ref> and modify it to avoid having word nested inside each other and rotated keywords.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.2">Marks and Channels: Magnitude Encoding</head><p>A common way to describe the visual encoding process of a quantitative variable is to select a mark, a geometric primitive that represents the object, and a visual channel, a visual property that encodes a value associated to the object <ref type="bibr" target="#b18">[19]</ref>.</p><p>In popular word cloud designs such as Wordle, the mark used is actually the word itself and the channel used is the size of the font (typically encoded through a linear mapping between data value and font size). This specific choice however does not cover all sets of possible combinations.</p><p>There are two main additional options that have potentially interesting applications. The first one, is to use other visual properties of fonts to encode quantitative information (e.g., font color intensity). The second one, is to introduce additional marks (e.g., bars or circles) with the purpose of conveying quantitative information and let words function exclusively as labels attached to the marks.</p><p>The advantage of using font properties such as size and color intensity is that they do not require the potentially distracting effect and complexity of encoding related information in two separate visual objects. The advantage of using separate marks, is that it enables the use of more effective encoding strategies for the communication of quantitative information. Font properties, in fact, do not permit the use of some of the most effective visual channels such as position and length <ref type="bibr" target="#b18">[19]</ref>. Furthermore, words are also influenced by word length which may interfere with other useful spatial visual properties. <ref type="bibr" target="#b0">[1]</ref> In order to study these two main strategies, we selected two representative solutions for each category: for solutions based on font properties we included font size and color intensity, whereas for solutions based on additional marks we included bars, encoding magnitude with bar position+length, and circles, encoding magnitude with area size.</p><p>Font Property: Size: This is the most commonly used channel in word clouds. It maps magnitude to the height of the font. Previous research suggests it is the font channel that best conveys the meaning of importance <ref type="bibr" target="#b2">[3]</ref>. The visualization literature and theory, suggest that font size is also not an optimal channel to convey quantitative information <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b25">25]</ref> because of the irregular shape and not direct relationship between height, width and painting area.</p><p>Font Property: Color Intensity: According to Beateman <ref type="bibr" target="#b2">[3]</ref>, after discarding color hue that only works for categorical values and font weight that has to little resolution to be effective, color intensity is the next best font channel to convey importance of a keyword and supports quantitative information.</p><p>Additional Mark: Bars Length: Bars are one of the most used marks in visualization, it allows the use of very strong channels like length and when aligned they can double encode the value using position, the strongest channel for quantitative visualization <ref type="bibr" target="#b18">[19]</ref>. In our experiments we use horizontal bars, since they align with the word reading order. We also place them beneath the keyword to save space and to facilitate visual matching between the label and the mark.</p><p>Additional Mark: Circle Area: Circles are often used in scatter plots as bubbles to convey a third value or in other visualizations in which the spatial properties are already used to encode other information (e.g., bubble maps). Since the diameter of circles change together with area size, it is not possible to find a unique strategy to overlap circles with labels the same way we do with bars. For this reason, in our experiments labels are placed on the left side of each circle.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Benchmark Tasks</head><p>In selecting benchmark tasks for our studies we aim at two main goals. First, we aim at tasks that are representative of the goals pursued when keyword summaries are used in data analysis settings, that is, when the main goal of the user to identify interesting patterns that may lead to useful hypotheses and discoveries. Second, we aim at tasks able to capture performance at various levels of granularity: from low-level perceptual tasks to more high-level ones that require more complex cognitive efforts.</p><p>Our main intent is not only to verify which design elements work best in each of these tasks, but also to connect performance across tasks and see if results observed on lower level task translates into observed improvements in higher level tasks.</p><p>Our experiments are therefore organized around the following tasks: (1) Magnitude Judgment, to study performance in extracting quantitative information out of the encoded magnitudes; (2) Keyword Search, to capture performance in searching for a specific word; (3) Topic Matching, to capture performance in matching a word cloud to a set of predefined topic classes; and (4) Topic Discovery, to capture performance in extracting useful topics out of an assigned word cloud.</p><p>We chose tasks 2 to 4 based on the study presented to Rivadeneira et al. <ref type="bibr" target="#b19">[20]</ref>, where they can be mapped to search, matching and gisting respectively. Task 1 was chosen based on the classic study of Cleveland and McGill <ref type="bibr" target="#b5">[6]</ref>. In the following section, we provide full details on our studies, including information on the specific setup used to study each of these tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">STUDIES</head><p>In this section we describe the series of studies we conducted in order to evaluate each combination of task, layout, and visual encoding we described above. Each subsection covers one task type and each task type was tested using cross combinations of layout and visual encoding. The studies were conducted on-line using Amazon Mechanical Turk. Previous research has shown the reliability of this platform to support visual perception studies <ref type="bibr" target="#b14">[15]</ref>, allowing us to achieve a high number and diversity of subjects. All participants recruited in our studies were from the United States and had a task acceptance rate of at least 99% and levels of education ranging from primary education to doctorate, with at least 60% of them having an undergraduate degree or higher. The participants' age across the studies always ranged between 18 and 71 years. The studies were conducted independently from each other and each participant was limited to participation in one study. All results are presented using effect sizes and confidence intervals (using bootstrap 95% confidence intervals) as suggested in <ref type="bibr" target="#b7">[8]</ref>. All analyses reported in the studies were pre-planned before gathering the data of each experiment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Study 1: Magnitude Judgment</head><p>This first study focuses on understanding how accurate are people in decoding quantitative values from the keyword summary. Being able to gather this information accurately is important because one of the main goals of a keyword summary is to gain an understanding of how frequency or relevance distribute across the words it displays. More precisely, our goal is to understand how different layouts and encoding strategies may affect magnitude estimation and comparison.</p><p>To this purpose, we model our experiment after the classic graphical perception experiment conducted by Cleveland and McGill <ref type="bibr" target="#b5">[6]</ref> in which subjects are presented with different visual encodings and asked to judge proportions between pairs of values. In our study we use a similar set up, with the main difference of replacing the conditions used in the original experiment with the ones described in our design space.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.1">Method</head><p>The first study used a mixed 3 × 4 design, with the 3 layouts (row, column, spatial) assigned between subjects and the 4 visual encodings (font size, color intensity, bar length and circle area) assigned within subjects. This choice was made to find a balance between the duration of a trial for each participants and the number of participants needed to test all possible combinations of the design space.</p><p>We recruited a total of 60 participants and split them randomly into 3 groups of 20 participants for each condition. Each participant performed a total of 48 trials split into 4 sections of 12 trials, one for each visual encoding tested. The order of the visual encodings, as well as the list of words used in each trial, were randomized to avoid learning effects. Each keyword summary depicted a total of 24 keywords in an area of 610 × 410 pixels.</p><p>The data were generated from 3 different data sets: a set of health care reviews, an email collection, and a collection of surveys on humanitarian issues. For each dataset we generated multiple thematic summaries by extracting the top 24 keywords most relevant to a specific category, e.g., keywords related to the dentists category in the healthcare reviews dataset. Relevance was computed using the Normalized Google Distance <ref type="bibr" target="#b4">[5]</ref> between the category and each word.</p><p>The magnitude of the value associated to each keyword was generated using the following equation w i = 10 × 10 i−1 <ref type="bibr" target="#b24">24</ref> , where w i is the ith keyword in the summary. This formula produces a smooth exponential distributions, in which the proportion between any two words is constant and limits the proportions in our study to just 10 possible values, making the data easier to generate and analyze. Such distribution also mimics real-world data sets in which frequency is often distributed exponentially.</p><p>At the beginning of each experiment we presented a consent form. After the participant agreed with the terms, we collected demographic data and presented instructions to describe the task to be performed. After that, the participant went through a training phase to familiarize with the conditions and the task. After the training phase, a screen was shown with final instructions for the actual study and an option to opt out or perform the training phase again.</p><p>For each trial in the study, two words were randomly highlighted using a red triangle below each one. The participants were then instructed to select the smaller of the two and to provide an estimate of how much bigger was the larger compared to the smaller.</p><p>For each trial, we collected the proportion estimated by the participant and measured the absolute error using the formula error = |percentage true − percentage estimated |, where error is the absolute error, percentage true is the true proportion between the values and percentage estimated is the estimated proportion. In order to minimize the effect of outliers we a applied a logarithmic function log-error = log 2 (error + 1/8), where the 1/8 term is used to avoid an indefinite result when the error is 0.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.2">Results</head><p>In <ref type="figure">Figure 2</ref> we present the results of the study. We consider, in order, first the effect of encoding, then layout, and finally the combination between these two factors. For each case we present interval estimates of the log-error calculated as described above. The estimates have been computed by first calculating the mid-mean of log-error for each participant and then computing the 95% bootstrapped confidence intervals sampling from the pool of participants. <ref type="figure">Figure 2(A)</ref> shows the effect of visual encoding. Bar and circle marks perform better than font size and color intensity, although there are some overlapping results. A clear view of the difference between using font properties and additional mark is shown below in <ref type="figure">Figure 2</ref>(B) where contrast confidence intervals have been computed aggregating these two categories. <ref type="figure">Figure 2</ref>(C) shows the performance of each layout: while the column layout interval has some overlap with row, it presents almost no overlap with the spatial layout condition. One possible explanation is that in spatial layout the marks are not aligned and as such they are harder to compare. The column and row layouts, in contrast, align marks vertically or horizontally and, as such, make comparison between some of the channels easier.</p><p>The interaction between marks and alignment is clearer in <ref type="figure">Figure  2</ref>(D), which shows the performance of each combination of layout and visual encoding. It is possible to see a consistent effect of layout across all visual encodings, with the combination bar+column being the most effective. Interestingly, the same advantage of aligned layouts shows up even with the color encoding, a channel that is not expected to benefit from alignment.</p><p>Overall, keyword summaries benefit from using additional marks when the task involves judgment of values. Bars show a small advantage over circles; a result that is corroborated by previous research stating that humans are better at judging length then area <ref type="bibr" target="#b18">[19]</ref>. Bars benefit even more from aligned layouts, allowing comparison on aligned scales.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Study 2: Keyword Search</head><p>In this section we focus on how different encodings and layouts affect the time it takes to find a keyword in a summary. Searching for a keyword is a common low-level task when the user wants to confirm the presence of a specific word he or she has in mind. In previous work the same task has been investigated but always including, among the conditions, one or more layouts in which the words were ordered alphabetically.</p><p>Sorting a keyword summary alphabetically reduces the time to find a word <ref type="bibr" target="#b11">[12]</ref> and as such it makes orderable layouts (e.g., column layout) more effective than un-orderable layouts (e.g., spatial layout). Since this advantage of orderable layouts is established, we designed our studies in a way to avoid this factor and decided to randomize the  order of the words in every condition. In turn, this has also the benefit of comparing layouts independently from their ordering properties, including the case in which a column or row layout is sorted according to a different strategy (e.g., sorted by magnitude).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1">Method</head><p>In this study we used the same mixed 3 × 4 design used in Study 1, with the 3 layouts assigned between subjects and the 4 visual encodings assigned within subjects. For this task, however, we controlled for two additional parameters: target quadrant and target magnitude, which respectively represent in which quadrant the target word is and which magnitude the target word is associated to. The target can be in one out of 5 possible quadrants (top-left, top-right, bottom-left, bottomright and center) and can have 3 possible associated magnitudes (small, medium and large). We hypothesized that searching for a specific word would be influenced by these two additional parameters because: (a) people tend to read words in reading order, from top to bottom and from left to right (albeit limited to Western countries) and (b) because visually encoding the target with high magnitudes can speed up search by making the target stand out from the rest. For each participant we generated a total of 60 trials, which came from all possible combinations of 5 target quadrants, 3 target magnitudes, and 4 visual encodings. All the trials were pre-computed and assigned in random order to each participant to avoid learning effects. Each keyword summary we generated was made of 500 × 400 pixels, each depicting a list of 50 keywords. We recruited 60 participants from Amazon Mechanical Turk, split them into 3 groups of 20 participants and each group was assigned to one of the layouts.</p><p>Following the same procedure of our first study, we presented the participants first with instructions on how to perform the tasks, then with a training phase to check their understanding and level of proficiency, and then, when the participants confirmed they were ready, they could start the actual test.</p><p>In each trial, we instructed the participants to find a given target keyword in a maximum amount of 15 seconds (we found this to be more than enough time through a pilot study). The target word was positioned, during the whole duration of the experiment, right above the keyword summary together with a timer to convey information about elapsed time. The participant could mark the target as found by first clicking on it and then submitting with a submit button. The trial was marked as unfinished when the participant did not click on any word by the end of the time allocated.</p><p>The main metric used to evaluate this task is the time necessary to find a keyword. More precisely we calculated the time interval between the time each summary was presented to the participant and the time the user clicked on the submit button.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2">Results</head><p>The results are analyzed using mean time (calculated for each participant) as the main effect size and bootstrap 95% confidence intervals calculated as in Study 1. In <ref type="figure" target="#fig_2">Figure 3</ref>(A) we show the main effect of visual encoding. Font size and color clearly outperform bar and circle with a difference between the estimated means of about 1.18 seconds. In <ref type="figure" target="#fig_2">Figure 3</ref>(B) we show the effect of target magnitude parameter in relation to the encoding parameter. As expected, larger magnitudes lead to faster target selection. We can also see that the difference between encodings is more prominent with large and medium magnitudes and tends to disappear with small ones.</p><p>In <ref type="figure" target="#fig_2">Figure 3</ref>(C) we show the main effect of layout. The spatial and column layouts have very similar performance and seem to have a somewhat better performance than the row layout. Given the amount of overlap between the confidence intervals the evidence for performance differences is very weak.</p><p>In <ref type="figure" target="#fig_2">Figure 3</ref>(D) we show all the conditions at once organized according to the effect of mark first and then layout. As one can see, the effect of layout is stable across all conditions, with spatial and column layout outperforming the row layout virtually in every condition. We refrain to comment further on individual comparisons as they may be the result of spurious trends due to the high number of conditions presented in the chart.</p><p>Finally, <ref type="figure" target="#fig_2">Figure 3(E)</ref> shows the effect of quadrant on performance. As we expected, our study replicates the same finding reported by Halvey &amp; Keane <ref type="bibr" target="#b11">[12]</ref> and Schramel et al. <ref type="bibr" target="#b20">[21]</ref>, that is, we can see a progressive decrease in performance going from top to bottom and left to right, with top-left being clearly better than bottom-right with a difference between the estimated means of about 1.6 seconds. The figure also shows that the effect of quadrant is also slightly modulated by layout, with the row layout being affected more prominently than the others.</p><p>In contrast to the magnitude judgment study, search tasks are negatively affected by the addition of marks. Adding marks seems to increase the time it takes to spot the target keyword, possibly because they interfere with the search task. The effect of layout, similarly to Study 1, is not particularly prominent but it seems to favor in this case the spatial and column layout.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Study 3: Topic Matching</head><p>In our third experiment we study topic matching, that is, the ability of viewers to identify topics the keyword summaries describe. This study enables us to test the conditions with a more realistic higher level task which requires participants to seek and integrate information across multiple keywords rather than from a few selected ones.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.1">Method</head><p>In this study we used a 3×5 mixed-design with order inverted compared to the first two studies, that is, using layout as within subjects factor and visual encoding as between subjects factor. This choice was made due to the increased complexity of the topic matching task. To reduce the cognitive strain required to perform the whole set of trials, we decided to use layout, which has only 3 distinct values, as the within subjects factor. All trials used keyword summaries with 24 keywords, displayed in a 610 × 410 pixels canvas. In addition to the 4 visual encodings described in the design space, we also included a control condition where no visual encoding was used to visualize the magnitude value; the values were just written in front of each respective keyword as numbers.</p><p>We recruited 150 participants from Amazon Mechanical Turk, split them into 5 groups of 30 participants, one for each value encoding strategy. Each participant performed 30 trials, 10 for each layout assigned in random order. The topics for each trial were also selected in random order without replacement.</p><p>For this test we used exclusively the data set of medical reviews described in Study 1 and generated keyword summaries using 30 different medical specialties contained in the data set as categories. We built each keyword summary using the 24 most discriminative keywords of its own category using the same procedure described in Section 4.1.1.</p><p>For each keyword summary, we generated 4 possible labels: one corresponding to its associated category and 3 additional ones to use as alternative options. To generate the alternative options we created a similarity function that estimates the similarity between any two categories as the cosine distance between word vectors that describe each category. Such function was then used to generate for a given category three alternative labels at a small, medium and high distance. In order to avoid an excessively easy recognition of a category from its keywords, we removed from all trials keywords that were too similar to the labels used to describe the categories.</p><p>Each participant was presented with a consent form, instructions, and a training step to verify proficiency with the task (using a data set not included in the actual test). The participant was admitted to the actual study only after having performed the three preliminary training tasks correctly.</p><p>After the training phase, the study began and for each trial the participant was given 10 seconds to select which, among the displayed 4 options corresponded to the actual category. The 4 options were positioned below the keyword summary during the entire time of the trial and an option could be selected with a mouse click and submitted by clicking on a submit button. The time limit was introduced to emphasize the difference between the conditions we tested. In a preliminary pilot study we found that given unlimited time, the participants would be able to perform the matching task with high accuracy across all conditions. For each study we measure accuracy as the percentage of topics the participant selected correctly.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.2">Results</head><p>The results are reported using mean accuracy as the main metric and bootstrap 95% confidence intervals as uncertainty estimates. <ref type="figure" target="#fig_3">Figure  4(A)</ref> shows the mean accuracy for each visual encoding. Bar and color intensity show slightly better performance, but the extensive overlap between different encodings prevents us to conclude anything strong regarding the effect of encoding.  Here as well the results do not show any particularly strong trend. The lack of strong difference between conditions seems to indicate that as a task increases in complexity, the difference between the conditions becomes smaller or disappears.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Study 3: Topic Matching</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Study 4: Topic Discovery</head><p>In this final study we examine how different design solutions affect the performance of a topic discovery task. In this experiment, we simulated the scenario in which the reader does not have a specific target to search for but he or she is rather exploring the keyword summary to extract and identify potential topics of interest.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.1">Method</head><p>Similar to Study 3, we designed the study as a 3 layouts by 5 encodings (4 visual encodings + one conditions without any value encoding depicting just the keyword) mixed design. We recruited 150 participants from Amazon Mechanical Turk and assigned all the conditions using a between-subjects design method, with 10 participants assigned randomly to each combination of layout + visual encoding. We generated a keyword summary with 24 words placed in a canvas of 610 × 410 pixels according to the given layout and visual encoding.</p><p>To generate the topics, we decided to use the data set of medical reviews described above and focus on topics capturing issues patients have with their doctors. To this purpose, we sampled reviews with negative scores and manually extracted 4 main topics: manners, mistakes, waiting time and financial issues. For each of these topics we manually selected 4 topic-matching words, 4 words with more generic meaning (for example the word "hospital" was considered generic since all reviews are about hospitals), and a set of 4 unrelated words to use as noise. The magnitude of each word was selected using the same exponential distribution described in section 4.1 for Study 1, so that each of the 6 groups of words (4 topics, 1 generic, 1 noise) had its keywords associated with values of similar magnitude but in random order for each participant.</p><p>To verify that the keywords selected were a good match with the topics, we conducted a small survey with 10 Master and PhD students gathered from our lab. Each participant received the list of words and was asked to match topics with the most related words. We then compared the answers to verify the level of agreement and found only a few words with high degree of disagreement. Those words were discarded and replaced with more specific words, based on participants' feedback. As a final step, we also added 4 stop words to function as additional noise.</p><p>We presented the study as a fictitious scenario. In the scenario the participants were instructed to imagine being a data analyst in an insurance company analyzing reviews for a hospital and that their goal was to identify as many issues as possible using the keyword summary. The study started with instructions describing the scenario, followed by a training task, after which the user performed the main task. The main task consisted of 2 steps. First the keyword summary was presented to the user for 30 seconds, in the second step, we removed the keyword summary and asked the participant to provide short sentences describing the issues they identified on the keyword summary.</p><p>The answers provided by the participants were then coded by two of the authors, assigning matching topics to each sentence submitted. After performing the coding, we found an agreement value between the two coders of 91% (and a Kappa coefficient of inter-rater reliability of 0.81). Given the high level of agreement, inconsistencies between the two coders were simply resolved by randomly sampling between their two sets of results. We then computed two metrics: accuracy, representing the percentage of the topics the participant reported correctly out of all those they reported, and coverage, representing the percentage of topics identified out of all the available topics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.2">Results</head><p>The results are reported using mean accuracy and coverage as the main metrics and bootstrap 95% confidence intervals as uncertainty estimates. <ref type="figure" target="#fig_5">Figure 5</ref>(A) shows accuracy and coverage results for the 5 possible visual encoding strategies. As one can see, accuracy is high for all conditions, whereas coverage ranges between 55%-75%. All intervals overlap considerably, preventing us to conclude anything substantial on the tested conditions. Interestingly, the performance of the control condition, with no visual encoding of the magnitude value, is equal, if not better, than the other conditions. We obtain similar results in <ref type="figure" target="#fig_5">Figure  5</ref>(B), when comparing layouts: all intervals overlap considerably and the point estimates are all close one to another.</p><p>An unplanned analysis we performed is the analysis of the effect of target magnitude on topic identification. To this purpose we segmented the trials according to the magnitudes used to display the topic words (remember that trials with all possible sizes have been included for every topic tested) and calculated the mean coverage value and 95% boostrap confidence intervals. <ref type="figure" target="#fig_5">Figure 5(C)</ref> shows the results. As one can see, the topics encoded with larger magnitudes are identified more often than topics with smaller magnitude words, corroborating the results found in Study 2 (see <ref type="figure" target="#fig_2">Figure 3</ref> (B)).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">SUMMARY OF RESULTS</head><p>Overall the results showed a strong dependency on tasks, that is, there is no condition that clearly outperforms all the others across all tested tasks. In the magnitude judgment task, having additional marks improved accuracy, and using a spatial layout led to lower performance. In the keyword search task, we find almost opposite results: with font properties reducing time to find a word and spatial layout being the best option, together with the column layout. In the topic matching task, we did not observe any major differences. The only condition that seems to perform worse than the others is the column layout. Finally, in the topic discovery task the difference between layouts disappears and color intensity is the only encoding clearly worse than the top ranked control. The study also, somewhat surprisingly, shows that the control condition does not perform any worse than the others. The studies also led to a number of additional findings. In the magnitude judgment task, the ranking of visual variables is in accordance with results reported in previous studies <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b14">15]</ref>, but it also extends them by confirming the poor performance of font size and color intensity. In the word search task, we confirm the previous finding <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b20">21]</ref> that the quadrant in which a target word is located has an effect on time. Finally, we also find that search time depends substantially on the magnitude value associated to the target word (Study 2 and Study 4).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">DISCUSSION AND GUIDELINES</head><p>The results we summarized above lead to a number of interesting observations. One of the most relevant findings is the dependence of performance on task. As noted above, there is no condition that clearly outperforms the others across all tasks. Furthermore, as we move from lower level to higher level tasks, any difference observed between the conditions seems to vanish.</p><p>Regarding the shortcomings often mentioned regarding traditional word clouds, namely, the lack of natural reading order and the use of font size to encode quantitative information we find that these negative effects seem to be circumscribed to specific tasks. More precisely, we find that font encoding is an issue when comparing magnitude values (Study 1) but it can also speed up search time when the target happens to have a large magnitude associated to it (Study 2). As for the effect of spatial layout, we did not observe a strong effect. In the magnitude judgment task we do find a slight decrease of performance (Study 1) but no strong effect is found in the keyword search task (Study 2). Whether these effects have an impact on higher level tasks such as those that we tested is not clear, further research is needed.</p><p>"Which solution should be used then?". The answer seems to depend on the specific use one wants to make of a keyword summary. If the goal is to get a general sense of the main concepts contained in the summary, disregarding frequency or relevance, simple lists seem to be a powerful solution. This is corroborated by the observation that as soon as marks or fonts encode frequency values, the reading order of the observer can be influenced and thus generate potentially harmful biases. If searching for specific words is an important task, adding marks rather than using font encoding seems to be detrimental to the search. It is important to keep in mind that this advantage is highly dependent on whether a target word is associated with a large value or not. We conjecture that an increased performance in searching a high frequency word can also signal an excessive influence of visual encoding on attention. If high frequency words attract the attention of the reader too strongly, they may lead to sub-optimal scanning paths and to neglecting potentially interesting terms and concepts; an effect that may be relevant in time-critical situations and in data analysis more in general.</p><p>If extracting frequency or relevance values associated to the words is important, then using additional marks such as bars (using length/position) or circles (using area) seems to be a good choice, as well as using a column or row layout. If a compromise between search and value encoding is needed then the column layout with bars seems to be a good solution because: a) the column layout is the only one that performs well both with magnitude judgment and keyword search and b) the bar encoding does not seem to have a too strong effect on attention. More research is needed to verify this further.</p><p>Before concluding, we want to briefly mention other important aspects we have not tested in our work. First of all, our studies did not investigate how the elements of our design space affect aesthetics judgments. Since visualization is sometimes used in contexts where aesthetics is one of the possible relevant factors, knowing that effect would have some practical relevance. Furthermore, our design space does not exhaust all possible variations one may want to study in a keyword summary. Some other potentially relevant dimensions include: word orientation, number of words, use of color to encode a secondary value, font type and word length. The analysis of these conditions may be addressed in future studies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">FUTURE WORK</head><p>One of the most important aspects to address in future work is the effect of using different keyword extraction methods to generate summaries. While in this study we focused exclusively on aspects that pertain to visual encoding, it is important to keep in mind that the quality of a summary may heavily depend on which terms are selected in the first place. Another important aspect to study is the effect of the number of words shown in a summary. In our study we kept the number of words fixed but it would be useful to know how performance relates to keyword cardinality. Finally, many interesting effects we found in our studies may benefit from further investigation based on eyetracking analysis. Especially, understanding how a viewer directs attention to the words as layouts and marks change. We are particularly interested in further investigating whether some visual encoding may excessively attract attention to some regions, leading the viewer to neglect potentially useful words.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Design space summary showing examples of visualizations generated by the intersection of different visual encodings and layouts for 8 keywords (note: the actual studies presented below used summaries with a larger number of words).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .</head><label>3</label><figDesc>Keyword Search (Study 2). Comparison of mean task completion time for: (A) visual encoding strategies; (B) magnitude of the target and visual encoding strategy used; (C) layout strategies; (D) visual encoding + layout strategies; (E) target quadrant and target quadrant + layout.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 4 .</head><label>4</label><figDesc>Topic Matching (Study 3). Comparison of mean topic matching accuracy for: (A) visual encoding strategies; (B) layout strategies; (C) layout strategies as pairs of contrast confidence intervals.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 (</head><label>4</label><figDesc>B) and (C) show the accuracy results by layout.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 5 .</head><label>5</label><figDesc>Topic Discovery (Study 4). Comparison of mean topic detection accuracy and coverage for: (A) visual encoding strategies; (B) layout strategies; (C) magnitude of target topic.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>is with New York University. E-mail: cristian.felix@nyu.edu. • Steven Franconeri is with Northwestern University. E-mail: franconeri@northwestern.edu. • Enrico Bertini is with New York University. E-mail: enrico.bertini@nyu.edu.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Study 1: Value Comparison Visual Encoding</head><label></label><figDesc></figDesc><table><row><cell>A</cell><cell></cell><cell>D</cell><cell>Visual Encoding and Layout</cell></row><row><cell>Visual Encoding</cell><cell></cell><cell>Visual encoding / Layout</cell></row><row><cell></cell><cell></cell><cell>Log Error</cell></row><row><cell></cell><cell></cell><cell></cell><cell>Log Error</cell></row><row><cell>B</cell><cell cols="2">Font vs. Mark</cell></row><row><cell></cell><cell>Mark is better</cell><cell>Font is better</cell></row><row><cell></cell><cell cols="2">Log Error Contrast CI</cell></row></table><note>Column Fig. 2. Magnitude Judgment (Study 1). Comparison of mean log error for: (A) visual encoding strategy; (B) encoding with font properties vs. additional marks; (C) layout strategy; and (D) combinations of layout + visual encoding strategies.</note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">more examples and details at: https://nyuvis.github.io/word-cloud 2 the order can be reversed for viewers who use a different convention</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">ACKNOWLEDGMENTS</head><p>We thank Pierre Dragicevic and Marti Hearst for their invaluable feedback and suggestions. We also thank Yelp for providing the healthcare reviews dataset. This work is supported in part by CAPES Foundation, Ministry of Education of Brazil -process: BEX 13235/13-3.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">The Biasing Effect of Word Length in Font Size Encodings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Alexander</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Shimabukuro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Franconeri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Collins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gleicher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Poster Proceedings of the IEEE Visualization Conference</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Assessing topic representations for gistforming</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Alexander</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gleicher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the International Working Conference on Advanced Visual Interfaces (AVI)</title>
		<meeting>of the International Working Conference on Advanced Visual Interfaces (AVI)</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Seeing things in the clouds: The effect of visual features on tag cloud selections</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bateman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Gutwin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Nacenta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the ACM Conference on Hypertext and Hypermedia (HT)</title>
		<meeting>of the ACM Conference on Hypertext and Hypermedia (HT)</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">without the clutter of unimportant words: Descriptive keyphrases for text visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Chuang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Heer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Computer-Human Interaction (TOCHI)</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">19</biblScope>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">The google similarity distance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">L</forename><surname>Cilibrasi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">M</forename><surname>Vitanyi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Knowledge and Data Engineering</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Graphical Perception: Theory, Experimentation, and Application to the Development of Graphical Methods</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">S</forename><surname>Cleveland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Mcgill</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Statistical Association</title>
		<imprint>
			<biblScope unit="volume">79</biblScope>
			<biblScope unit="issue">387</biblScope>
			<biblScope unit="page" from="531" to="554" />
			<date type="published" when="1984" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Parallel tag clouds to explore and analyze faceted text corpora</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Collins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">B</forename><surname>Viegas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Wattenberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the IEEE Symposium on Visual Analytics Science and Technology</title>
		<meeting>of the IEEE Symposium on Visual Analytics Science and Technology</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Fair statistical communication in hci</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dragicevic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Modern Statistical Methods for HCI</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="291" to="330" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">TextTile: An Interactive Visualization Tool for Seamless Exploratory Analysis of Structured Data and Unstructured Text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Felix</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">V</forename><surname>Pandey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Bertini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="161" to="170" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Birdvis: Visualizing and understanding bird populations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Ferreira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Lins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Fink</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kelling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wood</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Freire</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Silva</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2374" to="2383" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Google books</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Google</surname></persName>
		</author>
		<ptr target="http://books.google.com" />
		<imprint>
			<biblScope unit="page" from="2017" to="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">An assessment of tag presentation techniques</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Halvey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">T</forename><surname>Keane</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the International Conference on World Wide Web</title>
		<meeting>of the International Conference on World Wide Web</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Hearst</surname></persName>
		</author>
		<title level="m">Whats Up with Tag Clouds? Visual Business Intelligence Newsletter</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Tag clouds: Data analysis tool or social signaller?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Hearst</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Rosner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Annual Hawaii International Conference on System Sciences (HICSS)</title>
		<meeting>of the Annual Hawaii International Conference on System Sciences (HICSS)</meeting>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Crowdsourcing graphical perception: Using mechanical turk to assess visualization design</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Heer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bostock</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the SIGCHI Conference on Human Factors in Computing Systems (CHI)</title>
		<meeting>of the SIGCHI Conference on Human Factors in Computing Systems (CHI)</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="203" to="212" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Comparing tag clouds, term histograms, and term lists for enhancing personalized web search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Hoeber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the IEEE/WIC/ACM International Conference on Web Intelligence and Intelligent Agent Technology (WI-IAT)</title>
		<meeting>of the IEEE/WIC/ACM International Conference on Web Intelligence and Intelligent Agent Technology (WI-IAT)</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Sparkclouds: Visualizing trends in tag clouds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">H</forename><surname>Riche</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">K</forename><surname>Karlson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Carpendale</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1182" to="1189" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Comparison of Tag Cloud Layouts: Task-Related Performance and Visual Exploration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lohmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ziegler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Tetzlaff</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
			<publisher>Springer</publisher>
			<pubPlace>Berlin Heidelberg</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Visualization analysis and design</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Munzner</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Getting our head in the clouds: Toward evaluation studies of tagclouds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">W</forename><surname>Rivadeneira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">M</forename><surname>Gruen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Muller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">R</forename><surname>Millen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the SIGCHI Conference on Human Factors in Computing Systems (CHI)</title>
		<meeting>of the SIGCHI Conference on Human Factors in Computing Systems (CHI)</meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Visual search strategies of tag clouds -results from an eyetracking study</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schrammel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Deutsch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Tscheligi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the IFIP TC 13 International Conference on Human-Computer Interaction (INTERACT)</title>
		<meeting>of the IFIP TC 13 International Conference on Human-Computer Interaction (INTERACT)</meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Springer-Verlag</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Semantically structured tag clouds: An empirical evaluation of clustered presentation approaches</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schrammel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Leitner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Tscheligi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the SIGCHI Conference on Human Factors in Computing Systems (CHI)</title>
		<meeting>of the SIGCHI Conference on Human Factors in Computing Systems (CHI)</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Steinbock</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Tagcrowd</surname></persName>
		</author>
		<ptr target="http://tagcrowd.com" />
		<imprint>
			<biblScope unit="page" from="2017" to="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Mapping text with phrase nets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Van Ham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Wattenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">B</forename><surname>Viégas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">6</biblScope>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Timelines: Tag clouds and the case for vernacular visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">B</forename><surname>Viégas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Wattenberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Interactions</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="49" to="52" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Participatory visualization with wordle</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">B</forename><surname>Viegas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Wattenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Feinberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1137" to="1144" />
			<date type="published" when="2009-11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Semantic-preserving word clouds by seam carving</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Provan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K.-L</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the EG/IEEE VGTC Conference on Visualization (EuroVis)</title>
		<meeting>of the EG/IEEE VGTC Conference on Visualization (EuroVis)</meeting>
		<imprint>
			<publisher>Blackwell Publishing Ltd</publisher>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
