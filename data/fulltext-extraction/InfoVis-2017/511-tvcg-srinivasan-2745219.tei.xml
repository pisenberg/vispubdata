<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/pisenberg/grobid/grobid-0.6.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main"></title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="DOI">10.1109/TVCG.2017.2745219</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2021-02-19T19:16+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Multimodal interaction</term>
					<term>network visualization</term>
					<term>natural language input</term>
					<term>direct manipulation</term>
					<term>multitouch input</term>
				</keywords>
			</textClass>
			<abstract>
				<p>Data visualization systems have predominantly been developed for WIMP-based direct manipulation interfaces. Only recently have other forms of interaction begun to appear, such as natural language or touch-based interaction, though usually operating only independently. Prior evaluations of natural language interfaces for visualization have indicated potential value in combining direct manipulation and natural language as complementary interaction techniques. We hypothesize that truly multimodal interfaces for visualization, those providing users with freedom of expression via both natural language and touch-based direct manipulation input, may provide an effective and engaging user experience. Unfortunately, however, little work has been done in exploring such multimodal visualization interfaces. To address this gap, we have created an architecture and a prototype visualization system called Orko that facilitates both natural language and direct manipulation input. Specifically, Orko focuses on the domain of network visualization, one that has largely relied on WIMP-based interfaces and direct manipulation interaction, and has little or no prior research exploring natural language interaction. We report results from an initial evaluation study of Orko, and use our observations to discuss opportunities and challenges for future work in multimodal network visualization interfaces.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Data visualization systems have predominantly been developed for WIMP-based direct manipulation interfaces. More recently, there has been increased interest within the visualization community to explore</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>• Arjun Srinivasan and John Stasko are with Georgia Institute of</head><p>Technology. E-mail: arjun010@gatech.edu, stasko@cc.gatech.edu visualization on devices and settings where conventional input modalities such as keyboard and mouse are not available (commonly referred to as post-WIMP systems <ref type="bibr" target="#b31">[32]</ref>). One line of research has explored how data visualization can be conducted on large (wall or tabletop) and small (tablets) displays facilitating touch input via a finger or pen <ref type="bibr" target="#b43">[44,</ref><ref type="bibr" target="#b44">45,</ref><ref type="bibr" target="#b53">54]</ref>. These efforts have shown that developing visualization systems on new devices requires significant changes in the interaction style of a visualization system's interface <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b55">56]</ref>.</p><p>Another line of research has explored natural language as an input modality for visualization systems <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b59">60,</ref><ref type="bibr" target="#b63">64]</ref>. Natural language interfaces (NLIs) take a person's utterance as input, and then create or modify visualizations in response to the utterance. Natural language is a promising interaction modality for visualization systems because people often can express their questions and commands more easily using natural language than by translating their intentions to interface actions <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b23">24]</ref>.</p><p>While recent research has explored touch and natural language input, each modality largely has been explored on its own. Prior work within the HCI community has shown, however, that multimodal interaction can significantly enhance user experience and system usability. For instance, in a study comparing the use of speech and pen-based input individually to a combination of both input modalities in the context of an interactive mapping system, evaluations showed that multimodal interaction significantly improved error handling and reliability: people made 36% fewer errors with a multimodal interface <ref type="bibr" target="#b45">[46]</ref>. A recent evaluation of an NLI for visualization also indicated potential value in combining direct manipulation and natural language as complementary interaction techniques <ref type="bibr" target="#b59">[60]</ref>.</p><p>In our work we explore multimodal interaction with visualization, with a particular focus on network-based data. Network visualizations are useful for describing and exploring data relationships in many domains such as transportation planning <ref type="bibr" target="#b38">[39]</ref>, biology <ref type="bibr" target="#b40">[41]</ref>, and the social sciences <ref type="bibr" target="#b42">[43]</ref>. Interaction plays an important role in network visualization systems because users need to engage with elements of interest (e.g., nodes, links) and interact with interface widgets (e.g., sliders, dropdown menus) in order to better understand the data.</p><p>Until now, little work has been done in exploring natural language and multimodal interfaces for network visualizations. We hypothesize that the freedom of expression provided by natural language can be a powerful addition to direct manipulation-based network visualization tools. Natural language combined with direct manipulation may facilitate a better analytical flow by allowing people to more naturally communicate operations such as finding nodes and paths, even while interacting with different parts of the visualization system.</p><p>While multimodal interfaces for network visualization appear to be a promising idea, clearly further research and evaluation is needed to determine whether the conjectures above are true. Will such interfaces facilitate common network exploration and analysis tasks? Will they lead to an improved user experience? To answer such questions, we developed a system, Orko, that facilitates direct manipulation and natural language based multimodal interaction with network visualizations. The primary contributions of our work are as follows:</p><p>• Building upon existing visualization task taxonomies, we highlight the types of queries and interaction patterns that a multimodal network visualization tool needs to support. • Through the design and implementation of Orko, we exemplify how multimodal input can be processed to generate context that can be used to complement the individual modalities. We discuss how coupling this context with time lags between inputs helps facilitate unimodal (touch or speech only), and simultaneous or sequential multimodal interaction with a given visualization. • We report observations from an evaluation of Orko that show people naturally use multimodal input when performing network visualization tasks. Further, we discuss varying preferences for modalities and interaction patterns highlighting the need for future visualization tools to further explore multimodal interaction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK</head><p>Networks have been studied extensively by the visualization community. Many existing systems (e.g., <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b65">66]</ref>) allow people to interactively explore networks by visualizing them using different layouts and representations. Various researchers have proposed different task taxonomies for network visualizations. Lee et al. <ref type="bibr" target="#b32">[33]</ref> present a list of tasks commonly encountered while analyzing network data. They define network specific objects and demonstrate how complex tasks could be seen as a series of low-level tasks <ref type="bibr" target="#b1">[2]</ref> performed on those objects. Pretorius et al. <ref type="bibr" target="#b52">[53]</ref> give an overview of the entities and properties of multivariate networks and present a taxonomy for general visualization tasks. They describe how multivariate network tasks can be composed of lower-level tasks of the general taxonomy. Saket et al.</p><p>[57] present a group-level task taxonomy for network visualizations and characterize a subset of the proposed tasks using a multi-level typology of abstract visualization tasks <ref type="bibr" target="#b10">[11]</ref>. As part of our work, we utilized these taxonomies to understand the tasks that our system would need to support and the types of questions people may ask. A large part of our motivation to explore input modalities (e.g., natural language and touch) that are afforded by post-WIMP interfaces is based on opportunities and challenges highlighted by Lee et al. <ref type="bibr" target="#b31">[32]</ref>. The authors specifically identify "going beyond the mouse and keyboard" and "providing a high freedom of expression" as two of the five key opportunities for research within the visualization community. Given the widespread adoption of direct manipulation as an interaction technique, visualization systems on post-WIMP interfaces have largely been explored using touch-based input <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b44">45,</ref><ref type="bibr" target="#b53">[54]</ref><ref type="bibr" target="#b54">[55]</ref><ref type="bibr" target="#b55">[56]</ref>. Along similar lines, there has been work exploring network visualizations, particularly node-link diagrams, on post-WIMP interfaces. Schmidt et al. <ref type="bibr" target="#b58">[59]</ref> proposed a set of multi-touch gestures for selections in network visualizations. Frisch et al. <ref type="bibr" target="#b19">[20]</ref> explored how people interact with network visualizations on interactive tabletop surfaces using multimodal interaction in the form of touch and pen-based input. More recently, Cordeil <ref type="bibr" target="#b14">[15]</ref> et al. investigated the relative advantages of immersive technologies like CAVE-style environments and low-cost head-mounted displays (HMDs) for collaborative analysis of network connectivity.</p><p>Another input modality that has recently gained renewed interest for data analysis and visualization is natural language. There are several NLIs that allow users to ask questions of their data in the context of databases (NLIDBs) <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b61">62]</ref>. More recently, Li and Jagadish <ref type="bibr" target="#b34">[35]</ref> showed how even novice users were able to specify complex SQL queries using natural language. NLIs for visualization, have been explored both in the research community and as commercial software (e.g., IBM Watson Analytics). Cox et al. <ref type="bibr" target="#b15">[16]</ref> presented some of the earliest work in the space of NLIs for visualization. They combined natural language and direct manipulation in a data visualization environment and showed that multimodal input provides more expressibility than a single modality <ref type="bibr" target="#b48">[49]</ref>. The Articulate system <ref type="bibr" target="#b63">[64]</ref> presents a natural language interface for visualization. It maps user queries to tasks and uses these tasks in combination with data attributes to generate required visualizations. DataTone <ref type="bibr" target="#b20">[21]</ref> is another system that allows users to generate visualizations using natural language queries. It specifically focuses on detecting ambiguity in natural language queries and uses a mixed-initiative approach to resolve this ambiguity and help users iteratively construct visualizations. Kumar et al. <ref type="bibr" target="#b30">[31]</ref> present Ar-ticulate2 an initial prototype of a conversational interface for visualization which aims to explore the dialogue between a user and a system to generate visualizations. The Eviza system <ref type="bibr" target="#b59">[60]</ref> presents a visualization and allows users to ask questions in the context of the given visualization. In doing so, Eviza enables users to have an interactive conversation with the system. By emphasizing the ability for a user to continually revise and update their queries, Eviza seeks to provide a rich dialog with the visualization.</p><p>We also use the context of a given network visualization as a starting point for a conversation between our system and its users. Our work builds upon techniques presented by prior work and extends them to support tasks required to interact with network visualizations. We use a combination of grammar-based and lexicon-based parsing techniques to interpret natural language queries. Further, while existing NLIs for visualization facilitate some level of multimodal input (e.g., Eviza lets users ask a query and then select points on a map), these systems focus more on responding to user queries rather than exploring how people may use multiple modalities. Additionally, most existing NLIs focus on WIMP-based settings and largely let users interact via a mouse and keyboard.</p><p>The broader HCI community, on the other hand, has explored multimodal interfaces facilitating natural language in post-WIMP settings <ref type="bibr" target="#b64">[65]</ref>. Possibly the first, and one of the best known multimodal systems was presented in Bolt's article "Put-that-there" <ref type="bibr" target="#b8">[9]</ref> in 1980. Following this, there were many systems that explored multimodal interaction using a combination of of touch or pointing devices and natural language for a variety of applications including graphics manipula-  tion <ref type="bibr" target="#b27">[28,</ref><ref type="bibr" target="#b51">52,</ref><ref type="bibr" target="#b67">68]</ref>, writing and painting <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b66">67]</ref>, exploring maps <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b45">46]</ref>, among many others. As part of our work, we investigate how the two emerging input modalities of touch and natural language can be combined to facilitate multimodal interaction with network visualizations. While we focus on touch and speech based input, we designed our prototype such that it also works on WIMP-based systems to enable future comparisons between the two settings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">CHALLENGES IN INTERPRETING NATURAL LANGUAGE IN-PUT FOR NETWORK VISUALIZATION</head><p>While the designers of network visualization systems generally understand the challenges and issues of implementing direct manipulation interfaces, natural language interfaces provide an altogether different set of challenges. For instance, consider the different types of queries that people may pose to such a system. (We use the term "query" throughout the remainder of the article to refer to any type of utterance such as a command, comment, or question from a person.) To help understand the possibilities, we collected a set of sample queries by referring to existing network visualization task taxonomies <ref type="bibr" target="#b32">[33,</ref><ref type="bibr" target="#b52">53,</ref><ref type="bibr" target="#b56">57]</ref> and through pilot studies with students and research colleagues. We then used an affinity diagramming approach, grouping similar queries and iteratively refining the groups according to how precise queries were in terms of conveying user intent. We made the assumption that user intent is conveyed by tasks and the values they map to. We then combined groups under broader categories. This process resulted in three higher-order categories of queries: explicit, contextual and follow-up, and high-level <ref type="figure" target="#fig_1">(Figure 2a</ref>).</p><p>For the remainder of the article, we will use a specific example, a network of European football (soccer) players, to help ground our discussions and make concepts more explicit. The network contains 552 players (nodes) and 6772 connections (links) between those players. A link is created between two players if they play for the same club team (league team) or the same national team. In addition to the name, club, and country information, other attributes associated with players include number of goals scored, market value (in USD), age, club, country, preferred foot, and field position.</p><p>Of the three categories of queries introduced above, explicit queries typically provide sufficient information in terms of both tasks and values for a system to parse the query and generate a response. Command-like queries can be considered as a subset of explicit queries. Examples of these types of queries include "Find Ronaldo" or "Show the shortest path from Evra to Kroos".</p><p>Given the conversational nature of NLIs, users may frequently pose queries that are follow-ups to their previous queries. Such queries typically lack references to tasks or values associated with a task. For example, consider the query "Color nodes by country" followed by "Now club", followed by "How about position?". While the queries following the first one appear incomplete individually, they refer to the coloring task implied by the first query. In a multimodal setting, users may even present queries that are follow-ups to their actions on the direct manipulation interface. We refer to such questions or queries as "contextual" queries. For example, if the user selects a subset of nodes and utters the query "Show connections of these players", the system needs to detect that the user is referring to the selected players and automatically map the task of finding connections to those players.</p><p>Finally, high-level queries are generally open-ended user questions.</p><p>These questions typically do not specify explicit tasks and can be interpreted and answered in multiple ways depending on the interpretation. Examples include questions like "How are France and Italy connected?" or "Players from which countries tend to play more for clubs in the same country?" To generate a response for such queries, a system typically needs to break the question into smaller tasks, solve those tasks and combine the results into a final response. The sheer variety of ways of saying something poses another challenge. Given the freedom of expression associated with natural language, a person's particular intent can be stated in multiple ways. For example, <ref type="figure" target="#fig_1">Figure 2b</ref> shows some of the many ways that a person could state a query to find the connections of a node. Additionally, other challenges of natural language such as ambiguity exist as well. Ambiguity may exist not only at a syntactic level (e.g., misspelled words) but also at a semantic level in the context of words (e.g., synonyms and hypernyms) and the data (e.g., "high goal scorers" can refer to players with over 10 goals, 20 goals, and so on).</p><p>The presented examples and classifications in <ref type="figure" target="#fig_1">Figure 2</ref> are not exhaustive, nor is our goal to provide a definitive taxonomy of query types. Instead, the intent of this section is to present a general overview of the input space of natural language queries for network visualizations in the targeted multimodal setting, and highlight the associated complexities. We will reference these different query types later when describing Orko's functionality.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">ORKO</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Design Goals</head><p>Although we sought to achieve a variety of objectives while building Orko, two primary high-level goals drove the design of the system. DG1. Facilitate a variety of network visualization tasks. A core goal for Orko was to support exploratory analysis similar to that done in existing desktop-based network visualization systems (e.g., <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b36">37]</ref>), but in a multimodal setting. More specifically, we wanted to focus on supporting a variety of tasks including topology-based, attributebased, and browsing tasks in context of the taxonomy by Lee et al. <ref type="bibr" target="#b32">[33]</ref>, a subset of structure-based and attribute-based tasks at a node (entity) level per the taxonomy by Pretorius et al. <ref type="bibr" target="#b52">[53]</ref>, and finally, a small subset of group-only, and group-node tasks as specified in the taxonomy by Saket et al. <ref type="bibr" target="#b56">[57]</ref>.</p><p>DG2. Facilitate a variety of input integration patterns for multimodal interaction. Multimodal interfaces provide more freedom of expression allowing users to interact with the system in multiple ways. For such systems, input patterns are typically categorized based on the number of modalities used and temporal synchronization between modalities <ref type="bibr" target="#b47">[48,</ref><ref type="bibr" target="#b49">50,</ref><ref type="bibr" target="#b50">51]</ref>. Given the system's primary usage setting (touch and speech input), our goal was to support a variety of these input patterns, including unimodal input (touch-only, speech-only), sequential multimodal input (e.g., selecting nodes via touch followed by a pause followed by a find connections query), and simultaneous input (e.g., issuing a Color nodes query while highlighting a node's connections). More specifically, in addition to incorporating both input modalities individually, this goal required us to consider synergies between the two modalities while designing the interface, and support not just explicit and follow-up but also contextual queries <ref type="figure" target="#fig_1">(Figure 2a</ref>). We chose not to focus on high-level questions <ref type="figure" target="#fig_1">(Figure 2a</ref>) as we believe they are more specific to NLIs. Further, these queries pose a challenge of overcoming the variability in responses that is beyond the scope of our current work focusing on multimodal interaction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">System Overview and User Interface</head><p>Implemented as a web-based tool, Orko runs on both conventional desktops/laptops and other devices supporting touch and speech interaction. <ref type="figure" target="#fig_0">Figure 1</ref> shows the system's user interface, and we provide an overview of its capabilities and operations below.</p><p>At the top of the window ( <ref type="figure" target="#fig_0">Figure 1A</ref>), is an input box that shows the typed or spoken natural language query. Users can input natural language queries in two ways: pressing the microphone button ( ) next to the input box and speaking the query, or by saying "System" and then speaking the actual query (similar to the interaction with Amazon.com's Alexa <ref type="bibr" target="#b2">[3]</ref> or Google's Assistant <ref type="bibr" target="#b21">[22]</ref>). Below the input text box is an action feedback row that conveys the changes made to the interface as part of the response to a query. Orko also provides optional audio feedback where the system narrates the content of the feedback row. Some examples of feedback messages include "Highlighting nodes directly connected to Gareth Bale", "Changed coloring attribute to country", or "Sorry I'm unable to process that query. Can you try asking the question differently?". In some cases, the feedback row is interactive, allowing users to modify the input query (discussed further in section 4.4.3).</p><p>The network canvas ( <ref type="figure" target="#fig_0">Figure 1B</ref>) presents the network visualization with entities represented as circles and connections between entities represented as lines connecting the circles. Node positions are determined by D3's force-directed layout <ref type="bibr" target="#b9">[10]</ref>. By default, labels are hidden to avoid clutter. Labels are only shown when nodes are selected or highlighted. A click or tap on the canvas background clears selections. Quick access icons ( <ref type="figure" target="#fig_0">Figure 1C</ref>) are provided at the bottom right of the canvas to reset the view by clearing all selections and filters ( ), unpin all pinned nodes and reset the force-layout ( ), and re-center the network ( ).</p><p>As mentioned earlier, we designed Orko primarily for touchscreen devices. Consequently, we implemented the interactions within the visualization such that they do not rely on hover (unavailable on commonly found touchscreens <ref type="bibr" target="#b28">[29]</ref>) and can work on both touch and pointing devices (e.g., mouse, stylus). Users can single-tap on nodes to get details, double-tap to highlight a node's connections, drag a node to modify the layout by pinning a node, long press (individually) on two nodes to highlight the shortest path between them, zoom using a pinch-gesture, and pan using a single finger drag on the background of the canvas. When a node's connections are highlighted, details of individual links can be seen using a single-tap on the link. Keeping in mind issues like the fat-finger problem <ref type="bibr" target="#b60">[61]</ref>, we sized nodes such that it is easy to tap them and add buffer space while detecting interactions with links to handle offset touches. The details container ( <ref type="figure" target="#fig_0">Figure 1D</ref>) shows attributes of selected nodes and link descriptions.</p><p>The summary container ( <ref type="figure" target="#fig_0">Figure 1E</ref>) shows bar charts that complement the selections on the network visualization. The charts present attribute-level summaries for active (highlighted) nodes. The bar charts are coordinated with the network visualization and facilitate brushing and linking. The bars within charts are sorted in descending order of width from top to bottom to facilitate ordered comparisons. The charts dynamically reorder based on the sequence of user interactions with attributes-the most recently used attribute is always shown on top of the container. We made this design decision of reordering charts based on two hypotheses. First, users would find it beneficial to see the summary statistics for attributes they most recently used on top to answer possible questions they have in mind for the attribute (e.g., if a user filters nodes by goals scored, the summary chart for goals would show up on top presenting a ranked list of the highlighted players and the number of goals they scored). Second, since the container shows all attributes available in the dataset, it could help facilitate an analytical conversation by triggering questions in users' minds about potential attributes they may not have considered.</p><p>The filters and encodings row ( <ref type="figure" target="#fig_0">Figure 1F</ref>) presents the various filtering and encoding options. Filtering widgets include range sliders for numerical values and dropdown menus for categorical values. Visual</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Operation Applicable to Sample queries</head><p>Find nodes Label attribute "Find Wayne Rooney", "Show Bale and Ronaldo", "Highlight Iniesta"</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Find connections</head><p>Label attribute "Show Griezmann's teammates", "Highlight players connected to David de Gea", "Find players who play with Sergio Ramos", "Show players connected to these players"</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Find path</head><p>Label attribute "How are James McCarthy and Toni Kroos connected", "Show connection between Giroud and Neuer", "Highlight a path from Sergio Busquets to Patrice Evra", "Show a path between these nodes"</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Filter nodes</head><p>Categorical &amp; numerical attributes "Show left footed Madrid players", "Find players with more than 15 goals", "Highlight German players over the age of 28", "Remove age and market value filters"</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Color nodes</head><p>Categorial attributes "Color by country", "Highlight player positions", "Color players by their field positions", "Can you add coloring based on foot"</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Size nodes</head><p>Numerical attributes "Size by market value", "Resize nodes to highlight age", "Size nodes by betweenness centrality"</p><p>Interface actions -"Refresh view", "Clear all filters and selections", "Deselect all nodes", "Re-center graph" encoding widgets include dropdowns for assigning node coloring and sizing attributes. Users can choose to keep the widgets on or remove them at any point using the icon next to each widget.</p><p>To support the targeted categories of network analysis tasks (DG1), Orko currently provides a set of seven more specific low-level operations listed in <ref type="figure" target="#fig_2">Figure 3</ref>. In the context of a recent categorization of potential tasks people try to perform in visualization related NLIs <ref type="bibr" target="#b62">[63]</ref>, Orko currently focuses on supporting visualization-specific interactions, and provides basic support for low-level analytical operations and system control-related tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Usage Scenario: European Soccer Players</head><p>To provide a better sense of how the system works, we describe a hypothetical usage scenario below. Imagine Joe, a visitor at the FIFA World Football Museum, interacting with the European soccer player network using Orko on a touch and speech-enabled display (The scenario is illustrated more explicitly in a storyboard sequence and a video as part of the supplementary material for this paper.) Orko: Shows the network using a force-directed layout. Joe: To focus on high scoring players, says "Show top goal scorers". Orko: Identifies ambiguity in the question due to the word 'top'. Consequently, adds a slider for the goals attribute ( <ref type="figure">Figure 4a</ref>). Joe: Adjusts the slider and observes the summary charts to highlight the top five goal scorers in the network (Robbie Keane, Zlatan Ibrahimovic, Cristiano Ronaldo, Wayne Rooney, Lucas Podolski). To see connections of the highlighted players, says "Show players connected to these players". Orko: Detects that by "these" Joe is referring to the filtered set of five players, thus highlights their connections. Preserving the goals filter, shows the connections as faded nodes (similar to faded nodes in <ref type="figure" target="#fig_0">Figure 1B)</ref>. Joe: To highlight all connections of top five goal scorers, removes the goals filter. Orko: Highlights top five goal scorers and their connections. Also highlights common connections between two or more of the top five goal scorers using a yellow stroke around the node <ref type="figure">(Figure 4b)</ref>. Joe: Modifies the layout by pinning the top five players in different locations. Using the modified layout and highlighted common connections, observes that Cristiano Ronaldo and Lucas Podolski have a common connection (Toni Kroos). Wayne Rooney and Lucas Podolski also have a common connection (Bastian Schweinsteiger). Robbie Keane and Zlatan Ibrahimovic have no common connections with the other top goal scorers. Wondering about the market value of players, says "Size players by their salaries" Orko: Maps the word "salaries" to the attribute market value and resizes nodes by the market values of players. Joe: Observes that Podolski, even though among the top five goal scorers, is paid much less in comparison to his teammates. Observes that Toni Kroos, who is the common connection between Podolski and Ronaldo is paid notably more than Podolski. Intrigued by this, says "Highlight this connection between Ronaldo and Podolski". Orko: Highlights the path from Ronaldo to Podolski via Kroos <ref type="figure">(Figure 4c)</ref>. Joe: By tapping on the highlighted links, understands that both Kroos and Ronaldo play for the same club (Real Madrid) and Kroos and Podolski play for the same country (Germany). Curious to learn more about the differences in salaries between Podolski and his club and national teammates, double-taps on Podolski. Orko: Highlights Podolski and his connections. Joe: Notices that Podolski is a striker with a high number of goals and still is not even in the top ten players among his teammates (shown by the summary charts) in terms of market value. Wondering if field position has any correlation with salaries, says "Highlight field positions of these players". Orko: Colors nodes by the positions the players play in. Joe: Scanning the highlighted players, notices three German strikers (Muller, Gomez, Podolski). Muller is paid most, followed by Gomez and Podolski. Using the summary charts, notices that in terms of goals, Podolski has most goals (48) followed by Muller <ref type="bibr" target="#b30">(31)</ref> and Gomez <ref type="bibr" target="#b26">(27)</ref>. Intrigued by this fact, wonders about other attributes that may account for the differences in salaries between German strikers. To focus on the specific players, says "Just highlight the German strikers". Orko: Highlights the three German strikers and updates the summary container. Joe: To compare the three players across different attributes, toggles through the list of attributes available for node-sizing. Orko: Re-sizes nodes and re-orders the summary charts so that recently used attributes are shown on top <ref type="figure">(Figure 4d)</ref>. Joe: Stops at age attribute upon noticing that nodes representing Podolski and Gomez are much larger than the node representing Muller. Confirming the values using the age bar chart at the top of the summary container, hypothesizes that the age may be the factor leading to salary differences (since younger players are typically paid more).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">System Architecture and Design</head><p>To facilitate multimodal interaction and support the different combinations of input patterns (DG2), Orko employs a client-server architecture shown in <ref type="figure" target="#fig_4">Figure 5</ref>. Below we describe the individual components highlighting their specific functions and how they communicate with each other to facilitate multimodal interaction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.1">Processing direct manipulation or natural language input</head><p>All direct manipulation (e.g., mouse, pen, touch) events triggered on Orko's interface (e.g., tapping a node, changing a dropdown value, adjusting a slider) are collected and handled by the interface manager. We use the HTML5 webkit speech recognition API for detecting voice-input and performing speech-to-text translation. Once a query string is available (either via speech-to-text or user-typed), the interface manager sends it to the server for interpretation. On the server, the query processor parses natural language queries and generates a list of actions that need to be taken in response to a query.  To parse natural language queries, in comparison to existing NLIs for visualization that tend to use either a grammar-based approach (e.g., <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b63">64]</ref>) or a lexicon-based approach (e.g., <ref type="bibr" target="#b20">[21]</ref>), we implement a two-step approach combining both grammar and lexicon based parsing techniques. This approach lets the system parse queries that match a grammar pattern instantaneously while at the same time, also having a more general back-up parsing strategy based on a combination of keyword-matching and heuristics for query patterns not covered by the grammar.</p><p>Patterns for the grammar parser are specified using Artificial Intelligence Markup Language (AIML) <ref type="bibr" target="#b12">[13]</ref>. The patterns were generated based on question types and examples presented in existing task taxonomies <ref type="bibr" target="#b32">[33,</ref><ref type="bibr" target="#b52">53,</ref><ref type="bibr" target="#b56">57]</ref> and pilot studies with students and research col-leagues. We use a python based AIML interpreter (PyAIML) trained with the AIML files to parse incoming query strings. The interpreter builds a directed pattern tree and employs a backtracking depth-first search algorithm for pattern matching. For a given query, the grammar parser seeks to identify operations ( <ref type="figure" target="#fig_2">Figure 3</ref>) specified and substrings containing references to attributes or values the operations apply to (analogous to a set of non-terminal symbols in a context-free grammar <ref type="bibr" target="#b16">[17]</ref>). If there is no matching pattern found, the entire query is forwarded to the second parser, else, only the target referencing substring is sent to the lexicon-based parser. For instance, given a query like "Show connections of Ronaldo", the grammar parser identifies that the operation is find connections and the target is 'Ronaldo' (which is sent to the second parser). Alternatively, a query like "Show only if Barcelona and left foot" may not match an existing pattern and will be forwarded as-is to the lexicon-based parser. The lexicon used consists of attributes derived from the dataset (e.g. goals, country, names) and manually specified keywords (e.g., teammates, adjacent, striker) that help identify attributes, values, and operations in a given query. Some of these keywords are generic and apply to multiple datasets (e.g., adjacent) while others are dataset specific (e.g., striker, teammate). While we leverage existing lexical databases like WordNet <ref type="bibr" target="#b41">[42]</ref> to support using synonyms (discussed further below), there always will be dataset-specific cases that are not supported by such general databases (e.g., using "striker" instead of "forward" for position). For such cases, in our current implementation, both, domain-specific grammar patterns and dataset-specific keywords should be manually added the first time a dataset is loaded.</p><p>Given a portion of the query or the entire query string, the lexiconbased parser first performs stemming and removes stop words (with the exception of conjunction/disjunction phrases). It then extracts ngrams (with n ranging from 1 to the number of words in the input string). For each n-gram, it identifies POS tags (e.g., noun, verb) and entity types (e.g., person, location, organization) using NLTK <ref type="bibr" target="#b35">[36]</ref> and Stanford CoreNLP <ref type="bibr" target="#b39">[40]</ref>. n-grams not containing entity types relevant to the dataset or values that may apply to filters (e.g., numbers) are discarded. This filtering helps improve performance by ignoring ngrams that do not contain relevant information. Next, the relevant ngrams are compared to logically similar lexical entries (those that have related POS tags or entity types). This similarity-based comparison again helps improve performance by avoiding matches against potentially irrelevant values (e.g., comparing people to locations). Building upon existing work <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b59">60]</ref>, we use the cosine similarity and the Wu-Palmer similarity score <ref type="bibr" target="#b69">[70]</ref> when comparing n-grams to lexical entries. These scores help in detecting both syntactic (e.g., misspelled words) and semantic (e.g., synonyms, hypernyms) ambiguities. If there are no operations identified by the grammar parser, similar to Gao et al. <ref type="bibr" target="#b20">[21]</ref>, we use keyword-matching and a combination of POS-tags and dependency parsing techniques <ref type="bibr" target="#b39">[40]</ref> to identify operations specified in a query. In summary, for the query "Show only if Barcelona and left foot", the lexicon-based parser identifies a filter operation, a club ("Barcelona FC"), and a value for foot ("left").</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.2">Managing multimodal input</head><p>In addition to its focus on network visualizations, Orko's primary difference compared to related systems (e.g., <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b59">60]</ref>) is its support for various multimodal interaction patterns listed in DG2. As an example of the input patterns the current framework supports, consider the case of finding connections of a set of top goal scoring players for England. A user could accomplish this via only touch by applying multiple filters (for country and goals) and double tapping nodes to highlight connections. Instead, one could also use speech alone to perform the same task (using a single query like "Show connections of English players with more than 20 goals" or multiple smaller queries). Alternatively, a user could use a combination of the two modalities and: (1) apply filters (via touch) and follow it with a spoken query (e.g.,"show adjacent nodes"), or (2) apply filters via speech and then double-tap nodes, or (3) do both filtering and uttering a query simultaneously (starting with either of the two modalities). In cases (1) and (3), the context generated by one input is used to complement the second and high-light connections of the filtered nodes. For (2), the system processes the two inputs individually as described in the subsection above, preserving filters from the spoken query.</p><p>To support the patterns described above, the system needs to first classify input patterns and then share relevant information collected across input modes to appropriately respond to the user input. To accomplish this, Orko first classifies an input pattern as unimodal, sequential, or simultaneous. To classify an input pattern, we use a combination of interface context and time lag between user inputs. The interface context is tracked using an object that stores information about active/highlighted nodes, filters applied, encodings used, previous interaction modality used, and operations and target values in the last specified query. Both the interface manager and the query processor continually update this context object based on user inputs and actions.</p><p>When a user input (touch or speech) event occurs, we check in paralell if there is a change in the modality used between inputs. If so, we further check if there is any missing information in the input (e.g., missing target value in a query) and a corresponding interface context that can be applied to the current input. For example, if a user selects two nodes (via touch) and then issues a query "Find connections", Orko can leverage the context of the selected nodes and apply it to the user query. We use a heuristic approach and mappings between operations and attribute types <ref type="figure" target="#fig_2">(Figure 3</ref>) to decide if a context applies to an input. However, an applicable interface context could be generated in both sequential and simultaneous input.</p><p>To differentiate between the two, when there is an applicable interface context, we also check the time lag between the previous and recent input. Based on prior work on multimodal input patterns <ref type="bibr" target="#b50">[51]</ref> and our pilot studies, we differentiate between sequential and simultaneous input based on a time lag of two seconds between modalities. We make this differentiation to decide when context from the previous input should not be applied to the current one. For example, consider a case where there are no selected nodes and a user issues a query "Show nodes connected to" and follows it by a long pause. Now, the user adds a filter (via touch) to highlight the Spanish players. If the context from the query is applied by default, connections of the filtered nodes will automatically be shown. However, after such a pause, it is likely that the user was trying to perform a new filter action and wanted to ignore the previous query. In such cases, since we know that the pattern in this case was sequential, we can choose to not apply the system context and ignore the previous query instead.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.3">Supporting follow-up queries and query refinement</head><p>To handle follow-up queries (discussed in Section 3), we implement a conversational centering <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b26">27]</ref> (or immediate focusing <ref type="bibr" target="#b24">[25]</ref>) based approach. The centers are maintained by the query processor and include operations, attributes, and values. We retain, shift, or continue centers across utterances <ref type="bibr" target="#b26">[27]</ref> depending on the information shared or added between queries. Consider the query "Show only Real Madrid players" followed by "Show strikers". In this case, the club filter "Real Madrid" is retained across queries, and a position filter ("striker") is added after the second query (a continue operation). Now, when another query "Show defenders for Barcelona" is presented, the center is shifted to "defender" and "Barcelona FC" respectively.</p><p>Since we wanted to test Orko in a speech+touch setting where typing to modify specific parts of a query or repeatedly uttering similar queries can become tedious, while designing Orko, we also considered interface elements that may assist users in modifying their queries. We considered ways in which we could assist users to ask followup queries that refer to the same operation but different target(s) (e.g. "Show Real Madrid players" followed by "Show Barcelona players"). Such queries can be very common during network exploration, particularly while users try to scan through different node groups. To assist in constructing such follow-up queries, Orko adds query manipulation widgets (dropdowns and sliders) to the action feedback row highlighting the domain of input values for an attribute alongside the operation being performed (e.g., <ref type="figure" target="#fig_5">Figure 6a</ref>). Hence, for the club example discussed above, the user can specify a filter by club query once and then keep updating the club names for consecutive queries using the drop-down. Users can still ask follow-up queries or modify existing queries by typing if they prefer to do so. To allow users to instantly revert back to the original query, it is preserved in the text box ( <ref type="figure" target="#fig_0">Figure 1A)</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.4">Highlighting ambiguity in queries</head><p>Similar to prior work <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b59">60]</ref>, we also provide ambiguity widgets to highlight and help users resolve ambiguity via Orko's interface. Currently supported ambiguity widgets include range sliders (for numerical attributes) and interactive tooltips (for label and categorical attributes). The interactive tooltips work as follows: vertical ellipsis icons ( ) are added next to query manipulation dropdowns to notify users that the system detected ambiguous matches. When pressed, these icons display a tooltip showing the list of matched values <ref type="figure" target="#fig_0">(Figures 1F and 6b)</ref>. Selecting an item in the tooltip updates the value of the adjacent dropdown. By default, the query manipulation dropdown is populated with the value most similar to the ambiguous string. We also explored how the system can suggest operations in cases where a presented query lacks references to operations (or there is ambiguity in operations) and there is no preceding query or an applicable interface context to leverage. Such queries can be common with issues in speech detection that lead to partial detection of queries (e.g., "Rooney and Ronaldo" instead of "Find connections of Rooney and Ronaldo"). When the response generator detects attributes or values in a query but is unable to map them to a specific operation, it makes a "guess" at the operation that a user could perform based on a reverse mapping from attribute types to the list of available operations <ref type="figure" target="#fig_2">(Figure 3</ref>). An example of this is shown in <ref type="figure" target="#fig_5">Figure 6c</ref> where three operations, find nodes, find connections, and find path are suggested in response to an underspecified query using an interactive tooltip.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">EVALUATION</head><p>We conducted a user study to evaluate Orko's design and multimodal approach for interacting with network visualisations. We had three main goals: (1) assess basic usability of the system, (2) collect qualitative feedback on Orko's features and design, and (3) collect observational data on how people interact with network visualizations when they have the option of using multimodal input.</p><p>We initially considered performing a comparative study to measure usability and performance but struggled to find the right comparison since we could not find any publicly available network visualization tool that supported multimodal interaction. We also considered comparisons to unimodal interfaces (touch-only, NL-only) but decided against doing so because that evaluation would focus more on an examination of unimodal versus multimodal interaction, which was not our goal in this study. We finally decided on a study where all participants would interact with Orko and perform the same set of tasks using the European soccer player network described earlier.</p><p>Selecting and phrasing the study tasks themselves was another challenge. Due to the availability of speech as an input modality, posing tasks as direct questions was not an option since participants could simply repeat (say) the questions. Thus, we adopted the Jeopardy-style evaluation approach proposed by Gao et al. <ref type="bibr" target="#b20">[21]</ref>. We gave participants a set of facts and asked them to modify the visualization to show each fact. For example, one such fact was "Robbie Keane only plays with Irish players." To "answer" this, participants would need to show that all of Robbie Keane's connections belong to Ireland. (So, participants would need to find connections + color nodes by country, or find connections + scan summary charts, or find connections + scan individual nodes). We also added some entity naming tasks that required participants to explore the network to identify specific entities. The tasks again were framed so that participants could not simply parrot them to get an answer. For example, one of the questions was "Name an FC Barcelona midfielder. Identify at least two non-Barcelona midfielders the player is connected to." To respond to the first part of this question, participants would have to name (using filter or find) and highlight a Barcelona midfielder. For the second part, they would have to highlight the player's connections with two other non-Barcelona players and show that those two are also midfielders.</p><p>To assess the prototype's usability, we used the standard 10 question SUS questionnaire <ref type="bibr" target="#b11">[12]</ref>. We used SUS since it has been shown to provide a global measure of system satisfaction and sub-scales of usability and learnability <ref type="bibr" target="#b33">[34]</ref>. Further, the correlation between SUS scores and task performance is similar to most other post-test questionnaires <ref type="bibr" target="#b57">[58]</ref>.</p><p>To collect qualitative feedback on Orko's design and features, we encouraged participants to think aloud and interact with the experimenter while performing the given tasks. We also conducted informal interviews at the end of the session asking participants about their experience and feedback on the system features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Participants and Experimental Setup</head><p>We recruited six participants, ages 22 to 42, five male and one female. All participants had prior experience with visualization tools such as Tableau. All participants had some prior experience with network visualization tools (e.g., Gephi <ref type="bibr" target="#b6">[7]</ref>). Two participants stated they had some prior experience working with touch-based visualization systems and only one participant (P2) had never used a voice-based system (e.g., Siri). In terms of domain knowledge, two participants were well acquainted with the sport of soccer and the data, and remaining four stated they were aware of it but did not follow the game or know much about the data. All participants interacted with Orko running on Google's Chrome browser on a 55" Microsoft Perceptive Pixels (PPI) device. The PPI was set to a resolution of 1920 x 1080 pixels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Procedure</head><p>Participants were given a brief introduction (approximately 5-7 minutes) to the system's UI and the European soccer player dataset. For the UI, we highlighted the different components <ref type="figure" target="#fig_0">(Figure 1)</ref>, possible touch-interactions (tap, double-tap, drag etc.), and told participants that they could use typed (using a virtual keyboard) or speech-based input for natural language interaction. We did not show any trials or videos of how participants could perform any specific task since we wanted to observe their natural behavior and reactions. Participants were then asked to try the touch and speech input using any interactions and commands they wanted to test, until they felt comfortable (approximately 1-3 minutes).</p><p>Next, we gave participants a list of 10 tasks printed on a sheet of paper and 30 minutes to interact with the system. The order of the tasks was randomized for each participant. The tasks contained a mix of Jeopardy-style <ref type="bibr" target="#b20">[21]</ref> facts and entity identification questions. The questions were constructed using previously defined network visualization task taxonomies <ref type="bibr" target="#b32">[33,</ref><ref type="bibr" target="#b56">57]</ref> and included topology-level tasks, attributelevel tasks, browsing-tasks, and some group-level tasks. Details of the tasks are provided as part of the supplementary materials.</p><p>We told the participants that we would not be measuring how quickly they perform the tasks, so they should feel free and interact as naturally as possible. We recorded both video and audio of participants interacting with the system during these 30 minutes. Participants who finished the tasks before 30 minutes could continue exploring the data using the system if desired. Participants were then given a post-session questionnaire that consisted of SUS questions and questions asking them about their experience with Orko. We also conducted informal interviews asking the participants about what they liked/disliked most about the system and recorded their their responses as audio files. Sessions lasted between 40-60 minutes and participants were given a $20 Amazon gift card.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Results and Observations</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.1">System Usability Scale responses</head><p>All participants attempted each of the 10 tasks and on average, provided correct responses for 8.67 tasks. <ref type="figure">Figure 7</ref> (right) summarizes overall SUS scores. Participants gave Orko an average SUS score of 75.42. SUS scores have a range of 0 to 100 and a score of around 60 and above is generally considered as an indicator of good usability <ref type="bibr" target="#b37">[38]</ref>. The SUS scores indicate that even though the prototype is in its initial stages, participants in general found the interface and the interactions facilitated by Orko usable. <ref type="figure">Figure 7</ref> (left) summarizes interactions for the six participants for each study task (descriptions provided as supplementary material). The cell values indicate the number of times an input modality was used to accomplish operations in <ref type="figure" target="#fig_2">Figure 3</ref>. For example, for a find connections operation, P1 used a combination of speech and touch (find query + double-tap) once and two speech queries (find + find connections) the second time (first and second row of the table respectively).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.2">Interaction Patterns and preferences</head><p>Of 181 total constructions, 92 (50.8%) instances of just spoken queries arose, unimodal touch accounted for 55 (30.9%), and multimodal interaction where both speech and touch were used sequentially made up the remaining 33 (18.3%) constructions. No instances existed where modalities were used simultaneously (a myth of multimodal interaction <ref type="bibr" target="#b46">[47]</ref>). However, all participants used more than one input modality at least once while performing the study tasks. Interaction patterns varied for the same task across participants (e.g., P1 performed task T1 using a multimodal pattern of speech+touch whereas P2 performed the same task using a single speech query). Similarly, individual participants' patterns varied as they performed similar tasks multiple times too. For instance, P6 performed task T5 using a series of spoken, touch, and multimodal interactions but when performing a similar task T6, used only speech.</p><p>In general, speech was typically used for search, filtering, and topology-based tasks involving multiple nodes (e.g., finding path and common connections). Touch, on the other hand was typically used for tasks like highlighting connections of individual nodes and changing values of existing graphical encodings. However, preferences for modalities also varied across task types <ref type="figure" target="#fig_2">(Figure 3</ref>). For instance, for a find connections task, four participants (P1, P3, P4, P5) generally used a combination of speech (for find) and touch (for finding connections) whereas the remaining two participants used only spoken queries to see connections (P2, P6). For filtering, all participants used speech at least once (typically at the beginning). For the spoken queries, two participants (P1, P4) used longer queries with multiple filters (e.g., "Show Barcelona midfielders") whereas three participants (P2, P5, P6) used multiple single filter queries. One participant (P3) typically followed a spoken query with touch interactions for modifying filters. Preferences even varied for less-visualization specific tasks such as coloring and sizing. Four participants mostly used spoken queries to change node color/size whereas two (P3, P6) often used a combination of speech and touch for the same.</p><p>The use of multiple modalities (individually and together) to accomplish tasks and the variable nature of interaction patterns across participants highlights the need and potential value of multimodal interfaces that accommodate such varying user preferences.</p><p>Natural language interaction and interpretation. Participants commended Orko's natural language capabilities and felt it interpreted queries fairly well <ref type="figure">(Figure 7-right)</ref>. Multiple participants were initially skeptical about natural language input based on their previous experiences but were pleasantly surprised by the system's capabilities and the usefulness of speech input. For instance, P6, who reported that she frequently used applications like Siri and Notes stated "I was surprised by the speech feature. I did not expect it to work as well as it did". She also mentioned that speech not only worked well but actually improved her experience with visualization tools. She said "having worked with many visualization programs before, having to go through and manually clicking is really annoying epecially when you have a ton of dropdowns. So I really like the speech feature, I know it's still in a rudimentary stage but it does a really good job".</p><p>In terms of query interpretation, there were only seven instances where Orko either did not respond or responded incorrectly to a query. Some of these were queries included operations that were not yet supported (e.g., layout change) while others queries had multiple values that were not separated by conjunctions. For example, for the query "Show connections of Rooney McCarthy and Stones" P5 expected the system to find connections of three players. The system, however, only showed connections of two players (Rooney and Stones), but still listing McCarthy within the ambiguity tooltip widget <ref type="figure" target="#fig_5">(Figure 6b</ref>). In such cases, participants typically thought of an alternative way to perform operations via touch or broke the query further into more explicit ones.</p><p>Although speech recognition was viewed favorably by participants in general, it was not perfect. On average, 16% of queries were missed or incorrectly translated from speech-to-text. The percentage was higher for some participants (e.g., 30% for P3) due to variations in accent and speaking tone. Speech detection issues did cause some frustration among participants. For example, P3 stated "It was a little frustrating when the system did not understand my voice or did not react at all to voice". Ambiguity widgets did help for incorrectly detected player names, but only twice. Participants typically used the virtual keyboard to fix their utterances since it happened only occasionally. The more common case was the system failing to detect queries. In such cases, participants either repeated queries by tapping the icon ( <ref type="figure" target="#fig_0">Figure 1A</ref>) or used touch input to proceed with the task. For example, when the system did not detect a participant's (P4) find connections query, the participant simply double-tapped the node to see its connections.</p><p>These observations further motivate the need to study multimodal interaction for visualization systems. With a growing number of NLIs, such examples show how users can leverage alternative modalities to counterbalance issues such as speech detection in NLIs.</p><p>Contextual and follow-up queries Based on prior work that has shown a high preference for queries where touch (or pen) is followed by speech input <ref type="bibr" target="#b50">[51,</ref><ref type="bibr" target="#b68">69]</ref>, we hypothesized that such contextual queries <ref type="figure" target="#fig_1">(Figure 2a</ref>) would be a common pattern. However, this was not the case. Only two participants (P2, P6) uttered such contextual queries that referred to nodes highlighted via touch interaction. Both P2 and P6 used a contextual query when highlighting connections within a group of nodes. They applied a country filter through the dropdown and then said "Show the connections of these nodes" (P2) and "Highlight connections" (P6). However, we suspect the nature of the study tasks and prior experience of participants with visualization tools may have had an effect on the reduced usage of this pattern. Observing users (including novice users) perform more open-ended tasks and exploring the use of contextual queries in the context of other visualizations is certainly a direction for future work. Additionally, Orko currently only supports a limited number of touch gestures. Three participants (P1, P4, P5) also expressed a desire in having more expressive multitouch gestures to select and move groups of nodes. Exploring if the availability of additional multitouch gestures <ref type="bibr" target="#b58">[59]</ref> increases the use of contextual queries is another open question.</p><p>For follow-up utterances, queries involving continue operations <ref type="bibr" target="#b26">[27]</ref> were most common (e.g., adding new filters). Followup queries with references to new values (e.g., "Filter to show Real Madrid" &gt; "now Barcelona" &gt; "now strikers") were only used five times (thrice by P2 and twice by P5), all during a filtering operation. Instead, participants preferred to repeat entire queries (e.g., "Filter to show Real Madrid" &gt; "Filter to show Barcelona" &gt; "Filter by strikers") and often also repeated existing filters (e.g., "Filter to show strikers" &gt; "Show only strikers for England"). Given this behavior, the  <ref type="figure">Fig. 7</ref>. (Left) Summary of interactions per study task for each participant. S: Speech, T : Touch, ST : Sequential speech+touch, TS: Sequential touch+speech. (Right) Participant respones for specific SUS questions and Orko's query interpretation query manipulation widgets were not frequently used. Based on these observations, we believe future work could focus more on exploring elements like ambiguity widgets <ref type="bibr" target="#b20">[21]</ref> and ways to help users correct their queries and potentially less on how systems could help users ask follow-up questions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.3">Reaction to system feedback and proactive behavior</head><p>A recent analysis of NLI utterances to visualization systems <ref type="bibr" target="#b62">[63]</ref> highlights instruction and feedback as well as proactive system behavior as two areas for data visualization NLIs to explore. Along these lines, in Orko, we present both audio and textual feedback when responding to natural language queries. However, even after multiple modes of feedback, one participant (P2) repeated his query twice before he realized the query had already been executed. P2 also expressed that he would like the system to show the possible space of input queries and said "If the system used the keyboard, an auto-complete function would be very helpful". Such observations and feedback indicate that we need to explore more ways to surface feedback and potentially expose the input query space on post-WIMP interfaces. Orko exhibits proactive behavior with its suggestion of tasks for underspecified queries and by rearranging the summary charts based on user interactions and queries. The task suggestion feature was only triggered thrice (twice for P5 and once for P3). In both cases, the participants did not detect it and went on to change their query indicating that the feature needs improvement and more importantly, needs to be surfaced in a more detectable way. All participants used the summary charts at least once. Three participants did not realize the charts were changing order but the ones who did (P1, P2, P4) stated they liked the system behavior. P2 stated "I enjoyed how quickly the system filtered and changed the settings like color and size of the nodes and provided summary statistics like goals, age, market value". The reordered summary charts also helped trigger new questions in participants' minds. For instance, after applying a club filter, one participant (P1) scanned the summary charts to realize that there was an attribute for position and said "Oh yeah! There's position too" and asked the system to filter based on one of the position values. Based on the feedback and our observations, we feel that adding such proactive behavior to complement interactions within the main visualization was a useful design choice. As future work, similar system behavior should be explored to help facilitate an analytical conversation between users and multimodal (and NLIs) visualization systems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.4">Participants' feedback on multimodal interaction</head><p>Participants overall felt that the various features of the system were well integrated <ref type="figure">(Figure 7-right)</ref>. They generally found the multimodal interaction to be intuitive and stated they would want to use such a system frequently <ref type="figure">(Figure 7-right)</ref>. One participant (P3) wrote "It was fun to use and a very intuitive way to explore a network.". Other participants even stated that they felt direct manipulation and speech-based multimodal input should become a part of network visualization tools in general. For example, one participant (P4) who works with network visualizations almost on a daily basis wrote, "The ability to perform simple actions like "find node" and "find path between two nodes" was really fun to use, and I see this being highly used in general network visualization tools, especially for novice users". He further stated that he felt that the speech input worked particularly well for navigation and topology-based tasks. He suggested that the natural language modality for such tasks would be a great addition to keyboard and mouse based network visualization systems and it can speed up performance. He did state, however, that he still wanted to use direct manipulation for tasks like selecting specific values for graphical encodings or tuning parameters for analytical operations, emphasizing that he wanted both modalities.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">FUTURE WORK</head><p>Facilitating network presentation tasks. One particularly interesting category of tasks that emerged from our experiment were network presentation tasks. Three of the participants mentioned that they found the ability of being able to spatially drag and pin nodes useful. As stated earlier, some of these participants even wanted to drag and pin entire groups. During the session, one participant (P5) even asked "Can I ask it to modify the layout to something other than force-directed?". Such observations indicate potential value in exploring ways in which we can help people accomplish network presentation related tasks such as layout modification, bundling or untangling edges, and minimizing edge crossings. Particularly with natural language, one can even envision layouts being set automatically by the system in response to user queries. Another possible extension of this idea is the system suggesting alternative representations (e.g., a matrix instead of a node-link diagram) that can be most effective in answering a given question.</p><p>Exploring additional classes of networks. As part of our current work, we have primarily used Orko to explore multivariate, undirected networks. While interactions supported by Orko are rather generic and can be used in other network types such as directed and multipartite networks, we need to explore other types of networks further to identify and support network-specific tasks that people may want to perform. For instance, for a temporal network, in addition to considering what questions people want to answer and how they ask those questions, considering how multimodal interaction can be leveraged for tasks such as navigating through temporal variations in the network structure is another direction for future research.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">CONCLUSION</head><p>We introduced Orko, a network visualization tool facilitating multimodal interaction via natural language and direct manipulation (e.g., touch) input. To explain the difficulty of providing such an interface, we highlighted challenges associated with interpreting natural language in such a multimodal setting. We presented Orko's architecture describing how it processes multiple input modalities and facilitates multimodal interaction. Through an example scenario of use and descriptions of Orko's capabilities, we sought to illustrate its innovative approach and potential for a new style of network exploration and data analysis. We reported results from an evaluation study of Orko and used our observations to discuss opportunities and challenges for future work in multimodal network visualization interfaces.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Orko's user interface being used to explore a network of European soccer players. Cristiano Ronaldo, Gareth Bale, and their connections are highlighted. Connected nodes with lower opacity do not meet all the filtering criteria. Interface components: (A) Natural language input and action feedback row (B) Network canvas (C) Quick access icons (D) Details container (E) Summary container (F) Filters and visual encodings row.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>An illustration of the variety of potential natural language utterances.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .</head><label>3</label><figDesc>Currently supported operations with sample queries. The label attributes refer to the attributes defining the nodes.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Top 5 Fig. 4 .</head><label>54</label><figDesc>goal scorers are highlighted as the goals slider is adjusted. (a) Connections of top 5 goal scorers (indicated using a red stroke) are highlighted. Common connections are emphasized using a yellow stroke. (b) Path between Ronaldo to Podolski is highlighted. Connection between Podolski and Kroos is displayed. (c) Player nodes are re-sized by age. Summary panel is re-organized to facilitate expedited exploration. (d) Scenes from the Orko usage scenario. Sub-figure captions summarize system states.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 5 .</head><label>5</label><figDesc>Orko system architecture.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 6 .</head><label>6</label><figDesc>Query manipulation and ambiguity widgets. (a) Dropdown menu to change player name in a query. (b) Tooltip showing values matched to an ambiguous word "Wayne". (c) Tooltip suggesting tasks guessed by the system for an underspecified query.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>Manuscript received 31 Mar. 2017; accepted 1 Aug. 2017. Date of publication 28 Aug. 2017; date of current version 1 Oct. 2017. For information on obtaining reprints of this article, please send e-mail to: reprints@ieee.org, and reference the Digital Object Identifier below. Digital Object Identifier no. 10.1109/TVCG.2017.2745219</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Follow-up &amp; Contextual AreHigh-level HowShow nodes connected to Ronaldo.</head><label></label><figDesc>Explicit Find Ronaldo. -Show Pepe's connections. -Show connections between Pogba and Bale. -Show the shortest path from Evra to Kroos. -Color by position. -Size nodes by betweenness centrality. -What is the clustering coefficient of this network. -Only show German forwards. -Clear all filters. -Resize graph to fit the screen. -Add a filter widget for country. -Change value of the age slider to show players over the age of 30. -Change red nodes to blue. any of these players right footed. -Filter by this player's club. -Show connections of these players. -Do any of these players play for the same club and national team. -Show the different countries players come from. -Ronaldo and Rooney. -Color nodes by country &gt; Now club &gt; How about position? are France and Italy connected. -Players from which countries tend to play more with clubs in the same country. -Which clubs have more left footed players. -Which countries have highest number of common players. -Modify the network layout to focus on England players. -Which three nodes have highest betweenness centralities. -Modify layout to show least edge crossings. -Find clusters.</figDesc><table><row><cell></cell><cell>Show Ronaldo's connections.</cell></row><row><cell></cell><cell>Find players linked to Ronaldo.</cell></row><row><cell></cell><cell>Highlight players who play with Ronaldo.</cell></row><row><cell></cell><cell>Which players play in the same team as Ronaldo.</cell></row><row><cell></cell><cell>Show nodes directly connected to Ronaldo.</cell></row><row><cell></cell><cell>Find nodes adjacent to Ronaldo.</cell></row><row><cell></cell><cell>Show Ronaldo's teammates.</cell></row><row><cell></cell><cell>Who all is Ronaldo directly connected to.</cell></row><row><cell></cell><cell>Find players with a direct link to Ronaldo.</cell></row><row><cell></cell><cell>Find direct connections of Ronaldo.</cell></row><row><cell>(a) Possible query types</cell><cell>(b) Different ways of asking the same query</cell></row></table><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS</head><p>We thank the anonymous reviewers for the detailed and helpful feedback on the article. This work was supported in part by the National Science Foundation.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">DBXplorer: A system for keyword-based search over relational databases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Agrawal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chaudhuri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Das</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 18th International Conference on Data Engineering</title>
		<meeting>the 18th International Conference on Data Engineering</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2002" />
			<biblScope unit="page" from="5" to="16" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Low-level components of analytic activity in information visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Amar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Eagan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Stasko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2005 IEEE Symposium on Information Visualization</title>
		<meeting>the 2005 IEEE Symposium on Information Visualization</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2005-10" />
			<biblScope unit="page" from="111" to="117" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amazon</forename><surname>Alexa</surname></persName>
		</author>
		<ptr target="https://en.wikipedia.org/wiki/Amazon_Alexa" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Natural language interfaces to databases-an introduction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Androutsopoulos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">D</forename><surname>Ritchie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Thanisch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Natural language engineering</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">01</biblScope>
			<biblScope unit="page" from="29" to="81" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">TopoLayout: Multilevel Graph Layout by Topological Features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Archambault</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Munzner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Auber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="305" to="317" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Show me data&quot;: Observational study of a conversational interface in visual data exploration (poster paper)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Aurisano</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gonzales</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Reda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Leigh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">Di</forename><surname>Eugenio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Johnson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE VIS &apos;15</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Gephi: an open source software for exploring and manipulating networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bastian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Heymann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Jacomy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Third International Conference on Weblogs and Social Media, ICWSM</title>
		<meeting>the Third International Conference on Weblogs and Social Media, ICWSM</meeting>
		<imprint>
			<date type="published" when="2009-05" />
			<biblScope unit="page" from="361" to="362" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">TouchWave: kinetic multi-touch manipulation for hierarchical stacked graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Baur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Carpendale</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2012 ACM International Conference on Interactive Tabletops and Surfaces (ITS)</title>
		<meeting>the 2012 ACM International Conference on Interactive Tabletops and Surfaces (ITS)</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2012-11" />
			<biblScope unit="page" from="255" to="264" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">put-that-there&apos;: Voice and gesture at the graphics interface</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">A</forename><surname>Bolt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 7th Annual Conference on Computer Graphics and Interactive Techniques, SIGGRAPH &apos;80</title>
		<meeting>the 7th Annual Conference on Computer Graphics and Interactive Techniques, SIGGRAPH &apos;80</meeting>
		<imprint>
			<date type="published" when="1980" />
			<biblScope unit="page" from="262" to="270" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">D 3 data-driven documents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bostock</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Ogievetsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Heer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2301" to="2309" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">A multi-level typology of abstract visualization tasks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Brehmer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Munzner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2376" to="2385" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">SUS-A quick and dirty usability scale. Usability evaluation in industry</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Brooke</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1996" />
			<biblScope unit="volume">189</biblScope>
			<biblScope unit="page" from="4" to="7" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Artificial Intelligence Markup Language (AIML) Version 1.0. 1. ALICE AI Foundation Working Draft</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Bush</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Wallace</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Ringate</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Taylor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Baer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Quickset: Multimodal interaction for simulation set-up and control</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">R</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Johnston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Mcgee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Oviatt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pittman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Clow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the fifth conference on Applied natural language processing</title>
		<meeting>the fifth conference on Applied natural language processing</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="1997" />
			<biblScope unit="page" from="20" to="24" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Cordeil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Dwyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Laha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Marriot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">H</forename><surname>Thomas</surname></persName>
		</author>
		<title level="m">Immersive Collaborative Analysis of Network Connectivity: CAVE-style or Head-Mounted Display? IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="441" to="450" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A multi-modal natural language interface to an information visualization environment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Cox</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">E</forename><surname>Grinter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">L</forename><surname>Hibino</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">J</forename><surname>Jagadeesan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Mantilla</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Speech Technology</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">3-4</biblScope>
			<biblScope unit="page" from="297" to="314" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Context-free grammar forms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Cremers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ginsburg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Computer and System Sciences</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="86" to="117" />
			<date type="published" when="1975" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">TouchViz: a case study comparing two interfaces for data analytics on tablets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M</forename><surname>Drucker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Fisher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Sadana</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Herron</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the SIGCHI Conference on Human Factors in Computing Systems</title>
		<meeting>the SIGCHI Conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2013-05" />
			<biblScope unit="page" from="2301" to="2310" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Network visualization as a higher-order visual analysis tool</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Dwyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer Graphics and Applications</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="78" to="85" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Investigating multi-touch and pen gestures for diagram editing on interactive surfaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Frisch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Heydekorn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Dachselt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM International Conference on Interactive Tabletops and Surfaces</title>
		<meeting>the ACM International Conference on Interactive Tabletops and Surfaces</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2009-11" />
			<biblScope unit="page" from="149" to="156" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">DataTone: Managing Ambiguity in Natural Language Interfaces for Data Visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Dontcheva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Adar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">G</forename><surname>Karahalios</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th Annual ACM Symposium on User Interface Software &amp; Technology</title>
		<meeting>the 28th Annual ACM Symposium on User Interface Software &amp; Technology</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015-10" />
			<biblScope unit="page" from="489" to="500" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Google</forename><surname>Assistant</surname></persName>
		</author>
		<ptr target="https://en.wikipedia.org/wiki/Google_Assistant" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Two case studies of software architecture for multimodal interactive systems: Voicepaint and a voice-enabled graphical notebook</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">P</forename><surname>Gourdol</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Nigay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Salber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Coutaz</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1992" />
			<biblScope unit="volume">92</biblScope>
			<biblScope unit="page" from="271" to="84" />
		</imprint>
		<respStmt>
			<orgName>Engineering for Human-Computer Interaction</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">How information visualization novices construct visualizations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Grammel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Tory</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-A</forename><surname>Storey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="943" to="952" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Focusing and description in natural language dialogues</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">J</forename><surname>Grosz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">DTIC Document</title>
		<imprint>
			<date type="published" when="1979" />
		</imprint>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Attention, intentions, and the structure of discourse</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">J</forename><surname>Grosz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">L</forename><surname>Sidner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational linguistics</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="175" to="204" />
			<date type="published" when="1986" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Centering: A framework for modeling the local coherence of discourse</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">J</forename><surname>Grosz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Weinstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">K</forename><surname>Joshi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational linguistics</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="203" to="225" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Speech and gestures for graphic image manipulation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">G</forename><surname>Hauptmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI &apos;89)</title>
		<meeting>the SIGCHI Conference on Human Factors in Computing Systems (CHI &apos;89)</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="1989-03" />
			<biblScope unit="page" from="241" to="245" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Input technologies and techniques</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Hinckley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Wigdor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Human-Computer Interaction Handbook: Fundamentals, Evolving Technologies and Emerging Applications</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2002" />
			<biblScope unit="page" from="151" to="168" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Discover: Keyword search in relational databases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Hristidis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Papakonstantinou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th international conference on Very Large Data Bases</title>
		<meeting>the 28th international conference on Very Large Data Bases</meeting>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="670" to="681" />
		</imprint>
		<respStmt>
			<orgName>VLDB Endowment</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Towards a dialogue system that supports rich visualizations of data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Aurisano</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">Di</forename><surname>Eugenio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gonzalez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Leigh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">17th Annual Meeting of the Special Interest Group on Discourse and Dialogue</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page">304</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Beyond mouse and keyboard: Expanding design considerations for information visualization interactions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Isenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">H</forename><surname>Riche</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Carpendale</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2689" to="2698" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Task taxonomy for graph visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Plaisant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">S</forename><surname>Parr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-D</forename><surname>Fekete</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Henry</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the &apos;06 BELIV Workshop</title>
		<meeting>the &apos;06 BELIV Workshop</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2006-05" />
			<biblScope unit="page" from="1" to="5" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">The factor structure of the system usability scale</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">R</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sauro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Human Centered Design</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="94" to="103" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Constructing an interactive natural language interface for relational databases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Jagadish</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the VLDB Endowment</title>
		<meeting>the VLDB Endowment</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="73" to="84" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Nltk: The natural language toolkit</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Loper</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bird</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACL-02 Workshop on Effective tools and methodologies for teaching natural language processing and computational linguistics</title>
		<meeting>the ACL-02 Workshop on Effective tools and methodologies for teaching natural language processing and computational linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2002" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="63" to="70" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Cytoscape web: an interactive web-based network browser</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">T</forename><surname>Lopes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Franz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Kazi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">L</forename><surname>Donaldson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Morris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">D</forename><surname>Bader</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">18</biblScope>
			<biblScope unit="page" from="2347" to="2348" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">PowerAqua: Supporting users in querying and exploring the semantic web</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Lopez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Fernández</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Motta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Stieler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Semantic Web</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="249" to="265" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Network design and transportation planning: Models and algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">L</forename><surname>Magnanti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">T</forename><surname>Wong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transportation Science</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="55" />
			<date type="published" when="1984" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">The Stanford CoreNLP Natural Language Processing Toolkit</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Surdeanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">R</forename><surname>Finkel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bethard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Mcclosky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL (System Demonstrations)</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="55" to="60" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Graph theory and networks in biology</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Mason</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Verwoerd</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IET Systems Biology</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="89" to="119" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">WordNet: a lexical database for English</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">A</forename><surname>Miller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="39" to="41" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">The structure of a social science collaboration network: Disciplinary cohesion from 1963 to 1999</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Moody</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">American Sociological Review</title>
		<imprint>
			<biblScope unit="volume">69</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="213" to="238" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">maeve-an interactive tabletop installation for exploring background information in exhibitions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Nagel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Pschetz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Stefaner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Halkia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Müller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Human-Computer Interaction</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="483" to="491" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Understanding multi-touch manipulation for surface computing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>North</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Dwyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Fisher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Isenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Robertson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Inkpen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IFIP Conference on Human-Computer Interaction</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="236" to="249" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Multimodal interactive maps: Designing for human performance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Oviatt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Human-Computer Interaction</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="93" to="129" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Ten myths of multimodal interaction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Oviatt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="74" to="81" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title level="m" type="main">Multimodal interfaces. The human-computer interaction handbook: Fundamentals, evolving technologies and emerging applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Oviatt</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="286" to="304" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Perceptual user interfaces: multimodal interfaces that process what comes naturally</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Oviatt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Cohen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="45" to="53" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Toward a theory of organized multimodal integration patterns during human-computer interaction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Oviatt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Coulston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Tomko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Lunsford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Wesson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Carmichael</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 5th international conference on Multimodal interfaces</title>
		<meeting>the 5th international conference on Multimodal interfaces</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2003" />
			<biblScope unit="page" from="44" to="51" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Integration and synchronization of input modes during multimodal human-computer interaction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Oviatt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Deangeli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kuhn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Referring Phenomena in a Multimedia Context and their Computational Treatment</title>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="1997" />
			<biblScope unit="page" from="1" to="13" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">An empirical study: Adding voice input to a graphical editor</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Pausch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">H</forename><surname>Leatherby</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Journal of the American Voice Input/Output Society. Citeseer</title>
		<imprint>
			<date type="published" when="1991" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Tasks for multivariate network analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">J</forename><surname>Pretorius</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">C</forename><surname>Purchase</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">T</forename><surname>Stasko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Multivariate Network Visualization</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="77" to="95" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Kinetica: naturalistic multi-touch data visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Rzeszotarski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kittur</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 32nd annual ACM Conference on Human Factors in Computing Systems</title>
		<meeting>the 32nd annual ACM Conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="897" to="906" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Designing and implementing an interactive scatterplot visualization for a tablet computer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Sadana</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Stasko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 International Working Conference on Advanced Visual Interfaces</title>
		<meeting>the 2014 International Working Conference on Advanced Visual Interfaces</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="265" to="272" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Designing multiple coordinated visualizations for tablets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Sadana</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Stasko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics Forum</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="261" to="270" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Saket</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Simonetto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kobourov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1403.7421</idno>
		<title level="m">Group-level graph visualization taxonomy</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Correlations among prototypical usability metrics: evidence for the construct of usability</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sauro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">R</forename><surname>Lewis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the SIGCHI Conference on Human Factors in Computing Systems</title>
		<meeting>the SIGCHI Conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="1609" to="1618" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">A set of multi-touch graph interaction techniques</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Schmidt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Nacenta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Dachselt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Carpendale</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM International Conference on Interactive Tabletops and Surfaces</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="113" to="116" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Eviza: A natural language interface for visual analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Setlur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">E</forename><surname>Battersby</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Tory</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Gossweiler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">X</forename><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 29th Annual Symposium on User Interface Software and Technology</title>
		<meeting>the 29th Annual Symposium on User Interface Software and Technology</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="365" to="377" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Fat finger worries: how older and younger users physically interact with pdas</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">A</forename><surname>Siek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Rogers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">H</forename><surname>Connelly</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IFIP Conference on Human-Computer Interaction</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2005" />
			<biblScope unit="page" from="267" to="280" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<monogr>
		<title level="m" type="main">Précis: from unstructured keywords as queries to structured databases as answers. The International Journal on Very Large Data Bases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Simitsis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Koutrika</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ioannidis</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="117" to="149" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Natural language interfaces for data analysis with visualization: Considering what has and could be asked</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Srinivasan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Stasko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EuroVis &apos;17</title>
		<meeting>EuroVis &apos;17</meeting>
		<imprint>
			<date type="published" when="2017-06" />
			<biblScope unit="page" from="55" to="59" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Articulate: A semi-automated model for translating natural language queries into meaningful visualizations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Leigh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Symposium on Smart Graphics</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="184" to="195" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Post-WIMP user interfaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Van Dam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="63" to="67" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Search, show context, expand on demand: Supporting large graph exploration with degree-of-interest</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Van Ham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Perer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="953" to="960" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Building an application framework for speech and pen input integration in multimodal learning interfaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">T</forename><surname>Vo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wood</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 1996 IEEE International Conference on Acoustics, Speech, and Signal Processing</title>
		<meeting>1996 IEEE International Conference on Acoustics, Speech, and Signal Processing</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="1996" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="3545" to="3548" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Making color adjustment accessible to non-experts through the use of language</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Woolfe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Color and Imaging Conference</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="3" to="7" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Multimodal integration-a statistical view</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">L</forename><surname>Oviatt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">R</forename><surname>Cohen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Multimedia</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="334" to="341" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Verbs semantics and lexical selection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Palmer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 32nd annual meeting on Association for Computational Linguistics</title>
		<meeting>the 32nd annual meeting on Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="1994" />
			<biblScope unit="page" from="133" to="138" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
