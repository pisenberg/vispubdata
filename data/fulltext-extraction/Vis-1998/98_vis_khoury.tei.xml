<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/pisenberg/grobid/grobid-0.6.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Volumetric Modeling of Acoustic Fields in CNMAT&apos;s Sound Spatialization Theatre</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sami</forename><surname>Khoury</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Center for New Music and Audio Technologies (CNMAT) † † CNMAT</orgName>
								<address>
									<addrLine>1750 Arch Street</addrLine>
									<postCode>94709</postCode>
									<settlement>Berkeley</settlement>
									<region>CA</region>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adrian</forename><surname>Freed</surname></persName>
							<email>adrian@cnmat.berkeley.edu</email>
							<affiliation key="aff0">
								<orgName type="laboratory">Center for New Music and Audio Technologies (CNMAT) † † CNMAT</orgName>
								<address>
									<addrLine>1750 Arch Street</addrLine>
									<postCode>94709</postCode>
									<settlement>Berkeley</settlement>
									<region>CA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Wessel</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Center for New Music and Audio Technologies (CNMAT) † † CNMAT</orgName>
								<address>
									<addrLine>1750 Arch Street</addrLine>
									<postCode>94709</postCode>
									<settlement>Berkeley</settlement>
									<region>CA</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Volumetric Modeling of Acoustic Fields in CNMAT&apos;s Sound Spatialization Theatre</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2021-02-19T20:38+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>J.5 Arts and Humanities: Performing Arts Acoustic Modeling, Real-time Visualization</keywords>
			</textClass>
			<abstract>
				<p>A new tool for real-time visualization of acoustic sound fields has been developed for a new sound spatialization theatre. The theatre is described and several applications of the acoustic and volumetric modeling software are presented.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">SOUND SPATIALIZATION THEATRE</head><p>The Center for New Music and Audio Technologies, CNMAT, i s an interdisciplinary research center at the University of California at Berkeley. Our sound spatialization theatre is built into the main performance and lecture space at CNMAT's facility. A unique feature of the theatre is a flexible suspension system built primarily for loudspeakers. Each speaker hangs from a rotating beam. The pivot point for each speaker runs i n a track that slides along rails bolted to the ceiling. With height adjustment of each suspension cable, this system safely allows speakers to be moved anywhere in the room and oriented along two of the three possible axes. Rotational symmetry of the concentric drivers in Meyer HM-1 speakers obviates the need for adjustments around the third or "roll" axis. Real-time, lowlatency audio signal processing for the speaker array i s performed on a multiprocessor Silicon Graphics Octane workstation. This machine was chosen because of its built-in multi-channel audio, reliable real-time performance, and the availability of sound synthesis and processing software <ref type="bibr" target="#b0">[1]</ref><ref type="bibr" target="#b1">[2]</ref><ref type="bibr" target="#b2">[3]</ref>.</p><p>Most current applications of spatial audio are based on a model where source material is spatially encoded for an ideal room with a predetermined speaker geometry <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b4">5]</ref>. The result i s often unsatisfactory because of the difficulty in adapting real rooms to the ideal. We are working on a more general model where the source material may be from instruments and performers in the room, and therefore real-time spatial processing is required for all sources.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">THE PROBLEM</head><p>Optimizing the speaker array positioning and sound processing for each performance in the theatre is challenging. The traditional empirical approach is far too time-consuming to support situations in which there are weekly (and sometimes daily) performances with varied configurations. The problem with the trial and error approach is the difficulty of evaluating the effects of new speaker positions and software parameter changes for all listening positions. It is easy to optimize the listening experience for the lucky person in the "sweet spot" at the expense of the rest of the audience. The challenge is to find a compromise where as many listeners as possible experience the intent of the sound designer and as few listeners as possible endure disastrous seats.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">A Solution</head><p>To aid sound designers and composers in achieving a good compromise for the diverse applications of the theatre, we have developed software for visualizing source signals, a model of the acoustic sound field in the room, and interpretations of the field according to perceptual models. Important examples of prior work in this area include <ref type="bibr" target="#b5">[6]</ref> and <ref type="bibr" target="#b6">[7]</ref>. Unique features of the work described here include the emphasis on interactive, realtime visualization, the use of a highly configurable performance space, and the focus on adapting the processing and space to achieve diverse artistic goals.</p><p>The visualization software is part of a complete system managing audio, gestural flow and visual display. The heart of the system is a database describing the room. It contains information on geometric features such as the shape of the room, positioning and orientation of sources, microphones and audience seating, live performer location and their musical instrument's location. Acoustic properties of each object in the room include: frequency dependent radiation patterns and the location of their acoustic "centers". This database is used by the spatial sound processing software to process source signals to create an audience percept of virtual sources from arbitrary regions in space. The desired percept may also involve creating the illusion that listeners are in a room of a different size than the actual theatre <ref type="bibr" target="#b7">[8]</ref>. The location of these sources is controlled in real-time through gestures <ref type="bibr" target="#b8">[9]</ref> or arbitrary control messages arriving from the network <ref type="bibr" target="#b9">[10]</ref>.</p><p>The visualization software has access to the room database and real-time parameter estimates from the spatialization software.</p><p>Since it has no access to the real sound pressure levels in the room it must estimate these based on an acoustic model of the room. The image source method was used <ref type="bibr" target="#b10">[11]</ref> because of its amenability to real-time computation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">APPLICATION EXAMPLES 3.1 Pressure Levels</head><p>Volumetric visualization of the time varying sound pressure level in CNMAT's sound spatialization theatre is illustrated i n <ref type="figure">Figure 1</ref>. The sound sources in this case are organ pipes. Pressure is shown using a color map on horizontal cut planes through the space. These movable planes are typically set t o the average positions of audience's and performer's ears. Multiple simultaneous cut surfaces may be necessary, for example, for balcony seating in large theatres.</p><p>It is interesting to contrast this volumetric visualization with traditional audio metering where scalar signal levels are displayed for various nodes in the signal processing chain. Such metering is useful for managing signal levels in the electrical elements of the audio system to avoid distortion and speaker overload. However it is hard even for experienced sound engineers to use scalar metering to predict actual sound pressure levels in many locations in a venue.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Summing Localization</head><p>The summing localization model <ref type="bibr" target="#b11">[12]</ref>, known in its general form as vector panning <ref type="bibr" target="#b12">[13]</ref> is a commonly adopted strategy for sound localization with speaker arrays. With this technique a virtual source can be placed between a pair (or triple in the 3-D case) of speakers by dosing the level of the source signal appropriately to each pair or triple <ref type="bibr" target="#b13">[14]</ref>. A vector field display is useful to indicate perceived direction of a virtual sound source:</p><p>Our initial experience with this method was good. Speakers were placed at equal distances from the center of the room and panning worked smoothly around the room. When the speakers were moved to more practicable locations, above the audience and closer to the walls and corners of the room, vector panning failed to provide good virtual source imaging. This may be explained by the precedence effect <ref type="bibr" target="#b11">[12]</ref> that may work against summation localization. As the difference in the time of arrival of wavefronts from the two speakers approaches one millisecond, the source of the earliest wavefront is perceived as the actual source, regardless of the amplitude dosing performed by vector-panning. By visualization of an isosurface along which wavefront time difference is a constant we can illustrate the geometric implications of this perceptual phenomenon <ref type="figure">(Figure 3</ref>). This isosurface representation is also used to view other important time delay effects in spatial hearing such as the varied values of the echo threshold, backward masking, and multiple event thresholds <ref type="bibr" target="#b11">[12]</ref>. We are experimenting with techniques to minimize the effects of the precedence effect including, source decorrelation <ref type="bibr" target="#b14">[15]</ref>, and the introduction of appropriate delays into the feeds of the speakers in the room s o that they all have the same effective distance from a chosen "center" of the listening space.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Interference</head><p>Acoustic models have to take phase from coherent sources of sound into account. <ref type="figure">Figure 3</ref> shows the sound pressure level of a sine tone at a particular frequency in the room. At low frequencies destructive and constructive interference create markedly different sound levels around the room.</p><p>When a loudspeaker is placed close to a hard wall, reflected waves interfere with the direct source, distorting the frequency and phase response of the loudspeaker. These effects are modeled by introducing the reflections as further sources, as illustrated by the smaller speakers outside the room in <ref type="figure">Figure 4</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">IMPLEMENTATION 4.1 Visualization and User Interaction</head><p>The high level programming tool that binds the spatial visualization system together is Tcl/Tk <ref type="bibr" target="#b15">[16]</ref>, a scripting language and graphical user interface toolkit.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">. 1 . 1 Data Visualization</head><p>The Visualization Toolkit (VTK) <ref type="bibr" target="#b16">[17]</ref>, a C++ class library for visualizing data, provides a set of bindings to the Tcl language that allow access to all the classes in the system. Through this scriptable interface, it is possible to create visualizations which change interactively and dynamically in response to user input data. A VTK data object is maintained internally for each sample region in the listening space. This data object i s synchronized with the sample points in the region.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">. 1 . 2 User Interaction</head><p>Interactive tasks such as moving and orientating sound sources take advantage of user-interface event bindings in Tk. Realtime operation based on monitoring signals being supplied t o the sound sources is achieved by a Tcl thread that repeatedly requests current energy estimates, computes the acoustic model and visualization of that model, and renders the scene.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Geometric Acoustic Modeling</head><p>Three kinds of objects are modeled: active sound sources for loudspeakers and musical instruments, passive reflective objects for walls and diffusers, and finally listening points.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">. 2 . 1 Listening space</head><p>Listening space geometry is represented using a set of polygonal faces corresponding to walls, ceilings, floor etc. Each face is decorated with information describing its sound properties, such as frequency dependent reflection coefficients. Small room models can be easily described numerically. More complicated models may be imported from a specialized 3D modeling package. Maya <ref type="bibr" target="#b17">[18]</ref> is interesting in this respect because it supports storage of arbitrary data (i.e. acoustic) i n nodes of its scene graph.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">. 2 . 2 Listening points</head><p>Listening points are represented as two-dimensionally sampled bounded surfaces in three-dimensional space. This representation allows for fine sampling at important locations without the computational load that would be required for complete volumetric models. Common surfaces used include cut planes corresponding to ear level of seated listeners and performers; and meshes of planes for tiered seating.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">. 2 . 3 Sound Sources</head><p>Sources are represented using as polygonal models. Each model is decorated with information describing its acoustic properties such as its acoustic center location and frequency-dependent directivity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Image Source Modeling</head><p>In this acoustic modeling technique, information is computed for each listening point in turn. Conceptually, lines are projected from the listening point to the acoustic center of each source and to the acoustic center of reflections of each source from the passive reflecting objects in the space. The lengths of these lines are used to estimate energy reaching the listening point. The solid angles of each line are used to compute the effect of source directivity, and energy loss as a function of frequency and angle of incidence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Model Computation</head><p>Once the geometric implications of the relative positions of sources, listening points, and reflecting objects are calculated, the actual acoustic modeling calculation can be performed. The simplest computation uses sine wave probe tones directly calculating and summing vectors for the phase and amplitude of wave fronts arriving at each listening point. For real-time modeling an optimization is required. We use energy estimates of adjacent frequency bands averaged at the visual display rate, to avoid the expense of a sequence of convolutions at the full audio sample rate. This method allows for plausible approximations of energy, although pathological locations where cancellations may occur would not be accurately displayed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">CONCLUSION AND FUTURE WORK</head><p>The visualization system described here is a valuable tool for spatial sound researchers. sound engineers and composers using CNMAT's sound spatialization theatre. Further work is i n progress on the adaptation of better acoustic simulation methods <ref type="bibr" target="#b6">[7]</ref> for more accurate display of the quality of the reverberant field. The room database will be automatically extracted from a model built with 3D modeling software <ref type="bibr" target="#b17">[18]</ref>. Volume visualization strategies are being explored to display sounds in spectral and impulse response form.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">S P O N S O R S</head><p>We gratefully acknowledge support from : </p><formula xml:id="formula_0">• Alias/</formula></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>Tom Johnson, Tibor Knowles and Matt Wright developed the speaker mounting and audio patching system for the theatre. René Caussé, Jean-Marc Jot and John Meyer provided essential insights and data on room and loudspeaker acoustics. Amar Chaudhary provided VTK expertise and developed the organ pipe geometric models.</figDesc><table><row><cell></cell><cell>Wavefront</cell></row><row><cell>•</cell><cell>Edmond Campion</cell></row><row><cell>•</cell><cell>Edmund O'Neill foundation</cell></row><row><cell>•</cell><cell>Gibson Guitar</cell></row><row><cell>•</cell><cell>LCS</cell></row><row><cell>•</cell><cell>Meyer Sound</cell></row><row><cell>•</cell><cell>Silicon Graphics</cell></row><row><cell cols="2">7 ACKNOWLEDGEMENT</cell></row><row><cell cols="2">Richard Andrews,</cell></row></table><note></note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Codevelopment of user interface, control and digital signal processing with the HTM environment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Freed</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">5th International Conference on Signal Processing Applications and Technology</title>
		<meeting><address><addrLine>Dallas, TX, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1994" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Synthesis and control of hundreds of sinusoidal partials on a desktop computer without custom hardware</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Freed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Rodet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Depalle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Fourth International Conference on Signal Processing Applications and Technology ICSPAT &apos;93</title>
		<meeting><address><addrLine>Santa Clara, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Real-Time Inverse Transform Additive Synthesis for Additive and Pitch Synchronous Noise and Sound Spatialization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Freed</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998" />
			<pubPlace>San Francisco, CA</pubPlace>
		</imprint>
	</monogr>
	<note>presented at AES 104th Convention</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">High quality audio coding for HDTV: an overview of AC-3</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bosi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">E</forename><surname>Forshay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">presented at International Workshop on HDTV &apos;94</title>
		<meeting><address><addrLine>Turin, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1994" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Microsoft&apos;s DirectSound</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Feibus</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1996" />
			<biblScope unit="page">203</biblScope>
		</imprint>
	</monogr>
	<note>Windows Sources</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Computer graphics visualization for acoustic simulation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Stettner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Greenberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">presented at Conference Proceedings</title>
		<meeting><address><addrLine>Boston, MA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1989" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Acoustic Simulation and Visualization using a New Unified Beam Tracing and Image Source Approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Monks</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">M</forename><surname>Oh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dorsey</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1996" />
		</imprint>
	</monogr>
	<note>presented at Convention of the Audio Engineering Society</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Virtual auditory environment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lehnert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Blauert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Fifth International Conference on Advanced Robotics. Robots in Unstructured Environments (Cat. No.91TH0376-4)</title>
		<meeting><address><addrLine>Pisa, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1991" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A survey of 3D interaction techniques</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Hand</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics Forum</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="269" to="81" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Open Sound Control: A New Protocol for Communicating with Sound Synthesizers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Wright</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Freed</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">at International Computer Music Conference</title>
		<meeting><address><addrLine>Thessaloniki, Greece</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">An efficient algorithm for the image model technique</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Heewon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Byung-Ho</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Applied Acoustics</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="87" to="115" />
			<date type="published" when="1988" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Spatial hearing : the psychophysics of human sound localization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Blauert</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1997" />
			<publisher>MIT Press</publisher>
			<pubPlace>Cambridge</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Virtual sound source positioning using vector base amplitude panning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Pulkki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Audio Engineering Society</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="page" from="456" to="66" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">The simulation of moving sound sources</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Chowning</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1970" />
			<pubPlace>New York, NY, USA</pubPlace>
		</imprint>
	</monogr>
	<note>presented at Audio Engineering Society 39th Convention</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">The decorrelation of audio signals and its impact on spatial imagery</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">S</forename><surname>Kendall</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Music Journal</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="71" to="87" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Tcl and the Tk toolkit</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">K</forename><surname>Ousterhout</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1994" />
			<publisher>Addison-Wesley</publisher>
			<pubPlace>Reading, Mass</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">The design and implementation of an object-oriented toolkit for 3D graphics and visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">J</forename><surname>Schroeder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">M</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">E</forename><surname>Lorensen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">/</forename><surname>Alias</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Wavefront</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998" />
			<publisher>Alias/WaveFront</publisher>
			<pubPlace>Toronto, Canada</pubPlace>
		</imprint>
	</monogr>
	<note>Maya 1.0,&quot;.</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
