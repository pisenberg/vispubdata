<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/pisenberg/grobid/grobid-0.6.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Real-Time Techniques For 3D Flow Visualization</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anton</forename><surname>Fuhrmann</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduard</forename><surname>Gröller</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">Vienna University of Technology</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">Institute of Computer Graphics</orgName>
								<orgName type="institution">Vienna University of Technology</orgName>
								<address>
									<addrLine>Karlsplatz 13/186</addrLine>
									<postCode>A-1040</postCode>
									<settlement>Vienna</settlement>
									<country key="AT">Austria</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Real-Time Techniques For 3D Flow Visualization</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2021-02-19T20:37+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>I.3.3 [Computer Graphics]: Picture/Image Generation -Viewing Algorithms; I.3.6 [Computer Graphics]: Methodology and Techniques -Interaction Techniques virtual environments</term>
					<term>flow visualization</term>
					<term>texturing</term>
					<term>interaction</term>
					<term>magic lens</term>
					<term>focussing</term>
				</keywords>
			</textClass>
			<abstract>
				<p>Visualization of three-dimensional steady flow has to overcome a lot of problems to be effective. Among them are occlusion of distant details, lack of directional and depth hints and occlusion. In this paper we present methods which address these problems for real-time graphic representations applicable in virtual environments. We use dashtubes, i.e., animated, opacity-mapped streamlines, as visualization icon for 3D-flow visualization. We present a texture mapping technique to keep the level of texture detail along a streamline nearly constant even when the velocity of the flow varies considerably. An algorithm is described which distributes the dashtubes evenly in space. We apply magic lenses and magic boxes as interaction techniques for investigating densely filled areas without overwhelming the observer with visual detail. Implementation details of these methods and their integration in our virtual environment conclude the paper.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION AND MOTIVATION</head><p>Many visualization techniques for two-dimensional flows have already been investigated in detail <ref type="bibr">[Post93]</ref>. Visualization of 3D flow phenomena, however, tend to produce complex images with often heavily overlapping geometry. Occlusion, ambiguities in depth and orientation of flow strain the viewer's abilities to interpret the visualized data.</p><p>The main point of this paper is to show how real-time graphics in a virtual environment can be used to overcome some of these problems. Stereo cues, interactive and intuitive changes of the viewpoint and the feeling of immersion allow users to get a better impression of the structure of the 3D flow in a virtual environment as compared to a desktop system.</p><p>We present a combination of selected visualization and interaction techniques, which enable the user to rapidly explore complex 3D vector fields. Fast texture-based visualization techniques, which utilize the graphics hardware to get real-time performance, are applied to streamlines. A new parameterization scheme allows a direct mapping of a wide range of flow velocity to texture velocity without loss of detail. These techniques together with interactive 3D focussing enable the user to quickly identify and explore areas of interest. The focussed volume is selected with magic lenses and magic boxes that also use mainly hardware accelerated features. Animation is realized in the texture coordinate domain with moving opacity maps. This reduces occlusion and cluttering by simulating particle traces. An automatic streamline placement algorithm [Joba97] is extended into the third dimension to generate an even distribution of streamlines in the virtual environment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK</head><p>Several techniques for the visualization of 2D and 3D flows inspired this work. Some examples of texture based techniques for the visualization of 2D flows are [Cabr93], <ref type="bibr" target="#b15">[Wijk93]</ref>, <ref type="bibr" target="#b9">[Stal95]</ref>. We already applied texture-based visualization techniques in <ref type="bibr" target="#b7">[Löff97]</ref>.</p><p>FROLIC [Wege97a] is a variation of OLIC (Oriented Line Integral Convolution, [Wege97b]) based on LIC <ref type="bibr">[Cabr93]</ref>. OLIC uses sparse textures and an asymmetric convolution kernel to encode the orientation of the flow in still images. Costly convolution operations as done in LIC and OLIC are replaced in FROLIC by approximating a streamlet by a set of disks with varying intensity. The visualization icons we call dashtubes are basically 3D streamlines with animated texturing and apply similar techniques to 3D flows.</p><p>Interrante et. al.</p><p>[Inte97] use LIC for 3D flow volumes. Halos around streamlets offer additional depth and ordering cues. The high cost of volume rendering, however, precludes an interactive exploration. Texture splats as discussed in <ref type="bibr" target="#b2">[Craw93]</ref> encode direction and orientation of 3D flows. Fast splatting operations are realized with hardware supported texture mapping. Animated texture splats illustrate the flow dynamics. While these techniques produce good results, their rendering times are prohibitive for real-time applications.</p><p>Max et.al.</p><p>[Max94] presented various techniques for visualizing 3D flows close to contour surfaces. Motion-blurred particles are generated in the vicinity of surfaces. Particles are started automatically on a lattice. Generation and deletion of particles is density based. Line bundles are realized as texture splats with antialiased lines as texture. Hairs are 3D particle traces originating on the surface. Additional information is encoded in the color, length and transparency of these hairs.</p><p>Streamline placement is an important task to achieve an approximately uniform coverage of phase space. An image-guided streamline placement has been presented in [Turk96]. Another approach for creating evenly spaced streamlines uses a regular grid [Joba97]. For each grid element a list of passing streamlines determines whether there is still space for the placement of another streamline.</p><p>Queues of streamline vertices administer possible seedpoints for new streamlines. Tapering of streamline widths produce handdrawing effects. Directional glyphs illustrate flow orientation. A 3D variation of the streamline placement in [Joba97] was used in our approach (see section 3).</p><p>provide the visual cues needed. Normally, lines are rendered with the same width regardless of distance to the viewpoint so they lack perspective distortion, which is a significant cue for judging distance.</p><p>Additional techniques like halos [Inte97] are necessary to resolve the ambiguities of overlapping lines. When visualizing flow, streamlines need to be enhanced to convey the direction of the flow. This can be done by directional color variations or by placing icons along the streamline as shown in <ref type="bibr">[Joba97]</ref>. Texture based techniques like LIC can be modified to include directional variations as we have shown in [Wege97a] and [Wege97b]. A more direct approach however is the visualization of flow by animation. In the 2D case we use FROLIC combined with lookuptable animation to do this in real-time. Bryson <ref type="bibr" target="#b1">[Bry97]</ref> has successfully used streaklines -2D particles moving along the vector field -in the virtual windtunnel to animate flow in space. This technique depends on continually updating the position of all particles with every animation step, leading to a considerable consumption of processing power.</p><p>In this paper we present dashtubes as visualization tool for steady 3D-flow. Dashtubes are generalized cylinders extruded along the direction of the flow <ref type="figure" target="#fig_0">(Figure 1</ref>). Their geometry is displayed with animated, opacity mapped texturing to visualize velocity and direction of flow. They appear as "dashes" -short opaque segments -moving along the direction of the flow.</p><p>Our requirements for dashtubes are: Volume-filling properties: the dashtubes have to exhibit an even distribution over the volume of interest. Otherwise the omission of interesting features would be probable.</p><p>Reduced occlusion: we need a method which reduces the occlusion of distant features by features near the observer. This demand is almost the opposite from the volume-filling properties mentioned above.</p><p>Animation of flow: the velocity and direction of the flow should be visible in the animation. Dash velocity should directly correspond to flow velocity.</p><p>Visibility of dashes: the length of the dashes should not vary too much with velocity. High velocity areas would otherwise produce long dashes and gaps, which do not give the desired appearance, while low velocity would lead to very short dashes and eventually to aliasing artifacts.</p><p>Fast Rendering: Since one of our main points is the real-time applicability, we want a fast, hardware-assisted rendering method. Like FROLIC we would like to use the graphics hardware to do the animation, leaving the CPU time for simulation and interaction. This is advantageous as the graphics hardware has anyhow to update the image continuously when rendering a virtual environment.</p><p>Dashtubes meet the mentioned requirements. To avoid the occlusion of distant parts of the visualization by closer features and to generate the desired effect of particles moving along the dashtube we render it partially invisible. This is done by using an opacity texture, which includes transparency information for the rendering hardware. Since semi-transparency does not work well in combination with z-buffered visibility resolution, we only map completely opaque or complete transparent values to the geometry. Thereby we avoid artifacts produced by the order in which we render different parts of the scene. The dashtubes are assigned texture coordinates, which correspond to a temporal parameterization along streamlines.  When combined with an appropriate opacity texture, this leads to the desired dashed appearance, with opaque dashes intermitted by empty sections <ref type="figure" target="#fig_1">(Figure 2</ref>). Since animating the texture image itself is a relatively time-expensive operation on most graphics hardware, we just transform the texture coordinates along the direction of the tube. In OpenGL this can be done by modifying the texture transform matrix, which has the additional advantage that it works even when more than one texture map is used. Animation is an essential part of the method, since otherwise structural information visible in <ref type="figure" target="#fig_0">Figure 1</ref> would be lost in the opacity-mapped representation ( <ref type="figure" target="#fig_1">Figure 2</ref>).</p><p>Early tests showed that the animated texture produces annoying visual artifacts at the ends of the dashtubes. The opaque segments entering and leaving the surface of the extrusion exhibited an irritating "blinking" behavior, comparable to the pulsation we had to overcome in FROLIC. We treated this by reducing the radius of the first and last cross-section of the dashtubes to null, thereby tapering the extrusion at the ends <ref type="figure" target="#fig_0">(Figure 1</ref> and <ref type="figure" target="#fig_1">Figure 2</ref>). This yields smooth transitions at both ends, comparable to a "fade-in" effect.</p><p>As most texture mapping techniques, our method is prone to aliasing. When the length of one dash in image-space is reduced to a single pixel width or below annoying artifacts make the distinction of dashes difficult. Even worse, the speed and direction of the visualized flow becomes impossible to observe.</p><p>These effects appear when the viewpoint moves away from the texture-mapped tube or when the flow velocity is very low. In both cases a large texture area is mapped to a small region of the screen.</p><p>Therefore we need a method to reduce aliasing while preserving the essential properties of dashtubes: a high contrast texture moving along the tube at the speed of the visualized flow which contains distinctive opaque and completely transparent sections. Furthermore the maximum length of a dash and gap sequence must not be too big. Otherwise the appearance of the dashtube as a line of moving particles would suffer. Long dashes, while giving a good impression of the direction of the flow, occlude much of the scene farther away and reduce the impression of a volume flow. Ideally we want approximately uniform spaced dashes in image space, independent of viewpoint and flow velocity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Mipmap Method</head><p>Most commonly the mipmap-method [Will83] is used to reduce texture aliasing. Thereby the texture is filtered to consecutively lower resolutions. A single texture is represented by a series of texture maps with decreasing size and texture-frequency ( <ref type="figure">Figure  3a</ref>). Since this method does the filtering in a pre-processing step, the additional expenses at runtime are relatively low making it the method used by most real-time graphics hardware.</p><p>To apply mipmaps on dashtubes we have to alter the standard algorithm of producing the reduced texture maps. Normally each sub-map of a mipmap contains a filtered version of the level above, thereby halving resolution and maximum frequency of the texture <ref type="figure">(Figure 3a</ref>) This clashes with our rejection of semitransparent objects in section 3: the contrast of lower resolution maps is reduced due to filtering, which also produces semitransparent areas. The flow velocity is preserved, but the dashes get shorter in areas with reduced velocity or a more distant viewpoint.</p><p>So we have to produce sub-maps which do not exhibit this undesired properties. <ref type="figure">Figure 3b</ref> shows an example how such maps could look like: They posses the fractal property of having the same amount of detail on every level.</p><p>Using such a mipmap produces the following effects: If the viewpoint moves farther away, the texture (the dashes) shrink continuously in length until a new mipmap level is reached, where the switch to a coarser resolution is performed and the dashes again have a distinguishable length. Sections of dashtubes where the low flow velocity would produce very short dashes are also mapped to coarser resolutions and therefore exhibit longer dashes ( <ref type="figure" target="#fig_2">Figure 4</ref>).</p><p>An important aspect of this approach is that only the contents of the texture are switched, not the mapping of texture to object. This leads to the intended effect when animating the texture: the velocity of the texture along the tube directly corresponds to the flow velocity independently of the length of the dashes. The main problem when using mipmaps for adaptive texturemapping arises from the small number of available mipmap levels: Since every two-dimensional sub-map has exactly the double resolution of the next lower level, the memory consumption exponentially rises with the number of levels. Additionally the switch between one level and the next leads to discontinuities in the texture appearance. Since the textures move along the tubes these discontinuities are especially annoying when they appear along a single tube.</p><p>Most mipmap implementations -including the one used in OpenGL -reduce the artifacts due to level switching by interpolating between two adjacent sub-maps. We can not apply this method in our case since this strongly reduces contrast because the interpolation is performed between two essentially different maps, not between maps only differing in the highfrequency components. Furthermore the interpolation produces semi-transparent areas causing the already in section 3 discussed problems when rendering into the z-buffer.</p><p>These problems occur since the transition between one level and the next is relatively coarse. If we could reduce the difference between level resolutions and increase the number of levels we would be able to exactly specify how switches between longer (less) and shorter (more) dashes are performed. The vast memory consumption of mipmaps with a high number of levels denies us the trivial solution of this problem, so we have to approach it differently.</p><p>In section 4.2 we show a different approach to adaptive texturemapping, which overcomes some of the problems mentioned above. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Texture-Coordinate Method</head><p>If the flow velocity along a dashtube is falling as in <ref type="figure">Figure 5a</ref>, the resulting texturing leads to short dashes in the low-velocity region of the dashtube <ref type="figure">(Figure 5b</ref>, region C). This behavior violates our demands from section 3, where we require the dashes to be distinguishable independently of flow velocity. Since these short dashes can lead to undesirable aliasing artifacts, we would prefer longer dashes in region C, which should still reflect flow velocity. If we want longer dashes moving with the same speed as the shorter ones, we have to somehow reduce the number of dashes travelling from region A to region C. A possible solution, which reduces annoying artifacts shows region B in <ref type="figure">Figure 5c</ref>: every three dashes leaving region A get joined to a single dash while moving through region B. The low-velocity part (region C) of the dashtube contains one long dash in <ref type="figure">Figure 5c</ref> for every three short dashes in <ref type="figure">Figure 5b</ref>. When animated, this shows three dashes leaving the high-velocity region A of the dashtube, which reduce their gaps until they merge into one longer dash in the lowvelocity region C.</p><p>To implement this behavior using conventional (OpenGL) texture-mapping hardware we have to alter the way we map a texture to the geometry of the dashtube. In ordinary texturemapping applications two spatial texture coordinates are mapped onto the 2D surface of an object. Since the rotationally-symmetric dashtubes represent essentially 1D objects -the underlying streamlines -we only need one texture coordinate for the spatial mapping. We use the remaining texture coordinate to smoothly vary the dashes appearance. <ref type="figure">Figure 6</ref> shows a texture map, which maps velocity and time along the dashtube onto opacity. For constant velocity horizontal rows of the texture are mapped along the tube. Constant low velocity maps the lowest row of the texture onto a short segment of the dashtube <ref type="figure">(Figure 6c</ref>), whereas constant high velocity maps the uppermost row of the map onto a long segment of the tube <ref type="figure">(Figure 6a</ref>). Changing velocity along a segment samples the map along a slanted line <ref type="figure">(Figure 6b)</ref>, thereby producing the effects depicted in <ref type="figure">Figure 5c</ref>, region B.</p><p>The merging dashes in the transitions exhibit slightly irritating artifacts when the gaps shrink to one pixel width. To reduce this effect, we want to map the transitions only to short segments of the dashtubes. Between this transition segments we allow the dashes to lengthen or shorten a bit, without altering their number. This gives the motion of the dashes a more uniform appearance.</p><p>The texture map in <ref type="figure">Figure 6</ref> is designed to restrict the transition segments <ref type="figure">(Figure 5c</ref>, section B) to small velocity ranges. In the areas where the texture contains parallel, vertical stripes the sampled texture is independent of the velocity. Only when the sampling passes into one of the branching areas of the map dashes are joined or split.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">STREAMLINE PLACEMENT</head><p>When using streamlines for flow-visualization, the quality of the result depends heavily on the placement of the streamlines. Even when visualizing two dimensional flow fields a uniform distribution is desirable, but when extending the flow visualization to three dimensions the added complication of occlusions make an even placement essential. The start-and endpoints of streamlines introduce distracting artifacts into the visualization so we want to keep their number small. Therefore we want to populate our flow volume with evenly distributed streamlines of maximum length.</p><p>To accomplish this we extend the algorithm of Jobard and Lefer [Joba97] to three dimensions. The streamlines are placed in [Joba97] by using local criteria only. A new streamline can only be placed if the distance to already existing streamlines does not fall below a certain minimum. Since the speed of the algorithm depends mainly on this distance test, certain techniques are applied to accelerate the test. Each streamline is approximated by a set of evenly spaced sample points. The distance between two streamlines is defined as the minimal distance between any of their sample points. This works reasonably well when the sample points are always closer spaced than the minimum distance between lines. A regular grid is used to reduce the set of points to be tested to the ones in the immediate neighborhood of a new point. The distribution of seedpoints depends on the desired density of the resulting images. For densely placed streamlines the seedpoints are distributed randomly, while for sparsely placed streamlines the seedpoints are introduced near the sample points of existing streamlines.</p><p>The adaptation of this algorithm to our needs was quite straightforward. We extended the grid to three dimensions, making it necessary to check now a maximum of 27 cells per distance test. Another technique presented in [Joba97], the agglomerative seedpoint placement for sparse distributions mainly produce visually appealing results in 2D. In 3D, where streamlines can pass in front of each other and their visual distance depends mainly on the viewpoint it produces no distinctive advantage opposed to random startpoint placement.</p><p>For this reason we chose to distribute the seedpoints on a jittered grid, a process which works faster than agglomerative seedpoint placement and produces acceptable results. Since streamlines which are short with respect to the dash length can produce irritating "blinking" artifacts, we reject them as soon as they are introduced, therefore allowing other streamlines to grow.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">FOCUSSING AND CONTEXT</head><p>One of the main problems when visualizing 3D flow fields is finding the correct information density. Too much information per volume occludes features further away and too little information may hide important details. When using streamlines for 3D-flow visualization, the amount of information in a given volume is directly related to the number of streamlines through it. To a lesser degree it also depends on the number of sample points along the streamline. As described in section 5 we place our streamlines approximately equidistant to each other. Therefore density of the streamlines in the resulting images depends mainly on this user selected distance. Other factors contributing to the general appearance are width of the streamline and -in case of dashtubes -the length ratio of opaque to transparent sections.</p><p>When investigating a 3D flow we first try to get an overview of the flow field. This includes investigation of global features, the identification of areas of special interest, like vortices, separatrices, and cycles. Then, when an interesting feature has been identified, we want to single out this feature and investigate it. We want to view it in great detail, without distractions or occlusions from other features.</p><p>In many practical cases, these two different goals are difficult to achieve simultaneously. Therefore we tested techniques where we first use the context of a coarse representation to identify interesting regions. Then we use one of the mechanisms described in sections 6.1 and 6.2 to focus our attention on these regions and investigate them with finer detail.</p><p>Magic lenses, as presented in <ref type="bibr" target="#b0">[Bier97]</ref> are transparent user interface elements for conventional 2D windowing desktop environments. They are represented by special windows, which do not display their own independent content but rather change the representation of the underlying information. They can be used for filtering or otherwise modifying underlying image data but also for more abstract operations like showing additional information like comments. In <ref type="bibr" target="#b14">[Vieg96]</ref> magic lenses are used in virtual environments. This work also deals with volumetric lenses, an extension of magic lenses in three dimensions.</p><p>We use these interface elements to view a higher resolution representation of the flow field. This representation contains more streamlines per volume and the streamlines are thinner and generated with closer spaced vertices than the representation used for coarse navigation. We found that both focussing techniqueslenses and boxes -have specific advantages.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Magic Lenses</head><p>A magic lens is a planar polygon with arbitrary boundaries (e.g., circle, square) which can be positioned with a 6DOF input device, normally a 3D mouse or tracked pen <ref type="figure" target="#fig_5">(Figure 9)</ref>. When looking through the lens, the user focuses on the high-resolution representation.</p><p>The main difference to 2D magic lenses is that our lens additionally acts as a clipping plane, allowing only the parts of the high resolution scene behind the lens to be seen. Without this clipping plane, the lens would also display features of the detailed representation between lens and viewpoint, resulting in the same occlusion problems as if the entire detailed flow visualization were to be investigated. Together with the current viewpoint a magic lens effectively defines a viewing frustum with its near clipping plane lying in the plane of the lens and its cross-section defined by the shape of the lens <ref type="figure" target="#fig_4">(Figure 8)</ref>.</p><p>Working with the magic lens is easy and intuitive. The user positions it in front of interesting features and views them through it like through a magnifying glass <ref type="figure" target="#fig_5">(Figure 9</ref>). The frame of the lens masks the border between focus and context. While presenting an effective and visually appealing investigation mechanism, magic lenses have one distinctive disadvantage compared to magic boxes (section 6.2): the focussed volume depends strongly not only on the position of the lens but also on the viewpoint. This does not matter when a single user is looking for a local feature. The user typically sweeps the lens through space, positioning it and himself until the area of interest is located. When this has been accomplished, the investigation technique normally changes: Now, that the detail has been located, it has to be examined from different angles, a procedure for which magic lenses are not well suited. The lens has to be dragged around the feature together with the changing viewpoint. This is a cumbersome process, which may lead to accidental loss of the focus area and the contained feature.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Magic Boxes</head><p>Magic Boxes -volumetric magic lenses -overcome the above mentioned disadvantages of viewpoint dependency. Instead of only implicitly defining the focussed volume depending on the current viewpoint <ref type="figure" target="#fig_4">(Figure 8)</ref>, they explicitly define a volume of interest ( <ref type="figure" target="#fig_0">Figure 10</ref>). In the interior of a magic box the detailed representation of the flow is displayed.</p><p>The user positions the box with a 6DOF input device until it contains the local feature <ref type="figure" target="#fig_0">(Figure 11</ref>). Then this feature may be viewed from all directions. This is especially important when there are several users viewing the same focus like in our multiuser virtual environment STUDIERSTUBE <ref type="bibr" target="#b12">[Szal98]</ref>. When using magic lenses every user has to position his own lens according to his position, or different users have to trade places when looking through a single lens.</p><p>The border between focus and context is more noticeable when using boxes instead of lenses, since it consists of the whole surface of the box and cannot be masked by a frame like the image-aligned border of the lens. On the other hand the confined volume of the box allows focussing in all three dimension, whereas magic lenses do not inherently define a far plane of the focus. Additionally the box occludes features of the context behind it, thereby reducing distraction.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">IMPLEMENTATION</head><p>The visualization and investigation methods described above were implemented in C++ using Open Inventor <ref type="bibr" target="#b10">[Stra92]</ref>. This OpenGL based graphics toolkit enabled us to efficiently realize our methods providing high-level graphics concepts like a scene graph and sophisticated desktop interaction elements, which we used in the early phases of our tests. The main advantage when implementing our methods was Open Inventors ability to supply these high-level concepts while simultaneously enabling direct access to all OpenGL functions. This was essential when manipulating rendering sequences for magic lenses and magic boxes. Since our virtual environment STUDIERSTUBE is also based on Open Inventor, the transfer from a desktop evaluation-implementation to the application in our virtual environment was straightforward. The following sections describe implementation details of the techniques and their integration into our virtual environment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1">Interaction in the Virtual Environment</head><formula xml:id="formula_0">STUDIERSTUBE [Szal98]</formula><p>is a multi-user augmented environment, which we use for scientific visualization <ref type="bibr" target="#b4">[Fuhr97]</ref>. It implements basic interaction methods like positioning objects by dragging them with a 6 DOF pen <ref type="figure" target="#fig_5">(Figure 9</ref> and <ref type="figure" target="#fig_0">Figure 11</ref>) as well as conventional 2D interaction elements like sliders, dials and buttons for parameterization of the visualization methods. These purely virtual interface elements are positioned on the PIP <ref type="bibr" target="#b11">[Szal97]</ref>, a handheld tablet. Users hold this board in their nondominant hand while they make adjustments to the interface elements with the same pen they use for 6 DOF interaction <ref type="figure" target="#fig_0">(Figure 12)</ref>. In our application we used the PIP to adjust parameters of the dynamical system which provided the flow field as well as properties of the dashtubes and the magic box. The speed, length of dashes and distance between dashes was adjustable with dials. Sliders on the PIP adjust the overall size of the magic box and allow independent scaling of one dimension of the box. This transforms the box to a "slab", allowing the user to use it to cut slices of arbitrary width out of the flow field. Buttons on the PIP were used to switch between magic lens and magic box and to disable the coarse representation on demand. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2">Dashtubes</head><p>Dashtubes are realized as textured polygonal extrusions along the direction of the flow. Ideally the cross-section of the extrusion should be a circle to provide a symmetric appearance from all directions, but we found that the polygonal approximation can be reduced down to 3 to 6 edges depending on the resolution of the display and the required quality of the image. By using Gouraud shading the resulting discontinuities of the approximation are only visible along the silhouette edges. Coarse tesselations like these are prone to generating artifacts when the geometry is twisted along the extrusion axis. The resulting radial contractions lead to irritating variations in the width of the dashtube <ref type="figure" target="#fig_0">(Figure 13</ref>). To avoid this, we generate the segments of the extrusion not by following the Frenet-frame along the streamline. We use a algorithm similar to [Bloo90], which reduces the torsion by aligning the orientation of the polygonal cross-sections along the segments.</p><p>The geometry of the dashtubes was implemented as Open Inventor Shapekit, containing fields for the vertices of the extrusion axis, the texture parameters and the geometric parameters of the cross-section. The Shapekit produces OpenGL trianglestrips, which give a better rendering performance than other OpenGL primitives. Rendering the dashtubes with culled backfaces produces a "halfpipe" appearance at both ends of the opaque segments as visible in <ref type="figure">Figure 7</ref>. Since this is only evident in extreme close-up, we decided that the rendering speedup justifies this artifact.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.3">Magic Lenses</head><p>Magic lenses act as window from context to focus. Our implementation uses SEAMs [Scha98], a mechanism to connect two virtual worlds by "windows" of arbitrary geometry. Our magic lens has the appearance of a magnifying glass, using a circular SEAM inside a ring geometry providing the frame <ref type="figure" target="#fig_5">(Figure 9</ref>). According to the nomenclature of [Scha98], the context outside the lens would be the "primary world" and the focus seen through the lens the "secondary world". The geometry of both worlds is given as a directed acyclic graph (scene graph). The scene graph of the context is traversed and rendered. When a SEAM is encountered, the associated polygon -in our case the "lens" -is passed to the rendering hardware for scan conversion.</p><p>To restrict the rendering of the focus to the area covered by the SEAM we use the OpenGL stencil buffer, an additional layer for masking areas of the screen during rendering. For all pixels that the z-test for the SEAM polygon finds to be visible:</p><p>• The frame buffer is set to the background color of the secondary world (clear screen),</p><p>• the Z-buffer is set to infinity (clear Z-buffer),</p><p>• the mask (stencil buffer) is set to 1.</p><p>Note that these image modifications are only carried out for the visible portion of the SEAM surface. After this preparation step, rendering the focus is performed inside the stencil mask created in the previous step. This prevents that the focus is drawn outside the SEAM area. A clipping plane coincident with the SEAM polygon prevents the focus from protruding from the SEAM. Finallybefore rendering of the context proceeds -the SEAM polygon is rendered again, but only the computed depth values are written into the z-buffer. Thereby the SEAM is "sealed". The resulting zvalues are all smaller than any z-value of the focus. This asserts that no geometric primitive of the context located behind the SEAM will overwrite a pixel generated by rendering the focus.</p><p>This gives the desired impression of a "window" behind which only the focus is displayed <ref type="figure" target="#fig_5">(Figure 9</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.4">Magic Boxes</head><p>We found that displaying only the contents of the magic box without visual representation of its boundaries makes it difficult to locate and position the box and tends to confuse the user. Therefore we added a cube as geometric representation of the focussing volume. The front faces of the cube are culled, leading to an "open front" appearance regardless of the viewpoint.</p><p>Magic boxes are rendered using the same SEAM algorithm as described above, but use a cube instead of a plane to define the "windows" between focus and context. Six clipping planes coincident with the faces of the cube clip the secondary world (the detailed representation).</p><p>Our implementation renders the complete scene (focus and context) only once, while <ref type="bibr" target="#b14">[Vieg96]</ref> needs six rendering passes, one for each halfspace derived from a cube face. This leads to a significant improvement in the frame rate. Our method does not display any parts of the context that lie behind the box, which for our application would anyway only be distractive.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">EVALUATION AND RESULTS</head><p>Animated dashtubes produce an intuitive visualization of a 3D flowfield. The main problem when applying our focussing techniques lies in finding the correct density for focus and context. When testing lenses and boxes with different densities of dashtubes in the focus we found that magic boxes work better than lenses with densely placed dashtubes. Since lenses do not clip distant parts of the detailed scene they are only applicable to scenes of higher density when they are rendered with strong depth cues (haze, fog).</p><p>Most users applied magic lenses without any problems, but needed some experimentation to grasp the concept of volumetric magic boxes.</p><p>The method of slicing the flow field with "slabs" -magic boxes of small height -as mentioned in section 7.1 was implemented after users started to experiment with the distances of near and far clipping plane of the view volume to achieve this "slicing" effect in a view dependent manner.</p><p>When using magic boxes, most users applied the following technique: position coarse representation conveniently; position box until interesting features visible; switch off coarse representation; magnify box with included details for investigation Since our application allowed independent positioning of focussing element and flow field, some users preferred positioning the flow field and keeping the box or lens stationary. During the design phase of the dashtubes we used shutter glasses to produce stereoscopy. While this works very well for the examination of the flow field, interaction with magic lenses and magic boxes using the 2D desktop mouse is cumbersome and nonintuitive compared to the interaction in the virtual environment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9">CONCLUSION</head><p>In this paper we discussed several techniques which facilitate 3Dflow visualization within a virtual environment. The newly introduced adaptive texture mapping method shows that texture hardware can be efficiently used to produce dashtubes with uniform spatial resolution. The approach ensures that velocity variations are still encoded in the animation. Dashtubes are automatically positioned in phase space to produce an even representation of the underlying 3D flow.</p><p>Interactive tools like magic lenses and magic boxes proved to be valuable in the investigation of local features. They enable the user to interactively select finely detailed features and reduce distraction by context. In our investigations 3D phase space contains spatially complex structures, which are difficult to interpret. The added cues of a virtual environment (e.g., stereoscopic viewing, interactive and intuitive viewpoint change) are quite helpful when inspecting these structures.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Streamline geometry without texturing</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Dashtubes with opacity-texture</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4 :</head><label>4</label><figDesc>dashtubes with (a) and without (b) mipmap-texturing</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 5 :Figure 6 :Figure 7 :</head><label>567</label><figDesc>Adaptive texturing with texture-coordinate method Texture usage of texture-coordinate method D E dashtubes with (a) and without (b) adaptive texturing</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 8 :</head><label>8</label><figDesc>Volume defined by magic lens</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 9 :</head><label>9</label><figDesc>Focussing with a magic lens</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 10 :</head><label>10</label><figDesc>Volume defined by magic box</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 11 :</head><label>11</label><figDesc>Focussing with a magic box</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 12 :</head><label>12</label><figDesc>Interaction using the PIP</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 13 :</head><label>13</label><figDesc>Contraction artifacts due to torsion</figDesc></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGEMENT</head><p>Special thanks to Hermann Wurnig, who did more than his share to implement the interaction methods, and to Michael Gervautz, Robert Tobler, Dieter Schmalstieg and Helwig Löffelmann for their help and suggestions.</p><p>This work has been supported by the Austrian Science Foundation (FWF) under project no. P-12074-MAT.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Enhanced illustration using magic lens filters</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Bier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Stone</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Pier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Bloomenthal. Calculation of Reference Frames Along a Space Curve. Graphic Gems</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="567" to="571" />
			<date type="published" when="1990" />
			<publisher>Academic Press</publisher>
		</imprint>
	</monogr>
	<note>IEEE Computer Graphics and Applications</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">The virtual windtunnel: An environment for the exploration of three-dimensional unsteady flows</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steve</forename><surname>Bryson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Creon</forename><surname>Levitt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">;</forename><forename type="middle">B</forename><surname>Cabral</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">C</forename><surname>Leedom</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings SIGGRAPH &apos;93</title>
		<meeting>SIGGRAPH &apos;93</meeting>
		<imprint>
			<date type="published" when="1991" />
			<biblScope unit="page" from="263" to="272" />
		</imprint>
	</monogr>
	<note>Visualization &apos;91</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Texture splats for 3D scalar and vector field visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Crawfis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Max</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Visualization &apos;93</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">Proceedings</title>
		<imprint>
			<biblScope unit="page" from="261" to="266" />
			<date type="published" when="1993-10" />
			<publisher>IEEE Computer Society</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Collaborative augmented reality: Exploring dynamical systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Fuhrmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Löffelmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Schmalstieg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Visualization &apos;97 Proceedings</title>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="1997-10" />
			<biblScope unit="page" from="459" to="462" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Strategies for effectively visualizing 3D flow with volume LIC</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Interrante</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ch</forename><surname>Grosch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">; B</forename><surname>Jobard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Lefer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Visualization in Scientific Computing</title>
		<editor>Wilfrid Lefer and Michel Grave</editor>
		<imprint>
			<date type="published" when="1997" />
			<biblScope unit="page">43</biblScope>
		</imprint>
	</monogr>
	<note>Proceedings of Visualization &apos;97</note>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Springer-Wien-Newyork</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Stream Arrows: Enhancing the Use of Stream Surfaces for the Visualization of Dynamical Systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Löffelmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Mroz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Gröller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Purgathofer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Visualization &apos;94</title>
		<editor>Max94] N. Max, R. Crawfis, and Ch. Grant</editor>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1997" />
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="359" to="369" />
		</imprint>
	</monogr>
	<note>Visual Computer</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Sewing worlds together with seams</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">H</forename><surname>Post</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Van Walsum</surname></persName>
		</author>
		<idno>TR-186-2-98-11</idno>
	</analytic>
	<monogr>
		<title level="m">Focus on Scientific Visualization</title>
		<editor>H. Hagen, H. Müller, and G. M. Nielson</editor>
		<meeting><address><addrLine>Vienna, Austria</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1993-08" />
			<biblScope unit="page" from="1" to="40" />
		</imprint>
		<respStmt>
			<orgName>Institute of Computer Graphics 1862, Technical University of Vienna</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
	<note>Fluid flow visualization</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Fast and resolution independent line integral convolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Stalling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hege</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Graphics (SIGGRAPH 1995 Proceedings)</title>
		<editor>Robert Cook</editor>
		<imprint>
			<date type="published" when="1995-08" />
			<biblScope unit="page" from="249" to="256" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">An object oriented 3D graphics toolkit</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Strauss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Carey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings SIGGRAPH 1992</title>
		<meeting>SIGGRAPH 1992</meeting>
		<imprint>
			<date type="published" when="1992" />
			<biblScope unit="page" from="341" to="347" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">The personal interaction panel A two-handed interface for augmented reality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Szalavari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gervautz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics Forum</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="335" to="346" />
			<date type="published" when="1997-09" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Szalavari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Schmalstieg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Fuhrmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Studierstube -An Environment for Collaboration in Augmented Reality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gervautz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Virtual Reality: Research, Development &amp; Applications</title>
		<imprint>
			<date type="published" when="1996" />
			<biblScope unit="page" from="453" to="459" />
		</imprint>
	</monogr>
	<note>Proceedings SIGGRAPH 1996</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Fast oriented line integral convolution for vector field visualization via the internet</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Viega</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Conway</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Pausch ; R. Wegenkittl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Gröller ; R. Wegenkittl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Gröller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Purgathofer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Visualization &apos;97 Proceedings</title>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="1983-07" />
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="1" to="11" />
		</imprint>
	</monogr>
	<note>Proceedings)</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Flow visualization with surface particles</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">J</forename><surname>Van Wijk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer Graphics &amp; Applications</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="18" to="24" />
			<date type="published" when="1993-07" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
