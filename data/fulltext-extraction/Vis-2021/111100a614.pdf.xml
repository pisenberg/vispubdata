<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Rapid Labels: Point-Feature Labeling on GPU</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">V</forename><surname>Áclav Pavlovec</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Faculty of Electrical Engineering</orgName>
								<orgName type="institution">Czech Technical University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Ladislav</forename><surname>Čmolík</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Faculty of Electrical Engineering</orgName>
								<orgName type="institution">Czech Technical University</orgName>
							</affiliation>
							<affiliation key="aff0">
								<orgName type="department">Faculty of Electrical Engineering</orgName>
								<orgName type="institution">Czech Technical University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">V</forename><surname>Pavlovec</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Faculty of Electrical Engineering</orgName>
								<orgName type="institution">Czech Technical University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Rapid Labels: Point-Feature Labeling on GPU</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">181730EAF26F5C74FC60A5FFCA0D8EA8</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.1" ident="GROBID" when="2022-06-13T13:56+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Label placement</term>
					<term>Point-feature labeling</term>
					<term>GPU</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Labels, short textual annotations are an important component of data visualizations, illustrations, infographics, and geographical maps. In interactive applications, the labeling method responsible for positioning the labels should not take the resources from the application itself. In other words, the labeling method should provide the result as fast as possible. In this work, we propose a greedy point-feature labeling method running on GPU. In contrast to existing methods that position the labels sequentially, the proposed method positions several labels in parallel. Yet, we guarantee that the positioned labels will not overlap, nor will they overlap important visual features. When the proposed method is searching for the label position of a point-feature, the available label candidates are evaluated with respect to overlaps with important visual features, conflicts with label candidates of other point-features, and their ambiguity. The evaluation of each label candidate is done in constant time independently from the number of point-features, the number of important visual features, and the resolution of the created image. Our measurements indicate that the proposed method is able to position more labels than existing greedy methods that do not evaluate conflicts between the label candidates. At the same time, the proposed method achieves a significant increase in performance. The increase in performance is mainly due to the parallelization and the efficient evaluation of label candidates.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Labels, short textual annotations, are an important component of data visualizations, illustrations, infographics, and geographical maps. The main function of the labels is to provide annotations, for which we can easily see to which visual features they relate. The annotations (e.g., names of the visual features) are crucial in identifying the visual features, especially in information visualization and geographical maps where all visual features have the same or similar shape.</p><p>The label placement was identified as one of the most important problems in Discrete Computational Geometry <ref type="bibr" target="#b2">[3]</ref>. The label placement is usually divided according to the feature type that is being labeled into point-feature labeling, line-feature labeling, and area-feature labeling. In this work, we are focusing on the point-feature labeling where the features are points or small areas that can be approximated with points.</p><p>The point-feature labeling problem also denoted as label number maximization problem is an optimization problem. The goal is to label maximum number of point-features possible with labels of given dimensions such that each label can be unambiguously associated with the labeled point-feature and that no label overlaps with other labels or important visual features (e.g., labels of point-features in a line chart will not overlap the line). The problem does not have an easy solution as it is NP-hard <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b9">11,</ref><ref type="bibr" target="#b16">18]</ref>.</p><p>Oftentimes, the point-feature labeling problem is extended to consider several groups of point-features where the priority of each group is given by order of the groups. In a such case, the goal for each group is to maximize the number of positioned labels while not decreasing the number of positioned labels in groups with higher priority.</p><p>The vast majority of point-feature labeling techniques, discussed in detail in Section 2, position the label in close proximity to the labeled point-feature. Most often, the techniques choose the label from four or eight predetermined label candidates around the pointfeature. Less often, the techniques use the sliding model where the label candidate is allowed to slide around the point-feature. Only several techniques <ref type="bibr" target="#b11">[13,</ref><ref type="bibr" target="#b14">16]</ref> allow positioning the label further away from the point-feature. They associate the label with the labeled point-feature with a leader -a line or a curve that connects the label with the pointfeature.</p><p>In interactive applications, especially in interactive data visualizations and interactive geographic information systems, we often obtain previously unknown configurations of point-features after loading a dataset or performing a dynamic query <ref type="bibr" target="#b22">[24]</ref>. In such situations, to support the user in identifying the point-features, the label layout needs to be found in a very limited time.</p><p>In this work, we propose a screen-space greedy method that is running on GPU. The proposed method takes a list of point-features with their coordinates and labels as the input. Further, the method takes as the input a raster image containing the important visual features that cannot be occluded by the labels and a raster image into which the labels will be drawn. This way, any application that is able to produce an image can be easily integrated with the proposed method. The proposed method allows to label a large number of point-features at interactive framerates without the need for a pre-processing of the input data. Alternatively, the proposed method can be utilized to quickly preprocess the input data to generate a label layout that supports zoom and pan. As the method is greedy, we do not guarantee that the proposed method will find the optimal label layout. We highlight our four main contributions:</p><p>1. In contrast to existing methods that position the labels sequentially, the proposed method positions several labels in parallel. Yet, we guarantee that the positioned labels will not overlap, nor will they overlap important visual features.</p><p>2. The proposed method is evaluating overlaps with important visual features, considering conflicts with label candidates of other point-features, and evaluating ambiguity when it is determining the position of a label. This makes the proposed method more flexible than the existing greedy methods that either evaluate overlaps with important visual features <ref type="bibr" target="#b10">[12,</ref><ref type="bibr" target="#b14">16]</ref> or consider conflicts with label candidates of other point-features <ref type="bibr" target="#b18">[20]</ref>. Further, none of the existing greedy methods evaluate ambiguity when it is determining the position of a label.</p><p>3. The proposed method uses Summed Area Table <ref type="bibr" target="#b4">[5]</ref> to evaluate overlaps of a label candidate with important visual features, to evaluate conflicts of the label candidate with label candidates of other features, and to evaluate ambiguity of the label candidate. Due to the Summed Area Table, the evaluation is done in constant time independently of the number of important visual features, labeled point-features, and resolution of the created image. Please note that there is a performance cost associated with the creation of the Summed Area Table, but the overall acceleration is greater than the cost. Fig. <ref type="figure">1</ref>. The eight predetermined label candidates around the point-feature (indicated with the cross). The horizontal and vertical offset of each label candidate from the point-feature is given by the offset o. For each label candidate, we depict its preference as a number (lower is better). The conflict rectangle enclosing all label candidates is indicated with red color.</p><p>4. We have compared the performance and the number of labeled point-features of the proposed method with two existing greedy methods, Particle-based labeling of Luboschik et al. <ref type="bibr" target="#b14">[16]</ref>, and Fast Labels of Kittivorawong et al. <ref type="bibr" target="#b10">[12]</ref>. To assess the impact of the greedy approach used in the proposed method on the number of labeled point-features, we have compared the proposed method with a modified meta-heuristic method of Zoraster <ref type="bibr" target="#b31">[33]</ref> based on simulated annealing. Our measurements indicate that the proposed method achieves a significant increase in performance compared to the other methods. At the same time, the proposed method is able to label more point-features than the two greedy methods but fewer point-features than the modified method of Zoraster.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK</head><p>The point-feature labeling problem has been extensively studied, and many optimization strategies were used to solve it. Often, the strategies are using the same concept called conflict graph <ref type="bibr" target="#b23">[25]</ref> to represent possible conflicts (e.g., overlaps) among label candidates. Within this concept, the objective of the point-feature labeling problem is to find the maximum independent set of the conflict graph. Many optimization strategies have been applied to the problem, including simulated annealing <ref type="bibr" target="#b20">[22,</ref><ref type="bibr" target="#b31">33]</ref>, tabu search <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b30">32]</ref>, genetic algorithms <ref type="bibr" target="#b6">[8,</ref><ref type="bibr" target="#b26">28,</ref><ref type="bibr" target="#b27">29]</ref>, ant colonies <ref type="bibr" target="#b21">[23]</ref>, and 0-1 integer programming <ref type="bibr" target="#b7">[9,</ref><ref type="bibr" target="#b15">17,</ref><ref type="bibr" target="#b17">19]</ref>. For an extensive list of the existing methods, please see the website of Wolff and Strijk <ref type="bibr" target="#b29">[31]</ref>, who catalogs the map labeling techniques.</p><p>All the above-described methods provide high-quality label layouts for various applications. However, only several methods <ref type="bibr" target="#b7">[9,</ref><ref type="bibr" target="#b12">14]</ref> consider overlaps among labels and other important visual features. Further, all the above-described methods share a common problem. The computation time ranges from seconds for small datasets to minutes or hours for large datasets. Consequently, these methods cannot be used in interactive applications where the positions of point-features can change in time or where the label layout of a previously unknown configuration of point-features is needed quickly.</p><p>Petzold et al. <ref type="bibr" target="#b19">[21]</ref> addressed the problem of high computation time for a special case of zooming in a map. They divided the calculation into a time-demanding pre-processing stage and fast labeling phase. In the pre-processing stage, they determine a modified conflict graph to resolve label conflicts at any given zoom level of the map. Due to the time-demanding pre-processing stage, the method is not applicable in scenarios where the point-features cannot be pre-processed in advance.</p><p>Been et al. <ref type="bibr" target="#b1">[2]</ref> explored the labeling of dynamic maps. They propose a method that can position the labels consistently with panning and zooming operations. Interactive computation times are again achieved by a heavy pre-processing phase.</p><p>Greedy methods are also addressing the problem of high computation time, but for a general case of the point-feature labeling problem. Greedy methods do not guarantee to find the optimal label layout. Generally, they will find a worse label layout than the above-described methods, but they are able to calculate the label layout in milliseconds which makes them applicable in situations where heavy pre-processing is not possible.</p><p>Mote <ref type="bibr" target="#b18">[20]</ref> introduced a greedy method based on a so-called trellis strategy. The method divides the screen area into a 2-dimensional grid and determines a simplified version of a conflict graph for the given point-features. Only point-features in neighboring cells need to be checked for conflict with a given point-feature. The technique assigns a cost to every label candidate and selects the least expensive set of non-conflicting candidates. However, overlaps of labels with important visual features are not evaluated. Subsequently, the labels can occlude important visual features.</p><p>Lubostchik et. al. <ref type="bibr" target="#b14">[16]</ref> introduced Particle-based labeling, where the particles represent both the already positioned labels and the visual features that the labels cannot overlap. To reduce the number of particles that need to be tested for overlaps with a label candidate, they introduce a local neighborhood data structure similar to the Trellis strategy of Mote <ref type="bibr" target="#b18">[20]</ref>. In contrast to the method of Mote, Particle-based labeling does not evaluate conflicts among the label candidates, which leads to label layouts with a lower number of positioned labels when the labels are positioned to the close proximity of the point-features. They compensate it with so-called distant labels positioned further away from the point-features. The relationship is established with straight leaders that connect each distant label with the corresponding pointfeature. The distant labels also allow for the labeling of dense clusters of point-features. Unfortunately, the straight leaders often cross the point-features, the labels, and one another, which generates a significant visual clutter. The performance of Particle-based labeling depends heavily on the number of used particles. The method is significantly slower for cases with complex visual features that the labels cannot occlude.</p><p>The performance problem of Particle-based labeling was addressed by Kittivorawong et al. <ref type="bibr" target="#b10">[12]</ref> with occupancy bitmask. The occupancy bitmask allows faster evaluation of the overlaps of the label candidates with the visual features that cannot be occluded. However, the time required to determine overlap for a label candidate still depends on the size of the label candidate and the screen resolution.</p><p>Recently, Lhuillier et al. <ref type="bibr" target="#b11">[13]</ref> proposed an approach to determine the distant labels without the visual clutter. They calculate a density map of point-features. The positions of labels are calculated by gradient descent of the density map with leaders corresponding to the trajectory. Therefore, the leaders are guaranteed to be crossing-free. They incorporate an obstacle map to avoid overlaps of labels and other important visual features. However, the method is not suitable for large datasets due to high computation time.</p><p>As our proposed method uses Summed Area Table <ref type="bibr" target="#b4">[5]</ref> to evaluate the label candidates, we mention that recently Čmolík et al. <ref type="bibr" target="#b3">[4]</ref> used Summed Area Table to evaluate label candidates of area-features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">LABELING OF POINT-FEATURES ON GPU</head><p>In this work, we propose a greedy method that allows to provide visual features that the labels cannot overlap and evaluates conflicts between the label candidates of point-features. Further, we propose how to evaluate the ambiguity of the label candidates. We demonstrate that the evaluation of ambiguity further improves the resulting label layout. Finally, in contrast to other existing methods, the proposed method positions labels of several point-features in parallel.</p><p>The proposed method is choosing the label for each point-feature from eight predetermined label candidates around the point-feature, see Figure <ref type="figure">1</ref>. Each label candidate has its preference (lower is better). The proposed method is choosing the label based on the preference of the label candidates and other properties of the label candidates discussed later. The horizontal and vertical offset of the label candidates from the point-feature is given by the offset o. All label candidates of a point-feature are enclosed in the conflict rectangle with the width</p><formula xml:id="formula_0">w = 2 • w L + 2 • o and height h = 2 • h L + 2 • o,</formula><p>where w L is the width of the label and h L is the height of the label.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Parallel Point-Feature Labeling</head><p>To allow labeling of multiple point-features at once, we utilize distance between the point-features. We can label a set of point-features in parallel if the vertical distance d v ≥ w max and the horizontal distance d h ≥ h max for each pair of point-features in the set, where w max and b�� q = 0 q = 2 q = 1 q = 3 The quadrant of each block with quadrant id q = 1 is highlighted in gray color. Three point-features at extreme positions and their conflict rectangles are depicted in red color to show that in a worst-case, the conflict rectangles will touch but not overlap.</p><p>h max are the maximum with and height of conflict rectangles of all point-features calculated from the provided labels and font size.</p><p>Finding such a set of point-features is relatively easy. We divide the space into grid a of blocks of width 2 • w max and height 2 • h max , see Figure <ref type="figure" target="#fig_1">2</ref> for an example. We denote each block as b i j , where i and j are x and y coordinates of the block in the grid. Then, we divide each block into four quadrants of width w max and height h max . We assign quadrant id q ∈ {0, 1, 2, 3} to each quadrant according to its position in the block, see Figure <ref type="figure" target="#fig_1">2</ref> for an example. Finally, by choosing one point-feature from the quadrant with given q of each block, we obtain the set of point-features that can be labeled in parallel. In Figure <ref type="figure" target="#fig_1">2</ref>, we highlight the quadrant with q = 1 in each block with gray color and depict three point-features with extreme positions and with the width w = w max and height h = h max of their conflict rectangles to show that in the worst case the labels will touch but not overlap. Please note that if certain quadrants do not contain any point-features then the condition that the labels will not overlap is still met.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Overview of the Algorithm</head><p>The proposed algorithm is a screen-space technique that operates in image space. The algorithm works with 2D buffers. A 2D buffer is similar to a 2D raster image, but the values stored in a 2D buffer do not need to be colors; they can be any desired values.</p><p>Our algorithm takes the list of point-features and two buffers as the input. For each point-feature, the [x, y] coordinates and the label string are provided. The obstacles buffer is a buffer that contains a mask of the important visual features that the labels cannot overlap. Essentially, the pixels of the obstacles buffer that the labels cannot overlap have the value 1 while the remaining pixels have the value 0. The color buffer contains the image that will be overlaid with the labels.</p><p>The output of the algorithm is the color buffer overlaid with the positioned labels. Alternatively, the output of the algorithm can be the labels buffer, a buffer of the width equal to the number of point-features and of the height 1 containing the coordinates and dimensions of the positioned labels. The x coordinate in this buffer corresponds to the index of the point-feature in the input list of point-features.</p><p>The algorithm uses other buffers internally. The conflict buffer is used to evaluate conflicts between the label candidates of different pointfeatures. The ambiguity buffer is used for the evaluation of ambiguity of the label candidates. The label obstacles buffer is used to evaluate overlaps of label candidates with already positioned labels. All these buffers have the same size as the input obstacles buffer. In fact, we combine the obstacles buffer, conflict buffer, ambiguity buffer, and label obstacles buffer into the evaluation buffer. The evaluation buffer is a buffer with four channels (similar to an RGBA image), where the obstacles buffer, conflict buffer, ambiguity buffer, and label obstacles buffer are each represented as one channel. Further, the algorithm uses the block buffer that represents the blocks of the grid. The size of the buffer corresponds to the size of the grid of blocks, i.e., there is one pixel of the block buffer for each block of the grid. Finally, the algorithm uses the priority buffer of the same size as the block buffer. The priority buffer is used to find the point-feature with the highest For each iteration we depict the obstacles buffer, the conflict buffer, the ambiguity buffer, and the label obstacles buffer. In the obstacles buffer, we indicate the processed quadrant with light red color and the labels positioned in the previous iterations. In the first iteration, a label of one point-feature is positioned.</p><p>The conflict rectangle of the point-feature is removed from the conflict buffer, and the label is added to the label obstacles buffer.</p><p>priority for each block of the grid. Below, we describe the overview of the proposed algorithm. We explain the details in the following sections. We indicate the corresponding sections in the overview. Figure <ref type="figure" target="#fig_2">3</ref> depicts how the evaluation buffer will be modified during the first four iterations of the algorithm for a simple line chart with four point-features. For a graphical version of the overview with all used buffers, please see Figure <ref type="figure" target="#fig_3">4</ref>.</p><p>1. Establish the set of quadrant ids Q = {0, 1, 2, 3} and set the quadrant id q = 0.</p><p>2. Create evaluation buffer, see Section 3.3 for details.</p><p>3. Create priority buffer, block buffer, and labels buffer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>4.</head><p>While the set of quadrant ids Q is not empty:</p><p>(a) Set quadrant id q = (q + 1)%4.</p><p>(b) If the quadrant id q / ∈ Q then go to Step 4.</p><p>(c) Set the value of each pixel in the priority buffer to 0. Clear each pixel in the block buffer to contain no label and pointfeature.</p><p>(d) Do in parallel for each unlabeled point-feature f in the quadrant with id q:</p><p>i. Determine the coordinates [i, j] of the block b i j which contains the point-feature f . ii. Determine the label L and the priority p of the pointfeature f using the evaluation buffer, see Section 3.4 for details. If the point-feature f cannot be labeled, then the processing of the point-feature f ends. iii. Atomic operation: If the priority p is greater than the priority at position [i, j] in the priority buffer, then set priority at position [i, j] in the priority buffer to p and store the position and dimensions of the label candidate l and position and id of the point-feature f in the block buffer at position [i, j].</p><p>(e) Do in parallel for each block b i j :</p><p>i. If a point-feature in block b i j was labeled, then update the evaluation buffer, see Section 3.5 for details.</p><p>(f) If no point-feature was labeled for quadrant id q, then remove the quadrant id q from the set of quadrant ids Q.</p><p>(g) Otherwise, do in parallel for each block b i j : i. If a point-feature in block b i j was labeled, then copy the position and dimensions of the chosen label into the labels buffer at the position given by the id of the point-feature. ii. Mark the point-feature as labeled. The atomic operation used in the algorithm means that the whole step is executed at once for each point-feature without interruption.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Creating the Evaluation Buffer</head><p>We create the evaluation buffer by combining the obstacles buffer, conflict buffer, ambiguity buffer, and label obstacles buffer into a single buffer similarly to how the RGBA image combines red, green, blue, and alpha channels. We will express the value of a pixel of the evaluation buffer as e = [e o , e c , e a , e l ], where the e o , e c , e a , and e l are values of the corresponding pixel in the obstacles buffer, conflict buffer, ambiguity buffer, and label obstacles buffer, respectively. Now let us describe how we create the individual buffers. The obstacles buffer is the input of the algorithm, and the remaining buffers are created with the same size. The value of each pixel in the conflict buffer is set to 0. For each point-feature, we render its conflict rectangle and add 1 to each pixel in the conflict buffer inside the conflict rectangle. After this, each pixel of the conflict buffer contains the number of conflict rectangles that it is inside of. The ambiguity buffer is created exactly the same as the conflict buffer. This is because the content of the conflict buffer is changing during the labeling, while the content of the ambiguity buffer remains the same. Please see Figure <ref type="figure" target="#fig_2">3</ref> for an example. Lastly, the value of each pixel in the label obstacles buffer is set to 0.</p><p>After we create the evaluation buffer, we calculate the Summed Area Table <ref type="bibr" target="#b4">[5]</ref> of all blocks b i j in the buffer in parallel. Calculating the Summed Area Table for blocks b i j instead of the whole evaluation buffer makes the calculation dependent on the size of the blocks which is smaller than the size of the whole buffer. Further, it allows us to update the Summed Area Table more efficiently. We describe the update process in detail later in Section 3.5. To calculate the Summed Area Table, we use the method of Hensley et al. <ref type="bibr" target="#b8">[10]</ref> tailored for the parallel calculation on GPU.</p><p>In the Summed Area Table, each pixel p of the buffer inside of block b i j contains sum S = [S o , S c , S a , S l ] of the values of pixels in the rectangle with the bottom left corner at the bottom left corner of the block and top right corner at the position of pixel p. Again, the values S o , S c , S a , and S l are sums of values of pixels in the corresponding rectangle in the obstacle buffer, conflict buffer, ambiguity buffer, and label obstacles buffer.</p><p>Summed Area Table allows to obtain the sum of values in a given rectangle in the evaluation buffer in constant time. In our case, the maximum size of the given rectangle is equal to the size of one quadrant of the block. In other words, the given rectangle can be inside of a single block, overlap two blocks horizontally, overlap two blocks vertically, or overlap four blocks of the grid. In the following text, we show that in the worst case we need nine reads from the Summed Area Table of the evaluation buffer to obtain the sum of values in the given rectangle.</p><p>If the given rectangle is inside of a single block, we can obtain the sum of values in the rectangle with reading values in the four corners of the rectangle. In Figure <ref type="figure" target="#fig_4">5</ref>(a), we depict the rectangle together with the bottom and left border of the block. To obtain the sum S of values in the rectangle, we calculate</p><formula xml:id="formula_1">S = S 3 − S 1 − (S 2 − S 0 ) = S 0 − S 1 − S 2 + S 3 ,<label>(1)</label></formula><p>where S 0 , S 1 , S 2 , and S 3 are sums in the Summed Area Table in the corners of the given rectangle depicted in Figure <ref type="figure" target="#fig_6">6</ref>.</p><p>In the case that the given rectangle overlaps two blocks vertically, we need six reads from the Summed Area Table, see Figure <ref type="figure" target="#fig_5">5(b)</ref>. For the part of the rectangle in the bottom block, we can use Equation <ref type="formula" target="#formula_1">1</ref>. For the part of the rectangle in the top block, we can calculate the sum by subtracting the sum S 4 from the sum S 5 . This gives us the equation</p><formula xml:id="formula_2">S = S 0 − S 1 − S 2 + S 3 − S 4 + S 5 .<label>(2)</label></formula><p>Similarly, in the case that the given rectangle overlaps two blocks horizontally, we need six reads from the Summed Area Table, see Figure <ref type="figure" target="#fig_5">5(c)</ref>. For the part of the rectangle in the left block, we can use Equation <ref type="formula" target="#formula_1">1</ref>. For the part of the rectangle in the right block, we can calculate the sum by subtracting the sum S 6 from the sum S 7 . This gives us the equation</p><formula xml:id="formula_3">S = S 0 − S 1 − S 2 + S 3 − S 6 + S 7 .<label>(3)</label></formula><p>Finally, in the case that the rectangle overlaps four blocks of the grid, we need nine reads from the Summed Area Table, see Figure <ref type="figure" target="#fig_5">5(d)</ref>. For the part of the rectangle in the bottom left block, we can use Equation <ref type="formula" target="#formula_1">1</ref>. For the part of the rectangle in the top left block, we need to subtract sum S 4 from sum S 5 . For part of the rectangle in the bottom right block, we need to subtract sum S 6 from sum S 7 . And for the part of the rectangle in the top right block, the sum equals to sum S 8 . Adding the values for all parts of the rectangle gives us the equation </p><formula xml:id="formula_4">S = S 0 − S 1 − S 2 + S 3 − S 4 + S 5 − S 6 + S 7 + S 8 .<label>(4)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Evaluating the Point-Features</head><p>This section describes how we determine the label L and the priority p of a point-feature. The evaluation is based on the Summed Area Table of the evaluation buffer. To simplify the following description, we will not distinguish between label candidates completely inside in a single block, label candidates overlapping two blocks vertically, label candidates overlapping two blocks horizontally, and label candidates overlapping four blocks. Instead, let us consider that the correct formula from the previous section is used to obtain the sum of values inside of the label candidate in the evaluation buffer.</p><p>In the following text, we describe an algorithm that determines label L of a given point-feature from the label candidates of the point-feature and assigns priority p to the point-feature. If the point-feature cannot be labeled then, the label L is not set. In the algorithm, the label candidates of the point-feature are evaluated sequentially in ascending order according to their preference.</p><p>To evaluate a label candidate l, we obtain the sum S = [S o , S c , S a , S l ] inside of the label candidate l from the Summed Area Table of the evaluation buffer. First, we test that the candidate does not overlap important visual features encoded in the obstacles buffer or already positioned labels encoded in the label obstacles buffer. If that is the case then S o + S l = 0.</p><p>For the satisfactory label candidate l, we evaluate the conflicts of the label candidate l as a ratio of the area of the label A to the sum of conflicts S c inside of the label candidate. Please note that A/S c = 1 only if the label candidate does not overlap the conflict rectangle of any other unlabeled point-feature (i.e., the label candidate overlaps only the conflict rectangle of its point-feature). If the label candidate overlaps conflict rectangles of other unlabeled point-features then A/S c &lt; 1.</p><p>If there are multiple label candidates of a point-feature with the same ratio A/S c (this will happen most often when point-feature has several label candidates without conflicts), then we prefer the label candidate with the lowest ambiguity. We evaluate the ambiguity of label candidate l as a ratio of the area of the label A to the sum of ambiguity S a inside of the label candidate. The sum of ambiguity is similar to the sum of conflicts, but also considers the conflict rectangles of already labeled point-features. Please note that the higher the ratio, the lower the ambiguity. Again, A/S a = 1 only if the label candidate does not overlap the conflict rectangle of any other labeled or unlabeled point-feature. A label candidate with such a ratio is not ambiguous because it is not located in the proximity of any other point-feature. The lower the ratio A/S a , the closer is the label candidate to other point-features. In Figure <ref type="figure" target="#fig_2">3</ref>, we have depicted two label candidates with dashed lines in the conflict buffer and the ambiguity buffer in the algorithm's third iteration. The evaluation of the conflicts alone will not allow to prefer one of the candidates while the evaluation of ambiguity will. Choosing the label candidate further away from other point-features will make the label point-feature association easier. However, the evaluation of ambiguity usually will not improve the label layout in areas with densely packed point-features, as such pointfeatures typically will not have multiple label candidates with the same ratio A/S c .</p><p>If there are multiple label candidates of a point-feature with the same ratio A/S c and with the same ratio A/S a , then we prefer the label candidate with the highest preference.</p><p>Further, we use two rules of Wagner et al. <ref type="bibr" target="#b28">[30]</ref> to simplify the dependencies between the point-features. We have extended the second rule to consider the ambiguity of the label candidates. (1) If a pointfeature has only one available label candidate left, then we use the candidate, and the point-feature is assigned the highest priority possible.</p><p>(2) If a point-feature has label candidates that are not in conflict with any label candidate of any other point-feature, then we use the least ambiguous of the label candidates, and the point-feature is assigned second highest priority.</p><p>The first rule will have the following effect. In the processed quadrant of blocks, we will always label a point-feature f with only one available label candidate first. It is important to label the point-feature f as soon as possible because the space needed for the last available label candidate could be used by a label of another point-feature, and then we would not be able to label the point-feature f . The second rule allows to simplify the evaluation of conflicts between the label candidates. Please note that after a point-feature is labeled, its conflict rectangle is removed from the channel of the conflict buffer in the Summed Area Table of the evaluation buffer which increases the chance of finding new point-features with label candidates that are not in conflicts in the next iteration.</p><p>The complete algorithm is as follows:</p><p>1. Set the number of available candidates N = 8.</p><p>2. Set best conflicts c = 0.  Please note that in Step 4(c)i, we use the multiplication factor 0.9 to calculate the priority p to make sure that the priority of the pointfeature with the last available label candidate (Step 4d) is the highest. If there is no point-feature with the last available label candidate, then the multiplication will not have any effect on the resulting label layout.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Updating the Evaluation Buffer</head><p>In each iteration, after we have positioned a label for one point-feature in certain blocks, we need to update the information in the Summed Area Table of the evaluation buffer. One option is to remove the conflict rectangle of each labeled point-feature from the conflict buffer, add each positioned label into the label obstacles buffer, and calculate the Summed Area Table of the evaluation buffer again. Unfortunately, this approach leads to poor performance. Therefore, we update the Summed Area Table of the evaluation buffer directly.</p><p>To remove a conflict rectangle of a labeled point-feature from the conflict buffer, we need to subtract 1 from each pixel in the conflict buffer inside the conflict rectangle of the labeled point-feature. Based on this, we can update the Summed Area Table of the evaluation buffer directly.</p><p>First, let us consider a conflict rectangle that is completely inside of a single block. For such a conflict rectangle, we need to update the rectangle from the lower-left corner of the conflict rectangle to the top right corner of the block, see Figure <ref type="figure" target="#fig_8">7</ref>(a) for an example. We will denote the rectangle as update rectangle. For the sum S c in each pixel p in the update rectangle, we need to subtract the number of pixels C that are inside of the intersection of the positioned label and the rectangle with lower-left corner c 0 and top right corner p. In Figure <ref type="figure" target="#fig_9">8</ref>, we depict the intersection for four pixels in various quadrants of the update rectangle. To calculate the number of pixels C for each pixel p, we use the equation</p><formula xml:id="formula_5">C = ( min(x p , x c 1 ) − x c 0 ) • ( min(y p , y c 1 ) − y c 0 ). (<label>5</label></formula><formula xml:id="formula_6">)</formula><p>If we consider that the conflict rectangle overlaps two or four blocks, see Figures <ref type="figure" target="#fig_8">7(c</ref>), 7(b), and 7(d), all we need to do is to determine the update rectangle for each block, and for each update rectangle determine the positions of pixels c 0 and c 1 . We depict the positions for each update rectangle in Figure <ref type="figure" target="#fig_8">7</ref>. Then, we can use Equation <ref type="formula" target="#formula_5">5</ref>to update all pixels in each update rectangle.</p><p>Similarly, to update the obstacles buffer, we need to add 1 to each pixel in the obstacles buffer inside the label of the labeled point-feature. Based on this, we can again update the Summed Area Table of the evaluation buffer directly. The approach is the same as for the conflict rectangle, but instead of the conflict rectangle, we use the positioned label. Further, instead of subtracting from the S c in each pixel, we are adding to S l . Now let us discuss why we are calculating the Summed Area Table of the evaluation buffer for the individual blocks instead of for the whole  <ref type="table">.</ref> We depict the sum pixel p in four quadrants of the update rectangle.</p><p>buffer. Let us consider that the Summed Area Table was calculated for the whole buffer. In consequence, the update rectangles will be much larger. Each rectangle will be from the lower-left corner of the conflict rectangle (or the label) of the positioned point-feature to the top-right corner of the buffer. Therefore, we need to update many more pixels of the buffer. As a GPU has a fixed number of shader units, updating more pixels will result in sequential processing of several pixels by each shader unit, and thus the performance will decrease dramatically.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.6">Supporting Priority Groups of Point-Features</head><p>In many real-world situations, we have several groups of point-features with various priorities (e.g., capital cities and regular cities). To achieve this with the proposed method, we establish a list of the groups where the groups are sorted according to their priority in descending order. Then, we sequentially run the algorithm for each group. We recommend using the same grid of blocks for all runs of the algorithm.</p><p>For each run of the algorithm, we need to set up the obstacles buffer, conflict buffer, ambiguity buffer, and label obstacles buffer correctly. The conflict buffer should contain conflict rectangles of point-features that are only in the processed group. On the other hand, the ambiguity buffer should contain conflict rectangles of all point-features. This way, the algorithm will evaluate the ambiguity of label candidates with respect to all point-features. The label obstacles buffer should contain the labels positioned by all preceding runs of the algorithm. Finally, the obstacles buffer can be the same for all runs of the algorithm. Please note that by providing different obstacles buffer for each group of pointfeatures, we can control which important visual features will not be occluded by the labels of the point-features in the group. For example, the labels of capital cities cannot overlap other capital cities, but can overlap the regular cities and the regular cities cannot overlap both capital cities and other regular cities.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.7">Supporting Zoom and Pan</head><p>In interactive scenarios, users typically use zoom and pan to navigate in the environment (e.g. in a 2D map). During zooming and panning, the labeling of the point-features needs to be consistent. Been et al. <ref type="bibr" target="#b1">[2]</ref> provide four rules for consistent point-feature labeling: (R1) labels are not vanishing when zooming in or appearing when zooming out, (R2) position and size of a label is changing continuously under the pan and zoom operations, (R3) labels are not vanishing or appearing during panning, and (R4) the placement of any label is a function of the current zoom and pan state (i.e., it is not influenced by previous states).</p><p>In order to support the zoom and pan scenario and fulfill all the rules for consistent labeling, we need to sequentially calculate the label layout of point-features at increasing discrete zoom levels. Further, for each point-feature we need to store the zoom level z l at which its label   The number of positioned labels in dependence on the resolution of the obstacles buffer (d), the number of point-features in the dataset (e), and the font size (f). In charts (a) and (d), we show on the x axis only the width of the obstacles buffer as the size of the buffer was always in the 4 : 3 ratio.</p><p>was positioned. Please note that during the label layout calculation, we do not scale up the environment. Instead, with the increasing zoom level, we scale down the labels with 1/z l .</p><p>We start with zoom level z l = 1 and subsequently multiply the zoom level z l with zoom factor z f until the desired maximum zoom level is reached. In our case, we are using zoom factor z f = 1.05. Before we calculate the label layout for zoom level z l &gt; 1, we render the labels of point-features labeled on lower zoom levels to the label obstacles buffer and calculate label positions only for the remaining point-features.</p><p>Finally, during the rendering of the labels, we render only the labels with zoom level z l ≤ z r , where z r is the rendering zoom level.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">RESULTS AND DISCUSSION</head><p>In this section, we present the results of the proposed method. Further, we compare the performance and the quality of the resulting label layouts of the proposed method with existing methods. To assess the quality of the resulting label layouts, we use the number of labeled point-features. For the comparison, we have used the implementation of the proposed method in Java and OpenGL.</p><p>We compare the proposed method with the available Java implementation <ref type="bibr" target="#b13">[15]</ref> of Particle-based labeling <ref type="bibr" target="#b14">[16]</ref>. For one dataset, we compare the proposed method also with the improved Particle-based labeling by Kittivorawong et al. <ref type="bibr" target="#b10">[12]</ref>. The comparison is made based on their reporting of performance improvement over Particle-based labeling for the particular dataset. To assess the impact of the greedy approach used in the proposed method on the number of labeled point-features, we compare the proposed method with the modified meta-heuristic method of Zoraster <ref type="bibr" target="#b31">[33]</ref> based on simulated annealing. We have modified the method to consider the obstacles buffer and eliminate label candidates that overlap the important visual features.</p><p>Please note that comparing the performance of the proposed method with existing methods is complicated as the proposed method is running on GPU while the existing methods are running on CPU. We have approached the comparison from the point of the end-user. Therefore, we have measured the performance of all methods on the same computer equipped with Intel Xeon E3-1275 V2 running at 3.5 GHz, 16 GB of RAM, and NVIDIA GeForce GTX 1660 Ti with 6 GB of RAM and 1536 unified shaders.</p><p>For the comparison, we also consider the visual representation of the point-features. In other words, each point-feature can be visually represented as a small circle, square, or any other shape. This is usual in visualization, geographic maps, geographic information systems, and many other areas. Please note that while we are rendering the point-features as small circles (or any other shape), we are still labeling them as points. To ensure that the labels will not overlap the visual representations of the point-features, the visual representations need to be treated as important visual features that the labels cannot overlap. Therefore, we provide the same obstacles buffer as an input to all compared methods.</p><p>First, we have measured the time needed to calculate the label layout and the number of positioned labels in dependency on the number of labeled point-features, on the precision with which we evaluate the overlaps with important visual features (e.g., the point-features rendered as small circles) and already placed labels, and on the size of the font used for the labels. Please note that in all compared methods, the precision depends on the resolution of the input obstacles buffer.</p><p>To measure the dependencies, we rendered the given number of pseudo-randomly distributed point-features into the obstacles buffer of the given resolution, calculated the sizes of the labels based on the given font, and provided the point-features together with the label sizes and the obstacles buffer as the input of all compared methods.</p><p>For each given number of point-features, we repeated the measurement 100 times, that is 10 times for each of the 10 variants of distributed point-features. From these measurements, we calculated the average computation time and the average number of positioned labels that we report. In the supplemental material, we depict a cut-out from one of the ten random datasets used for the performance test.</p><p>We depict the computation times of the methods and the number of positioned labels in dependency on the resolution of the input obstacles buffer in Figures <ref type="figure" target="#fig_11">9(a</ref>) and 9(d). The number of point-features was fixed at 2000. For the obstacles buffer resolution 1000 × 750, the font size was 8 pt. The font size was increasing with the increasing resolution of the obstacles buffer. This way, the same configuration of point-features and label candidates was evaluated but with increasing precision. Our measurement indicates that the computation time of the proposed method increases with the resolution of the obstacles buffer more slowly than the computation time of Particle-based labeling. For  the highest measured resolutions of the obstacles buffer, the proposed method needed 36% of the computation time of Particle-based labeling. We do not depict the computation time for the method of Zoraster as it required from 1 s for the resolution 1000 × 750 to 1.5 s for the resolution 8000 × 6000. Further, the proposed method positioned labels for more point-features than Particle-based labeling, but less than the method of Zoraster. Please note that the slight increase in the number of positioned labels with the increasing resolution of the obstacles buffer for all methods is due to the increasing precision of the evaluation.</p><p>In Figures <ref type="figure" target="#fig_11">9(b</ref>) and 9(e), we show the computation times of the methods and the number of positioned labels in dependency on the number of point-features. For this measurement, the resolution of the obstacles buffer was fixed at 4000 × 3000 and the font size was fixed at 8pt. The measurement indicates that while Particle-based labeling is faster for a lower number of point-features (n = 1000), the computation time of the proposed method increases with the number of point-features much more slowly than the computation time of Particlebased labeling. For the highest measured number of point-features, the proposed method needed only 3% of the computation time of Particlebased labeling. Particle-based labeling was faster for a lower number of point-features (n = 1000) due to the cost associated with the Summed Area Table calculation that is resolution-dependent. For higher numbers of point-features, the speed up in evaluation of the label candidates outweighs this cost. Again, we do not depict the computation time for the method of Zoraster as it required 0.9 s for 1000 point-features and 4.7 s for 8000 point-features. The proposed method positioned more labels in dependency on the number of point-features than Particlebased labeling, but less than the method of Zoraster. The reason for the decreasing number of positioned labels with the increasing number of point-features is less free space for the labels with the increasing number of point-features.</p><p>We depict the computation times of the methods and the number of positioned labels in dependency on the font size in Figures <ref type="figure" target="#fig_11">9(c</ref>) and 9(f). For this measurement, the resolution of the obstacles buffer was fixed at 2000 × 1500 and the number of point-features was fixed at 1000. The measurement indicates that the proposed method is slightly font-sizedependent. This comes from the fact that the number and dimensions of blocks are dependent on the font size. Particle-based labeling was faster for small fonts, but the computation time of the proposed method increased with the font size much more slowly than the computation time of Particle-based labeling. For the highest measured font size, the proposed method needed 38% of the computation time of Particlebased labeling. Again, we do not depict the computation time for the method of Zoraster as it required 0.8 s for the font size of 8 pt and 0.7 s for the font size of 32 pt. As expected, the number of positioned labels decreased with the increasing font size, as every label takes up more space. Still, the proposed method was able to position more labels than Particle-based labeling, but less than the method of Zoraster.</p><p>From the measurements, we can see that the performance of the proposed method decreases the most with the increasing resolution of the obstacles buffer. This is due to the calculation of the Summed Area Table, and its update as the performance of these steps decreases with increasing resolution of the obstacles buffer. For more details, please see the supplementary material.</p><p>Next, we have measured the computation time and the number of positioned labels on a real-world dataset of 3340 airports in the USA <ref type="bibr" target="#b25">[27]</ref>. For this dataset, we measured the computation time and the number of positioned labels in dependency on the resolution of the input obstacles buffer. Again the font size was decreasing or increasing with the resolution of the obstacles buffer to preserve the configuration of point-features and label candidates, but increase the precision of the evaluation. For the measurement, we have divided the input pointfeatures into two priority groups. In the first priority group were 56 airports with direct flights to Seattle-Tacoma airport. The remaining airports were in the second priority groups. The point-features in the first group were labeled with red font of size 26 pt. The point-features in the second group were labeled with black font of size 19 pt. These font sizes were used for the obstacles buffer resolution 4000 × 3000. Please see Figure <ref type="figure" target="#fig_13">10</ref>(a) for the result of the proposed method. The labels of the point-features in the first group (in red color) were not allowed to overlap the connecting lines and visual representations of the point-features in the first group. The labels of the point-features in the second group (in black color) were not allowed to overlap the connecting lines, visual representations of the point-features in both groups, and the boundaries of US states.</p><p>We depict the performance of the methods and the number of positioned labels in dependency on the resolution of the input obstacles buffer in Figures <ref type="figure" target="#fig_13">10(b</ref>) and 10(c). Our measurement indicates again that the computation time of the proposed method increases with the resolution of the obstacles buffer much more slowly than the computation time of Particle-based labeling. For the highest resolutions of the obstacles buffer, the proposed method needed 11% of the computation time of Particle-based labeling. Interestingly, the method of Zoraster was faster than Particle-based Labeling for the highest resolution. This was due to the extreme number of label candidates removed based on the obstacles buffer. The proposed method positioned labels for more point-features than Particle-based labeling, but less than the method of Zoraster. The slight increase in the number of positioned labels with the increasing resolution of the obstacles buffer for all methods is again due to the increasing precision of the evaluation. In Figure <ref type="figure" target="#fig_13">10</ref>(b), we also indicate the performance of the Fast Labels method by Kittivorawong et al. <ref type="bibr" target="#b10">[12]</ref> based on their reporting of a performance increase for the same dataset. The computation time of the proposed method increased with the resolution of the obstacles buffer much more slowly than the computation time of the Fast Labels method. Kittivorawong et al. <ref type="bibr" target="#b10">[12]</ref> report that the Fast Labels method positions labels of slightly fewer point-features than Particle-based labeling. Therefore, we can expect that the proposed method will position labels of more point-features than the Fast Labels method.</p><p>Further, we used the proposed method to support zoom and pan for the US airports dataset and the GapMinder dataset <ref type="bibr">[7]</ref>. The proposed method calculated label positions for all 62 zoom levels between 1 and 20 (zoom factor z f = 1.05) in 1644 ms for the US airports dataset and in 756 ms for the GapMinder dataset for the year 2008. Please see the supplementary material for images of the results and the supplementary video for the live capture of interaction with the results.</p><p>In Figure <ref type="figure" target="#fig_14">11</ref>, we demonstrate the effect of the evaluation of conflicts between the label candidates and the evaluation of ambiguity of the label candidates on the connected scatter-plot dataset <ref type="bibr" target="#b24">[26]</ref>. In Figure <ref type="figure" target="#fig_14">11</ref>(a), the labels were positioned without evaluating conflicts and ambiguity, the label candidates were evaluated based on overlaps with important visual features and already positioned labels and their preference. In the figure, we have magnified five areas (purple boxes) where the label layout can be improved (red boxes). In Figure <ref type="figure" target="#fig_14">11(b)</ref>, the labels were positioned based on overlaps, conflicts, and preference. The evaluation of conflicts between the label candidates improved the label layout in two of the five areas. In Figure <ref type="figure" target="#fig_14">11</ref>(c), labels were positioned based on the overlaps, conflicts, ambiguity, and preference. The evaluation of ambiguity of the label candidates further improved the label layout in two more areas. In the figure, we have highlighted with a red box the single problematic part of the label layout. As it can be seen, the evaluation of conflicts and ambiguity improves the label layout. Please note that the single problematic label for the year 1966 was not centered below the point-feature due to the overlapping conflict rectangles of the previous and next point-features in that region. In consequence, the algorithm considers such positions as more ambiguous.</p><p>To assess the impact of the evaluation of ambiguity on areas with densely positioned point-features, we labeled the US airports dataset with and without the evaluation of ambiguity. Please see the supplementary material for the results. The evaluation of ambiguity had a small effect on the resulting layout. In both cases, the proposed method positioned labels for the same 939 point-features, and only 13 labels were positioned at different positions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Limitations</head><p>In this section, we discuss the limitations of the proposed method. Foremost, it is a greedy algorithm that cannot recover from a local minimum/maximum. Therefore, we cannot guarantee that the algorithm finds the optimal solution nor that the found solution will be close to the optimal solution.</p><p>We are using the grid of blocks to label multiple point-features in each iteration. However, we cannot guarantee that a point-feature with a low priority from the processed quadrant will not use the space of a point-feature with a higher priority in the remaining quadrants. In consequence, this may lead to a lower number of labeled point-features. Fortunately, the evaluation of the conflicts and the ambiguity for each label candidate helps to decrease the problem.</p><p>The proposed method works well only with rectangular labels. Labels of different shapes (e.g., circles) need to be enclosed by rectangles which may lead to inefficient utilization of the space available for labels.</p><p>If the difference in the size between the smallest label and the largest label is large, then the used blocks may contain many small labels, which will lead to a higher number of iterations of the algorithm and to a decrease in performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">CONCLUSIONS AND FUTURE WORK</head><p>In this work, we propose a screen space greedy method to solve the point-feature labeling problem. In contrast to other existing methods, the proposed method positions labels of several point-features in parallel based on a grid of blocks. When determining the position of the label of a point-feature, the proposed method evaluates overlaps of the label candidates with important visual features and already positioned labels, conflicts of the label candidates with label candidates of other point-features, and ambiguity of the label candidates.</p><p>We have demonstrated that the proposed method supports pointfeatures divided into several priority groups, that the proposed method can be utilized in the zoom and pan scenario, and that the evaluation of conflicts and ambiguity of the label candidates improves the label layout. Further, we have compared the proposed method with Particlebased labeling of Luboschik et al. <ref type="bibr" target="#b14">[16]</ref> and with the modified metaheuristic method of Zoraster <ref type="bibr" target="#b31">[33]</ref>. Our measurements indicate that for the number of point-features greater than 1000 and the font size greater than 10 pt, the proposed method achieves significantly lower computation times while positioning labels for more point-features than Particle-based labeling, but fewer point-features than the modified meta-heuristic method of Zoraster.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. An illustration of four blocks b 00 , b 01 , b 10 , and b 11 and their quadrants.The quadrant of each block with quadrant id q = 1 is highlighted in gray color. Three point-features at extreme positions and their conflict rectangles are depicted in red color to show that in a worst-case, the conflict rectangles will touch but not overlap.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .</head><label>3</label><figDesc>Fig.3. An illustration of changes in the evaluation buffer during the first four iterations of the proposed algorithm. For each iteration we depict the obstacles buffer, the conflict buffer, the ambiguity buffer, and the label obstacles buffer. In the obstacles buffer, we indicate the processed quadrant with light red color and the labels positioned in the previous iterations. In the first iteration, a label of one point-feature is positioned. The conflict rectangle of the point-feature is removed from the conflict buffer, and the label is added to the label obstacles buffer.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Graphical overview of the proposed algorithm. Black nodes and arrows represent the state diagram of the algorithm. Inside each node, we depict the created buffers. Gray arrows incoming to a black node indicate that the node is reading from the buffer. A gray arrow outgoing from a black node indicates that the node is writing into the buffer. In the red circles, we provide the numbering of the steps in the description of the algorithm.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>5 .</head><label>5</label><figDesc>Do in parallel for each point-feature: (a) Draw the label on the screen.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. The pixels (highlighted in red color) of the Summed Area Table from which we need to read in order to calculate the sum of values in the rectangle contained in a single block (a), overlapping two blocks vertically (b), overlapping two blocks horizontally (a), and overlapping four blocks (d).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 6 .</head><label>6</label><figDesc>Fig.6. The sum of values (indicated with gray color) that is stored in a pixel (highlighted in red color) of the Summed Area Table.We depict the sum of values for the four pixels in the corners of a rectangle.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>3. Set best ambiguity a = 0. 4 .</head><label>4</label><figDesc>For each label candidate l: (a) Calculate area A of the label candidate. (b) Obtain the sum S = [S o , S c , S a , S l ] inside of the label candidate l from the Summed Area Table of the evaluation buffer. (c) If S o + S l = 0: i. If A/S c &gt; c or (A/S c = c and A/S a &gt; a): Set the label L = l, set the priority p = 0.9 • A/S c , set best conflicts c = A/S c , and set the best ambiguity a = A/S a . Otherwise: N = N − 1 (d) If N = 1: Set the priority p = 1.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 7 .</head><label>7</label><figDesc>Fig. 7. The update rectangles (in red, green, blue, and purple color) with highlighted pixels c 0 and c 1 for a conflict rectangle inside a single block (a), overlapping two blocks horizontally (b), overlapping two blocks vertically (c), and overlapping four blocks (d).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig. 8 .</head><label>8</label><figDesc>Fig.8. The sum of values (indicated with gray color) that is subtracted from pixel p in the update rectangle (red rectangle) when we are removing the conflict rectangle (black rectangle) of a labeled point-feature from the Summed Area Table.We depict the sum pixel p in four quadrants of the update rectangle.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Fig. 9 .</head><label>9</label><figDesc>Fig. 9. (top) The measured computation time in dependence on the resolution of the obstacles buffer (a), the number of point-features in the dataset (b), and the font size (c). (bottom)The number of positioned labels in dependence on the resolution of the obstacles buffer (d), the number of point-features in the dataset (e), and the font size (f). In charts (a) and (d), we show on the x axis only the width of the obstacles buffer as the size of the buffer was always in the 4 : 3 ratio.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Fig. 10 .</head><label>10</label><figDesc>Fig. 10. (a) The US airports dataset labeled with the proposed method. (b) The measured computation time in dependence on the resolution of the obstacles buffer. (c) The number of positioned labels in dependence on the resolution of the obstacles buffer.</figDesc><graphic coords="8,47.24,49.50,359.12,210.65" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>Fig. 11 .</head><label>11</label><figDesc>Fig.11. Connected scatter-plot dataset labeled with the proposed method. To evaluate the label candidates, we have used the overlaps and preference of the label candidates (a), the overlaps, conflicts, and preference of the label candidates (b), and the overlaps, conflicts, ambiguity, and preference of the label candidates (c).</figDesc><graphic coords="9,56.24,54.48,164.15,110.63" type="bitmap" /></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS</head></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Popmusic for the point feature label placement problem</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Alvim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">É</forename><forename type="middle">D</forename><surname>Taillard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">European Journal of Operational Research</title>
		<imprint>
			<biblScope unit="volume">192</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="396" to="413" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Dynamic map labeling</title>
		<author>
			<persName><forename type="first">K</forename><surname>Been</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Daiches</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Yap</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="773" to="780" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Application challenges to computational geometry</title>
		<author>
			<persName><forename type="first">B</forename><surname>Chazelle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Amenta</surname></persName>
		</author>
		<idno>TR-521-96</idno>
	</analytic>
	<monogr>
		<title level="j">Computational Geometry Impact Task Force</title>
		<imprint>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Mixed labeling: Integrating internal and external labels</title>
		<author>
			<persName><forename type="first">L</forename><surname>Čmolík</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Pavlovec</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ollenburg</surname></persName>
		</author>
		<idno type="DOI">10.1109/TVCG.2020.3027368</idno>
	</analytic>
	<monogr>
		<title level="m">IEEE Transactions on Visualization and Computer Graphics, Early access</title>
				<imprint>
			<biblScope unit="page">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Summed-area tables for texture mapping</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">C</forename><surname>Crow</surname></persName>
		</author>
		<idno type="DOI">10.1145/964965.808600</idno>
	</analytic>
	<monogr>
		<title level="j">SIGGRAPH Comput. Graph</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="207" to="212" />
			<date type="published" when="1984-01">Jan. 1984</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A packing problem with applications to lettering of maps</title>
		<author>
			<persName><forename type="first">M</forename><surname>Formann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Wagner</surname></persName>
		</author>
		<idno type="DOI">10.1145/109648.109680</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Seventh Annual Symposium on Computational Geometry, SCG &apos;91</title>
				<meeting>the Seventh Annual Symposium on Computational Geometry, SCG &apos;91<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="1991">1991</date>
			<biblScope unit="page" from="281" to="288" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A constructive genetic algorithm for discrete dispersion on point feature cartographic label placement problems</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">P</forename><surname>Gomes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">A N</forename><surname>Lorena</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">M</forename><surname>Ribeiro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Geographical Analysis</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="43" to="58" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Beyond maximum independent set: An extended model for point-feature label placement. International Archives of the Photogrammetry</title>
		<author>
			<persName><forename type="first">J.-H</forename><surname>Haunert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Wolff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Remote Sensing &amp; Spatial Information Sciences</title>
		<imprint>
			<biblScope unit="page">41</biblScope>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Fast summed-area table generation and its applications</title>
		<author>
			<persName><forename type="first">J</forename><surname>Hensley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Scheuermann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Coombe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Lastra</surname></persName>
		</author>
		<idno type="DOI">10.1111/j.1467-8659.2005.00880.x</idno>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics Forum</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="547" to="555" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Np-hardness of some map labeling problems</title>
		<author>
			<persName><forename type="first">C</forename><surname>Iturriaga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Lubiw</surname></persName>
		</author>
		<idno>CS-97-18</idno>
		<imprint>
			<date type="published" when="1997">1997</date>
			<pubPlace>Waterloo, ON, Canada</pubPlace>
		</imprint>
		<respStmt>
			<orgName>University of Waterloo</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Fast and flexible overlap detection for chart labeling with occupancy bitmap</title>
		<author>
			<persName><forename type="first">C</forename><surname>Kittivorawong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Moritz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Wongsuphasawat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Heer</surname></persName>
		</author>
		<idno>doi: 10. 1109/VIS47514.2020.00027</idno>
	</analytic>
	<monogr>
		<title level="m">2020 IEEE Visualization Conference (VIS)</title>
				<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="101" to="105" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Density-based label placement. The Visual Computer</title>
		<author>
			<persName><forename type="first">A</forename><surname>Lhuillier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Van Garderen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Weiskopf</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="1041" to="1052" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">A labeling model based on the region of movability for point-feature label placement</title>
		<author>
			<persName><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Kuai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Hu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ISPRS International Journal of Geo-Information</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page">159</biblScope>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Java implementatin of particle-based labeling</title>
		<author>
			<persName><forename type="first">M</forename><surname>Luboschik</surname></persName>
		</author>
		<ptr target="https://sourceforge.net/projects/fpf-labeling/" />
		<imprint>
			<biblScope unit="page" from="2021" to="2023" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Particle-based labeling: Fast point-feature labeling without obscuring other visual features</title>
		<author>
			<persName><forename type="first">M</forename><surname>Luboschik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Schumann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Cords</surname></persName>
		</author>
		<idno type="DOI">10.1109/TVCG.2008.152</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1237" to="1244" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Towards unambiguous map labeling-integer programming approach and heuristic algorithm</title>
		<author>
			<persName><forename type="first">A</forename><surname>Marın</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Pelegrın</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Expert Systems with Applications</title>
		<imprint>
			<biblScope unit="volume">98</biblScope>
			<biblScope unit="page" from="221" to="241" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">The computational complexity of cartographic label placement</title>
		<author>
			<persName><forename type="first">J</forename><surname>Marks</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Shieber</surname></persName>
		</author>
		<idno>TR-05-91</idno>
		<imprint>
			<date type="published" when="1991">1991</date>
			<pubPlace>Cambridge, MA, USA</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Harvard University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">A new mathematical model and a lagrangean decomposition for the point-feature cartographic label placement problem</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">R</forename><surname>Mauri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">M</forename><surname>Ribeiro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">A</forename><surname>Lorena</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computers &amp; Operations Research</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2164" to="2172" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Fast point-feature label placement for dynamic visualizations</title>
		<author>
			<persName><forename type="first">K</forename><surname>Mote</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Visualization</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="249" to="260" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Fast screen map labelingdata-structures and algorithms</title>
		<author>
			<persName><forename type="first">I</forename><surname>Petzold</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Gröger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Plümer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 21th Internat. Cartographic Conf.(ICC&apos;03)</title>
				<meeting>21th Internat. Cartographic Conf.(ICC&apos;03)</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="288" to="298" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">A clustering search metaheuristic for the point-feature cartographic label placement problem</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">L</forename><surname>Rabello</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">R</forename><surname>Mauri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">M</forename><surname>Ribeiro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">A N</forename><surname>Lorena</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">European Journal of Operational Research</title>
		<imprint>
			<biblScope unit="volume">234</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="802" to="808" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Letting ants labeling point features [sic.: for&apos;labeling&apos;read&apos;label</title>
		<author>
			<persName><forename type="first">M</forename><surname>Schreyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">R</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2002 Congress on Evolutionary Computation. CEC&apos;02 (Cat. No. 02TH8600)</title>
				<meeting>the 2002 Congress on Evolutionary Computation. CEC&apos;02 (Cat. No. 02TH8600)</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2002">2002</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1564" to="1569" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Dynamic queries for visual information seeking</title>
		<author>
			<persName><forename type="first">B</forename><surname>Shneiderman</surname></persName>
		</author>
		<idno type="DOI">10.1109/52.329404</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Software</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="70" to="77" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Algorithms for maximum independent set applied to map labelling</title>
		<author>
			<persName><forename type="first">T</forename><surname>Strijk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Verweij</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename></persName>
		</author>
		<idno>UU-CS-2000-22</idno>
		<imprint>
			<date type="published" when="2000">2000</date>
		</imprint>
		<respStmt>
			<orgName>Dept of Computer Science, Utrecht University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<ptr target="https://vega.github.io/editor/#/examples/vega/connected-scatter-plot" />
		<title level="m">UW Interactive Data Lab. Connected scatter-plot dataset</title>
				<imprint>
			<biblScope unit="page" from="2021" to="2023" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<ptr target="https://vega.github.io/editor/#/examples/vega-lite/geo_rule" />
		<title level="m">UW Interactive Data Lab. Us airports dataset</title>
				<imprint>
			<biblScope unit="page" from="2021" to="2023" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Using genetic algorithms for solving hard problems in gis</title>
		<author>
			<persName><forename type="first">S</forename><surname>Van Dijk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Thierens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M. De</forename><surname>Berg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">GeoInformatica</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="381" to="413" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Placing text labels on maps and diagrams using genetic algorithms with masking</title>
		<author>
			<persName><forename type="first">O</forename><forename type="middle">V</forename><surname>Verner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">L</forename><surname>Wainwright</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Schoenefeld</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">INFORMS Journal on Computing</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="266" to="275" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Three rules suffice for good label placement</title>
		<author>
			<persName><forename type="first">F</forename><surname>Wagner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Wolff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Kapoor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Strijk</surname></persName>
		</author>
		<idno>doi: 10.1007/ s00453-001-0009-7</idno>
	</analytic>
	<monogr>
		<title level="j">Algorithmica</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="334" to="349" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><surname>Wolff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Strijk</surname></persName>
		</author>
		<ptr target="http://i11www.iti.uni-karlsruhe.de/map-labeling/bibliography" />
		<title level="m">Map labeling bibliography</title>
				<imprint>
			<biblScope unit="page" from="2021" to="2023" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Tabu search heuristic for point-feature cartographic label placement</title>
		<author>
			<persName><forename type="first">M</forename><surname>Yamamoto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Camara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">A N</forename><surname>Lorena</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">GeoInformatica</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="77" to="90" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Practical results using simulated annealing for point feature label placement</title>
		<author>
			<persName><forename type="first">S</forename><surname>Zoraster</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cartography and Geographic Information Systems</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="228" to="238" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
