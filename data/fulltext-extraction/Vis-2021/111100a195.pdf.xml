<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">KG4Vis: A Knowledge Graph-Based Approach for Visualization Recommendation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Haotian</forename><surname>Li</surname></persName>
							<email>haotian.li@connect.ust.hk</email>
						</author>
						<author>
							<persName><forename type="first">Yong</forename><surname>Wang</surname></persName>
							<email>yongwang@smu.edu.sg</email>
						</author>
						<author>
							<persName><forename type="first">Songheng</forename><surname>Zhang</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Yangqiu</forename><surname>Song</surname></persName>
							<email>yqsong@cse.ust.hk</email>
						</author>
						<author>
							<persName><forename type="first">Huamin</forename><surname>Qu</surname></persName>
							<email>huamin@cse.ust.hk</email>
						</author>
						<author>
							<persName><forename type="first">•</forename><forename type="middle">H</forename><surname>Li</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<address>
									<country>United States Great Britain China Russia Germ any Japan Franc e South Korea Italy Austra lia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<address>
									<postCode>20 40 60</postCode>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="institution">Hong Kong University of Science and Technology and Singapore Management University</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="institution">Singapore Management University</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff4">
								<orgName type="institution">Singapore Management University</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff5">
								<orgName type="institution">Hong Kong University of Science and Technology</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">KG4Vis: A Knowledge Graph-Based Approach for Visualization Recommendation</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">53636014C1BB9316687DDE4172CC2769</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.1" ident="GROBID" when="2022-06-13T13:51+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Data visualization</term>
					<term>Visualization recommendation</term>
					<term>Knowledge graph</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Visualization recommendation or automatic visualization generation can significantly lower the barriers for general users to rapidly create effective data visualizations, especially for those users without a background in data visualizations. However, existing rule-based approaches require tedious manual specifications of visualization rules by visualization experts. Other machine learning-based approaches often work like black-box and are difficult to understand why a specific visualization is recommended, limiting the wider adoption of these approaches. This paper fills the gap by presenting KG4Vis, a knowledge graph (KG)-based approach for visualization recommendation. It does not require manual specifications of visualization rules and can also guarantee good explainability. Specifically, we propose a framework for building knowledge graphs, consisting of three types of entities (i.e., data features, data columns and visualization design choices) and the relations between them, to model the mapping rules between data and effective visualizations. A TransE-based embedding technique is employed to learn the embeddings of both entities and relations of the knowledge graph from existing dataset-visualization pairs. Such embeddings intrinsically model the desirable visualization rules. Then, given a new dataset, effective visualizations can be inferred from the knowledge graph with semantically meaningful rules. We conducted extensive evaluations to assess the proposed approach, including quantitative comparisons, case studies and expert interviews. The results demonstrate the effectiveness of our approach.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Fig. <ref type="figure">1</ref>. This figure illustrates the overall workflow of KG4Vis. We extract features from existing dataset-visualization pairs and construct a knowledge graph (KG). Then the embeddings of entities and relations in the KG are learned. Based on the embeddings, we conduct inference on a new dataset and finally recommend multiple visualizations. Also, various rules are extracted based on the embeddings and presented together with recommended visualizations to improve the interpretability of visualization recommendation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Data visualization can effectively facilitate data exploration, insight communication and decision making in various application domains such as business, scientific research, social media and journalism <ref type="bibr" target="#b30">[31,</ref><ref type="bibr" target="#b46">47]</ref>. However, transforming the input data to an effective visualization requires users to be familiar with both the input data and visualization tools. Many existing visualization tools have a steep learning curve <ref type="bibr" target="#b12">[13]</ref>. For example, the popular data visualization packages including D3 <ref type="bibr" target="#b4">[5]</ref>, Vega <ref type="bibr" target="#b36">[37]</ref> and ggplot2 <ref type="bibr" target="#b47">[48]</ref> require users to know programming languages (e.g., JavaScript and R) as well as the syntax of these packages. Those methods are often tedious and time-consuming for generating visualizations. Though dedicated visualization tools like Microsoft Excel or Google Spreadsheets are able to create standard charts by using templates, users still need to manually specify data attributes, and the mapping between them and the visual encodings. Also, these dedicated visualization tools offer limited expressiveness and customization. To address these challenges, researchers have proposed a series of techniques and tools to automatically generate or recommend effective visualizations for input datasets <ref type="bibr" target="#b41">[42,</ref><ref type="bibr" target="#b59">60]</ref>.</p><p>Existing techniques and tools for automated visualization design and recommendation mainly consist of two categories <ref type="bibr" target="#b18">[19]</ref>: rule-based approaches and machine learning (ML)-based approaches. Rule-based approaches, such as APT <ref type="bibr" target="#b26">[27]</ref>, SAGE <ref type="bibr" target="#b34">[35]</ref>, Show Me <ref type="bibr" target="#b27">[28]</ref>, SeeDB <ref type="bibr" target="#b39">[40]</ref> and Foresight <ref type="bibr" target="#b9">[10]</ref>, take into account the underlying data characteristics (e.g., statistical measures) and further leverage visualization principles or perceptual heuristics to automatically generate visualizations for analysts. Such rule-based approaches are also often augmented by supporting data variable selection and faceted browsing of recommended charts <ref type="bibr" target="#b48">[49,</ref><ref type="bibr" target="#b49">50]</ref>. These rule-based approaches are straightforward and intuitive to understand. However, they intrinsically suffer from limitations. For example, these approaches need an explicit list of rules and heuristics that often rely on expert judgment. It is difficult and tedious to compile a complete rule list due to the necessity of significant manual effort. Also, the rules may not be generalizable to different datasets or visualization choices. With the increase of the input data dimensions, there will be explosive combinations of visualization recommendations.</p><p>ML-based approaches (e.g., VizML <ref type="bibr" target="#b18">[19]</ref>, Data2Vis <ref type="bibr" target="#b12">[13]</ref>, and Deep-Drawing <ref type="bibr" target="#b44">[45]</ref>) often train a machine learning model (especially a deep learning model) to directly learn the visualization rules from examples of dataset-visualization pairs. For instance, Data2Vis <ref type="bibr" target="#b12">[13]</ref> leverages an LSTM-based neural translation model, which is trained on a Vega-Lite visualization corpus, to achieve the automatic generation of data visualizations. There has been an increasing trend to apply deep learning techniques to visualization generation and recommendation <ref type="bibr" target="#b41">[42,</ref><ref type="bibr" target="#b59">60]</ref>, since they do not require users to manually specify the rules of visualization recommendation. The contexts of the data and visualization are implicitly encoded by the trained models. However, these deep learning models often work as a black box <ref type="bibr" target="#b17">[18]</ref>. Thus, it is often difficult for users, to understand why a specific visualization is recommended, which further affects their trust in the recommended visualizations.</p><p>Motivated by the limitations of prior studies, we aim to achieve visualization recommendation that requires no manual specifications of visualization rules and also guarantees good explainability of the recommendations to general visualization users. It is a non-trivial task and little research has been conducted in this direction.</p><p>In this paper, we propose KG4Vis, a Knowledge Graph-based approach for Visualization recommendation. Similar to ML-based approaches for visualization recommendation, our approach also distills the rules for visualization design from existing examples such as the dataset-visualization pairs collected in VizML <ref type="bibr" target="#b18">[19]</ref>. Knowledge graphs are widely used in the natural language processing field for different purposes such as question answering and product recommendation <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b56">57]</ref> and have shown great potential in modeling the relationship between different entities (i.e., knowledge). Such knowledge is often semantically understandable to human users. Inspired by this, we explored how a knowledge graph can be constructed to model visualization rules and further apply it to achieve effective visualization recommendations. Specifically, we extract an extensive list of data features for each dataset and further build a knowledge graph based on three types of entities: data features, data columns and visualization design choices. The directed links between two types of entities indicate different semantic meanings, e.g., "(One feature) is a data feature of (a specific data column)", "(One data column) is visually encoded by (a specific visualization design choice)". Then, we employ TransE <ref type="bibr" target="#b3">[4]</ref> to learn the embeddings of both relations and entities by using the datasetvisualization pair examples. These embeddings essentially encode the visualization generation rules presented in the examples. Given a new dataset input, our approach can directly infer the relevant rules and recommend effective visualizations for the dataset, which intrinsically provides two desirable advantages. First, users can trace back to the relevant rules to understand why a specific visualization is recommended, thereby enhancing their trust in the visualization recommendations (explainability) and improving their knowledge of visualization principles. Also, the whole recommendation process is data-driven and fully automated (no manual specification of visualization rules).</p><p>We investigated the effectiveness and usability of our approach through both quantitative and qualitative evaluations. Specifically, to verify the knowledge graph model choice, we compared the visualization recommendation accuracy of knowledge graph models with that of other knowledge graph models. Further, we conducted in-depth interviews with 12 visualization experts to assess whether our recommendation rules and recommended visualizations are meaningful to human users. We also showcased the visualization recommendation rules and the recommended visualizations to provide support for the effectiveness of KG4Vis.</p><p>In summary, the major contributions of this paper are as follows:</p><p>• We present KG4Vis, a novel knowledge graph-based approach for visualization recommendation, which is essentially a datadriven approach and explainable to human users. To the best of our knowledge, this is the first time that a knowledge graph is employed to model visualization principles and recommend effective visualizations. • We conduct extensive evaluations, including qualitative comparisons with other models, case studies on different types of charts and in-depth expert interviews, which demonstrates the effectiveness and explainability of our approach. • We summarize the detailed lessons we have learned during the development of KG4Vis, which, we hope, can benefit subsequent work on applying knowledge graphs in the visualization field.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK</head><p>Our related work can be categorized into three groups: visualization recommendation, knowledge graph-based recommendation and knowledge graph embedding.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Visualization Recommendation</head><p>Visualization has been widely used for exploratory data analysis and decision making in various domains including stock trading <ref type="bibr" target="#b38">[39]</ref>, online education <ref type="bibr" target="#b22">[23]</ref> and urban planning <ref type="bibr" target="#b14">[15]</ref>. However, most existing tools for creating visualizations heavily rely on users' manual specifications <ref type="bibr" target="#b18">[19]</ref>. To facilitate visualization usage by users with no background of visualization, many researchers have recently explored the automated visualization recommendation using rule-based methods and machine learning (ML)-based methods <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b50">51]</ref>. Rule-based visualization recommendation methods are mainly based on manually-specified rules for mapping data to visual encodings according to previous studies on human perception on visualizations <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b20">21]</ref>. Representative studies include APT <ref type="bibr" target="#b26">[27]</ref>, SAGE <ref type="bibr" target="#b34">[35]</ref>, Show Me <ref type="bibr" target="#b27">[28]</ref> and Voyager2 <ref type="bibr" target="#b49">[50]</ref>. Though rule-based visualization recommendation methods have been widely studied their disadvantages are also obvious. Since the rules are proposed or summarized by humans, the effort of constructing a thorough list of rules is enormous and the following update of rules can be hard <ref type="bibr" target="#b33">[34]</ref>.</p><p>On the contrary, ML-based approaches have been investigated for visualization recommendation to address the limitation of rule-based methods. For example, DeepEye <ref type="bibr" target="#b25">[26]</ref> and Draco <ref type="bibr" target="#b29">[30]</ref> have been proposed to augment existing rules proposed by experts with learning the preference of visualizations and then ranking recommended visualizations. Hu et al. <ref type="bibr" target="#b18">[19]</ref> and Qian et al. <ref type="bibr" target="#b33">[34]</ref> fed features of datasets to Neural Networks (NNs) to infer how the datasets are represented by visualizations. These models have advanced the performance of visualization recommendations. However, these methods often use a deep learning approach and the "black-box" nature of these models makes it hard to interpret the recommended results.</p><p>In this paper, we aim to propose a visualization recommendation method based on a knowledge graph to leverage the advantages of both rule-based and ML-based methods. It can recommend satisfactory visualizations and also make the reasons behind the recommendations transparent to users by providing explainable recommendation rules.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Knowledge Graph-based Recommendation</head><p>Incorporating knowledge graphs (KGs) in recommender systems is an emerging research direction in recent years <ref type="bibr" target="#b15">[16]</ref>. KGs are structured representations of human knowledge and consist of entities and relations between entities <ref type="bibr" target="#b19">[20]</ref>. KG-based recommendation algorithms have two major advantages: effectively modeling different latent relations between entities <ref type="bibr" target="#b15">[16]</ref> and providing explainable recommendation results based on the graph structure <ref type="bibr" target="#b40">[41]</ref>. According to Guo et al. <ref type="bibr" target="#b15">[16]</ref>, there are mainly three types of methods for KG-based recommender systems, embedding-based methods <ref type="bibr" target="#b53">[54,</ref><ref type="bibr" target="#b56">57]</ref>, path-based methods <ref type="bibr" target="#b51">[52,</ref><ref type="bibr" target="#b58">59]</ref> and unified methods <ref type="bibr" target="#b40">[41,</ref><ref type="bibr" target="#b43">44]</ref>.</p><p>Among these three types of methods, our recommendation algorithm is closer to embedding-based methods. We explicitly learn the embeddings of entities and relations in our KG and conduct recommendations based on the embeddings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Knowledge Graph Embedding</head><p>Knowledge graph embedding (KGE) represents the entities and relations in a KG with low-dimensional embedding vectors so that various entities and relations can be easier to handle in downstream tasks <ref type="bibr" target="#b42">[43]</ref>, such as link prediction <ref type="bibr" target="#b37">[38,</ref><ref type="bibr" target="#b45">46]</ref> and triplet classification <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b45">46]</ref>.</p><p>According to prior studies <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b42">43]</ref>, KGE methods can mainly be categorized into 3 classes: translational models, tensor decomposition models and neural models. Translational models aim to model the relations between two entities as a translation in space. The most representative method under this category is TransE <ref type="bibr" target="#b3">[4]</ref>. It assumes that the embedding of a tail entity should be the sum of the embedding of a head entity and a translation vector which is the relation between them. A more detailed introduction to TransE is provided in Section 3. Following TransE, a series of translational methods have been proposed. For example, TransR <ref type="bibr" target="#b24">[25]</ref> represents relations in different spaces and conducts translation with a relation after projecting entities to the corresponding space. RotatE <ref type="bibr" target="#b37">[38]</ref> employs rotation in the complex space to represent relations between entities. Another class of KGE models aims to extract the embeddings of entities by applying tensor decomposition to model the graph structures <ref type="bibr" target="#b16">[17]</ref>, for example, RESCAL <ref type="bibr" target="#b31">[32]</ref> and DistMult <ref type="bibr" target="#b52">[53]</ref>. Recently, many neural models have also been proposed for KGE including SME <ref type="bibr" target="#b2">[3]</ref> and ConvE <ref type="bibr" target="#b11">[12]</ref>.</p><p>In our paper, due to its efficiency and intuitiveness, an improved version of the widely recognized embedding approach (i.e., TransE <ref type="bibr" target="#b3">[4]</ref>) is applied in our model to learning the embedding vectors of entities and relations in our KG.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">BACKGROUND: TRANSE</head><p>As introduced in Section 2.2, a KG represents human knowledge as a directed graph consisting of entities and relations. Each entity is represented as a node in the graph and each relation is an edge type. In the directed graph, each edge indicates the existence of a relation between two entities, i.e., the head entity and the tail entity. Thus, it is common to use a triplet, (head entity, relation,tail entity), to represent an edge, which can also be denoted as (h, r,t) in short. However, if a KG is represented with symbolic triplets, the manipulation can be hard <ref type="bibr" target="#b42">[43]</ref>. Thus, researchers propose knowledge graph embedding (KGE) to represent entities and relations in KGs as continuous embedding vectors. TransE <ref type="bibr" target="#b3">[4]</ref> is one of the most representative KGE methods with great efficiency and intuitiveness. In this paper, we leverage an approach based on TransE to learn the representations of various data features and visualization designs, as well as the relations between data features and visualization designs, which are further used to recommend appropriate visualizations. The basic idea of TransE is that the relation r between a head entity h and a tail entity t can be approximately represented by a translation from h to t. Suppose the embedding vectors of h, r,t are h, r, t, the relationship among them can be written as</p><formula xml:id="formula_0">h + r ≈ t,<label>(1)</label></formula><p>which is also illustrated in Fig. <ref type="figure" target="#fig_2">3</ref>(a). Thus, the scoring function that measures the possibility of a triplet's existence is defined as</p><formula xml:id="formula_1">g(h, r,t) = −||h + r − t|| 1/2 , (<label>2</label></formula><formula xml:id="formula_2">)</formula><p>where a larger score indicates that the triplet (h, r,t) tends to be plausible and the distance can be calculated by using either L1 or L2 distance.</p><p>With the scoring function of triplets, TransE applies a margin-based ranking criterion as the loss function in embedding learning:</p><formula xml:id="formula_3">L = ∑ (h ,r,t )∈S ReLU(γ + g(h, r,t) − g(h , r,t )),<label>(3)</label></formula><p>where γ &gt; 0 is a margin parameter and S and S denotes the set of training triplets and the set of negative triplets, respectively. Intuitively, we can consider the loss function which aims to make the difference between scores of training triplets and scores of negative triplets as large as possible. Here the negative triplets are generated by a random replacement of the head entity or the tail entity in a training triplet. In the training process, TransE applies gradient descent to minimize the loss and optimize the learned embeddings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">METHOD</head><p>KG4Vis consists of four major modules: feature extraction, KG construction, embedding learning, and embedding-based inference, as illustrated in Fig. <ref type="figure">1</ref>. First, we extract both data features and visualization design choices from dataset-visualization pairs (Section 4.1). Then, we propose building knowledge graphs to model the mapping from datasets to visualizations. Specifically, we define three types of entities (i.e., data features, data columns and visualization design choices) and the relations between them (Section 4.2). Further, we leverage the classic knowledge graph embedding approach TransE to represent the entities and relations with embedding vectors (Section 4.3). The final step of KG4Vis is to infer visualization design choices for a new dataset, where explicit visualization rules are also generated (Section 4.4).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Data Features and Visualization Design Choices</head><p>Inspired by VizML <ref type="bibr" target="#b18">[19]</ref>, we also extract data features of a dataset by quantifying the characteristics of its individual columns, where each column of the dataset is referred to as a data column in this paper. Specifically, we extract 81 data features introduced in VizML <ref type="bibr" target="#b18">[19]</ref>. These features include 50 continuous features and 31 categorical features. The data features of data columns are categorized into three classes: the data type of the data column (Types), the statistical features of values in the data column such as distribution and outliers (Values) and the name of the data column (Names). A detailed feature list is available in the supplementary material.</p><p>To visualize a given data column, the key visualization design choices are the type of the visualization and the axes where each data column is encoded. In our method, we limit our scope of recommended visualizations to six common types of 2-D visualizations: bar charts, box plots, heatmaps, histograms, line charts and scatter plots. In the rest of the paper, we will use bar, line, scatter, box, heatmap, and histogram to refer to them respectively for simplicity. Since these visualization types supported in our method are 2-D visualizations, the axes where the data is encoded are limited to horizontal and vertical axes, which are denoted as xand y-axis in the rest of our paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Knowledge Graph Construction</head><p>We build knowledge graphs (KGs) to model the complex mapping from data to visualizations. According to our survey, there are no existing studies on constructing knowledge graphs for visualization recommendations. We propose defining four types of entities and three types of relations among entities to delineate the mapping from a dataset to appropriate visualizations. By leveraging a large number of existing dataset-visualization pairs in real practice, our knowledge graphs can capture the widely-used visualization design principles. An overall description of the knowledge graph construction is shown in Fig. <ref type="figure">1</ref> and an example is shown in Fig. <ref type="figure" target="#fig_1">2</ref>. Definition of Entities. The first step of building our KG is to define the entities. Since the purpose of KG is to represent the relationship between data features, data columns and visualization design choices, they are naturally considered as entities in the KG. Generally, an entity in KG represents a categorical value, for example, a person or a place. Thus, a data column, a visualization design choice or a categorical data feature can be directly represented as an entity. However, defining the entities for continuous data features is challenging, since continuous features are hard to be handled by KG. One possible method is to assign each concrete value of a continuous data feature to an entity, for example, we create two entities to represent that the length of a data column is 5 and the length of a data column is 6, respectively. However, the number of entities will inflate and then the KG will become sparse since the number of possible concrete values is large and the number of edges between an entity of a value and entities of data columns will be small. Learning the embeddings of a sparse KG with an enormous number of entities can consume lots of computational power and the learned embeddings can be of low quality <ref type="bibr" target="#b57">[58]</ref>. Thus, we propose to divide each continuous data feature into different intervals, and regard each discretized continuous data feature with a specific value interval as an entity in the KG.</p><p>There are many commonly used discretization strategies such as KMeans discretization, uniform discretization and quantile discretization. However, they suffer from a common pitfall: these discretization methods only consider the distribution of values of all data points and cannot take extra information (e.g., predictive attributes) into consideration. Thus, inspired by Ming et al. <ref type="bibr" target="#b28">[29]</ref>, we apply a discretization method based on the minimum description length principle (MDLP) <ref type="bibr" target="#b13">[14]</ref> to discretize the continuous data features. With MDLP, the visualization type is able to be used as extra criteria when discretizing continuous data features. Besides the consideration of visualization types, it can automatically decide how many intervals are generated based on the distribution of data and the minimum size of each interval. This is another advantage of MDLP, especially compared with other approaches like KMeans, where the number of intervals should be explicitly given. With the discretized continuous data features generated by MDLP, we treat each interval of a feature as an entity. In summary, we overall have four classes of entities, visualization design choices (E V ), discretized continuous data features (E DF ), categorical data features (E CF ) and data columns (E D ). The detailed list of entities is available in Table <ref type="table" target="#tab_0">1</ref>.</p><p>Definition of Relations. After introducing four classes of entities, we further defined three classes of relations as shown in Table <ref type="table" target="#tab_0">1</ref>. First, we have a class of relations that connect data columns to visualization design choices (R D→V ) and represent "(one data column) is visually encoded with (a specific visualization design choice)". To be specific, there are two relations that belong to this class: 1) a data column (often together with other data column(s)) is visualized as a specific visualization type, e.g., bar; 2) a data column is encoded on the x-axis or y-axis. The complete list of this type of relations and corresponding entities is in the first section of Table <ref type="table" target="#tab_0">1</ref>. The second and third classes of relations both describe the mapping from data features to data columns. Thus, the semantic meaning of relations in these two classes can be described as "(one feature) is a data feature of (a specific data column)". The second class of relations are those linking categorical data features to data columns (R CF→D ). For this class of relations, we group the categorical data features according to their semantic meanings and construct 13 relations, for example, "the general data type of (one data column) is (categorical)". A detailed list of relations in this class is in the second section of Table <ref type="table" target="#tab_0">1</ref>. The third class of relations aim to model the mapping from discretized continuous data features to data columns (R DF→D ). We define a relation for each continuous feature and there are 50 relations in total, which is equal to the number of continuous features as described in Section 4.1. An example is "the number of unique values in (one data column) is (between 0 and 30)".</p><p>After defining the entities and relations, we extract triplets from existing dataset-visualization pairs. These triplets serve as the edges that link different entities to form a graph. For a data column d with its data feature set F d , a set of triplets are extracted as</p><formula xml:id="formula_4">{( f i , r i , d)| f i ∈ F d }, where r i ∈ R CF→D ∪ R DF→D is the corresponding relation from f i to d.</formula><p>Similarly, for the set of visualization design choices V d of the data column d, we extract another set of triplets {(d, r n , v n )|v n ∈ V d }. Thus, all the triplets associated with the data column d can be denoted as</p><formula xml:id="formula_5">{( f i , r i , d)| f i ∈ F d } ∪ {(d, r n , v n )|v n ∈ V d }.</formula><p>By combining the triplets associated with all the data columns, we gain the knowledge graph that will be used for visualization recommendation. The general data type of the data in the column is categorical, quantitative, temporal</p><p>The specific data type of the data in the column is string, integer, decimal, datetime</p><p>The name of the data column contains "x", "y", "time", digit, whitespace, "$","C", "£", " " Outlier exists in the column according to criteria </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Embedding Learning</head><p>In this section, learning to represent entities and relations by embedding vectors with TransE is introduced. The major advantage of using embeddings to represent entities and relations is that the manipulation of them in KG <ref type="bibr" target="#b42">[43]</ref> is convenient, which greatly benefits our subsequent inference and explicit rule generation.</p><p>In our approach, we adopt an improved TransE with self-adversarial negative sampling (denoted as TransE-adv) <ref type="bibr" target="#b37">[38]</ref> due to its efficiency and intuitiveness <ref type="bibr" target="#b42">[43]</ref>. The major advantage of adopting self-adversarial negative sampling is that it can effectively improve the learning efficiency by considering the current embedding model and eliminating obviously false triplets. According to Sun et al. <ref type="bibr" target="#b37">[38]</ref>, each negative sample is assigned a weight which indicates its probability of being true when using the current embeddings. The weight is calculated as</p><formula xml:id="formula_6">w h , r,t = exp(αg(h , r,t )) ∑ (h i ,r,t i )∈S exp(αg(h i , r,t i )) ,<label>(4)</label></formula><p>where (h , r,t ) is a negative sample, S is the collection of negative samples, α is the temperature of sampling <ref type="bibr" target="#b0">[1]</ref> and g is the scoring function. Based on the weight of negative samples, a negative sampling loss function is applied in the training of TransE-adv, which is as follows:</p><formula xml:id="formula_7">L = − log σ (γ − g(h, r,t)) − ∑ (h ,r,t )∈S w h , r,t log σ g(h , r,t ) − γ , (<label>5</label></formula><formula xml:id="formula_8">)</formula><p>where σ is the Sigmoid function and γ is the margin. The overall procedure of embedding learning in our approach is as below. First, the embeddings of entities and relations are initialized. Then in each step, we randomly sample a batch of training triplets and generate negative samples accordingly. Then a weight value is assigned to each negative sample according to Equation <ref type="formula" target="#formula_6">4</ref>. With the batch of training triplets and negative triplets, the loss of current embeddings is calculated as Equation <ref type="formula" target="#formula_7">5</ref>. Finally, the loss is used for the optimization of embeddings in each step.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Inference with Embeddings</head><p>In the previous step, the embeddings of entities and relations in the KG are learned. In this section, we introduce the method of leveraging these embeddings to infer how to visually encode a new data column which has multiple data features.</p><p>As indicated by Equation <ref type="formula" target="#formula_0">1</ref>, the tail entity's approximate embedding equals the sum of the embedding of a given head entity and the embedding of the relation between them. Based on this assumption, we propose a method to infer the final visualization design choice of a data column in a new dataset. We first extract rules indicating the mapping from data features to visualization design choices. Then, we aggregate all the rules to decide the final visualization design choices.</p><p>Here each rule has a structure like "If the data column has {a data feature}, then the data column can be represented by {a visual design choice}", where the data feature refers to a categorical feature or a discretized continuous feature. For the rest of this paper, each rule will be denoted as "a data feature → a visual design choice" for simplicity. In each rule, the part before "→", i.e., "a data feature", is also called the condition of the rule. To derive such kind of rules from KG with embeddings, for each data feature entity f i ∈ E DF ∪ E CF , we conduct translations twice. The first translation is to approximate the embedding of an imaginary data column d im which is only connected by f i . The embedding of d im is computed as f i + r j , where r j is the embedding of the relation connects f i to d im . The second translation is to infer how d im will be visually represented under a specific relation r target ∈ R D→V by computing f i + r j + r target . After two translations, we can extract a rule as f i → v n with a score defined as follows:</p><formula xml:id="formula_9">g f i →v n = −||f i + r j + r target − v n ||, (<label>6</label></formula><formula xml:id="formula_10">)</formula><p>which indicates how much v n is preferred given f i . More specifically, the rule also reflects the possibility that f i → v n is correct. Then, by using the rules, we can calculate the average score of all the relations that link a data feature f i ∈ F new to a design choice v n as follows:</p><formula xml:id="formula_11">g(d new , r target , v n ) =<label>1</label></formula><formula xml:id="formula_12">|F new | ∑ f i ∈F new g f i →v n . (<label>7</label></formula><formula xml:id="formula_13">)</formula><p>This computation can also be viewed as an aggregation of all rules whose conditions are fulfilled by the current data column. Then, for every visualization design choice, the aggregation is computed to get the score of recommending it. After obtaining scores of all possible design choices, we compare them and select the visualization choice with the highest score as the inferred visualization choice for d new . For example, when we decide whether d new should be encoded on which axis, g(d new , r axis , v x−axis ) and g(d new , r axis , v y−axis ) can be computed with Equation <ref type="formula" target="#formula_12">7</ref>. If g(d new , r axis , v y−axis ) &gt; g(d new , r axis , v x−axis ), then we recommend to encode d new on y-axis.</p><p>After inferring the visualization type and the axis that will be used for each data column, we need to collectively consider the inference results of all the columns of a dataset and further assemble valid visualizations for the dataset. Thus, we need to propose a set of post-processing rules according to the visualization grammar (e.g., Vega-lite and Plotly) to guarantee that valid visualizations are generated. For example, in Plotly, among all the six visualization types, box plots and histograms only require specifications on one axis while other types requires specifications on both x-axis and y-axis. Thus, if any data column in a dataset is inferred to be visualized in histogram or box plots, all columns will be visualized on either x-or y-axis. Otherwise, we plot all columns according to their inferred axes. Since our method will assign a score to different visualization choices (e.g., bar and line), it is possible for us to recommend several different visualizations with top k visualization choices according to their scores.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">EVALUATION</head><p>This section introduces the evaluation of our method from the following perspective: evaluation setup, quantitative evaluations and qualitative evaluations. Qualitative evaluations consist of case studies, expert interviews and a comparison between generated and empirical rules. The source code of KG4Vis, the visualization corpus used in the evaluations and the supplementary material are available in https://kg4vis.github.io/. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Evaluation Setup</head><p>The evaluation settings include the generation of our visualization corpus, the pre-processing and hyper-parameter setting for embedding learning, and the visualization generation settings.</p><p>Visualization Corpus. We used the VizML corpus <ref type="bibr" target="#b18">[19]</ref> for our evaluations. It contains around 120k dataset-visualization pairs. In this corpus, each visualization is generated by Plotly in JavaScript. According to VizML <ref type="bibr" target="#b18">[19]</ref>, users may slightly modify their datasets and create duplicated visualizations, so they randomly sample one dataset of each user to generate a corpus for evaluation. We followed the same sampling strategy of VizML and created a new corpus for our evaluation, which covers the datasets of six visualization types (i.e., bar, box, heatmap, histogram, line and scatter). Note dataset in this paper refers to a table consisting of multiple columns. The final corpus has 88,548 dataset-visualization pairs and 309,335 data columns in total.</p><p>Embedding Learning Setup. To learn the embeddings of entities and relations, we randomly selected 70% of our corpus as the training set. Then, we extracted features and conducted several steps of preprocessing. First, we removed invalid data columns, e.g., data columns without a visualization type. Then, we dealt with extreme values by using the 5% quantile and the 95% quantile of each continuous feature to replace values less than the 5% quantile or larger than the 95% quantile respectively. After pre-processing, a KG can be constructed on the training set by extracting entities, relations and triplets, as introduced in Section 4.2. To extract entities representing continuous data features, MDLP was applied to discretize each continuous data feature to several intervals. When applying MDLP, we set the minimum proportion of samples to split an interval to 0.1 and the minimum proportion of samples in an interval to 0.05 (i.e., at most each continuous feature can be split into 20 intervals). The reason why we selected these two values is that we need to strike a balance between performance and intuitiveness. When there are more intervals for a data feature, the recommendation results may be better. However, an excessive number of intervals for a data feature can be harmful to the interpretability of rules. Thus, we adopted the values above according to our empirical observation.</p><p>In our KG, there are in total 216,851 entities, 56 distinct relations and 9,679,463 triplets. Then, TransE-adv was applied on the KG to learn the embeddings for inference. All the embedding vectors of entities and relations have 1,000 dimensions following a previous study <ref type="bibr" target="#b37">[38]</ref> and were initialized using a uniform distribution. In the training process, the batch size of each epoch was 1,024 and the number of training steps was 30,000. The initial learning rate was set as 0.001. Following the study by Sun et al. <ref type="bibr" target="#b37">[38]</ref>, we chose Adam <ref type="bibr" target="#b21">[22]</ref> as the optimizer and L2 distance was applied in all the scoring functions in Equations 4 -7.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Bar</head><p>Values in a column is not sorted </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Bar</head><p>All values in a column are unique </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Line</head><p>Values are monotonic</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Line</head><p>The data type of a column is decimal</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Line</head><p>The column is not the only one in dataset </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Quantitative Evaluation</head><p>To evaluate our embedding learning method, we conducted experiments. As stated in Section 4.1, we have two major tasks: 1) the inference of visualization types and 2) the inference of axis to be encoded on for a data column. To make our evaluation reliable, we conducted a 5-fold cross-validation and report results of different methods.</p><p>Metrics. In our inference method, each visualization design choice is given a score and then ranked in descending order. Thus, to comprehensively evaluate our method, we utilized two widely used metrics, the average rank of correct design choices (denoted as MR) and the proportion of correct visualization design choices ranked in the top two inferred design choices (denoted as Hits@2) <ref type="bibr" target="#b3">[4]</ref> to evaluate the performance of visualization types. Since the inference on the axis is binary (i.e., either x-or y-axis), we evaluated it by accuracy.</p><p>Baseline Models. The baseline embedding learning models used in our quantitative evaluation were TransE and RotatE <ref type="bibr" target="#b37">[38]</ref>. TransE here refers to TransE without self-adversarial negative sampling. The reason why we selected TransE without self-adversarial negative sampling as a baseline is that we would like to confirm self-adversarial negative sampling can advance the performance of embedding learning by comparing TransE-adv with TransE. Another baseline model is Ro-tatE. By comparing TransE-adv with RotatE, we would like to make sure TransE-adv can achieve a satisfactory performance compared to one of the state-of-the-art KGE models. As introduced in Section 2.3, RotatE models the relationship between two entities as a rotation in the complex space and has a different scoring function which is defined as g(h, r,t) = h • r − t , where • indicates element-wise product. The inference method of KG4Vis can still apply to the embedding learned by RotatE by replacing the scoring function of TransE with that of RotatE.</p><p>Results. According to the results in Table <ref type="table" target="#tab_3">2</ref>, TransE-adv outperforms other embedding learning models on both visualization type inference and axis inference. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Qualitative Evaluation</head><p>In this section, we evaluate KG4Vis by conducting case studies, expert interviews and comparing the generated rules with empirical rules.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.1">Case Study</head><p>Fig. <ref type="figure" target="#fig_4">4</ref> shows several recommendation results and rules to illustrate the effectiveness of our approach and how rules can guide visualization recommendation. These recommended visualizations and rules were rated highly in our expert interviews. Rules in Fig. <ref type="figure" target="#fig_4">4</ref> are related to four types of visualization: scatter, box, line and bar. To make the original rules more understandable for general users, we translated those rules with complex statistical meanings to straightforward descriptions. For example, "the entropy of values is large → box" is used to describe that box plots are often used when the entropy of the data column values falls in the discretized interval that corresponds to a large entropy. When dealing with the rules with simple categorical features, we followed the structure introduced in Section 4.4 to generate rules such as "values in a column are numerical → scatter", which means "if the values in the data column are numerical, then the data column can be represented by scatter". Scatter Plots. The first two rules regarding scatter are straightforward. As suggested in <ref type="bibr" target="#b27">[28]</ref>, scatter should be recommended when two columns of data are both numerical. It is also a common practice to use scatter to identify anomalies, which verifies our rule "if outliers are detected in a column with the 1.5IQR rule, then the column can be visualized by scatter". This rule also matches conclusions in an empirical study <ref type="bibr" target="#b35">[36]</ref>, as will be further discussed in Section 5.3.3.</p><p>Box Plots. Then we present two rules related to box plots. They both reflect how values in a data column are distributed. These rules are out of expectation but make sense. It has been seldom proposed that the values represented by box plots are not evenly distributed. However, it is a reasonable rule. Box plots are often used to help discover and present the characteristic of data distribution. In most cases, we care more about the distribution of data when it is not evenly distributed. Thus, as our examples in Fig. <ref type="figure" target="#fig_4">4(c)-(d</ref>) demonstrate, it is suitable to recommend box plot to users when the data is not evenly distributed. The other rule "the entropy of values is large → box" indicates that In other words, the values represented by box plots are often disordered. This rule is also reasonable as it is not quite meaningful to inspect values' distribution if these values are too concentrated.</p><p>Line Charts. The next three rules show conditions to recommend a line chart as the visualization type for a data column. Since line charts are often applied on time series data, it is natural that the column representing time is monotonic and the data type of other columns is decimal. Also, according to <ref type="bibr" target="#b35">[36]</ref>, line is the best choice to represent the correlation between two series of data. Thus, the column which is supposed to be visualized by line charts should not be the only column in the dataset. These rules are also applied on both our generated visualizations in Fig. <ref type="figure" target="#fig_4">4(e)-(f)</ref>.</p><p>Bar Charts. The last two rules for bar charts are also intuitive. When we use bar charts, an axis often represents a series of categorical data <ref type="bibr" target="#b27">[28]</ref> like countries or brands. It is quite common that these categorical values are unique, for example, the values on x-axes of our generated visualizations in Fig. <ref type="figure" target="#fig_4">4(g)-(h)</ref>. Furthermore, as the values shown in blue bars and red bars in Fig. <ref type="figure" target="#fig_4">4</ref>(g) suggest, the values represented by bars can often be unsorted.</p><p>These rules and visualizations show that our method can derive meaningful rules in a data-driven manner and then recommend appropriate visualizations. Furthermore, the unexpected but reasonable rules for box plots demonstrate that our method has the potential to help researchers identify implicit rules which map data features to appropriate visualization design choices.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.2">Expert Interviews</head><p>To further verify the effectiveness of recommended design choices and the correctness of generated rules, we conducted expert interviews.</p><p>Tasks. In our expert interviews, we designed three tasks to evaluate the quality of rules and recommended visualizations.</p><p>1. We presented the experts with the top five rules of each visualization type and asked them to give each rule a score ranging from 1 (the least reasonable) to 5 (the most reasonable). 2. The experts are presented with 30 datasets and the corresponding top two recommended visualizations by our approach. They were asked to give each recommended visualization a score ranging from 1 (the least reasonable) to 5 (the most reasonable). Here only the visualization type and the arrangement of x-and y-axes were required to be considered since other design choices (e.g., the position of the legend, color usage) are not in our scope. 3. We presented 30 datasets to experts and let them select the top two visualization types from all six types supported by our approach to visualize the current dataset. Among three tasks, Task 1 was designed to verify the correctness of individual rules on visualization types and Task 2 aimed to evaluate the overall quality of recommended visualizations including the visualization type and axes where data columns are encoded. Task 3 was a supplementary task to collect experts' preferred design choices. In all tasks, the sequences of visualization types or datasets were randomized.</p><p>Datasets. In our expert interviews, we presented 30 rules and 30 datasets to experts in total. In the selection of rules presented in Task 1, we first pruned rules of the same f i and only kept the strongest rule of each feature entity. To be more specific, after the pruning, we only kept rules with the top five highest scores in { f i → v n |v n ∈ all visualization types} for a specific f i . Then, we presented the top five rules for each visualization type to participants for verification. For Task 2 and Task 3, we randomly sampled 5 valid datasets for each visualization type. Here a valid dataset is defined as a dataset that can be correctly rendered by Plotly. In the questionnaire of our interview, we followed the study by Hu et al. <ref type="bibr" target="#b18">[19]</ref> to show a screenshot of the first 10 rows and the first 10 columns of each dataset to participants. For each dataset, we presented the top two recommended visualizations to experts since the mean rank of correct visualization types is about 2 according to Table <ref type="table" target="#tab_3">2</ref>. The recommended visualizations were exported as images with resolutions of 700 × 450.</p><p>Participants and Procedure. We invited 12 researchers (4 females, age mean = 25.42, age std = 1.93) who have conducted research in data visualization for at least 1 year. Due to the current COVID-19 pandemic, all expert interviews were conducted through online meetings. The length of an expert interview was about 1 hour. Before starting the interview, we collected experts' consent for collecting their feedback and recording audio. Each expert interview started with a 5-min brief introduction to our entire project. After that, experts were asked to finish the three tasks. For Task 2 and Task 3, to ensure that experts provide effective feedback for each question, they were only allowed to submit their answers on each dataset after 10 seconds. After finishing all three tasks, experts were asked to provide general comments on our approach including the advantages and disadvantages.</p><p>Feedback on the Generated Rules. Overall, our generated rules are appreciated by experts. An expert commented that "some rules are inspiring" and another expert said the rules are "straightforward and easy to understand". The rules with the highest average scores are shown in Fig. <ref type="figure" target="#fig_4">4</ref>. All the rules with the lowest (&lt; 2) average scores are shown in Table <ref type="table" target="#tab_4">3</ref>. In Table <ref type="table" target="#tab_4">3</ref>, we conclude that most of the rules with low scores are related to the names of columns, which also matches experts' comments, for example, "it is not suitable to use names of columns to decide how the column be visualized" and "hard to convince the column name's rule has a relationship with heatmap". After a careful inspection on these rules, we found that most of the rules related to column names are highly related to the grammar or the default setting of Plotly. Though they are useful in the prediction of visualization types on datasets crawled from Plotly, they may not be able to convince general users. For example, in our extracted rules, there are several rules related to Heatmap like the number of words in the column name, the number of characters in the column name and lack of uppercase in the column name. They truly make sense when the datasets are from Plotly since lots of datasets visualized by heatmaps have columns named using few lower-case letters such as "x" or "y". However, it is quite doubtful if these rules can be generalized to other datasets so our participants considered them as unreasonable rules. This type of unreasonable rules are mainly led by the characteristic of our dataset-visualization corpus and this issue will be further discussed in Section 6.1.2.</p><p>Feedback on Recommended Visualizations. According to experts' feedback, our recommended visualizations are thought to be of high quality and can lower the burden of manually creating visualizations when exploring the dataset and designing visualizations. For example, an expert concludes our approach as an "automated method to visualize dataset without human intervention, which can ease the human workload". In user interviews, we presented 2 recommended visualizations for each dataset and these visualizations are separately rated by experts. To evaluate the overall reasonable level of our recommendation on one dataset, we use the higher score between two scores of recommended visualizations on a dataset as the final score. The average final score of our recommendation is 3.7944, which shows that the experts think most of our recommended visualizations are reasonable. Detailed score distribution of visualization types is also shown in Fig. <ref type="figure" target="#fig_8">6</ref>. From Fig. <ref type="figure" target="#fig_8">6</ref>, we can learn that our approach performs well on bar, histogram, line and scatter but performs relatively worse on box and heatmap. The cases with the highest scores are shown in Fig. <ref type="figure" target="#fig_4">4</ref>.</p><p>To further understand sub-optimal recommended visualizations which are originally visualized by box plots and heatmaps, we checked these sub-optimal cases carefully and speculated that these datasets lack dominant features to determine their optimal visualization type and the visualization design choice of this dataset may depend on users' preference and analysis tasks. Fig. <ref type="figure" target="#fig_7">5</ref> illustrates a case which is originally visualized by a heatmap and got a low score in our expert interview.</p><p>To better analyze this failure case, we checked experts' preferred visualization type of this dataset in Task 3 and the results are shown in Fig. <ref type="figure" target="#fig_9">7</ref>. The results show that experts' opinion on the best type of visualization was quite inconsistent, which is also reflected by the entropy of selections. The entropy values of both the best and the second best visualization types are larger than average values (entropy top   To handle this kind of dataset, it is possible to further consider users' preferences and their specific tasks in our inference method to achieve better recommendation results, which is left as our future work.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.3">Comparison between Generated and Empirical Rules</head><p>One advantage of our method is that our recommendation results are explainable through a set of extracted rules and can be easily understood by users. So it is necessary to verify whether the extracted rules by our approach can align well with other empirical studies. According to our survey, Saket et al. <ref type="bibr" target="#b35">[36]</ref> have done a crowdsourced experiment to evaluate the effectiveness of five basic visualizations (i.e., table, line, bar, scatter, and pie) that has a large overlap of visualization types with our study. Therefore, we choose to compare the generated rules by our method with the empirical rules from this study. Three out of five general guidelines of this study <ref type="bibr" target="#b35">[36]</ref> are related to our research: 1. Bar charts are suitable for identifying clusters; 2. Line charts are appropriate when finding correlations; 3. Scatter plots should be used to find anomalies. We compare the rules above with our generated rules as follows:</p><p>Rule 1. The first rule above suggests that bar is the most effective visualization type to find clusters. Among all the data features defined in our approach, entropy is the feature that is more related to clusters. A larger entropy indicates that the data in the column is more disordered, meaning that the data probably does not have obvious clusters. Using the method described in Section 4.4, we generated rules which map the value of entropy to three visualization types (i.e., bar, line, scatter). The reason why only three visualization types are discussed is that the other three types of visualizations (i.e., box, heatmap, histogram) are not discussed in <ref type="bibr" target="#b35">[36]</ref>. The normalized scores of those rules are shown in Fig. <ref type="figure" target="#fig_10">8(a)</ref>. From the figure, we can notice that, among the three visualization types, bar is the best choice when entropy is low. Then along with the growth of entropy, scatter becomes the best choice and finally, line becomes the top choice among these three visualization types. Since a smaller entropy indicates more obvious clusters, our generated rule actually suggests that bar should be recommended when obvious clusters exist, which aligns well with Rule 1 of the prior study.</p><p>Rule 2. The second rule has been discussed in Section 5.3.1. This rule implies that there should be at least two data columns in the dataset when recommending a line chart, as correlation is defined for two variables. Such an idea is reflected in our extracted rule in Fig. <ref type="figure" target="#fig_4">4</ref>, i.e., "the column is not the only column in the dataset → line".</p><p>Rule 3. According to our learned rules shown in Fig. <ref type="figure" target="#fig_10">8</ref>(b), when there are outliers, scatter is always the most preferred visualization type among three common visualization types (i.e., bar, line and scatter), which is indicated by the highest normalized scores. Thus, the generated rules by KG4Vis also perfectly align with Rule 3. In summary, the above observations confirm that KG4Vis can extract reasonable rules that match empirical visualization guidelines.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">DISCUSSION</head><p>In this section, we summarize the lessons we learned during the development of KG4Vis and discuss the limitations of our approach.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Lessons</head><p>By modeling the relation between data features and effective visualizations, we have learned many lessons from building knowledge graphs for visualization recommendation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1.1">Knowledge Graph for Visualizations</head><p>Knowledge graph aims to build a structured form of human knowledge and has drawn great research attention from both the artificial intelligence (AI) research community and the industry <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b42">43]</ref>. However, little research has been done on building knowledge graphs for modeling the visualization design knowledge and common practices in real visualization applications. Our work is the first study along this direction. Two key steps have been crucial to the construction of knowledge graphs for visualization, i.e., KG construction and embedding learning.</p><p>Entity Construction. Entity construction in this paper aims to create entities to delineate continuous data features, which is intrinsically required by the structure of knowledge graphs. Those categorical data features (e.g., data attribute types) can be directly regarded as entities. But for data features with a continuous value, it is necessary to discretize them, so that they can be represented as entities which describe specific characteristics of a data feature, as discussed in Section 4.2. We employ the MDLP technique for the discretization of continuous data features, as it collectively considers both the distribution of each data feature and their overall correspondence with different visualization types. Before using MDLP, we also explored other techniques such as KMeans for feature discretization. But KMeans considers only the distribution of each individual feature, resulting in an inferior recommendation performance than MDLP. Thus, MDLP is finally chosen in our approach. Other advanced discretization techniques can be further explored, which, however, is beyond the major focus of this paper.</p><p>Embedding Learning. When developing KG4Vis, we have considered three types of embedding learning techniques including TransE, TransE-adv and RotatE and finally adopted TransE-adv. The reason why these three methods are considered is that these methods are widely recognized, efficient and intuitive. Compared with other models like TransR <ref type="bibr" target="#b24">[25]</ref> and RESCAL <ref type="bibr" target="#b31">[32]</ref>, these three models have lower time and space complexity <ref type="bibr" target="#b42">[43]</ref>. Also, their methods of modeling relations are intuitive. They model relations between entities as translation or rotation in the space. This can help users better interpret the learned embeddings and generated rules.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1.2">Data-driven Visualization Recommendation</head><p>Similar to the ML-based methods for visualization recommendation <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b18">19]</ref>, KG4Vis also learns from existing visualization examples and does not require users to manually specify a list of visualization rules. Our evaluations above have demonstrated the usefulness and effectiveness of KG4Vis. It benefits from two main perspectives and can be further improved: the corpus of dataset-visualization pairs and explainability. We will also further clarify its pros and cons compared with other visualization recommendation approaches in this section.</p><p>Corpus. KG4Vis is a data-driven approach for visualization recommendation, which intrinsically depends on dataset-visualization pairs. KG4Vis is built on the VizML corpus <ref type="bibr" target="#b18">[19]</ref> to construct knowledge graphs for visualizations. In the past few years, there has been an increasing number of open-sourced visualization corpora <ref type="bibr">[6-8, 11, 19, 33, 55]</ref>. These visualization corpora have made data-driven visualization recommendations or automated visualization designs feasible. On the other hand, we also noticed that these corpora suffer from some drawbacks, including the dependence on specific visualization grammar and limited visualization types, for example, the VizML corpus <ref type="bibr" target="#b18">[19]</ref> and the Vega-Lite corpus <ref type="bibr" target="#b32">[33]</ref>. More high-quality corpora with diverse visualization examples will further benefit the data-driven approaches for visualization recommendation.</p><p>Explainability. The visualization recommendations by KG4Vis can be explained by a set of rules, which is highly appreciated by users as shown in our user study. These rules explicitly inform users of common visualization practices and are helpful for users without a background of visualization to know why specific visualizations are recommended for a given dataset. Meanwhile, we also noticed two important issue within those rules that may hinder them from quickly understanding the rules: the feature complexity and the number of rule conditions. First, some data features are not that straightforward to general users who may have no knowledge of some data features. For example, our data features include the moments 1 of the distribution of a data column. The moments are used to describe the shape of data distribution and are widely applied in visualization recommendation approaches <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b18">19]</ref>. However, the detailed statistical meaning of moments may be unclear to some users and the related rules may confuse them. Thus, it may be necessary to strike a balance between expressiveness and intuitiveness when choosing data features. Also, how to present the rules to users in an automatic and more understandable way is worth further exploration.</p><p>Second, the number of conditions in one rule can also affect the intuitiveness and expressiveness of rules. A rule with multiple conditions is more expressive but less understandable for general users. Meanwhile, a rule with only one condition is more straightforward but not sufficient to capture the characteristics of data columns, negatively affecting the visualization recommendation. To address this issue, we have proposed the approach described in Section 4.4 to consider multiple conditions comprehensively by aggregating all the valid one-condition rules and further recommend visualization design choices. With this approach, we are able to present users with understandable rules with one condition and also guarantee an effective visualization recommendation.</p><p>Pros and Cons. Compared with existing rule-based and ML-based visualization recommendation methods, KG4Vis has its pros and cons. Compared with the rule-based methods (e.g., APT <ref type="bibr" target="#b26">[27]</ref>, Show Me <ref type="bibr" target="#b27">[28]</ref>), KG4Vis is also explainable, but has better extendability, since KG4Vis can derive rules automatically from an existing corpus of datasetvisualization pairs. Meanwhile, the corresponding limitation of KG4Vis is that the quality and coverage of the rules depend on the datasetvisualization corpus, as discussed previously. Similar to other MLbased methods (e.g., Data2Vis <ref type="bibr" target="#b12">[13]</ref>, VizML <ref type="bibr" target="#b18">[19]</ref>), KG4Vis can also achieve data-driven and real-time (average time is 0.07s per dataset) 1 https://en.wikipedia.org/wiki/Moment (mathematics) visualization recommendation for a new dataset. Furthermore, it guarantees the explainability of the recommendation by utilizing the derived rules. However, the performance of KG4Vis is slightly lower than the neural network used in VizML <ref type="bibr" target="#b18">[19]</ref> (MR of the visualization type is 1.7755), which can be further improved. The major reason may be that KG4Vis does not delineate non-linear relations between data features and design choices as well as neural networks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Limitations</head><p>Our evaluations in Section 5 have demonstrated the effectiveness of KG4Vis. However, it is not without limitations.</p><p>Limited Visualization Design Choices. For visualization design choices, we mainly consider the visualization types and the arrangement of x-/y-axes. However, there are more advanced visualization design choices when making charts, for example, the ratio of the chart and the usage of color. The major reason why we do not consider these design choices is as below. Some advanced design choices such as the usage of colors require more professional knowledge <ref type="bibr" target="#b55">[56]</ref>, which may not be able to be learned in the current corpus. For example, according to our observation, most of the visualizations in our corpus do not define colors explicitly and only use the default color scale of Plotly. To address this issue, some corpora containing other design choices can be used to augment the current KG. The KG used in KG4Vis can be easily extended by connecting the entities of data features, design choices and data columns. But when more data features and design choices are introduced, the number of triplets in the KG will grow linearly and a longer training time should be expected.</p><p>Evaluations. Though we have conducted extensive evaluations for our methods, one limitation of our evaluations is that we conduct interviews with only 12 experts. However, it is not very feasible to conduct our interviews at a larger scale, for example, using Amazon MTurk. The main reason is that participants are asked to verify the correctness of our generated rules, which requires that the participants should have enough knowledge in visualization design to judge the rules. Thus, we believe that this task is not suitable for MTurk workers, as they are not necessarily visualization experts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">CONCLUSION AND FUTURE WORK</head><p>We propose KG4Vis, a knowledge graph (KG)-based approach to achieve automated and explainable visualization recommendation, which can effectively capture the visualization knowledge from datasetvisualization pairs and provide users with meaningful rules to help them understand the visualization recommendation results. KG4Vis consists of four key modules: feature extraction, KG construction, embedding learning and embedding-based inference. First, expressive data features are extracted for dataset-visualization pairs. Then, we build a KG with three types of nodes, i.e., data features, data columns and visualization design choices. Further, TransE-adv is employed to learn the embeddings of entities and relations. Based on the learned embeddings, we finally propose an inference method that can recommend visualizations for new datasets and generate visualization rules for explaining the recommendation results. We conducted extensive evaluations to demonstrate the effectiveness of KG4Vis, including case studies, expert interviews and comparisons between the generated rules by our approach and empirical rules from a prior study.</p><p>In future work, we plan to explore how to incorporate cross-column features in our KG without increasing the need for computational power. Also, we would like to further investigate how to incorporate different user requirements and preferences to achieve personalized visualization recommendations to different users. Furthermore, it will be interesting to extend the proposed KG-based visualization recommendation approach to other types of visualizations such as infographics.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>jsts-quadtree p2-grid p2-grid rbush-bulk rbush-bulk rbush-incremental rbush-incremental box-intersect box-intersect brute-force brute-force p2-sweep p2-sweep simple-quadtree simple-quadtree jsts-strtree jsts-strtree Bar Values in a column is not sorted Box Values are not evenly distributed Line The column is not the only one in dataset Scatter Values in a column are numerical Histogram Outlier exists in a column (3Std) Data Columns</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. This figure shows an example of the transformation from a dataset-visualization pair to a part of the KG. Only a part of features and entities are shown. Red nodes represent visualization design choices. Blue nodes represent data columns. Green and yellow nodes represent discretized data features and continuous data features, respectively.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .</head><label>3</label><figDesc>This figure illustrates (a) TransE in 2-D space and (b) our inference method. In (a), two points, h and t, represent the embeddings of head and tail entities while vector r denotes the embedding of relation between two entities. The red arrow with two heads shows the distance ||h + r − t|| between h + r and t. In (b), each point is a 2-D embedding of an entity.f D 1f D 2 and f C 1f C2 represent two discretized continuous data features and two categorical data features of a new data column. r 1r 4 are relations connecting data features to data columns. v n is a visualization design choice connected by r target . v f s are the estimated embeddings of visualization design choices. Red arrows with two heads denote the distances between embeddings. g represents the scoring function.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. This figure shows a gallery of recommended visualizations in (a)-(h) and related rules with high scores. The listed rules are only a small subset of all rules applied in the recommendation of corresponding visualizations. Due to limited space, we only present rules of 4 visualization types, bar charts, box plots, line charts and scatter plots.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>1 = 1.4677, entropy top 2 = 1.6762, entropy top 1 mean = 0.9868, entropy top 2 mean = 1.4515).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. This figure shows (a) a sub-optimal recommended visualization identified in expert interviews and (b) the first 10 rows of its raw dataset.</figDesc><graphic coords="8,224.51,51.05,51.12,100.22" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 6 .</head><label>6</label><figDesc>Fig. 6. Average scores of recommended visualizations. The vertical lines on the top of the bars denote the standard deviation values.</figDesc><graphic coords="8,44.87,307.97,60.49,60.62" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig. 7 .</head><label>7</label><figDesc>Fig. 7. Experts' preferred visualization types of the dataset in Fig. 5(b).</figDesc><graphic coords="8,172.79,307.97,60.49,60.62" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Fig. 8 .</head><label>8</label><figDesc>Fig. 8. The two heatmaps show the normalized scores of rules about (a) entropy value and (b) outlier existence. Both heatmaps share the same y-axis and the same color scale. A higher score and a darker color mean the visualization type is more preferred. The values on the horizontal axis of (a) denote intervals of entropy values while the values on the horizontal axis of (b) represent different criteria of outlier detection.</figDesc><graphic coords="8,232.91,247.49,60.50,60.74" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>This table shows the definition of relations and their related entities. The first section presents R D→V and E V . The second section of the table illustrates R CF→D and E CF . The third section shows R DF→D and E DF . IQR is the interquartile range and Std is the standard deviation.</figDesc><table><row><cell>Class</cell><cell>Relations</cell><cell>Corresponding Entities</cell></row><row><cell>R D→V</cell><cell>Visualization type of the column is</cell><cell>bar, box, heatmap, histogram, line, scatter</cell></row><row><cell></cell><cell>The column is encoded on</cell><cell>x-axis, y-axis</cell></row><row><cell>R CF→D</cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 .</head><label>2</label><figDesc>This table shows the result of our quantitative evaluation on embedding learning methods. The best results are in bold. Overall, TransE-adv outperforms others. Among all metrics, a smaller MR indicates better performance while larger accuracy and Hits@2 are better.</figDesc><table><row><cell></cell><cell>Axis</cell><cell cols="2">Visualization Type</cell></row><row><cell></cell><cell>Accuracy</cell><cell>MR</cell><cell>Hits@2</cell></row><row><cell>TransE-adv</cell><cell>0.7350</cell><cell>1.9567</cell><cell>0.7489</cell></row><row><cell>TransE</cell><cell>0.7214</cell><cell>1.9718</cell><cell>0.7445</cell></row><row><cell>RotatE</cell><cell>0.7193</cell><cell>1.9608</cell><cell>0.7458</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3 .</head><label>3</label><figDesc>This table shows the five rules of the lowest scores. Most of the rules of low scores are related to the names of columns.</figDesc><table><row><cell>Feature</cell><cell>Type</cell><cell>Score</cell></row><row><cell>Only one word is in the column name.</cell><cell>Heatmap</cell><cell>1.3333</cell></row><row><cell>The column name is started with an lower case.</cell><cell>Heatmap</cell><cell>1.6667</cell></row><row><cell>The column name is less than 5 characters.</cell><cell>Heatmap</cell><cell>1.6667</cell></row><row><cell>No upper case is in the column name.</cell><cell>Heatmap</cell><cell>1.6667</cell></row><row><cell>A digit is in the the column name.</cell><cell>Scatter</cell><cell>1.8333</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS</head><p>This research was supported by the Singapore Ministry of Education (MOE) Academic Research Fund (AcRF) Tier 1 grant (Grant number: 20-C220-SMU-011). We would like to thank the experts in our expert interviews and anonymous reviewers for their feedback.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A learning algorithm for boltzmann machines</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">H</forename><surname>Ackley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">J</forename><surname>Sejnowski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognitive Science</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="147" to="169" />
			<date type="published" when="1985">1985</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Semiology of Graphics -Diagrams, Networks, Maps. ESRI</title>
		<author>
			<persName><forename type="first">J</forename><surname>Bertin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A semantic matching energy function for learning with multi-relational data -application to word-sense disambiguation</title>
		<author>
			<persName><forename type="first">A</forename><surname>Bordes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Glorot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning</title>
				<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="volume">94</biblScope>
			<biblScope unit="page" from="233" to="259" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Translating embeddings for modeling multi-relational data</title>
		<author>
			<persName><forename type="first">A</forename><surname>Bordes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Usunier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>García-Durán</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Yakhnenko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th Annual Conference on Neural Information Processing Systems</title>
				<meeting>the 27th Annual Conference on Neural Information Processing Systems</meeting>
		<imprint>
			<date type="published" when="2013">2013. 2013</date>
			<biblScope unit="page" from="2787" to="2795" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">D 3 data-driven documents</title>
		<author>
			<persName><forename type="first">M</forename><surname>Bostock</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Ogievetsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Heer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2301" to="2309" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Isenberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Isenberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sedlmair</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Moller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">S</forename><surname>Laramee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H.-W</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Wunsche</surname></persName>
		</author>
		<title level="m">A collection of figures and tables from ieee visualization conference publications. IEEE Transactions on Visualization and Computer Graphics</title>
				<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Composition and configuration patterns in multiple-view visualizations</title>
		<author>
			<persName><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">M</forename><surname>Al-Maneea</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1514" to="1524" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Towards automated infographic design: Deep learning-based auto-extraction of extensible timeline</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Qu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="917" to="926" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Graphical perception: Theory, experimentation, and application to the development of graphical methods</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">S</forename><surname>Cleveland</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Mcgill</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Statistical Association</title>
		<imprint>
			<biblScope unit="volume">79</biblScope>
			<biblScope unit="issue">387</biblScope>
			<biblScope unit="page" from="531" to="554" />
			<date type="published" when="1984">1984</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">¸</forename><surname>Demiralp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Haas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Parthasarathy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Pedapati</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1707.03877</idno>
		<title level="m">Foresight: Recommending visual insights</title>
				<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<author>
			<persName><forename type="first">D</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Shu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">F Y</forename><surname>Wu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2007.04584</idno>
		<title level="m">Visimages: A large-scale, high-quality image corpus in visualization publications</title>
				<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Convolutional 2d knowledge graph embeddings</title>
		<author>
			<persName><forename type="first">T</forename><surname>Dettmers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Minervini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Stenetorp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Riedel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 32nd AAAI Conference on Artificial Intelligence</title>
				<meeting>the 32nd AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="1811" to="1818" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Data2vis: Automatic generation of data visualizations using sequence-to-sequence recurrent neural networks</title>
		<author>
			<persName><forename type="first">V</forename><surname>Dibia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">¸</forename><surname>Demiralp</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer Graphics and Applications</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="33" to="46" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Multi-interval discretization of continuousvalued attributes for classification learning</title>
		<author>
			<persName><forename type="first">U</forename><forename type="middle">M</forename><surname>Fayyad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">B</forename><surname>Irani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th International Joint Conference on Artificial Intelligence</title>
				<meeting>the 13th International Joint Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="1993">1993</date>
			<biblScope unit="page" from="1022" to="1029" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Topology density map for urban data visualization and analysis</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Qu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="828" to="838" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">A survey on knowledge graph-based recommender systems</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Zhuang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>He</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003">2003.00911, 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">A</forename><surname>Hogan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Blomqvist</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Cochez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Amato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>De Melo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Gutierrez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E L</forename><surname>Gayo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kirrane</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Neumaier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Polleres</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2003.02320</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">Knowledge graphs. arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Visual analytics in deep learning: An interrogative survey for the next frontiers</title>
		<author>
			<persName><forename type="first">F</forename><surname>Hohman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kahng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Pienta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">H</forename><surname>Chau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="2674" to="2693" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Vizml: A machine learning approach to visualization recommendation</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">Z</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Bakker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Kraska</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A</forename><surname>Hidalgo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems</title>
				<meeting>the 2019 CHI Conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="1" to="12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">A survey on knowledge graphs: Representation, acquisition and applications</title>
		<author>
			<persName><forename type="first">S</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Cambria</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Marttinen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">S</forename><surname>Yu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002">2002.00388, 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Assessing effects of task and data distribution on the effectiveness of visual encodings</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Heer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics Forum</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="157" to="167" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 3rd International Conference on Learning Representations</title>
				<meeting>the 3rd International Conference on Learning Representations</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">A visual analytics approach to facilitate the proctoring of online exams</title>
		<author>
			<persName><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Qu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems</title>
				<meeting>the 2021 CHI Conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="1" to="17" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Kagnet: Knowledge-aware graph networks for commonsense reasoning</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Ren</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing</title>
				<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="2829" to="2839" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Learning entity and relation embeddings for knowledge graph completion</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 29th AAAI Conference on Artificial Intelligence</title>
				<meeting>the 29th AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="2181" to="2187" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Deepeye: Towards automatic data visualization</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 34th IEEE International Conference on Data Engineering</title>
				<meeting>the 34th IEEE International Conference on Data Engineering</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="101" to="112" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Automating the design of graphical presentations of relational information</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Mackinlay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Graphics</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="110" to="141" />
			<date type="published" when="1986">1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Show me: Automatic presentation for visual analysis</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Mackinlay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Hanrahan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Stolte</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1137" to="1144" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Rulematrix: Visualizing and understanding classifiers with rules</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Ming</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Bertini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="342" to="352" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Formalizing visualization design knowledge as constraints: Actionable and extensible models in draco</title>
		<author>
			<persName><forename type="first">D</forename><surname>Moritz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">L</forename><surname>Nelson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Howe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Heer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="438" to="448" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Visualization analysis and design</title>
		<author>
			<persName><forename type="first">T</forename><surname>Munzner</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014">2014</date>
			<publisher>CRC press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">A three-way model for collective learning on multi-relational data</title>
		<author>
			<persName><forename type="first">M</forename><surname>Nickel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Tresp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Kriegel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th International Conference on Machine Learning</title>
				<meeting>the 28th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="809" to="816" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Reverse-engineering visualizations: Recovering visual encodings from chart images</title>
		<author>
			<persName><forename type="first">J</forename><surname>Poco</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Heer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics Forum</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="353" to="363" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Ml-based visualization recommendation: Learning to recommend visualizations from data</title>
		<author>
			<persName><forename type="first">X</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Rossi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Koh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Malik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">Y</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Chan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009.12316, 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Interactive graphic design using automatic presentation knowledge</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">F</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kolojejchick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Mattis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Goldstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1994 CHI Conference on Human Factors in Computing Systems</title>
				<meeting>the 1994 CHI Conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<date type="published" when="1994">1994</date>
			<biblScope unit="page" from="112" to="117" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Task-based effectiveness of basic visualizations</title>
		<author>
			<persName><forename type="first">B</forename><surname>Saket</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Endert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">¸</forename><surname>Demiralp</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="2505" to="2512" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Reactive vega: A streaming dataflow architecture for declarative interactive visualization</title>
		<author>
			<persName><forename type="first">A</forename><surname>Satyanarayan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Russell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hoffswell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Heer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="659" to="668" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Rotate: Knowledge graph embedding by relational rotation in complex space</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 7th International Conference on Learning Representations</title>
				<meeting>the 7th International Conference on Learning Representations</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Tradao: A visual analytics system for trading algorithm optimization</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">W</forename><surname>Tsang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">M</forename><surname>Lam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Mu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Qu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 IEEE Visualization Conference</title>
				<meeting>the 2020 IEEE Visualization Conference</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="61" to="65" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Seedb: Efficient data-driven visualization recommendations to support visual analytics</title>
		<author>
			<persName><forename type="first">M</forename><surname>Vartak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Rahman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Madden</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Parameswaran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Polyzotis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the VLDB Endowment</title>
				<meeting>the VLDB Endowment</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="2182" to="2193" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Ripplenet: Propagating user preferences on the knowledge graph for recommender systems</title>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Guo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th ACM International Conference on Information and Knowledge Management</title>
				<meeting>the 27th ACM International Conference on Information and Knowledge Management</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="417" to="426" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">Applying machine learning advances to data visualization: A survey on ml4vis</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Qu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2012.00467</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Knowledge graph embedding: A survey of approaches and applications</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Guo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Knowledge and Data Engineering</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2724" to="2743" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">KGAT: knowledge graph attention network for recommendation</title>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Chua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</title>
				<meeting>the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="950" to="958" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Deepdrawing: A deep learning approach to graph drawing</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Qu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="676" to="686" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Knowledge graph embedding by translating on hyperplanes</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th AAAI Conference on Artificial Intelligence</title>
				<meeting>the 28th AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="1112" to="1119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title level="m" type="main">Interactive data visualization: foundations, techniques, and applications</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">O</forename><surname>Ward</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Grinstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Keim</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010">2010</date>
			<publisher>CRC Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">A layered grammar of graphics</title>
		<author>
			<persName><forename type="first">H</forename><surname>Wickham</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Computational and Graphical Statistics</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="3" to="28" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Voyager: Exploratory analysis via faceted browsing of visualization recommendations</title>
		<author>
			<persName><forename type="first">K</forename><surname>Wongsuphasawat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Moritz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Anand</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Mackinlay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Howe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Heer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="649" to="658" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Voyager 2: Augmenting visual analysis with partial view specifications</title>
		<author>
			<persName><forename type="first">K</forename><surname>Wongsuphasawat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Moritz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Ouk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Anand</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Mackinlay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Howe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Heer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems</title>
				<meeting>the 2017 CHI Conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="2648" to="2659" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Mobilevisfixer: Tailoring web visualizations for mobile phones leveraging an explainable reinforcement learning framework</title>
		<author>
			<persName><forename type="first">A</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Tong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Dwyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Isenberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Qu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="464" to="474" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Reinforcement knowledge graph reasoning for explainable recommendation</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Xian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Muthukrishnan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>De Melo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
				<meeting>the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="285" to="294" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Embedding entities and relations for learning and inference in knowledge bases</title>
		<author>
			<persName><forename type="first">B</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Yih</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Deng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 3rd International Conference on Learning Representations</title>
				<meeting>the 3rd International Conference on Learning Representations</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Bayes embedding (BEM): refining representation by integrating knowledge graphs and behavior-specific networks</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th ACM International Conference on Information and Knowledge Management</title>
				<meeting>the 28th ACM International Conference on Information and Knowledge Management</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="679" to="688" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<monogr>
		<author>
			<persName><forename type="first">L.-P</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C.-W</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Qu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2103.00741</idno>
		<title level="m">Deep colormap extraction from visualizations</title>
				<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b55">
	<monogr>
		<author>
			<persName><forename type="first">L.-P</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Qu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2102.02041</idno>
		<title level="m">Infocolorizer: Interactive recommendation of color palettes for infographics</title>
				<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Collaborative knowledge base embedding for recommender systems</title>
		<author>
			<persName><forename type="first">F</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">J</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Lian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</title>
				<meeting>the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="353" to="362" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Structure-augmented knowledge graph embedding for sparse data with rule learning</title>
		<author>
			<persName><forename type="first">F</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Jin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Communications</title>
		<imprint>
			<biblScope unit="volume">159</biblScope>
			<biblScope unit="page" from="271" to="278" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Meta-graph based recommendation fusion over heterogeneous information networks</title>
		<author>
			<persName><forename type="first">H</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">L</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</title>
				<meeting>the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="635" to="644" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">A survey on automatic infographics and visualization recommendations</title>
		<author>
			<persName><forename type="first">S</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Visual Informatics</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="24" to="40" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
