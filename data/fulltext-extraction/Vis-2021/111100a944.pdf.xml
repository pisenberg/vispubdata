<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Kineticharts: Augmenting Affective Expressiveness of Charts in Data Stories with Animation Design</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Xingyu</forename><surname>Lan</surname></persName>
							<email>xingyulan@tongji.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="laboratory">Intelligent Big Data Visualization Lab at Tongji University</orgName>
							</affiliation>
							<affiliation key="aff0">
								<orgName type="laboratory">Intelligent Big Data Visualization Lab at Tongji University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Yang</forename><surname>Shi</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Intelligent Big Data Visualization Lab at Tongji University</orgName>
							</affiliation>
							<affiliation key="aff0">
								<orgName type="laboratory">Intelligent Big Data Visualization Lab at Tongji University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Yanqiu</forename><surname>Wu</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Intelligent Big Data Visualization Lab at Tongji University</orgName>
							</affiliation>
							<affiliation key="aff0">
								<orgName type="laboratory">Intelligent Big Data Visualization Lab at Tongji University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Xiaohan</forename><surname>Jiao</surname></persName>
							<email>jiaoxiaohan.idvx@gmail.com</email>
							<affiliation key="aff0">
								<orgName type="laboratory">Intelligent Big Data Visualization Lab at Tongji University</orgName>
							</affiliation>
							<affiliation key="aff0">
								<orgName type="laboratory">Intelligent Big Data Visualization Lab at Tongji University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Nan</forename><surname>Cao</surname></persName>
							<email>nan.cao@gmail.com</email>
							<affiliation key="aff0">
								<orgName type="laboratory">Intelligent Big Data Visualization Lab at Tongji University</orgName>
							</affiliation>
							<affiliation key="aff0">
								<orgName type="laboratory">Intelligent Big Data Visualization Lab at Tongji University</orgName>
							</affiliation>
							<affiliation key="aff0">
								<orgName type="laboratory">Intelligent Big Data Visualization Lab at Tongji University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Kineticharts: Augmenting Affective Expressiveness of Charts in Data Stories with Animation Design</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">1A1291CA31AD3FD5F3409B7226625293</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.1" ident="GROBID" when="2022-06-13T13:59+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Animation</term>
					<term>Storytelling</term>
					<term>Affective Design</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Data stories often seek to elicit affective feelings from viewers. However, how to design affective data stories remains under-explored. In this work, we investigate one specific design factor, animation, and present Kineticharts, an animation design scheme for creating charts that express five positive affects: joy, amusement, surprise, tenderness, and excitement. These five affects were found to be frequently communicated through animation in data stories. Regarding each affect, we designed varied kinetic motions represented by bar charts, line charts, and pie charts, resulting in 60 animated charts for the five affects. We designed Kineticharts by first conducting a need-finding study with professional practitioners from data journalism and then analyzing a corpus of affective motion graphics to identify salient kinetic patterns. We evaluated Kineticharts through two user studies. The results suggest that Kineticharts can accurately convey affects, and improve the expressiveness of data stories, as well as enhance user engagement without hindering data comprehension compared to the animation design from DataClips, an authoring tool for data videos.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Recent years have witnessed an increasing prevalence of data-driven storytelling in various fields <ref type="bibr" target="#b71">[73,</ref><ref type="bibr" target="#b76">78]</ref>. To make data stories attractive, compelling, and attention-grabbing, designers and storytellers often seek to improve the affective expressiveness of their stories, namely to elicit emotions, moods, or feelings from viewers <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b42">43]</ref>. For example, a data story for entertainment should look fun <ref type="bibr" target="#b94">[96]</ref> while a story that calls for attention should make people feel surprised <ref type="bibr" target="#b58">[59]</ref>. Increasingly, researchers from the visualization community agree that it is critical to incorporate affective design into the creation of data stories <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b74">76,</ref><ref type="bibr" target="#b92">94]</ref>. Among numerous design factors, animation is one important and frequently-used technique to deliver affective information, as it helps enrich the meaning of motion, create a mood for storytelling, and make people more likely to become immersed in the storytelling process <ref type="bibr" target="#b51">[52,</ref><ref type="bibr" target="#b79">81,</ref><ref type="bibr" target="#b82">84]</ref>. For example, the Fallen of World War II <ref type="bibr" target="#b31">[32]</ref>, an award-winning data video that examines the victims of the war, uses animations such as zoom and pause to create suspense about the death toll and trigger surprise from a wide audience.</p><p>However, in the visualization community, prior work concerning animation has largely focused on how animation facilitates data transition and data analysis <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b72">74]</ref>, while recently, the role of animation as a powerful storytelling device has been highlighted. For example, Shi et al. <ref type="bibr" target="#b78">[80]</ref> introduced a design space that characterizes eight narrative strategies that animation can serve in data videos, such as emphasis and twist. Chevalier et al. <ref type="bibr" target="#b20">[21]</ref> summarized the roles played by animation and proposed that animation can be used to encode emotion and support story narratives. Fisher <ref type="bibr" target="#b28">[29]</ref> also stated that evoking affects can be a purpose of animation design. Nevertheless, as yet no systematic work has been done to investigate how to design affective animation for the charts in data stories. We still lack knowledge on which affects commonly found in data stories can be conveyed by animation, how to design animation for charts to appropriately express these affects, and what benefits such design can deliver.</p><p>To address these research questions, first, we conducted a preliminary study with nine experts from data journalism and 25 professional practitioners of data stories to understand their motivations to design affective animation, the possible pitfalls, and which affects should be designed for. As a result, we identified five affects, all of positive valence, that are likely to be communicated through animation in data stories: joy, amusement, surprise, tenderness, and excitement. Then, we collected a corpus of affective motion graphics using the search keywords of the identified affects and analyzed the animations by coding their design patterns. Based on these patterns, we designed Kineticharts, an animation design scheme for creating affective charts. Kineticharts are composed of five positive affects and three types of chart (bar charts, line charts, and pie charts), resulting in 60 animated charts in total. Last, we evaluated Kineticharts using two experiments. The first experiment was conducted with 80 participants to ensure that Kineticharts can convey the intended affects correctly. In the second crowdsourcing experiment with 197 participants, we applied Kineticharts to various data stories and compared Kineticharts with an alternative animation design used as a baseline with regard to data comprehension, story expressiveness, and affective engagement. The results of the experiment indicated that Kineticharts can significantly improve story expressiveness and affective engagement without hindering data comprehension compared to common animation techniques found in data videos authoring tools <ref type="bibr" target="#b2">[3]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK</head><p>In this section, we look back to previous research on affective design, designing data stories, and animation in visualization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Affective Design</head><p>Affective design is a user-centered design paradigm that aims to elicit users' affective responses, such as emotions, moods, and feelings <ref type="bibr" target="#b43">[44,</ref><ref type="bibr" target="#b46">47]</ref>. Since human beings are affective creatures <ref type="bibr" target="#b50">[51]</ref>, affect-inducing design is often felt more attractive, engaging, and interesting <ref type="bibr" target="#b66">[67,</ref><ref type="bibr" target="#b89">91]</ref>. There is also evidence that eliciting affects can enhance learning, improve memorability, and facilitate decisionmaking <ref type="bibr" target="#b26">[27,</ref><ref type="bibr" target="#b40">41,</ref><ref type="bibr" target="#b55">56]</ref>. To leverage such benefits, researchers from domains such as HCI <ref type="bibr" target="#b51">[52,</ref><ref type="bibr" target="#b79">81]</ref> and graphic design <ref type="bibr" target="#b89">[91]</ref> have been exploring how to design for affective responses. For example, researchers have found that static factors such as color <ref type="bibr" target="#b86">[88]</ref> and images <ref type="bibr" target="#b47">[48]</ref> can be affective. Some researchers, on the other hand, have looked into how dynamic elements such as animation elicit affects. As early as animation was born, cartoonists used animation to depict characters' affective states, and communicating affects is viewed as the core spirit of animation design <ref type="bibr" target="#b48">[49,</ref><ref type="bibr" target="#b82">84]</ref>. In the era of computer animation, such spirit has been introduced to the design of user interfaces, motion textures, and animated gifs to create affective systems or graphics <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b54">55,</ref><ref type="bibr" target="#b79">81,</ref><ref type="bibr" target="#b95">97]</ref>. In addition, more knowledge of affective science has been incorporated into affective design. For example, affects can be characterized as discrete categories <ref type="bibr" target="#b62">[63]</ref> or in a circumplex or the PAD space <ref type="bibr" target="#b61">[62,</ref><ref type="bibr" target="#b73">75]</ref>.</p><p>In the visualization community, although animation is a common device for data storytelling <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b81">83]</ref>, we still lack knowledge on how to design affective animation for the charts in data stories. Thus, this work introduces the idea of affective animation into data stories and explores how to design animated charts to convey five positive affects.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Designing Data Stories</head><p>Data stories combine visualization with storytelling techniques to facilitate data presentation and communicate the insights provided by the data <ref type="bibr" target="#b44">[45]</ref>. In recent years, more and more researchers have sought to understand how to design expressive data stories. Typical topics include the structure of data narratives <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b76">78]</ref>, visual embellishment <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b12">13]</ref>, and layout <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b15">16]</ref>. In addition, more measurements have been introduced to aid data story design from various perspectives, such as people's first impressions <ref type="bibr" target="#b34">[35]</ref>, memory <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b12">13]</ref>, and recall <ref type="bibr" target="#b11">[12]</ref>. Recently, affective feeling, as another important aspect of user experience with data stories, has been highlighted <ref type="bibr" target="#b42">[43,</ref><ref type="bibr" target="#b46">47,</ref><ref type="bibr" target="#b74">76,</ref><ref type="bibr" target="#b92">94]</ref> and used to evaluate data stories <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b93">95]</ref>. For example, Kennedy and Hill <ref type="bibr" target="#b42">[43]</ref> conducted an empirical study with 46 participants and found that emotion is an important constituent of everyday engagement with data.</p><p>However, while the importance of affects has been addressed, how to design affect-inducing data stories is still under-explored. Some studies have shed light on several design factors that may lead to affective feelings. For example, Bartram et al. <ref type="bibr" target="#b5">[6]</ref> proved that color can lead to different affects in visualizations. Boy et al. <ref type="bibr" target="#b13">[14]</ref> found that using human-like pictograms does not help elicit empathy when presenting human rights data. Lan et al. <ref type="bibr" target="#b46">[47]</ref> derived a set of affect-related design heuristics for infographics. Nevertheless, we still lack knowledge of how to evoke affects using animated charts. Thus, this work takes the first steps to explore how to design animated charts to express five positive affects in data stories.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Animation in Visualization</head><p>Animation, as the illusion of motion, plays various roles in design practice <ref type="bibr" target="#b20">[21]</ref>. In the visualization community, animation is a common technique to display the change in data mappings during data analysis <ref type="bibr" target="#b35">[36,</ref><ref type="bibr" target="#b72">74]</ref>. In this context, animation has been viewed as a doubleedged sword. While some researchers found that animation may hinder accurate perception <ref type="bibr" target="#b72">[74,</ref><ref type="bibr" target="#b85">87]</ref>, some has focused on how to utilize the benefits brought by animation <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b28">29]</ref>. In the context of storytelling, animation is more frequently viewed as a useful technique to support the narratives of data stories and keep users engaged <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b60">61,</ref><ref type="bibr" target="#b76">78,</ref><ref type="bibr" target="#b81">83]</ref>. One important reason is that animation is good at encoding affective messages and triggering affective feelings <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b22">23]</ref>. For example, Bach et al. <ref type="bibr" target="#b3">[4]</ref> observed that storytellers often use animation to express emotion in data stories. Shi et al. <ref type="bibr" target="#b78">[80]</ref> identified a set of storytellingrelated animation techniques in data videos. Some of them are designed to create suspense or surprise. Fisher <ref type="bibr" target="#b28">[29]</ref> also mentioned that animation can be designed to express affects such as happiness and sadness. He proposed that borrowing classic animation design principles from cartooning may bring new insights to visualization design.</p><p>While the above work has suggested animation's great potential to elicit affects in data stories, how to design affect-inducing animated charts remains under-explored. Therefore, we think that exploring the affective role of animation in data stories can be an important and timely complement to previous work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">NEED-FINDING STUDY</head><p>To start with, we conducted a need-finding study with professional practitioners experienced in data stories. The study contains two parts: First, we conducted in-depth interviews with nine domain experts to understand the motivations and pitfalls of designing affective animation for visualizations. Second, we sent a questionnaire to 25 professional practitioners of data stories to identify which affects in data stories are more likely to be conveyed by animation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Expert Interviews</head><p>By interviewing domain experts, we attempted to clarify two issues: (i) why affective animation design is needed by data stories and (ii) the pitfalls of designing affective animation for visualizations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.1">Procedure</head><p>We invited nine domain experts via social media platforms, including two data journalists (E1, E2 with three years experience writing data stories), one editor who is in charge of a data journalism channel (E3 with four years experience editing data stories), one scriptwriter of data videos (E4 with three years experience with data videos), three animators (E5, E6, E7 with six years, three years, and two years experience animating data videos), and two web designers (E8 and E9 with three years and four years experience designing interactive visualizations).</p><p>To start with, we introduced the key concepts (e.g., affective design, animation) in our research to the participants and asked for their consent to voice recording. Then, we interviewed the participants with a set of prepared questions, including "Do you think eliciting readers' affects is important for data stories?", "How would you design a visualization if you wanted to elicit affects?", "Do you think animation is a viable means of eliciting affects?", "If you wanted to design an affective animation for visualizations, what would you do? Any examples? (for designers)", "Did you meet any problems or challenges?". The questions were crafted by the lead author who was a data journalist and experienced in data storytelling. We also referred to the general guidelines for interviews <ref type="bibr" target="#b32">[33]</ref> (e.g., easy question first) to refine the questions. During the interview process, we asked follow-up questions if we found that the participants' answers were unclear or if we wanted to dig a little deeper. Each interview lasted approximately 30 minutes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.2">Analysis and Results</head><p>After the voice recordings were transcribed, we analyzed the transcriptions following a thematic analysis process <ref type="bibr" target="#b14">[15]</ref>. Two of the authors coded the transcriptions independently with the goal of finding answers to the two questions we were interested in, including the motivations and pitfalls of designing affective animation. Then, the coders met multiple sessions to compare codes, merge similar codes, and discuss mismatches until achieving consensus. Our findings are as follows:</p><p>Motivations All participants agreed that affective design is important for data stories, since many data stories are intentionally created to communicate affective messages such as surprising data facts to the audience. Besides, the participants thought that eliciting affects can engage the audience, make the story more memorable, and lead to more clicks and sharing. Common means of designing affective visualization include manipulating static features (e.g., color and embellishment) as well as dynamic features (e.g., animation). The participants also acknowledged that animation is an important component of affective design, especially for storytelling genres such as data videos and interactive web pages. Their reasons were summarized as follows:</p><p>Animation is a useful channel to encode affective messages. E5, E6, E8, and E9 mentioned that animation is a common visual channel to express affects. For example, E8 said that "animation can imitate living things as well as their feelings; when animated, even a square can look happy." E9 commented that "fast movement usually means positive feelings, while slow movement often relates to a negative vibe." E6 recalled his experience designing data videos and noted that "animation is a critical visual channel in data videos that definitely needs to be carefully designed; the animation design will decide the overall feeling of your story, for example, if a chart is bouncing, the story will look cheerful." E6 and E8 stated that animation, as a dynamic visual channel, is more eye-catching than static channels. For example, E8 said that "human eyes always like tracing moving objects; animated objects can quickly grab your attention among multiple visual elements, so I will give animation a high priority when doing affective design."</p><p>Affective animation creates a tone for data stories and enhances the presentation of data. Most participants (E1, E2, E4, E5, E6, E7, E9) mentioned that affective animation helps create an atmosphere for data stories and makes viewers feel more immersed in the content. For example, E5 said that "topics such as sports and gaming are exciting, so when I design animation for such stories, I usually use powerful motions to fit their themes." Similarly, E7 said that "animation design should match the tone of your story; when I design for stories that have a joyous tone, I'd make the visualization move in a joyous manner." E1 complemented that "affective animation can make people feel connected with the story and digest the data better."</p><p>Affective animation injects aesthetics and novelty into data stories. E3 and E8 talked about the aesthetic value of affective animation. E8 stated that "affective animation is like giving data a persona, making the visualization more human-like." E3 said, "I think affective animation is a good way to make the story more novel and interesting." Pitfalls While the experts all agreed on the benefits of applying affective animation into data stories, some also expressed their concerns, which we summarized as follows:</p><p>Animation is good at expressing limited types of affect. E1, E3, and E5 suggested that some affects can be more easily achieved by animation while some affects may ask for more complex design techniques. For example, E1 said, "I often want to elicit empathy from the audience, and I don't think animation alone can make it; photographs and narratives should also be integrated to do this job." E5 said that "designers need to decide which design techniques are most suitable for the story and prevent the wrong use of animation, which requires lots of experience. For example, to express negative feelings, I may rely more on design factors such as music and color."</p><p>Inappropriate animation design may distract users. E1, E7, and E9 noted that affective animation should be carefully designed. For instance, E1 said that "I want the animation to be engaging, but it should not be distracting." E7 referred to "chartjunk" <ref type="bibr" target="#b84">[86]</ref> and commented: "if the affective animation harms the clarity of visualization, I would say it is a chartjunk." However, what is an "appropriate" affective animation design remains unclear. For example, E1 said that "there are a lot of guidelines teaching me how to design emotion for cartoon characters, but I'm not quite sure how to apply these techniques to data visualizations." Thus, the participants anticipated a validated animation design scheme specifically for creating affective charts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Survey</head><p>As we have identified the necessity of designing affective animation, the next question is, which affects should be designed? We answer this question by first conducting a literature review and then sending a questionnaire to professional practitioners of data stories.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1">Study Material</head><p>We first conducted a literature review of previous studies. Since research about affective design is sparse in the visualization community, we expanded our survey to literature about visual storytelling. Specifically, we surveyed literature across various domains, and identified papers that study affects elicited by visual storytelling by conducting literature surveys, case studies, or user studies. These include works in visualization <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b42">43,</ref><ref type="bibr" target="#b92">94]</ref>, human-computer interaction <ref type="bibr" target="#b51">[52,</ref><ref type="bibr" target="#b52">53,</ref><ref type="bibr" target="#b70">72,</ref><ref type="bibr" target="#b90">92]</ref>, multimedia <ref type="bibr" target="#b30">[31,</ref><ref type="bibr" target="#b53">54,</ref><ref type="bibr" target="#b75">77,</ref><ref type="bibr" target="#b89">91,</ref><ref type="bibr" target="#b91">93,</ref><ref type="bibr" target="#b96">98]</ref>, advertising <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b25">26]</ref>, and communications studies <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b49">50,</ref><ref type="bibr" target="#b65">66,</ref><ref type="bibr" target="#b80">82]</ref>. We build on these prior works to compile an initial list of affects to consider in our research. During our analysis of the literature, we found that some affects have been frequently mentioned as the storytelling-related affects (e.g., joy, anger) while others were infrequently mentioned (e.g., shame). Therefore, we marked the affects mentioned by the 24 papers, merged synonyms <ref type="bibr" target="#b63">[64]</ref>, and counted the frequencies of the affects. The results showed that 14 affects had a frequency above one, including anger <ref type="bibr" target="#b12">(13)</ref>, fear <ref type="bibr" target="#b11">(12)</ref>, sadness <ref type="bibr" target="#b10">(11)</ref>, amusement <ref type="bibr" target="#b8">(9)</ref>, disgust <ref type="bibr" target="#b7">(8)</ref>, excitement <ref type="bibr" target="#b6">(7)</ref>, surprise <ref type="bibr" target="#b4">(5)</ref>, contentment (4), joy (4), awe (3), happiness (2), tenderness (2), seriousness (2), and empathy (2). Among the 14 affects, happiness is broad in connotation and can be split into joy and tenderness <ref type="bibr" target="#b91">[93,</ref><ref type="bibr" target="#b96">98]</ref>. Thus, we kept joy and tenderness and removed happiness from our list, resulting in 13 affects as possible candidates for affective animation design. The 13 affects include 7 positive affects and 6 negative affects. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2">Procedure and Results</head><p>Based on the identified affects, we conducted a survey with 25 participants (including the nine experts we interviewed). The 25 participants (17 female, aged from 23 to 34) were recruited via an open call on social media. In the open call, we mentioned that we were looking for people who have experience with data stories. We also sent the message to several chat groups concerning data journalism and data visualization. Among the 25 participants, seven are data journalists, three are data editors, two are scriptwriters, and 13 are visual designers or animators. All participants said that they have experience with data stories (1-3 years: 64%, 3-5 years: 28%, above 5 years: 8%). The participants were presented with an online questionnaire and were asked to: (i) provide their demographic information, (ii) choose and rank the affects (from the 13 affects) that are desired by data stories and explain reasons, and (iii) choose and rank the affects (from the 13 affects) that can be conveyed by animation in data stories and explain reasons. For question (iii), we also encouraged the participants to list specific story topics that tend to express the highly ranked affects. The ranking task allowed the participants to choose and rank any number of affects as they wanted. We also told the participants at the beginning of the questionnaire that if they could not find any proper choices, they could choose none of them.</p><p>We analyzed the ranking data by calculating the weighted average of each affect. Weights are applied in reverse. For example, the No.1 choice weights 13, and the No.2 choice weights 12. If an affect was not chosen, it earned a weight of 0. Therefore, the higher the weighted average, the more a choice is preferred. As a result, we found that not every affect rated high in terms of the desirability for data stories was rated high in terms of the possibility to be conveyed by animation (see Fig. <ref type="figure" target="#fig_0">1</ref>). For example, empathy, seriousness, and contentment, while desired by data stories, were thought not likely to be communicated through animation alone (e.g., "seriousness is a common goal of news reports but I don't think it is very related to animation.", "According to my experience, color and texts are good means of evoking empathy. Perhaps animation is also useful, but I think it should be used in company with color or texts."). Similarly, affects rated higher in terms of the possibility to be conveyed by animation may be rated lower in terms of the desirability for data stories (e.g., sadness, fear, anger). Therefore, we examined the intersection of the two rankings, removed the affects that ranked low in any of the two rankings, and identified five affects that are both desired by data stories and are likely to be conveyed by animation: joy, amusement, surprise, tenderness, and excitement (we discuss why they are all positive affects in Section 8). These five affects serve as our design goal in the next section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">DESIGNING AFFECTIVE ANIMATION</head><p>In this section, we present Kinecticharts, an animation design scheme for creating charts that express joy, amusement, surprise, tenderness, and excitement.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Methods</head><p>First, we proposed four principles to guide the design of Kinecticharts from a high level. Then, we collected a corpus of affective motion graphics that express the five positive affects (i.e., joy, amusement, surprise, tenderness, excitement) as design inspiration. Last, we distilled kinetic patterns from the corpus and designed Kinecticharts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.1">Design Principles</head><p>By reflecting on the motivations and pitfalls we identified in Section 3 and reviewing previous literature about visualization design and animation design, we identified four design principles for Kinecticharts: P1: Congruence. The animations should be meaningful and correspond to the semantics they carry <ref type="bibr" target="#b35">[36,</ref><ref type="bibr" target="#b85">87]</ref>. More specifically, the animations we design for Kinecticharts should deliver the five categories of affect successfully and accurately.</p><p>P2: Apprehension. The animations should present data clearly and should not confuse or overburden the viewers <ref type="bibr" target="#b35">[36,</ref><ref type="bibr" target="#b85">87]</ref>. To achieve this, the affective animations we design should support data comprehension and not be too exaggerated or distracting.</p><p>P3: Specificity. The animations designed for different affects should be distinguishable from one another. Since the representations of different affects may sometimes overlap <ref type="bibr" target="#b45">[46]</ref>, it is necessary to identify the typical motions of each affect during the design process.</p><p>P4: Generalizability. The animation design should be reusable <ref type="bibr" target="#b33">[34]</ref> and compatible with different data stories. In other words, the motions used to express affects should be generalizable and should not be constrained by conditions such as data sizes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.2">Design Inspirations</head><p>To design affective animation, we aimed to find the recurring kinetic patterns commonly used by animators to evoke the five types of affect (i.e., joy, amusement, surprise, tenderness, excitement). Thus, we collected a corpus of affective motion graphics from famous design platforms such as Pinterest and Dribbble by searching the keywords of these five positive affects. Motion graphics that came up in the searches for different affects were excluded. Then, two authors independently evaluated the quality of the motion graphics we collected to ensure that the motion graphics convey affects effectively (P1). For every motion graphic, if both of the authors agreed that it is effective in conveying the corresponding affect, we included it in our corpus. Otherwise, it is excluded. Finally, we collected 259 affective motion graphics (saved as GIF or MOV files), and each affect had more than 50 corresponding motion graphics. Fig. <ref type="figure">2</ref> shows some examples from our corpus.</p><p>To identify the kinetic patterns used to express the five affects, we coded the motion graphics from four aspects <ref type="bibr" target="#b78">[80,</ref><ref type="bibr" target="#b83">85]</ref>: (i) what is the motion of the main object? (ii) what is the motion of the camera? (iii) what is the motion of embellishment or symbols? and (iv) how is the timing? For example, Fig. <ref type="figure">2</ref> (a) uses repetitive jumps to express joy, and each jump lasts about 0.5 seconds. Fig. <ref type="figure">2 (c</ref>) uses a zoom-in camera effect to show surprise. Specifically, we adopted the methodology of open coding <ref type="bibr" target="#b64">[65]</ref>. The initial codes were grounded in and generated from the data. As more and more codes emerged, we grouped them into patterns. Two authors, including the lead author who is a visualization researcher and a co-author who is a visual designer, first coded the motion graphics independently. Then, we compared our codes, modified or dropped the codes until achieving a 100% agreement. For example, we found that the upward motion in Fig. <ref type="figure">2</ref> (e), a motion graphic that intends to express excitement, is similar to a jump. However, different from the jump of joy, which is more light and stretchy, the motion of excitement is more energetic and usually includes a process of accumulating power. Thus, we refined the code of jump in joy as bounce and described the upward motion of excitement as erupt to clarify their differences. We also identified some symbols used to express affects, such as blooming fireworks for joy, exclamation marks for surprise. However, these symbols are rich in semantic meanings, making it difficult to separate their motion from semantics. Therefore, we dropped these codes. Finally, the coding process yielded 23 kinetic patterns as the typical motions of the five affects.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.3">Design Process</head><p>Two co-authors who are professional visual designers started to design affective animation for visualization. After conducting a literature re-Fig. <ref type="figure">2</ref>. Examples of affective motion graphics: (a) joy <ref type="bibr" target="#b41">[42]</ref>, (b) amusement <ref type="bibr" target="#b36">[37]</ref>, (c) surprise <ref type="bibr" target="#b88">[90]</ref>, (d) tenderness <ref type="bibr" target="#b29">[30]</ref>, (e) excitement <ref type="bibr" target="#b57">[58]</ref>.</p><p>view as well as estimating the trade-off between design expressiveness and the workload of evaluation, we limited our design scope to the three most commonly used charts in data stories <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b77">79]</ref>: bar charts, line charts, and pie charts. The designers initially crafted animations for the charts according to the 23 patterns we identified. Then, the designers met four times to refine the design and discuss whether the animations violated our design principles. For example, we dropped a pattern called stretching the neck. Although it is a common body state of surprise, when being applied to charts, the data marks (e.g., bar, pie) will be stretched too exaggeratedly, thus violating P2. We also dropped two patterns called cheer and scamper, because both joy and excitement use these motions frequently, thus violating P3. Finally, 20 of our 23 patterns remained.</p><p>After the first version of Kineticharts was finished, we sent it to five experts, including three motion graphic designers who have more than five years experience designing motion graphics and two visualization researchers who specialize in data-driven storytelling and visualization design. By interviewing the three motion graphic designers, we aimed to polish the technical details of Kineticharts from aspects such as the obedience of the physical law and the smoothness of the animation. We interviewed the two visualization researchers to make sure that our animation design is appropriate for presenting data and will not lead to "chartjunk". Each interview lasted about 30 minutes, and we collected various suggestions. For example, one animation designer suggested we add more comical motion and stretchy effects to animations that express amusement. One visualization researcher suggested we improve the generalizability (P4) of the design by clarifying how the animations are bound with chart components such as visual marks. Following these suggestions, we refined our design and tagged each of the Kineticharts with five types of editorial layer <ref type="bibr" target="#b37">[38]</ref>, including chart marks, chart axes, chart as a whole, embellishment, and camera. These editorial layers are inspired by prior work <ref type="bibr" target="#b78">[80,</ref><ref type="bibr" target="#b83">85]</ref> that indicates which objects in a chart have been animated to communicate affective messages. Animations bound with chart marks or axes are likely to be transformed to charts that have identical marks or axes (e.g., from a line chart to an area chart). Effects such as embellishment and camera movement are independent of data mappings, so they are likely to be applied to all chart types.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Kineticharts</head><p>Kineticharts consist of two main dimensions: (i) five positive affects, including joy, amusement, surprise, tenderness, and excitement, and (ii) three charts, including bar charts, line charts, and pie charts (Fig. <ref type="figure" target="#fig_1">3</ref>). The dynamic version of Kineticharts tagged with editorial layers can be viewed at https://kineticharts.idvxlab.com/.</p><p>Joy Joy is a state when people feel delighted and pleasant. In data stories, joyous visual representations are often used to please people and echo topics such as vacations and entertainment. According to our observations, when expressing joy, animators usually use motion to mimic the body language of a joyous person and the overall pace of the motion is fast. Accordingly, in Kineticharts, we use three kinetic patterns to convey joy (Fig. <ref type="figure" target="#fig_1">3</ref> No. <ref type="bibr" target="#b0">[1]</ref><ref type="bibr" target="#b1">[2]</ref><ref type="bibr" target="#b2">[3]</ref><ref type="bibr" target="#b3">[4]</ref><ref type="bibr" target="#b4">[5]</ref><ref type="bibr" target="#b5">[6]</ref><ref type="bibr" target="#b6">[7]</ref><ref type="bibr" target="#b7">[8]</ref><ref type="bibr" target="#b8">[9]</ref>. The first pattern is bounce, which means jumping repeatedly up and down on springy objects. This is also the most common kinetic pattern in joyous motion graphics. Another frequently observed body language of joy is sway. In motion graphics, humans sway their bodies, heads, or hands to express joy, and dogs wag their tails. To mimic this body language, in Kineticharts, we let the marks sway from side to side when entering the scene. The third pattern is leap, which means jumping a long distance with force. In motion graphics, designers often let the character leap into the scene from the outside to show a joyous mood. Accordingly, in Kineticharts, the marks of the charts also leap in from the top-right corner of the scene and reach their positions along a curved trajectory.</p><p>Amusement Amusement is a state when people find something comic and humorous. Amusing data stories usually concern funny topics such as pets, kids, and anecdotes. By analyzing the motion graphics, we found that an important way to create amusement is to anthropomorphize the objects on the canvas and animate them like cartoon characters. Accordingly, we followed the guidelines from Disney animation <ref type="bibr" target="#b82">[84]</ref> and designed three kinetic patterns for amusement (Fig. <ref type="figure" target="#fig_1">3</ref> No.10-18). First, amusement can be achieved by mimicking the motion of cute creatures, such as the unsteady walk of babies and penguin shuffle. In Kineticharts, we let the chart components line up and move into the scene by dragging their "feet". Another common cause of amusement is to move one's body dramatically and rhythmically, such as to wiggle hips or arms. Thus, in Kineticharts, we let the chart components twist their "bodies" when entering the scene. The third pattern is collide. This pattern follows a common amusing plot in cartoons, that is to make a spectacle of someone, by letting the visual marks run into the chart, hit the axis, and collide with each other.</p><p>Surprise Surprise is an affect caused by unexpected events. In data stories, surprise usually happens when storytellers reveal some unusual or highly contrasting data facts to the audience. For example, Wealth Inequality in America [70] is a notable data video that triggers surprise by first introducing the ideal income distribution in the US and then revealing the actual situation. Our analysis of motion graphics also suggested that a sense of contrast is a critical contributor to surprise. Designers usually use visual contrast or timing contrast to elicit surprise. Accordingly, in Kineticharts, we use five kinetic patterns to convey surprise through contrast (Fig. <ref type="figure" target="#fig_1">3</ref> No. <ref type="bibr" target="#b18">[19]</ref><ref type="bibr" target="#b19">[20]</ref><ref type="bibr" target="#b20">[21]</ref><ref type="bibr" target="#b21">[22]</ref><ref type="bibr" target="#b22">[23]</ref><ref type="bibr" target="#b23">[24]</ref><ref type="bibr" target="#b24">[25]</ref><ref type="bibr" target="#b25">[26]</ref><ref type="bibr" target="#b26">[27]</ref><ref type="bibr" target="#b27">[28]</ref><ref type="bibr" target="#b28">[29]</ref><ref type="bibr" target="#b29">[30]</ref><ref type="bibr" target="#b30">[31]</ref><ref type="bibr" target="#b31">[32]</ref><ref type="bibr" target="#b32">[33]</ref>. The first pattern is unbox, which borrows a conventional scenario from daily life, namely unwrapping a gift box. In Kineticharts, we first hide the chart and then reveal it suddenly by opening their axes. Unveil, as another common pattern of surprise, mimics the process of removing the mask of something and then disclosing it. The third pattern of surprise is open, such as unzipping a cloth and pushing stage curtains aside. We recreate this process in Kineticharts by first covering the whole scene with a color block, then separating the block suddenly from its center. Fourth, camera language can also be used to express surprise. We found that in motion graphics, designers often convey surprise by quickly pulling the camera close to an object. In Kineticharts, we let the camera quickly zoom in to a certain data point after a short pause. Last, embellishment such as blink lines is often used to express surprise symbolically.</p><p>Tenderness Tenderness refers to gentleness and softness. In data stories, tenderness is often conveyed when the storytellers attempt to make people feel peaceful and relaxed. Typical topics include mental health, the beauty of nature, and social welfare. The most common patterns of tenderness in animation, as suggested by our coding process, include the use of a slow speed and the imitation of natural phenomena. Accordingly, four kinetic patterns were used to express tenderness in Kineticharts (Fig. <ref type="figure" target="#fig_1">3</ref> No. <ref type="bibr" target="#b33">[34]</ref><ref type="bibr" target="#b34">[35]</ref><ref type="bibr" target="#b35">[36]</ref><ref type="bibr" target="#b36">[37]</ref><ref type="bibr" target="#b37">[38]</ref><ref type="bibr" target="#b38">[39]</ref><ref type="bibr" target="#b39">[40]</ref><ref type="bibr" target="#b40">[41]</ref><ref type="bibr" target="#b41">[42]</ref><ref type="bibr" target="#b42">[43]</ref><ref type="bibr" target="#b43">[44]</ref><ref type="bibr" target="#b44">[45]</ref>. First, tenderness is often mapped to the imagery of smooth curves in motion graphics, such as flowing waves, curling up smoke, or fluttering curtains. Thus, in Kineticharts, we let the chart components undulate as if they are fluid. The second pattern, ripple, is imagery that reminds people of breezes and liquid. In Kineticharts, we imitate the physical appearance of a ripple by making a couple of small circles expand around the data points. Third, glow is a tender pattern caused by a steady radiance of light. In Kineticharts, we add soft fluffy light to the contours of the chart components. The fourth pattern imitates the tender motion of breath of living creatures. To recreate this motion, we let the chart components expand and shrink slowly and rhythmically in Kineticharts.</p><p>Excitement Excitement is the state when people feel very enthusiastic and eager. According to our need-finding study, data stories that aim to boost optimism or raise passion usually adopt an exciting tone. Relevant topics include economic and social progress, sports, or games. In animation design, we found that excitement usually requires fast and forceful motion. Accordingly, in Kineticharts, we use five kinetic patterns to convey excitement (Fig. <ref type="figure" target="#fig_1">3</ref> No. <ref type="bibr" target="#b45">[46]</ref><ref type="bibr" target="#b46">[47]</ref><ref type="bibr" target="#b47">[48]</ref><ref type="bibr" target="#b48">[49]</ref><ref type="bibr" target="#b49">[50]</ref><ref type="bibr" target="#b50">[51]</ref><ref type="bibr" target="#b51">[52]</ref><ref type="bibr" target="#b52">[53]</ref><ref type="bibr" target="#b53">[54]</ref><ref type="bibr" target="#b54">[55]</ref><ref type="bibr" target="#b55">[56]</ref><ref type="bibr" target="#b56">[57]</ref><ref type="bibr" target="#b57">[58]</ref><ref type="bibr" target="#b58">[59]</ref><ref type="bibr" target="#b59">[60]</ref>. The first pattern is drop. This pattern lets the charts drop heavily from the outside of the scene and shake the scene a bit due to the heavy force. Another typical pattern of excitement is erupt, which denotes accumulating power first and then bursting forth suddenly. Thus, in Kineticharts, we let the charts first tremble quickly and then release. The third pattern, rush, means moving with urgent haste. In Kineticharts, we let the chart components rush to their positions, exceed their supposed positions a bit, and then move back, following the law of inertia. Depth is also a cause of excitement as it expands the sense of distance <ref type="bibr" target="#b59">[60]</ref>. In Kineticharts, we use hit to pull the chart from a distant place to the front at full speed. We also add several speed lines stretching from afar to enhance the sense of depth. The last pattern, chase, elicits excitement using camera movement. In cinematography, a side view is often used to increase the depth of the scene <ref type="bibr" target="#b87">[89]</ref>. Similarly, in Kineticharts, we use a close-up to shoot the data points and let the camera chase newly-entered data points from a side view.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">STUDY I: EVALUATING AFFECT RECOGNIZABILITY</head><p>After finishing the design of Kineticharts, we conducted Study I to evaluate whether Kineticharts can convey affects accurately.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Methods</head><p>To measure the recognizability of design <ref type="bibr" target="#b33">[34,</ref><ref type="bibr" target="#b56">57]</ref>, Study I asked people to view the charts in Kineticharts and choose the affects they convey. We conducted Study I three times (marked as S1, S2, S3) with 80 participants in total to refine Kineticharts until all the charts had reached a satisfactory level of accuracy. According to previous research <ref type="bibr" target="#b56">[57]</ref>, researchers considered affective design as effective if the recognition accuracy is higher than 50% (the lowest threshold that most participants choose the right answer) or 60%. Note that the study procedures of S1, S2, and S3 were completely identical.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.1">Stimuli</head><p>We used Kineticharts as stimuli, which contain 60 animated charts in total. To avoid the influence of color on affective feelings, we made all the charts grey. Also, the visualized data were the same across all the charts (as shown in Fig. <ref type="figure" target="#fig_1">3</ref>). Other visual elements such as chart axes, labels, and legends were also kept identical across all the charts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.2">Participants</head><p>We recruited 80 college students (55 females), aged from 18 to 41 (M = 23.93, SD= 3.92), by making an open call on social medial platforms. We also sent the message to several big chat groups (&gt;50 people) and encouraged people to forward the message to others. The participants recruited have diversified backgrounds (Bachelor's or equivalent: 43.7%, Master's or equivalent: 46.2%, Doctoral or equivalent: 10.0%) and majors, such as design, computer science, and social science. Among the 80 participants, 28 were recruited for S1, 26 for S2, and 26 for S3. Each participant only took part in a discrete round of the study. We paid the participants $9 per hour, and the typical time taken to complete the study was 10 minutes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.3">Study Procedure</head><p>This study was conducted via an online questionnaire. First, we introduced our research intent and core concepts (e.g., affective design, data story) to the participants. Then, we presented the participants with 30 charts randomly chosen from the 60 Kineticharts, one at a time. To avoid the bias caused by the order effect, we randomly shuffled the charts in the chart sequence and presented them to the participants in different orders. After viewing each of the 30 charts, the participants answered a multiple-choice question. We offered six options, including joy, amusement, surprise, tenderness, excitement, and none of them, and asked the participants to pick the one option that best described their feelings. If the participants found the affect was unclear or ambiguous, they could select none of them. After evaluating all the 30 charts, the participants filled out a survey to provide their demographic information (i.e., age, gender, education level) and leave any feedback for the study. Afterward, we analyzed which charts tended to be interpreted inaccurately by the participants and conducted brief interviews with the participants via chatting software to understand why. We also asked the participants who chose none of them (this option has been selected 104 times by 33 participants in total) to explain their choices to help us improve our design. We used these interviews to collect more specific feedback about our design and to identify possible improvements.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Analysis and Results</head><p>After S1, 53 of the 60 Kineticharts earned an accuracy rate above 50% and 7 charts had an accuracy rate below 50%. User feedback showed that the wrong interpretation was mainly caused by: (1) a failure of understanding the kinetic patterns, and (2) a lack of distinction between affects. For example, unbox was meant to mimic the process of opening a gift box. In the first design version, we did this by expanding the axes suddenly. However, several participants said that this motion was too sudden for them to understand its meaning. Thus, we refined unbox by letting the axes first expand a little bit, pause for a while, and then expand completely. Besides, some participants had difficulty in distinguishing the animation of joy and amusement, as well as the animation of surprise and excitement. Therefore, we carefully analyzed all the comments and refined our design by reducing the overlapping animation techniques between different affects and strengthening the unique characteristics of each affect. For example, the core spirit of surprise should be creating suspense, and the key features of amusement should be personification and cartoonization. With these issues in mind, we revised Kineticharts and conducted S2. The second round of Study I (S2) yielded better results, while 3 charts still had an accuracy rate below 50%. For example, the chase of the pie (No.60 in Fig. <ref type="figure" target="#fig_1">3</ref>) initially used a camera to chase the growth of chart components from a side view. However, many participants said that viewing a pie chart from the side was strange. Thus, we created a new version of chase for pie charts, which uses a bird's-eye view to better suit the shape of the pie. We also fine-tuned the design of other Kineticharts according to user comments (e.g., "I may want amusement to look more childish.").</p><p>Fig. <ref type="figure" target="#fig_2">4</ref> shows the results of the last round (S3). Each chart in Kineticharts had been viewed by 13 times on average. All charts received an accuracy above 50% and 54 of the 60 Kineticharts earned an accuracy rate above 60%. Among the five affects, tenderness had the highest mean accuracy rate (96%, SD = 0.04),followed by surprise (78%, SD = 0.11), joy (73%, SD = 0.10), excitement (68%, SD = 0.09), and amusement (65%, SD = 0.12). The average accuracy of bar charts (M = 76%, SD = 0.14), line charts (M = 75%, SD = 0.16), and pie charts (M = 78%, SD = 0.14) was similar. Given that we presented the participants with only animated charts without any contextual information, we can say that the animations themselves can successfully deliver affects.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">STUDY II: APPLYING KINETICHARTS TO DATA STORIES</head><p>In this section, we conducted a crowdsourcing study with 197 participants to apply Kineticharts to data stories and examine the benefits brought by Kineticharts, compared to the commonly observed animations in the wild.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Methods</head><p>To assess whether Kineticharts is better at augmenting the affective expressiveness of data stories compared to existing animation techniques, we used the animations in DataClips <ref type="bibr" target="#b2">[3]</ref>, an authoring tool for data videos, as the baseline. Our reasons are as follows. First, the authors of Dataclips had analyzed a corpus of data videos and identified the most frequently applied animations in data videos. In other words, the animations in Dataclips are common in the wild. Second, the animations in Dataclips were not designed intentionally to convey affects. Using them as the baseline can help us examine whether Kineticharts, which were designed intentionally to convey affects, would perform significantly better in affect-related metrics. Last, Dataclips is a system available online, making it possible for us to replicate its animations. Based on these considerations, we replicated the animations in DataClips <ref type="bibr" target="#b2">[3]</ref> and used them as the baseline. For example, In DataClips, when a bar chart enters the scene, its bars grow one by one; when a line chart is created, the lines and the data points reveal gradually from left to right; when a pie chart enters, its slices grow radially. Here are our hypotheses: H1: Kineticharts will not lower data comprehension compared to the baseline animation.</p><p>H2: Kineticharts will lead to greater story expressiveness compared to the baseline animation.</p><p>H3: Kineticharts will lead to greater affective engagement compared to the baseline animation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1.1">Stimuli</head><p>To create the stimuli, we first referred to our findings from the preliminary study, which shed light on which kind of stories tend to express the five affects. For example, we found that entertainment is a typical topic of joyous stories and social progress is a common topic of exciting stories. Accordingly, we decided on two story topics for each of the five affects: vacations and movies for joy, income inequality and science knowledge for surprise, economic growth and sports for excitement, yoga and nature for tenderness, and pets and kids for amusement. Within each story topic, we created three independent story pieces, visualized into bar charts, line charts, and pie charts, respectively. In total, we created 30 data story pieces (i.e., 5 affects  2 topics  3 charts). The story pieces were adapted from published data stories by the first author and two experts we interviewed in Section 3. We then conducted a pilot study with 8 participants to ensure that the data story pieces had similar complexity and would not overburden the participants. Specifically, we assessed the complexity of the stories by asking the participants "did you find that a story is more complex than others?" and "do you think that the amount of information is comfortable for you to read?" in a post-study interview. We originally designed stories with nine data points, seven data points, and five data points and found that the participants were most comfortable with the five-data-point version as it cost them the least reading and interpreting texts. At last, all the charts comprised five data points. For each of the story pieces, we animated it with both Kineticharts and the baseline, thus resulting in 150 animated story pieces. The 150 animated story pieces served as the stimuli can be accessed at https://kineticharts.idvxlab.com/.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1.2">Participants</head><p>We recruited 197 participants who speak English as their first language from Prolific. As a crowdsourcing platform, Prolific offers a diversified population <ref type="bibr" target="#b68">[69]</ref>, making it more likely for us to reach the target audience of data stories, namely the general public. Among the participants, 108 were female, 87 were male, and 2 identified as non-binary. Their ages ranged from 18 to 76 (M = 36.67, SD = 13.73) and their educational level varied (Less than a high school diploma: 0.9%, High school or equivalent: 30.1%, Bachelor's or equivalent: 48.4%, Master's or equivalent: 19.8%, Doctoral or equivalent: 0.4%, Others: 0.4%). We paid the participants $9 per hour, and the average time for one participant to complete the study was 45.20 minutes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1.3">Measurements</head><p>To measure data comprehension, we referred to the method of Bateman et al. <ref type="bibr" target="#b6">[7]</ref> who broke down data comprehension into four specific aspects, including (1) the subject ("what is the subject of the chart?"), <ref type="bibr" target="#b1">(2)</ref> values ("what are the displayed categories and values?"), (3) trend ("what is the basic trend of the graph? (only for line charts)"), and (4) value message ("what message do you think the storyteller wants to communicate?"). In our study, we also asked the participants questions (1)-(3). To focus on the affective expressiveness of data stories, we rephrased <ref type="bibr" target="#b3">(4)</ref> as "what affective messages do you think the storyteller wants to communicate?" and used the modified question during the full study. We did not find standard metrics for measuring the affective expressiveness of storytelling. We used four indicators, including the creation of the story tone, the delivery of affective messages, the relatability of the story content, and the overall level of the story's affective expressiveness. The indicators were partly inspired by literature <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b69">71]</ref> that has suggested some important aspects of storytelling such as the "delivery of affective messages", and insights from our expert interviews. To measure users' affective engagement, we referred to previous research <ref type="bibr" target="#b39">[40,</ref><ref type="bibr" target="#b66">67]</ref> and decided on eight measurements for affective engagement, including affective arousal, the feeling of fun, interest, focused attention, enjoyment, the feeling of novelty, the feeling of aesthetics, and likability. During the study, the participants set scores to the four prompts of story expressiveness (e.g., "I think the animation helps create a tone for the story") and eight prompts of affective engagement (e.g., "I like the animation") using a 5-point Likert scale (1 denotes "strongly disagree", and 5 denotes "strongly agree").</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1.4">Study Procedure</head><p>The study consisted of three parts. In the first part, we presented the participants with an introduction to the key concepts in our research (e.g., data story, affective design) and told them that they were going to view a set of animated charts and evaluate the animation design of the charts. We did not inform the participants which animated charts were designed by the experimenter. Then, the participants were shown ten animated data story pieces randomly chosen from all the stimuli, one at a time. When assigning the story pieces to the participants, we ensured that at least one story piece was animated with the baseline and the participants would not view the same animation technique nor story piece twice. After viewing each of the story pieces, the participants were asked to answer four questions about story comprehension (i.e., subject, values, trend (for line charts only), value message), and assign scores to four questions about story expressiveness and eight questions about affective engagement in a questionnaire. After viewing the 10 story pieces, the participants were guided to a summary page where they provided demographic information (e.g., gender, age). They were also presented with the 10 animated charts that they had viewed and were asked to choose which animation(s) impressed them most, which animation(s) did they like most, and to give their reasons. Last, the participants were welcome to leave any feedback for us.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Analysis and Results</head><p>We excluded the answers from participants whose writing did not make sense or could not explain their choices (e.g., "none", "no reason"). As a result, we got 1670 valid ratings and each stimulus was viewed 11.13 times on average.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.1">Data Comprehension</head><p>To evaluate H1, we tested the following null hypothesis: H0: the animation condition (Kineticharts or animation baseline) has no effect on any of the metrics of data comprehension. For the four questions about data comprehension (i.e., subject, category, trend, value message), we collected 1670, 1670, 569, and 1670 answers, respectively. We manually coded the correctness of subject, category, and trend following the four-point scale proposed by <ref type="bibr" target="#b6">[7]</ref>: 3 for all correct, 2 for mostly correct, 1 for mostly incorrect, and 0 for all incorrect. As the question about value messages did not have an absolutely correct answer, we coded it with "yes" or "no" to describe whether the viewers had received any affective messages. Two authors first coded 15% answers independently, and then compared their codes and discussed until reaching 100% agreement. Then, they went on to finish coding all the remaining data. Mann-Whitney U tests showed that Kineticharts earned similar scores in people's comprehension of the story subject (M = 2.92), data categories and values (M = 2.22), and trend (M = 2.85) with the baseline (M = 2.90, 2.18, 2.90, respectively), and the differences were not significant (p = .737, .257, .348, respectively). Thus, the null hypothesis is retained, providing support for our H1 hypothesis. As for the value message question, 13% of the answers did not address the question explicitly. Thus, we analyzed the remaining answers and found that when viewing the baseline, 61% of participants said that they did not receive any affective messages (e.g., "The data provides factual information only.") However, 68% of participants who watched Kineticharts successfully received affective messages (e.g., "The way the chart run into the scene really creates a fun, childish atmosphere, where I can imagine children playing."), suggesting that Kineticharts might be more prone to delivering affective messages.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.2">Story Expressiveness</head><p>To evaluate H2, we tested the following null hypothesis: H0: the animation condition (Kineticharts or animation baseline) has no effect on any of the metrics of story expressiveness. Mann-Whitney U tests showed that Kineticharts earned significantly higher (p &lt; .01) scores in the four indicators concerning story expressiveness (see Fig. <ref type="figure" target="#fig_4">5</ref>), including the creation of a story tone (M = 3.89), the delivery of affective messages (M = 3.73), content relatability (M = 3.69), and the overall affective expressiveness (M = 3.62) than the baseline (M = 3.22, 3.03, 3.03, 2.86, respectively). Besides, Fig. <ref type="figure" target="#fig_4">5</ref> suggests that the difference between Kineticharts and the baseline within each affect was significant too. Then, we conducted pairwise comparisons between each animation in Kineticharts and the baseline. The results showed that 52 of the 60 Kineticharts (87%) significantly outperformed the baseline in at least one metric in story expressiveness when  = .05. On the downside, eight animations such as erupt bar (No.49) and unveil pie (No.24) did not outperform the baseline significantly in story expressiveness when  = .05, although their mean scores were higher than the baseline (we discuss these animations in <ref type="bibr">Section 7)</ref>. Given that most Kineticharts outweighed the baseline in the indicators of story expressiveness, the null hypothesis is rejected, providing support for our H2 hypothesis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.3">Affective Engagement</head><p>To evaluate H3, we tested the following null hypothesis: H0: the animation condition (Kineticharts or animation baseline) has no effect on any of the metrics of affective engagement. Mann-Whitney U tests showed that Kineticharts were rated significantly higher (p &lt; .01) in all the indicators of affective engagement (see Fig. We also analyzed people's favorite animations. Among the 301 animations that were chosen as the most liked, 82% were Kineticharts. Among the 324 most impressive animations, 84% were Kineticharts. There was slight difference between the top 5 most liked animations and the top 5 most impressed animations. Shuffle (12.9%), undulate (9.6%), collide (7.6%), wiggle (7.3%), and ripple (5.6%) were the top liked animations, and the most impressed animations were shuffle (9.8%), wiggle (9.8%), undulate (7.4%), zoom (7.0%), and collide (6.7%). The qualitative feedback showed that people appreciated these animations because they enriched the story content (e.g., "it works very well with the content of the graph and the story behind it."),  enticed reading (e.g., "caught my attention and made me want to read more."), and were well designed (e.g., "I think these strike the best balance of being readable and aesthetically appealing.") Overall, since Kineticharts largely outperformed the baseline, the null hypothesis is rejected, providing support for our H3 hypothesis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">GALLERY</head><p>To demonstrate the potential application of Kineticharts, one author who was a data journalist and two authors who are professional visual designers have created ten short data stories using Kineticharts. Unlike the stimuli used in the user studies whose visual representations have been controlled, these new data stories were created to mimic real-world storytelling practice and show the possible utilization of Kineticharts. We created two stories for each of the five positive affects using Kineticharts. The stories were adapted from real data stories and are based on different data sizes or topics. We also integrated factors such as color, embellishment, and music into the stories to show how Kineticharts work in combination with other design techniques. The gallery can be accessed at https://kineticharts.idvxlab.com/.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">DISCUSSION</head><p>Here we list some design implications emerging from this work. First, in our need-finding study, negative affects were ranked relatively lower than positive affects in terms of the possibility to be conveyed by animation. This is an unexpected finding for us. One reason might be that the cognitive structures of affects are different and the experience of negative affects is often related to judgement-making <ref type="bibr" target="#b67">[68]</ref>. For example, empathy is related to how people judge the fortunes of others, and anger can be caused by judging something or somebody as wrong. To elicit these affects, designers may have to use more complex techniques to activate people's beliefs, moral values, or attitudes. We also noticed that even the five positive affects we designed for have different natures. When we reflected upon our iterative design process, we felt that the complexity of designing for amusement is the highest. One reason might be that the kinetic patterns of amusement are highly metaphorical.</p><p>Second, we found that making people understand and willingly accept the affects conveyed by animation can be difficult because people's interpretation of animation is dependent on their personal experience and thought patterns. For example, open and unveil were rated low by some of the participants because they did not receive the affective message (e.g., "I don't understand what the animation for.") or resist to accept the affective message (e.g., "the 'reveal' nature of the animation didn't fit for me at all."). Such involvement of subjectivity may pose difficulties for animation design. Third, it is not easy to balance the expressiveness and the functionality of animation. In this work, we fine-tuned Kineticharts multiple times to make them affective while presenting data clearly. However, the participants in our study still showed different opinions to several Kineticharts. For example, while some people enjoyed the vividness of erupt (e.g., "I quite like the tremble and the sudden reveal of the bars."), some thought it was too fast for their eyes (e.g., "A little bit of unease as the chart was pushed upwards quickly."). Thus, we suggest that when using these animations, designers be careful and avoid overwhelming or distracting viewers.</p><p>There are several limitations in this work. First, in the need-finding study, we composed a 13-affect list from literature and asked the participants to choose from the list. This approach has restricted the affects to a limited scope and may not capture the full landscape of all the affects elicited by data stories. Besides, the final affects we chose are all positive affects, and this has made us overlook the design of negative affects and conduct the user studies using the metrics concerning positive affects. Thus, we clarify that the contribution of this work mainly lies in the design of positive affects. Second, the participants we recruited for Study I are people who have some college education. Future work can include a wider population, more representative of the target audience of data stories. Third, we used the animations in Dataclips as the baseline in Study II without investigating their affective qualities. This has hindered us from knowing the exact influence of Kineticharts on affective responses to a certain extent. Using static charts as another baseline would allow us to assess the affective traits of both Dataclips and Kineticharts animations better. Besides, this work limits the visualizations in Kineticharts to three commonly used charts and only covers the build-up animation of charts. More work can be done to explore other kinds of animation in data stories, such as the animation for data transition. The specific attributes of animation, such as speed, continuity, and smoothness, are also worthy of further research. In the future, we plan to implement Kineticharts with programming and enable users to apply the animations to their own charts. It is also interesting to examine other affective design factors (e.g., color, narratives, music) in data stories, as well as how to deliver negative affects using design methods <ref type="bibr" target="#b17">[18]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9">CONCLUSION</head><p>In this work, we explore how to use animated charts to express five positive affects in data stories by incorporating practitioners of data stories into a need-finding study and proposing Kineticharts, an animation design scheme for creating charts that express joy, amusement, surprise, tenderness, and excitement. Two user studies indicated that Kineticharts can express the five affects accurately, and improve story expressiveness as well as enhance users' affective engagement with the stories without hindering data comprehension, compared to the animations in Dataclips. We envision that Kineticharts can be applied to fields such as data journalism to enrich the current practice of data storytelling and help spark interest from a larger audience, especially those who have less expertise in data. It can also be integrated into current tools or systems to facilitate the creation of affective data stories.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. The ranking of the affects desired by data stories (left) and the affects that can be conveyed by animation (right). The five affects we chose at last are highlighted.</figDesc><graphic coords="3,316.55,49.37,250.46,114.74" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. The design of Kineticharts, categorized according to the five affects.</figDesc><graphic coords="5,53.75,472.49,137.18,141.50" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. The results of Study I (S3) showing the percentages of participants who accurately recognized the affects expressed by Kineticharts.</figDesc><graphic coords="7,53.99,49.37,250.46,167.30" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>6), including affective arousal (M = 3.18), fun (M = 3.76), interest (M = 3.68), focused attention (M = 3.87), enjoyment (M = 3.71), novelty (M = 3.58), aesthetics (M = 3.69), and likability (M = 3.76) than the baseline (M = 2.47, 3.13, 3.18, 3.29, 3.23, 2.83, 3.29, 3.30, respectively). Fig. 6 suggests that if we compare Kineticharts with the baseline within each affect, their difference was also significant in terms of most metrics. Next, pairwise comparison further showed that 56 of the 60 Kineticharts (93%) significantly outperformed the baseline in at least one metric in affective engagement when  = .05. On the downside, four animations such as open (No.26) for line charts and unveil (No.24) for pie charts did not outperform the baseline significantly when  = .05.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. Mean scores for Kineticharts and the baseline in metrics concerning story expressiveness. Error bars represent 95% CI.</figDesc><graphic coords="8,307.55,572.81,250.46,139.10" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 6 .</head><label>6</label><figDesc>Fig. 6. Mean scores for Kineticharts and the baseline in metrics concerning affective engagement. Error bars represent 95% CI.</figDesc><graphic coords="9,53.99,49.37,513.02,150.14" type="bitmap" /></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS</head><p>Nan Cao is the corresponding author. This work was supported by NSFC 62072338 and NSF Shanghai 20ZR1461500. We would like to thank all the reviewers for their constructive feedback.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Understanding data videos: Looking at narrative visualization through the cinematography lens</title>
		<author>
			<persName><forename type="first">F</forename><surname>Amini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Henry Riche</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Hurter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Irani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the CHI Conference on Human Factors in Computing Systems</title>
				<meeting>the CHI Conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1459" to="1468" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Hooked on data videos: assessing the effect of animation and pictographs on viewer engagement</title>
		<author>
			<persName><forename type="first">F</forename><surname>Amini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">H</forename><surname>Riche</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Leboe-Mcgowan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Irani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Advanced Visual Interfaces</title>
				<meeting>the International Conference on Advanced Visual Interfaces</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="1" to="9" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Authoring data-driven videos with dataclips</title>
		<author>
			<persName><forename type="first">F</forename><surname>Amini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">H</forename><surname>Riche</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Monroy-Hernandez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Irani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="501" to="510" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Narrative design patterns for data-driven storytelling</title>
		<author>
			<persName><forename type="first">B</forename><surname>Bach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Stefaner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Boy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Drucker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Bartram</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wood</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Ciuccarelli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Engelhardt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Koeppen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Tversky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Data-Driven Storytelling</title>
				<meeting><address><addrLine>Boca Raton, FL, US</addrLine></address></meeting>
		<imprint>
			<publisher>CRC Press</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="107" to="133" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Fast, cheap, and good: Why animated gifs engage us</title>
		<author>
			<persName><forename type="first">S</forename><surname>Bakhshi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Shamma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Kennedy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">De</forename><surname>Juan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kaye</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the CHI Conference on Human Factors in Computing Systems</title>
				<meeting>the CHI Conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="575" to="586" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Affective color in visualization</title>
		<author>
			<persName><forename type="first">L</forename><surname>Bartram</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Patra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Stone</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the CHI Conference on Human Factors in Computing Systems</title>
				<meeting>the CHI Conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1364" to="1374" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Useful junk? the effects of visual embellishment on comprehension and memorability of charts</title>
		<author>
			<persName><forename type="first">S</forename><surname>Bateman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">L</forename><surname>Mandryk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Gutwin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Genest</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Mcdine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Brooks</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the CHI Conference on Human Factors in Computing Systems</title>
				<meeting>the CHI Conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="2573" to="2582" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Affective responses mediating acceptance of advertising</title>
		<author>
			<persName><forename type="first">R</forename><surname>Batra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">L</forename><surname>Ray</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Consumer Research</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="234" to="249" />
			<date type="published" when="1986">1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Possessions and the extended self</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">W</forename><surname>Belk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Consumer Research</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="139" to="168" />
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Narration in the fiction film</title>
		<author>
			<persName><forename type="first">D</forename><surname>Bordwell</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013">2013</date>
			<pubPlace>Routledge, Abingdon, England</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">An empirical study on using visual embellishments in visualization</title>
		<author>
			<persName><forename type="first">R</forename><surname>Borgo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Abdul-Rahman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Mohamed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">W</forename><surname>Grant</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Reppa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Floridi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2759" to="2768" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Beyond memorability: Visualization recognition and recall</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Borkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Bylinskii</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">W</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">M</forename><surname>Bainbridge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">S</forename><surname>Yeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Borkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Pfister</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Oliva</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="519" to="528" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">What makes a visualization memorable?</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Borkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">A</forename><surname>Vo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Bylinskii</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Isola</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sunkavalli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Oliva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Pfister</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2306" to="2315" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Showing people behind data: Does anthropomorphizing visualizations elicit more empathy for human rights data?</title>
		<author>
			<persName><forename type="first">J</forename><surname>Boy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">V</forename><surname>Pandey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Emerson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Satterthwaite</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Nov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Bertini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the CHI Conference on Human Factors in Computing Systems</title>
				<meeting>the CHI Conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<biblScope unit="page" from="5462" to="5474" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Using thematic analysis in psychology</title>
		<author>
			<persName><forename type="first">V</forename><surname>Braun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Clarke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Qualitative Research in Psychology</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="77" to="101" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Timelines revisited: A design space and considerations for expressive storytelling</title>
		<author>
			<persName><forename type="first">M</forename><surname>Brehmer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Bach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">H</forename><surname>Riche</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Munzner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="2151" to="2164" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">A comparative evaluation of animation and small multiples for trend visualization on mobile phones</title>
		<author>
			<persName><forename type="first">M</forename><surname>Brehmer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Isenberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">K</forename><surname>Choe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="364" to="374" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Emotional data visualization: Periscopic&apos;s &quot;u.s. gun deaths&quot; and the challenge of uncertainty</title>
		<author>
			<persName><forename type="first">A</forename><surname>Cairo</surname></persName>
		</author>
		<ptr target="https://www.peachpit.com/articles/article.aspx?p=2036558" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Common fate for animated transitions in visualization</title>
		<author>
			<persName><forename type="first">A</forename><surname>Chalbi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ritchie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Roussel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Elmqvist</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Chevalier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="386" to="396" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">The not-so-staggering effect of staggered animated transitions on visual tracking</title>
		<author>
			<persName><forename type="first">F</forename><surname>Chevalier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Dragicevic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Franconeri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2241" to="2250" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Animations 25 years later: New roles and opportunities</title>
		<author>
			<persName><forename type="first">F</forename><surname>Chevalier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">H</forename><surname>Riche</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Plaisant</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Chalbi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Hurter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Working Conference on Advanced Visual Interfaces</title>
				<meeting>the International Working Conference on Advanced Visual Interfaces</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="280" to="287" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Describing the emotional states that are expressed in speech</title>
		<author>
			<persName><forename type="first">R</forename><surname>Cowie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">R</forename><surname>Cornelius</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Speech Communication</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">1-2</biblScope>
			<biblScope unit="page" from="5" to="32" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">A taxonomy of motion applications in data visualization</title>
		<author>
			<persName><forename type="first">I</forename><surname>De La Torre-Arenas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Cruz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Symposium on Computational Aesthetics</title>
				<meeting>the Symposium on Computational Aesthetics</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1" to="2" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">The multiple affective outcomes of aids psas: Fear appeals do more than scare people</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">P</forename><surname>Dillard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A</forename><surname>Plotnick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">C</forename><surname>Godbold</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">S</forename><surname>Freimuth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Edgar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communication Research</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="44" to="72" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Humor in advertising: A behavioral perspective</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">P</forename><surname>Duncan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Academy of Marketing Science</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="285" to="306" />
			<date type="published" when="1979">1979</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">The power of feelings in understanding advertising effects</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Edell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">C</forename><surname>Burke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Consumer Research</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="421" to="433" />
			<date type="published" when="1987">1987</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">The role of affect in marketing</title>
		<author>
			<persName><forename type="first">S</forename><surname>Erevelles</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Business Research</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="199" to="215" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Evaluating affective features of 3d motionscapes</title>
		<author>
			<persName><forename type="first">C</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Bartram</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">E</forename><surname>Riecke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM Symposium on Applied Perception</title>
				<meeting>the ACM Symposium on Applied Perception</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="23" to="30" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Animation for visualization: Opportunities and drawbacks</title>
		<author>
			<persName><forename type="first">D</forename><surname>Fisher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Beautiful Visualization. O&apos;Reilly Media</title>
				<meeting><address><addrLine>Sebastopol, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Oh my goddess!</title>
		<author>
			<persName><forename type="first">K</forename><surname>Fujishima</surname></persName>
		</author>
		<ptr target="https://www.pinterest.com/pin/777504323159640634/" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Emotion elicitation using films</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">W</forename><surname>Levenson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognition and Emotion</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="87" to="108" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">The fallen of world war ii</title>
		<author>
			<persName><forename type="first">N</forename><surname>Halloran</surname></persName>
		</author>
		<ptr target="https://www.youtube.com/watch?v=DwKPFT-RioU" />
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Interview methodology</title>
		<author>
			<persName><forename type="first">H</forename><surname>Hamill</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014">2014</date>
			<publisher>Oxford University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Kineticons: using iconographic motion in graphical user interface design</title>
		<author>
			<persName><forename type="first">C</forename><surname>Harrison</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hsieh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">D</forename><surname>Willis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Forlizzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">E</forename><surname>Hudson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the CHI Conference on Human Factors in Computing Systems</title>
				<meeting>the CHI Conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="1999" to="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Infographic aesthetics: Designing for the first impression</title>
		<author>
			<persName><forename type="first">L</forename><surname>Harrison</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Reinecke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the CHI Conference on Human Factors in Computing Systems</title>
				<meeting>the CHI Conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1187" to="1190" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Animated transitions in statistical data graphics</title>
		<author>
			<persName><forename type="first">J</forename><surname>Heer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Robertson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1240" to="1247" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Charlie&apos;s quirky dance</title>
		<author>
			<persName><forename type="first">C</forename><surname>Huang</surname></persName>
		</author>
		<ptr target="https://dribbble.com/shots/3061819-Charlie-s-Quirky-dance" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Visualization rhetoric: Framing effects in narrative visualization</title>
		<author>
			<persName><forename type="first">J</forename><surname>Hullman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Diakopoulos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2231" to="2240" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">A deeper understanding of sequence in narrative visualization</title>
		<author>
			<persName><forename type="first">J</forename><surname>Hullman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Drucker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">H</forename><surname>Riche</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Fisher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Adar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2406" to="2415" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Affective engagement for communicative visualization: quick and easy evaluation using survey instruments</title>
		<author>
			<persName><forename type="first">Y.-H</forename><surname>Hung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Parsons</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Visualization for Communication</title>
				<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Positive affect facilitates creative problem solving</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Isen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">A</forename><surname>Daubman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">P</forename><surname>Nowicki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Personality and Social Psychology</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1122" to="1131" />
			<date type="published" when="1987">1987</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">Happy little orange</title>
		<author>
			<persName><forename type="first">N</forename><surname>Ivanova</surname></persName>
		</author>
		<ptr target="https://dribbble.com/shots/3563286-Happy-little-orange" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">The feeling of numbers: Emotions in everyday engagements with data and their visualisation</title>
		<author>
			<persName><forename type="first">H</forename><surname>Kennedy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">L</forename><surname>Hill</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sociology</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="830" to="848" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Embracing diversity in user needs for affective design</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">M</forename><surname>Khalid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Applied Ergonomics</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="409" to="418" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Storytelling: The next step for visualization</title>
		<author>
			<persName><forename type="first">R</forename><surname>Kosara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Mackinlay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="44" to="50" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title level="m" type="main">Metaphor and emotion: Language, culture, and body in human feeling</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Kvecses</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003">2003</date>
			<publisher>Cambridge University Press</publisher>
			<pubPlace>Cambridge, England</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Smile or scowl? looking at infographic design through the affective lens</title>
		<author>
			<persName><forename type="first">X</forename><surname>Lan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Cao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="2796" to="2807" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Lang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Bradley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">N</forename><surname>Cuthbert</surname></persName>
		</author>
		<idno>A-8</idno>
		<title level="m">International affective picture system (IAPS): Affective ratings of pictures and instruction manual</title>
				<meeting><address><addrLine>Gainesville, FL</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
		<respStmt>
			<orgName>University of Florida</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report Technical Report</note>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Principles of traditional animation applied to 3d computer animation</title>
		<author>
			<persName><forename type="first">J</forename><surname>Lasseter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Annual Conference on Computer Graphics and Interactive Techniques</title>
				<meeting>the Annual Conference on Computer Graphics and Interactive Techniques</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="1987">1987</date>
			<biblScope unit="page" from="35" to="44" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Dealing with feelings: Positive and negative discrete emotions as mediators of news framing effects</title>
		<author>
			<persName><forename type="first">S</forename><surname>Lecheler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">R</forename><surname>Schuck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">H</forename><surname>De Vreese</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="189" to="209" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
		<title level="m" type="main">The emotional brain: The mysterious underpinnings of emotional life</title>
		<author>
			<persName><forename type="first">J</forename><surname>Ledoux</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998">1998</date>
			<publisher>Simon &amp; Schuster</publisher>
			<pubPlace>New York, NY, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Using kinetic typography to convey emotion in text-based interpersonal communication</title>
		<author>
			<persName><forename type="first">J</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Jun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Forlizzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">E</forename><surname>Hudson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Designing Interactive Systems</title>
				<meeting>the Conference on Designing Interactive Systems</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="41" to="49" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">The kinetic typography engine: an extensible system for animating expressive text</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Forlizzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">E</forename><surname>Hudson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM symposium on User Interface Software and Technology</title>
				<meeting>the ACM symposium on User Interface Software and Technology</meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="81" to="90" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Real-time movieinduced discrete emotion recognition from eeg signals</title>
		<author>
			<persName><forename type="first">Y.-J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Shi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Affective Computing</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="550" to="562" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Affective motion textures</title>
		<author>
			<persName><forename type="first">M</forename><surname>Lockyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Bartram</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computers &amp; Graphics</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="776" to="790" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">The role of affect in decision making</title>
		<author>
			<persName><forename type="first">G</forename><surname>Loewenstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lerner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Handbook of Affective Science</title>
				<meeting><address><addrLine>Oxford, England</addrLine></address></meeting>
		<imprint>
			<publisher>Oxford University Press</publisher>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="619" to="642" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Guidelines for depicting emotions in storyboard scenarios</title>
		<author>
			<persName><forename type="first">X</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Forlizzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Dow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">8th International design and emotion conference</title>
				<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<monogr>
		<title level="m" type="main">The crowd goes wild</title>
		<author>
			<persName><forename type="first">Mana</forename></persName>
		</author>
		<ptr target="https://dribbble.com/shots/5709898-The-crowd-goes-wild" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<monogr>
		<title level="m" type="main">A surprise viral hit: Income inequality, the movie</title>
		<author>
			<persName><surname>Marketplace</surname></persName>
		</author>
		<ptr target="https://www.marketplace.org/2013/03/08/surprise-viral-hit-income-inequality-movie/" />
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<monogr>
		<title level="m" type="main">Making comics: Storytelling secrets of comics, manga and graphic novels</title>
		<author>
			<persName><forename type="first">S</forename><surname>Mccloud</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006">2006</date>
			<publisher>William Morrow Paperbacks</publisher>
			<pubPlace>New York, NY, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Visual narrative flow: Exploring factors shaping data visualization story reading experiences</title>
		<author>
			<persName><forename type="first">S</forename><surname>Mckenna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Henry Riche</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Boy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Meyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics Forum</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="377" to="387" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Pleasure-arousal-dominance: A general framework for describing and measuring individual differences in temperament</title>
		<author>
			<persName><forename type="first">A</forename><surname>Mehrabian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Current Psychology</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="261" to="292" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Mikels</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">L</forename><surname>Fredrickson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">R</forename><surname>Larkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">M</forename><surname>Lindberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Maglio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">A</forename><surname>Reuter-Lorenz</surname></persName>
		</author>
		<title level="m">Emotional category data on images from the international affective picture system. Behavior Research Methods</title>
				<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="626" to="630" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Wordnet: a lexical database for english</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">A</forename><surname>Miller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="39" to="41" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Coding issues in grounded theory</title>
		<author>
			<persName><forename type="first">A</forename><surname>Moghaddam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Issues in educational research</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="52" to="66" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<monogr>
		<title level="m" type="main">Thinking positively: Using positive affect when designing health messages. In Designing health messages: Approaches from communication theory and public health practice</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Monahan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1995">1995</date>
			<publisher>Sage Publications</publisher>
			<biblScope unit="page" from="81" to="98" />
			<pubPlace>London, England</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">What is user engagement? a conceptual framework for defining user engagement with technology</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">L</forename><surname>O'brien</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">G</forename><surname>Toms</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Society for Information Science and Technology</title>
		<imprint>
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="938" to="955" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<monogr>
		<title level="m" type="main">The cognitive structure of emotions</title>
		<author>
			<persName><forename type="first">A</forename><surname>Ortony</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">L</forename><surname>Clore</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Collins</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1990">1990</date>
			<publisher>Cambridge university press</publisher>
			<pubPlace>Cambridge, England</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Beyond the turk: Alternative platforms for crowdsourcing behavioral research</title>
		<author>
			<persName><forename type="first">E</forename><surname>Peer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Brandimarte</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Samat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Acquisti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Social Psychology</title>
		<imprint>
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="page" from="153" to="163" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">What makes a good story?: Towards the production of conversational narratives</title>
		<author>
			<persName><forename type="first">U</forename><forename type="middle">M</forename><surname>Quasthoff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Nikolaus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Psychology</title>
				<meeting><address><addrLine>Amsterdam, The Netherlands</addrLine></address></meeting>
		<imprint>
			<publisher>Elsevier</publisher>
			<date type="published" when="1982">1982</date>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="16" to="28" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Dancing with words: Using animated text for captioning</title>
		<author>
			<persName><forename type="first">R</forename><surname>Rashid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Vy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Hunt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">I</forename><surname>Fels</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Human-Computer Interaction</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="505" to="519" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<monogr>
		<title level="m" type="main">Data-driven storytelling</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">H</forename><surname>Riche</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Hurter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Diakopoulos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Carpendale</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
			<publisher>CRC Press</publisher>
			<pubPlace>Boca Raton, FL, US</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">Effectiveness of animation in trend visualization</title>
		<author>
			<persName><forename type="first">G</forename><surname>Robertson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Fernandez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Fisher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Stasko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1325" to="1332" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">A circumplex model of affect</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Russell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Personality and Social psychology</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1161" to="1178" />
			<date type="published" when="1980">1980</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">Beyond usability and performance: A review of user experience-focused evaluations in visualization</title>
		<author>
			<persName><forename type="first">B</forename><surname>Saket</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Endert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Stasko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Workshop on Beyond Time and Errors on Novel Evaluation Methods for Visualization</title>
				<meeting>the Workshop on Beyond Time and Errors on Novel Evaluation Methods for Visualization</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="133" to="142" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">Assessing the effectiveness of a large database of emotion-eliciting films: A new tool for emotion researchers</title>
		<author>
			<persName><forename type="first">A</forename><surname>Schaefer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Nils</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Sanchez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Philippot</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognition and Emotion</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1153" to="1172" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">Narrative visualization: Telling stories with data</title>
		<author>
			<persName><forename type="first">E</forename><surname>Segel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Heer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1139" to="1148" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main">Calliope: Automatic visual data story generation from a spreadsheet</title>
		<author>
			<persName><forename type="first">D</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Cao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="453" to="463" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<analytic>
		<title level="a" type="main">Communicating with motion: A design space for animated visual narratives in data videos</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Lan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Cao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the CHI Conference on Human Factors in Computing Systems</title>
				<meeting>the CHI Conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="1" to="13" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<analytic>
		<title level="a" type="main">Designing emotional expressions of conversational states for voice assistants: Modality and engagement</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Cao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Extended Abstracts of the CHI Conference on Human Factors in Computing Systems</title>
				<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<monogr>
		<title level="m" type="main">Depechemood: a lexicon for emotion analysis from crowd-annotated news</title>
		<author>
			<persName><forename type="first">J</forename><surname>Staiano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Guerini</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1405.1605</idno>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b81">
	<monogr>
		<title level="m" type="main">Emerging and recurring data-driven storytelling techniques: Analysis of a curated collection of recent stories</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">D</forename><surname>Stolper</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Henry Riche</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Stasko</surname></persName>
		</author>
		<idno>MSR-TR-2016-14</idno>
		<imprint>
			<date type="published" when="2016-04">April 2016</date>
		</imprint>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b82">
	<monogr>
		<title level="m" type="main">The illusion of life: Disney animation</title>
		<author>
			<persName><forename type="first">F</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Johnston</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Thomas</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1995">1995</date>
			<publisher>Hyperion Books</publisher>
			<pubPlace>New York, NY, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b83">
	<analytic>
		<title level="a" type="main">Understanding the design space and authoring paradigms for animated data graphics</title>
		<author>
			<persName><forename type="first">J</forename><surname>Thompson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Stasko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics Forum</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="207" to="218" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b84">
	<analytic>
		<title level="a" type="main">The visual display of quantitative information</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">R</forename><surname>Tufte</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal for Healthcare Quality</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">15</biblScope>
			<date type="published" when="1985">1985</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b85">
	<analytic>
		<title level="a" type="main">Animation: can it facilitate?</title>
		<author>
			<persName><forename type="first">B</forename><surname>Tversky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">B</forename><surname>Morrison</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Betrancourt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Human-Computer Studies</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="247" to="262" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b86">
	<analytic>
		<title level="a" type="main">Effects of color on emotions</title>
		<author>
			<persName><forename type="first">P</forename><surname>Valdez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mehrabian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: General</title>
		<imprint>
			<biblScope unit="volume">123</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="394" to="409" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b87">
	<monogr>
		<title level="m" type="main">Cinematic storytelling: The 100 most powerful film conventions every filmmaker must know</title>
		<author>
			<persName><forename type="first">J</forename><surname>Van Sijll</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005">2005</date>
			<publisher>Michael Wiese Productions</publisher>
			<pubPlace>Studio City, CA, US</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b88">
	<monogr>
		<title level="m" type="main">Morning surprise</title>
		<author>
			<persName><forename type="first">W</forename><surname>Hart</surname></persName>
		</author>
		<ptr target="https://dribbble.com/shots/14261810-Morning-Surprise" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b89">
	<monogr>
		<title level="m" type="main">Designing for emotion. A Book Apart</title>
		<author>
			<persName><forename type="first">A</forename><surname>Walter</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011">2011</date>
			<pubPlace>New York, NY, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b90">
	<analytic>
		<title level="a" type="main">Communicating emotions in online chat using physiological sensors and animated text</title>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Prendinger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Igarashi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Extended Abstracts of the CHI Conference on Human Factors in Computing Systems</title>
				<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="1171" to="1174" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b91">
	<analytic>
		<title level="a" type="main">Affective understanding in film</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L.-F</forename><surname>Cheong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Transactions on Circuits and Systems for Video Technology</title>
				<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="689" to="704" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b92">
	<analytic>
		<title level="a" type="main">An emotional response to the value of visualization</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Segal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Klatzky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">F</forename><surname>Keefe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Isenberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hurtienne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Hornecker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Dwyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Barrass</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer Graphics and Applications</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="8" to="17" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b93">
	<analytic>
		<title level="a" type="main">Comparing effectiveness and engagement of data comics and infographics</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Farinella</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Murray-Rust</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Henry Riche</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Bach</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the CHI Conference on Human Factors in Computing Systems</title>
				<meeting>the CHI Conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="1" to="12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b94">
	<analytic>
		<title level="a" type="main">Baby names, visualization, and social data analysis</title>
		<author>
			<persName><forename type="first">M</forename><surname>Wattenberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Symposium on Information Visualization, 2005. INFOVIS 2005</title>
				<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="1" to="7" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b95">
	<analytic>
		<title level="a" type="main">Human-centered emotion recognition in animated gifs</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Luo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Multimedia and Expo</title>
				<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="1090" to="1095" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b96">
	<analytic>
		<title level="a" type="main">Affective visualization and retrieval for music video</title>
		<author>
			<persName><forename type="first">S</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Tian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Multimedia</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="510" to="522" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
